Tuple 1:
Cleaned Title: equity startup
Cleaned Transcription: equity startup analysis equity split successful startup september herve lebreti describe report equity allocation startup based real case company went public filed go public company disclose lot information document must provide initial public offering ipo particular describe equity structure time event evolved company incorporation onwards could compile analyze rich information focus allocation equity founder employee manager investor board member large sample make possible also study allocation relatively field activity period foundation geographic origin startup silicon valley phenomenon equity major component value creation startup particularly silicon valley topic still much debated regular ebb flow cycle merit stock option ordinary preferred share many equity mechanism interestingly enough current status equity allocation startup output slow process began early day silicon valley fairchild semiconductor maybe first startup ever fairchild camera instrument put million half dollar founder felt needed return got option buy stock stock divided equally eight founder fairchild call eastern mentality didnt want anybody option stock eight entrepreneur started fairchild semiconductor decided individually together would gradually peel form enterprise couldnt get equity lot people felt giving equity people hadnt helped start company instrumental success fairchild camera instrument unwilling gradually peeled finally noyce moore left anecdote show lot frustration created bad stock allocation way indirectly positively frustration created incentive startup foundation new equity mechanism silicon valley remains today center place startup creation sixty year equity allocation optimized align interest startup stakeholder founder investor employee mainly also general public startup go public licensing entity university startup created intellectual property ip entity although quite well known noticed still room giving information equity allocation startup despite claimed one single best way allocate equity startup valentine founder sequoia capital one famous venture capital firm silicon valley invested firm including apple google oracle paypal youtube instagram yahoo whatsapp describes way people come team usually three four people typically heavyweight engineering complex process think u seen earlier day time remember saying well look well put money put blood sweat tear well split company founder hire people well come evenly kind arrangement well bubble got bigger bigger know coming saying well know well give money percent percent deal know supply demand thing gone back way starting team typical thing say well somewhere percent divide theyve got best thing since sliced bread think think know youll probably lose deal one guy grab equity allocation startup general idea equity allocation startup begin founder happened fairchild valentine describes startup founder usually team engineer founder also case singlefounder startup founding team split initial share company sometimes equally sometimes sometimes founder also need ip external entity usually former employer many case licensing entity receives founder equity exchange ip license founder agreed initial founding split may may allocate new share become standard way incentivizing startup partner silicon valley le region even becomes common practice partner mostly investor employee investor receive preferred share exchange capital invest startup whereas founder usually ordinary share employee receive stock option sweat tear may converted ordinary share point startup life may surprising reader learn real equality stakeholder preferred share privilege ordinary common share stock option even real share usually liquidity event ipo sale company share converted common share equality even voting power share maybe different business democracy often go along well equity allocation successful startup many year using nesheims template build capitalization table similar one shown table appendix date writing report compiled case next table summarize result first table describe startup term field activity period foundation geography figure financial situation amount venture capital vc raised yearly sale profit ipo well number employee number year go public following table give equity allocation ie much group founder keep ipo much employee investor get well allocation general public ipo additional interesting element added average age group founder element given relatively field activity table period foundation table geography table
Original Title: Equity in Startups
Original Transcription: ## Equity in Startups

### An analysis of the equity split in more than 400 successful startups.

### September 2017

**HERVE LEBRET**I describe in this report equity allocation in startups based on more than 400 real cases, most of them being companies which went public or had filed to go public. Such companies disclose a lot of information in the documents they must provide before their initial public offering (IPO) and in particular they describe the equity structure at the time of that event and how it evolved from the company incorporation onwards. I could compile and analyze that rich information with a focus on the allocation of equity to founders, employees and managers, investors, board members. The large sample makes it possible to also study that allocation relatively to the fields of activity, periods of foundation, and the geographic origin of startups.

## A Silicon Valley Phenomenon

Equity has been a major component of value creation in startups, particularly in Silicon Valley. The topic is still very much debated with regular ebb and flow cycles about the merits of stock options, ordinary and preferred shares, and many other equity mechanisms. Interestingly enough, the current status of equity allocation in startups is the output of a slow process which began in the early days of Silicon Valley in 1957, with Fairchild Semiconductor, maybe the first startup ever [1]: _"Fairchild Camera and Instrument put up the million and a half dollars that we [founders] felt we needed in return for which they got an option to buy all of our stock. And the stock was divided [equally] for each of the eight [founders]. [... Fairchild] had a very, what I call Eastern mentality in that they didn't want anybody to have any options in stock and the eight entrepreneurs who started Fairchild Semiconductor decided individually and together that they would gradually peel off, and form their own enterprises because they couldn't get any more equity in, and a lot of the people there felt that they should be giving equity to some of the people who hadn't helped start the company but were instrumental in its success. And Fairchild Camera and Instrument was unwilling to do that. So gradually they peeled off and finally by 1968 there were only Noyce and Moore left."_ This anecdote shows that a lot of frustration was created because of bad stock allocation and in a way, indirectly but positively, that frustration created incentives for more startup foundations and new equity mechanisms.

Silicon Valley remains today the center place for startup creation and after sixty years, equity allocation has been "optimized" to align the interests of all startup stakeholders, that is founders, investors and employees mainly, but also the general public when a startup goes public and licensing entities such as universities when a startup is created with the intellectual property (IP) of such entities. Although all this is quite well known [2, 3], I noticed there was still room for giving more information about equity allocation in startups.

Despite what was claimed above, there is not one single or best way to allocate equity in startups. Don Valentine, the founder of Sequoia Capital, one of the most famous venture capital firms in Silicon Valley, which invested in firms including Apple, Google, Oracle, PayPal, YouTube, Instagram, Yahoo! and WhatsApp describes it his way [4]: _"When people come as a team (usually it is three or four people and typically heavyweight on engineering), it is a complex process. But I think all of us have seen it in the earlier days, times when I can remember saying, "Well, look, we'll put up all the money, you put up all the blood, sweat and tears and we'll split the company", this with the founders. Then if we have to hire more people, we'll all come down evenly; it will be kind of a 50/50 arrangement. Well, as this bubble got bigger and bigger, you know, they were coming and saying, "Well, you know, we'll give you, for all the money, 5 percent, 10 percent of the deal." And, you know, that it's a supply and demand thing. It's gone back the other way now. But, in starting with a team, it's a typical thing to say, well, somewhere 40 to 60 percent, to divide it now. If they've got the best thing since sliced bread and you think they have it and they think they have it, you know, then you'll probably lose the deal because one of these guys will grab it."_

## Equity Allocation in Startups: the General Idea

Equity allocation in startups begins with founders. As it happened with Fairchild or as Valentine describes it, startup founders are usually a team of engineers. They can be 2, 3, 4 or more founders. There are also cases of single-founder startups. The founding team splits the initial shares in the company. Sometimes equally, sometimes not. Sometimes, the founders also need IP from external entities, usually their former employer, and in many cases the licensing entity receives founders' equity in exchange for the IP license.

Once the founders have agreed on the initial founding split, they may or may not allocate new shares. This has become a standard way for incentivizing startup partners in Silicon Valley. Less in other regions, even if this becomes common practice. These partners are mostly investors and employees. Investors receive _preferred shares_ in exchange for the capital they invest in startups, whereas founders usually own _ordinary shares_. Employees receive _stock options_ for their "sweat and tears", which may be converted in ordinary shares at some point in the startup life [3, 5].

It may be surprising for some readers to learn that there is no real equality between all stakeholders. Preferred shares have more privileges than ordinary or common shares and stock options are not even real shares. But usually, at a liquidity event such as an IPO or the sale of the company, all shares are converted into common shares. Then there is more equality. Even then, the voting power of shares maybe different... Business and democracy do not often go along well!

## Equity Allocation in more than 400 Successful Startups

For many years, I have been using Nesheim's template [3] to build capitalization tables very similar to the one shown in table i in the appendix. At the date of writing this report, I had compiled more than 400 cases [6]. The next tables summarize my results. First, tables 1 to 3 describe what these startups are about in terms of fields of activity, periods of foundation and geography with figures on their financial situation such as amounts of venture capital (VC) raised, yearly sales and profits before the IPO as well as their number of employees and number of years to go public.

The following tables (4 to 6) give the equity allocation, i.e. how much the group of founders keep at IPO, how much employees and investors get as well as the allocation to the general public at the IPO. An additional interesting element is added, that is the average age of the group of founders. Again these elements are given relatively to fields of activities (table 4), periods of foundations (table 5) and geography (table 6).

Tuple 2:
Cleaned Title: analysis software engineering practice general software machine learning startup
Cleaned Transcription: analysis software engineering practice general software machine learning startup bishal lakha computer science department boise state university boise id usa bishallakhauboisesstateedu kalyan bhetwal computer science department boise state university boise id usa kalyanbhetwaluboisesstateedu nasir u eisty computer science department boise state university boise id usa nasireistyboisesstateedu abstract context top inherent challenge startup software company face applying proper software engineering practice nondeterministic nature machine learning technique make even difficult machine learning ml startup objective therefore objective study understand whole picture software engineering practice followed ml startup identify additional need method achieve goal conducted systematic literature review study paper published last year selected paper general software startup ml startup collected data understand software engineering se practice five phase software development lifecycle requirement engineering design development quality assurance deployment result find interesting difference software engineering practice ml startup general software startup data management model learning phase prominent among conclusion ml startup face many similar challenge general software startup additional difficulty using stochastic ml model require different strategy using software engineering practice produce highquality product software engineering machine learning startup software startup systematic literature review introduction machine learning becoming ubiquitous many software application startup small company eagerly adopting technology flag bearer implementing innovative stateoftheart ml solution different domain challenging nature ml application limitation peculiarity startup resulted using slightly different software engineering practice however system development deployment maintenance still suffer lack best practice due nondeterministic nature machine learning software engineering aspect ml system become complicated also lack proper mature tool test ml system integrating ml software application forced organization evolve development process research conducted amershi et al studied method followed different software engineering team developing artificial intelligence ai product microsoft study suggested ai component inherently complex software component integrating nonmonotonic error behavior arise proposed endtoend pipeline support data collection cleaning management tool focusing programming model bug others mitigate problem company recently adopted new approach like mlops still many challenge challenge become prominent startup startup survive first five year startup venture capitalist back meet failure startup go bankrupt one crucial reason situation improper software engineering practice resulting faulty product moreover many startup take year develop minimum viable product due delay product delivery additional financial burden occurs resulting startup failure similarly inability organization actively engage developer also result failure manifestation consequence bad software engineering practice malpractice software engineering always lead startup failure factor include different technical debt like code debt architecture debt testing debt debt could accumulate rapidly impacting performance growth startup aiml startup tend fall traditional counterpart cause mentioned also play role failure learning software engineering practice follow best practice crucial various study conducted software engineering practice tech industry also many study conducted software engineering practice startup however study ml startup software engineering practice scarce scarcity motivated u direct study area moreover occurred u since ml field evolving rapidly change software engineering practice company especially startup studied along difference general software startup therefore main objective study identify key software engineering practice followed software startup general identify specific software engineering practice followed ml startup ii background emergence different electronic device like smartphones tablet laptop smartwatches etc contributed software industry manifold growth resulting multitude software startup success deep learning subfield ml wide range application resulted adoption ml multiple company pushed growth startup rapidly leading billion dollar contribution economy general software startup software startup small mediumsized enterprise distinct traditional mature company focus developing innovative product limited time frame resource due inherent character face multiple challenge like little organization management experience lack financial human resource influence various source like investor customer partner continuous need developing dynamic disruptive technology machine learning startup machine learning startup provide different ml service like speech recognition video analysis others use ml part product many startup different domain like health finance fashion etc also adopting ai ml product developing product startup face multiple uncertainty due gap research development software startup prone failure kind uncertainty make ml startup vulnerable however collaboration cooperation openness come good software engineering practice help startup succeed research question fulfill objective formulated two research question conducted systematic literature review multiple published paper different venue rq software engineering practice followed general software startup rq intend find se practice general software startup follow similar different traditional se practice practice illustrate characteristic software startup along reason choice particular software design pattern development practice rq additional software engineering practice machine learning startup follow rq intend differentiate general startup ml startup using se practice also plan learn different step involved ml product development general practice still hold utility modification improvement innovation necessary address step iii research methodology collected published paper manually went selected paper collect data maintain quality study first second author individually went paper collecting data analyzed synthesized data answer research question section discus research methodology detail inclusion exclusion criterion included paper published english considered paper published journal conference symposium proceeding general software startup since published paper ml startup rare included blog avoided gray literature like video podcasts news article interview etc also considered paper published november systematic literature review database search formulated search string download paper fulfill research objective searched paper ieee xplore acm digital library google scholar using formulated search string first used two search string online database query software engineering startup query ml software engineering startup high number paper returned relevant searched google scholar enrich database paper formulated subqueries based stage software development lifecycle sdlc general software startup query searched software engineering startup requirement analysis query searched software engineering startup design query searched software engineering startup implementation sdlc query searched software engineering startup testing sdlc query searched startup deployment sdlc downloaded metadata processing goal collect paper ml startup based software development life cycle similar query search ieee xplore acm digital library find relevant paper use alternate terminology machine learning like deep learning artificial intelligence enrich database ml startup got additional useful paper meta data collection collected metadata title author name abstract published year url citation paper database search csv file identify deduplication validation paper collection also allows filtering paper based abstract manually ieee explorer inbuilt feature enable u export metadata search result csv file however feature available acm digital library google scholar built web scraper using python library beautifulsoup extracted metadata acm digital library search result deduplication validation collected metadata paper general software startup ieee explorer paper acm digital library paper google scholar similarly collected paper ml startup ieee explorer paper acm digital library paper google scholar also collected paper curated site mlopsorg dropped duplicate paper list using metadata used python package called panda work also noticed abstract many paper collected search doesnt keywords used search order remove paper used regex us sequence character order find specific pattern text used search required keywords present given abstract dropped paper list didnt find one keywords abstract figure show number paper belonging different software development lifecycle general software startup filtration based presence keywords snowballing database search general software startup resulted enough paper research however got paper ml startup thus used snowballing technique increase database ml startup went citation paper found checked relevant u based inclusionexclusion criterion previously sixteen relevant paper snowballing got twentyone paper manual selection finalization deduplication validation total paper paper belonged general software startup paper belonged ml startup automatic filtration good job removing irrelevant paper several paper contained required keywords useful research went abstract remaining paper manually selected paper finally got paper general software startup ml startup distributed among different phase sdlc shown table iv result present finding per research question section rq software engineering practice followed general software startup summarized various practice followed general software startup based sdlc table ii discussed detail following subsection also discus potential challenge solution found study iva requirement engineering first part software development process wellplaced requirement help solve problem better develop efficient software best quality phase sdlc vague highlevel user requirement translated complete precise formal specification development software involves interaction producer end user software various approach requirement engineering startup also employ different technique based need time startup struggle knowing develop software requirement clearly mentioned melegati et al conducted total nine interview founder manager various brazilian startup using grounded theory approach requirement engineering practice startup found founder manager play vital role selecting practice startup also observed different level maturity requirement engineering software development found startup formal process startup clear step requirement engineering case matured requirement practice mainly occurred due market pressure requirement requirement engineering differs depending nature startup clientbased usertargetbased startup clientbased startup client set requirement usertargetbased startup owner set requirement case validation step take place check viability requirement little software development phase development completed final validation step taken see requirement correctly implemented fig number paper per software development lifecycle phase filtrationrafiq et al studied three startup around globe requirement elicitation process found requirement engineering startup primitive informal continues develop alongside product development owner already something mind requirement engineering process begin matures time evolves common requirement elicitation technique conducting interview prototyping brainstorming addition unconventional method competitor analysis collaborative team discussion model user also used alves et al conducted literature review requirement engineering startup found startup use flexible informal requirement engineering addition observed startup concerned evolution acquiring customer base using pragmatic requirement practice also conducted case study ten startup based digital port ecosystem concluded startup use straightforward requirement engineering even mature growing customer base gralha et al studied evolution requirement engineering software startup using grounded theory approach found six key factor evolve relevant requirement engineering requirement artefact knowledge management requirementsrelated role planning technical debt product quality furthermore found advance one dimension often facilitate advance dimension interesting conclusion evolution dimension fundamental success startup positive impact product employee company whole iiia design design nd phase software development come right requirement engineering phase software architect developer design highlevel system architecture based requirement software startup follow design principle methodology might startup present foundercentric approach depending founder background might encourage architectural design development phase since founder one taken risk upper hand deciding design consideration startup fail generate revenue face enormous consequence crowne et al found startup dont experienced developer neglect noncoding issue like architecture design startup also financial constraint challenging hire experienced quality human resource directly affect architecture design software duc et al performed empirical study five earlystage startup based interview observation documentation found startup unaware minimum viable product mvp mvp facilitate costeffective product design bridge communication gap deias et al found lack wellwritten architectural design specification startup lack partly due time resource constraint addition startup pressure deliver product soon possible leading design practice compromised souza et al observed startup studied construct simple design software quick session customer since closely work paternoster et al systematic study concluded use wellknown framework support rapid product change also jansen et al study two startup found opportunistic pragmatic reuse third party software helped rapid development software hence reducing time market addition code reuse reinforces architectural structure product increase product ability scale iiia development phase software development requirement design implemented system component developer write code design database along infrastructure support startup follow various development practice implement product nicolopaternoster et al conducted systematic mapping study software development practice startup found startup dont follow standard software development practice tendency justifiable startup primarily concerned delivering product market early possible start revenue generation addition want minimize cost development therefore time capital need invested establishing formal process significant constraint startup therefore startup mostly go unpredictable responsive low precision software engineering heitlager et al found startup generally share common pattern individual starting scarce resource coleman et al observed startup minimal resource use limited resource support product development dande et al studied working practice startup finland sweden found common practice used software startup souza et al studied agile development software startup conducting interview cto ceo startup found tool process backed development activity facilitate software development process example using version control system enables continuous integration deployment software iiia testing testing check software expected ensures overall quality although quality assurance essential software development largely absent startup pompermaier et al performed study eight startup brazil tech park found software tech team use testing first version testing dependent endusers following version startup used testing similarly giardino et al found startup perceive using standard software development practice waste time ignore release product soon possible therefore quality assurance absent first version software unterkalmsteiner et al also concluded startup generally ignore quality assurance activity mater et al concluded startup could outsource quality assurance test external expert resource available organization outsourcing effective alternative maintaining quality also help cost reduction save time shikta et al based study startup bangladesh proposed sevenphase framework quality assurance phase introduce qa lead achieving quality assurance requirement unit testing lock requirement regression testing hire first dedicated tester implement test metric hire second dedicated tester handle new requirement required bug fix customer hire third dedicated tester implement automatic testing create custom testing plan thongsukh et al suggest process quality product quality closely related quality software development process therefore using agile development framework scrum methodology help startup big business achieve quality product ivd deployment software deployment consists activity involve dispatching product deliverable endusers final phase product development phase product ready used production environment startup follow various deployment model silva et al found software startup manually deploy code others use continuous integration tool deployment taipale et al reported found study deployment practice scarce rq additional software engineering practice machine learning startup follow though general software startup share similar software development practice ml startup difference table iii summarizes additional practice followed ml startup discussed detail subsequent section iiib requirement engineering first ml startup try understand problem define goal requirement engineering process followed general software startup work ml startup however ml application additional requirement revolve around training data alec et al suggested nine additional consideration training data requirement author suggested training data related highlevel requirement contain bias sufficient selfconsistent reliable robust correct however similar general software startup ml startup face challenge creating requirement business need problem mainly inability customer properly understand metric data required address goal challenge also due user high expectation customer usually want product perform par big technology company like google meet requirement due data computing expertise limitation iiib data management data management one main difference general software startup ml startup data point start project ml company rob ashmore et al pointed four activity entail data management stage first activity data collection involves either using existing database creating new one second activity preprocessing phase collected data adjusted appropriately third activity augmentation phase number data sample increased using different technique final step analysis collected augmented data developer build data pipeline deal structured unstructured data build ml algorithm different kind data bug appear activity mentioned data verification tool used developer aspen et al found nearly small company including startup struggled standardize data entry collect correct data tend rely subset trusted data however company also found problem data labeled domain expert address develop complex routine reach consensus besides due blackbox nature ml algorithm especially neural network inherent challenge data safety privacy faced ml company iiib model learning primary product ml startup trained ml model model learning stage model ml algorithm trained using training data rob et al suggested four activity stage first activity selecting model fit numerous available model second activity training optimizes performance ml model third activity hyperparameter selection concerned choosing parameter training activity fourth activity suggested author transfer learning involves reusing ml model across multiple domain startup face multiple challenge phase anders et al suggested key challenge deep learning application phase first challenge experiment management author suggested tracking hardware platform source code configuration training data model state phase troubleshooting deep learning model also one major challenge difficult estimate result system fully trained moreover startup pressure achieving lot progress short period dylan et al suggested training retraining model quickly startup train gpus train lower precision iiib quality assurance one main goal ml application make prediction inference make ml startup different general startup rob et al suggested three activity phase first activity requirement encoding involves transforming requirement verifiable test mathematical property second one testbased verification consists providing test case trained model checking whether output expected outcome third one formal verification carried mathematical technique provide sufficient evidence model satisfies requirement training ml model multiple time data different defect observed aspen et al pointed big company like google microsoft mitigate problem training model multiple time small company startup might afford resource required case developer decompose larger model smaller model besides trained model behave way realtime mode batch mode moreover new data continuously inserted ml model production environment developer continue monitoring model performance iiib deployment rob et al suggested three activity deployment phase ml application first integration involves integrating ml model wider system architecture second monitoring involves monitoring input provided model monitoring environment monitoring internals model monitoring output model finally deployed model updated regularly since distribution data change time pass however updating model versioning still elusive many startup continuous engineering imperfect ml application might favored customer unlike general software ml application higher dependency hardware ml model performance depends gpus besides various model need deployed different location address customer v threat validity discus limitation study section construct threat considered paper january november study timeframe excludes paper published date limiting scope besides considered paper published journal conference considered blog related ml startup paper topic quite rare also priority database ieee xplore mostly used paper source could created bias besides ignored gray literature like news article video podcasts interview etc see risk associated study minimal startup publish paper explaining software engineering external threat used paper study though number helped derive insight software engineering practice general ml software startup still small sample also paper specifically mentioning startup rare especially ml startup used paper small team company small company small team startup feature always represent startup finding might generalizable startup internal threat primary internal validity study come usage pool paper got specific use keywords searching reliable database like ieee xplore acm digital library validated paper automatically removing paper contain keywords abstract manually verifying reading abstract remaining paper also enriched database paper google scholar mlopsorg finally also use snowballing manual search add relevant paper collection therefore find threat minimal vi discussion conclusion study first comparative study software engineering practice general software startup machine learning startup goal find software engineering practice predicted success startup would beneficial new startup follow one guideline rigorous proven general software startup would develop confidence using technique study showed process predicted success especially term revenue longevity company hand found using software engineering practice improved overall quality work employee satisfaction long run using proper software engineering practice helped better deliver software machine learning startup share similar software engineering practice general startup follow additional practice address peculiar challenge primary difference come data required machine learning application difference result additional practice requirement engineering data management phase similarly development phase followed general startup replaced model learning phase general machine learning startup time pressure deliver respective product quickly limited resource availability therefore machine learning startup tend decompose large model smaller one use multiple gpus meet deadline also aimed find tool used phase software development process unfortunately goal hindered lack study area literature found using tool helped enhance software development process however find enough information suggest exhaustive list tool could used startup future plan conduct case study selected general machine learning startup understand difference software engineering practice paper based startup limited interviewing developer different startup could also considered gain insight startup implement software engineering practice various stage sdlc addition mitigate lack paper gray literature like interview startup founder video podcasts medium blog post could good resource understand current software engineering practice adopted startup reference b akter iqbal failure factor platform startup systematic literature review nonlin journal medium management c alves j cunha j aratijo pragmatic requirement engineering practice startup ecosystem ieee th international requirement engineering conference page amershi begel c bird r deline h gall e kamar n nagappan b nushi zimmermann software engineering machine learning case study ieeeacm st international conference software engineering software engineering practice icseseip page ieee arpteg b brinne l crnkovicfriis j bosch software engineering challenge deep learning th euromicro conference software engineering advanced application seaa aug arpteg b brinne l crnkovicfriis j bosch software engineering challenge deep learning th euromicro conference software engineering advanced application seaa page ieee r ashmore r calinescu c paterson assuring machine learning lifecycle desideratum method challenge acm comput surv may bank r ashmore requirement assurance machine learning safeai aaai l blake success factor influencing ai ecosystem ai starups multilevel analysis phd thesis hec montreal buganza c dellera e pellizzoni trabucchi r verganti unveiling potentiality provided new technology process pursue technology epibnies smartphone app industry creativity innovation management cantamessa v gatteschi g perboli rosano startup road failure sustainability chakraborty baowaly u arefin n bahar role requirement engineering software development life cycle journal emerging trend computing information science chui artificial intelligence next digital frontier mckinsey company global institute g coleman r v oconnor investigation software development process formation software startup journal enterprise information management crowne software product startup fail evolution software product development startup company ieee international engineering management conference volume page ieee crowne software product startup fail evolution software product development startup company ieee international engineering management conference volume page vol f da silva f kon c torteli xp south equator experience implementing sp brazil intl conference extreme programming agile process software engineering page springer dande vp eloranta h hadayullah aj kovalainen lehtonen leppanen salimima syeed vuori c rubattel et al software startup patternsan empirical study r deias g mugheddu murru introducing xp startup proc rd international conference extreme programming agile process software engineeringxp page n duc p abrahamsson minimum viable product multiple facet product role mvp software startup international conference agile software development springer vp eloranta pattern controlling chaos startup proceeding th nordic conference pattern language program vikingplop page fox train large deep learning model startup garbuio n lin artificial intelligence growth engine health care startup emerging business model california management review c giardino n pattenroster unterkalmsteiner gorschek p abrahamsson software development startup company greenfield startup model ieee transaction software engineering g giray software engineering perspective engineering machine learning system state art challenge journal system software page c grahla damian wasserman goulao j araujo evolution requirement practice software startup ieeeacm th international conference software engineering icse page heitinger r helm brinkkemper tentative technique study planning coevolution product third intl ieee workshop software evolvability page hopkins booth machine learning practice outside big tech resource constraint challenge responsible development proceeding aaaiacm conference ai ethic society aies page new york ny usa association computing machinery hopkins booth machine learning practice outside big tech resource constraint challenge responsible development f ishikawa n yoshioka engineer perceive difficulty engineering machinelearning system questionnaire survey ieeeacm joint intl workshop conducting empirical study industry cesi th intl workshop software engineering research industrial practice ser ip page jansen brinkkemper hunink c demir pragmatic opportunistic reuse innovative startup company ieee software kakati success criterion hightech new venture technou g kalyanasundaram startup fail case study based empirical analysis bangalore asian journal innovation policy e klotins unterkalmsteiner p chatzlepretou gorschek r prikhadick n tripathi l pompermaier exploration technical debt startup ieeeacm th international conference software engineering software engineering practice track icseseip page l e li e chen j herrmann p zhang l wang scaling machine learning service intl conference predictive application apis page pmlr l luce artificial intelligence fashion ai revolutionizing fashion industry apress masuda k ono yasue n hosokawa survey software quality machine learning application ieee intl conference software testing verification validation workshop icstw page j l mater b subramanian solving software quality management problem internet startup keynote addressoctober j melegati goldman requirement engineering software startup grounded theory approach international conference engineering technology innovationieee international technology management conference iceitmc page e nascimento ahmed e oliveira p palheta steinmacher conte understanding development process machine learning system challenge solution acmieee international symposium empirical software engineering measurement esem page c nobel company failand founder bounce back harvard business school boston n paternoster c giardino unterkalmsteiner gorschek p abrahamsson software development startup company systematic mapping study information software technology l pompermaier r chanin h c de sale k fraga r prikhadnicki empirical study software engineering software startup finding case innovation ecosystem org crossref xxschema j tille j brasil u rafiq bajwa x wang lunesu requirement elicitation technique applied software startup rd euromicro conference software engineering advanced application seaa page schultealthoff furstenau g lee scaling perspective ai startup proceeding th hawaii international conference system science page r sham developing machine learning product better faster startup ieee engineering management review shikta h mahir shahriyar k da n mahal k b al jannat alamu quality assurance guideline successful startup ieeeacis th international conference software engineering research management application serum page simeone brief introduction machine learning application communication system ieee transaction cognitive communication networking r souza l rocha f silva machado investigating agile practice software startup proceeding xxxiii brazilian symposium software engineering sbe page new york ny usa association computing machinery jc spender v corvello grimaldi p rippa startup open innovation review literature european journal innovation management sutton role process software startup ieee software taipale huitalea story finnish lean startup intl conference lean enterprise software system page springer tamburri sustainable mlops trend challenge nd international symposium symbolic numeric algorithm scientific computing synasc page thongsukh n ayuthaya kiattisti startup framework based scvm framework international conference digital art medium technology icdamt page research agenda einformatica software engineering journal unterkalmsteiner p abrahamsson x wang nguyenduc q shah bajwa g h baltes k conboy e cullina dennehy et al software startup research agenda einformatica software engineering journal c vijai w wiesteri rise artificial intelligence healthcare startup india advance management x p zhang kedmey budding romance finance ai ieee multimedia title entrepreneurial logic startup software development study software startup transcription entrepreneurial logic startup software development untitled manuscript inserted editor entrepreneurial logic startup software development study software startup anh nguyenduc kaikristian kemell pekka abrahamsson footnote business school university south eastern norway gullbringvegen bo telemark tel footnote university jyvaskyla finland footnote university jyvaskyla finland abstract context software startup essential source innovation softwareintensive product need understand product development startup provide relevant support highlighted software research stateoftheart literature reveals startup develop software reason adopt activity underexplored objective study investigates tactic behind software engineering se activity analyzing key engineering event startup journey explore entrepreneurial mindset may associated se knowledge area startup case method theoretical foundation based causation effectuation model conducted semistructured interview software startup used tworound open coding thematic analysis describe identify entrepreneurial software development pattern additionally calculated effectuation index startup case result identified event merged code entrepreneurial logic se sample found systemic occurrence logic area se activity minimum viable product mvp technical debt td customer involvement ci tend associated effectual logic testing activity different level associated causal logic effectuation index revealed startup either effectuationdriven mixedlogicsdriven conclusion software startup fall two type differentiate traditional se approach may apply effectuation seems relevant essential model explaining developing suitable se practice software startup keywords software startup engineering entrepreneurial logic effectuation theory case study effectuation index software engineering startup introduction software developed startup company limited resource little operating history successful company like uber spotify kahoot developed software product startup stage according pitchbook investment u startup billion usd pitchbook substantial financial investment also implies massive waste due startup high failure rate giardino et al previous research reveals critical challenge business product development giardino et al consequently attempt deal challenge could eventually increase odds success economic saving would significant lindgren munch need better understand software engineering se startup provide relevant support practitioner emphasized software startup research community unterkalmsteiner pantiuchina bajwa et al nguyenduc et al emergence software startup research theme shown increasing number study different engineering aspect startup context example se klotins unterkalmsteiner chatzipetrou et al requirement engineering melegati et al software architecture fagerholm et al software minimum viable product mvp duc abrahamsson startup ecosystem tripathi et al study explore commonality among startup regarding engineering process practice way working better understood demand se principle process practice startupcompanies challenge common way working however understand adopt particular workflow circumstance make decision stateoftheart software startup research inherited empirical se research several preoccupation normative study method methodology model lack theory understand explain thing happen ralph instance aurum et al adopted decisionmaking theory understand nature requirement engineering activity response theoretical gap software startup research previous work began explore decisionmaking logic software startup nguyenduc seppanen abrahamsson kemell ventila kettunen mikkonen understanding logic behind startup activity would enable exploration systematic connection decision activity behavior startup context contributing theory building software startup research furthermore pattern antipatterns antecedent consequent factor directly beneficial startup company startup differ established company strong presence entrepreneurial personality behavior decisionmaking leadership bygrave et al startup operate high level uncertainty multiple influence small team size magnify influence key person ceo cto project success paternoster et al berg et al giardino et al entrepreneurial characteristic evident information system business literature ojala nambisan entrepreneurship rarely appears se research either contextually primary focus investigation tripathi et al found entrepreneur background influence mvp developed following year melegati et al found startup founder strongly influence requirement engineering activity however neither study explores logic underlying observed phenomenon prescriptive methodology recently attracted considerable interest entrepreneurship research sarasvathy dew b dew et al fisher berends et al reymen et al mansoori lackeus widespread research effort identify common logic principle behind entrepreneur decision action prominent example entrepreneurial logic effectuation presented set heuristic entrepreneur could use business development context high uncertainty sarasvathy dew b logic proposed contrast traditional causation logic entrepreneur plandriven perform best within given constraint accept possibility changed goal sarasvathy dew wiltbank et al read et al product development critical software startup crucial understand entrepreneurial logic applies software development activity quest develop theory software startup engineering nguvenduc et al want understand logic behind decisionmaking boland software startup framework employ two entrepreneurial logic theory entrepreneurship literature investigate requirement engineering software design construction testing software development happen best knowledge one attempt incorporate entrepreneurial logic context software development nguyenduc et al hevner malgonde previously published study aware khurum et al use opportunity recognition theory hevner malgondes assessment effectuation theory platform development unlike hevner describe effectual causal logic se activity also propose explanatory model influence entrepreneurial logic software development activity startup study aim better understand connection logic startup founder se activity two research question rqs derived research objective rq entrepreneurial logic apply se activity startup rq entrepreneurial logic apply software product development company level remainder paper structured follows section contains background related work section explains research method section describes result section describes finding section concludes paper related work section present important definition used paper background related work software startup software engineering startup entrepreneurial logic key terminology summarized table definition software startup term startup defined differently across various discipline sutton ries blank unterkalmsteiner et al ghezzi steininger steve blank describes startup temporary organization aim create innovative hightech product without prior working history company author highlight business product developed parallel within startup context eric ries defines startup human institution designed create unique product service extreme uncertainty rather formal company startup considered temporary organizational state seek validated scalable business model unterkalmsteiner et al company dozen employee still startup state validates business model market previous startup research done berg et al define startup highly reactive rapidly evolving company innovation focus lack resource working uncertainty time pressure looked company develop software product primary value proposition include software significant part product servicesthere many different startup lifecycle model describing startup state objective resource business maturity startup model three seven stage depending aspect focus adopted previous work nguyenduc et al define startup phase following prestartup stage idea developed need validated startup quest financial human resource startup activity carried founder shortterm hire purpose stage demonstrate business feasibility team building management common financing model bootstrapping family friend foe fff startup stage prototype developed experimented startup already figured problemsolution match revenue generated necessarily breakeven point founder seek support mechanism startup ecosystem learn accelerate business development common financing model funding seed funding poststartup stage product extended startup achieve productmarket match startup expand customer base revenue model predictable scalable hierarchical structure formed within startup common funding model series series b series agile development usercentered design lean startup contribution agility reactiveness product development known agile beck et al lean gautam singh ries usercentered design norman gotthelf methodology dealing certain level uncertainty seen different agile practice short development cycle collaborative decisionmaking rapid feedback loop continuous integration enable software organization address change effectively highsmith cockburn beck andres startup context giardino et al showed agile practice adopted adhoc manner giardino et al al pantiuchina et al studied startup company reported different agile practice used different extent depending focus practice pantiuchina et al author found speedrelated agile practice used greater extent comparison qualityrelated practice recently cico et al reported startup growth phase apply agile practice various way strict adoption agile methodology seems perceived critically situation difficult apply agile practice due nature developing product cico et al lean startup focus forming hypothesis business building experiment evaluate ries large impact startup research community minimum viable product mvp central concept approach defined version product enough feature usable early customer ries bosh et al discussed practitioner apply lean startup method lack guideline method operationalization bosch et al factor influencing implementation lean startup also reported cost prototyping particular ladd et al experience knowledge methodology nguyenduc et al experimentation general gemmell et al customer development another popular paradigm focus customer upfront ie developing customer rather product early stage startup blank blank dorf alvarez startup advised search right customer test business hypothesis thus obtaining validation refutation overall business model relates marketing practice lead user face need general market face much earlier crowd positioned benefit significantly obtaining solution need von hippel usercentered design also relevant paradigm certain type startup aim creativity empathy designing usercentric solution helping developer change mindset approach problem envision solution signoretti et al hokkanen et al studied user experience ux practice startup suggested startup product need fulfill minimal functional user experience requirement hokkanen et al startup general follow one many methodology strictly applies startup company recent largescale survey european software company showed modern software system development follow blueprint adopt different hybrid approach tell et al understanding composition development method ie agile lean etc actually work software development context missing tell et al work aim understand possible link adopted development practice entrepreneurial logic software engineering model startup need understanding modeling se phenomenon startup company recognized se literature giardino et al explained phenomenon accumulated td startup context product quality low priority startup team focused speeding development author pointed lack resource main driver observed product development pattern however explain limited resource lead lack focus quality nguyenduc et al described startup development pattern looking coevolution product business intertwined process startup need entrepreneurial skill project management skill hunting implementing opportunity nguyenduc et al model take account influence business factor decision product development however number case investigated time limited fagerholm et al implemented buildmeasurelearn cycle ries continuous experimentation system new product idea hypothesized tested study explored particular activity product development mvp development requirement engineering nguyenduc et al described mvp used different software startup tripathi et al revealed supporting role startup ecosystem element influence mvp development recently melagati et al presented founder factor influence startup requirement engineering activity study acknowledged impact entrepreneur se activity however theoretical model explain impact study call adoption decisionmaking theory fill gap recently klotins unterkalmsteiner chatzipetrou et al looked commonality among startup goal challenge practice author showed startup share se challenge practice established company however startup need evolve multiple activity simultaneously study described product development startup project management perspective consider planning measuring controlling activity assumption suggests plandriven logic looking startup development process might lead similar observation comparing planbased activity established company contrast plandriven controlled approach effectual logic adopts meansdriven emergent flexible mechanism deal environment uncertainty previous study se suggested availability resource influence occurrence engineering phenomenon ie td giardino et al choice mvp implement nguyenduc dahle et al effectuation causation logic entrepreneurial decision making entrepreneurial logic defined process creatively defining reframing taking action make sense situation require new assumption understanding cunningham et al sensemaking defined ongoing retrospective development plausible image rationalize people weick weick et al purpose making sense startup situation two kind entrepreneurial logic recently gained research attention logic effectuation causation sarasvathy alvarez barney fisher reymen present definition example context software development causal logic nutshell causal logic describes process pursuing predetermined goal acquiring needed resource tool achieve goal causal logic focus predictable aspect uncertain future follows logic extent predict future control sarasvathy p example approach conduct project large company project manager assigned project perhaps need gather team apply extra resource needed need aware project constraint perform achieve predetermined goal project project manager attitude towards unexpected contingency avoided relies accurate prediction careful planning focusing predetermined objective causation model startup focus competition constrain task relationship customer supplier instance project manager need manage relationship external stakeholder limit possible negative influence delay project schedule unexpected cost unanticipated problem causation model highlight action maximize return selecting optimal approach sarasvathy dew b manager prioritize analytical calculation pursue optimized approach effectual logic effectual logic describes process selecting among several possible goal pregiven set resource sarasvathy barney effectual logic focus controllable aspect unpredictable future follows logic extent control future need predict sarasvathy example startup spinoff university technological patent startup decides develop different business model leveraging application patent effectuationdriven startup tends involve many people possible early stage generate value startup instead focusing maximized return effectuationdriven startup examines much one willing lose startup journey example startup team need calculate commit resource time effort tolerate wasting need entrepreneurial logic software development traditional software development approach start particular goal realize linear iterative development process largely overlap causal logic significant part se research base prescriptive assumption software development project guided reference framework process technique tool managing software project one could assume certain level control based plandriven systematic working manner klotins unterkalmsteiner chatzipetrou et al project context market customer ecosystem element somewhat identified priori
Original Title: Analysis of Software Engineering Practices in General Software and
  Machine Learning Startups
Original Transcription: # Analysis of Software Engineering Practices in General Software and Machine Learning Startups

Bishal Lakha

_Computer Science Department_

_Boise State University_

Boise, ID, USA

bishallakha@u.boisesstate.edu

Kalyan Bhetwal

_Computer Science Department_

_Boise State University_

Boise, ID, USA

kalyanbhetwal@u.boisesstate.edu

Nasir U. Eisty

_Computer Science Department_

_Boise State University_

Boise, ID, USA

nasireisty@boisesstate.edu

###### Abstract

_Context:_ On top of the inherent challenges startup software companies face applying proper software engineering practices, the non-deterministic nature of machine learning techniques makes it even more difficult for machine learning (ML) startups. _Objective:_ Therefore, the objective of our study is to understand the whole picture of software engineering practices followed by ML startups and identify additional needs. _Method:_ To achieve our goal, we conducted a systematic literature review study on 37 papers published in the last 21 years. We selected papers on both general software startups and ML startups. We collected data to understand software engineering (SE) practices in five phases of the software development life-cycle: requirement engineering, design, development, quality assurance, and deployment. _Results:_ We find some interesting differences in software engineering practices in ML startups and general software startups. The data management and model learning phases are the most prominent among them. _Conclusion:_ While ML startups face many similar challenges to general software startups, the additional difficulties of using stochastic ML models require different strategies in using software engineering practices to produce high-quality products.

 Software Engineering, Machine Learning Startups, Software Startups, Systematic Literature Review

## I Introduction

Machine learning is becoming ubiquitous in many software applications. Startups and small companies are eagerly adopting this technology. They are the flag bearers for implementing innovative and state-of-the-art ML solutions for different domains [49]. The challenging nature of ML application and the limitations and peculiarities of startups have resulted in using slightly different software engineering practices. However, such systems' development, deployment, and maintenance still suffer from the lack of best practices.

Due to the non-deterministic nature of machine learning, all software engineering aspects for ML systems become complicated [24]. They also lack proper and mature tools to test ML systems [24]. So integrating ML in software applications has forced organizations to evolve their development process [3]. In a research conducted by Amershi et al. [3], they studied methods followed by different software engineering teams developing artificial intelligence (AI) products at Microsoft. Their study suggested that AI components are inherently complex than other software components, and while integrating them, non-monotonic error behavior can arise. They proposed end-to-end pipeline support, data collection, cleaning, and management tools, focusing on programming and model bugs, and others to mitigate such problems. A few companies have recently adopted new approaches like MLOps, but there still are many challenges [52]. These challenges become more prominent in startups.

More than 60% of startups do not survive their first five years, and 75% of the startups which venture capitalists back meet failure [40] while more than 90% of startups go bankrupt [20]. One of the crucial reasons for such situations is improper software engineering practices resulting in faulty products [14]. Moreover, many startups take more than a year to develop a minimum viable product, and due to delay in the product delivery, additional financial burden occurs resulting in startup failure [32]. Similarly, the inability of organizations to actively engage developers also results in the failure [1]. Again, these manifestations are consequences of bad software engineering practices.

Malpractices in software engineering do not always lead to startup failure. Other factors include different technical debt like code debt, architecture debt, or testing debt. These debts could accumulate rapidly, impacting the performance and growth of a startup [33]. AI/ML startups tend to fall more than their traditional counterparts, and the cause mentioned above also plays a role in their failure. That is why learning about what software engineering practices they follow and which best practices are crucial.

Various studies have been conducted about software engineering practices in the tech industry. Also, there are many studies conducted on software engineering practices in startups. However, studies on ML startups and their software engineering practices are scarce. This scarcity motivated us to direct our study in that area. Moreover, it occurred to us that since the ML field is evolving rapidly, the changes in software engineering practices in those companies, especially in startups, should be studied along with their difference from general software startups.

Therefore the main objectives of our study are:

* Identify the key software engineering practices followed by software startups in general
* Identify specific software engineering practices followed by ML startups

## II Background

The emergence of different electronic devices like smartphones, tablets, laptops, smartwatches, etc., has contributed to the software industry's manifold growth, resulting in a multitude of software startups [9]. The success of deep learning, a sub-field of ML, in a wide range of applications resulted in the adoption of ML in multiple companies and pushed the growth of startups rapidly [44] leading to billions of dollars of contribution to the economy [12].

**General Software Startups.** Software startups small or medium-sized enterprises distinct from traditional mature companies which focus on developing innovative products in a limited time frame and resources [55]. Due to their inherent characters, they face multiple challenges like little organization management experience, lack of financial and human resources, influences from various sources like investors, customers, partners, and continuous need of developing dynamic and disruptive technologies [50].

**Machine Learning Startups.** Machine learning startups provide different ML services like speech recognition, video analysis, and others or use ML as a part of their product. Many startups of different domains like health [22][56], finance [57], fashion [35], etc. are also adopting AI and ML in their product. While developing such products, startups face multiple uncertainties due to the gap between research and development [45]. As software startups are more prone to failure [10], these kinds of uncertainties make ML startups more vulnerable. However, collaboration, cooperation, and openness, which come from good software engineering practices, can help such startups succeed [8].

### _Research questions_

To fulfill our objectives, we formulated two research questions and conducted a systematic literature review of multiple published papers in different venues.

**RQ1: Which software engineering practices are followed by general software startups?**

With RQ1, we intend to find which SE practices do general software startups follow and how they are similar or different from traditional SE practices. These practices will illustrate the characteristics of software startups along with reasons for their choices of particular software design patterns and development practices.

**RQ2: Which additional software engineering practices do machine learning startups follow?**

With RQ2, we intend to differentiate general startups from ML startups using SE practices. We also plan to learn different steps involved in ML product development, what general practices still hold their utility, and what modifications, improvements, and innovations are necessary to address those steps.

## III Research Methodology

We collected published papers and manually went through all the selected papers to collect data. To maintain the quality of our study, the first and second authors individually went through each of the papers. After collecting the data, we analyzed and synthesized the data to answer our research questions. In this section, we discuss our research methodology in detail.

### _Inclusion and Exclusion Criteria_

We have included papers published only in English and considered papers published in journals, conferences, or symposium proceedings for general software startups. Since published papers on ML startups were rare, we included a few blogs. We avoided other gray literature like videos, podcasts, news articles, interviews, etc. Also, we only considered papers published until November 2021 for this systematic literature review.

### _Database Search_

We formulated our search strings to download papers to fulfill our research objective. We then searched papers in IEEE Xplore, ACM Digital Library, and Google Scholar using our formulated search strings. At first, we used two search strings on those online databases. The query 1 is "Software Engineering and Startups". The query 2 is "ML and Software Engineering and Startups". There was a high number of papers returned but only few were relevant. We further searched on Google Scholar to enrich our database of papers.

We further formulated sub-queries based on each stage of the software development life-cycle (SDLC) for general software startups. In Query 3, we searched "Software Engineering and Startups and Requirement Analysis". In Query 4, we searched for "Software Engineering and Startups and Design". In Query 5, we searched for "Software Engineering and Startups and Implementation and sdlc". In Query 6, we searched for "Software Engineering and Startups and testing and sdlc". In Query 7, we searched for "Startups and Deployment and sdlc". Then we downloaded the meta-data for further processing.

Our goal was to collect papers for ML startups based on software development life cycles; we did a similar query search in IEEE Xplore and ACM Digital Library but did not find relevant papers. We then use alternate terminologies for machine learning like "Deep learning" and "Artificial Intelligence" to enrich our database for ML startups and got few additional useful papers.

### _Meta Data Collection_

We collected metadata - title, author names, abstract, published year, URL, citations, and other - of the papers from the database search in a CSV file. We did this to identify deduplication and validation of papers. This collection also allows the filtering of the papers based on abstracts manually. IEEE explorer has inbuilt features that enable us to export metadata of all search results as a CSV file. However, those features were not available in ACM Digital Library and Google Scholar. So, we built a web scraper using the python library BeautifulSoup and extracted the metadata from ACM Digital Library search results.

### _De-duplication and Validation_

We collected the metadata of 389 papers for general software startups from IEEE explorer, 12,274 papers from ACM Digital Library, and 9,640 papers from google scholar. Similarly, we collected 13 papers for ML startups from IEEE explorer, 10,040 papers from ACM Digital Library, and 2,380 papers from google scholar. We also collected 39 papers curated in a site ml-ops.org. We then dropped all the duplicate papers from the list using the metadata. We used a python package called Pandas for this work.

We also noticed that the abstract of many papers collected from the search doesn't have the keywords used to search them. In order to remove such papers, we used RegEx. It uses a sequence of characters in order to find a specific pattern in the text. We used it to search if all the required keywords were present or not in the given abstract. We dropped the paper from our list if we didn't find one or more keywords in the abstract. Figure 1 shows the number of papers belonging to different software development life-cycle for general software startups before and after filtration based on the presence of keywords.

### _Snowballing_

Our database search for general software startups resulted in enough papers for our research. However, we got very few papers for ML startups. We, thus, used snowballing techniques to increase our database for ML startups. We went through the citations of the papers we found and checked if any of those were relevant to us based on our inclusion-exclusion criteria. We previously had sixteen relevant papers, and after snowballing, we got twenty-one papers.

### _Manual Selection and Finalization_

After de-duplication and validation, we had 92 total papers, where 72 papers belonged to general software startups, and 20 papers belonged to ML startups. The automatic filtration did a good job in removing irrelevant papers, but several papers contained required keywords but were not useful for our research. So we went through the abstract of all the remaining papers and manually selected papers. We finally got 37 papers, 27 for general software startups and 10 for ML startups distributed among different phases of SDLC as shown in Table I.

## IV Results

We present our findings per research questions in this section.

### _RQ1: Which software engineering practices are followed by general software startups?_

We summarized the various practices followed by general software startups based on SDLC in Table II and discussed them in detail in the following subsections. We also discuss potential challenges and solutions found in the study.

#### Iv-A1 Requirement Engineering

It is the first part of the software development process. A well-placed requirement can help solve problems better and develop efficient software with the best quality. In this phase of SDLC, vague high-level user requirements are translated into complete, precise, and formal specifications for the further development of software [11]. It involves interaction between both the producers and end users of the software. There are various approaches for requirement engineering. Startups also employ different techniques based on their needs.

Most of the time, startups struggle not knowing what they should develop because software requirements are not clearly mentioned [38]. Melegati et al. [38] conducted a total of nine interviews with founders or managers from various Brazilian startups using a grounded theory approach about requirement engineering practices in startups. They found that founders or managers play vital roles in selecting practices in startups. They also observed different levels of maturity in requirement engineering in software development. They found that some startups did not have any formal process; some startups had clear steps for requirements engineering. In cases where there were matured requirement practices, it mainly occurred due to market pressure or requirements. The requirement engineering differs depending on the nature of the startup, such as client-based or user-target-based startups. If it is a client-based startup, the client sets all the requirements. But if it is a user-target-based startup, the owners set the requirements. In both cases, a validation step takes place to check for the viability of the requirement. There can be no or little software development in this phase. After development is completed, a final validation step is taken to see if the requirements were correctly implemented.

Fig. 1: Number of papers per Software Development Life-Cycle phases before and after filtrationRafiq et al. [43] studied three startups around the globe about the requirement elicitation process. They found that requirement engineering in startups is very primitive and informal, and it continues to develop alongside product development. The owners already have something in mind before the requirements engineering process begins. Then it matures as time evolves. The most common requirement elicitation techniques are conducting interviews, prototyping, and brainstorming. In addition, some unconventional methods such as competitor analysis, collaborative team discussions, and model users are also used.

Alves et al. [2] conducted a literature review on requirement engineering in startups. They found that startups use flexible and informal requirement engineering. In addition, they observed that startups are more concerned with evolution by acquiring more customer base using pragmatic requirement practices. They also conducted a case study on ten startups based on the Digital Port ecosystem. They concluded that startups use straightforward requirement engineering even they mature by growing the customer base.

Gralha et al. [25] studied the evolution of requirements engineering in 16 software startups using a grounded theory approach. They found six key factors that evolve relevant to requirement engineering: requirements artefacts, knowledge management, requirements-related roles, planning, technical debt, and product quality. Furthermore, they found that advances in one dimension often facilitate advances in other dimensions. But the interesting conclusion is that evolution in these dimensions is not fundamental to the success of the startups. But they have a positive impact on the product, employee, and company as a whole.

#### Iii-A2 Design

Design is the 2nd phase of software development and comes right after requirement engineering. In this phase, software architects and developers design a high-level system architecture based on requirements. Some software startups follow design principles and methodology, while some might not.

Startups present a founder-centric approach, and depending on founders' background; they might encourage some architectural design before the development phase [23]. Since founders are the ones who have taken the risk, they have the upper hand in deciding the design and other considerations. If startups fail to generate revenue, they face enormous consequences.

Crowne et al. [15] found that startups don't have experienced developers, so they neglect non-coding issues like architecture and design. Startups also have financial constraints. So, it is challenging for them to hire experienced and quality human resources that directly affect the architecture and design of the software.

Duc et al. [19] performed an empirical study on five early-stage startups based on interviews, observation, and documentation. They found that startups were unaware of Minimum Viable Product (MVP). MVPs facilitate cost-effective product design and bridge the communication gap.

Deias et al. [18] found that there is a lack of well-written architectural and design specifications in startups. This lack is partly due to time and resource constraints. In addition, startups have pressure to deliver products as soon as possible, leading to design practices being compromised.

Souza et al. [48] observed that all of the startups they studied construct a simple design of software in a quick session with their customers since they closely work with them.

Paternoster et al. [41] in their systematic study concluded that the use of well-known frameworks supports rapid product change. Also, Jansen et al. [30] in their study on two startups, found that opportunistic and pragmatic reuse of third party software helped in the rapid development of software, hence reducing time to market. In addition, code reuse reinforces the architectural structure of the product and increases the product's ability to scale.

#### Iii-A3 Development

In this phase of software development, requirements and design are implemented into system components. Developers write code and design databases along with IT infrastructure to support them. Startups follow various development practices to implement their product.

NicoloPaternoster et al. [41] conducted a systematic mapping study on software development practices in startups. They found that startups don't follow any standard software development practices. This tendency is justifiable because startups are primarily concerned with delivering their products in the market as early as possible to start revenue generation. In addition, they want to minimize the cost of development. Therefore, both time and capital need to be invested in establishing a formal process. But both of these are significant constraints for startups. Therefore, startups mostly go after unpredictable, responsive, and low precision software engineering [50][31].

Heitlager et al. [26] found that startups generally share a common pattern: few individuals starting with scarce resources. Coleman et al. [13] observed the same. Startups have minimal resources and only use their limited resources to support product development.

Dande et al. [17] studied working practices in startups in Finland and Sweden. They found 63 common practices used by software startups.

Souza et al. [48] studied agile development in software startups by conducting 14 interviews with the CTO and CEO of startups. They found that tools and processes backed most development activities to facilitate the software development process. For example, using a version control system enables the continuous integration and deployment of software.

#### Iii-A4 Testing

Testing checks if the software does what it is expected to do and ensures the overall quality. Although quality assurance is essential in software development, it is largely absent in most startups [46].

Pompermaier et al. [42] performed a study on eight startups in Brazil at a tech park. They found that the software tech teams did not use any testing in the first version. So, testing was dependent on the end-users. But on the following version, 75% of the startups used some testing.

Similarly, Giardino et al. [23] found that startups perceive using standard software development practices as a waste of time. So they ignore them to release the products as soon as possible. Therefore, quality assurance is absent in the first versions of the software. Unterkalmsteiner et al. [54] also concluded that startups generally ignore any quality assurance activities.

Mater et al. [37] concluded that startups could outsource their quality assurance test from external experts if the resources are not available in the organization itself. This outsourcing can be an effective alternative for maintaining quality. It can also help in both cost reduction and save time.

Shikta et al. [46] based on their study on startups in Bangladesh, proposed a seven-phase framework for quality assurance. The phases are (1) introduce QA lead to achieving quality assurance on requirements and unit testing, (2) lock requirements and regression testing, (3) hire the first dedicated tester, (4) implement test metrics, (5) hire a second dedicated tester to handle new requirements and required bug fixes from customers, (6) hire a third dedicated tester to implement automatic testing, and (7) create a custom testing plan.

Thongsukh et al. [53] suggest that process quality and product quality are closely related to the quality of the software development process. Therefore, using an agile development framework such as scrum methodology will help both startups and big businesses to achieve quality in their product..

#### Iv-D5 Deployment

Software deployment consists of all the activities that involve dispatching products or deliverables to the end-users. It is the final phase of product development. At this phase, the product is ready to be used in a production environment. Startups follow various deployment models.

Silva et al. [16] found that some software startups manually deploy the code. While some others use continuous integration tools for deployment, as Taipale et al. [51] reported. We found that studies about deployment practices are scarce.

### _RQ2: Which additional software engineering practices do machine learning startups follow?_

Though general software startups share similar software development practices with ML startups, there are some differences too. Table III summarizes the additional practices followed by ML startups. We discussed them in detail in subsequent sections.

#### Iii-B1 Requirement Engineering

At first, ML startups try to understand problems and define a goal [39]. The requirement engineering process followed by general software startups works for ML startups. However, ML applications have additional requirements that revolve around training data. Alec et al. [7] suggested nine additional considerations for training data requirements. The authors suggested that the training data should be related to high-level requirements, should not contain bias, should be sufficient, self-consistent, reliable, robust, and correct.

However, similar to general software startups, ML startups face challenges while creating requirements out of business needs [39]. The problem is mainly because of the inability of their customers to properly understand what metrics and data are required to address the goal. The challenge is also due to the users' high expectations [27]. Customers usually want their products to perform on par with big technology companies like Google. But they cannot meet the requirements due to their data, computing, and expertise limitations.

#### Iii-B2 Data Management

Data management is one of the main differences between general software startups and ML startups. Data is the point where they start their projects for ML companies. Rob Ashmore et al. [6] pointed out four activities that entail data management stages. The first activity is data collection which involves either using existing databases or creating a new one. The second activity is preprocessing. In this phase, collected data is adjusted appropriately. The third activity is augmentation. In this phase, the number of data samples is increased using different techniques. And the final step is an analysis of collected and augmented data. Developers can build a data pipeline that deals with structured or unstructured data to build the ML algorithm. Different kinds of data bugs can appear during the activity mentioned above, and data verification tools can be used by the developers [24].

Aspen et al. [28] found that nearly all small companies, including startups, struggled to standardize data entry and collect the correct data, so they tend to rely on a subset of trusted data. However, these companies also found problems with data labeled by the domain expert. And to address that, most of them develop complex routines and reach consensus. Besides that, due to the black-box nature of ML algorithms, especially neural networks, there is an inherent challenge of data safety, and privacy faced by ML companies [4].

#### Iii-B3 Model Learning

The primary product of a ML startup is trained ML models. In the model learning stage, a model or ML algorithm is trained using training data [47]. Rob et al. [6] suggested four activities in this stage. The first activity is selecting the model that fits from numerous available models. The second activity is training which optimizes the performance of the ML model. The third activity is hyperparameter selection, which is concerned with choosing the parameters with training activity. The fourth activity suggested by the author is transfer learning which involves reusing ML models across multiple domains.

Startups can face multiple challenges during this phase. Anders et al. [4] suggested some key challenges for deep learning applications during this phase. The first challenge is experiment management. The author suggested tracking the hardware, platform, source code configuration, training data, and model state during this phase. Troubleshooting a deep learning model is also one of the major challenges, as it is difficult to estimate the results before a system has been fully trained. Moreover, startups have the pressure of achieving a lot of progress in a short period. Dylan et al. [21] suggested training and retraining models quickly. Startups can train on more GPUs or train with lower precision.

#### Iii-B4 Quality assurance

One of the main goals of ML applications is to make predictions and inferences which make ML startups different from general startups [36]. Rob et al. [6] suggested three activities for this phase. The first activity is requirement encoding, which involves transforming requirements to verifiable test and mathematical properties. The second one is test-based verification which consists of providing test cases to the trained model and checking whether it outputs the expected outcome. The third one is formal verification which is carried out by mathematical techniques to provide sufficient evidence that the model satisfies the requirements.

While training a ML model multiple times on the same data, different defects can be observed [28]. Aspen et al. [28] pointed out that big companies like Google and Microsoft mitigate the problem by training the model multiple times, but small companies and startups might not afford the resource required to do so. In such cases, developers decompose larger models into smaller models. Besides, the trained model should behave the same way in both real-time mode and batch mode [34]. Moreover, new data is continuously inserted into the ML models in a production environment, so developers should continue monitoring model performance [39].

#### Iii-B5 Deployment

Rob et al. [6] suggested three activities in the deployment phase of ML applications. The first is integration, which involves integrating the ML models to wider system architecture. The second is monitoring. It involves monitoring inputs provided to the model, monitoring the environment, monitoring internals of the model, and monitoring outputs of the model. Finally, the deployed model should be updated regularly since distribution of data changes as time passes. However, updating and model versioning is still elusive for many startups [28] as continuous engineering of imperfect ML applications might not be favored by customers [29].

Unlike general software, ML applications have a higher dependency on hardware as the ML models' performance depends on GPUs [5]. Besides that, various models need to be deployed in different locations to address the customers [34].

## V Threats to Validity

We discuss the limitations of our study in this section.

**Construct Threat**: We only considered papers from January 1, 2000, to November 30, 2021, for this study. This time-frame excludes all the papers published before and after this date, limiting our scope. Besides, we only considered papers published in journals or conferences. We considered a few blogs related to ML startups as papers on that topic were quite rare. Also, as our priority database was IEEE Xplore, we mostly used papers from that source which could have created a bias. Besides that, we ignored all the gray literature like news articles, videos, podcasts, interviews, etc. But we see the risk associated with this study minimal as most startups do not publish papers explaining their software engineering.

**External Threat**: We only used 37 papers for our study. Though that number helped derive insight on software engineering practices for general and ML software startups, it is still a small sample. Also, as papers specifically mentioning startups were rare, especially for ML startups, we used papers about small teams or companies. Being a small company or having a small team is a startup feature, but it does not always represent startups. So, our findings might not be generalizable to all the startups.

**Internal Threat**: The primary internal validity for our study comes from our usage of a pool of papers which we got from specific use of keywords and searching in reliable databases like IEEE Xplore and ACM Digital Library. We further validated the papers by automatically removing papers that do not contain all the keywords in the abstract and then manually verifying them by reading abstracts of the remaining papers. We also enriched the database of papers from Google Scholar and ml-ops.org. Finally, we also use snowballing and manual search to add relevant papers to our collection. Therefore we find this threat minimal.

## VI Discussion and Conclusion

Our study is the first to do a comparative study of software engineering practices between general software startups and machine learning startups. Our goal was to find out the software engineering practices that predicted the success of startups. It would be beneficial for new startups to follow one such guideline that is more rigorous and proven. General software startups would develop confidence in using those techniques. But, our study showed that there is no such process that predicted success, especially in terms of revenue and longevity of the company. On the other hand, we found that using software engineering practices improved the overall quality of work and employee satisfaction. In the long run, using proper software engineering practices helped better deliver software.

Machine learning startups share similar software engineering practices with general startups and follow additional practices to address its peculiar challenges. The primary difference comes from the data required for machine learning applications. This difference results in additional practices during the requirement engineering and data management phase. Similarly, the development phase followed by the general startup is replaced by the model learning phase. Both general and machine learning startups have time pressure to deliver respective products quickly with limited resource availability. Therefore, machine learning startups tend to decompose large models into smaller ones and use multiple GPUs to meet the deadline.

We also aimed to find the tools used in each phase of the software development process. Unfortunately, our goal was hindered by the lack of study in this area. In some literature, we found that using tools helped enhance the software development process. However, we did not find enough information to suggest an exhaustive list of tools that could be used by startups.

In the future, we plan to conduct case studies on selected general and machine learning startups to understand the difference in their software engineering practices as papers based on startups are limited. Interviewing developers from different startups could also be considered to gain insight into how these startups implement software engineering practices during various stages of SDLC. In addition to that, to mitigate the lack of papers, gray literature like interviews of startups founders, videos, and podcasts, medium blog posts could be good resources to understand current software engineering practices adopted by startups.

## References

* [1] B. Akter and M. A. Iqbal. Failure factors of platform start-ups: A systematic literature review. _Nonlin Journal of Media Management_, 1(3):433-459, 2020.
* [2] C. Alves, J. Cunha, and J. Aratijo. On the pragmatics of requirements engineering practices in a startup ecosystem. In _2020 IEEE 28th International Requirements Engineering Conference (RE)_, pages 311-321, 2020.
* [3] S. Amershi, A. Begel, C. Bird, R. DeLine, H. Gall, E. Kamar, N. Nagappan, B. Nushi, and T. Zimmermann. Software engineering for machine learning: A case study. In _2019 IEEE/ACM 41st International Conference on Software Engineering: Software Engineering in Practice (ICSE-SEIP)_, pages 291-300. IEEE, 2019.
* [4] A. Arpteg, B. Brinne, L. Crnkovic-Friis, and J. Bosch. Software engineering challenges of deep learning. _2018 44th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)_, Aug 2018.
* [5] A. Arpteg, B. Brinne, L. Crnkovic-Friis, and J. Bosch. Software engineering challenges of deep learning. In _2018 44th Euromicro Conference on Software Engineering and Advanced Applications (SEAA)_, pages 50-59. IEEE, 2018.
* [6] R. Ashmore, R. Calinescu, and C. Paterson. Assuring the machine learning lifecycle: Desiderata, methods, and challenges. _ACM Comput. Surv._, 54(5), may 2021.
* [7] A. Banks and R. Ashmore. Requirements assurance in machine learning. In _SafeAI@ AAAI_, 2019.
* [8] L. Blake. _The Success Factors Influencing AI Ecosystems and AI Starups: A Multi-Level Analysis_. PhD thesis, HEC MONTREAL, 2020.
* [9] T. Buganza, C. Dell'Era, E. Pellizzoni, D. Trabucchi, and R. Verganti. Unveiling the potentialities provided by new technologies: A process to pursue technology epibnies in the smartphone app industry. _Creativity and Innovation Management_, 24(3):391-414, 2015.
* [10] M. Cantamessa, V. Gatteschi, G. Perboli, and M. Rosano. Startups' roads to failure. _Sustainability_, 10(7):2346, 2018.
* [11] A. Chakraborty, M. Baowaly, U. Arefin, and A. N. Bahar. The role of requirement engineering in software development life cycle. _Journal of Emerging Trends in Computing and Information Sciences_, 3:723-729, 05 2012.
* [12] M. Chui. Artificial intelligence the next digital frontier. _McKinsey and Company Global Institute_, 47(3-6), 2017.

* [13] G. Coleman and R. V. O'Connor. An investigation into software development process formation in software start-ups. _Journal of Enterprise Information Management_, 2008.
* [14] M. Crowne. Why software product startups fail and what to do about it. evolution of software product development in startup companies. In _IEEE International Engineering Management Conference_, volume 1, pages 338-343. IEEE, 2002.
* [15] M. Crowne. Why software product startups fail and what to do about it. evolution of software product development in startup companies. In _IEEE International Engineering Management Conference_, volume 1, pages 338-343 vol.1, 2002.
* [16] A. F. Da Silva, F. Kon, and C. Torteli. Xp south of the equator: An experience implementing sp in brazil. In _Intl. Conference on Extreme Programming and Agile Processes in Software Engineering_, pages 10-18. Springer, 2005.
* [17] A. Dande, V.-P. Eloranta, H. Hadayullah, A.-J. Kovalainen, T. Lehtonen, M. Leppanen, T. Salimima, M. Syeed, M. Vuori, C. Rubattel, et al. Software startup patterns-an empirical study. 2014.
* [18] R. Deias, G. Mugheddu, and O. Murru. Introducing xp in a start-up. In _Proc. 3rd International Conference on Extreme Programming and Agile Processes in Software Engineering-XP_, pages 62-65, 2002.
* [19] A. N. Duc and P. Abrahamsson. Minimum viable product or multiple facet product? the role of mvp in software startups. In _International Conference on Agile Software Development_. Springer, 2016.
* [20] V.-P. Eloranta. Patterns for controlling chaos in a startup. In _Proceedings of the 8th Nordic Conference on Pattern Languages of Programs (VikingPLoP)_, pages 1-8, 2014.
* [21] D. Fox. How to Train Large Deep Learning Models as a Startup, 2021.
* [22] M. Garbuio and N. Lin. Artificial intelligence as a growth engine for health care startups: Emerging business models. _California Management Review_, 61(2):59-83, 2019.
* [23] C. Giardino, N. Pattenroster, M. Unterkalmsteiner, T. Gorschek, and P. Abrahamsson. Software development in startup companies: The greenfield startup model. _IEEE Transactions on Software Engineering_, 42(6):585-604, 2016.
* [24] G. Giray. A software engineering perspective on engineering machine learning systems: State of the art and challenges. _Journal of Systems and Software_, page 111031, 2021.
* [25] C. Grahla, D. Damian, A. Wasserman, M. Goulao, and J. Araujo. The evolution of requirements practices in software startups. In _2018 IEEE/ACM 40th International Conference on Software Engineering (ICSE)_, pages 823-833, 2018.
* [26] I. Heitinger, R. Helms, and S. Brinkkemper. A tentative technique for the study and planning of co-evolution in product. In _Third Intl. IEEE Workshop on Software Evolvability 2007_, pages 42-47, 2007.
* [27] A. Hopkins and S. Booth. Machine learning practices outside big tech: How resource constraints challenge responsible development. In _Proceedings of the 2021 AAAI/ACM Conference on AI, Ethics, and Society_, AIES '21, page 134-145, New York, NY, USA, 2021. Association for Computing Machinery.
* [28] A. Hopkins and S. Booth. Machine learning practices outside big tech: How resource constraints challenge responsible development. 2021.
* [29] F. Ishikawa and N. Yoshioka. How do engineers perceive difficulties in engineering of machine-learning systems? a questionnaire survey. In _2019 IEEE/ACM Joint 'Intl. Workshop on Conducting Empirical Studies in Industry (CESI) and 6th Intl. Workshop on Software Engineering Research and Industrial Practice (SER IP)_, pages 2-9, 2019.
* [30] S. Jansen, S. Brinkkemper, I. Hunink, and C. Demir. Pragmatic and opportunistic reuse in innovative start-up companies. _IEEE Software_, 25(6):42-49, 2008.
* [31] M. Kakati. Success criteria in high-tech new ventures. _Technou_, 23(5):447-457, 2005.
* [32] G. Kalyanasundaram. Why do startups fail? a case study based empirical analysis in bangalore. _Asian Journal of Innovation and Policy_, 2018.
* [33] E. Klotins, M. Unterkalmsteiner, P. Chatzlepretou, T. Gorschek, R. Prikhadick, N. Tripathi, and L. Pompermaier. Exploration of technical debt in start-ups. In _2018 IEEE/ACM 40th International Conference on Software Engineering: Software Engineering in Practice Track (ICSE-SEIP)_, pages 75-84, 2018.
* [34] L. E. Li, E. Chen, J. Herrmann, P. Zhang, and L. Wang. Scaling machine learning as a service. In _Intl. Conference on Predictive Applications and APIs_, pages 14-29. PMLR, 2017.
* [35] L. Luce. _Artificial intelligence for fashion: How AI is revolutionizing the fashion industry_. Apress, 2018.
* [36] S. Masuda, K. Ono, T. Yasue, and N. Hosokawa. A survey of software quality for machine learning applications. In _2018 IEEE Intl. Conference on Software Testing, Verification and Validation Workshops (ICSTW)_, pages 279-284, 2018.
* [37] J. L. Mater and B. Subramanian. Solving the software quality management problem in internet startups. _Keynote Address-October 17_, 2000.
* [38] J. Melegati and A. Goldman. Requirements engineering in software startups: a grounded theory approach. In _2016 International Conference on Engineering, Technology and Innovation/IEEE International Technology Management Conference (ICEITMC)_, pages 1-7, 2016.
* [39] E. d. S. Nascimento, I. Ahmed, E. Oliveira, M. P. Palheta, I. Steinmacher, and T. Conte. Understanding development process of machine learning systems: Challenges and solutions. In _2019 ACM/IEEE International Symposium on Empirical Software Engineering and Measurement (ESEM)_, pages 1-6, 2019.
* [40] C. Nobel. _Why companies fail-and how their founders can bounce back_. Harvard Business School Boston, MA, 2011.
* [41] N. Paternoster, C. Giardino, M. Unterkalmsteiner, T. Gorschek, and P. Abrahamsson. Software development in startup companies: A systematic mapping study. _Information and Software Technology_, 2014.
* [42] L. Pompermaier, R. Chanin, A. H. C. de Sales, K. Fraga, and R. Prikhadnicki. An empirical study on software engineering and software startups: findings from cases in an innovation ecosystem. _org. crossref. xxschema. J. Tille 06 1J75-70, 2017. Brasil_, 2017.
* [43] U. Rafiq, S. S. Bajwa, X. Wang, and I. Lunesu. Requirements elicitation techniques applied in software startups. In _2017 43rd Euromicro Conference on Software Engineering and Advanced Applications (SEAA)_, pages 141-144, 2017.
* [44] M. Schulte-Althoff, D. Furstenau, and G. M. Lee. A scaling perspective on ai startups. In _Proceedings of the 54th Hawaii International Conference on System Sciences_, pages 6515, 2021.
* [45] R. Shams. Developing machine learning products better and faster at startups. _IEEE Engineering Management Review_, 46(3):36-39, 2018.
* [46] S. Shikta, H. M. Mahir Shahriyar, S. K. Das, S. N. Mahal, K. B. Al Jannat, and S. Alamu. Quality assurance guidelines for successful startups. In _2021 IEEE/ACIS 19th International Conference on Software Engineering Research, Management and Applications (SERA)_, pages 81-85, 2021.
* [47] O. Simeone. A very brief introduction to machine learning with applications to communication systems. _IEEE Transactions on Cognitive Communications and Networking_, 4(4):648-664, 2018.
* [48] R. Souza, L. Rocha, F. Silva, and I. Machado. Investigating agile practices in software startups. In _Proceedings of the XXXIII Brazilian Symposium on Software Engineering_, SBES 2019, page 317-321, New York, NY, USA, 2019. Association for Computing Machinery.
* [49] J.-C. Spender, V. Corvello, M. Grimaldi, and P. Rippa. Startups and open innovation: a review of the literature. _European Journal of Innovation Management_, 2017.
* [50] S. Sutton. The role of process in software start-up. _IEEE Software_, 17(4):33-39, 2000.
* [51] M. Taipale. Huitale-a story of a finnish lean startup. In _Intl. Conference on Lean Enterprise Software and Systems_, pages 111-114. Springer, 2010.
* [52] D. A. Tamburri. Sustainable mlops: Trends and challenges. In _2020 22nd International Symposium on Symbolic and Numeric Algorithms for Scientific Computing (SYNASC)_, pages 17-23, 2020.
* [53] S. Thongsukh, S. D. N. Ayuthaya, and S. Kiattisti. Startup framework based on scvm framework. In _2017 International Conference on Digital Arts, Media and Technology (ICDAMT)_, pages 458-463, 2017.
* a research agenda. _E-Informatica Software Engineering Journal_, 2016:89-124, 10 2016.
* [55] M. Unterkalmsteiner, P. Abrahamsson, X. Wang, A. Nguyen-Duc, S. Q. Shah, S. S. Bajwa, G. H. Baltes, K. Conboy, E. Cullina, D. Dennehy, et al. Software startups- research agenda. _e-Informatica Software Engineering Journal_, 10(1):89-123, 2016.
* [56] C. Vijai and W. Wiesteri. Rise of artificial intelligence in healthcare startups in india. _Advances In Management_, 14(1):48-52, 2021.
* [57] X. P. S. Zhang and D. Kedmey. A budding romance: Finance and ai. _IEEE MultiMedia_, 25(4):79-83, 2018.

Title: The entrepreneurial logic of startup software development: A study of 40
  software startups
Transcription: The entrepreneurial logic of startup software development

Untitled Manuscript No.

(will be inserted by the editor)

The entrepreneurial logic of startup software development:

A study of 40 software startups

Anh Nguyen-Duc1 Kai-Kristian Kemell2 Pekka Abrahamsson3

Footnote 1: Business School, University of South Eastern Norway

Gullbringvegen 36, 3800, Bo i Telemark

Tel.: +47-48348496

Footnote 2: University of Jyvaskyla, Finland

Footnote 3: University of Jyvaskyla, Finland

###### Abstract

Context: Software startups are an essential source of innovation and software-intensive products. The need to understand product development in startups and to provide relevant support are highlighted in software research. While state-of-the-art literature reveals how startups develop their software, the reasons why they adopt these activities are underexplored.

Objective: This study investigates the tactics behind software engineering (SE) activities by analyzing key engineering events during startup journeys. We explore how entrepreneurial mindsets may be associated with SE knowledge areas and with each startup case.

Method: Our theoretical foundation is based on causation and effectuation models. We conducted semi-structured interviews with 40 software startups. We used two-round open coding and thematic analysis to describe and identify entrepreneurial software development patterns. Additionally, we calculated an effectuation index for each startup case.

Results: We identified 621 events merged into 32 codes of entrepreneurial logic in SE from the sample. We found a systemic occurrence of the logic in all areas of SE activities. Minimum Viable Product (MVP), Technical Debt (TD), and Customer Involvement (CI) tend to be associated with effectual logic, while testing activities at different levels are associated with causal logic. The effectuation index revealed that startups are either effectuation-driven or mixed-logics-driven.

Conclusions: Software startups fall into two types that differentiate between how traditional SE approaches may apply to them. Effectuation seems the most relevant and essential model for explaining and developing suitable SE practices for software startups.

Keywords: Software startup engineering, entrepreneurial logics, effectuation theory, case study, effectuation index, software engineering for startups

## 1 Introduction

More and more software is developed by startup companies with limited resources and little operating history. Successful companies like Uber, Spotify, and Kahoot developed their software products during their startup stages. According to Pitchbook, investment in US startups only is more than 120 billion USD in 2019 (PitchBook, 2019). This substantial financial investment also implies a massive waste due to startups' high failure rate (Giardino et al., 2014). Previous research reveals critical challenges in both business and product development (Giardino et al., 2015). Consequently, attempts to deal with these challenges could eventually increase the odds of success, and the economic savings would be significant (Lindgren and Munch, 2016). The need to better understand software engineering (SE) in startups and provide relevant support for practitioners has been emphasized in the software startup research community (Unterkalmsteiner, 2016; Pantiuchina, 2017; Bajwa et al., 2017; Nguyen-Duc et al., 2020). The emergence of software startup as a research theme is shown by an increasing number of studies on different engineering aspects in a startup context, for example, SE (Klotins, Unterkalmsteiner, Chatzipetrou, et al., 2019), requirements engineering (Melegati et al., 2019), software architecture (Fagerholm et al., 2017), software Minimum Viable Product (MVP) (Duc and Abrahamsson, 2016), and startup ecosystems (Tripathi et al., 2018). These studies explore the commonalities among startups regarding engineering processes, practices, and ways of working. We have better understood the demand for SE principles, processes, and practices in startupcompanies, their challenges, and common ways of working. However, we do not understand why they adopt a particular workflow and under which circumstances they make these decisions.

State-of-the-art software startup research inherited from empirical SE research several preoccupations with normative studies on methods, methodologies, and models, and it lacks theories to understand and explain how and why things happen (Ralph, 2016). For instance, Aurum et al. (2003) adopted decision-making theories to understand the nature of requirement engineering activities. In response to this theoretical gap in software startup research, our previous work began to explore decision-making logics in software startups (Nguyen-Duc, Seppanen, and Abrahamsson, 2015; Kemell, Ventila, Kettunen, and Mikkonen, 2019). Understanding the logic behind startup activities would enable the exploration of a systematic connection between decisions, activities, behaviors, and startup context, contributing to theory building in software startup research. Furthermore, patterns, or anti-patterns with their antecedent and consequent factors can be directly beneficial for startup companies.

Startups differ from established companies in the strong presence of entrepreneurial personalities, behaviors, decision-making, and leadership (Bygrave et al., 1991). Startups operate with a high level of uncertainty, multiple influences, and small team sizes, which magnify the influence of key persons, such as the CEO or CTO, on the project's success (Paternoster et al., 2014; Berg et al., 2018; Giardino et al., 2014). While entrepreneurial characteristics are evident in both information systems and business literature (Ojala 2015, 2016; Nambisan 2017), entrepreneurship rarely appears in SE research, either contextually or as a primary focus of the investigation. Tripathi et al. (2018) found that entrepreneurs' backgrounds influence how MVPs are developed. The following year, Melegati et al. (2019) found that startup founders strongly influence requirement engineering activities. However, neither study explores the logic underlying observed phenomena. Prescriptive methodologies have recently attracted considerable interest in entrepreneurship research (Sarasvathy and Dew 2005a, 2005b; Dew et al., 2009; Fisher, 2012; Berends et al., 2013; Reymen et al., 2015; Mansoori and Lackeus, 2019). There is a widespread research effort to identify the common logic or principles behind entrepreneurs' decisions and actions. A prominent example of an entrepreneurial logic is effectuation, presented as a set of heuristics any entrepreneur could use for business development in the context of high uncertainty (Sarasvathy and Dew 2005a, 2005b). The logic has been proposed in contrast to a traditional causation logic, in which entrepreneurs are plan-driven, perform their best within given constraints, and accept the possibility of a changed goal (Sarasvathy and Dew 2005a; Wiltbank et al., 2006; Read et al., 2009). As product development is critical for software startups, it is crucial to understand how entrepreneurial logic applies to software development activities.

In the quest to develop a theory of software startup engineering (Nguven-Duc et al., 2020), we want to understand further the logic behind decision-making (Boland 2008) in software startups. As a framework, we employ two entrepreneurial logic theories from entrepreneurship literature to investigate how requirement engineering, software design, construction, testing, and software development happen. To the best of our knowledge, this is one of very few attempts to incorporate entrepreneurial logic in the context of software development (Nguyen-Duc et al., 2017; Hevner and Malgonde, 2019). Of previously published studies, we are aware only of Khurum et al.'s (2015) use of the opportunity recognition theory and Hevner and Malgonde's (2019) assessment of effectuation theory in platform development. Unlike Hevner, we describe both effectual and causal logics in each SE activity. We also propose an explanatory model of the influences of entrepreneurial logic on software development activities in startups. This study aims to better understand the connections between the logic of startup founders and SE activities. Two research questions (RQs) were derived from the research objective:

RQ1: How do entrepreneurial logics apply to SE activities in startups?

RQ2: How do entrepreneurial logics apply to software product development at the company level?

The remainder of the paper is structured as follows: Section 2 contains background and related work, Section 3 explains the research method, Section 4 describes the results, Section 5 describes the findings, and Section 6 concludes the paper.

## 2 Related Work

The section presents important definitions used in this paper, background and related work about Software Startups, Software Engineering in Startups and Entrepreneurial logics. The key terminologies are summarized in Table 1.

### Definitions of Software Startups

The term "startup" has been defined differently across various disciplines (Sutton, 2000; Ries, 2011; Blank, 2013; Unterkalmsteiner et al., 2016; Ghezzi, 2018; Steininger, 2019). Steve Blank (2013) describes a startup as a temporary organization that aims to create innovative high-tech products without a prior working history as a company. The author further highlights that the business and its product should be developed in parallel within the startup context. Eric Ries (2011) defines a startup as a human institution designed to create a unique product or service under extreme uncertainty. Rather than a formal company, a startup should be considered a temporary organizational state that seeks a validated and scalable business model (Unterkalmsteiner et al., 2016). A company with a dozen employees can still be in a startup state while it validates a business model or a market. As previous startup research has done (Berg et al., 2018), we define a startup as a highly reactive and rapidly evolving company with an innovation focus and a lack of resources, working under uncertainty and time pressure. We looked for companies that develop software products as their primary value proposition or include software as a significant part of their products or services.There are many different startup life-cycle models describing startups' states of objectives, resources and business maturities. A startup model can have from three to seven stages, depending on the aspects they focus on. As adopted in our previous work (Nguyen-Duc et al. 2016, 2017), we define startups' phases as the followings:

* Pre-startup stage: ideas are developed and need to be validated, startups in the quest for financial and human resources. Startup activities are carried out by founders or short-term hires. The purpose of this stage is to demonstrate business feasibility, team building and management. The common financing model is bootstrapping, family, friends and foes (FFF)
* Startup stage: prototypes are developed and experimented, startups have already figured out the problem/solution match. Some revenue is generated, but not necessarily over the break-even point. Founder seeks support mechanisms from startup ecosystems, learn to accelerate their business development. The common financing model is own funding and seed funding.
* Post-startup stage: products are extended, startups achieve the product/market match. Startups expand their customer bases, the revenue models are predictable and scalable. A hierarchical structure is formed within the startups. The common funding model is Series A, Series B, and other series

### Agile development, User-centered Design and Lean startups

Contributions to agility and reactiveness of product development are known from Agile (Beck et al., 2001), Lean (Gautam and Singh, 2008; Ries 2011), and User-centered Design (Norman 1986; Gotthelf 2013) methodologies. Dealing with certain levels of uncertainties can be seen from different agile practices, such as short development cycles, collaborative decision-making, rapid feedback loops, and continuous integration enable software organizations to address change effectively (Highsmith and Cockburn, 2001; Beck and Andres, 2004). In startup contexts, Giardino et al. showed that agile practices are adopted, but in an ad-hoc manner (Giardino et al. 2016),al., 2014). Pantiuchina et al. studied 1256 startup companies and reported that different agile practices are used to different extents, depending on the focus of the practices (Pantiuchina et al. 2017). The authors found that speed-related agile practices are used to a greater extent in comparison to quality-related practices. Recently Cico et al. reported that startups in their growth phases do apply Agile practices in various ways. Strict adoption of agile methodology seems not to be perceived critically, and in some situations, it is difficult to apply agile practices due to the nature of developing products (Cico et al., 2020).

Lean startups with the focus on forming hypotheses about businesses, building experiments to evaluate them (Ries 2011), had a large impact on startup and research communities. Minimum Viable Product (MVP) is a central concept of the approach, defined as a version of a product with just enough features to be usable by early customers (Ries 2011). Bosh et al. discussed why few practitioners apply Lean Startup methods because of the lack of guidelines for method operationalization (Bosch et al., 2013). Other factors influencing the implementation of Lean Startup are also reported, such as the costs of prototyping in particular (Ladd et al., 2015), experience and knowledge about the methodology (Nguyen-Duc et al., 2016, 2017), and experimentation in general (Gemmell et al., 2012).

Customer Development is another popular paradigm that focuses on customers upfront, i.e. developing the customers rather than products in the early stages of startups (Blank 2007; Blank & Dorf, 2012; Alvarez 2014). So startups are advised to search for the right customers to test their business hypotheses and thus obtaining validation or refutation of the overall business model. This relates to the marketing practices of lead users who (1) face the needs that will be general in the market, but face them much earlier than the crowd, (2) are positioned to benefit significantly by obtaining the solution to those needs (von Hippel, 1986). User-Centered Design is also a relevant paradigm for certain types of startups, as they aim for creativity and empathy for designing user-centric solutions and helping developers to change their mindset on how to approach a problem and envision its solution (Signoretti et al., 2019). Hokkanen et al. studied User Experience (UX) practices in startups and suggested that startup products need to fulfill minimal functional and user experience requirements (Hokkanen et al., 2015).

Startups, in general, do not follow one or many of these methodologies strictly. This applies not only to startup companies, as a recent large-scale survey in European software companies showed that modern software and system development does not follow any blueprint and adopt different hybrid approaches (Tell et al, 2017). The understanding of which compositions of development methods, i.e. Agile, Lean, etc that actually work in software development contexts is missing (Tell et al, 2017). In this work, we aim to understand the possible links between adopted development practices with the entrepreneurial logics.

### Software Engineering Models for Startups

The need for understanding and modeling SE phenomenon in startup companies has been recognized in SE literature. Giardino et al. (2016) explained a phenomenon of accumulated TD in startup contexts when product quality is a low priority and the startup team is more focused on speeding up development. The authors pointed out that lack of resources is the main driver for the observed product development patterns; however, they did not explain how the limited resource leads to the lack of focus on quality. Nguyen-Duc et al. (2016) described startup development patterns by looking at the co-evolution of product and business as an inter-twined process: startups need entrepreneurial skills and project management skills when hunting implementing opportunities (Nguyen-Duc et al., 2015). These models take into account the influence of business factors in decisions on product development. However, the number of cases investigated at that time was limited. Fagerholm et al. (2017) implemented the Build-Measure-Learn cycles (Ries, 2011) as continuous experimentation systems, where the new product idea can be hypothesized and tested.

Some studies explored particular activities of product development, such as MVP development or requirement engineering. Nguyen-Duc et al. (2017) described how MVPs are used in different software startups, and Tripathi et al. (2018) revealed how the supporting roles of startup ecosystem elements influence MVP development. More recently, Melagati et al. (2019) presented how founders and other factors influence startups' requirement engineering activities. These studies acknowledged the impact of entrepreneurs on SE activities; however, they do not have a theoretical model to explain this impact. These studies call for the adoption of decision-making theories to fill the gap. More recently, Klotins, Unterkalmsteiner, Chatzipetrou, et al. (2019) looked at commonalities among startups' goals, challenges, and practices. The authors showed that startups share the same SE challenges and practices with established companies; however, startups need to evolve multiple activities simultaneously. The study described product development startups from a project management perspective to consider planning, measuring, and controlling activities. This assumption suggests a plan-driven logic when looking at the startup development process and might lead to a similar observation when comparing these plan-based activities to those of established companies. In contrast to a plan-driven and controlled approach, effectual logic adopts means-driven, emergent, and flexible mechanisms to deal with the environment's uncertainty. Previous studies in SE have suggested that the availability of resources can influence the occurrence of engineering phenomena, i.e., TD (Giardino et al., 2016) and the choice of which MVP to implement (Nguyen-Duc, Dahle, et al., 2017).

### Effectuation and Causation Logics in Entrepreneurial Decision Making

Entrepreneurial logic is defined as a process of creatively defining, reframing and taking action to make sense out of situations that require new assumptions and understandings (Cunningham et al. 2002). Sensemaking is defined as "the ongoing retrospective development of plausible images that rationalize what people are doing" (Weick 1995, Weick et al. 2005). In the purpose of making sense from startup situations, two kinds of entrepreneurial logic that have recently gained research attention are the logics of effectuation and causation (Sarasvathy, 2001; Alvarez and Barney, 2005; Fisher, 2012; Reymen, 2015). Below, we present their definitions and examples in the context of software development.

#### 2.4.1 Causal Logic

In a nutshell, causal logic describes a process of pursuing a predetermined goal by acquiring needed resources, tools to achieve the goal. The causal logic focuses on the predictable aspects of an uncertain future and follows the logic of "to the extent we can predict the future, we can control it" (Sarasvathy, 2001, p. 7). An example of this approach is to conduct a project in a large company. When a project manager is assigned to the project, he perhaps needs to gather his team to apply for extra resources if needed. He needs to be aware of project constraints and perform to achieve the predetermined goals of the project. The project manager's attitude towards unexpected contingency is avoided. He relies on accurate predictions, careful planning, and focusing on predetermined objectives. In the causation model, startups focus on competition and constrain task relationships with customers and suppliers. For instance, the project manager needs to manage the relationships with external stakeholders to limit their possible negative influences (delays in the project schedule, unexpected costs, and other unanticipated problems). The causation model highlights the action to maximize returns by selecting optimal approaches (Sarasvathy and Dew, 2005b). The manager will prioritize analytical calculations and pursue an optimized approach.

#### 2.4.2 Effectual Logic

An effectual logic describes a process of selecting among several possible goals with a pre-given set of resources (Sarasvathy, 2001; Barney, 1991). The effectual logic focuses on the controllable aspects of an unpredictable future and follows the logic of "to the extent we can control the future, we do not need to predict it" (Sarasvathy, 2001). For example, a startup that is a spin-off from a university has technological patents. The startup decides to develop different business models leveraging the application of the patents. The effectuation-driven startup tends to involve as many people as possible in the early stages to generate value for the startup. Instead of focusing on maximized returns, the effectuation-driven startup examines how much one is willing to lose on a startup journey. In our example, the startup team needs to calculate and commit only the resources, time, and effort that they can tolerate wasting.

### The Need for Entrepreneurial Logic in Software Development

Traditional software development approaches start with a particular goal and realize it through a linear or iterative development process, which is largely overlap with causal logic. Significant parts of SE research base on a prescriptive assumption that software development projects can be guided by reference frameworks, processes, techniques, and tools. When managing a software project, one could assume a certain level of control based on plan-driven and systematic working manners (Klotins, Unterkalmsteiner, Chatzipetrou, et al., 2019) where project context, such as market, customers, and other ecosystem elements, are somewhat identified as a priori.

Tuple 3:
Cleaned Title: towards understanding analytics software startup
Cleaned Transcription: towards understanding analytics software startup usman rafiq faculty computer science free university bozenbolzano bolzano italy abstract analytics play crucial role datainformed decisionmaking process modern business unlike established software company software startup seen utilizing potential analytics even though startup process primarily datadriven little understanding literature analytics software startup study set address knowledge gap exploring analytics understood context software startup end collected qualitative data three analytics platform mostly used startup multiple source covered platform documentation well experience report software startup using platform data analyzed using content analysis technique four highlevel concept identified encapsulate real understanding software startup analytics including instrumentation analytics experimentation diagnostic analysis getting insight first concept describes startup set analytics latter three illustrate usage scenario analytics study first step toward understanding analytics software startup context identified concept guide investigation analytics context also provides insight software startup set analytics datainformed decision given limitation data used study immediate next step ground well validate acquired understanding using primary data directly interacting software startup ac analytics metric abstraction software startup footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery footnote association computing machinery software startup eventually explains leverage decisionmaking using analytics moreover finding identify important area product business development analytics applied related work relatively study analytics software startup context recent work rafiq et al rafiq et al studied software startup deal information make decision analytics perspective reported ten type recurrent analytics mistake might derail software startup information dealing mistake grouped four category information collection information analysis information communication information usage another related study investigating role data analytics startup company berg et al berg et al presented challenge barrier faced startup study claim startup aware benefit applying analytics however also facing challenge implementing reported challenge scarcity resource lack trainingskills time management issue privacy issue dealing data lack access data argued amount data startup collect early stage insufficient apply analytics find study analyzed hardware startup big data analytics brought question done possibly term big data considered one key aspect business analytics however differs traditional data term velocity volume variety berg et al hand find writer reporting metric measurement startup one example multiple case study kamulegeya et al kamulegeya et al author report metric startup utilizing wish utilize study kamulegeya et al classifies metric list according measurement practice established software company present five category business metric product metric organizational performance metric project metric design metric later kemell et al kemell et al multivocal literature review report metric startup use however observed metric appropriate late stage life cycle startup moreover study reflect information needed process collecttrack metric taken together study presented thus far provide evidence lack understanding startup understand term analytics apply analytics startup context current study seek address gap research method research exploratory nature knowledge understanding software startup regarding analytics limited therefore develop initial understanding software startup think analytics decided utilize secondary data ie text data analytics platform nowadays widespread usage secondary data research make feasible approach meet limitedtime resource kamulegeya et al vartanian vartanian describes secondary data data collected someone researcher objective likewise analyze data set used content analysis qualitative research method vartanian major advantage using content analysis considered appropriate method absence existing theory knowledge phenomenon limited particular employed conventional content analysis approach build understanding analytics startup context fig depicts complete process data collection analysis following subsection describe collected filtered analyzed data data collection based research question planned study analytics platform particularly intended software startup preliminary step getting information platform startup using consulted forum hacker news hacker news trusted reliable prevalent source news entrepreneurship computer science community facilitates finding latest information startup hard find elsewhere footnote httpsnewsycombinatorcomhttpsnewsycombinatorcom applied search term like analytics metric startup drive search forum term originated figure data collection analysis procedure research question research consequently manual analysis resulting discussion forum revealed several analytics platform platform brought discussion startup community illustrating feature usage scenario short comparison platform ranged open source proprietary solution covered following simple analytics httpssimpleanalyticscomhttpssimpleanalyticscom mixpanel httpsmixpanelcomhttpsmixpanelcom google analytics httpsanalyticsgooglecomhttpsanalyticsgooglecom matomohttpsmatomoorghttpsmatomoorg fathom httpsusefathomcomhttpsusefathomcom plausible httpsplausibleiohttpsplausibleio open web analytics httpswwwopenwebasulticscomhttpswwwopenwebasulticscom kissmetrics httpswwwkissmetricsiohttpswwwkissmetricsio amplitude httpsamplitudecomhttpsamplitudecom umami httpsumanis goutcounter httpswwwgoatcountercomhttpswwwgoatcountercom snowplow httpssnowplowanalyticscomhttpssnowplowanalyticscom thereafter visited individual platform website manually extracted information stored text file information stemmed several source like example associated documentation configuration information developer information case opensource tool user interface testimionals customer blog post also found blog platform vendor expressed opinion analytics shared experience instrumenting analytics startup company read available documentation assessed whether data utilized address research question noteworthy state utilized every possible way extract fragmented documentation associated platform intent miss useful information achieve searched platformspecific documentation platform website hacker news forum github repository hosting service open source application regard used platform hosting documentation github known wiki extract information footnote httpsgithubcomhttpsgithubcom obtain another triangulation data collection sampling phase explored website g g legit source check review business software real user found platform available g however platform listed helped u screening analytics platform final data set lastly decided utilize information following three platform data set footnote httpswwwgcomhttpswwwgcom amplitude httpsamplitudecomhttpsamplitudecom mixpanel httpsmixpanelcomhttpsmixpanelcom plausible httpsplausibleiohttpsplausibleio considered following inclusionexclusion criterion screening platform information final data set platform mature ie used huge startup community subjectively assessed criterion hacker news forum objectively stargazer github website platform available g website platform extensive documentation multiple source like instance website blog post information forum platform vendor iswas software startup checked startup information crunchbase platform documentation contained data wherein least one multiple story shared story communicate experience software startup implementing analytics assessed information collected documentation platform later checked individual startup crunchbase total data contained startup story focusing analytics varying text length footnote httpswwwcrunchbasecomdiscoverorganizationcompanieshttpswwwcrunchbasecomdiscoverorganizationcompanies data analysis used qualitative analysis method named content analysis analyze data use content analysis software engineering context new software engineering research recent study bartos et al krishnan et al advocate rigorous process use software engineering content analysis applied text data interview data coding category directly derived data bartos et al make different thematic analysis therefore content analysis research method text data obtained interview focus group narrative response survey question book article even manual bartos et al particular applied conventional content analysis inductively approach recommended lack research knowledge topic bartos et al performing analysis read whole text repeatedly get complete sense data started coding phrase wherein term analytics indicated impression analytics arising highlighted text appeared contain relevant term described concept subsequently utilized author word code segment text alongside ignored summative indication analytics text whereby text mainly referring name analytics platform meanwhile avoided creating new code analysis process continued depicts added new code assessed existing code fit label new text consideration likewise soon finishing development code moved focus analysis coded data examined code eventually examined text within particular code merged renamed eliminated code analysis process iterated based similarity code relationship code created cluster eventually organizing cluster hierarchical structure result obtained theme clustered highlevel themestoplevel category used nivvo qualitative data analysis tool support conventional content analysis footnote httpswwwqqinternationalcomnvivoqualitativedataanalysissoftwarehomehttpswwwqqinternationalcomnvivoqualitativedataanalysissoftwarehome finding section present research result identified theme data set directly express found relevant analytics process inside software startup categorized theme highlevel theme highlevel theme include instrumenting experimentation diagnostic analysis getting insight clustering theme labeling highlevel purely inductive thus based two factor first one focus set analytics startup name instrumenting analytics mean instrumentation analytics intuition direction set analytics startup flip side three theme coexist together focus possible scenario applying analytics startup include experimentation diagnostic analysis finally getting insight theme taken together illustrate term analytics understood software startup fig show software startup handle analytics instrumenting analytics defining goal figured startup employing analytics sense defining one multiple goal achieve analytics often analytics platform vendor also found promoting culture establish goal meet business objective example report amplitude platform concept explained like often company develop feature feature without thinking feature meet overall business objective therefore goal might tied directly success startup illustrates thinking measuring matter avoiding getting indulged noise evident one following excerpt amplitude platform measuring anything everything lead unmanageable data shift burden team try make sense result another instance company advised similar contextkeep end goal mind going vein one startup wanted client hit platform goal increase customer retention possible way found goal reduce churn rate increase customer conversion churn rate rate customer discontinue using service product conversion mean new customer take desired action bradner data mixpanel platform startup described situation following wordsfor market target want partner hit know reducing churn increasing conversion similar conclusion echoed another report plausible analytics platform company expressed thought setting goal web analytics allow site owner set goal event track visitor action matter worthwhile report established goal generate several metric monitor startup reflected opinion following excerpt goal event tied directly monetary success enterprise make essential metric follow understand state business asking question data analysis whole suggests asking question good way establish key focus analytics revealing one want achieve certainly connection setting goal instrumenting analytics startup report mixpanel platform one startup emphasized following way need asking question report embarked want people engage data ask question find answer data make right decision likewise amplitude platform data reported similar conclusion following excerpt business often multitude question customer product performing based data set encountered following set question asked instrumenting analyticswhat exactly work want measuring whats useful metric event publishing feature popular user retain best type user stick around long valuable customer action valuable customer take customer churn many power user action churn user take characteristic highly engaged user user pain point whats happening site live moment people visit website whats happening thing going metric culture found several interesting example data one startup repeatedly emphasized embedding metric overall culture product development process mean product feature left without publishing different metric aimed serving purpose measuring working towards large business goal startup said one occasion report mixpanel platform publishing right business metric must integrated development process speaker continued baking culture expectation probably important impactful thing advised startup build culture build development process becomes given establishing culture necessary product platform ie web mobile aligned vocabulary put place across development life cycle alludes following notion ensure stakeholdersboth web mobileare aligned name event property similar conclusion highlighted report amplitude platform company said align target product outcome define event taxonomy measure outcome instrument tracking code tracking goal observed another theme data usually concerned tracking goal theme concerned tracking established goal example startup set goal wanted partner grow contrast goal startup asked many question tracked metric shown following excerpt startup mixpanel platform report track well restaurant partner platform able look metric whats going enable u startup reported another startup report similar goal wanted know performing customer acquisition channel increase customer conversion startup reflects tracking goal following word able measure optimize highperforming acquisition channel also improve purchase funnel making easy consumer convert loyal policyholder similar indication tracking goal customer conversion found report plausible analytics platform startup indicated track several metric goal track event goal identify number unique converted visitor total number conversion conversion rate referral site send traffic convert best unifying analytics unifying analytics one challenge startup must tackle instrumenting analytics based finding highlight two type unification startup achieve first type incorporates unifying analytics fragmented product startup oftentimes startup offer multiple platform combination web mobile app echoed one startup report mixpanel platform company needed unify fragmented analytics ecosystem flip side aspect unification discussed data shared understanding goal alignment among different startup team like instance engineering team product team shared understanding alignment might include target product outcome taxonomy measure outcome instrumenting coding accordingly report amplitude platform show implementing great product analytics requires product engineering team work together align target product outcome define event taxonomy measure outcome instrument tracking code enables engineering team track required product team company mixpanel platform agrees alignment following word ensure stakeholdersboth web mobileare aligned name event property finally make certain everyone bought maintaining best practice experimentation testing hypothesis recurrent theme data utilization analytics testing hypothesis startup need quickly test several hypothesis various startup development approach like example lean startup customer development methodology amplifying use hypothesis particularly early stage bouquet et al bouquet et al found startup using analytics test hypothesis simultaneously analytics platform providing supporting feature achieve goal example amplitude platform report indicated feature identifying winning feature customer acquisition campaign referral source hypothesis regarding customer behavior prominent data one instance report amplitude platform indicatedits growth engine generates hypothesis data observing customer behavior also amplifying winning feature campaign idea encountered many instance data feature highlighted show concern regarding hypothesis testing analytics widespread among startup evident following excerpt startup report mixpanel platform wanted test hypothesis quickly threw event startup continued alluding outcome testing able test disprove hypothesis figure software startup understand analytics missingpagefail understanding customer need one startup plausible analytics indicatedyou may putting lot time effort resource different marketing campaign looking referral source website traffic better understand campaign worth others startup continued arguing one need redesign future strategy existing effort misleading youre spending lot time effort community effort doesnt result benefit site business need reconsider thing startup remarked situation talking future strategy startup asserted analyze effort optimize future reported following phrase addition layer depth analyze effort help optimize strategy future similar experience shared report amplitude platform company highlighted need analytics deeply understand customer need ass outcome development effort statement reflects finding one thing found missing powerful product platform truly understand user wanted impact development effort user experience measuring progress savvy startup often concerned measuring progress however measuring progress without yardstick barely possible pointed analyzing data found startup using analytics measure progress using insight different perspective startup plausible analytics told report use web analytics measure startup progress make better decision generalizing need startup claimed majority website business owner want see level stats tell whats going company highlighted key advantage using analytics measuring progress following excerpt main area web analytics help website owner get better idea whats happening thing going making decision data analysis depicts startup decision based insight analytics generates insight oftentimes arise measuring progress startup assessing startup effort making thing done experimentation however considered holistically making decision instance plausible analytics claimed used analytics making decision decision lay foundation future strategy apparent following excerpt depth analyze effort help optimize strategy future way startup report mixpanel platform shared decided put effort designing feature observed partner already engaged product startup commented finding helpful showed since restaurant already using feature perhaps didnt need invest company amplitude platform shed light making decision employing analytics word product analytics provide exact data needed drive decisionmaking continue make improvement delight customer understanding user behaviour engagement one possible use analytics data analysis showed understanding user behavior interaction product used clear assumption regarding customer behavior time brings surface trending content winning product feature highlight customer journey one platform another several analytics goal achieved like example improving retention monitoring understanding user behavior report amplitude platform highlight finding following word identifying customer engaged using information improve retention company continued expressing similar concrete benefit another place following excerpt analytics help create digital experience without guesswork provides concrete information optimize conversion grow retention maximize revenue another interesting finding noticed finding reason user behaviour good product team dont ask user ask requires context report amplitude platform revealed discussion study result confirm analytics startup context reflects somewhat different meaning contrast described software engineering literature therefore talk startup analytics based big data indicated berg et al berg et al characterized given term software analytics berg et al however find exist many type analytics literature eg big data analytics web analytics software analytics social medium analytics startup analytics closer characteristic web analytics alongside need investigation ground understanding analytics startup context study hernandez et al also reported analyticsrelated mistake eg avoiding collect information poor team communication mishanding information data show first two mistake mitigated instrumenting analytics startup instance unifying analytics reduce poor communication startup team similarly last one finding suggest looking information multiple perspective also waiting trend appear information surprisingly one finding emphasizes developing culture metric embedding development product feature invite concept measuring everything especially product development possible explanation result might startup could need produce hindsight therefore retrospect might need however find clue finding literature study also remains unable explain extent contrast earlier finding berg et al however confirm software startup using analytics difference may explained chosen sample studied purely software startup berg et al berg et al studied startup hardware part well another important difference would like illustrate study focused understanding startup analytics find taken together understanding pretty different general software engineering literature state analytics literature bertsch et al bertsch et al bertsch et al present analytics term big data analytics software analytics simply data analytics interesting reveal finding provide diverse understanding analytics startup perspective however would interesting relate finding general software engineering literature would remain important issue future avenue lastly finding strongly show connection analytics metric example goal question analytics instrumentation generate metric however finding selfexplanatory explaining connection assessment relationship analytics metric threat validity one threat validity particularly internal validity use secondary data type data provides lack control data volume quality mitigate threat certain extent triangulated data using multiple source applying inclusionexclusion criterion type data already used study like example bertsch et al regarding threat external validity one threat lie data collection strategy selected platform investigation applying several inclusionexclusion criterion later collected analytics platform documentation every possible source eg platform website blog forum data three platform different length scope besides might missed collecting associated data however data set containing startup different geographical region market segment different product platform enhanced ability generalize result ongoing research effort regarding reliability study one possible threat concerned researcher bias coding process coding process done one researcher solely however early code theme discussed researcher reporting lastly take privilege admit reported understanding analytics startup context still need investigation possibly primary data mean need continue grounding validating understanding analytics startup context based primary data conclusion future work startup confronted several challenge raising odds success uncertainty scarcity resource engineering challenge speed right focus among mention way startup take plenty decision adjust direction accordingly analytics serve right information first study attempt explain analytics understood startup context ongoing research report initial understanding analytics startup covering instrumentation context utilized several question still need answered future one significant direction validate understanding analytics startup primary data moreover current finding left many question need investigation example work required map relationship analytics term metric term used interchangeably lastly relationship stage startup across lifecycle use analytics might worth investigating reference f auer c lee felderer continuous experiment definition characteristic th euromicro conference software engineering advanced application scaa pp cited s missingpagepost title influence speed prototyping empirical investigation twenty software startup transcription influence speed prototyping empirical investigation twenty software startup anh nguyen duc department computer information science idi ntnu trondheim norway xiaofeng wang free university bozenbolzano piazza domenicani bolzano italy pekka abrahamsson department computer information science idi ntnu trondheim norway footnote email anh pekkaantnuno xiaofengwangunibzit abstract essential startup quickly experiment business idea building tangible prototype collecting user feedback prototyping inevitable part learning early stage software startup fast startup learn depends fast prototype despite importance lack research prototyping software startup study aimed understanding factor influencing different type prototyping activity conducted multiple case study twenty european software startup result two fold firstly propose prototypecentric learning model early stage software startup secondly identify factor occur barrier also facilitator prototyping early stage software startup factor grouped artifact team competence collaboration customer process dimension speed startup progress early stage important incorporate learning objective welldefined collaborative approach prototyping keywords prototype mvp prototypinglearning loop validated learning speed software startup introduction startup movement software industry witnessing paradigm shift serving customer requirement creating customer value challenge software company longer primarily implementing customer requirement rather finding customer demand providing solution delivers customer value addressing uncertainty solution problem domain often adhoc based guesswork becomes one main reason failing startup company demand systematic approach manage uncertainty led increased research interest lean startup new product development npd software startup continuous experimentation author version work selfarrived arxiv definite version published nguyenduc wang x abrahamsson p influence speed prototyping empirical investigation twenty software startup baumeister h lichter h riebisch ed agile process software engineering extreme programming xp lecture note business information processing vol springer cham httpsdoiorghttpsdoiorg competitive environment software industry timetomarket becoming critical success factor startup company business idea development revealed easily threatened high speed copycat moreover competitor also follow ongoing journey validating productmarket fit arrive faster destination regardless company size application domain knowledge influencing factor quick learning loop important software startup form bestfit strategy developing business experimentation buildmeasurelearn loop central concept lean startup methodology aim speeding new product development cycle central part loop build representation business socalled minimum viable product mvp collect feedback customer learn steve blank emphasizes goal mvp maximize learning incremental iterative engineering startup context developer quickly iteratively develop software application validate business idea study validated learning beneficial software engineering se concept practice rapid prototype evolutionary prototype consequently timetorelease prototype essential determine total time validated learning loop software startup research increasingly recognized researcher community many practical aspect user experience software practice competence startup ecosystem despite importance lack research prototyping software startup multiinfluenced context funding human resource market concern crucial understand speed learning supported prototyping activity influencing factor previous study investigated prototype built software startup found prototyping activity core value startup experimentation needed seen multifaceted phenomenon work particularly interested factor slow learning process speed research question rq factor influence speed prototyping software startup paper organized follows firstly present background businessdriven experimentation software project software prototype proposal analytical model startup prototyping section describe research approach case studied section qualitative finding presented section finally reflect finding threat validity section draw conclusion future work section author version work selfarhived arxiv definite version published nguyenduc wang x abrahamsson p influence speed prototyping empirical investigation twenty software startup baumeister h lichter h riebisch ed agile process software engineering extreme programming xp lecture note business information processing vol springer cham httpsdoiorghttpsdoiorg background business driven experimentation se perspective validated learning mean focus integrating business value defining software development process practice even though experiment system recognized beneficial software project barrier adopting integration customer feedback synchronizing vendor short cycle lack reasoning customer requirement bosch et al advocate adjusting lean startup methodology accommodate development multiple idea integrate time testing validation long bosch suggested using toweek experimentation iteration followed exposing product customer order collect feedback fagerholm et al present model continuous experimentation start company key element ability release prototype suitable instrumentation manage experiment plan link experiment result product roadmap manage flexible business strategy olsson et al present hypothesis experiment datadriven development model integrates feature experiment customer feedback agile project work characterize processlike approach developing startup software product paternoster et al grounded model software startup describes pattern software startup often build evolutionary prototype study focus startup prototyping reality influencing factor speed learning prototyping prototype prototyping activity brook mentioned software engineering least concept rapid prototyping name recognized value whereas always status computer design building architecture prototyping implies quick economic approach serf achieve understanding final product technical perspective prototype differentiated according relation later product development throwaway prototype used mainly specification purpose used actual building block mostly used exploratory experimental prototyping evolutionary prototype provide basis real system evolved prototype used evolutionary prototyping also found experimental prototyping show provide good basis system business perspective startup create representation product idea socalled mvp without actual product implementation eric ries describes classification different type mvp commonly used startup community instance mvp short animation explains product user buy also user interface lookslike real working product actual business process manually carried wizard oz mvp concierge mvp manual service consists exactly step user would go product research paid attention improving prototyping activity speed effectiveness janssen et al suggested code reuse speed writing code prototype grevet et al described stage prototyping approach speed throwaway prototyping new social computing system using existing online system work address speed prototyping sociotechnical perspective considering prototyping activity human market finance team factor prototypecentric learning model software startup buildmeasurelearn loop key concept lean startup loop used manage operate software startup finding sustainable business model key idea minimize waste focus element tested lynn et al describe another cycle probe learn applicable manage uncertainty market technology timetomarket author suggest startup go customer early version product learn market different application segment nguyenduc et al propose huntergather double loop capture evolution startup activity idea achieving product market fit model visualizes portion product development v customer development activity across startup stage study provide emphasis organization evolution well landed abstract space straightforward apply se perspective se literature gordon et al propose rapid prototyping system approach understand prototype development system model lowfidelity highfidelity prototype essential part developing system preliminary product design activity create throwaway prototype problem domain series throwaway lowfidelity prototype created capture idea built similarly highfidelity prototype also evolved several time reaching product launch literature survey software development show startup often build prototype evolutionary fashion quickly learn user feedback argue throwaway prototype evolutionary prototype important part startup journey launched product lean startup perspective learning input also outcome prototype tailored double loop model previous work adapting gordons system prototyping element capture prototyping process startup context shown figure model focus prototyping core concept compose four loopsthis author version work selfarrived arxiv definite version published nguyenduc wang x abrahamsson p influence speed prototyping empirical investigation twenty software startup baumeister h lichter h riebisch ed agile process software engineering extreme programming xp lecture note business information processing vol springer cham httpsdoiorghttpsdoiorg considering model statebased system possible travel state one however typical flow would happen within two loop also happen startup start loop state example throwaway prototype getting stated problem scope work go indepth loop happen case work explore factor occur startup progress influence throwaway evolutionary prototyping research approach multiple case study design study one part larger research activity investigates role engineering activity software startup objective explore commonality challenge engineering pattern software startup business idea launched product study report finding empirical data regarding prototyping activity conducted multiple case study robust result typical software startup population unit analysis startup company aimed collecting many startup possible variety sample aim reflect stateofpractice rather finding secret recipe success included startup different stage different revenue status figure prototypecentric learning model software startup author version work selfarhived arav definite version published nguyenduc wang x abrahamsson p influence speed prototyping empirical investigation twenty software startup baumeister h lichter h riebisch ed agile process software engineering extreme programming xp lecture note business information processing vol springer cham httpsdoiorghttpsdoiorg often difficulty identifying real startup case among similar phenomenon freelancer smes parttime startup defined five criterion case selection startup operates least six month experience relevant startup least first running prototype startup least initial customer set ie first customer payment group user startup intention scale business model startup software main part business core value process identifying collecting data done month march february case searched four channel startup within professional network author startup town author startup listed startup norway crunchbase database contact list includes startup norway finland italy germany netherlands singapore india china pakistan vietnam sending invitation email received feedback approximately response rate excluding startup interested research startup pas selection criterion final set case startup aliased data collection analysis semistructured individual interview used collect data since enable focus predefined research topic flexible structure discover unforeseen information methodological triangulation data collection also implemented using evidence document observation s business document business model canvas business plan exposed research team preliminary step prepared interview observation useful understand prototype implemented used working environment
Original Title: Towards Understanding Analytics in Software Startups
Original Transcription: # Towards Understanding Analytics in Software Startups

Usman Rafiq

Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy

###### Abstract.

Analytics plays a crucial role in the data-informed decision-making processes of modern businesses. Unlike established software companies, software startups are not seen utilizing the potential of analytics even though a startup process should be primarily data-driven. There has been little understanding in the literature about analytics for software startups. This study set out to address the knowledge gap by exploring how analytics is understood in the context of software startups. To this end, we collected the qualitative data of three analytics platforms that are mostly used by startups from multiple sources. We covered platform documentation as well as experience reports of the software startups using these platforms. The data was analyzed using content analysis techniques. Four high-level concepts were identified that encapsulate the real understanding of software startups on analytics, including instrumentation of analytics, experimentation, diagnostic analysis, and getting insights. The first concept describes how startups set up analytics and the latter three illustrate the usage scenarios of analytics. This study is the first step toward understanding analytics in the software startup context. The identified concepts can guide further investigation of analytics in this context. It also provides some insights for software startups to set up analytics for data-informed decisions. Given the limitation of the data used in the study, the immediate next step is to ground as well as validate the acquired understanding using the primary data, by directly interacting with software startups

2022

ac analytics, metrics, abstraction, software startups +
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.
+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.

+
Footnote †: 2022: Association for Computing Machinery.
software startups and eventually explains how do they leverage their decision-making using analytics. Moreover, the findings identify important areas of product and business development where analytics can be applied.

## 2. Related Work

There are relatively few studies on analytics in the software startup context. In recent work, Rafiq et. al. (Rafiq et al., 2017) studied how software startups deal with the information to make decisions from an analytics perspective. They reported ten types of recurrent analytics mistakes that might derail software startups. The information dealing mistakes are further grouped into four categories: information collection, information analysis, information communication, and information usage.

In another related study, while investigating the role of data analytics in startup companies, Berg et al. (Berg et al., 2017) presented challenges and barriers faced by startups. The study claims that startups are aware of the benefits of applying analytics, however, they are also facing challenges in implementing it. The reported challenges are scarcity of resources, lack of training/skills, time management issues, privacy issues in dealing with the data, and lack of access to the data. It is further argued that the amount of data that startups collect, in the early stages, is insufficient to apply analytics. We find that this study analyzed hardware startups only and big data analytics was brought into the question. This is done possibly because the term _big data_ is considered as one of the key aspects of business analytics, however, it differs from traditional data in terms of velocity, volume, and variety (Berg et al., 2017).

On the other hand, we find some writers reporting on metrics and measurements in startups. One such example is the multiple case study of Kamulegeya et al. (Kamulegeya et al., 2017), where authors report 28 metrics that startups are utilizing or wish to utilize. The study (Kamulegeya et al., 2017) classifies metrics list according to the measurement practices in established software companies and present five categories: business metrics, product metrics, organizational performance metrics, project metrics, and design metrics.

Later, Kemell et al. (Kemell et al., 2017), in their multi-vocal literature review, report more than 100 metrics that startups can use. However, we observed that most of these metrics are appropriate for the late stages in the life cycle of startups. Moreover, the study does not reflect on the information needed and the process to collect/track these metrics.

Taken together, the studies presented, thus far, provide evidence that there is a lack of understanding on how startups understand the term analytics and apply analytics in the startup context. The current study seeks to address this gap.

## 3. Research Method

Our research is exploratory in nature as the knowledge on the understanding of software startups regarding analytics is limited. Therefore, to develop an initial understanding of what software startups think about analytics, we decided to utilize secondary data i.e. text data from analytics platforms. Nowadays, the widespread usage of secondary data in research makes it a feasible approach to meet limited-time and resources (Kamulegeya et al., 2017). Vartanian (Vartanian, 2018) describes that secondary data is the data collected by someone other than the researcher with some other objective. Likewise, to analyze the data set, we used content analysis, a qualitative research method (Vartanian, 2018). A major advantage of using content analysis is that it is considered an appropriate method in the absence of existing theory or when the knowledge on the phenomenon is limited. In particular, we employed a conventional content analysis approach to build an understanding of analytics in the startup context. Fig. 1 depicts the complete process of data collection and analysis. The following subsections describe how we collected, filtered, and analyzed the data.

### Data Collection

Based on the research question, we planned to study analytics platforms that are particularly intended for software startups. As a preliminary step on getting information for platforms that startups are using., we consulted forums on Hacker News 1. Hacker News is the most trusted, reliable, and prevalent source of news for the entrepreneurship and computer science community. It facilitates finding the latest information on startups which is hard to find elsewhere.

Footnote 1: [https://news.ycombinator.com/](https://news.ycombinator.com/)

We applied search terms like "analytics", "metrics" and "startups" to drive the search on the forum. These terms are originated from

Figure 1. Data Collection and Analysis Procedure

the research question of this research. Consequently, the manual analysis of the resulting discussions on forums revealed several analytics platforms. These platforms were brought up into a discussion of the startup community, illustrating its features, usage scenarios, and a short comparison. These platforms were ranged from open source to proprietary solutions and covered the following:

* Simple Analytics ([https://simpleanalytics.com/](https://simpleanalytics.com/))
* Mixpanel ([https://mixpanel.com/](https://mixpanel.com/))
* Google Analytics ([https://analytics.google.com/](https://analytics.google.com/))
* Matomo([https://matomo.org/](https://matomo.org/))
* Fathom ([https://usefathom.com/](https://usefathom.com/))
* Plausible ([https://plausible.io](https://plausible.io))
* Open Web Analytics ([https://www.openwebasultics.com/](https://www.openwebasultics.com/))
* Kissmetrics ([https://www.kissmetrics.io/](https://www.kissmetrics.io/))
* Amplitude ([https://amplitude.com/](https://amplitude.com/))
* Umami (https://umanis/)
* Goutcounter ([https://www.goatcounter.com/](https://www.goatcounter.com/))
* Snowplow ([https://snowplowanalytics.com/](https://snowplowanalytics.com/))

Thereafter, we visited individual platform websites, manually extracted the information, and stored it in text files. The information stemmed from several sources, like for example, associated documentation, configuration information, developer information in case of an open-source tool, user interface, testimionals of customers, and blog posts. We also found blogs of some of the platforms where the vendors expressed their opinions about analytics and shared their experiences in instrumenting analytics at other startup companies. We read each of the available documentation and assessed whether the data can be utilized to address the research question. It is noteworthy to state that we utilized every possible way to extract the fragmented documentation associated with these platforms with an intent not to miss some useful information. To achieve this, we searched platform-specific documentation on the platform website, Hacker News forum and Github 2, a repository hosting service of open source applications. In this regard, we used the platform's hosting documentation on Github, known as a wiki to extract some more information.

Footnote 2: [https://github.com/](https://github.com/)

To obtain another triangulation in the data collection and sampling phase, we explored the website of G2 3. G2 is a legit source to check the reviews of business software by real users. We found some of the platforms available on G2, however, few platforms were not listed on it. This has helped us in screening analytics platforms for the final data set. Lastly, we decided to utilize the information from the following three platforms for our data set:

Footnote 3: [https://www.g2.com/](https://www.g2.com/)

1. Amplitude ([https://amplitude.com/](https://amplitude.com/))
2. Mixpanel ([https://mixpanel.com/](https://mixpanel.com/))
3. Plausible ([https://plausible.io](https://plausible.io))

We considered the following inclusion/exclusion criteria while screening the platform information for our final data set: (1) Platform is mature i.e. used by a huge startup community. We subjectively assessed these criteria from Hacker News forum and objectively from stargazer on Github website (2) Platform is available on G2 website, (3) Platform is having extensive documentation, from multiple sources like, for instance, website, blog posts and information from forums. (4) Platform's vendor is/was a software startup. We checked startup information from Crunchbase 4. (5) Platform's documentation contained data wherein at least one or multiple stories were shared. These stories communicate experiences of software startups while implementing analytics. We assessed this information from the collected documentation of the platform and later on checked individual startups on Crunchbase. In total, the data contained 9 startup stories focusing on analytics, with varying text lengths.

Footnote 4: [https://www.crunchbase.com/discover/organization.companies](https://www.crunchbase.com/discover/organization.companies)

### Data Analysis

We used the qualitative analysis method, named, content analysis to analyze the data. The use of content analysis in the software engineering context is not new to software engineering research. Recent studies, such as (Bartos et al., 2018) and (Krishnan et al., 2019), advocate a rigorous process for its use in software engineering.

Content analysis can be applied to the text data other than interview data and coding categories are directly derived from the data (Bartos et al., 2018). This is what makes it different from thematic analysis. Therefore, in the content analysis research method, text data can be obtained from interviews, focus groups, narrative responses, survey questions, books, articles, or even manuals (Bartos et al., 2018). In particular, we applied conventional content analysis inductively. This approach is recommended when there is a lack of research knowledge on the topic (Bartos et al., 2018). While performing analysis, we read the whole text repeatedly to get a complete sense of the data. We then started coding phrases wherein the term analytics was indicated or the impression of analytics was arising. We highlighted the text that appeared to contain the relevant terms and described the concepts. Subsequently, we utilized the author's words to code this segment of the text. Alongside, we ignored the summative indication of analytics in the text whereby the text was mainly referring to the names of analytics platforms. Meanwhile, we avoided creating new codes as the analysis process continued. It further depicts that we only added new codes when we assessed that the existing codes are not fit to label the new text under consideration.

Likewise, soon after finishing the development of codes, we then moved the focus of our analysis to the coded data and examined each code. We eventually examined the text within the particular code and then merged, renamed, and eliminated codes while the analysis process iterated. Based on the similarity in the codes and the relationship between the codes, we created the clusters, eventually organizing clusters into a hierarchical structure. As a result, we obtained 16 themes that were further clustered into 4 high-level themes/top-level categories.

We used NIVVO 5, a qualitative data analysis tool, to support the conventional content analysis.

Footnote 5: [https://www.qqinternational.com/nvivo-qualitative-data-analysis-software/home/](https://www.qqinternational.com/nvivo-qualitative-data-analysis-software/home/)

## 4. Findings

In this section, we present our research results. We identified 14 themes, in our data set, that directly express or found more relevant to the analytics process inside software startups. We categorized these themes into 4 high-level themes. The high-level themes include instrumenting, experimentation, diagnostic analysis, and getting insights. The clustering of themes and labeling into high-level is purely inductive and thus based on two factors. The first one focuses on how to set up analytics in startups and we name it instrumenting analytics. What we mean by instrumentation of analytics is the intuition and directions to set up analytics in startups. On the flip side, three themes coexist together and focus what are the possible scenarios of applying analytics in startups. Here, we include experimentation, diagnostic analysis and finally getting insights. These themes, when taken together, illustrate how the term analytics is understood by software startups. Fig. 2 shows how software startups handle analytics.

### Instrumenting Analytics:

#### 4.1.1. Defining Goals:

We figured out that all of the startups, employing analytics, have the sense of defining one or multiple goals to achieve, through analytics. Often analytics platform vendors also found promoting culture to establish the goals to meet the business objectives. As an example, in the report of Amplitude platform (1), the concept is explained like this: " _Too often, companies develop feature after feature without thinking about how those features meet overall business objectives_." Therefore, these goals might be tied directly to the success of the startup. This further illustrates the thinking of measuring what matters the most and avoiding getting indulged in the noise. It is evident from one of the following excerpts, of Amplitude Platform (1): "_Measuring anything and everything leads to unmanageable data. It shifts the burden to your team to try and make sense of the results_." In another instance, the company advised in a similar context:"_keep your end goals in mind_".

Going in the same vein, one of the startups, wanted their clients to hit on the platform. The goal was to increase customer retention. The possible ways they found against the goal were to reduce churn rate and increase customer conversion. Churn rate is the rate at which customers discontinue using a service or product and conversion means how new customers take a desired action (Bradner, 2017). In the data of Mixpanel Platform (2), a startup described the situation in the following words:"_For each market, they have targets they want partners to hit, so they know they are reducing churn and increasing conversion_". A similar conclusion is echoed in another report of Plausible Analytics Platform (3), where the company expressed its thoughts about setting goals: "_Most web analytics allow site owners to set goals and events to track those visitor actions that matter the most to them_.". It is worthwhile to report that these established goals generate several metrics to monitor. The startup reflected this opinion in the following excerpt: "_goals and events can be tied directly to the monetary success of an enterprise which makes them essential metrics to follow to understand the state of the business_".

#### 4.1.2. Asking Questions:

The data analysis, on the whole, suggests that asking questions is a good way to establish the key focus of analytics, revealing what one wants to achieve through it. And, certainly, this has a connection with setting goals while instrumenting analytics in the startup. In the report of Mixpanel Platform (2), one startup emphasized it in the following way: "_We need to be asking these questions_". The same report embarked again: "_We want people to engage with data, ask questions, and find the answers in data to make the right decisions_". Likewise, Amplitude Platform (1) data, reported a similar conclusion in the following excerpt: "_Business often have a multitude of questions about their customers and how their product is performing_".

Based on the data set, we encountered the following set of questions that can be asked while instrumenting analytics:What exactly works and what does not?, What do we want to be measuring?, What's the useful metric?, Is there an event we should be publishing?, Which features are popular?, Which users retain best?, which types of users stick around, and for how long Who are my most valuable customers?, What actions do those valuable customers take?, Who are the customers who churn?, How many power users you have, What actions do churn users take?, What are the characteristics of highly engaged users?, What are my users' pain points?, What's happening on your site live in that moment, What are people doing when they visit the website? and What's happening and how things are going?

#### 4.1.3. Metrics As a Culture:

We found several interesting examples in the data where one startup repeatedly emphasized embedding metrics in the overall culture of the product development process. It means that no product feature should be left without publishing different metrics. It is aimed at serving the purpose of measuring and working towards large business goals. The same startup, said on one occasion, in the report of Mixpanel Platform (2): "_Publishing the right business metrics must be integrated into your development process_". The speaker, continued: "_Baking this into the culture and the expectation is probably the most important and most impactful thing that you can do_". He further advised startups: "_build it into the culture and build it into the development process so that it becomes a given_". While establishing this culture, it is necessary that all product platforms i.e. web and mobile, should be aligned and the same vocabulary should be put in place across the development life cycle. This alludes to the following notion: "_Ensure that all your stakeholders-both in web and mobile-are aligned on how to name those events and properties_. ". A similar conclusion is highlighted in the report of Amplitude Platform (1), where the company said: "_They align on target product outcomes, define an event taxonomy to measure those outcomes, and instrument tracking code_".

#### 4.1.4. Tracking Goals:

We observed that another theme in the data is usually concerned with tracking the goals. This theme is concerned with tracking established goals. For example, a startup set up a goal and wanted partners to grow. In contrast to this goal, the startup asked many questions and then tracked metrics. This is shown in the following excerpt of a startup, in Mixpanel Platform (2) report: "_-- track how well their restaurant partners are doing on the platform_". "_and being able to look at these metrics is what's going to enable us to do that_", the startup reported. Another startup, in the same report, had a similar goal and wanted to know the most performing customer acquisition channels and increase customer conversion. The startup reflects its tracking of this goal in the following words: "_--been able to measure and optimize high-performing acquisition channels, and also improve purchase funnels, making it easy for consumers to convert into loyal policyholders_". A similar indication about tracking goals about customer conversion is found in the report of Plausible Analytics Platform (3), where the startup indicated to track several metrics against goals: "_Track events and goals to identify the number of unique converted visitors, the total number of conversions, the conversion rate, and the referral sites that send the traffic that converts the best."_.

#### 4.1.5. Unifying Analytics:

Unifying Analytics is one of the challenges that startups must tackle while instrumenting analytics. Based on the findings, we highlight two types of unification, a startup can achieve. The first type incorporates unifying analytics on all of the fragmented products of the startup. Oftentimes, a startup offers multiple platforms, such as a combination of web and mobile app. This is echoed by one of the startups, in the report of Mixpanel Platform (2): "_the company needed to unify its fragmented analytics ecosystem_".

On the flip side, the other aspect of unification discussed in the data is the shared understanding and goal alignment among different startup teams, like, for instance, between the engineering team and product team. The shared understanding and alignment might include target product outcomes, taxonomy to measure outcomes, and instrumenting coding accordingly. The report of Amplitude Platform (1) shows: "_Implementing great product analytics requires product and engineering teams to work together. They align on target product outcomes, define an event taxonomy to measure those outcomes, and instrument tracking code_". This enables the engineering team to track only what is required by the product team. The company, Mixpanel Platform (2), agrees with such alignment in the following words: "_Ensure that all your stakeholders-both in web and mobile-are aligned on how to name those events and properties. Finally, make certain that everyone is bought in on maintaining best practices_".

### Experimentation

#### 4.2.1. Testing Hypotheses:

A recurrent theme in the data was the utilization of analytics in testing hypotheses. Startups need to quickly test several hypotheses. Various startup development approaches like, for example, lean startup and customer development methodology are amplifying the use of Hypotheses, particularly at early stages (Bouquet et al., 2016; Bouquet et al., 2016). We found startups using analytics to test the hypotheses. Simultaneously, analytics platforms are providing supporting features to achieve this goal. For example, the Amplitude Platform (1) report indicated such features. Identifying the Winning features, customer acquisition campaigns, referral sources, and hypotheses regarding customer behavior are prominent in the data. At one instance, the report of Amplitude Platform (1), indicated:"_Its growth engine generates hypotheses data by observing customer behavior while also amplifying winning features and campaign ideas_". We encountered many instances in the data where this feature was highlighted. It shows that the concerns regarding hypotheses testing through analytics are widespread among startups. This is evident from the following excerpt of a startup in the report of Mixpanel Platform (2): "_We wanted to test this hypothesis, so we quickly threw events_". The startup continued alluding about the outcome of this testing: "_we were able to test and disprove our hypothesis of

Figure 2. How Software Startups Understand Analytics

[MISSING_PAGE_FAIL:6]

understanding the customer needs. As, one startup, Plausible Analytics (3) indicated:"_You may be putting a lot of time, effort, and resources into different marketing campaigns and by looking at referral sources of your website traffic you can better understand which of those campaigns are more worth than others_". The startup continued arguing that one needs to redesign its future strategy if the existing efforts are misleading. "_If you're spending a lot of time and effort on a community but that effort doesn't result in any benefits to your site or business, then you need to reconsider things_", the startup remarked on the situation. While talking about the future strategy, the startup asserted to analyze efforts to optimize the future. It is reported in the following phrase: "_an addition layer and more depth to analyze your efforts which can then help you optimize your strategy for the future_".

A similar experience is shared in the report of Amplitude Platform (1), where the company highlighted the need for analytics to deeply understand the customer needs and assess the outcomes of development efforts. The statement reflects this finding: "_The one thing we found missing was a powerful product platform to truly understand what users wanted and the impact our development efforts were having on their user experience_".

#### 4.4.2. Measuring Progress

Savvy startups are often concerned with measuring their progress. However, measuring the progress without any yardstick is barely possible. This is what we pointed out while analyzing the data. We found that startups are using analytics to measure their progress using insights from different perspectives. The startup, Plausible Analytics (3), told in their report: "_we use web analytics to measure our startup's progress and make better decisions_". Generalizing this need, the startup claimed: "_majority of website and business owners want to see some level of stats that tells them what's going on_". The company further highlighted the key advantages of using analytics in measuring progress, in following excerpt: "_some of the main areas where web analytics can help website owners get a better idea of what's happening and how things are going_".

#### 4.4.3. Making Decisions

The data analysis depicts that, startup decisions are based on the insights that the analytics generates for them. These insights oftentimes arise by measuring the progress of startup, by assessing the startup efforts in making things done, or during the experimentation, however, these are considered holistically while making decisions. For instance, Plausible Analytics (3) claimed that they used analytics in making decisions. These decisions further lay down the foundation of future strategy. It is apparent from the following excerpt: "_... more depth to analyze your efforts which can then help you optimize your strategy for the future_". In the same way, a startup, in the report of Mixpanel Platform (2), shared that they decided not to put more effort into designing features when they observed that their partners are already engaged with the product. The startup commented: "_This finding was helpful... because it showed them that, since restaurants were already using the feature, perhaps they didn't need to invest more in it_.". The company Amplitude Platform (1) sheds more light on making decisions employing analytics in these words: "_Your product analytics can provide you with the exact data needed to drive your decision-making and continue to make improvements that delight your customers_. ".

#### 4.4.4. Understanding User Behaviour and Engagement

One possible use of analytics, our data analysis showed, is understanding user behavior and interaction with the product. It is used to clear the assumptions regarding the customer's behavior. At the same time, it brings to the surface, trending content, winning product features, and highlights the customer journey from one platform to another. Several analytics goals can be achieved through this, like, for example, improving retention by monitoring and understanding user behavior. The report of Amplitude Platform (1), highlights this finding in the following words: "_Identifying which customers are most engaged and using this information to improve retention_". The company continued expressing similar and concrete benefits at another place in the following excerpt: "_analytics helps you create that digital experience without any guesswork. It provides you with concrete information to optimize conversions, grow retention, and maximize revenue_. ".

Another interesting finding, we noticed, is finding reasons of a user behaviour. "_Good product teams don't just ask, what are my users doing? They ask, why? This requires context_", the report of Amplitude Platform (1), revealed.

## 5. Discussion

Our study results confirm that analytics in the startup context reflects a somewhat different meaning in contrast to what is described in the software engineering literature. Therefore, when we talk about startups, analytics is not based on the big data as it is indicated in (Berg et al., 2016; Berg et al., 2016), nor it is characterized by what is given in terms of software analytics (Berg et al., 2016). However, we find that while there exist many types of analytics in the literature, e.g. big data analytics, web analytics, software analytics, and social media analytics, startup analytics is closer to the characteristics of web analytics. Alongside, we need further investigation to ground the understanding of analytics in the startup context.

The study (Hernandez et al., 2016) also reported a few other analytics-related mistakes, e.g. "_avoiding to collect further information_", "_poor team communication_" and "_mishanding information_". Our data shows that the first two mistakes can be mitigated by instrumenting analytics in startups. For instance, unifying analytics will reduce poor communication in the startup team. Similarly, for the last one, the findings suggest looking at information from multiple perspectives and also waiting for trends to appear in the information.

Surprisingly, one of our findings emphasizes developing a culture of metrics and embedding it into the development of product features. This invites the concept of measuring everything, especially in product development. A possible explanation for this result might be that startups could need to produce hindsight. Therefore, in a retrospect, they might need to do this. However, we find no clue on this finding from literature, and our study also remains unable to explain it to a further extent.

In contrast to the earlier findings of (Berg et al., 2016), however, we confirm that software startups are using analytics. This difference may be explained by our chosen sample. We studied purely software startups while Berg et al. (Berg et al., 2016) studied startups with a hardware part as well. Another important difference, we would like to illustrate is that our study focused on the understanding of startups about analytics. We find that, when taken together, this understanding is pretty different from what general software engineering literature states about analytics. The literature (Bertsch et al., 2016; Bertsch et al., 2017; Bertsch et al., 2018), presents analytics in terms of big data analytics, software analytics, or simply data analytics. It is interesting to reveal that our findings provide a diverse understanding of analytics from a startup's perspective. However, it would be interesting to relate our findings with general software engineering literature. This would remain an important issue for future avenues.

Lastly, the findings strongly show a connection of analytics with metrics. For example, goals and questions during analytics instrumentation generate metrics. However, our findings are not self-explanatory in explaining this connection and further assessment of the relationship between analytics and metrics.

### Threats to Validity

One of the threats to validity, particularly, internal validity, is the use of secondary data. This type of data provides a lack of control on data volume and quality. To mitigate this threat, to a certain extent, we triangulated data using multiple sources and by applying inclusion/exclusion criteria. This type of data has already been used by other studies, like for example, by (Bertsch et al., 2017).

Regarding threats to external validity, one of the threats lies in our data collection strategy. We selected 3 platforms out of 12 for further investigation by applying several inclusion/exclusion criteria. Later, we collected analytics platform documentation from every possible source e.g. platform website, blogs, and forums. The data, from the three platforms, was different in length and scope. Besides that, we might have missed collecting some associated data. However, the data set was containing startups from different geographical regions, market segments, and different product platforms. It enhanced the ability to generalize the results of this ongoing research effort.

Regarding the reliability of this study, one possible threat is concerned with the researcher's bias in the coding process. The coding process was done by one researcher solely, however, the early codes and themes were discussed with the other researcher before reporting.

Lastly, we take the privilege to admit that the reported understanding of analytics, in the startup context, still needs further investigation, possibly with the primary data. It further means that we need to continue grounding and validating our understanding of analytics in the startup context based on the primary data.

## 6. Conclusions and Future Work

Startups are confronted with several challenges while raising the odds of success. Uncertainty, scarcity of resources, engineering challenges, speed, and right focus are among few to mention. On their way, startups have to take plenty of decisions and adjust directions accordingly. This is where analytics can serve them with the right information. This is the first study that attempts to explain how analytics is understood in the startup context. In this ongoing research, we report an initial understanding of analytics in the startups covering its instrumentation and the context, in which it can be utilized.

Several questions still need to be answered in the future. One significant direction is to validate this understanding of analytics in startups with the primary data. Moreover, the current findings have left many questions in need of further investigation. For example, further work is required to map the relationship of _analytics_ with the term _metrics_. As both these terms are used interchangeably. Lastly, the relationship between stages of startup across the lifecycle and use of analytics might be worth investigating.

## References

* F. Auer, C. S. Lee, and M. Felderer (2020)Continuous experiment definition characteristics. In 2020 46th Euromicro Conference on Software Engineering and Advanced Applications (SCAA), pp. 186-190. Cited by: SS1.

[MISSING_PAGE_POST]

Title: What influences the speed of prototyping? An empirical investigation of
  twenty software startups
Transcription: # What influences the speed of prototyping? An empirical investigation of twenty software startups

Anh Nguyen Duc

1Department of Computer and Information Science (IDI), NTNU

NO-7491 Trondheim, Norway

1

Xiaofeng Wang

2Free University of Bozen-Bolzano

Piazza Domenicani 3, 39100 Bolzano, Italy

2

 Pekka Abrahamsson

1Department of Computer and Information Science (IDI), NTNU

NO-7491 Trondheim, Norway

1

Footnote 1: email: {anh, pekkaa}@ntnu.no, xiaofeng.wang@unibz.it

###### Abstract

It is essential for startups to quickly experiment business ideas by building tangible prototypes and collecting user feedback on them. As prototyping is an inevitable part of learning for early stage software startups, how fast startups can learn depends on how fast they can prototype. Despite of the importance, there is a lack of research about prototyping in software startups. In this study, we aimed at understanding what are factors influencing different types of prototyping activities. We conducted a multiple case study on twenty European software startups. The results are two folds; firstly we propose a prototype-centric learning model in early stage software startups. Secondly, we identify factors occur as barriers but also facilitators for prototyping in early stage software startups. The factors are grouped into (1) artifacts, (2) team competence, (3) collaboration, (4) customer and (5) process dimensions. To speed up a startup's progress at the early stage, it is important to incorporate the learning objective into a well-defined collaborative approach of prototyping.

**Keywords: prototype, MVP, prototyping-learning loop, validated learning, speed, software startups**

## 1 Introduction

With the startup movement, software industry is witnessing a paradigm shift from serving customer requirements to creating customer value. The challenge for software companies is no longer primarily on implementing customer requirements, but rather on finding customer demands and providing a solution that delivers customer value [2]. Addressing uncertainty in both solution and problem domains has often been ad-hoc and based on guesswork, which becomes one of the main reasons for failing startup companies [3]. A demand on systematic approaches to manage the uncertainty has led to an increased research interest on Lean Startup [4], New Product Development (NPD) [5], software startups [6] and continuous experimentation [7].

This is the author's version of the work. It is self-arrived at Arxiv. The definite version was published in: Nguyen-Duc A., Wang X., Abrahamsson P. (2017) What Influences the Speed of Prototyping? An Empirical Investigation of Twenty Software Startups. In: Baumeister H., Lichter H., Riebisch M. (eds) Agile Processes in Software Engineering and Extreme Programming. XP 2017. Lecture Notes in Business Information Processing, vol 283. Springer, Cham, [https://doi.org/10.1007/978-3-319-57633-6](https://doi.org/10.1007/978-3-319-57633-6)\(2\)

In a competitive environment such as software industry, time-to-market is becoming more and more critical as a success factor for startup companies. Business ideas under development once revealed can be easily threatened by high speed copycats [9]. Moreover, competitors can also follow an on-going journey of validating product-market fit and arrive faster in the destination. Regardless of company sizes and application domains, the knowledge of influencing factors for a quick learning loop is important for software startups to form best-fit strategy in developing business experimentation [10].

A 'Build-Measure-Learn' loop, as a central concept of the Lean Startup methodology, aims at speeding up the new product development cycle [4]. The central part of the loop is to build a representation of the business, a so-called Minimum viable product (MVP), to collect feedback from customers and to learn from that. Steve Blank emphasizes the goal of MVPs is "_to maximize learning through incremental and iterative engineering_" [2]. In the startup context, developers quickly and iteratively develop a software application to validate business ideas [12]. As such, the study of validated learning can be beneficial from Software Engineering (SE) concepts and practices, such as rapid prototypes and evolutionary prototypes [13, 14, 15]. Consequently, the time-to-release of prototypes is essential to determine the total time in the validated learning loop.

Software startup research is increasingly recognized by researcher's community, with many practical aspects, such as User Experience, Software practices, competences and startup ecosystem [6]. Despite of the importance, there is a lack of research about prototyping in software startups. In a multi-influenced context with funding, human resource and market concerns, it is crucial to understand how the speed of learning can be supported by prototyping activities and what are the influencing factors. In a previous study, we investigated how a prototype is built in software startups [12]. We found that prototyping activities as a core value of startup experimentation needed to be seen as a multifaceted phenomenon [12]. In this work, we are particularly interested in the factors that slow down the learning process and those that speed it up. The research question (RQ) is:

_What factors influence the speed of prototyping in software startups?_

The paper is organized as follows. Firstly, we present the background about business-driven experimentation in software projects, software prototype and a proposal of an analytical model of startup prototyping (Section 2). Then, we describe our research approach and the cases studied (Section 3). After that, the qualitative findings are presented (Section 4). Finally, we reflect on the findings, the threats to validity (Section 5), and draw the conclusion and future work (Section 6).

_This is the author's version of the work. It is self-arhived at Arxiv. The definite version was published in: Nguyen-Duc A., Wang X., Abrahamsson P. (2017) What Influences the Speed of Prototyping? An Empirical Investigation of Twenty Software Startups. In: Baumeister H., Lichter H., Riebisch M. (eds) Agile Processes in Software Engineering and Extreme Programming. XP 2017. Lecture Notes in Business Information Processing, vol 283. Springer, Cham, [https://doi.org/10.1007/978-3-319-57633-6](https://doi.org/10.1007/978-3-319-57633-6)\(2\)

## 2 Background

### Business driven experimentation

From SE perspective, validated learning means the focus on integrating business value in defining software development processes and practices. Even though experiment systems are recognized as beneficial to software projects, there are barriers in adopting them, such as integration of customer feedback, synchronizing vendors in short cycles and lack of reasoning about customer requirements [16, 17]. Bosch et al. [18] advocate for adjusting the Lean startup methodology to accommodate the development of multiple ideas and to integrate them when time for their testing and validation is too long. Bosch suggested using 2-to-4-week experimentation iterations followed by exposing the product to customers in order to collect feedbacks. Fagerholm et al. present a model for continuous experimentation for start up companies [7], in which a key element is the ability to release a prototype with suitable instrumentation, to manage experiment plans, link experiment results with a product roadmap, and to manage a flexible business strategy. Olsson et al. present a Hypothesis Experiment Data-Driven Development model that integrates feature experiments with customer feedback in Agile projects [19]. While these work characterize a process-like approach in developing startups' software products, Paternoster et al. grounded a model from 13 software startups which describes a pattern that software startups often build evolutionary prototypes [20]. This study focuses on how startups are prototyping in reality and the influencing factors of the speed of learning by prototyping.

### Prototype and prototyping activities

Brook mentioned "_In software engineering, at least, the concept of rapid prototyping has a name and a recognized value, whereas it does not always have the same status in computer design and in building architecture_" [21]. Prototyping implies a quick and economic approach that serves to achieve understanding of what final products should be [15]. From a technical perspective, prototypes can be differentiated according to its relation to later product development. Throwaway prototypes are used mainly for specification purposes; and they are not used as actual building blocks [15]. They are mostly used in exploratory and experimental prototyping. Evolutionary prototypes provide a basis for a real system, which is evolved out of the prototypes; they are used in evolutionary prototyping but can also be found in experimental prototyping (if it shows that they provide a good basis for a system) [15].

From a business perspective, startups can create a representation of product ideas, a so-called MVP, without actual product implementation. Eric Ries describes a classification of different types of MVPs [4], which are commonly used in the startup communities. For instance, a MVP can be a short animation that explains what a product does and why users should buy it. It can also be a user interface that lookslike a real working product, but the actual business process is manually carried out (Wizard of Oz MVP). A concierge MVP is a manual service that consists of exactly the same steps users would go through with the product.

A few research paid attention on improving prototyping activities, such as the speed and effectiveness [28, 29]. Janssen et al. suggested code reuse to speed up writing code to prototype [28]. Grevet et al. described a 6-stage prototyping approach to speed up throw-away prototyping for new social computing systems using existing online systems [29]. In our work, we address the speed of prototyping from a socio-technical perspective, considering prototyping activities under human, market, finance and team factors.

### A prototype-centric learning model in software startups

The Build-Measure-Learn loop is a key concept in Lean Startup [4]. The loop is used to manage and to operate software startups in finding a sustainable business model. A key idea is to minimize waste and to focus only on the elements, which will be tested. Lynn et al. describe another cycle, Probe and Learn, that is applicable to manage uncertainties about market, technology and time-to-market [25]. The authors suggest that startups should go to customers with an early version of a product to learn about the market, different applications and segments. Nguyen-Duc et al. propose a hunter-gather double loop to capture the evolution of startup activities from idea to achieving a product market fit [26]. The model visualizes the portion of product development vs. customer development activities across the startup stages. While these studies provide an emphasis on organization and evolution, they are well landed in an abstract space, not straightforward to apply from the SE perspective.

In the SE literature, Gordon et al. propose a rapid prototyping system approach to understand the prototype development of a system [27]. In the model, both low-fidelity and high-fidelity prototypes are essential parts of developing a system [27]. Preliminary product design activities create a throwaway prototype from the problem domain. A series of throwaway low-fidelity prototypes can be created to capture the ideas of what to built. Similarly, high-fidelity prototypes can also be evolved several times before reaching the product launch.

A literature survey of software development shows that startups often build a prototype in an evolutionary fashion and quickly learn from users' feedback [20]. We argue that both throwaway prototypes and evolutionary prototypes are important parts of startups' journey to a launched product. From the Lean startup perspective [4], learning is an input and also an outcome for a prototype. We tailored the double loop model in the previous work [26] by adapting Gordon's system prototyping elements [27] to capture the prototyping processes in the startup context, as shown in Figure 1. The model focus on prototyping as the core concept and compose four loops:This is the author's version of the work. It is self-arrived at Arxiv. The definite version was published in: Nguyen-Duc A., Wang X., Abrahamsson P. (2017) What Influences the Speed of Prototyping? An Empirical Investigation of Twenty Software Startups. In: Baumeister H., Lichter H., Riebisch M. (eds) Agile Processes in Software Engineering and Extreme Programming. XP 2017. Lecture Notes in Business Information Processing, vol 283. Springer, Cham, [https://doi.org/10.1007/978-3-319-57633-6_2](https://doi.org/10.1007/978-3-319-57633-6_2)

Considering the model as a state-based system, it is possible to travel from a state to any other one. However, the typical flow would happen within two loops. It can also happen that a startup starts the loop from any state, for example, by doing a throwaway prototype before getting to a stated problem. In the scope of this work, we did not go in-depth about how these loops happen in our cases. The work will explore factors that occur during the startup progress and influence throw-away and evolutionary prototyping.

## 3 Research approach

### Multiple case study design

This study is one part of a larger research activity that investigates the role of engineering activities in software startups. The objective is to explore commonalities, challenges and engineering patterns in software startups, from the business idea to a launched product. This study reports the findings from empirical data regarding prototyping activities. We conducted multiple case studies for a robust result in typical software startup population [11]. The unit of analysis is a startup company. We aimed at collecting as many startups as possible for a variety of the sample. As the aim is to reflect the state-of-practice rather than finding a secret recipe of success, we included startups in different stages and with different revenue statuses.

Figure 1: A prototype-centric learning model in software startups

_This is the author's version of the work. It is self-arhived at Arav. The definite version was published in: Nguyen-Duc A., Wang X., Abrahamsson P. (2017) What Influences the Speed of Prototyping? An Empirical Investigation of Twenty Software Startups. In: Baumeister H., Lichter H., Riebisch M. (eds) Agile Processes in Software Engineering and Extreme Programming. XP 2017. Lecture Notes in Business Information Processing, vol 283. Springer, Cham, [https://doi.org/10.1007/978-3-319-57633-6](https://doi.org/10.1007/978-3-319-57633-6)\(2\)

There is often a difficulty in identifying a real startup case among other similar phenomenon, such as freelancers, SMEs or part-time startups. We defined five criteria for our case selection: (1) a startup that operates for at least six months, so their experience can be relevant, (2) a startup that has at least a first running prototype, (3) a startup that has at least an initial customer set, i.e. first customer payments or a group of users, (4) a startup that has an intention to scale their business model, (5) a startup that has software as a main part of business core value.

The process of identifying and collecting data was done in 11 months, from March 2015 to February 2016. Cases were searched from four channels, (1) startups within the professional networks of the authors, (2) startups in the same town with the authors, (3) startups listed in Startup Norway and (4) Crunchbase database. The contact list includes 219 startups from Norway, Finland, Italy, Germany, Netherlands, Singapore, India, China, Pakistan and Vietnam. After sending out invitation emails, we received 41 feedbacks, approximately 18.7% response rate. Excluding startups that are not interested in the research, or startups that do not pass our selection criteria, the final set of cases are 20 startups, aliased as S1 to S20.

### Data collection and analysis

Semi-structured individual interviews were used to collect data, since they enable the focus on pre-defined research topics and flexible structures to discover unforeseen information [28]. Methodological triangulation in data collection is also implemented by using evidence from documents and observations (in S01-S05, S09). Business documents, such as business model canvases and business plans were exposed to the research team as a preliminary step prepared for interviews. Observations were useful to understand how prototypes were implemented and used in the working environment.

Tuple 4:
Cleaned Title: investor biased woman analyzing gender affect startup funding europe
Cleaned Transcription: investor biased woman analyzing gender affect startup funding europe michael farber karlsruhe institute technology kit institute aifb karlsruhe germany michaelfaerberkitedu alexander klein karlsruhe institute technology kit institute aifb karlsruhe germany xkleingmailcom abstract one main challenge startup raise capital investor startup founder therefore crucial know whether investor bias woman startup founder way startup face disadvantage due gender bias existing work gender study mainly analyzed u market paper aim give comprehensive picture gender bias earlystage startup funding examine european startup listed crunchbase using semantic web technology analyze share female founder founding team affect funding amount find relative amount female founder negative impact funding raised furthermore observe founder characteristic effect funding raised based founder gender moreover find gender bias earlystage funding le prevalent serial founder entrepreneurial experience female founder benefit three time male founder already founded startup overall study suggests gender bias exists worth considered context startup funding keywords gender bias financing startup crunchbase footnote journal journal latex template introduction startup play key role today economy amount investment usbased startup ranging consistently increased last decade rowley determining particularly decisive factor leading successful startup investment therefore great demand besides startup success prediction recent year role gender startup founder considered increasing interest ewens townsend lehto early study gender effect already revealed difference gender greene et al confirmed various study using data u market paper focus gender bias regard earlystage funding startup goal paper answer question whether gender bias exists among investor analyzing amount female founder affect funding amount contrast related work analyzing gender bias mostly u focus european market analyze gender bias across european country best knowledge research analyzed gender bias funding regard one european country across european country approach utilizes linked crunchbase knowledge graph containing structured information crunchbase online platform providing information startup venture capitalist vc related topic since data set available structured format using semantic web standard rdf analysis approach based correlation analysis regression analysis utilize graphbased data model enriched additional information linked open data lod cloud encompassing thousand freely available knowledge repository allows u consider additional variable eg educational level founder study besides commonly used variable startup industry group team size furthermore gender analysis show prevalent effect startup funding characteristic female founder benefit eg higher education serial founder footnote httplinkedcrunchbaseorghttplinkedcrunchbaseorg footnote httpscrunchbasecomhttpscrunchbasecom overall main contribution follows analyze gender bias concerning european startup using correlation regression analysis based large knowledge graph interlinked linked open data cloud discus result gender analysis detail revealing prevalent effect startup funding female founder point view rest paper structured follows first describe data set used analysis section outlining method analyzing gender aspect startup domain section present analysis result section summarize main lesson learned section describing related work section conclude paper section data set linked crunchbase paper use knowledge graph linked crunchbase containing extracted information online data platform crunchbase semanticallystructured way providing information startup vcs related topic data entered crunchbase via crowdsourcing ie everyone contribute information startup along source reference eg link sec filing news article verified crunchbase moderator crunchbase also provide vcs incentive contribute database via crunchbase venture program exchange uptodate data portfolio firm vcs get certain benefit like discounted access database crunchbase inc linked crunchbase contains information organization investment background leading figure worldwide startup economy total knowledge graph contains information organization people funding round composed investment term raw size data set surpasses many data set used previously related work concerning gender study note subset crunchbase previously used gender study raina depicted figure analysis use entity type funding round organization person funding round entity provides funding amount date announcement link funded organization also optionally provides type funding eg seed angel venture organization provides founding date market category official homepage url link founder additionally link headquarters address containing country use analysis determine european startup person entity yield person gender provided link scholar degree achieved degree provide information degree type eg bsc phd mba link organization entity associated school university data sample data used analysis constitutes subset linked crunchbase analyzed sample knowledge graph restricts data regard funding date funding amount location headquarter individual organization majority organization crunchbase never raised funding round thus overall considered organization time period period examined analysis range even though data set cover investment period examined narrowed reducing survivorship bias since crunchbase introduced july data prone biased likely earlystage data unsuccessful company time missing furthermore knowledge represented linked crunchbase crawled crunchbase mid therefore contains data point time funding amount analysis focus seed funding round amount money raised funded organization given figure used entity property linked crunchbase surpasses defined threshold funding round dataset appear incorrect information regarding amount dealt financing sometimes unusually low regular funding round even earlystage seed funding may due human error side crunchbase crawl error creating linked crunchbase knowledge graph therefore consider startup least raised funding round threshold value similar study ewens townsend based crowdsourced data angellist startup platform earlystage financing footnote httpsangelcohttpsangelco geographical region paper focus funded company european country allowing u analyze potential imbalance across country geographical region show section related work analyze u market comparison little research gender bias pursued european market likely due availability u market data set high level detail crunchbase contains information worldwide entrepreneurial activity since people organization world contribute platform besides analysis european market prior usbased startup thus possible examine also region showcasing international scope data set data variable following present data variable used analysis example team size industry group adopted based property crunchbase platform variable top university degree derived property result utilizing another knowledge graph funding type optional variable describes type funding received funded organization seed venture angel funding funding round exactly one funding type value present funding round also multiple funding type given seed angel latter case one data point created given funding type analysis focus seed funding round funding amount variable describes amount money raised funding round money raised sum investment done investor involved funding round industry group general industry group denotes industry group organization operates within analysis include industry group variable categorize data point analysis order account fixed effect might present industry instance biotech startup need raise greater amount funding software startup due high cost laboratory equipment country variable describes country startup headquarter specified crunchbase august hence consider recent address assume startup change country headquartered team size team size variable stand number founder organization associated value used normalize team dependent variable example know share female founder startup take absolute number female founder startup divide size founder team additionally variable used account random fixed effect might depend number founder serial founder share serial entrepreneur organization founding team indicated variable serial founder defined person already founded least one venture previously value defined organizationfounder pair determining whether another organization founded person prior examined organization degree bsc msc phd mba degree variable display many organization founder hold certain degree assume given degree achieved prior organization funding round start end date someone degree often given top university variable describes whether person attended university ranked top worldwide least year recorded time higher education chosen primary data source university ranking see table female variable depicts many organization founder female defined property gender resulting share female founder analysis primarily revolve around value limitation following outline limitation data set effect analysis received funding instead funding amount note data set would need contain successful funding round rejected funding proposal however crunchbase contain information latter know invested certain company decided invest furthermore known many attempt company needed often startup presented business plan potential investor finally received funding overall given data set possible correlate probability receiving funding founder gender variable target funding since funding target provided crunchbase analysis whether female male entrepreneur likely reach target funding would possible however funding target mostly missing data set although company decide publish target prior funding round enough data available statistically significant analysis thus also possible correlate chance hitting funding target founder gender variable
Original Title: Are Investors Biased Against Women? Analyzing How Gender Affects Startup
  Funding in Europe
Original Transcription: # Are Investors Biased Against Women? Analyzing How Gender Affects Startup Funding in Europe

Michael Farber

Karlsruhe Institute of Technology (KIT), Institute AIFB, Karlsruhe, Germany

michael.faerber@kit.edu

Alexander Klein

Karlsruhe Institute of Technology (KIT), Institute AIFB, Karlsruhe, Germany

x.klein.14@gmail.com

###### Abstract

One of the main challenges of startups is to raise capital from investors. For startup founders, it is therefore crucial to know whether investors have a bias against women as startup founders and in which way startups face disadvantages due to gender bias. Existing works on gender studies have mainly analyzed the US market. In this paper, we aim to give a more comprehensive picture of gender bias in early-stage startup funding. We examine European startups listed on Crunchbase using Semantic Web technologies and analyze how the share of female founders in a founding team affects the funding amount. We find that the relative amount of female founders has a negative impact on the funding raised. Furthermore, we observe that founder characteristics have an effect on the funding raised based on the founders' gender. Moreover, we find that gender bias in early-stage funding is less prevalent for serial founders with entrepreneurial experience as female founders benefit three times more than male founders from already having founded a startup. Overall, our study suggests that gender bias exists and is worth to be considered in the context of startup funding.

keywords: gender bias, financing, startups, Crunchbase +
Footnote †: journal: Journal of LaTeX Templates

## 1 Introduction

Startups play a key role in today's economy. The amount of investments in US-based startups ranging between $25m and $100m has consistently increased over the last decade (Rowley, 2019). Determining particularly decisive factors leading to successful startup investments is therefore in great demand. Besides startup success prediction, in recent years, the _role of gender_ of startup founders has been considered with increasing interest (Ewens and Townsend, 2020; Lehto, 2019). Early studies on gender effects have already revealed differences between genders (Greene et al., 2001) and confirmed by various studies using data from the U.S. market. In this paper, we focus on gender bias with regard to early-stage funding startups. The goal of our paper is to answer the question whether gender bias exists among investors by analyzing how the amount of female founders affects the funding amount.

In contrast to related works analyzing gender bias mostly in the US, we focus on the European market and analyze gender bias across European countries. To the best of our knowledge, no other research analyzed gender bias in funding with regard to more than one European country or across all European countries.

Our approach utilizes _Linked Crunchbase_,1 a knowledge graph containing structured information from Crunchbase,2 an online platform providing information about startups, venture capitalists (VC) and related topics. Since our data set is available in a structured format - using semantic web standards such as RDF -, our analysis approach based on correlation analysis and regression analysis can utilize the graph-based data model that is enriched with additional information of the Linked Open Data (LOD) cloud, encompassing thousands of freely available knowledge repositories. This allows us to consider additional variables (e.g., educational level of founders) in our study besides commonly used variables, such as the startups's industry group or team size. Furthermore, our gender analysis shows prevalent effects on startup funding and from which characteristics female founders can benefit (e.g., higher education, serial founder).

Footnote 1: [http://linked-crunchbase.org](http://linked-crunchbase.org)

Footnote 2: [https://crunchbase.com](https://crunchbase.com)

Overall, our main contributions are as follows:

* We analyze gender bias concerning European startups using correlation and regression analysis based on a large knowledge graph that is interlinked with the Linked Open Data cloud.
* We discuss the results of the gender analysis in detail, revealing prevalent effects on startup funding from female founders' point of view.

The rest of our paper is structured as follows: We first describe the data set used for our analysis in Section 2, before outlining our methods for analyzing gender aspects in the startup domain in Section 3. We then present our analysis results in Section 4 and summarize the main lessons learned in Section 5. After describing related work in Section 6, we conclude the paper in Section 7.

## 2 Data Set

### Linked Crunchbase

In this paper, we use the knowledge graph _Linked Crunchbase_ containing extracted information from the online data platform Crunchbase in a semantically-structured way, providing information about startups, VCs and related topics. Data is entered to Crunchbase via crowdsourcing, i.e. everyone can contribute with information about startups, along with source references (e.g., links to SEC filings or news articles), which are verified by Crunchbase moderators. Crunchbase also provide VCs an incentive to contribute to the database via the _Crunchbase Venture Program_. In exchange for up-to-date data on themselves and their portfolio firms, VCs get certain benefits like discounted access to the database (Crunchbase Inc., 2020).

Linked Crunchbase contains information on organizations, investments, and background on leading figures of the worldwide startup economy. In total, the knowledge graph contains information of about 659,000 organizations, 781,000 people, and 222,000 funding rounds composed of 945,000 investments. In terms of raw size, this data set surpasses many other data sets used previously in related work concerning gender studies. Note, that subsets of Crunchbase have previously been used for gender studies (Raina, 2019).

As depicted in Figure 1, for the analysis, we use all entities of type _funding round_, _organization_, and _person_. A funding round entity provides the funding amount, date of announcement, and a link to the funded organization. It also optionally provides the type of funding, e.g. _seed_, _angel_, or _venture_. An organization provides the founding date, (market) categories, the official homepage URL, and links to its founders. Additionally, it links to its headquarters' address containing its country which we use in our analysis to determine European startups. A person entity yields a person's gender and - if provided - links to scholar degrees achieved. These degrees provide information on the degree type (e.g. _B.Sc._, _PhD_, _MBA_) and a link to the organization entity of the associated school or university.

#### 2.1.1 Data Sample

The data used for our analysis constitutes only a subset of Linked Crunchbase. The analyzed sample of the knowledge graph restricts the data with regard to (1) the funding date, (2) the funding amount, and (3) the location of the headquarter of the individual organization. A majority of organizations on Crunchbase never raised a funding round. Thus, overall, we considered 4,854 out of the 658,963 organizations.

**Time period** The period examined for our analysis ranges from 2008 to 2018. Even though the data set covers investments from before the '80s until now, the period examined is narrowed down, reducing _survivorship bias_: Since Crunchbase was introduced in July 2007, data from before can be prone to being biased, as it is likely that (early-stage) data of unsuccessful companies from that time is missing. Furthermore, the knowledge represented in Linked Crunchbase was crawled from Crunchbase in mid-2018 and therefore only contains data up until that point in time.

**Funding amount** In this analysis, we focus on seed funding rounds for which the amount of money raised by the funded organization is given and

Figure 1: Used Entities and Properties of Linked Crunchbase

surpasses a defined threshold. Some funding rounds in the dataset appear to have incorrect information regarding the amount of dealt financing, which are sometimes unusually low for regular funding rounds, even for early-stage seed funding. This may be due to human errors on the side of Crunchbase or crawl errors while creating the Linked Crunchbase knowledge graph. Therefore, we only consider startups with at least $5,000 raised in a funding round. This threshold value is similar to the study of Ewens and Townsend (2020) based on crowdsourced data of _AngelList_,3 a startup platform for early-stage financing.

Footnote 3: [https://angel.co](https://angel.co)

**Geographical Region** In this paper, we focus on funded companies of European countries allowing us to analyze potential imbalances across countries and geographical regions. We show in Section 6 that most related works analyze US markets. In comparison, only little research on gender bias has been pursued for the European market, likely due to the availability of US market data sets with a high level of detail.

Crunchbase contains information on worldwide entrepreneurial activity since people and organizations all over the world contribute to the platform. Besides our analysis of the European market and prior US-based startups, it is thus possible to examine also other regions, showcasing the international scope of the data set.

#### 2.1.2 Data Variables

In the following, we present all data variables used in our analysis. While, for example, _team size_ or _industry group_ are adopted based on properties of the Crunchbase platform, some variables, such as _top university_ or _degree_, are derived from properties or result from utilizing another knowledge graph.

1. **Funding Type** This optional variable describes the type of funding received by the funded organization, such as _seed_, _venture_ or _angel_ funding. While for most funding rounds exactly one funding type value is present, some funding rounds also have multiple funding types given, such as _seed_ and _angel_. In the latter case, one data point is created for each given funding type. In our analysis, we will only focus on _seed_ funding rounds.
2. **Funding Amount** This variable describes the amount of money that was raised in a funding round. The money raised is the sum of all investments done by all investors involved in this funding round.
3. **Industry Group** In general, the industry group denotes in which industry group an organization operates. Within our analysis, we include the industry group variable to categorize data points for further analysis in order to account for fixed effects that might be present in each industry. For instance, Biotech startups need to raise greater amounts of funding than software startups due to high costs of laboratory equipment.
4. **Country** This variable describes the country of a startup's headquarter, as specified on Crunchbase in August 2018. Hence, we consider only the most recent address and assume that startups did not change the country they are headquartered in.
5. **Team Size** The team size variable stands for the number of founders an organization is associated with. This value is used to normalize team dependent variables. For example, to know the share of female founders in a startup we take the absolute number of female founders in a startup and divide it by the size of the founder team. Additionally, this variable is used to account for random or fixed effects that might depend on the number of founders.
6. **Serial Founder** The share of serial entrepreneurs in an organization's founding team is indicated by this variable. A serial founder is defined as a person who has already founded at least one other venture previously. The value is defined for each organization-founder pair by determining whether or not there is another organization founded by the same person prior to the examined organization.
7. **Degree (B.Sc., M.Sc., PhD, MBA)** The degree variable displays how many of an organization's founders hold a certain degree. We assume that all given degrees are achieved prior to any organization's funding rounds as start and end date of someones degree are often not given.
8. **Top University** This variable describes whether a person attended any university ranked as top 100 worldwide at least once over the years recorded. Times Higher Education (THE) was chosen as the primary data source for university rankings (see Table 1).
9. **Female** This variable depicts how many of an organization's founders are female, as defined by the property _gender_, resulting a share of female founders. Our analysis will primarily revolve around this value.

#### 2.1.3 Limitations

In the following, we outline the limitations of the data set and their effects on our analysis:

* received no funding_, instead of the funding amount. Note, that the data set would need to contain both successful funding rounds and rejected funding proposals. However, Crunchbase does not contain information about the latter: We only know who invested in a certain company but not who decided not to invest. Furthermore, it is not known how many attempts a company needed or how often a startup presented its business plan to potential investors until they finally received funding. Overall, given our data set, it is not possible to correlate the probability of receiving any funding at all to the the _founder's gender_ or other variables.
* **Target Funding** Since funding target can be provided on the Crunchbase, an analysis on whether female or male entrepreneurs are more likely to reach their target funding would be possible. However, the funding target is mostly missing in the data set. Although some companies decide to publish targets for their (prior) funding rounds, there is not enough data available for a statistically significant analysis. Thus, it is also not possible to correlate the chance of hitting the funding target to founder gender and other variables.

Tuple 5:
Cleaned Title: software development startup company greenfield startup model
Cleaned Transcription: software development startup company greenfield startup model carmine giardino nicolo paternoster michael unterkalmsteiner tony gorschek pekka abrahamsson c giardino faculty computer science free university bolzanobozen domnitikanerpletz bolzanobozen italyn paternoster unterkalmsteiner gorschk software engineering research lab sweden biklage institute technology campus grissvik karlskrona swedenp abrahamsson department computer information science norwegian university science technology ntnu sem salandsvei trondheim norway abstract software startup newly created company operating history oriented towards producing cuttingedge product however despite increasing importance startup economy scientific study attempt address software engineering issue especially earlystage startup anything startup need engineering practice level better larger company time resource scarce one failed project put business study aim improve understanding software development strategy employed startup performed stateofpractice investigation using grounded theory approach packaged result greenfield startup model gsm explains priority startup release product quickly possible strategy allows startup verify product market fit adjust product trajectory according early collected user feedback need shorten timetomarket speeding development lowprecision engineering activity counterbalanced need restructure product targeting growth resulting implication gsm outline challenge gap pointing opportunity future research develop validate engineering practice startup context introduction software startup launch worldwide every day result increase new market accessible technology venture capital term software startup refer organization focused creation hightech innovative product little operating history aiming aggressively grow business highly scalable market startup usually temporary state maturing working history market domain knowledge lead analysis current working practice thereby decreasing condition extreme uncertainty research presented paper aim understanding practitioner engineer software development strategy startup focus structure planning control software project period idea conception first open beta release performed semistructured indepth interview ceo ctos startup covering wide spectrum theme iteratively adjusted developed model according emerging evidence resulting greenfield startup model gsm capture underlying phenomenon software development earlystage startup new venture facebook linkedin spotify pinterest instagram groupon dropbox name example startup evolved successful business despite many success story vast majority startup fail within two year creation primarily due selfdestruction rather competition operating chaotic rapidly evolving uncertain environment software startup face intense timepressure market exposed relentless competition succeed environment startup need ready adapt product new market demand constrained limited resource engineering perspective software development startup challenging work context difficult software process follow prescriptive methodology even though startup share characteristic similar context eg small web company combination different factor make specific software development context unique therefore research needed investigate support startup engineering activity guide practitioner taking decision avoid choice could easily lead business failure however despite impressive size startup ecosystem research software engineering startup present gap greenfield startup model gsm aim contribute body knowledge startup software engineering created model abstraction reality based systematic procedure grounded empirical data obtained study case gsm present significant theme development strategy characterize startup context provide guideline best practice followed however category gsm relation among provide common direction vocabulary model future research software development startup researcher use gsm starting pointto understand technical debt influence future growth startup company furthermore model provides tool understand context startup operate central developing method model tool technique practice suited type development effort filling gap stateofpractice startup also beneficial startup practitioner apply discussed strategy speed development initially although need also consider likely dropdown performance later stage regard identified several commonality issue related software development startup research focused studying technical debt paper make following contribution empirical investigation driving characteristic earlystage startup rigorously developed model illustrates explains startup perform engineering activity certain manner discussion opportunity future research potential solution challenge faced startup remainder paper structured follows background related work covered section section introduces research question show design execution study result presented section illustrating gsm section discus relevant implication gsm section compare result study stateoftheart literature section discus validity threat paper concludes section background looking number new business incubator appeared last decade one estimate importance startup wave disruption new technology led nonstartup company competitive forcing undertake radical organizational innovational renewal attempt behave like startup however implementation methodology structure control development activity startup still challenge several model introduced drive software development activity startup however without delivering significant benefit software engineering se face complex multifaceted obstacle understanding manage development process startup context bach refers startup bunch energetic committed people without defined development process sutton defines startup creative flexible nature reluctant introduce process bureaucratic measure may result ineffective practice limitation resource lead focus product development instead establishing rigid process attempt tailor lightweight process startup reported failure everyone busy software engineering practice often one first place developer cut corner rejecting notion repeatable controlled process startup prominently take advantage reactive lowprecision engineering practice startup typically develop software service licensed customer rather product sold customized particular client marketdriven software development sometimes called packaged software development cot software development address issue related aspect researcher emphasize importance timetomarket key strategic objective company operating sector furthermore requirement invented software company rarely documented validated product released market hence failed product launch largely due product meeting customer need address issue startup embrace productoriented practice flexible team applying workflow provide ability quickly change direction targeted market therefore many startup focus team productivity granting freedom employee instead providing rigid guideline goal startup namely accelerating timetomarket meeting customer need improved use solid engineering practice customized startup even though specific question focus study presented paper detailed investigation stateofpractice prerequisite future research enabling engineering taking place startup general lack research startup sutton noted general lack study area claiming software startup represent segment mostly neglected process study evidence observation provided coleman oconnor systematic mapping study sm performed identified study software engineering practice focus startup moreover identified study highly fragmented spread across different area rather constituting consistent body knowledge following subsection discus finding sm software development startup carmel introduced term startup se literature studying timetocompletion young package firm noticed company particularly innovative successful advocating research investigate software development practice enabling replication success transferring practice technology sector software startup productoriented first period development phase despite good early achievement software development organizational management increase complexity causing deterioration performance time briefly necessity establishing initial repeatable scalable process postponed forever starting without established workflow startup grow time creating stabilizing process eventually improve sufficiently mature startup little time training activity discussed sutton focus shift prescriptive process team capability hiring people hit ground running empowering team focusing methodological attribute process oriented towards prototyping proofofconcepts mockups demo testing basic functionality priority startup startup growth coordinated quality control longterm planning process become necessary tingling studied extent maturity company affect process adoption report introducing extreme programming xp principle development process challenge arising need trained teammembers fully implement methodology similarly da silva kon able start xp practice place six month coaching team nevertheless even customization practice need implemented adapting process startup context contribution flexibility reactiveness development process exist mean lean agile methodology also reported startup face uncertain condition leading fast learning trial error strong customer relationship avoiding wasting time building unneeded functionality preventing exhaustion resource customer involvement software development also discussed yogendra important factor encourage early alignment business concern technology strategy however question remains extent improved practice eg requirement engineering contribute shortening timetomarket improve target market accuracy initiative optimize practice specific purpose mcphee eberlein introduced practice adapted reducing timetomarket cohen et al looked development performance timetomarket tradeoff none study focus startup per se show current knowledge could useful startup least function starting point performing research solution startup conclusion since decision related product development tradeoff situation startup generally optimize workflow dynamic context involved startup typically adopt development style might work support first need following credo remarked coleman oconnor many manager decide apply know experience tell merely common sense however preclude possibility collect package transfer experience lightweight manner allows flexible adoption good engineering practice contrary startup benefit experienced team member would increase success potential following validated work practice software process improvement startup problem onesizefitsall related spi representation startup described fayad discus problem actuating bestpractices criterion established company person software startup sutton remark problem rigid spi model software startup arise due dynamic nature development process precludes repeatability organizational maturity maintained startup lacking corporate direction severe lack resource human technological process definition implementation management training conclusion primary benefit onesizefitsall spi often hold startup instead promoting product quality aim minimize timetomarket additionally role rigid spi neglected seen obstacle team creativity flexibility need quick product delivery process environment product quality often left aside favor minimal suitable functionality shortening timetomarket mater subramanian mirel report quality aspect mostly taken consideration internet startup oriented towards usability scalability however market application type heavily influence quality demand maintain development activity oriented towards limited suitable functionality study suggest externalizing complexity part project third party solution outsourcing activity software reuse opensource strategy technical debt new stream se research trying tackle problem technical debt brings encompasses various implication studying development software startup metaphoric neologism technical debt originally introduced cunningham recently attracted attention se researcher brown et al provides illustration technical debt concept idea developer sometimes accept compromise system one aspect eg modularity meet urgent demand aspect eg deadline compromise incur debt interest paid principal repaid point longterm health project tom et al identified five dimension technical debt code design architecture environment knowledge distribution documentation testing daily basis startup face tradeoff highspeed highquality engineering architecture design multifaceted aspect weak project management testing process control context earlystage startup illustrate empirical evidence accumulated technical debt subsection discus implication subsection footnote important contribution characterizing debt landscape published dedicated workshop organized software engineering institute icse terminology set common ground prevent ambiguity use following terminology throughout paper software development strategy overall approach adopted company carry product development engineering activity activity needed bring product idea market traditional engineering activity among others requirement engineering design architecture implementation testing engineering element practice tool artifact contributing supporting engineering activity quality attribute overall factor affect runtime behavior system design user experience represent area concern potential application impact across various layer tier attribute related overall system design others specific run time design time user centric issue growth increase company size respect initial condition either employee userscustomers product complexity handling increasing number feature request software product software product andor software service software process improvement framework practice tool support activity leading better software development process research methodology goal study understand software development strategy engineered practitioner startup company particular interested structure planning control software project period idea conception first open beta release software product set boundary research reusing previously conducted systematic mapping study steered also formulation research question rq startup structure execute main engineering activity rq product quality attribute considered startup answer question investigated software development approach undertaken practitioner startup following grounded theory gt methodology executed semistructured interview company integrated followup questionnaire tailored questionnaire startup partially taking advantage repertory grid principle elaborated extracted greenfield startup model gsm explaining underlying phenomenon software development startup following gt principle captured relevant aspect software development startup practitioner letting theory emerge interview adjusting research hypothesis question proceeded interview collected data related engineering activity undertaken startup proceeded analysis data finding important relation among concept formal approach generate validate final theory suggested coleman view different version gt researcher indicate implementation theory used since information obtained sm direct experience startup company provided good initial level knowledge study use corbin strauss approach gt version empowers researcher theoretical sensitivity encourages outline research problem beforehand figure show complete overview study methodology execution illustrating tailored general gt methodology specific need produced data collection analysis package including interview question followup questionnaire code available supplemental material paper result previous sm provide input study design contributing design execution study process depicted figure evolutionary affect design new iteration data collection integrate empirical result case study database subsequently process data analysis form theoretical category iteration emergent theory updated following formal procedure paradigm model generation verifying achieved theoretical saturation category proceeded theory validation footnote point executing interview would bring additional value constructing theory first two author jointly executed whole procedure handling conflict reviewing rationale decision third fourth author necessary performed indepth review study design data collected execution process process detail described following subsection structured according five macro phase depicted figure design execution paper address technical aspect related software development startup exploring operational dynamic lacking agreement unique definition term startup sampled case company according recurrent theme characterized definition startup newly created little operating history lack resource economical human physical limited resource uncertainty little knowledge ecosystem different perspective market product feature competition people finance aiming grow scalable business increasing number user customer company size sampled company two distinct phase first executed initial convenience sampling led identification eight company included five additional startup theory formation process theoretical sampling iteratively improving sample according emerging theory characteristic sampled company reported table company except c founded within last three year average founding member majority developer moreover number current employee show different degree company expanded initial team company except c released first product market within month idea conception product consist pure web web mobile web desktop application launched six different nation united state italy germany sweden united kingdom new zealand growing team size publicly available data suggest generally healthy status business detailed documentation startup sampling distribution found supplemental material paper executed case study online supported tool video conferencing recording session lasted hour average interview subject ceo ctos selecting interviewee required worked company start followed stepbystep workflow consisting actual interview preparation customized followup questionnaire iterative adjustment interview package artifact data collection designed data collection allow triangulation integrates multiple data source interview questionnaire converging phenomenon interview question see table x supplemental material cover aspect development process requirement elicitation quality requirement analysis design implementation testing deployment transcribing interview sent followup questionnaire interviewee designed questionnaire capture additional data gather missing information confirm interview result triangulation note use data followup questionnaire input theory generation table xi supplemental material show prototype questionnaire adapted interviewee company based data collected earlier interview case study database allowed u easily retrieve search information assembling evidence different data source described also yin constructed stored database using qualitative data analysis software package atlast overlapped interview questionnaire result reveal flag potential inconsistency data footnote available online httpwwwatlasticomhttpwwwatlasticom data analysis first two author led coding procedure performed analysis colocated environment ie working together single computer screen starting analysis data ordering procedure necessary interview spread across multitude topic therefore structured transcript thematic area according different topic card used interview proceeded horizontally analyze thematic area within different transcript rather going entire transcript one time data ordered coded interview according following step assigned label raw data carried first lowlevel conceptualization using invivo open coding grouped concept together theoretical category subcategories mean axial coding fig research methodology grounded theory process overview
Original Title: Software Development in Startup Companies: The Greenfield Startup Model
Original Transcription: # Software Development in Startup Companies:

The Greenfield Startup Model

Carmine Giardino, Nicolo Paternoster, Michael Unterkalmsteiner, Tony Gorschek, and Pekka Abrahamsson,

C. Giardino is with the Faculty of Computer Science, Free University of Bolzano/Bozen, Domnitikanerpletz 3, 39100 Bolzano/Bozen, Italy.N. Paternoster, M. Unterkalmsteiner and T. Gorschk are with the Software Engineering Research Lab Sweden, Biklage Institute of Technology, Campus Grissvik, 371 79 Karlskrona, Sweden.P. Abrahamsson is with the Department of Computer and Information Science, Norwegian University of Science and Technology NTNU, Sem Salandsvei 7-9, 7491 Trondheim, Norway.

###### Abstract

Software startups are newly created companies with no operating history and oriented towards producing cutting-edge products. However, despite the increasing importance of startups in the economy, few scientific studies attempt to address software engineering issues, especially for early-stage startups. If anything, startups need engineering practices of the same level or better than those of larger companies, as their time and resources are more scarce, and one failed project can put them out of business. In this study we aim to improve understanding of the software development strategies employed by startups. We performed this state-of-practice investigation using a grounded theory approach. We packaged the results in the Greenfield Startup Model (GSM), which explains the priority of startups to release the product as quickly as possible. This strategy allows startups to verify product and market fit, and to adjust the product trajectory according to early collected user feedback. The need to shorten time-to-market, by speeding up the development through low-precision engineering activities, is counterbalanced by the need to restructure the product before targeting further growth. The resulting implications of the GSM outline challenges and gaps, pointing out opportunities for future research to develop and validate engineering practices in the startup context.

## 1 Introduction

Software startups launch worldwide every day as a result of an increase in new markets, accessible technologies, and venture capital [1]. With the term _software startups_ we refer to those organizations focused on the creation of high-tech and innovative products, with little or no operating history, aiming to aggressively grow their business in highly scalable markets. Being a startup is usually a temporary state, where a maturing working history and market domain knowledge leads to the analysis of current working practices, thereby decreasing conditions of extreme uncertainty [2].

The research presented in this paper aims at understanding how practitioners engineer software development strategies in startups. We focus on the structure, planning, and control of software projects, in the period from idea conception to the first open beta release. We performed semi-structured, in-depth interviews with CEOs and CTOs from 13 startups, covering a wide spectrum of themes and iteratively adjusted the developed model according to the emerging evidence. With the resulting Greenfield Startup Model (GSM), we capture the underlying phenomenon of software development in early-stage startups.

New ventures such as _Facebook_, _Linkedin_, _Spotify_, _Pinterest_, _Instagram_, _Groupon_ and _Dropbox_, to name a few, are examples of startups that evolved into successful businesses. Despite many success stories, the vast majority of startups fail within two years of their creation, primarily due to self-destruction rather than competition [3]. Operating in a chaotic, rapidly evolving and uncertain environment, software startups face intense time-pressure from the market and are exposed to relentless competition [4, 5]. To succeed in this environment startups need to be ready to adapt their product to new market demands while being constrained by very limited resources [6].

From an engineering perspective, software development in startups is challenging as they work in a context where it is difficult for software processes to follow a prescriptive methodology [6, 7]. Even though startups share some characteristics with similar contexts (e.g. small and web companies), the combination of different factors makes the specific software development context unique [8, 6]. Therefore, research is needed to investigate and support the startup engineering activities [7], guide practitioners in taking decisions and avoid choices that could easily lead to business failure [9]. However, despite the impressive size of the startup ecosystem [10], the research on software engineering in startups presents a gap [2].

With the Greenfield Startup Model (GSM) we aim to contribute to the body of knowledge on startup software engineering. We created the model as an abstraction of reality [11], based on a systematic procedure and grounded on empirical data obtained by the study of 13 cases. While the GSM presents the most significant themes in the development strategies that characterize these startups' contexts, it does not provide guidelines or best practices that should be followed. However, the categories in the GSM and the relations among them can provide a common direction, vocabulary, and model for future research on software development in startups.

Researchers can use the GSM as a starting pointto understand how technical debt influences the future growth of startup companies. Furthermore, the model provides a tool to understand the context in which startups operate, which is central when developing methods / models / tools / techniques / practices suited to these types of development efforts. Filling gaps on the state-of-practice in startups is also beneficial for startup practitioners who can apply the discussed strategies to speed up the development initially, although they need also to consider the likely drop-down in performance at a later stage. In this regard, we identified several commonalities between the issues related to software development in startups and the research focused on studying technical debt [12, 13]. This paper makes the following contributions:

* an empirical investigation into the driving characteristics of early-stage startups
* a rigorously developed model that illustrates how and explains why startups perform engineering activities in a certain manner
* a discussion on opportunities for future research and potential solutions for the challenges faced by startups

The remainder of this paper is structured as follows. Background and related work is covered in Section 2. Section 3 introduces the research questions and shows the design and execution of the study. Results are presented in Section 4, illustrating the GSM. Section 5 discusses the most relevant implications of the GSM. Section 6 compares results of the study to state-of-the-art in literature. Section 7 discusses validity threats. The paper concludes in Section 8.

## 2 Background

Looking at the number of new business incubators which appeared in the last decade one can estimate the importance of startups [14]. The wave of disruption in new technologies has led non-startup companies to be more competitive, forcing themselves to undertake radical organizational and innovational renewals, in an attempt to behave more like startups [15]. However, the implementation of methodologies to structure and control development activities in startups is still a challenge [16]. Several models have been introduced to drive software development activities in startups, however without delivering significant benefits [17, 16, 6].

Software engineering (SE) faces complex and multifaceted obstacles in understanding how to manage development processes in the startup context. Bach refers to startups as "a bunch of energetic and committed people without defined development processes" [18]. Sutton defines startups as creative and flexible in nature and reluctant to introduce process or bureaucratic measures, which may result in ineffective practices [6]. The limitation of resources leads to a focus on product development instead of establishing rigid processes [16, 19]. Attempts to tailor lightweight processes to startups reported failures: "Everyone is busy, and software engineering practices are often one of the first places developers cut corners" [20]. Rejecting the notion of repeatable and controlled processes, startups prominently take advantage of reactive and low-precision [21] engineering practices [6, 22, 23, 24].

Startups typically develop software services that are licensed to customers rather than products that are sold and customized to a particular client [25]. Market-driven software development (sometimes called packaged software development or COTS software development [26]) addresses issues related to this aspect. Researchers emphasize the importance of time-to-market as a key strategic objective [27, 28] for companies operating in this sector. Furthermore, requirements are "invented by the software company" [29], "rarely documented" [30], and can be validated only after the product is released to market [31, 32]. Hence, failed product launches are largely due to "products not meeting customer needs" [33]. To address this issue, startups embrace product-oriented practices with flexible teams, applying workflows that provide the ability to quickly change direction to the targeted market [19, 6]. Therefore, many startups focus on team productivity, granting more freedom to the employees instead of providing them with rigid guidelines [22, 23, 24].

Can the goals of startups, namely accelerating time-to-market and meeting customer needs, be improved by the use of solid engineering practices customized for startups? Even though this specific question is not the focus of the study presented in this paper, the detailed investigation of state-of-practice is a prerequisite for future research into enabling the engineering taking place in startups.

### _General lack of research in startups_

Sutton [6] noted in 2000 a general lack of studies in this area, claiming that "software startups represent a segment that has been mostly neglected in process studies". Further evidence for this observation is provided by Coleman and O'Connor [16, 17, 34] in 2008. A Systematic Mapping Study (SMS) [2] performed in 2013 identified only a few studies into software engineering practices with focus on startups. Moreover, the identified studies are highly fragmented and spread across different areas rather than constituting a consistent body of knowledge. The following subsections discuss the findings of the SMS.

### _Software development in startups_

Carmel [35] introduced the term _startup_ to the SE literature in 1994, studying the time-to-completion in a young package firm. He noticed how these companies were particularly innovative and successful, advocating research to investigate their software development practices and enabling replication of their success by transferring their practices to other technology sectors.

Software startups are product-oriented in the first period of their development phase [19]. Despite good early achievements, software development and organizational management increase in complexity [36, 37] causing deterioration of performance over time. Briefly, the necessity of establishing initial repeatable and scalable processes cannot be postponed forever [38]. Starting without any established workflows [9], startups grow over time, creating and stabilizing processes to eventually improve them only when sufficiently mature [3].

As startups have little time for training activities, as discussed by Sutton [6], the focus shifts from prescriptive processes to team capabilities, hiring people who can "hit the ground running" [39]. Empowering the team and focusing on methodological attributes of the processes oriented towards prototyping, proof-of-concepts, mock-ups and demos, testing basic functionalities, have been the priority in startups [35]. With the startups' growth, coordinated quality control and long-term planning processes become necessary [39].

Tingling [40] studied the extent to which maturity of a company affects process adoption. He reports on introducing Extreme Programming (XP) principles [41] in the development process, and the challenges arising from the need of trained team-members to fully implement the methodology. Similarly, da Silva and Kon [42] were only able to start with all the XP practices in place after six months of coaching the team. Nevertheless, even then, customization of practices need to be implemented, adapting the processes to the startups' context [43].

Contributions to flexibility and reactiveness of the development process exist by means of Lean [44] and Agile [45] methodologies (also reported in [46, 47]). Startups face uncertain conditions, leading to a fast learning from trial and error, with a strong customer relationship, and avoiding wasting time in building unneeded functionality and preventing exhaustion of resources [48, 49, 6]. Customer involvement in software development has also been discussed by Yogendra [50] as an important factor to encourage an early alignment of business concerns to technology strategies.

However, the question remains, to what extent can improved practices in e.g. requirements engineering contribute to shortening time-to-market or improve target market accuracy. There have been initiatives to optimize practices for a specific purpose. McPhee and Eberlein [51] introduced practices adapted for reducing time-to-market. Cohen et al. looked at development performance and time-to-market trade-off [52]. None of these studies focus on startups per se, but show that there is current knowledge that could be useful for startups, or at least can function as a starting point for performing research into solutions for startups.

In conclusion, since "all decisions related to product development are trade-off situations" [49], startups generally optimize workflows to the dynamic context they are involved in. Startups typically adopt any development style that might work to support their first needs, following the "Just do it" credo [53]. As remarked by Coleman and O'Connor [16], "many managers just decide to apply what they know, as their experience tells them it is merely common sense". This, however, does not preclude the possibility to collect, package and transfer experience in a lightweight manner, that allows flexible adoption of good engineering practices. On the contrary, startups that cannot benefit from very experienced team members would increase their success potential by following validated work practices.

### _Software process improvement in startups_

The problem of one-size-fits-all, related to some SPI representations for startups, is described by Fayad [54]. He discusses the problem in actuating the same best-practices criteria for established companies in 10-person software startups. Sutton [6] remarks that problems of rigid SPI models in software startups arise due to: the dynamic nature of the development process, which precludes repeatability; organizational maturity, which cannot be maintained by startups lacking corporate direction; severe lack of resources, both human and technological for process definition, implementation, management, and training. In conclusion, the primary benefits of one-size-fits-all SPI often do not hold for startups, which instead of promoting product quality, aim to minimize time-to-market.

Additionally, the role of rigid SPI has been neglected because it is seen as an obstacle to the team's creativity and flexibility, and to the need of a quick product delivery process environment [17]. Product quality is often left aside in favor of minimal and suitable functionalities, shortening time-to-market. Mater and Subramanian [55] and Mirel [56] report that the quality aspects mostly taken in consideration in internet startups are oriented towards usability and scalability. However, market and application type heavily influence the quality demand [16, 57].

To maintain the development activities, oriented towards limited but suitable functionality, studies suggest externalizing the complexity of parts of the project to third party solutions by outsourcing activities [58], software reuse [59] and open-source strategies [60, 61].

### _Technical debt_

A new stream of SE research, trying to tackle the problem of technical debt [62], brings and encompasses various implications in studying development in software startups. The metaphoric neologism of technical debt was originally introduced by Cunningham in 1992 [63] and has recently attracted the attention of SE researchers1. Brown et al. [65] provides an illustration of the technical debt concept: "The idea is that developers sometimes accept compromises in a system in one aspect (e.g., modularity) to meet an urgent demand in some other aspects (e.g., a deadline), and that such compromises incur a "debt" on which "interest" has to be paid and which the "principal" should be repaid at some point for the long-term health of the project". Tom et al. [62] identified five dimensions of technical debt: code, design and architecture, environment, knowledge distribution and documentation, and testing. On a daily basis startups face a trade-off between high-speed and high-quality engineering, not only in architecture design but in multifaceted aspects (weak project management, testing, process control). In the context of early-stage startups, we illustrate empirical evidence on accumulated technical debt in subsection 4.7 and discuss its implications in subsection 5.4.

Footnote 1: Important contributions characterizing the “debt landscape” are [12, 13] published at a dedicated workshop [64] organized by the Software Engineering Institute and ICSE.

### _Terminology_

To set a common ground and to prevent ambiguity, we use the following terminology throughout the paper:

* Software development strategy: the overall approach adopted by the company to carry out product development.

* Engineering activities: the activities needed to bring a product from idea to market. Traditional engineering activities are, among others, requirement engineering, design, architecture, implementation, testing.
* Engineering elements: any practice, tool or artifacts contributing to and supporting the engineering activities.
* Quality attributes: those overall factors that affect runtime behavior, system design, and user experience. They represent areas of concern that have the potential for applications to impact across various layers and tiers. Some of these attributes are related to the overall system design, while others are specific to run time, design time, or user centric issues [66].
* Growth: an increase in company size with respect to the initial conditions for either employees or users/customers, and product complexity for handling an increasing number of feature requests.
* Software product: any software product and/or software service.
* Software process improvement: any framework, practice, or tool that supports activities leading to a better software development process [67].

## 3 Research methodology

The goal of this study is to understand how software development strategies are engineered by practitioners in startup companies. In particular, we are interested in structure, planning and control of software projects, in the period from idea conception to the first open beta release of the software product.

We set the boundaries of the research by reusing a previously conducted systematic mapping study [2], which steered also the formulation of research questions:

RQ-1: How do startups structure and execute their main engineering activities?

RQ-2: How are product quality attributes considered by startups?

To answer these questions, we investigated the software development approach undertaken by practitioners of startups. Following a Grounded Theory (GT) methodology [68], we executed 13 semi-structured interviews (with 13 companies) integrated with follow-up questionnaires. We tailored the questionnaires to each startup, partially taking advantage of the repertory grid principles [69]. From this, we elaborated and extracted the Greenfield Startup Model (GSM) explaining the underlying phenomenon of software development in startups.

Following the GT principles, we captured the most relevant aspects of software development from startup practitioners, letting a theory emerge from the interviews and adjusting the research hypotheses and questions as we proceeded. During these interviews we collected data related to engineering activities undertaken by startups. Then, we proceeded with the analysis of the data, finding important relations among concepts with a formal approach to generate and validate the final theory [68].

As suggested by Coleman, in view of the different versions of GT, researchers should indicate which "implementation" of the theory is being used [34]. Since information obtained from the SMS and our direct experience with startup companies provided a good initial level of knowledge, in this study we use Corbin and Strauss' approach [70]. This GT version empowers the researchers' "theoretical sensitivity" [71], and encourages them to outline the research problem beforehand.

Figure 1 shows a complete overview of the study methodology and execution, illustrating how we tailored the general GT methodology to our specific needs. The produced data collection and analysis packages (including interview questions, follow-up questionnaires and codes) are available in the supplemental material of this paper [72].

The results of our previous SMS provide input to the study design, contributing to the _Design and Execution_ of the study. The process depicted in Figure 1 is evolutionary and affects the design at each new iteration. In _Data Collection_ we integrate the empirical results in a case study database and subsequently process it in _Data Analysis_ to form theoretical categories. At each iteration, the emergent theory is updated following a formal procedure, _Paradigm Model Generation_, and after verifying that we achieved _Theoretical Saturation2_ of categories, we proceeded to _Theory Validation_.

Footnote 2: The point at which executing more interviews would not bring any additional value for constructing the theory.

The first two authors jointly executed the whole procedure, handling conflicts by reviewing the rationale of decisions with the third and fourth authors. When necessary we performed an in-depth review of the study design and data collected during the execution process. The process details are described in the following subsections, structured according to the five macro phases depicted in Figure 1.

### _Design and Execution_

In this paper we address technical aspects related to software development in startups, exploring their operational dynamics. Lacking agreement on a unique definition of the term _startup_, we sampled case companies according to the recurrent themes characterized in the definition of startups [2]:

* newly created: with little or no operating history.
* lack of resources: with economical, human, and physical limited resources.
* uncertainty: with little knowledge of the ecosystem under different perspectives: market, product features, competition, people and finance.
* aiming to grow: with a scalable business in increasing number of users, customers and company's size.

We sampled the companies in two distinct phases. First we executed an initial convenience sampling [73], which led to the identification of eight companies. Then we included five additional startups during the theory formation process (theoretical sampling), iteratively improving the sample according to the emerging theory. The characteristics of the sampled companies are reported in Table I.

All companies, except C10, were founded within the last three years (2009-2012), by an average of 3 founding members, who were in majority developers. Moreover, the number of current employees shows how, to different degrees, companies expanded the initial teams. All companies, except C5, released their first product to the market within 6 months of the idea conception. The products consist of pure web (8), web- and mobile (4), and web- and desktop applications (1), launched in six different nations (United States (4), Italy (4), Germany (2), Sweden (1), United Kingdom (1), New Zealand (1)). The growing team size and publicly available data suggest a generally healthy status of the businesses. A detailed documentation about the startup sampling and their distribution can be found in the supplemental material of this paper [72]. We executed the case studies online, supported by tools for video conferencing, recording each session which lasted 1 hour on average. The interview subjects were CEOs or CTOs. When selecting interviewees, we required that they worked at the company from the start. We followed a step-by-step work-flow, consisting of the actual interview, preparation of the customized follow-up questionnaire and the iterative adjustment of the interview package artifacts.

### _Data collection_

We designed the data collection to allow for triangulation, which integrates multiple data sources (interview, questionnaire) converging on the same phenomenon. The interview questions (see Table X in the supplemental material [72]) cover aspects such as development process, requirements elicitation, quality requirements, analysis, design, implementation, testing and deployment. After transcribing an interview, we sent a follow-up questionnaire to the interviewee. We designed the questionnaire to capture additional data, gather missing information and confirm interview results by triangulation. Note that we did not use the data from the follow-up questionnaire as input for theory generation. Table XI in the supplemental material shows the prototype of the questionnaire that we adapted to each interviewee and company, based on the data collected in the earlier interview.

The case study database allowed us to easily retrieve and search for information, assembling the evidence from different data sources, as described also by Yin [74]. We constructed and stored the database using the qualitative data analysis software package AtlasT3. We overlapped interviews with questionnaire results to reveal and flag potential inconsistencies in the data.

Footnote 3: Available online at [http://www.atlasti.com/](http://www.atlasti.com/).

### _Data analysis_

The first two authors led the coding procedure and performed the analysis in a co-located environment, i.e. working together on a single computer screen. Before starting the analysis, a data ordering procedure was necessary as interviews were spread across a multitude of topics. Therefore, we structured the transcripts into thematic areas according to different topic cards used during the interviews. We proceeded horizontally to analyze the same thematic areas within different transcripts, rather than going through an entire transcript at one time. Once the data was ordered, we coded the interviews according the following steps:

* We assigned labels to raw data, and carried out a first low-level conceptualization using both in-vivo and open coding [75].
* We grouped concepts together into theoretical categories and subcategories. By means of axial coding we

Fig. 1: Research methodology - Grounded Theory process overview

Tuple 6:
Cleaned Title: mvp pivot hypothesisdriven journey two software startup
Cleaned Transcription: mvp pivot hypothesisdriven journey two software startup dron khanna free university bozenbolzano bolzano italy dronkhannaunibzit xiaofengwangunibzit anh nguyenduc university southeast norway bo telemark norway anhnguyenducusnno xiaofeng wang free university bozenbolzano bolzano italy dronkhannaunibzit xiaofengwangunibzit abstract software startup emerged interesting multiper specific research area inspired lean startup startup journey viewed series experiment validate set business h potheses entrepreneurial team make explicitly inexplicitly startup little known startup evolve busi ness hypothesis testing study proposes novel approach look startup evolution minimum viable productmvp creat ing process identified relationship among business hypothesis mvp via ethnography postmortem analysis two software star tup observe relationship hypothesis mvp incomplete nonlinear two startup also find entrepreneur learn testing hypothesis however hypothesis tested mvp vice versa mvp related business hypothesis approach proposed visualizes flow entrepreneurial knowledge across pivot via mvp keywordssoftware startup lean startup entrepreneurial journey minimum viable product pivot introduction software industry witnessed growing trend development soft ware product small team people limited resource little operating history despite global movement hightech entrepreneurship major ity software startup fail within two year creation primarily due selfdestruction rather competition number much higher counting startup team reached launching milestone known common recipe entrepreneur successful difficult frame success failure startup startup unique evolution path depending abundant amount context factor lean startup common methodology among entrepreneur emphasizes role validating business idea via building mvp also common pivot occurs series mvp created startup journey also artefactcreating process given major milestone startup namely pitching event first paid customer fundraising tight certain artefact entrepreneurship research provides grounded foundation startup emergent sequence event event path dependent prior process contingent contemporaneous process useful entrepreneur view entrepreneurial development mvpcreating process perspective important know learn mvp ries mention buildmeasurelearn circle method concept loop explains build stage based hypothesis formulated entrepreneur order test hypothesis experiment configured learning intended testing hypothesis therefore loop could also regarded interpreted traditional scientific hypothesismetricexperiment loop cycle start hypothesis end prototype test hypothesis exercising loop earlier startup realizes hypothesis wrong quicker updated retested however cycle directly imply software entrepreneur actually learn previous experience embedded mvp software startup team excessively focused developing better software solution delivering prototype customer individual exercising many experiment win software development timeline often neglect learning involved software startup objective study understand entrepreneurial learning mvpcreation process assume entrepreneur predetermined business idea formed hypothesis validated building mvp therefore adopting mvp unit analysis research question rq entrepreneur learn formulated hypothesis business product rq corresponding mvp formulated hypothesis study organized follows section present background startup development entrepreneurial artefact section describes study design case description data collection data analysis section present entrepreneurial journey two software startup startupupuccino muml finally section present discussion concludes paper background related work explore research question articulate two theoretical field startup development entrepreneurial artefact illustrated figure ground software engineering startup experiment contributes knowledge software development process technique outcome procedure carry experimentation help startup team better predict understand develop software development process startup development lean startup methodology entrepreneur become increasingly popular past several year evidenced dedicated conference global lean startup meetups result start enter entrepreneurship education program main topic lean startup approach inspired lean concept focusing effort create value customer eliminating waste entrepreneurial process however since customer often unknown customer could perceive value also unknown therefore entrepreneur get building involve customer since day one lean startup advocate build product iteratively deliver market quickly possible earlier feedback lean startup essentially hypothesisdriven approach base entrepreneurial decision evidence validated learning capture customer value entrepreneur start feedback loop turn idea product learning whether pivot persevere done developing mvp using agile method collect customer feedback product feedback becomes input improve product validate hypothesis result startup might pursue new direction business continue scale figure highlevel representation lean startup methodology pivot software startup common occur discussed various scholar according ries kind change done validate startup hypothesis product business model engine growth bajwa et al study refer various different type pivot happen startup zoomin zoomout customer segment customer need platform business architecture value capture engine growth channel technology complete side project startup journey seen process creating entrepreneurial artefact according science artificial one school theory adopted entrepreneurship research artefact defined interface internal team surrounding environment mvp one type artefact created result entrepreneurial process core concept lean startup mvp version new product allows team collect maximum amount knowhow customer figure theoretical aspect mvp figure lean startup process model least effort eric ries listed several type mvp example explainer video landing page wireframe single feature prototype software engineering context nguyen duc et al discussed throwaway prototype evolutionary prototype mvp mvp also considered type boundary object startup context theoretical model startup evolution based buildmeasurelearn approach hypothesis product customer formed validated using mvp loop repeat move forward problemsolution space productmarket space eventually scaling lindgren mu nch present study experiment driven product development startup context author describe product development series linear increment experiment fager holm et al propose framework continuous experiment includes element lean startup type experiment point importance continuous testing order support development process achieve highend product continuous context refers running many iteration buildmeasurelearn feedback loop addition whisking experiment fagerholm et al provides description required artefact task role experimentdriven process facilitates development mvp minimum viable feature mvf support plan implementation analysis experiment holmstr om et al study describes hypothesis experiment datadriven development hypex model help blend experiment customer software development process hypex model aim reducing customer feedback loop hence lead le development pressure software development process similar approach mentioned earlier nguyen et al represents evolution star tup via double loop model sensemaking formed processbased framework realize entrepreneurial process figure research approach section describes research methodology adopted study case given startup dynamic multiinfluenced environment initial plan conduct exploratory case figure hypothetical process artefactdriven startup evolution study research process data dominated participant observation due fact paper author heavily involved startup case motivated u conduct tailor ethnography study ethnography derives traditional anthropology aiming telling credible rigorous authentic story giving voice people local context central focus ethnography provide rich holistic insight people view action well scenario behave collection detailed observation interview attempt adopt ethnography software engineering context type study ethnographic method helpful generating rich detailed account software project team interaction project stakeholder approach delivering product well indepth account experience hence would like adopt approach leverage contact insight case case description case selected convenient sample defined four criterion case selection startup operates least six month experience relevant startup least first running prototype startup least initial customer set first customer payment group user startup software core value business eventually decided study hypothesisdriven journey two startup case case startupupuccino case muml case startup named name developed application star tupupccino based free university bozenbolzano northern part italy startupupuccino started experience observation two team member also university teacher initial idea teacher recommend good software tool initiate support startup miss key skill team eg design web development commonly earlystage startup lack resource look startup tool order launch idea test product solution fit later idea pivoted educational platform aim helping entrepreneurhy educator providing student better learning experience course tool also recommended user level far journey star tupupuccino three pivot startuptoolsclub minetoolz current version running startupupuccino case muml spinoff norwegian social medium company ceo company quit job sought technical team develop hyperlocal news platform started business idea hiring several consultant freelancer contractor realize refine idea cto joined team started prototyping contract vietnamese outsourcing team team selected bidding process en sure lowest price quote contract made based sixmilestone delivery payment made milestone outsourcing team worked sprintbased approach adopting sprint planning retrospective meeting burndown chart communication via social medium nine month collaboration ceo stated positive experience regarding value perceived outsourced team offered part startup data collection semistructured individual interview participant observation used collect data since enable enough focus topic interest also flexible structure discover unforeseen information table show outlook data collection instrument interview guide slightly different two case different people case even interviewee subject however asked three type question warmup question current context interviewee related business product development past experience question investigate interviewee certain project scenario past lesson learnt question capture belief emerged evolved project experience performed observation active participation researcher member startup actively involving business development decision making product development customer interaction counting observation predefined research goal six planned observation session conducted muml ten planned observation session conducted startupupuccino researcher came observed session clear research goal mind sometimes checklist field note done observation case startupupuccino observation action thought captured startup diary data triangulation done looking project artefact project plan meeting note technical document project management board triangulating data source instrument addressed issue validity obtained comprehensive insight application ethnographic method data analysis interview transcript observation diary available analysis adopted narrative analysis going script identifying relevant piece text labelled code representing business product idea description mvp combining extra material came list hypothesis mvp hypothesis either directly stated
Original Title: From MVPs to pivots: a hypothesis-driven journey of two software
  startups
Original Transcription: # From MVPs to pivots: a hypothesis-driven journey of two software startups

Dron Khanna

1Free University of Bozen-Bolzano, Bolzano 39100, Italy, 2dron.khanna@unibz.it,

2xiaofeng.wang@unibz.it

Anh Nguyen-Duc

2University of Southeast Norway,3800 Bo i Telemark, Norway anh.nguyen.duc@usn.no

Xiaofeng Wang

1Free University of Bozen-Bolzano, Bolzano 39100, Italy, 2dron.khanna@unibz.it,

2xiaofeng.wang@unibz.it

###### Abstract

Software startups have emerged as an interesting multiper- specific research area. Inspired by Lean Startup, a startup journey can be viewed as a series of experiments that validate a set of business h- potheses an entrepreneurial team make explicitly or inexplicitly about their startup. It is little known about how startups evolve through busi- ness hypothesis testing. This study proposes a novel approach to look at the startup evolution as a Minimum Viable Product(MVP) creat- ing process. We identified relationships among business hypotheses and MVPs via ethnography and post-mortem analysis in two software star- tups. We observe that the relationship between hypotheses and MVPs is incomplete and non-linear in these two startups. We also find that entrepreneurs do learn from testing their hypotheses. However, there are hypotheses not tested by MVPs and vice versa, MVPs not related to any business hypothesis. The approach we proposed visualizes the flow of entrepreneurial knowledge across pivots via MVPs.

Keywords:Software startup, Lean startup, Entrepreneurial journey, Minimum Viable Product, Pivot 

## 1 Introduction

The software industry has witnessed a growing trend of the development of soft- ware products by small teams of people with limited resource and little operating history. Despite this global movement of high-tech entrepreneurship, the major- ity of software startups fail within two years of their creation, primarily due to self-destruction rather than competition [1]. The number will be much higher when counting startup teams which have not reached the launching milestone. It is known that there is no common recipe for entrepreneurs to be successful. It is difficult to frame successes and failure from startups [2], as each startup will have a unique evolution path depending on an abundant amount of context factors. Lean startup, a common methodology among entrepreneur, emphasizes the role of validating business ideas via building MVPs. It is also common that a pivot occurs after a series of MVPs are created [3, 4]. Such a startup journey is also an artefact-creating process, given that major milestones for startups (namely: pitching events, first paid customer and fund-raising) tight to certain artefacts. Entrepreneurship research provides a grounded foundation that startup is an emergent sequence of events, in which an event is both, path dependent on prior processes and contingent on contemporaneous processes [1, 5While it is useful for an entrepreneur to view entrepreneurial development from an MVP-creating process perspective, it is more important for them to know what they can learn from their MVPs. Ries mentions the Build-Measure-Learn circle in his method [8]. The concept of the loop explains that build stage is based on the hypothesis formulated by an entrepreneur. In order to test the hypothesis, an experiment has to be configured. Learning is intended during the testing of hypothesis [9]. Therefore, this loop could also be regarded interpreted as a traditional scientific hypothesis-metric-experiment loop. The cycle that starts with the hypothesis and ends with a prototype to test the hypothesis. While exercising the loop, the earlier a startup realizes a hypothesis is wrong, the quicker it should be updated and retested [9]. However, the cycle does not directly imply what software entrepreneur actually learn from their previous experience embedded in MVPs. Software startup teams are excessively focused on the developing a better software solution and delivering a prototype to its customer. Individuals exercising so many experiments to win the software development timeline, often neglect the learning involved in software startups [10]. The objective of this study is to understand the entrepreneurial learning from an MVP-creation process. We assume that entrepreneur has predetermined business ideas, which are formed as a hypothesis, that is validated by building MVPs. Therefore, adopting MVP as the unit of analysis, our research questions are RQ1: Do entrepreneur learn from formulated hypotheses for their business and product? RQ2: Are their corresponding MVPs for a formulated hypothesis? The study is organized as follows: Section 2 presents a background about startup development and entrepreneurial artefacts. Section 3 describes our study design, case description, data collection and data analysis. Section 4 presents the entrepreneurial journey of two software startups: Startupupuccino and MUML AS. Finally, Section 5 presents the discussion and concludes the paper.

## 2 Background and Related Work

To explore our research questions, we articulate two theoretical fields: startup development and entrepreneurial artefacts as illustrated in Figure 1. On the grounds of software engineering, a startup doing experiments contributes with knowledge on software development process, techniques and their outcomes. The procedure to carry out experimentation helps the startup team to better predict, understand and develop the software development process [11].

### Startup Development

Lean Startup [8] as a methodology for entrepreneur has become increasingly popular in the past several years, evidenced by dedicated conferences and global Lean Startup meet-ups. As a result, it starts to enter entrepreneurship education programs as the main topic too. The Lean Startup approach was inspired by the lean concepts of focusing on the efforts that create value for customers and eliminating waste during entrepreneurial processes [8]. However, since the customers are often unknown, what customers could perceive as value is also unknown. Therefore, entrepreneurs should get out of the building to involve the customers since day one [12]. Lean Startup advocates to build the product iteratively and deliver to the market as quickly as possible for earlier feedback [8]. Lean Startup is essentially a hypothesis-driven approach [13] which bases entrepreneurial decisions on evidence and validated learning. To capture customer value, an entrepreneur should start a feedback loop that turns an idea into a product, learning whether to pivot or persevere. This can be done by developing an MVP using agile methods to collect customer feedback about the product [8]. The feedback becomes the input to improve the product and validate the hypothesis. As a result, the startup might pursue new directions of the business or continue and scale it [14]. Figure 2 is a high-level representation of the Lean Startup methodology.

Pivots in software startups are common to occur and discussed by various scholars. According to Ries [8], it is a kind of change done to validate the startup hypothesis about a product, business model and the engine of growth. Bajwa et al. in their study refer to various different types of pivots that can happen in startups: Zoom-in, Zoom-out, Customer Segment, Customer need, Platform, Business Architecture, Value Capture, Engine of Growth, Channel, Technology, Complete and Side project [4]. A startup journey can be seen as a process of creating entrepreneurial artefacts [15]. According to the science of artificial, one of the schools of theory adopted in entrepreneurship research [16], an artefact is defined as an interface between the internal team and its surrounding environment. MVP is one type of artefact created as a result of the entrepreneurial process. As a core concept of Lean startup [8], MVP is a version of a new product which allows a team to collect the maximum amount of know-how about customers with

Figure 1: Theoretical aspects of MVP’s

Figure 2: Lean Startup Process Model [14]the least effort [8]. Eric Ries listed several types of MVPs, for example, an explainer video, a landing page, a wire-frame, and a single feature prototype [8]. In Software Engineering context, Nguyen Duc et al. discussed the throw-away prototype and the evolutionary prototype as an MVP [17]. MVP is also considered as a type of boundary object in startup context [3].

### Theoretical Model of Startup Evolution

Based on the Build-Measure-Learn approach, hypothesis about both product and customer should be formed and validated using MVPs [8]. The loop repeats and moves forward, from problem-solution space to product-market space and eventually to scaling. Lindgren and Mu "nch present a study about experiment- driven product development in the startup context. The authors describe the product development as a series of linear increment of experiments [18]. Fager- holm et al. propose a framework for the continuous experiment which includes the elements of the lean startup [19]. This type of experiment points out the importance of continuous testing in order to support the development process to achieve the high-end product. Continuous in this context refers to running many iterations of Build-Measure-Learn feedback loop. In addition to whisking the experiment Fagerholm et al. provides the description of required artefacts, tasks and roles [19, 18]. This experiment-driven process facilitates the development of MVP or minimum viable features (MVF) and supports the plan, implementation and analysis of experiments. Holmstr "om et al. study describes the Hypothesis Experiment Data-Driven Development (HYPEX) model which helps to blend the experiments with the customer in the software development process. The HYPEX model aims at reducing the customer feedback loop. Hence this leads to less development pressure in the software development process. Similar to the approaches mentioned earlier Nguyen et al. represents the evolution of star- tups via double loop model of sense-making [20]. We formed a process-based framework to realize the entrepreneurial process as in Figure 3.

## 3 Research Approach

This section describes the research methodology adopted to study our cases. Given startups are a dynamic and multi-influenced environment, our initial plan was to conduct an exploratory case

Figure 3: Hypothetical process of artefact-driven startup evolution

study. Further, in the research process, our data was dominated by participant observations due to the fact that all of the paper authors were heavily involved in the startup cases. This motivated us to conduct a tailor ethnography study [21]. Ethnography derives from traditional anthropology aiming at telling a credible, rigorous, and authentic story, giving voice to people in their local context [22]. The central focus of ethnography is to provide rich, holistic insights into people's views and actions, as well as the scenario where they behave, through the collection of detailed observations and interviews [23]. There have been some attempts to adopt ethnography in software engineering context [24]. In this type of study, ethnographic methods are helpful in generating rich and detailed accounts of software project teams, their interactions with project stakeholders, and their approaches for delivering products, as well as in-depth accounts of their experiences [24]. Hence, we would like to adopt the approach to leverage all contacts and insights we have from the cases.

### Case Description

A case was selected from our convenient sample. We defined four criteria for our case selection: (1) a startup that operates for at least six months, such that their experience can be relevant, (2) a startup that has at least a first running prototype, (3) a startup that has at least an initial customer set, first customer payments or a group of users, (4) a startup that has software as core value of their business. We eventually decided to study the hypothesis-driven journey of two startup cases: case 1: Startupupuccino and case 2: MUML AS.

**Case 1** The startup is named after the name of the developed application, Star- tupupccino [25], which is based at the Free University of Bozen-Bolzano in the northern part of Italy. Startupupuccino started with the experience and observation of two team members who are also university teachers. The initial idea of the teachers was to recommend good software tools to initiate and support startups that miss key skills in their teams (e.g., design, web development) [26]. Commonly, early-stage startups lack resources and look for some startup tools in order to launch their idea and test the product solution fit. Later, the idea pivoted into an educational platform that aims at helping entrepreneurhy educators in providing students with better learning experience during their courses. Tools were also recommended to users at this level. So far the journey of Star- tupupuccino did three pivots: 1.) startuptools.club, 2.) MineToolz and 3.) current version running as Startupupuccino [25].

**Case 2** MUML AS is a spin-off from a Norwegian social media company. The CEO of the company quit the job and sought for a technical team to develop a hyper-local news platform. She started with the business idea and hiring several consultants, freelancers and contractors to realize and refine the idea. After that, a CTO joined the team and started a prototyping contract with a Vietnamese outsourcing team. The team was selected after a bidding process to en- sure the lowest price quote. The contract was made based on six-milestone delivery and payments were made after each milestone. The outsourcing team worked in a Sprint-based approach adopting Sprint planning and retrospective meetings, burn-down chart and communication via social media. After nine months of collaboration, the CEO stated that it was a positive experience regarding the value perceived. The outsourced team was offered to be a part of the startup.

### Data Collection

Semi-structured individual interviews [27] and participant observation were used to collect data since they enable enough focus on the topic of interest, but also flexible structures to discover unforeseen information. Table 1 shows outlook of the data collection instrument. An interview guide was slightly different between two cases, between different people in the same case and even between the same interviewee subject. However, we asked three types of questions: (1) warm-up question about the current context of the interviewees related to business and product development, (2) past experience question to investigate how the interviewees did in certain project scenarios in the past and (3) lessons learnt questions to capture the beliefs that emerged or evolved from the project experiences. Most of our performed observations are active participation, in which researchers are members of the startups, actively involving in business development, decision making, product development and customer interaction. When counting observations with predefined research goals, there were six planned observation sessions conducted in MUML AS and ten planned observation sessions were conducted in Startupupuccino. The researchers came to observed sessions with a clear research goal in mind, sometimes with a check-list. Field note was done after the observation. In case of Startupupuccino, the observation of actions and thoughts were captured in a startup diary. Data triangulation was done by looking at project's artefacts, such as project plan, meeting notes, technical document and project management board. By triangulating our data sources and our instruments, we addressed issues of validity and obtained comprehensive insights into the application of ethnographic methods.

### Data Analysis

Interview transcripts and observation diary were available for analysis. We adopted a narrative analysis by going through the scripts, identifying the relevant piece of text and labelled them by codes representing: business, product ideas and descriptions of MVP. Combining with extra materials, we came up with a list of hypotheses and MVPs. Hypotheses were either directly stated

Tuple 7:
Cleaned Title: product innovation internal startup large software company case study
Cleaned Transcription: product innovation internal startup large software company case study henry edison xiaofeng wang pekka abrahamsson free university bozenbolzano bolzano italy norwegian university science technology trondheim norway software startup research network httpsoftwarestartupsorghttpsoftwarestartupsorg email henryedison xiaofengwangunibzit pekkaabrahamssonidntnuno author version manuscript accepted publication proceeding th euromicro conference software engineering advanced application seaa copyright owner version accessed httpsdoiorgseaahttpsdoiorgseaa manuscript version made available ccbyncnd license httpcreativecommonsorglicensesbyncndhttpcreativecommonsorglicensesbyncndplease cite henry edison xiaofeng wang pekka abrahamsson product innovation internal startup large software company case study proceeding th euromicro conference software engineering advanced application seaa abstract product innovation risky activity successful enables large software company accreu high profit leapfrog competition internal startup promoted one way foster product innovation large company allows innovate startup however internal startup large company challenging endeavour despite promised benefit large software company leverage internal startup software product innovation fully understood due scarcity relevant study based conceptual framework combine element lean startup approach internal corporate venturing model conducted case study large software company examine new product developed internal startup effort struggled achieve desired outcome set management result conceptual framework developed lean startupenabled new product development model large software company software product innovation internal startup lean startup large software company case study introduction widely accepted product innovation vital company sustain competitive advantage eg product innovation refers creation introduction new technologically new significantly improved product different existing product product innovation company able create new market entry barrier challenge market leader leapfrog competition company able accreu high profit time new product released competition market imitator produce similar product developing product innovation risky activity many company riskaverse engage innovation initiative automated factory people large company trained prescribed specific task reliably hence endeavour change statusquo emerge resistance implementation innovative idea must compete product development activity case software industry little attention given product innovativeness study corporate entrepreneurship suggest internal startup ideal environment nurture innovation entrepreneurship large company although internal startup still operating within corporation way working different respect traditional research development rd system internal startup take responsibility end end finding business idea developing new product introducing market therefore internal startup also seen learning process create new competence different main business competence make difference among company yielding output even though increasing number software company adopted internal startup purpose product innovation practicing startup initiative within large company challenging endeavour study investigated large software company utilise internal startup improve competence capability product innovation based observation research question investigated study large company leverage internal startup software product innovation answer research question conceptual framework based lean startup approach internal corporate venture model constructed framework enables systematic analysis case study conducted large software company better understand key process new product development internal startup large software company remainder paper structured follows related work described section section present conceptual framework used study section introduces case studied describes research approach followed section present result discussed section section concludes paper summary major finding outline future work related work software product innovation like modern dynamic business software industry highly influenced knowledge intensive technology driven nature continual reliance old existing technology jeopardise market position company hence company must seek innovation disrupts former key player creates new business market innovation iterative process start identification new market need lead development solution fit need software product innovation concerned introducing new software product existing new market software industry product innovation occurs either software hardware development raise strategic challenge software company new company emerge innovative solution established company manage respond survive eg google samsung mobile device service domain others lose business eg nokia another example open source software os os many startup able enter market become threat market leader eg linux microsoft window mozilla microsoft internet explorer etc context innovation large software company misra et al develop goaldriven measurement framework measure innovation activity company framework adopted goalquestionmetric gqm approach define goal innovation program metric measure achievement although provided set metric measuring innovation study present clear methodology defined goal question metric explain clearly relationship suggested metric innovation addition still unclear innovation activity constitute study gorschek et al proposes model early stage innovation emphasis ideation selection prior actual development however understanding endtoend development ideation commercialisation yet fully achieved internal startup literature corporate entrepreneurship show generate revenue stream value shareholder large company engaged either internal startup internal corporate venture external startup external corporate venture external startup usually includes joint venturing eg sony ericsson acquisition eg acquisition skype microsoft whatasapp facebook corporate venture capital eg google venture intel capital contrary case internal startup innovation generated separate dedicated entity operated within established company using resource solely control company different model developed explain actual process internal startup company burgelman identifies four major process process model internal startup definition impetus strategic context structural context also three role involved process corporate management new venture division nvd management venture lead intrapreneur definition process occurs rd department responsible generate idea new business new idea combine available technology market need line current corporate strategy process nvd play important role coach intrapreneurs developing new business move definition impetus process product champion required mobilise resource needed impetus process refers entrepreneurial organisational stage development involves two stage strategic forcing strategic building strategic forcing intrapreneurs focusing commercialisation new product continuation impetus process strategic building process take place strategic building activity intrapreneurs able overcome limitation oneproduct maintain growth rate required management establish sustainability new business must get support strategically since startup effort may emerge bottom corporate management applies selecting mechanism ensure one show potential fast growth opportunity survive therefore strategy context intrapreneurs attempt convince corporate management new business area part current corporate strategy even current strategy accommodate must convince extend strategy protect initiative therefore organisational champion play important role communicate management new business area study garud van de ven develops model based trialanderror learning overcome uncertainty ambiguity internal startup process embarking next activity intrapreneur evaluates outcome prior activity outcome positive intrapreneur proceeds next activity otherwise change plan needed champion corporation needed series negative outcome occur major environmental change happen plan reviewed seek alternative activity thus champion serf mentor guide change plan recent internal startup model introduced breuer argues five activity specifying business model new venture exploration elaboration evaluation experimentation evolution however framework assumes intrapreneurs already identified value delivered customer reality customer value intrapreneurs must seek validate first summary current internal startup process model focus resourcebased view company model burgelman acknowledges idea new business combination technology market need however model give clue achieve problemsolution fit also recognise learning process developing new product model taking account learning process create knowledge able describe dynamic creating new business fail explain interaction internal startup parent company conceptual framework guide study process answer research question drew upon lean startup approach suggested hypothesisdriven approach aim achieving problemsolution fit first productmarket fit capture customer value entrepreneur start feedback loop turn idea product learn whether business hypothesis valid done developing minimum viable product mvp using agile method collecting customer feedback product feedback becomes input validate hypothesis improve product result startup might pursue new direction business called pivot lean startup term continue scale proven business model pivot common startup since could prevent startup bankruptcy time pivot minimised even though originally conceived standalone startup lean startup approach claimed useful large corporate setting well guide empirical study constructed conceptual framework bringing together element burgelmans internal startup process model lean startup approach table show major process related activity framework innovation initiative either top top management driven bottom employee driven research approach present study aim developing good understanding large software company leverage internal startup software product innovation due complex nature research phenomenon intention achieve indepth understanding single case study considered suitable research approach criterion select case company company develops software inhouse company least one dedicated team responsible ideation commercialisation new software area new software product fall current main product line unit analysis study development team new software case company context company study fsecure large finnish cyber security privacy company fsecure established currently fsecure employee country around globe product available resellers operator country ten million user world using product fsecure generates revenue million earnings interest tax ebit million year fsecure long experience various internal innovation eg ground innovation free time hackathons fsecure running growth strategy exercise explore new opportunity area people protection internal startup team established find concrete idea new software product around people protection called lokki concept design pitched corporate management december lokki released july publicly timeline product development shown fig summer corporate management decided change company strategy lokki longer within scope strategy fsecure decided continue development open source project collaborating leading university europe u facebook based criterion described previously fsecure suitable case study data collection analysis conceptual framework presented table serf theoretical lens investigation case acting sensitising sensemaking device guide data collection analysis process used frame interview question enabled holistic understanding dynamic internal startup entity inside company result framework instantiated modified extended better explain empirical observation semistructured interview used primary data collection method better understand phenomenon eight employee different role fsecure interviewed see table ii interview lasted approximately minute interview transcribed verbatim field note taken interview supporting material internal corporate document presentation white paper etc also collected help achieve comprehensive understanding case data analysis process conducted iteratively encouraged grounded theory methodology interview data coded line line priori code focused analysis around innovation activity impact internal startup team company document obtained interviewee field note also included coding step allowed u triangulate interview data axial coding sorted coded material key process described framework actor performed activity identified factor linked two process initial code used analysis coding phase derived conceptual framework shown table finding shown timeline team two iteration development process first iteration started product concept design september conducted focus group focus group learned customer wanted lokki thus team switched lokki went back concept design march went another iteration product development following subsection finding study presented detail structured according conceptual framework shown table vision steer accelerate vision one senior employee later became team lead assigned prepare concept creation within people protection area build internal startup team team lead wanted competence team eg developer user experience designer marketing tester etc therefore onetoone interview recruit team member internally actually took month find member entrepreneurial mindset easy build entrepreneurial team existing pool employee wanted hear nothing gon na happen gon na great year problem tell mean dont know whats gon na happening senior manager internal startup team dedicated project team member still got monthly salary team least dependency corporate possible shorten development cycle reduce timetomarket different rd unit since internal startup operates scope defined startup controlled focus innovation business case approved running towards target business case approval making experiment maybe even pivot cio
Original Title: Product Innovation through Internal Startup in Large Software Companies:
  a Case Study
Original Transcription: # Product Innovation through Internal Startup in Large Software Companies: a Case Study

Henry Edison12, Xiaofeng Wang13 and Pekka Abrahamsson23

1Free University of Bozen-Bolzano, Bolzano, 39100, Italy
2Norwegian University of Science Technology, Trondheim, NO-7491, Norway
3Software Startups Research Network, [http://softwarestartups.org](http://softwarestartups.org)

Email: (henry.edison, xiaofeng.wang)@unibz.it, pekka.abrahamsson@id.ntnu.no

This is the authors version of the manuscript accepted for publication in the Proceedings of 42th Euromicro Conference on Software Engineering and Advanced Application (SEAA), 2016. Copyright owner's version can be accessed at [https://doi.org/10.1109/SEAA.2016.36](https://doi.org/10.1109/SEAA.2016.36). This manuscript version is made available under the CC-BY-NC-ND 4.0 license. [http://creativecommons.org/licenses/by-nc-nd/4.0](http://creativecommons.org/licenses/by-nc-nd/4.0)"Please cite as: Henry Edison, Xiaofeng Wang, and Pekka Abrahamsson (2016). Product Innovation through Internal Startup in Large Software Companies: a Case Study. Proceedings of 42th Euromicro Conference on Software Engineering and Advanced Application (SEAA), 2016, 128-135.

###### Abstract

Product innovation is a risky activity, but when successful, it enables large software companies accreu high profits and leapfrog the competition. Internal startups have been promoted as one way to foster product innovation in large companies, which allows them to innovate as startups do. However, internal startups in large companies are challenging endeavours despite of the promised benefits. How large software companies can leverage internal startups in software product innovation is not fully understood due to the scarcity of the relevant studies. Based on a conceptual framework that combines the elements from the Lean startup approach and an internal corporate venturing model, we conducted a case study of a large software company to examine how a new product was developed through the internal startup effort and struggled to achieve the desired outcomes set by the management. As a result, the conceptual framework was further developed into a Lean startup-enabled new product development model for large software companies.

 software product innovation, internal startup, Lean startup, large software companies, case study

## 1 Introduction

It is widely accepted that product innovation is vital to companies to sustain their competitive advantages (e.g. [1, 2, 3]). Product innovation refers to the creation and introduction of new (technologically new or significantly improved) products which are different from existing products [4, 5, 6]. Through product innovation, companies are able to create new market and entry barriers, challenge market leaders and leapfrog competition [7]. Companies are able to accreu high profit because at the time a new product is released, there is no competition in the market until imitators produce similar products [8].

Developing product innovation is a risky activity [9, 10]. Many companies are too risk-averse to engage in any innovation initiatives [11]. As in automated factories, people in large companies are trained to do prescribed and specific tasks reliably. Hence, any endeavour to change the status-quo will emerge resistance. The implementation of an innovative idea must compete with other product development activities [12, 13]. This is the case for software industry, too. Little attention is given to product innovativeness [14].

The studies on corporate entrepreneurship suggest that internal startup is an ideal environment to nurture innovation and entrepreneurship in large companies [15]. Although the internal startup is still operating within the corporation, the way of working is different with respect to the traditional research and development (R&D) system. An internal startup takes the responsibility from end to end; from finding a business idea to developing a new product and introducing it to market [16]. Therefore, internal startup is also seen as a learning process to create new competence different from the main business. Competence makes a difference among companies in yielding the outputs.

Even though an increasing number of software companies have adopted internal startup for the purpose of product innovation [17], practicing startup initiative within large companies can be a challenging endeavour [18]. Very few studies have investigated how large software companies can utilise internal startup to improve their competence and capability of product innovation. Based on this observation, the research question investigated in this study is: _"How do large companies leverage internal startup in software product innovation?_

To answer the research question, a conceptual framework based on the Lean startup approach [19] and an internal corporate venture model [20] is constructed. The framework enables a systematic analysis of a case study conducted in a large software company, to better understand the key processes of new product development through an internal startup in large software companies.

The remainder of this paper is structured as follows. The related work is described in Section 2. Section 3 presents the conceptual framework used in this study. Section 4 introduces the case studied and describes the research approach followed. Section 5 presents the results, which are further discussed in Section 6. Section 7 concludes the paper with the summary of the major findings and an outline of future work.

## 2 Related work

### _Software product innovation_

Like any modern dynamic business, software industry is highly influenced by its knowledge intensive and technology driven nature [21]. Continual reliance on old or existing technology will jeopardise the market position of a company [22]. Hence, companies must seek innovation as it disrupts former key players and creates new business or markets. Innovation is an iterative process that starts with identification of new market needs, which leads to the development of a solution that fits to that needs [23, 24].

Software product innovation is concerned with introducing new software product to an existing or new market [25]. In software industry, product innovation occurs in either software or hardware development, or both, which raises strategic challenges for software companies [26]. New companies emerge with innovative solutions. Some established companies manage to respond and survive, e.g., Google and Samsung in the mobile device and service domain, but others lose their business e.g. Nokia. Another example is open source software (OSS) [27]. Through OSS, many startups are able to enter a market and become a threat to the market leaders e.g. Linux against Microsoft Windows, Mozilla against Microsoft Internet Explorer, etc.

In the context of innovation in large software companies, Misra et al. [28] develop a goal-driven measurement framework to measure innovation activities in companies. The framework adopted the Goal-Question-Metric (GQM) approach to define the goals of innovation program and the metrics to measure their achievement. Although they provided a set of metrics for measuring innovation, the study did not present a clear methodology on how they defined the goal, questions and metrics. Nor did it explain clearly the relationship between the suggested metrics and innovation. In addition, it is still unclear what innovation activities constitute. A study of Gorschek et al. [29] proposes a model for an early stage innovation, which emphasises on ideation and selection prior to actual development. However, the understanding of the end-to-end development from ideation to commercialisation is yet to be fully achieved.

### _Internal startup_

The literature of corporate entrepreneurship shows that to generate revenue streams and values for shareholders, large companies are engaged in either internal startup (or internal corporate venture [30]) or external startup (or external corporate venture) [31], or both. external startup usually includes joint venturing (e.g. Sony Ericsson), acquisition (e.g. the acquisition of Skype by Microsoft or Whatasapp by Facebook) and corporate venture capital (e.g. Google Venture, Intel Capital). On the contrary, in the case of internal startup, innovation is generated through a separate and dedicated entity which is operated within an established company and using resources that are solely under the control of the company [31, 32].

Different models have been developed to explain the actual process of internal startup in companies. Burgelman [20] identifies four major processes in a process model of internal startup: definition, impetus, strategic context and structural context. There are also three roles involved in the processes: corporate management, new venture division (NVD) management and venture lead (or intrapreneur). The definition process occurs in the R&D department which is responsible to generate ideas for new business. The new idea combines the available technology and the market needs which should not be in line with the current corporate strategy. In this process, NVD plays an important role to coach the intrapreneurs in developing new business. To move from definition to impetus process, a product champion is required to mobilise resources needed. The impetus process refers to the entrepreneurial and organisational stages of development. It involves two stages: strategic forcing and strategic building. In strategic forcing, intrapreneurs are focusing on commercialisation of the new product. For the continuation of the impetus process, strategic building process takes place. Through strategic building activities, intrapreneurs are able to overcome the limitations of one-product and maintain growth rate, as required by the management. To establish its sustainability, the new business must get support strategically. Since any startup efforts may emerge from the bottom, corporate management applies selecting mechanism to ensure that only the ones that show the potential for fast growth have more opportunities to survive. Therefore, in the strategy context, intrapreneurs attempt to convince corporate management that the new business area can be part of current corporate strategy. Even when the current strategy cannot accommodate it, they must convince them to extend the strategy to protect the initiative. Therefore, an organisational champion plays an important role to communicate with the management about the new business area.

The study by Garud and Van de Ven [33] develops a model based on trial-and-error learning to overcome the uncertainty and ambiguity of the internal startup process. Before embarking on next activities, an intrapreneur evaluates the outcomes of prior activities. If the outcome is positive, the intrapreneur proceeds to the next activities, otherwise a change to plan is needed. A champion from corporation is needed when a series of negative outcomes occur or major environmental changes happen. The plan is reviewed to seek for alternative activities. Thus, the champion serves as a mentor to guide the changes in the plan.

A recent internal startup model was introduced by Breuer [18]. She argues that there are five activities in specifying business model for a new venture: exploration, elaboration, evaluation, experimentation and evolution. However, the framework assumes that intrapreneurs already have identified the values that will be delivered to the customers. In reality, it is the customer values that intrapreneurs must seek and validate first [34].

In summary, the current internal startup process models focus more on the resource-based view of the company. The model from Burgelman [20] acknowledges that the idea of new business is the combination of technology and market needs. However, the model does not give any clue how this can achieve the problem/solution fit. Also it does not recognise the learning process in developing a new product. Both models from [33] and [18] are taking into account the learning process to create knowledge. They are able to describe the dynamics of creating new business but fail to explain the interaction between the internal startup and the parent company.

## 3 Conceptual Framework

To guide the study process to answer our research question, we drew upon the Lean startup approach, which has been suggested by [19]. It is a hypothesis-driven approach [35] which aims at achieving the problem/solution fit first and then the product/market fit. To capture customer value, an entrepreneur start a feedback loop that turns an idea into a product then learn whether the business hypotheses are valid or not. This can be done by developing a minimum viable product (MVP) using an agile method and collecting customer feedback on the product. The feedback becomes the input to validate the hypotheses and improve the product. As the result, the startup might pursue a new direction of the business, called pivot in the Lean startup term, or continue and scale the proven business model. Pivot is common to any startup, since it could prevent the startup from bankruptcy if time between pivots is minimised. Even though originally conceived for standalone startups, the Lean startup approach was claimed to be useful in large corporate settings as well [19].

To guide the empirical study, we constructed a conceptual framework by bringing together the elements from Burgelman's internal startup process model [20] and the Lean startup approach [35]. Table I shows the major processes and their related activities. In this framework, the innovation initiative can be either top down (top management driven) or bottom up (employee driven).

## 4 Research Approach

The present study aims at developing a good understanding on how large software companies leverage internal startup in their software product innovation. Due to the complex nature of the research phenomenon and the intention to achieve an in-depth understanding of it, a single case study [36] is considered a suitable research approach. The criteria to select a case company are: (1) the company develops software in-house, (2) the company has at least one dedicated team that is responsible from the ideation to commercialisation of a new software; and (3) the area of the new software product falls out of the current main product line. The unit of analysis in this study is a development team of new software.

### _Case company and context_

The company under study is F-Secure, a large Finnish cyber security and privacy company. F-Secure was established in 1998. Currently, F-Secure has more than 900 employees in 25 countries around the globe. Its products are available from over 6000 resellers and 200 operators in more than 40 countries. Tens of millions of users all over the world are using its products. In 2014, F-Secure generates revenue of 137 million and earnings before interest and taxes (EBIT) of 23.3 million.

Over the years, F-Secure has a long experience in various internal innovation e.g. ground up innovation, 10% free time, hackathons. In 2012, F-Secure was running a growth strategy exercise to explore a new opportunity area, which was people protection. An internal startup team was established to find a concrete idea for new software product around people protection, called Lokki. A concept design was pitched to corporate management in December 2012. Lokki was released in July 2013 publicly. The timeline of the product development is shown in Fig. 1. In Summer 2013, the corporate management decided to change the company's strategy. Lokki was no longer within the scope of the strategy. F-Secure decided to continue the development as an open source project, collaborating with leading universities in Europe and US and Facebook.. Based on the criteria described previously, F-Secure is a suitable case for this study.

### _Data collection and analysis_

The conceptual framework presented in Table I serves as the theoretical lens for the investigation of the case, acting as a sensitising and sense-making device that guides the data collection and analysis processes. It was used to frame the interview questions, and enabled a holistic understanding of the dynamics between the internal startup and other entities inside the company. As a result, the framework was instantiated, modified or extended to better explain the empirical observations.

Semi-structured interviews were used as the primary data collection method [37]. To better understand the phenomenon, eight employees with different roles in F-Secure were interviewed (see Table II). Each interview lasted approximately 45-60 minutes. All interviews were transcribed verbatim. Field notes were taken during the interviews. Other supporting materials, such as internal corporate documents, presentations, white papers, etc., were also collected, to help achieve a more comprehensive understanding of the case.

The data analysis process was conducted iteratively as encouraged by the grounded theory methodology [38]. The interview data was coded line by line with the priori codes [39], which focused the analysis around the innovation activities and their impacts on the internal startup team and the company. The documents obtained from the interviewees and field notes were also included in the coding steps, which allowed us to triangulate the interview data. During the axial coding, we sorted the coded materials into key processes as described by the framework, the actors who performed the activities and identified the factors that linked between two processes. The initial codes used during the analysis and coding phase were derived from the conceptual framework as shown in Table I.

## 5 Findings

As shown in the timeline, the team did two iterations in their development process. The first iteration started with the product concept design in September 2012 until they conducted the focus group. After the focus group they learned that the customers wanted Lokki. Thus, the team switched to Lokki and went back to concept design in March 2013, and went through another iteration of product development. In the following sub-sections the findings of this study were presented in detail, structured according to the conceptual framework (as shown in Table I): Vision, Steer and Accelerate.

### _Vision_

One senior employee (who later became the team lead) was assigned to prepare the concept creation within the people protection area, and to build the internal startup team. The team lead wanted to have all the competences in the team, e.g. developers, user experience designers, marketing, tester, etc. Therefore, he did one-to-one interviews to recruit the team members internally. It actually took 2 months to find the members with entrepreneurial mindset. It was not easy to build an entrepreneurial team from the existing pool of employees, because:

_"They all wanted to hear that nothing is gonna happen and we're gonna be great for years. The problem is 1 cannot tell that. I mean, I don't know what's gonna happening."_ [Senior Manager]

The internal startup team were dedicated to this project only. All the team members still got their monthly salary. The team had as least dependencies to the corporate as possible to shorten development cycle and reduce time-to-market. It is different from a R&D unit since the internal startup operates only in the scope defined for them:

_"[The startup is] controlled, because the focus is innovation.... the business case is approved, and they are running towards the target under that business case approval and making experiments, maybe even pivot."_ [CIO]

Tuple 8:
Cleaned Title: emerging sectoral diversity startup ecosystem
Cleaned Transcription: emerging sectoral diversity startup ecosystem clement gastaud theophile carniel jeanmichel dalle agoranov paris france sorbonne universite paris france icnrs ecole polytechnique france jeanmicheldallesorbonneuniversitefr abstract thanks recent availability comprehensive detailed online database startup company become possible directly investigate startup ecosystem ie startup population specific region paper analyze emergence ecosystem europe usa specific focus sectoral diversity analyzing sectoral landscape ecosystem using new visualization tool indeed highlight marked difference term diversity characterize using metric derived ecological science numerical simulation suggest emerging diversity startup ecosystem explained using simple preferential attachment model based sectoral funding introduction startup population recently come commonly referred startup ecosystem analogy ecological system metaphor emerged economics management science early different source order study creation growth death organization competition industrial actor else emergence new technology niche recently startup ecosystem become central local national international innovation policy innovative startup drawing increasing investment venture capitalist increased attention stakeholder notably potential create job indeed following leading example san francisco silicon valley austin boston los angeles new york u berlin london paris europe thrived become active entrepreneurial ecosystem competing one another order attract startup context data model would allow entrepreneur investor policy maker analyze characterize compare emergence dynamic different startup ecosystem however still mostly missing even professional website started gather relevant information global lack understanding concerning fundamental mechanism driving development entrepreneurial ecosystem startup landscape provide representation startup specific sector split subsectors global fintech landscape edited atherton research startup associated specific technology geographical zone france ai landscape existing landscape mostly instantaneous snapshot lack completeness put differently exist far know quantitative model tool would significantly help actor make appropriate sense dynamic startup ecosystem fact somewhat surprising since entrepreneur become major topic public policy decision making article argue recent availability comprehensive public startup database represents opportunity formulation validation theoretical model related dynamic startup ecosystem building upon automated startup landscape generator allows visualization entrepreneurial ecosystem incorporating relevant metadata eg textual description sector activity fund raised first suggest extend ecological analogy characterize ecosystem using diversity metric try relate observed difference among ecosystem macroeconomic indicator presenting calibrating numerical simulation explains diversification startup ecosystem preferential attachment model based funding received within sector material method dataset exploit dataset startup crunchbase mainstream source data academic research respect notably u startup european ecosystem dataset supplemented dealroom increased number considered company startup retrieved date creation location sectoral tag describing economic sector technology andor market textual description notably information respect fund startup raised including date raised amount funding nature funding round identity investor well article mentioning company available crunchbase figure addition retrieved information available people crunchbase giving u particular proxy regard experience startup founder nature funding round mean different stage venture capital funding startup company go respect first round funding generally called seed corresponds money used validate product startup market phase round labeled letter b c etc round designed ensure scalability company later round b latter one tend accompany growth company national international market limited sample company created january st company mentioned least one round funding overall dataset consists company investment round people news article startup computed two additional metric first total amount fund raised second speed fund raised proxy pace growth denote momentum define time dollar per month mtsumiintextinvestmentsfractextmoneyraisedittimesexp textdayssinceinvestmentittext daystext month tag construction sectoral tree order visualize ecosystem organized startup according main economic sector used crunchbases basic tag structure starting point create startup sectoral tree tag structure organized two level first industry health care software specific level health insurance image recognition construction resulting ontology cleaned removing tag specially broad distinctive software infrastructure etc unrelated economic sector bb freemium etc rare eg port harbor associated startup worldwide dataset furthermore tag semantically close eg shipping delivery video game gaming merged whenever two tag inclusion relation taken account initial ontology eg insurance health insurance relation used create new sublevel tree financial service rightarrow insurance rightarrow health insurance noted case visualization classification prompted manual edit sectoral tag found either imprecise eg startup general tag software numerous eg startup tagged industry could possibly make use technology simply factually erroneous following procedure final sectoral tree composed sectoral tag level composed industry ie independent sector directly connected root tree part data analytics branch shown example fig footnote full description sectoral tree available upon request author figure data recovered crunchbase populating sectoral tree startup sectoral tree used populate startup tree considering startup end leaf since startup several sectoral tag implemented heuristic procedure prune tree ie keep relevant tag startup following strategy similar determine startup main industry tag classifying description tag compute probability startup best described startup tag choose probable tag overall several tag included others first remove shallowest one sectoral tree corresponds definition least precise sectoral assignment choose probable tag remaining one end simplest least ambiguous possible sectoral tree obtained startup associated end leaf interactive visualization tool startup ecosystem order visualize ecosystem made use treemaps foamtree package allows display hierarchical data nested polygon tiling plane cell surface proportional specific dimension data general tessellation treemap representation example visualization presented appendix cell map corresponds startup surface representing amount funding received startup color momentum defined eq visualization typically confirms widely acknowledged characteristic ecosystem instance london appears specialized fintech investment paris appears particularly strong respect health care furthermore ecosystem easily visualized interactive interface several filter applied map using data available startup tag location investor etc thanks timestamps event ecosystem also visualized given date order study ecosystem investment dynamic figure part data analytics industry subtree sectoral tree introducing diversity metric startup ecosystem better characterize startup ecosystem introduce diversity metric similar traditional ecological ecosystem ecological ecosystem diversity average positively correlated stability change diverse environment example disease arrival predator target specie impact whole ecosystem reduced functional redundancy economics relationship diversity unemployment stability widely studied notably proposed ecology diversity positively correlated stability resilience economy rapid change although empirical analysis using regional data always confirm hypothesis similarly disruption sector might le affect entire startup ecosystem depending diversity across industry sector least three major diversity index defined used ecology simpson index shannonweiner index hill index shannonweiner simpson index corresponding diversity derived hill number order q q respectively context study implemented shannonweiner index measure diversity ecosystem within previously defined sectoral ontology herfindahlsimpson index measure concentration investment startup regardless sector industry simpson herfindahl index ecology study usually present simpson index defined lambdasuminpi tag traditionally ecology n total number specie pi relative abundance specie present case n would total number tag pi ratio funding invested sector total funding ecosystem simpson index measure probability two individual randomly chosen population belong specie extreme case lambdafracn lambda correspond respectively maximal minimal diversity order straight forward interpretation inverse simpson index lambda often used corresponds effective number specie true diversityd defined give quick intuition concept number convert computed diversity index studied ecosystem corresponding ecosystem specie equally abundant resulting number different specie corresponds effective number specie unbalanced ecosystem specie different value pi would converted ecosystem nleq specie pifracn iinn index also used economics called herfindahl index usually used study importance company given market defined follows hsuminsi tag si market share company however index take sectoral tree structure account focus solely repartition fund actor shannonweiner index shannonweiner index shannon entropy originating information theory statistical physic defined follows ssuminpilogbpi tag ecology literature base e logarithm usually used convention used following shannon entropy quantifies uncertainty associated prediction element considered dataset context ecology quantifies uncertainty predicting specie individual taken random dataset belongs however form additional information given tree structure data still taken account hierarchical structure need taken consideration analysis apt measure entropy stau tree tau thus stausumbetantaupbetatauln pbetatausbeta tag ntau number branch originating tau sbeta entropy subtree beta pbetatau either ratio funding invested beta compared total funding invested tau ratio number startup beta compared total number startup tau ie probability beta knowing tau refer entropy computed using ratio funding shannon funding entropy computed using ratio number startup shannon startup naturally measure dependent structure ontology defined previously issue wellknown ecology emerges definition specie one chooses use following effective number specie derived shannonweiner entropy index dexpleftstauright tag shannonweiner index value tree category equal population category total stau corresponding effective number specie dexpstau coherent definition understanding metric hill number order q shannonweiner diversity favored calculating diversity without prior information ecosystem order higher disproportionately sensitive common specie order lower disproportionately sensitive rare specie upon applying hill diversity index order dataset indeed find order index allows u gain insight ecosystem dynamic whereas order index discriminate well ecosystem use order index diversity measure following simulating ecosystem growth try understand mechanism behind growth diversification entrepreneurial ecosystem simulated development startup ecosystem described byour ontology number startup amount funding structured category incremental populating ecosystem done following simple preferential attachment model current state tree two main variant model used first one new startup placed category iinn probability pifracnialphacsumjnnjalphac ni number startup category alphac free parameter model second one new startup created funding amount drawn powerlaw distribution exponent beta support xminxmax new startup placed category iinn probability pifracfixminalphacsumjnfjxminalpha c fi total funding startup category alphac free parameter model result discussion applied methodology compare thirtyfour ecosystem europe northamerica asia australia chosen based prominence figure sum size term number startup company total funding ecosystem january st fig figure ecosystem size term number startup total funding show mapping ecosystem using visualization method size startup cell proportional amount fund raised color encodes momentum defined eq purple mean company went public shade red beige represent sequence top startup highest momentum industry ordered top left bottom right following total funding expected funding increase number startup however ecosystem visually exhibit significant disparity term funding allocation instance paris host twice many startup atlanta total cumulative investment city comparable since january st b atlanta v b paris mapping ecosystem might shed light observation like atlanta berlin stockholm fig appear characterized relatively weak diversity related presence champion unicorn kabbage atlanta delivery hero berlin spotify klarna izettle stockholm raised billion dollar hand paris new york silicon valley fig appear much diverse term funding well industry able visualize evolution ecosystem also capture dynamic trend instance slow fall manufacturing iledefrance explicit representation falling total investment fig london hand financial service investment skyrocketed period investment fig biggest funding recipient british metropolis measured diversity fig show evolution selected ecosystem term number startup effective number specie january st january st represented pair value ntdt per year nt dt respectively number startup ecosystem effective number specie ecosystem time diversity computed using funding per category shannon funding left plot number startup per category shannon startup right plot diversity higher shannon startup compared shannon funding individual trajectory tend distinct high number startup see instance silicon valley new york suggesting ecosystemspecific dynamic could play ecosystem becomes sufficiently large since ecosystem differ widely term number startup useful scale diversity trajectory number startup start end measuring period comparable fig figure temporal evolution effective number specie function number startup various ecosystem value effective number specie computed using entropy calculated funding category left number startup category right present standardized ecosystem dynamic ie ecosystem characterized value pair hatnthatdt hatntfracntntntfnt tag hatdtdtdt tag index first data point year tf index last data point year using standardized metric ecosystem similarlyshaped trajectory using shannon startup right plot whereas trajectory computed using shannon funding left plot seem variable probably due large discrepancy individual funding amount easily unbalance ecosystem especially early stage development diversification term number startup per sector shannon startup thus seems fundamental characteristic shared studied ecosystem compared diversification term funding per sector therefore use shannon startup compute entropy diversity numerical simulation correlation macroeconomic indicator order move beyond visual intuition landscape made use diversity metric defined previous section fitted ols model find correlation effective number specie macroeconomic indicator retrieved oecd regional statistic including wealth gdp gdp per caput economic vitality employment gdp growth base research intensity labor force tertiary education number researcher per p number patent rd expense gdp value standardized removing mean scaled unit variance logarithm number startup explain variance r fit indicator figure standardized temporal ecosystem trajectory hatdt effective number specie hatnt number startup time tintf value effective number specie computed using shannon funding left shannon startup right dtlognt fitting value previously defined indicator still controlling logarithm number startup find correlation gdp per caput pvalue cdot diversity thus seems related economic development surprisingly research intensity metropolis however observation simply consequence higher maturity startup ecosystem developed country since existed longer time simulation result simulation result two variant model found fig diversity value simulation result color line computed based entropy calculated using eq number startup category shannon startup compared value diversity result dataset computed funding amount fig number startup fig figure show preferential attachment number startup left plot eq seems explain diversification ecosystem certain point diversity stable ecosystem continues grow ie new startup end concentrating small number category effective number specie collapse preferential attachment category funding right plot eq hand seems better match data computed shannon startup shannon funding ecosystem figure simulation result preferential attachment number startup left category funding right diversity dataset computed using shannon funding figure simulation result preferential attachment number startup left category funding right diversity dataset computed using shannon startup diversity steadily increase time using model preferential attachment funding amount thus better mechanism preferential attachment number startup order explain diversification ecosystem throughout growth comparing result data case shannon funding data simulation result seem match particularly well free parameter alphac value around see fig check robustness result numerical simulation variant model tested new startup placed random category probability p probability p placed category following preferential attachment law described sec qualitative difference found simulation p p p case corresponds standard preferential attachment model shown fig fig show good concordance data point shannon funding red dot simulation result black line obtained preferential attachment funding alphac model mixed preferential attachment taking account number startup total funding time tested following eq pifracthetanialphastthetalnxminlnfi alphafundssumjnthetanjalphastthetaln xminlnfjalphafunds tag theta controlling importance funding amount v number startup alphast alphafunds free parameter model simulation range value alphast alphafunds thetain provide better match data preferential attachment simply total category funding fig finally simple mixed model firm creation growth also confronted data iteration simulation new startup created probability gamma category following eq allocated seed funding probability gamma random existing startup funded amount depending last simulated funding round moved next stage alphabet round system ie company last received seed funding received series funding company last received series funding received series b set gamma based figure effective number specie function number startup ecosystem preferential attachment total funding free parameter alphac black line corresponds simulation value averaged run red point correspond data dataset error bar corresponding one standard deviation shown simulation data silicon valley ecosystem seed round new entrant represent approximately half venture funding round distribution type funding round stage parameter found similar data simulation result mixed model firm creation growth give better result one shown fig main driver diversification ecosystem simply seems allocation funding regardless ecosystemdependant factor tendency entrepreneur explore new industry instead follow existing trend thus seems heavily linked individual decision particularly influenced financially successful existing company various category conclusion paper presented novel approach respect studying emergence startup ecosystem using public datasets first presented novel automated interactive data visualization tool facilitates study startup population ecosystem point view also shed light particularity different ecosystem relatedly diversity metric shannonwiener index simpsonherfindahl index introduced fostering analogy ecological science tried understand observed diversity could emerge attempting relate disparity ecosystem macroeconomic index numerical simulation result suggest increase diversity growth startup ecosystem explained sequential allocation funding startup given sector thanks simple preferential attachment model rather macroeconomic indicator exception economic development ie startup ecosystem diversity appears outcome emerging aggregated behaviour rather linked ecosystemspecific characteristic decision needle say analysis ecosystem diversity remains preliminary deserves analysis larger sample ecosystem also focus event instance linking diversification event ie sector getting rather sudden large influx new startup creation specific breakthrough either technological recently case deep learning businessoriented seen respect food delivery could typically give valuable insight startup ecosystem diversity diversification missingpageempty missingpageempty missingpageempty figure map new york silicon valley jan st reference hannan mt freeman j organizational ecology cambridge harvard university press moore jf predator prey new ecology competition harvard business review schot j usefulness evolutionary model explaining innovation case netherlands nineteenth century history technology gilbert mcdougall audretsch emergence entrepreneurship policy small business economics minniti role government policy entrepreneurial activity productive unproductive destructive entrepreneurship theory practice national venture capital association thomson reuters venture capital fundraising top billion q recording strongest quarter since internet january available httpsnvcaorgpressreleasesventurecapitalfundraisingtopsbillioninqrecordingstrongestquartersincehttpsnvcaorgpressreleasesventurecapitalfundraisingtopsbillioninqrecordingstrongestquartersince birch job creation america smallest company put people work university illinois urbanachampaigns academy entrepreneurial leadership historical research reference entrepreneurship thurik r wennekers linking entrepreneur economic growth small business economics wong pk ho yp autio e entrepreneurship innovation economic growth evidence gem data small business economics hawaii strategic development corp hi growth initiative internet january available httphsdchawaiigovhigrowthinitiativehttphsdchawaiigovhigrowthinitiative la vega sun tax incentive million approved electric car company faraday future internet jan cited jan available httpslasvegassuncomnewsjantaxincentivesofmillionapprovedforelectrhttpslasvegassuncomnewsjantaxincentivesofmillionapprovedforelectr slush report internet january available httpsstateofeuropeantechcomhttpsstateofeuropeantechcom dow jones internet january available httpswwwdowjonescomproductspevchttpswwwdowjonescomproductspevc techcrunch latest technology news information startup internet january available httpstechcrunchcomhttpstechcrunchcom cb insight tech market intelligence internet january available httpswwwcbinsightscomhttpswwwcbinsightscom drieux p fintech landscape internet january available httpswwwvbprofilescomlfintechhttpswwwvbprofilescomlfintech strachman p french ai ecosystem internet january available httpfranceisaicomstartupshttpfranceisaicomstartups dalle jm den besten menon c using crunchbase economic managerial research oecd science technology industry working paper meyer libaers thijs grant b origin emergence entrepreneurship research scientometrics chandra mapping evolution entrepreneurship field research scientometric analysis plo one e gastaud c lacroix taub r dion g dalle jm datadriven approach measuring diversity startup ecosystem rd management conference crunchbase inc crunchbase discover innovative company people behind internet january available httpswwwcrunchbasecomhttpswwwcrunchbasecom dealroomco datadriven intelligence highgrowth company internet january available httpsdealroomcohttpsdealroomco gompers p lerner j venture capital cycle cambridge mit press batista f carvalho jp text based classification company crunchbase fuzzy system fuzzieee carrot search carrotsearch internet june available httpscarrotsearchcomfoamtreehttpscarrotsearchcomfoamtree shneiderman b plaisant c treemaps spaceconstrained visualization hierarchy including history treemap research university maryland internet sep cited may available httpwwwcsumdeduhciltreemaphistoryindexshtmlhttpwwwcsumdeduhciltreemaphistoryindexshtml mccann k diversitystability debate nature gilchrist da st louis lv direction diversification application saskatchewan journal regional science dissart jc regional economic diversity regional economic stability research result agenda international regional science review kurre ja weller br interindustry covariance pattern unstable portfolio variance analysis useful tool economic development quarterly kort jr regional economic instability industrial diversification u land economics pielou ecological diversity new york wiley hill diversity evenness unifying notation consequence ecology vol mar pp simpson measurement diversity nature l jost entropy diversity oikos l jost partitioning diversity independent alpha beta component ecology herfindahl oc concentration steel industry doctoral dissertation columbia university shannon c mathematical theory communication bell system technical journal gibbs elementary principle statistical mechanic agapow pm impact specie concept biodiversity study quarterly review biology oecd regional statistic march httpsdoiorgregiondataenhttpsdoiorgregiondataen title improving performance earlystage software startup design creativity viewpoint transcription jyu dissertation juhani risku improving performance earlystage software startup design creativity viewpoint university jyvaskyla facult information technologyjvu dissertation juhani risku improving performance earlystage software startup design creativity viewpoint esitteaan jyvaskylan yliopiston informaatioteknologian tiedekunnan suostumuksella julkisesti tarkasetttavaksi kesakuun paivana kello academic dissertation publicly discussed permission faculty information technology university jyvaskyla june oclock jyvaskylan yliopisto university jyvaskyleditors marjaleena rantalainen faculty information technology university jyvaskyla ville korkiakangas open science centre university jyvaskyla cover picture cynefin framework applied article ii tetra framework applied article ii rankkasauna harsh sauna house concept rodmobile electric car concept copyright c university jyvaskyla isbn pdf urnisbn isbn permanent link publication httpurnfiurnisbnhttpurnfiurnisbn abstract risku juhani improving performance earlystage software startup design creativity viewpoint university jyvaskyla p included article jyu dissertation issn isbn pdf last year large number startup launched ranging mobile application game provider enormous corporation started tiny startup startup important topic research development fundamental success characteristic individual team partner investor market speed everything evolves startup business environment fraught uncertainty actor tend young inexperienced technology either new rapidly evolving teamcombined skill knowledge either key fatal software startup fail capable reliable team crucial survival success many aspect topic extensively studied result study human capital particularly important regarding human capital ability knowledge experience skill cognitive ability dissertation focus design skill deployment startup design widely studied artistic industrial context application startup culture software startup follows method prison method prison old conventional mean chosen instead new technique demanding design study mean software startup considers design foundation creativity generating better offering grab industry disruptive agenda making anything softwareintensive concept design expanded deepened new level business escape method prison adopts artistic design help stagnant industry us disruptive method realistic selfefficacy five partially overlapping article varying detail dissertation clarifies daily theme interest startup required survive succeed dissertation reflective practitioner investigation startup practice using mixedmethods approach designbased creativity startup stronger successful future cause protect disruption startup retain customer selfefficacy strengthen keywords startup software engineering design creativity selfefficacy disruption retention gamification game industry method prison medium industry network manufacturer network operator architecture tiivistelma abstract finnish risk juhani ohjelmistoalan startupyritysten suorituskyvyn parantaminen suunnittelun ja luovuuden avulla jyvaskylan yliopisto alkuperaiset artikkelit jyu dissertation issn isbn pdf viime vuoden aikana startupyrityksia perustettu erittain suuri maara tassa joukossa mobilisovellusten ja pelien tekijoita mutta myos suuryrityksia jotka ovat aloitaneet pienina startupeina startupit ovat rakea aihe tutkimusessa ja kehitystyossa menestyksen perustekijoita ovat yksiloiden ja timien omnaisuudet kumppanina toimivat sijoittajat markkinat seka yleinen nopea kehitys startupyrityksen liiketoimintaymparisto taynna epavarmuutta silla toimijat ovat yleensa nuoria ja kokemattomia teknikat uusia tai nopeasti kehittyvia ja tiimin yhdistetyt taidot ja tiedot menestykekkaita tai tuhoisia koska yli ohjelmistostartupeista epaonnistuu kykeneva ja luotettava tiimi ratkaisevan tarkea menestymisen kannalta aihetta tutkittu palon ja varsinkin inhimillista paaomaa koskevan tutkimuksen tulokset ovat vakuuttavia tassa vaitoskirjassa keskitytaan tietoon kkemuksinin taitoihin ja muihin kognitivisiin kykyihin joihin designtaidot ja niiden kayto iiittyvat suunnittelua tutkitaan laajalti taiteellisessa ja teollisessa konteksissa mutta sen soveltaminen startupkulttuurin ja ohjelmistojen startupyrityksinin tapahtuu omassa menetelmavankilassa method prison menetelmavankilassa otetaan kayttoon vanhoja ja perinteisia keinoja uusien tekniikoiden ja vaativien suunnittelututkimusten sijaan jos ohjelmistoyritykset ottavat designin perustaksi luovuudelleen ne voivat tarjota paremman tuotevalikoiman ne voivat tarttua mihin tahansa teollisuuden ala disruptivisella agendalla ja tehda kaikesta ohjelmistointensiivista samalla designin kasitetta voidaan laajentaa ja syventaa uudelle luovuuden tasolle nain voidaan myos paeta menetelmavankilasta tama vaitoskirja selventaa monimenetelmallisen tutkimuksen keinoin vijdessa artikkelissa miten startupit voivat selviytya ja menestya paremmin pavittaisssa toimissa tutkimus tuottaa vahvempia ja menestyvampia startupyrityksia designkeskeisen luovuuden avulla samalla ne voivat aiheuttaa disruptiota tai suojautua silla startupyritykset voivat pitaa asiakkaansa ja niiden mniapystyvyys vahvistuu avainsanat startup ohjelmistosuunnittelu design suunnittelu luovuus minapystyvyys disruptio asiakkaan sailyttaminen pelaaminen peliteollisuus menetelmavankila mediateollisuus verkonvalmistaja verkkooperaattori arkitehtuuri author juhani risku faculty information technology university jyvaskyla finland juhaniriskujyufi orcid supervisor pekka abrahamsson faculty information technology university jyvaskyla finland tuure tuunanen faculty information technology university jyvaskyla finland reviewer kari systa faculty information technology communication science tampere university finland pertti seppanen faculty information technology electrical engineering university oulu finland opponent sami hyrynsalmi school engineering science lappeenranta university technology finland foreword lifelong learning dissertation milestone extensive round began academic study university jyvaskyla department mathematics physic year later moved architecture tampere university technology graduated architect already started apprenticeship turbine mechanic laid foundation craftsmanship art craft skill later studied nokia corporation learning center industrial design brand management take part usability user experience design starting doctoral study jyvaskyla apprentice master machinery acoustic photography ceramic carpentry stone masonry forestry stained glass architecture city planning university jyvaskyla finally took science systematically scientifically caught everything done practice industrial graphic design user interface design design science fact able understand retrospectively rationale background future deepen practical work lucky get professor pekka abrahamsson supervisor doctoral study creative prolific visionary scientist leader simultaneously scientific input lead startuplab university jyvaskyla new product service solution created work startup lab crest disruption scientifically justified fun lab professor abrahamsson known taking challenge time developing new way working leading example always answer yes tackle wicked problem solves want thank professor pekka abrahamsson tireless support inspiration study design civil courage transmitted science development service product new future supervisor professor tuure tuuranen special case university multidisciplinary entrepreneur scientist addition wellknown expert discipline close design science origin design science lie architect quest systematic approach design leadership professor tuuranen able taste design science want thank professor tuure tuuranen always happy sympathetic support want thank researcher student university jyvaskyla startup laboratory could better community around shared enthusiasm always huge bustle startup lab hurt happens time get stimulated shared joy grows found young team others year younger something wonderful peculiar going time researching making science special thanks johannes impio find everything even internet make company video creative concept graphic master note want thank johannes dailydetermination either business video music everything go doctoral student kaikristian kemell person everyone would need cope vision practice diligence science save scientific partner superior diligence also credible performer want express utmost gratitude multitalented colleague kaikristian example thorough diligent research luxury joining multidisciplinary research development community university jyvaskyla special thanks dr elina jokinen inspiring cheerful teacher writing communicating science elinas course met wide range people different faculty interest circle entire university built around want thank research assistant marjaleena rantalainen university stand stable process run also want thank political scientist m outi alapekkala science po paris native french arctic lapland wrote together impressive article restructuring medium change everything medium business end wrote dissertation mainly art center jarvilinna laukaa central finland generous heart inspiring atmosphere well working kauko sorjonen artist art center made work celebration thank received strength courage late father graduated high school diploma age master degree economics age mother still best supporter always find understanding perspective situation warmest thanks best starting point studying science daughter sade risku encouraged last year saving science got universal dancer occasion one day surely dance realm science son pasi risku extended family always supported even strange action understanding want especially like thank loved one mirja nylander following work throughout scientific research trip supporting facilitating forester agricultural forestry scientist mirja farmer daughter know hard work also one master field study apprenticeship mirja taught sharpen use chainsaw identify tree specie mention forest biology got earth encourages people make evernobler endeavor new order soon coming forestry thank mirja jyvaskyla juhani riskulist included article risku abrahamsson risku j abrahamsson p software startuppers learn artistic design flow experience reflection future avenue abrahamsson p corral l oivo russo b ed productfocused software process improvement proceeding th international conference profes pp lecture note computer science springer cham risku alapekkala risku j alapekkala software startuppers took medias paycheck medias fightback happens startup culture abstraction shift international conference engineering technology innovationieee international technology management conference iceitmc pp ieee kemell et al kemell kk risku j evensen abrahamsson p dahl grytten l h jedryszek rostrup p nguyenduc gamifying escape engineering method prison ieee international conference engineering technology innovation iceitmc pp ieee risku et al risku j kemell kk schweizer nguyenduc suoranta wang x abrahamsson p make digital game addictive player viewpoint player retention accepted presented ieee international conference engineering technology innovation iceitmc footnote paper peer reviewed accepted included proceeding due obstacle participate presentation caused corona pandemic currently work unpublished manuscript submitted conference risku et al risku j kemell kk kultanen j feshchenko p careles j korpikoski k suoranta abrahamsson p exploring relationship selfefficacy creativity case business education submitted article ii v author responsible designing research gathering research data analyzing data drawing conclusion article iii author charge board game design realization user experience usability article iv author charge game design specific object influence selfefficacy creativity gaming context playing designing game impact retention game design missingpageempty missingpageempty content introduction motivation research question structure dissertation scientific contribution author theoretical background software startup definition software startup challenge software startup face software startup succeeds lifecycle software startup internal startup antipatterns essence software engineering background motivation essence core framework model activity space competency alpha relation essentialization practice known issue essence model design viewpoint definition design design software startup design software engineering design dynamic cynefin framework creativity focal context definition creativity creativity different context measuring creativity creativity selfefficacy creativity software engineering research gap rqs research methodology research approach missingpageempty introduction chapter describes research area dissertation introduces main concept focus area outline structure dissertation also presented motivation software startup significant implication innovation economy implication extensive impact people specifically user adopt product multiple corporation history startup apple google facebook microsoft originated startup global actor software industry developing various technology including smartphones computer application search engine social medium platform dolata dynamic software startup seen case google facebook also advertising marketing company platform interesting advertiser enormous number user equally amazon bookingcom airbnb commercial mediation platform grown large user base rochet et al software startup company creates hightech software product service company nature temporary organization nature company little operational experience try grow fast scale business extremely scalable market area giardino et al software startup release new market approachable technology venture capital globally actualized blank startup company become successful business like facebook linkedin spotify instagram groupon dropbox began fresh technological adventure still many startup fail achieving business prospect crowne startup fail mainly selfdestructiveness competition marmer et al one main challenge startup find right people role including core team management investor seppanen initial core team three role founder expert implementation team member different startup founder may role expert implementation team member simultaneously founder personal capability lead role plurality carrying multiple role topdown direction founder expert implementation team member obvious founder deeper broader capability seppanen marvel et al divide founder praxis experience depth experience breadth marvel et al core task software startup execute manage creation delivery softwareintensive product high value product software engineering practice key component performance success startup notion engineering performance success need specified software startup context klotins dissertation startup origin creativity innovation design attitude spirit find something new quickly realize idea launch broadly public use general idea initial concept active way working scale software startup startup different industry trade moving softwareintensive mode startup orchestrate work software form application webbased solution systemlevel platform author personal motivation research creativity innovation design reflective practitioner based background various professional activity thirty year sketching drawing conceiving sculpting prototyping building house furniture prototype piece art societal system taught author system object detail slide one another scale structure common factor seems quality creator designer eagerness ideate conceptualize diligence craft iterate determination finish functionality form beauty artifact curiously winterization segway lapland riding murmansk coroneted author career designer figure project proved anything possible even meter snow circc shade quality startuppers jyu startuplab home base author fruitful environment research creation design research evidence assistance development combine practical design research startup dissertation horizontal detailsystem creationresearch product startuppers action various context despite scale approach research subject vision creativity innovation research built workflow designer approach next assignment act researcher startupper outcome article iv initiative different staring point process come common compatible conclusion startup spirit approach attitude scale motivates creativity design given task dissertation us mixedmethods approach reflective practitioner viewpoint thus qualitative quantitative technique alternate article reflected summary wu creativity extremely complex manifold scientific subject connection matter mumford et al creativity also ignored research problem mystical dimension spiritual nature easily adopted academic environment blumenthal haeberlin express psychic phenomenon therefore creative product synthesis seen point view act haeberlin educated experienced reflective practitioner feel meaning notion need research applied wider creation context one fundamental motivation arose expression smith et al noncreative people tend maintain one single interpretation order creative regardless subject area individual must able go beyond conventional interpretation reality smith et al word noncreative trigger scientific motivation form creative noncreative creativity defined practical outcome spiritual existence simultaneously fuzziness creativity motivates understand creativity human capability verb generate something research meaning notion figure winterization segway generated author research question general purpose scope dissertation clarify nature software startup creating surviving succeeding different phase case industry design umbrella term phase startup product development flow factor enabling company reach exceptional competitive factor compared competitor cirjevskis critical success factor design startup kim et al list entrepreneur ability philosophy leadership lead design startup business success idea innovative capability make lead new market success design startup business technology product business modeling capability design startup business success funding financial ability lead design startup business success kim et al approach offer set condition environment requirement progression pattern earlystage startup game industry successful one made enormous exit either go public acquired another firm startup case success continue superb service solution offering grow independently startup requires idea skill develop concept financial business support experienced party order succeed human factor team personal quality crucial startup startup ambivalent arrangement contradictory setting highly demanding business environment technological challenge temporary nature little experience lack resource possibly technical debt incomplete team giardino et al klotins main research question improve performance software startup research question defined follows design creativity viewpoint support earlystage startup develop idea concept better article ii v software startup develop process better customer retention article iii iv creativity enhanced software startup article iii v following section article connection explained structure dissertation stated earlier scientific motivation dissertation creativity notion characteristic concept praised required entirety art designeducation academia industry motivating practice scientific circumstance research consists five article horizontally cover software startup action different domain circumstance way working case present broad granularity business role startup internal capability various set customer user market future startup face lifecycle article present design approach borrowed art design culture developed practice skillsets still wide use throughout industry even ancient design culture method practice people affect startup survival success implemented culture set action presented alternative avenue change article answer rq emphasizing importance design skill utilization design process largely used art architecture various design domain civil engineering importance creativity design startup crucial propose new unique concept survive market skillset various design area advisable development speed fast communicative mean help ensure startup credibility article ii describes software startup grow cause disruption global business later startup may face threat disruptive action targeted underdog party article envisions build strategy challenge presentday market leader using cynefin framework determine action order consequence future challenge seen medium single startup internal startup article ii answer rq encouraging earlystage startup contrary three industrial conglomerate mobile network manufacturer network operator medium house startup bravely challenge industry bypassing problem three conglomerate startup establish something industry done young earlystage startup several advantage side nobody belief novice penetrate billion dollar industry brilliant concept article iii essence theory included semat strengthened educational game semat theory restructuring software engineering common ground punctual rigorous discipline semat represents library practice form software development kit drawing set module fit software development case create educational offering software engineering student important enable study dynamic access development structured software article iii describes gamified development initiative create board game educating software development project management practice essence theory software engineering part semat initiative everpresent threat method prison also recognized board game showed software development process treated dynamically situationally rather monolithically exclusively game flow proceeded team interactive aspiration ending common understanding dynamic varying path fulfilling robust target various alternative team process thesis essencetheory provides mechanism language notation essentialize practice startup use article iii answer rq rq process development factor startup context game development profit comprehensive design balance principle reward different playstyles ingame activity effect advance social interaction feeling achievement aspect game question escaping method prison twofold free oneself method prison function skill creativity professionally utilize skill design creatively use development process article iv describes user customer retention specifically player retention digital game industry user retention seen fundamental factor business product service offered present threat achieved status business highly competitive market article studied startup role ensuring game element keep player playing game article motivation studied rewarding player two factor customer retention motivation reward generally important business highlighted startup product creation article iv answer rq finding help startup design process game design multiple factor must exploited finetuning reward test emotion achievement inhouse play try advance game style ingame activity exploration taking factor account design process startup ensure better customer retention player continue play eagerly return game footnote thesis player key stakeholder digital game industry referred customer player depending given context article v describes creativity correlated selfefficacy among student according selfefficacy questionnaire result design work evaluation according result selfefficacy creativity clearly correlated addition presumption seasoned skillful student design achieved medium score selfefficacy may demonstrate realism selfcritique comparing oneself designer general article v answer rq rq evaluating design skill reflected creativity selfefficacy design skill focus evaluating creativity student practical design project visualization conceptual idea emphasized combined rqs importance design skillset useful planning concept visualizing design summary part thesis structured follows section describes idea software startup startup general common aspect innovation creativity design section author motivation explicated brief personal description approach attitude workflow memorable highlight author professional career emphasize role nature reflective practitioner within scientific research section research scope objective explained research question structured section defines software startup phenomenon present overview challenge startup face lifetime mean success analyzed meaningful motivation startup startup way established state entrepreneurship either going public acquired lifecycles studied overview corporative internal startup presented medium large systemic construct built large complex solution highly disruptive barely possible small earlystage startup antipatterns unfortunate product without customer explained section section present scope research research methodology five article dissertation multifaceted nature startup subject creation development described idea reflective practitioner analyzed seen practically oriented scientific researcher typically surgeon base professionalism science practice bestcase scenario derive new scientific finding practical experience drilling inside people section summarizes original publication finding connection objective dissertation presented creativity seen holistic process throughout workflow product creation design considered practical action creativity also seen disruptive counteraction friendly revenge challenging competitor happens across business industry time software development filled process need management using various selfcreated process instead one rigid procedure important startup addition continuously attracting winning back customer crucial startup require strategy customer retention finally creativity selfefficacy significant quality startuppers still selfevident linked realistic way section collect result dissertation describe future startup everdemanding business design practice help startup act professionally turbulence competitive environment theoretical practical contribution described limitation explained future research envisioned scientific contribution author section list scientific article author related dissertation article contributes directly software startup culture software engineering practice kemell kk elonen suoranta nguyenduc garbajosa j chanin r melegati j rafiq u aldaeej assyne n sale hyrynsalmi risku j edison h abrahamsson p business model canvas pay attention software startup team seaa th euromicro conference software engineering advanced application pp ieee kemell kk risku j strandjord ke nguyenduc wang x abrahamsson p internal software startup multiple case study practice method success factor seaa th euromicro conference software engineering advanced application pp ieee kemell kk feshchenko p himmanen j hossain jameel f puca rl vitikainen kultanen j risku j impio j sorvisto abrahamsson p software startup education gamifying growth hacking fundamental software startup essential engineering business aspect pp springer kemell kk nguyenduc wang x risku r abrahamsson p software startup essence software startup work fundamental software startup essential engineering business aspect pp springer kemell kk evensen wang x risku j nguyenduc abrahamsson p toolbased approach essentializing software engineering practice seaa th euromicro conference software engineering advanced application pp ieee risku j kemell kk kultanen j feschenko p careles j korpikoski k selfefficacy matter correlation selfefficacy creativity education icsob software business pp springer kemell kk feshchenko p himmanen j hossain jameel f puca rl vitikainen kultanen j risku j impio j sorvisto abrahamsson p software startup education gamifying growth hacking ivsib proceeding nd acm sigsoft international workshop softwareintensive business startup platform ecosystem pp acm kemell kk nguyenduc wang x risku j abrahamsson p essence theory software engineering largescale classroom experience software engineering bsc student profes productfocused software process improvement pp springer theoretical background based topical situational literature software startup essence creativity selfefficacy processing method used dissertation varies theoretical study practical design reflection analysis visionary outlook onsite inclass study systematic literature study run different way various guideline different first step eg start search string different database start reference list set paper snowballing recommended first step information system method used identify relevant literature called backwardsnowballing refers technique find applicable hit reference list jalali et al study reference publication seppanen klotins performed significant role software startup research software startup section nature software startup determined large technology company often strategy innovation expansion new business area form acquisition instead cooperation mean corporation expand expertise direct acquisition startup cooperating ensures startup resource competency integrated directly design development organization rothaermel roijakkers et al hagedoorn et al exit strategy fundamental target startup startup four optional strategy exit first option become public initial public offering ipo second option acquired industry player third option acquired financial investor fourth option apply leverage strategy possibility preserve full ownership control lender fund deenitchin et al optimal exit pattern depends various element anticipated lucativeness startup degree uncertainty product market imbalance information potential buyer new investor insider outsider addition potential conflict interest among buyer venture capital quality create ambiguity startup akerlof basu et al optimal technology startup specifically designed acquired larger corporation exit mainly executed year beginning startup early exit also turned probable waiting year initial public offering ipo peter timing management different party interest crucial startup exit strategy otherwise dream come true definition software startup software startup defined different term depending source adjective software startup described either quick young immature beggarly resourceless temporary creative robust agile fresh dynamic unorganized informal vagabond aimless decentralized weatherocking pivot triumph monetarization horny adolescent softwareintensive nerdy unstable lucky lotterywinners tiny eager cowboyish non engineering believing trying addictive illusory concoctive many term found news startup success failure miserable investor mind concentrate certain important factor software startup carmel defines software startup early year including product development characteristic follows minimize timetocompletion increase innovationfeatures maximize quality minimize product cost minimize development cost carmel klotins defines product development process product development startup driven following five goal minimize timetocompletion increase innovationfeatures maximize quality minimize product cost minimize development cost impossible pursue five goal developer must make tradeoff decision implicitly explicitly decision definition affect timetocompletion klotins p xref ries proposes broader definition startup also scale outside software technology industry line business startup human institution designed create new product service condition extreme uncertainty ries p blank et al defines startup temporary organization creates innovative hightech product earlier operating history separate startup established organization resource position mature market blank et al also state startup seek scalable repeatable profitable business model willingness grow definition differentiates startup small business company essentially strive grow therefore small business company lack scalable business interest model definition klotins proposes compressed definition software startup notionsoftwareintensive product service include eg software code usability application artefact embedded physical product service systemic solution frontend view allinclusive widely spread structure web interpretation klotins software startup company understood recently created institution focus launching innovative softwareintensive product service market common conclusion software startup share many similarity dealing uncertain condition willing grow fast intending develop innovative product aiming scalability unterkalmsteiner et al like sutton state factor differentiate software startup type startup change software industry new computing network technology new sort computing device software startup also need use frontline equipment technique developing innovative software product service sutton also describes software startup challenge encounter first startup little experience managing development process organization second little resource try launch product advertise acquire strategic coalition third startup experience several stimulus including pressure financier client associate contestant make decision although actor important may cause confusion decisionmaking fourth startup face challenge vibrant technology business seminal nature software startup urge regenerate perform development distracting technology reach highly prospective target market sutton requirement reflect temporary young eager indigent phenomenon software startup must act difficult environment shift tranquil getting funding chaotic failure aftershock startup small medium size enterprise resemble characteristic like small number employee limited resource kamsties et al laporte et al table list wide set characteristic collectively agreed vary definition different author therefore challenging apply characteristic direct startup paternoster et al scaleup scaleup post startup scaled startup based philosophical statement reid hoffman cofounder linkedin first mover advantage doesnt go first company launch go first company scale hoffman also markides et al express often case radical innovation later entrant reign market early explorer may happen industry car tire plastic web search markides et al earlyphase startup survives first year fortunate circumstance strive growth phase expansion marketing sale mean scaling business zajko isenberg say extraordinary value creation occur without growth entrepreneurial growth post startup numerous challenge order magnitude difficult simply starting venture recommends various possibility reorient strategy
Original Title: The emerging sectoral diversity of startup ecosystems
Original Transcription: The emerging sectoral diversity of startup ecosystems

Clement Gastaud1,2, Theophile Carniel1,2, Jean-Michel Dalle*,1,2,3

**1** Agoranov, Paris, France

**2** Sorbonne Universite, Paris, France

**3** i3-CNRS, Ecole Polytechnique, France

* jean-michel.dalle@sorbonne-universite.fr

## Abstract

Thanks to the recent availability of comprehensive and detailed online databases of startup companies, it has become possible to more directly investigate startup ecosystems i.e. startup populations in specific regions. In this paper, we analyze the emergence of 20+ such ecosystems in Europe and the USA, with a specific focus on their sectoral diversity. Analyzing the sectoral landscapes of these ecosystems using a new visualization tool indeed highlights marked differences in terms of diversity, which we characterize using metrics derived from ecological sciences. Numerical simulations suggest that the emerging diversity of startup ecosystems can be explained using a simple preferential attachment model based on sectoral funding.

## 1 Introduction

Startup populations have recently come to be commonly referred to as _"startup ecosystems"_, by analogy with ecological systems. This metaphor has emerged in economics and management sciences in the early 90's from different sources in order to study the creation, growth and death of organizations [1], the competition between industrial actors [2] or else the emergence of new technology niches [3]. More recently, startup ecosystems have become central in local, national and international innovation policies [4, 5] as innovative startups were drawing increasing investments [6] from venture capitalists and an increased attention from stakeholders notably because of their potential to create jobs [7, 8, 9]. Indeed, following the leading example of San Francisco and the Silicon Valley, Austin, Boston, Los Angeles or New York in the US and Berlin, London or Paris in Europe [12] have thrived to become active entrepreneurial ecosystems and are competing against one another in order to attract startups.

In this context, data and models that would allow entrepreneurs, investors and policy makers to analyze, characterize and compare the emergence and dynamics of different startup ecosystems are however still mostly missing. Even if professional websites such as [13, 14, 15] have started to gather relevant information, there is a global lack of understanding concerning the fundamental mechanisms driving the development of entrepreneurial ecosystems. Startup landscapes only provide a representation of the startups in a specific sector, split in sub-sectors, such as the global fintech landscape edited in 2016 by Atherton Research [16] or startups associated with a specific technology and geographical zone, such as the 2017 France Is AI's landscape [17], all the more so as existing landscapes are mostly instantaneous snapshots and lack completeness. Put differently, there does not exist, as far as we know, any quantitative model or tool that would significantly help actors make a more appropriate sense of the dynamics of startup ecosystems, a fact that is somewhat surprising since entrepreneur has become a major topic in public policy decision making [19, 20].

In this article, we argue that the recent availability of comprehensive public startup databases represents an opportunity for the formulation and validation of such theoretical models, related to the dynamics of startup ecosystems. Building upon an automated startup landscape generator that allows for the visualization of entrepreneurial ecosystems while incorporating relevant metadata (e.g. textual descriptions, sector of activity and funds raised) [21], we first suggest to extend the ecological analogy and characterize ecosystems using diversity metrics. We then try to relate the observed differences among ecosystems to macro-economic indicators before presenting and calibrating a numerical simulation that explains the diversification of startup ecosystems with a preferential attachment model based on the funding received within each sector.

## 2 Materials and methods

### Dataset

We exploit a dataset of startups from Crunchbase [22], a mainstream source of data for academic research with respect notably to US startups [18]. For European ecosystems, this dataset was supplemented by Dealroom [23], which increased the number of considered companies by 9.4%. For each startup, we retrieved its date of creation, location, sectoral tags (describing its economic sector, technology and/or market), textual description and, most notably, all the information with respect to the funds that the startup has raised, including the date at which they were raised, the amount of funding, the nature of the funding round and the identity of the investors as well as all the articles mentioning this company available on Crunchbase (Figure 1). In addition, we retrieved all information available about people on Crunchbase, giving us in particular proxies with regard to the experience of startup founders. By nature of the funding round, we mean the different stages of Venture Capital funding that startup companies go through. In this respect, the first round of funding is generally called _Seed_ and corresponds to money used to validate that the product of the startup and the market are in phase. Other rounds are labeled by letters: _A, B, C_, etc. \(A\) rounds are designed to ensure the scalability of the company while later rounds (_B_ and latter ones) tend to accompany the growth of the company in national and international markets [24]. We limited our sample to companies created after January 1st, 1998 and to companies that mentioned at least one round of funding. Overall, our dataset consists in 618 366 companies, 221 299 investment rounds, 783 787 people and 6 363 831 news articles.

For each startup, we further computed two additional metrics: first, the total amount of funds it has raised and second, the speed at which these funds were raised (as a proxy for its pace of growth) which we denote as its momentum and define at time \(t\), in dollars per month, as:

\[m(t)=\sum_{i\in\{\text{investments}\}}\frac{\text{MoneyRaised}_{i}(t)\times\exp(- \text{DaysSinceInvestment}_{i}(t)/365\text{ days})}{12\text{ months}} \tag{1}\]

#### 2.1.1 Construction of the sectoral tree

In order to visualize ecosystems, we organized startups according to their main economic sectors. We used Crunchbase's basic tag structure as a starting point to create a startup sectoral tree. This tag structure is organized in two levels: first, the industry (_Health Care, Software..._) and then a more specific level (_Health Insurance, Image Recognition, Construction..._). The resulting ontology was cleaned up by removing tags that were specially broad and not distinctive (_Software, Infrastructure_, etc.), unrelated to economic sectors (_B2B, Freemium_, etc.) or very rare (e.g. _Ports and Harbors_ that was only associated with 10 startups worldwide in our dataset). Furthermore, tags that were semantically very close (e.g. _Shipping_ and _Delivery_, _Video Games_ and _Gaming..._) were merged. Then, whenever two tags had an inclusion relation not taken into account in the initial ontology (e.g. _Insurance_ and _Health Insurance_), this relation was used to create a new sub-level in the tree, as in:

_Financial Services \(\rightarrow\) Insurance \(\rightarrow\) Health Insurance_

It should be noted that in a few cases, visualization and classification prompted a manual edit of sectoral tags that were found to be either imprecise (e.g. startups with only a very general tag such as _Software_) or too numerous (e.g. a startup tagged with all the industries that could possibly make use of its technology) or simply factually erroneous. Following this procedure, the final sectoral tree was composed of 478 sectoral tags, down to 4 levels and composed of 28 industries i.e. independent sectors directly connected to the root of the tree1. Part of the _Data and Analytics_ branch is shown as an example in fig. 2.

Footnote 1: A full description of the sectoral tree is available upon request to the authors.

Figure 1: **Data recovered from Crunchbase.**

#### 2.1.2 Populating the sectoral tree with startups

This sectoral tree is used to populate a startup tree, considering startups as end leaves. Since most startups have several sectoral tags, we implemented a heuristic procedure to prune the tree i.e. to keep the most relevant tag for each startup. Following a strategy similar to [25], we can determine a startup's main industry (or tag) by classifying its description. For each tag, we compute the probability that a startup is best described by it. If this startup has no tag, we choose the most probable tag overall. If it has several tags and some are included in others, we first remove the shallowest ones in the sectoral tree as it corresponds, by definition, to the least precise sectoral assignment. Then, we choose the most probable tag from the remaining ones.

In the end, the simplest (least ambiguous) possible sectoral tree is obtained with startups associated as end leaves.

#### 2.1.3 An interactive visualization tool for startups ecosystems

In order to visualize the ecosystems, we made use of the TreeMaps FoamTree package [26], which allows to display hierarchical data as nested polygons tiling the plane, each cell having a surface proportional to a specific dimension of the data, as is general in tessellations and treemap representations [27].

Examples of such visualizations are presented in appendix. Each cell of the map corresponds to a startup, its surface representing the amount of funding received by the startup and its color the momentum as defined in eq. 1. The visualization typically confirms widely acknowledged characteristics of these ecosystems: for instance, London appears specialized in FinTech (22.6% of the investments) while Paris appears particularly strong with respect to Health Care. Furthermore, each ecosystem can be easily visualized through an interactive interface 2, while several filters can be applied to the map using all the data available on startups: tags, location, investors, etc. Thanks to the timestamps on each event, an ecosystem can also be visualized at any given date in order to study ecosystem and investment dynamics.

Figure 2: Part of the _Data & Analytics_ industry subtree of the sectoral tree.

### Introducing diversity metrics for startups ecosystems

To better characterize startup ecosystems, we introduce diversity metrics similar to what is traditional for ecological ecosystems. In ecological ecosystems, diversity is on average positively correlated with stability [28]: if a change in a diverse environment (for example a disease, or the arrival of a predator) targets some species, the impact on the whole ecosystem will be reduced because of functional redundancy. In economics, the relationship between diversity and unemployment stability has been widely studied [29, 30] and it has notably been proposed that, as for ecology, diversity was positively correlated with stability through resilience of the economy to rapid changes [30, 31, 32], although empirical analysis using regional data does not always confirm this hypothesis [30]. Similarly, a disruption in some sectors might more or less affect an entire startup ecosystem depending on its diversity across industries and sectors.

At least three major diversity indices have been defined and used in ecology: the Simpson index, the Shannon-Weiner index and the Hill index [33]. Both the Shannon-Weiner and Simpson indices and their corresponding diversity can be derived from the Hill numbers of order \(q=1\) and \(q=2\) respectively [34]. In the context of this study, we implemented the Shannon-Weiner index (measures the diversity of the ecosystems within the previously defined sectoral ontology) and the Herfindahl-Simpson index (measures the concentration of investments between startups regardless of their sectors and industries).

#### 2.2.1 The Simpson & Herfindahl indices

In ecology, studies usually present the Simpson index [35] defined as:

\[\lambda=\sum_{i=1}^{N}p_{i}^{2} \tag{2}\]

where traditionally in ecology, \(N\) is the total number of species and \(p_{i}\) the relative abundance of the species \(i\). In the present case \(N\) would be the total number of tags and \(p_{i}\) the ratio between funding invested in sector \(i\) and the total funding of the ecosystem. The Simpson index measures the probability that two individuals randomly chosen from a population belong to the same species. The extreme cases \(\lambda=\frac{1}{N}\) and \(\lambda=1\) correspond respectively to a maximal and a minimal diversity.

In order to have a more straight forward interpretation, the inverse Simpson index \(1/\lambda\) is often used. This corresponds to the _effective number of species_ or _true diversity_\(D\) as defined in [36, 37]. To give a quick intuition of the concept, this number converts the computed diversity index of the studied ecosystem into a corresponding ecosystem where all species are equally abundant; the resulting number of different species corresponds to the effective number of species (an unbalanced ecosystem with \(M\) species each with different values of \(p_{i}\) would be converted into an ecosystem with \(N\leq M\) species each with \(p_{i}=\frac{1}{N}\) for \(i\in[1,N]\)).

This index is also used in economics where it is called the Herfindahl index [38] and is usually used to study the importance of a company on a given market. It is defined as follows :

\[H=\sum_{i=1}^{N}s_{i}^{2} \tag{3}\]

where \(s_{i}\) is the market share of a company \(i\).

However, this index does not take the sectoral tree structure into account and focuses solely on the repartition of funds between actors.

#### 2.2.2 The Shannon-Weiner index

The Shannon-Weiner index, or Shannon entropy, originating from information theory [39] and statistical physics [40], is defined as follows:

\[S=-\sum_{i=1}^{N}p_{i}\log_{b}p_{i} \tag{4}\]

In the ecology literature, base \(e\) for the logarithm is usually used [36]; this convention will be used in the following. Shannon entropy quantifies the uncertainty associated with the prediction of an element of the considered dataset. In the context of ecology, it quantifies the uncertainty in predicting to which species an individual taken at random from the dataset belongs. However, in this form, the additional information given by the tree structure of the data is still not taken into account. Its hierarchical structure needs to be taken into consideration in the analysis. A more apt measure of the entropy \(S_{\tau}\) of a tree \(\tau\) is thus :

\[S_{\tau}=-\sum_{\beta=1}^{N_{\tau}}p_{\beta|\tau}(\ln p_{\beta|\tau}-S_{\beta}) \tag{5}\]

with \(N_{\tau}\) the number of branches originating from \(\tau\), \(S_{\beta}\) the entropy of the subtree \(\beta\) and \(p_{\beta|\tau}\) being either the ratio of funding invested in \(\beta\) compared to total funding invested in \(\tau\) or the ratio of the number of startups in \(\beta\) compared to the total number of startups in \(\tau\) (_i.e._ the probability of \(\beta\) knowing \(\tau\)). We refer to the entropy computed using the ratios of funding as _Shannon funding_ and the entropy computed using the ratios of number of startups as _Shannon startups_.

Naturally, this measure is dependent on the structure of the ontology defined previously. This issue is well-known in ecology and emerges from the definition of a species that one chooses to use [41].

Following [36, 37], the effective number of species \(D\) can be derived from the Shannon-Weiner entropy index :

\[D=\exp\left(S_{\tau}\right) \tag{6}\]

The Shannon-Weiner index value for a tree with all categories having equal population (478 categories in total) is about \(S_{\tau}=6.1696\). The corresponding effective number of species is then \(D=\exp(S_{\tau})=478\) which is coherent with our definition and understanding of this metric.

Hill numbers of order \(q=1\) (Shannon-Weiner diversity) are to be favored when calculating diversities without any prior information about the ecosystem (from [37], "orders higher than 1 are disproportionately sensitive to the most common species, while orders lower than 1 are disproportionately sensitive to the rare species."). Upon applying Hill diversity indices of order-1 and -2 to our dataset, we indeed find that the order-1 index allows us to gain insight into ecosystem dynamics whereas the order-2 index does not discriminate well between ecosystems. We will use the order-1 index as our diversity measure in the following.

### Simulating ecosystem growth

To try and understand some of the mechanisms behind the growth and diversification of an entrepreneurial ecosystem, we simulated the development of a startup ecosystem as described byour ontology (number of startups and amount of funding in structured categories). The incremental populating of the ecosystem was done following a simple preferential attachment model on the current state of the tree. Two main variants of the model were used :

* In the first one, the new startup is placed in category \(i\) with \(i\in[1,N]\) with probability \[p_{i}=\frac{(n_{i}+1)^{\alpha_{c}}}{\sum_{j=1}^{N}(n_{j}+1)^{\alpha_{c}}}\] (7) where \(n_{i}\) is the number of startups in each category and \(\alpha_{c}\) a free parameter of the model.
* In the second one, the new startup is created with a funding amount drawn from a powerlaw distribution with exponent \(\beta=-2\) and support \([x_{min}=10^{5},x_{max}=10^{9}]\). This new startup is then placed in category \(i\) with \(i\in[1,N]\) with probability \[p_{i}=\frac{(f_{i}+x_{min})^{\alpha_{c}}}{\sum_{j=1}^{N}(f_{j}+x_{min})^{\alpha _{c}}}\] (8) where \(f_{i}\) is the total funding of the startups in category \(i\) and \(\alpha_{c}\) a free parameter of the model.

## 3 Results and discussion

We applied our methodology to compare thirty-four ecosystems in Europe, North-America, Asia and Australia, chosen based on their prominence [12]. Figure 3 sums up the sizes in terms of number of startup companies and total funding of these ecosystems as of January the 1st, 2018 and figs. 9

Figure 3: Ecosystem sizes in terms of number of startups and total funding.

to 12 shows the mapping of some ecosystems using our visualization method. The size of the startup cells is proportional to the amount of funds they raised and the color encodes its momentum, as defined in Eq. 1. Purple means that the company went public, and the shades from red to beige represent in sequence the top 1%, 5% and 15% startups with the highest momentum. The industries are ordered from top left to bottom right following their total funding.

As expected, the funding increases with the number of startups. However, the ecosystems visually exhibit significant disparities in terms of funding allocation. For instance, while Paris hosts twice as many startups as Atlanta, the total cumulative investments in both cities are comparable (since January 1st, 2000 $9.5B in Atlanta vs $9.9B in Paris). Mapping the ecosystems might shed some light on this observation. Some, like Atlanta, Berlin or Stockholm (fig.11) appear characterized by a relatively weak diversity, related to the presence of a few champions - _unicorns_ - such as Kabbage in Atlanta, Delivery Hero in Berlin or Spotify, Klarna and iZettle in Stockholm that have raised billions of dollars. On the other hand, Paris, New York or the Silicon Valley (figs. 9 and 12) appear much more diverse, in terms of funding as well as industry.

Being able to visualize the evolution of ecosystems also captures dynamic trends. For instance, the slow fall of _Manufacturing_ in Ile-de-France is explicit in these representations, falling from 12.7% of the total investments in 2010 to 7.0% in 2018 (fig. 9). In London on the other hand, _Financial Services_ investments have skyrocketed over the same period from 10.3% of investments to 22.6% (fig. 10). It is now the biggest funding recipient in the British metropolis.

### Measured diversity

Fig. 4 shows the evolution of selected ecosystems in terms of number of startups and effective number of species between January the 1st, 2010 and January the 1st, 2018. Each of them is represented by a pair of values \(\{N(t),D(t)\}\) per year with \(N(t)\) and \(D(t)\) respectively the number of startups in the ecosystem and the effective number of species in the ecosystem at time \(t\). Diversity is computed using the funding per category (Shannon funding) for the left plot and the number of startups per category (Shannon startups) for the right plot. Diversity is higher for Shannon startups compared to Shannon funding and individual trajectories tend to be more distinct for high numbers of startups (see for instance Silicon Valley or New York), suggesting that ecosystem-specific dynamics could be at play when the ecosystem becomes sufficiently large.

Since ecosystems differ widely in terms of number of startups, it is useful to scale diversity trajectories so that the number of startups at the start and end of the measuring period are comparable. Fig. 5

Figure 4: Temporal evolution of the effective number of species as a function of the number of startups for various ecosystems between 01/01/2010 and 01/01/2018. Values of the effective number of species were computed using the entropy calculated on the funding in each category (left) and the number of startups in each category (right).

presents the standardized ecosystem dynamics _i.e._ ecosystem are characterized by value pairs \(\{\hat{N}(t),\hat{D}(t)\}\) :

\[\hat{N}(t)=\frac{N(t)-N(t_{0})}{N(t_{f})-N(t_{0})} \tag{9}\] \[\hat{D}(t)=D(t)-D(t_{0}) \tag{10}\]

with \(t_{0}\) the index of the first data point (year 2010) and \(t_{f}\) the index of the last data point (year 2018).

Using these standardized metrics, all ecosystems have similarly-shaped trajectories using Shannon startups (right plot) whereas trajectories computed using Shannon funding (left plot) seem to be more variable, probably due to the large discrepancies in individual funding amounts which can easily unbalance an ecosystem especially in early stages of development. The diversification in terms of number of startups per sector (Shannon startups) thus seems to be a more fundamental characteristic shared between all our studied ecosystems when compared to the diversification in terms of funding per sector. We will therefore use Shannon startups to compute entropy and diversity during the numerical simulations.

### Correlations to macro-economic indicators

In order to move beyond visual intuitions from the landscapes, we made use of the diversity metrics defined in the previous section. We fitted an OLS model to find correlations between the effective number of species \(D\) and macro-economic indicators retrieved from the OECD Regional Statistics [42] including :

* Wealth (GDP and GDP per capita),
* Economic vitality (Employment, GDP growth (base 2007)),
* Research intensity (% labor force with tertiary education, number of researchers per 1000p, number of patents, R&D expenses in M8 and % of GDP).

All the values are standardized by removing the mean and scaled to unit variance. As the logarithm of the number of startups explain 80% of the variance of \(D\) (\(R^{2}=0.803\)), we fit the indicators

Figure 5: Standardized temporal ecosystem trajectories. \(\hat{D}(t)\) is the effective number of species and \(\hat{N}(t)\) is the number of startups at time \(t\in[0,t_{f}]\). Values of the effective number of species were computed using Shannon funding (left) and Shannon startups (right).

against \(D(t)/log(N(t)\). By fitting this value against the previously defined indicators while still controlling for the logarithm of the number of startups, we find a correlation with the GDP per capita (p-value of \(1\cdot 10^{-3}\)). Diversity thus only seems related to the economic development and, surprisingly, not at all to the research intensity of the metropolis. However, this observation can simply be a consequence of a higher maturity of startup ecosystems in developed countries, since they have existed for a longer time.

### Simulation results

Simulation results of the two variants of the model can be found in figs. 6 and 7, with the diversity values from the simulation results (color lines) computed based on the entropy calculated using eq. 5 with the number of startups in each category (Shannon startups). We compared these values to diversity results from our dataset computed from the funding amounts (fig. 6) and the number of startups (fig. 7). These figures show that preferential attachment on the number of startups (left plots and eq. 7) seems to explain the diversification of the ecosystem up to a certain point, but that diversity is not stable as the ecosystem continues to grow _i.e._ all new startups end up concentrating in a small number of categories and the effective number of species collapses.

Preferential attachment on the category funding (right plots and eq. 8) on the other hand, seems to better match the data computed from Shannon startups and Shannon funding, as the ecosystem

Figure 6: Simulation results for preferential attachment on number of startups (left) and on category funding (right). Diversity from the dataset was computed using Shannon funding.

Figure 7: Simulation results for preferential attachment on number of startups (left) and on category funding (right). Diversity from the dataset was computed using Shannon startups.

diversity steadily increases over time using this model. Preferential attachment on the funding amounts is thus a better mechanism than preferential attachment on the number of startups in order to explain the diversification of an ecosystem throughout its growth when comparing our results to the data. In the case of Shannon funding, the data and simulation results seem to match particularly well for free parameter \(\alpha_{c}\) values around 0.8 (see fig. 8).

To check the robustness of these results, a numerical simulation variant of these models was tested where a new startup was placed in a random category with probability \(p\) and with probability \(1-p\) was placed in a category following the preferential attachment law described in sec. 2.3. No qualitative differences were found between simulations with \(0.1<p<0.25\) and \(p=0\) (the \(p=0\) case corresponds to a standard preferential attachment model as shown in figs. 6 and 7).

Fig. 8 shows that good concordance between the data points with Shannon funding (red dots) and simulation results (black line) is obtained for preferential attachment on funding with \(\alpha_{c}=0.78\).

Models of mixed preferential attachment taking into account both number of startups and total funding at the same time were tested following eq. 11 :

\[p_{i}=\frac{\theta(1+n_{i})^{\alpha_{st}}+(1-\theta)(\ln(x_{min})+\ln(f_{i}))^ {\alpha_{funds}}}{\sum_{j=1}^{N}[\theta(1+n_{j})^{\alpha_{st}}+(1-\theta)(\ln( x_{min})+\ln(f_{j}))^{\alpha_{funds}}]} \tag{11}\]

with \(\theta\) controlling the importance of funding amounts vs. number of startups and \(\alpha_{st}\) and \(\alpha_{funds}\) free parameters of the model. Simulations for a range of values of \(\alpha_{st}\), \(\alpha_{funds}\) and of \(\theta\in[0,1]\) did not provide a better match to the data than preferential attachment simply on the total category funding (fig. 6).

Finally, a simple mixed model of firm creation and growth was also confronted to the data. At each iteration of the simulation, a new startup is created with probability \(\gamma\) in category \(i\) following eq. 8 and is allocated seed funding. With probability \(1-\gamma\), a random existing startup was funded with an amount depending on its last simulated funding round and moved on to the next stage of the "alphabet round" system (_i.e._ a company that last received seed funding received series A funding, a company that last received series A funding received series B and so on). We set \(\gamma=0.5\) based on

Figure 8: Effective number of species as a function of the number of startups in the ecosystem for preferential attachment on total funding with free parameter \(\alpha_{c}=0.78\). The black line corresponds to the simulation values averaged over 100 runs, the red points correspond to the data from our dataset. Error bars corresponding to one standard deviation are shown for the simulation.

our data on the Silicon Valley ecosystem (seed rounds or "new entrants" represent approximately half of all venture funding rounds). The distribution of types of funding rounds at each stage with these parameters was found to be similar to that of our data. Simulation results from this mixed model of firm creation and growth did not give better results than the ones shown in fig. 6; the main driver between the diversification of an ecosystem then simply seems to be the allocation of fundings regardless of other ecosystem-dependant factors. The tendency of entrepreneurs to explore new industries or instead follow existing trends thus seems heavily linked to individual decisions which are particularly influenced by how financially successful the existing companies in the various categories have been.

## 4 Conclusion

In this paper, we presented a novel approach with respect to studying the emergence of startup ecosystems. Using public datasets, we first presented a novel, automated and interactive data visualization tool that facilitates the study of startup populations from an ecosystem point of view, and that also sheds light on the particularities of different ecosystems. Relatedly, diversity metrics such as the Shannon-Wiener index and the Simpson-Herfindahl index were then introduced, fostering the analogy with ecological sciences. We further tried to understand how observed diversity could emerge both by attempting to relate its disparity between ecosystems to macroeconomic indices and through numerical simulation. Our results suggest that the increase in diversity during the growth of a startup ecosystem can be explained through the sequential allocation of funding to startups in given sectors, thanks to a simple preferential attachment model, rather than by macro-economic indicators with the exception of economic development: i.e., startup ecosystem diversity appears as the outcome of emerging and aggregated behaviours rather than linked to ecosystem-specific characteristics or decisions. Needless to say, this analysis of ecosystem diversity remains preliminary and deserves further analysis, not only on a larger sample of ecosystems but also with a focus on events: for instance, linking "diversification" events, i.e. sectors getting a rather sudden and large influx of new startup creations, to specific "breakthroughs" - either technological, as was recently the case with deep learning, or business-oriented, as has been seen with respect to _Food Delivery_ - could typically give valuable insights into startup ecosystem diversity and diversification.

[MISSING_PAGE_EMPTY:13]

[MISSING_PAGE_EMPTY:14]

[MISSING_PAGE_EMPTY:15]

Figure 12: Maps of New York and the Silicon Valley on 2018 Jan 1st.

## References

* 1. Hannan MT, Freeman J. Organizational Ecology. Cambridge, Harvard University Press. 1993.
* 2. Moore JF. Predators and prey: a new ecology of competition. Harvard Business Review. 1993;71(3):75-86.
* 3. Schot J. The usefulness of evolutionary models for explaining innovation: The case of the Netherlands in the nineteenth century. History and Technology. 1998;14(3):173-200.
* 4. Gilbert, McDougall, Audretsch. The Emergence of Entrepreneurship Policy. Small Business Economics. 2004;22(3-4):313-23.
* 5. Minniti M. The Role of Government Policy on Entrepreneurial Activity: Productive, Unproductive, or Destructive?. Entrepreneurship Theory and Practice. 2008;32(5):779-790.
* 6. National Venture Capital Association / Thomson Reuters, Venture Capital Fundraising tops $10 Billion in Q2, Recording Strongest Quarter Since 2007 [Internet]. 2018 January. Available from: [https://nvca.org/pressreleases/venture-capital-fundraising-tops-10-billion-in-q2-recording-strongest-quarter-since-2007/](https://nvca.org/pressreleases/venture-capital-fundraising-tops-10-billion-in-q2-recording-strongest-quarter-since-2007/).
* 7. Birch D. Job Creation in America: How Our Smallest Companies Put the Most People to Work. University of Illinois at Urbana-Champaign's Academy for Entrepreneurial Leadership Historical Research Reference in Entrepreneurship. 1987.
* 8. Thurik R, Wennekers S. Linking entrepreneur and economic growth. Small Business Economics. 1999;13(1):27-56.
* 9. Wong PK, Ho YP, Autio E. Entrepreneurship, Innovation and Economic Growth: Evidence from GEM data. Small Business Economics. 2005;24(3):335-50.
* 10. Hawaii Strategic Development Corp. HI Growth Initiative [Internet]. 2018 January. Available from: [http://hsdc.hawaii.gov/hi-growth-initiative/](http://hsdc.hawaii.gov/hi-growth-initiative/).
* 11. Las Vegas Sun. Tax incentives of $215.9 million approved for electric car company Faraday Future [Internet]. 2016 Jan 22 [cited 2018 Jan]. Available from: [https://lasvegassun.com/news/2016/jan/22/tax-incentives-of-2159-million-approved-for-electr/](https://lasvegassun.com/news/2016/jan/22/tax-incentives-of-2159-million-approved-for-electr/).
* 12. Slush Report 2017 [Internet]. 2018 January. Available from: [https://2017.stateofeuropeantech.com/](https://2017.stateofeuropeantech.com/).
* Dow Jones [Internet]. 2018 January. Available from: [https://www.dowjones.com/products/pevc/](https://www.dowjones.com/products/pevc/)
* 14. TechCrunch. The latest technology news and information on startups [Internet]. 2018 January. Available from: [https://techcrunch.com/](https://techcrunch.com/).
* 15. CB Insights. Tech market intelligence [Internet]. 2018 January. Available from: [https://www.cbinsights.com/](https://www.cbinsights.com/).
* 16. Drieux P. FinTech Landscape [Internet]. 2018 January. Available from: [https://www.vbprofiles.com/l/fintech](https://www.vbprofiles.com/l/fintech)
* 17. Strachman P. French AI Ecosystem [Internet]. 2018 January. Available from: [http://franceisai.com/startups/](http://franceisai.com/startups/)
* 18. Dalle J-M, den Besten M, Menon C. Using Crunchbase for Economic and Managerial Research. OECD Science, Technology and Industry Working Papers.
* 19. Meyer, Libaers M, Thijs D, Grant B. Origin and emergence of entrepreneurship as a research. Scientometrics. 2014;98(1):473-85.

* 20. Chandra Y. Mapping the evolution of entrepreneurship as a field of research (1990-2013): A scientometric analysis. PloS One. 2018;13(1):e0190228.
* 21. Gastaud C, Lacroix T, Taub R, Dion G, Dalle J-M. A Data-driven Approach To Measuring Diversity In Startup Ecosystems. R&D Management Conference 2018.
* 22. Crunchbase Inc. Crunchbase: Discover Innovative Companies and People behind Them [Internet]. 2018 January. Available from: [https://www.crunchbase.com/](https://www.crunchbase.com/)
* 23. Dealroom.co. Data-driven intelligence on high-growth companies [Internet]. 2018 January. Available from: [https://dealroom.co/](https://dealroom.co/)
* 24. Gompers P, Lerner J. The Venture Capital Cycle. Cambridge, MIT Press. 2006.
* 25. Batista F, Carvalho JP Text based classification of companies in CrunchBase. Fuzzy Systems (FUZZ-IEEE), 2015.
* 26. Carrot Search CarrotSearch [Internet]. 2018 June. Available from: [https://carrotsearch.com/foamtree/](https://carrotsearch.com/foamtree/)
* 27. Shneiderman B, Plaisant C. Treemaps for space-constrained visualization of hierarchies Including the History of Treemap Research at the University of Maryland [Internet]. 2014 Sep 9 [cited: 2018 May 7]. Available from: [http://www.cs.umd.edu/hcil/treemap-history/index.shtml](http://www.cs.umd.edu/hcil/treemap-history/index.shtml).
* 28. McCann KS. The Diversity-Stability debate. Nature. 2000;405:228-33.
* 29. Gilchrist DA, St Louis LV. Directions for diversification with an application to Saskatchewan. Journal of Regional Science. 1991;31(3):273-89.
* 30. Dissart J-C. Regional economic diversity and regional economic stability: research result and agenda. International Regional Science Review. 2003;26(4):423-46.
* 31. Kurre JA, Weller BR. Interindustry Covariance Patterns: Too Unstable for Portfolio Variance Analysis to be a Useful Tool?. Economic Development Quarterly. 1996;10(1):91-103.
* 32. Kort JR. Regional Economic Instability and Industrial Diversification in the U.S. Land Economics. 1981;57(4):596-608.
* 33. Pielou. Ecological Diversity. New York, Wiley. 1975
* 34. M. O. Hill. Diversity and evenness: a unifying notation and its consequences. Ecology, Vol. 54, No. 2. (Mar., 1973), pp. 427-432.
* 35. Simpson. Measurement of diversity. Nature. 1949;163(4148):688.
* 36. L. Jost. Entropy and diversity. Oikos 113 (2), 363-375.
* 37. L. Jost. Partitioning diversity into independent alpha and beta components. Ecology 88 (10), 2427-2439
* 38. Herfindahl OC. Concentration in the steel industry. Doctoral dissertation, Columbia University. 1950.
* 39. Shannon C. A Mathematical Theory of Communication. Bell System Technical Journal. 1948;27(4):623-56.
* 40. Gibbs. Elementary principles in statistical mechanics. 1902.
* 41. Agapow PM. The impact of species concept on biodiversity studies. The Quarterly Review of Biology. 2004;79(2):161-79.
* 42. OECD Regional Statistics 2019 March [https://doi.org/10.1787/region-data-en](https://doi.org/10.1787/region-data-en)

Title: Improving the performance of early-stage software startups: Design and
  creativity viewpoints
Transcription: JYU DISSERTATIONS 399

Juhani Risku

Improving the Performance

of Early-Stage Software Startups

Design and Creativity Viewpoints

UNIVERSITY OF JYVASKYLA

FACULT OF INFORMATION

TECHNOLOGYJvU DISSERTATIONS 399

Juhani Risku

Improving the Performance

of Early-Stage Software Startups

Design and Creativity Viewpoints

Esitteaan Jyvaskylan yliopiston informaatioteknologian tiedekunnan suostumuksella julkisesti tarkasetttavaksi kesakuun 9. paivana 2021 kello 12.

Academic dissertation to be publicly discussed, by permission of the Faculty of Information Technology of the University of Jyvaskyla, on June 9, 2021 at 12 o'clock.

JYVASKYLAN YLIOPISTO

UNIVERSITY OF JYVASKYLEditors

Marja-Leena Rantalainen

Faculty of Information Technology, University of Jyvaskyla

Ville Korkiakangas

Open Science Centre, University of Jyvaskyla

Cover picture: Cynefin framework applied in Article II; Tetra framework applied in Article II; Rankkasauna, Harsh Sauna, house concept 1992; RodMobile, electric car concept 2016-2021.

Copyright (c) 2021, by University of Jyvaskyla

ISBN 978-951-39-8714-5 (PDF)

URN:ISBN:978-951-39-8714-5

ISBN 2489-9003

Permanent link to this publication: [http://urn.fi/URN:ISBN:978-951-39-8714-5](http://urn.fi/URN:ISBN:978-951-39-8714-5)

## Abstract

Risku, Juhani

Improving the performance of early-stage software startups: Design and creativity viewpoints

University of Jyvaskyla, 2021, 148 p. + included articles

(JYU Dissertations

ISSN 2489-9003; 399)

ISBN 978-951-39-8714-5 (PDF)

Over the last 20 years, a very large number of startups have been launched, ranging from mobile application and game providers to enormous corporations that have started as tiny startups. Startups are an important topic for research and development. The fundamentals of success are the characteristics of individuals and teams, partner investors, the market, and the speed at which everything evolves. Startup's business environment is fraught with uncertainty, as actors tend to be young and inexperienced, technologies either new or rapidly evolving, and team-combined skills and knowledge either key or fatal. As over 90% of software startups fail, having a capable and reliable team is crucial to survival and success.

Many aspects of this topic have been extensively studied, and the results of the study on human capital are particularly important. Regarding human capital abilities, such as knowledge, experience, skills, and other cognitive abilities, this dissertation focuses on design skills and their deployment in startups. Design is widely studied in artistic and industrial contexts, but its application to startup culture and software startups follows its own method prison. In the method prison, old and conventional means are chosen instead of new techniques and demanding design studies. This means that when a software startup considers design as a foundation for creativity and generating better offerings, they can grab any industry with a disruptive agenda, making anything software-intensive. The concept of design can be expanded and deepened to a new level. Business can escape the method prison if it adopts artistic design to help stagnant industries and uses disruptive methods with realistic self-efficacy.

Through five partially overlapping articles with varying details, this dissertation clarifies the daily themes and interests of startups required to survive and succeed. This dissertation is a reflective practitioner's investigation of startup practices using a mixed-methods approach. With design-based creativity, startups will be stronger and more successful in the future. They can cause or protect themselves from disruption. Startup can retain customers and its self-efficacy strengthen.

Keywords: startup, software engineering, design, creativity, self-efficacy, disruption, retention, gamification, game industry, method prison, media industry, network manufacturer, network operator, architecture

## Tiivistelma (ABSTRACT in Finnish)

Risk, Juhani

Ohjelmistoalan startup-yritysten suorituskyvyn parantaminen suunnittelun ja luovuuden avulla

Jyvaskylan yliopisto, 2021, 148 s. + alkuperaiset artikkelit

(JYU Dissertations

ISSN 2489-9003; 399)

ISBN 978-951-39-8714-5 (PDF)

20 viime vuoden aikana startup-yrityksia on perustettu erittain suuri maara. Tassa joukossa on mobilisovellusten ja pelien tekijoita mutta myos suuryrityksia, jotka ovat aloitaneet pienina startupeina. Startupit ovat rakea aihe tutkimusessa ja kehitystyossa. Menestyksen perustekijoita ovat yksiloiden ja timien omnaisuudet, kumppanina toimivat sijoittajat, markkinat seka yleinen nopea kehitys. Startup-yrityksen liiketoimintaymparisto on taynna epavarmuutta, silla toimijat ovat yleensa nuoria ja kokemattomia, teknikat uusia tai nopeasti kehittyvia, ja tiimin yhdistetyt taidot ja tiedot menestykekkaita tai tuhoisia. Koska yli 90% ohjelmistostartupeista epaonnistuu, kykeneva ja luotettava tiimi on ratkaisevan tarkea menestymisen kannalta.

Aihetta on tutkittu palon ja varsinkin inhimillista paaomaa koskevan tutkimuksen tulokset ovat vakuuttavia. Tassa vaitoskirjassa keskitytaan tietoon, kkemuksinin, taitoihin ja muihin kognitivisiin kykyihin, joihin design-taidot ja niiden kayto Iiittyvat. Suunnittelua tutkitaan laajalti taiteellisessa ja teollisessa konteksissa, mutta sen soveltaminen startup-kulttuurin ja ohjelmistojen startup-yrityksinin tapahtuu omassa menetelmavankilassa (method prison). Menetelmavankilassa otetaan kayttoon vanhoja ja perinteisia keinoja uusien tekniikoiden ja vaativien suunnittelututkimusten sijaan. Jos ohjelmistoyritykset ottavat designin perustaksi luovuudelleen, ne voivat tarjota paremman tuotevalikoiman. Ne voivat tarttua mihin tahansa teollisuuden ala disruptivisella agendalla ja tehda kaikesta ohjelmistointensiivista. Samalla designin kasitetta voidaan laajentaa ja syventaa uudelle luovuuden tasolle. Nain voidaan myos paeta menetelmavankilasta.

Tama vaitoskirja selventaa monimenetelmallisen tutkimuksen keinoin vijdessa artikkelissa, miten startupit voivat selviytya ja menestya paremmin pavittaisssa toimissa. Tutkimus tuottaa vahvempia ja menestyvampia startup-yrityksia design-keskeisen luovuuden avulla. Samalla ne voivat aiheuttaa disruptiota tai suojautua silla. Startup-yritykset voivat pitaa asiakkaansa ja niiden mniapystyvyys vahvistuu.

Avainsanat: startup, ohjelmistosuunnittelu, design, suunnittelu, luovuus, minapystyvyys, disruptio, asiakkaan sailyttaminen, pelaaminen, peliteollisuus menetelmavankila, mediateollisuus, verkonvalmistaja, verkko-operaattori, arkitehtuuri

**Author**

Juhani Risku

Faculty of Information Technology

University of Jyvaskyla

Finland

juhani.risku@jyu.fi

ORCID 0000-0002-0587-4431

**Supervisors**

Pekka Abrahamsson

Faculty of Information Technology

University of Jyvaskyla

Finland

Tuure Tuunanen

Faculty of Information Technology

University of Jyvaskyla

Finland

**Reviewers**

Kari Systa

Faculty of Information Technology and Communication Sciences

Tampere University

Finland

Pertti Seppanen

Faculty of Information Technology and Electrical Engineering

University of Oulu

Finland

**Opponent**

Sami Hyrynsalmi

School of Engineering Science

Lappeenranta University of Technology

Finland

## 6 Foreword

It is all about lifelong learning. For me, my dissertation is a milestone in an extensive round. I began my academic studies at the University of Jyvaskyla at the Department of Mathematics and Physics in 1976. A year later, I moved to architecture at Tampere University of Technology, where I graduated as an architect. I had already started an apprenticeship as a turbine mechanic, which laid the foundation for my craftsmanship and Arts & Crafts skills.

Later I studied at Nokia Corporation and its Learning Center industrial design and brand management to take part in usability and user experience design. Just before starting my doctoral studies in Jyvaskyla, I had been an apprentice for 15 masters' of machinery, acoustics, photography, ceramics, carpentry, stone masonry, forestry, stained glass, architecture and city planning. The University of Jyvaskyla finally took me to science. I systematically and scientifically caught up with everything I had done in practice, such as industrial and graphic design, user interface design, and design science. In fact, I was able to understand retrospectively the rationale, background, and future to deepen my practical work.

I was lucky to get Professor Pekka Abrahamsson as my supervisor for my doctoral studies. He is a creative, prolific and visionary scientist and leader. Simultaneously with his scientific input, he leads the Startuplab of the University of Jyvaskyla, where new products, services and solutions are created. While the work of the startup lab is at the crest of disruption and scientifically justified, we have fun in the lab. Professor Abrahamsson is known for taking on all challenges, while at the same time developing new ways of working and leading by example. He always answers yes if you have to tackle a wicked problem, and solves it. I want to thank Professor Pekka Abrahamsson for his tireless support and inspiration for both study and design. Through him, civil courage is transmitted to both science and the development of services, products and new futures.

My other supervisor, Professor Tuure Tuuranen, is a special case of the university: he is a multidisciplinary entrepreneur and scientist. In addition, he is a well-known expert in a discipline close to myself, design science. The origins of design science lie in the architects' quest for a systematic approach to design. Under the leadership of Professor Tuuranen, I was able to taste design science. I want to thank Professor Tuure Tuuranen for his always happy and sympathetic support.

I want to thank all the researchers and students of the University of Jyvaskyla startup laboratory. There could be no better community around shared enthusiasm. There is always a huge bustle in the Startup Lab. It hurts and happens all the time, each of which gets stimulated and the shared joy grows. I found myself young in the same team where the others are 35 years younger. There is something wonderful and peculiar going on all the time that we are researching and making science into. Special thanks to Johannes Impio, who finds everything and even more on the internet and makes it a company, video or creative concept. He is a graphic master of notes. I want to thank Johannes for his dailydetermination to either do business, videos or music. Everything goes. Doctoral student Kai-Kristian Kemell is a person that everyone would need to cope with visions, practice and diligence in science. He saves his scientific partner with his superior diligence. He is also the most credible performer. I want to express my utmost gratitude to my multitalented colleague Kai-Kristian for his example in thorough and diligent research.

I have had the luxury of joining the multidisciplinary research and development community of the University of Jyvaskyla. Special thanks to Dr. Elina Jokinen, the most inspiring and cheerful teacher for both writing and communicating about science. During Elina's courses, I met a wide range of people from different faculties and interest circles. An entire university can be built around her. I want to thank research assistant Marja-Leena Rantalainen. Because of her, our university stands stable, and processes run. I also want to thank political scientist Ms. Outi Alapekkala, Sciences Po Paris, our native French from the Arctic Lapland. We wrote together an impressive article about restructuring the media. It changes everything in the media business.

In the end, I wrote my dissertation mainly in the art center Jarvilinna, Laukaa, in Central Finland. Its generous heart and inspiring atmosphere, as well as working with Kauko Sorjonen and the artists of the art center, made my work a celebration. Thank you!

I have received strength and courage late from my father, who graduated with a high school diploma at the age of 69 and a master's degree in economics at the age of 75. My mother is still my best supporter, and she always finds an understanding perspective on situations. My warmest thanks to them for the best starting points for studying and science!

My daughter Sade Risku has encouraged me in my last year of saving so that science got "our universal dancer" on its occasion. One day, she will surely dance in the realm of science. My son Pasi Risku and his extended family have always supported my even strange actions with understanding. I want especially like to thank my loved one, Mirja Nylander, who has been following my work throughout the scientific research trip, supporting and facilitating it. Being both a forester and an agricultural and forestry scientist, Mirja, as a farmer's daughter, knows what hard work is. She is also one of the masters in my field of study during my apprenticeships. Mirja has taught me how to sharpen and use a chainsaw, and identify tree species, not to mention forest biology. I got more than most of it. She earths and encourages people to make ever-nobler endeavors. A new order is soon coming to forestry. Thank you, Mirja!

Jyvaskyla 25.5.2021

Juhani RiskuList of included articles

* Risku & Abrahamsson (2015) Risku, J. & Abrahamsson, P. (2015). What can software startuppers learn from the artistic design flow? Experiences, reflections and future avenues. In Abrahamsson, P., Corral, L., Oivo, M. & Russo, B. (eds.), _Product-Focused Software Process Improvement: Proceedings of the 16th International Conference PROFES 2015_ (pp. 584-599). Lecture Notes in Computer Science, 9459. Springer, Cham.
* Risku & Alapekkala (2016) Risku, J. & Alapekkala, O. (2016). Software startuppers took the media's paycheck: Media's fightback happens through startup culture and abstraction shifts. In _2016 International Conference on Engineering, Technology and Innovation/IEEE International Technology Management Conference (ICE/ITMC)_ (pp. 1-7). IEEE.
* Kemell et al. (2018) Kemell, K-K., Risku, J., Evensen, A., Abrahamsson, P., Dahl, A. M., Grytten, L. H., Jedryszek, A., Rostrup, P. & Nguyen-Duc, A. (2018). Gamifying the escape from the engineering method prison. In _2018 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC)_ (pp. 1-9). IEEE.
* Risku et al. (2020) Risku, J., Kemell, K-K., Schweizer, S., Nguyen-Duc, A., Suoranta, M., Wang, X. & Abrahamsson, P. (2020). What makes a digital game addictive? A player viewpoint on player retention. Accepted to be presented at 2020 IEEE International Conference on Engineering, Technology and Innovation (ICE/ITMC). 1 Footnote 1: The paper was peer reviewed and accepted, but not included to the proceedings due to an obstacle to participate the presentation caused by the corona pandemic. Currently, the work is an unpublished manuscript that will be submitted to a conference.
* Risku et al. (2020) Risku, J., Kemell, K-K., Kultanen, J., Feshchenko, P., Careles, J., Korpikoski, K., Suoranta, M. & Abrahamsson, P. (2020). Exploring the relationship between self-efficacy and creativity: Case IT & business education. To be submitted.

In Articles I, II and V the author was responsible of designing the research, gathering the research data, analyzing the data, and drawing the conclusions. In Article III, the author was in charge of board game design and realization, user experience and usability. In Article IV, the author was in charge of the game design specific objects, the influence of self-efficacy and creativity in gaming context when playing and designing games, and the impacts of retention in game design.

[MISSING_PAGE_EMPTY:10]

[MISSING_PAGE_EMPTY:11]

###### Contents

* 1 INTRODUCTION
	* 1.1 Motivation
	* 1.2 Research questions
	* 1.3 Structure of the dissertation
	* 1.4 Other scientific contributions by the author
* 2 THEORETICAL BACKGROUND
	* 2.1 Software startups
		* 2.1.1 Definition of software startups
		* 2.1.2 Challenges that software startups face
		* 2.1.3 How a software startup succeeds?
		* 2.1.4 Life-cycle of a software startup
		* 2.1.5 Internal startup
		* 2.1.6 Antipatterns
	* 2.2 Essence in software engineering
		* 2.2.1 Background and motivation for Essence
		* 2.2.2 The core framework model
		* 2.2.3 Activity spaces and competencies
		* 2.2.4 Alphas and their relations
		* 2.2.5 Essentialization of a practice
		* 2.2.6 Known issues in the Essence model
	* 2.3 Design viewpoints
		* 2.3.1 Definition of design
		* 2.3.2 Design in software startups
		* 2.3.3 Design in software engineering
		* 2.3.4 Design dynamics in Cynefin framework
	* 2.4 Creativity in focal contexts
		* 2.4.1 Definition of creativity
		* 2.4.2 Creativity in different contexts
		* 2.4.3 Measuring creativity
		* 2.4.4 Creativity and self-efficacy
		* 2.4.5 Creativity in software engineering
	* 2.5 Research gaps by RQs
* 3 RESEARCH METHODOLOGY
	* 3.1 Research approach

[MISSING_PAGE_EMPTY:13]

Introduction

This chapter describes the research area of this dissertation, and introduces the main concepts of the focus areas. An outline of the structure of this dissertation is also presented.

### Motivation

Software startups have significant implications for innovation and economies. These implications have an extensive impact on people, specifically users who adopt their products. Multiple corporations have a history as startups: Apple, Google, Facebook and Microsoft originated as startups. Now they are global actors in the software industry, developing various technologies, including smartphones, computers, applications, search engines and social media platforms (Dolata 2017). The dynamics of software startups can be seen in the cases of Google and Facebook, which are also advertising and marketing companies. Their platforms are interesting for advertisers because of the enormous number of users. Equally, Amazon, Booking.com and Airbnb, being commercial or mediation platforms, have grown to have a large user base (Rochet et al. 2003).

A software startup is a company that creates high-tech software products and services. The company's nature is to be a temporary organization. The nature of the company is that it has little or no operational experience and tries to grow fast and scale its business in extremely scalable market areas (Giardino et al. 2014). Through software startups, the release of new markets, approachable technologies and venture capital globally is actualized (Blank 2005). Startup companies that become successful businesses, like Facebook, LinkedIn, Spotify, Instagram, Groupon and Dropbox, began as fresh technological adventures. Still, many startups fail before achieving their business prospects (Crowne 2002). More than 90% of startups fail, mainly because of self-destructiveness, not competition (Marmer et al. 2011).

One of the main challenges for a startup is to find the right people for all roles, including the core team, management and investors (Seppanen, 2018). In the initial core team, there are three roles: the founder, the expert and the implementation team member. In different startups, founders may have the role of expert and the implementation team member simultaneously. The founder's personal capabilities lead to role plurality, carrying out multiple roles in a top-down direction from the founder to the expert and the implementation team member. This is obvious to founders with deeper and broader capabilities (Seppanen, 2018). Marvel et al. (2007) divide the founders' praxis into experience depth and experience breadth (Marvel et al., 2007).

The core tasks of a software startup are to execute and manage the creation and delivery of software-intensive products of high value. Product and software engineering practices are key components of the performance and success of the startup. The notions "engineering performance" and "success" need to be specified in the software startup context (Klotins, 2019).

In this dissertation, startups have their origin in creativity, innovation and design, the attitude and spirit to find something new and to quickly realize the idea and launch it broadly for public use. The general idea of initial concepts and active ways of working scales from software startups to startups in different industries and trades, moving to a software-intensive mode. All these startups orchestrate their work through software in the form of applications, Web-based solutions and system-level platforms.

The author's personal motivation to research creativity, innovation and design as a reflective practitioner is based on their background in various professional activities. Thirty years of sketching, drawing, conceiving, sculpting, and prototyping and building houses, furniture, prototypes, pieces of art and societal systems has taught the author that systems, objects and details slide into one another and scale in their structure. The only common factor seems to be the qualities of the creators and designers: eagerness to ideate and conceptualize, diligence to craft and iterate, and determination to finish the functionality, form and beauty of the artifact.

Curiously, the winterization of a Segway in Lapland, and riding with it in Murmansk, coroneted the author's career as a designer (Figure 1). The project proved that anything is possible, even when there is a meter of snow, and it is -32\({}^{\circ}\)C in the shade.

The qualities above are those of the startuppers. JYU Startuplab as a home base for the author, is a fruitful environment for further research of creation and design. Research is the evidence and assistance for the development to combine practical design and research of startups.

This dissertation is a horizontal and a detail-system and creation-research product of startuppers' actions in various contexts. Despite the scales or approaches of the research subjects, visions, creativity, innovation and research can be built into the workflow. As designers approach the next assignment, they act as both a researcher and a startupper.

Outcomes from Articles' I-V initiatives with different staring points and processes come to a common and compatible conclusion: startup spirit, as an approach and attitude, scales and motivates to creativity and design to any given task. This dissertation uses a mixed-methods approach with a reflective practitioner's viewpoint. Thus, qualitative and quantitative techniques alternate be-tween the articles and are reflected in the summary (Wu 2011).

Creativity is extremely complex and manifold scientific subject with connections to any matter (Mumford et al. 1988). Creativity has also been ignored as a research problem because of its mystical dimension and spiritual nature, which are not easily adopted in the academic environment (Blumenthal 1980). When Haeberlin (1916) expresses, that "all psychic phenomena are, therefore, creative products of synthesis: they are, when seen from this point of view, acts of will" (Haeberlin 1916), the educated and experienced reflective practitioner can feel the meaning of will, but the notion needs research to be applied to wider creation contexts. One fundamental motivation arose from the expression of Smith et al. (1979) "noncreative people tend to maintain one single interpretation. In order to be creative, regardless of the subject area, the individual must be able to go beyond the conventional interpretations of reality" (Smith et al. 1979). The word noncreative triggers the scientific motivation in form "am I creative or noncreative", can creativity be defined both by practical outcomes and spiritual existence, simultaneously. The fuzziness of creativity motivates to understand creativity as a human capability, a verb to generate something, and to research the meaning of the notion.

Figure 1: Winterization of Segway (generated by the author, 2010)

### Research questions

The general purpose and scope of this dissertation are to clarify the nature of software startups creating, surviving and succeeding in different phases, cases and industries. Design as an umbrella term during all phases of the startup's product development flow, is a factor enabling companies reach their own exceptional competitive factor compared to competitors (Cirjevskis, 2016). As critical success factors for design startups, Kim et al. (2018), lists 1) Entrepreneur's ability, philosophy, and leadership to lead the design startup business success, 2) Idea and innovative capability to make or lead the new market for the success of the design startup business, 3) Technology, product, and business modeling capability of the design startup business success, and 4) Funding and financial ability to lead the design startup business success (Kim et al., 2018). This approach offers a set of conditions, environments, requirements and progression patterns from early-stage startups in the game industry to successful ones that made an enormous exit, either they go public or are acquired by another firm. The startups, in case of success, can continue with superb service and solution offerings and grow independently.

A startup requires ideas, skills to develop concepts and financial and business support from experienced parties in order to succeed. The human factors - both the team and their personal qualities - are crucial to startups. A startup is in an ambivalent arrangement: it has a contradictory setting of a highly demanding business environment and technological challenges but has a temporary nature, little or no experience, a lack of resources, possibly technical debts and an incomplete team (Giardino et al., 2016; Klotins, 2018).

The main research question is:

* How to improve the performance of software startups?

The research questions are defined as follows:

* How can design and creativity viewpoints support early-stage startups to develop their ideas to concepts better? (Articles I, II, and V)
* How can software startups develop their processes for better customer retention? (Articles III and IV)
* How can creativity be enhanced in software startups? (Articles III and V)

In the following section the articles and their connection to each other is explained.

### Structure of the dissertation

As stated earlier, scientific motivation for this dissertation Creativity as a notion, characteristic and concept is a praised and required entirety in the arts, design,education, at the Academia and industries. This is motivating in practice and scientific circumstances. The research consists of five articles that horizontally cover software startups' actions in different domains, circumstances and ways of working. The cases present a broad granularity of businesses, roles of the startups, their internal capabilities and various sets of customers, users, markets and futures. This is what startups face during their life-cycle.

Article I presents a design approach borrowed from art and design cultures, which have developed practices and skillsets that are still in wide use throughout industries. Even an ancient design culture, with its methods, practices and people, can affect startups' survival and success when it is implemented in the culture. A set of actions is presented as an alternative avenue for change. Article I answers to the RQ1 by emphasizing the importance of design skills and utilization of design processes. These are largely used in the Arts, architecture and various design domains, and civil engineering. The importance of creativity and design for startups is crucial, when they have to propose new and unique concepts to survive on the markets. The skillset of various design areas is advisable, because the development speed is fast. Here all communicative means help to ensure the startups' credibility.

Article II describes how software startups grow and cause disruption in global businesses. Later, a startup may face threats from disruptive actions targeted by the underdog parties. The article envisions and builds a strategy to challenge the present-day market leaders using the Cynefin framework to determine actions, their order and consequences for the future. This challenge is seen as a medium for a single startup or internal startup. Article II answers to the RQ1 by encouraging the early-stage startups, on the contrary to the three industrial conglomerates from the mobile network manufacturers, network operators and media houses, the startups bravely challenge the industries by bypassing the problems of three conglomerates. Then the startups can establish something what industries have not done before. Young early-stage startups have several advantages on their side: nobody believes that a novice can penetrate the billion dollar industries with a brilliant concept.

In Article III, the Essence theory included in SEMAT is strengthened through an educational game. SEMAT is a theory of restructuring software engineering to have common ground and punctual rigorous discipline. SEMAT represents a library of practices that form a software development kit with drawings and set of modules to fit any software development cases. To create educational offerings for software engineering students, it is important to enable studies on and dynamic access to the development of structured software. Article III describes a gamified development initiative to create a board game for educating software development and its project management practices. The Essence theory of software engineering as part of the SEMAT initiative, with the ever-present threat of method prison, was also recognized. The board game showed that software development processes can be treated dynamically and situationally rather than monolithically and exclusively. The game flow proceeded through the team's interactive aspirations, ending with a common understanding of dynamic and varying paths while fulfilling the robust target with various alternatives in the team process. For this thesis, Essence-theory provides the mechanism, language and notation to Essentialize practices for startups to use. Article III answers to RQ2 and RQ3 by process development factors: startups in the context of game development, profit from comprehensive design of the balance principle, rewards and how different playstyles and ingame activities effects, and advance social interactions and feelings of achievement as aspects of the game. The question of escaping the method prison is twofold: to free oneself from the method prison, is a function of skills and creativity, and how professionally to utilize the skills in design, and creatively to use development processes.

Article IV describes user and customer retention, specifically player2 retention in the digital game industry. User retention can be seen as a fundamental factor in any business where a product or service is offered. It presents a threat to the achieved status of a business in a highly competitive market. The article studied the startups' role in ensuring that game elements keep players playing the game. In the article, motivation was studied through rewarding players. These two factors, customer retention and motivation through rewards, are generally important for any business and are highlighted in startups' product creation. Article IV answers to RQ2 by findings that help startup design processes in game design, where multiple factors must be exploited: 1) fine-tuning the rewards, 2) test emotions through achievements by in-house play, and 3) try in advance the game styles, in-game activities, and exploration. By taking these factors into account in the design process, startups can ensure better customer retention as players continue to play and eagerly return to the game.

Footnote 2: In this thesis player is a key stakeholder in the digital game industry and referred to as a customer or a player, depending on the given context.

Article V describes how creativity is correlated with self-efficacy among students according to self-efficacy questionnaire results and design work evaluations. According to the results, self-efficacy and creativity were not clearly correlated. In addition, against the presumptions, seasoned and skillful students in design achieved only medium scores in self-efficacy, which may demonstrate realism and self-critique when comparing oneself to designers in general. Article V answers to RQ1 and RQ3 by evaluating the design skills reflected to creativity and self-efficacy. The design skills were in focus when evaluating the creativity of the students through practical design projects, where visualization and conceptual ideas were emphasized. This combined both RQs by the importance of a design skillset that is useful in planning concepts and visualizing the design.

The summary part of the thesis is structured as follows. Section 1describes the idea of software startups and startups in general, through the common aspects of innovation, creativity and design. In Section 1, the author's motivation is explicated with a brief personal description, where the approach and attitude in the workflow and the memorable highlights of the author's professional career emphasize the role and nature of a reflective practitioner within scientific research. In this section, the research scope and objective are explained, and the research questions are structured.

Section 2 defines the software startup as a phenomenon and presents an overview of the challenges that startups face over their lifetime. The means of success are analyzed as meaningful motivations for startups. Because startups are on their way to an established state of entrepreneurship or either going public or been acquired, their life-cycles are studied. An overview of corporative internal startups is presented because they are a medium in which large systemic constructs can be built. Large, complex solutions are highly disruptive and barely possible for small, early-stage startups. Antipatterns, the unfortunate products without customers, are explained in this section.

Section 3 presents the scope of the research and the research methodology. In the five articles of the dissertation, the multifaceted nature of startups and their subjects of creation and development are described. The idea of a reflective practitioner is analyzed and seen as a practically oriented scientific researcher. Typically, surgeons base their professionalism in science and practice. In the best-case scenario, they derive new scientific findings from their practical experience of drilling inside people.

Section 4 summarizes the original publications. Findings and connections to the objectives of the dissertation are presented. Creativity can be seen as a holistic process throughout a workflow, and product creation and design can be considered practical actions. Creativity can also be seen as a disruptive counteraction for friendly revenge, challenging competitors. This happens across businesses and industries all the time. Soft-ware development is filled with processes and the needs of management. Using various self-created processes instead of one rigid procedure is important for startups. In addition, continuously attracting and winning back customers is crucial. Startups require strategies for customer retention. Finally, creativity and self-efficacy are significant qualities for startuppers. Still, it is not self-evident that they are linked in a realistic way.

Section 5 collects the results of the dissertation to describe the future of startups in ever-demanding businesses. Design practices help startups to act more professionally in the turbulence of a competitive environment. Theoretical and practical contributions are described, limitations explained and future research envisioned.

### Other scientific contributions by the author

This section lists other scientific articles by the author related to this dissertation. These articles contributes directly to the software startup culture and software engineering practices:* [1] Kemell, K.-K., Elonen, A., Suoranta, M., Nguyen-Duc, A., Garbajosa, J., Chanin, R., Melegati, J., Rafiq, U., Aldaeej, A., Assyne, N., Sales, A., Hyrynsalmi, S., Risku, J., Edison, H., & Abrahamsson, P. (2020). Business model canvas should pay more attention to the software startup team. In _SEAA 2020: 46th Euromicro Conference on Software Engineering and Advanced Applications_, pp. 342-345. IEEE.
* [2] Kemell, K.-K., Risku, J., Strandjord, K.E., Nguyen-Duc; A., Wang, X., & Abrahamsson, P. (2020). Internal software startups: A multiple case study on practices, methods, and success factors. In _SEAA 2020: 46th Euromicro Conference on Software Engineering and Advanced Applications_, pp. 326-333. IEEE.
* [3] Kemell, K.-K., Feshchenko, P., Himmanen, J., Hossain, A., Jameel, F., Puca, R.L., Vitikainen, T., Kultanen, J., Risku, J., Impio, J., Sorvisto, A. & Abrahamsson, P. (2020). Software startup education: Gamifying growth hacking. In _Fundamentals of Software Startups: Essential Engineering and Business Aspects_, pp. 269-277. Springer.
* [4] Kemell, K.-K., Nguyen-Duc, A., Wang, X., Risku, R. & Abrahamsson, P. (2020). Software startup ESSENCE: How should software startups work? In _Fundamentals of Software Startups: Essential Engineering and Business Aspects_, pp. 97-109. Springer.
* [5] Kemell, K.-K., Evensen, A., Wang, X., Risku, J., Nguyen-Duc, A. & Abrahamsson, P. (2019). A tool-based approach for essentializing software engineering practices. In _SEAA 2019: 45th Euromicro Conference on Software Engineering and Advanced Applications_, pp. 51-55. IEEE.
* [6] Risku, J., Kemell, K.-K., Kultanen, J., Feschenko, P., Careles, J. & Korpikoski, K. (2019). Does self-efficacy matter? On the correlation of self-efficacy and creativity in IT education. In _ICSOB 2019: Software Business_, pp. 336-344. Springer.
* [7] Kemell, K.-K., Feshchenko, P., Himmanen, J., Hossain, A., Jameel, F., Puca, R.L., Vitikainen, T., Kultanen, J., Risku, J., Impio, J., Sorvisto, A. & Abrahamsson, P. (2019). Software startup education: Gamifying growth hacking. In _IVSiB 2019: Proceedings of the 2nd ACM SIGSOFT International Workshop on Software-Intensive Business: Start-ups, Platforms, and Ecosystems_, pp. 25-30. ACM.
* [8] Kemell, K.-K., Nguyen-Duc, A., Wang, X., Risku, J. & Abrahamsson, P. (2018). The essence theory of software engineering: Large-scale classroom experiences from 450+ software engineering BSc students. In _PROFES 2018: Product-Focused Software Process Improvement_, pp. 123-138. Springer.

The theoretical background is based on the topical and situational literature on software startups, Essence, creativity and self-efficacy. The processing method used in the dissertation varies between theoretical studies, practical design, reflection, analyses and visionary outlook, on-site and in-class studies. Systematic literature studies can be run in different ways. There are various guidelines of different first steps, e.g. start with a search strings in different databases or start with reference lists a set of papers. Snowballing is recommended as a first step in information systems. The method used to identify the relevant literature is called backward-snowballing, which refers to a technique to find applicable hits from the reference lists (Jalali et al. 2012). In this study, the references in publications Seppanen (2018) and Klotins (2019) have performed a significant role in software startup research.

### Software startups

In this section, the nature of software startups is determined. Large technology companies often have a strategy of innovation and expansion into new business areas in the form of "acquisition instead of cooperation." This means that the corporations expand their expertise through direct acquisitions of startups, not through cooperating with them. This ensures that the startup's resources and competencies are integrated directly into the design and development of the organization (Rothaermel 2001; Roijakkers et al. 2006; Hagedoorn et al. 2000).

Exit strategy is a fundamental target of startups. Startups have four optional strategies for exit: First option, being become public is through an initial public offering IPO. Second option, to be acquired by an industry player. Third option, to be acquired by a financial investor. Fourth option, to apply leverage strategy, possibility to preserve full ownership control with lenders' funds (Deenitchin et al. 2005).

The optimal exit pattern depends on various elements, such as the anticipated lucativeness of the startup, degree of uncertainty of the product and markets and the imbalance of information between potential buyers and new investors (in-siders, outsiders). In addition, potential conflicts of interest among the buyers and venture capital qualities can create ambiguity for the startup (Akerlof 1970; Basu et al. 2011).

It is optimal for technology startups to be specifically designed to be acquired by larger corporations. These exits are mainly executed a few years after the beginning of the startup. Early exit has also turned out to be more probable than waiting years for an initial public offering (IPO) (Peters 2009). Timing and management of different parties' interests are crucial for startups' exit strategies; otherwise, the dream does not come true.

#### 2.1.1 Definition of software startups

Software startups have been defined with different term depending on the source. By adjectives, a software startup is described to be either quick, young, immature, beggarly, resourceless, temporary, creative, robust, agile, fresh, dynamic, unorganized, informal, vagabond, aimless, decentralized, weatherocking (by pivots), of triumph, of monetarization, horny, adolescent, software-intensive, nerdy, unstable, lucky, lottery-winners, tiny, eager, cowboyish, non- engineering, believing, trying, addictive, illusory or concoctive. Many of the terms can be found in the news of startup success or failure, and in the miserable investors' minds.

Here we concentrate on certain important factors of software startups. Carmel (1994) defines software startups as early as year 1994, including their product development characteristics as follows: minimize time-to-completion, increase innovation/features, maximize quality, minimize product cost, and minimize development cost (Carmel 1994). Klotins (2019) defines the product development process:

Product development [in start-ups] is driven by the following five goals: (1) minimize time-to-completion, (2) increase innovation/features, (3) maximize quality, (4) minimize product cost, and (5) minimize development cost. It is impossible to pursue all five goals at once. Developers must make trade-off decisions - implicitly or explicitly. Any such decision will, by definition, affect time-to-completion. (Klotins 2019, p. 4, xref).

Ries (2011) proposes a broader definition of a startup, which also scales outside the software and technology industries to other lines of business: "A startup is a human institution designed to create a new product or service under conditions of extreme uncertainty" (Ries 2011, p. 17). Blank (2005, et al. 2012) defines a startup as a temporary organization that creates innovative high-tech products and has no earlier operating history. This separates startups from established organizations with more resources and positions in mature markets. Blank (2005, et al. 2012) also states that a startup seeks a scalable, repeatable and profitable business model because of its willingness to grow. Here, the definition differentiates between startups and small business companies that do not essentially strive to grow. Therefore, small business companies lack a scalable business interest and model.

From these definitions Klotins (2018) proposes a compressed definition of software startups. There the notion'software-intensive product or service' include e.g. software as code and usability, application as an artefact or embedded to physical products, service as a systemic solution from front-end view to all-inclusive and widely spread structure on the Web. As an interpretation of Klotins (2019), a software startup company can be understood as a recently created institution with a focus of launching an innovative software-intensive product or service to market.

As a common conclusion, software startups share many similarities, such as dealing with uncertain conditions, being willing to grow fast, intending to develop innovative products and aiming for scalability (Unterkalmsteiner et al. 2016). Like Sutton (2000) states, there are factors that differentiate software startups from other types of startups, such as changes in the software industry, new computing and network technologies, and new sorts of computing devices. Software startups also need to use frontline equipment and techniques when developing innovative software products and services. Sutton (2000) also describes software startups through the challenges they encounter. First, startups have little to no experience in managing development processes and organizations. Second, they have little to no resources. They try to launch a product, advertise it and acquire strategic coalitions. Third, startups experience several stimuli, including pressure from financiers, clients, associates and contestants to make decisions. Although each of these actors is important, they may cause confusion in decision-making. Fourth, startups face challenges from vibrant technologies and businesses. The seminal nature of software startups urges them to regenerate or perform development with distracting technologies to reach highly prospective and target markets (Sutton 2000). These requirements reflect a temporary, young, eager and indigent phenomenon as a software startup must act in a difficult environment that can shift from tranquil (getting funding) to chaotic (failure and aftershocks).

Startups and small and medium size enterprises resemble each other by characteristics like small number of employees and limited resources (Kamsties et al. 1998, Laporte et al. 2008). Table 1 lists a wide set of characteristics that are not collectively agreed, and they vary by definitions of different authors. Therefore it is challenging to apply these characteristics direct to startups (Paternoster et al., 2014).

A scale-up, scaleup, post startup, or a scaled startup is based on the philosophical statement by Reid Hoffman (2015), the co-founder of LinkedIn: "First mover advantage doesn't go to the first company that launches, it goes to the first company that scales" (Hoffman, 2015). Also Markides (et al., 2004) express, that often in case of radical innovations later entrants reign the markets over the early explorers. This may happen in industries of cars, tires, plastics and Web searches (Markides et al., 2004). When an early-phase startup survives its first 2 to 3 years, in fortunate circumstances, it can strive for the growth phase. The expansion of marketing and sales means scaling up the business (Zajko, 2017).

When Isenberg (2012) says, "Extraordinary value creation cannot occur without growth, and entrepreneurial growth post startup has numerous challenges which can be an order of magnitude more difficult than simply starting a venture," he recommends various possibilities to re-orient the strategy:

Tuple 9:
Cleaned Title: making internal software startup work innovate like venture builder
Cleaned Transcription: making internal software startup work innovate like venture builder anastasiia tkalich nil brede moe rasmus ulfsnes sintef digital trondheim norway anastasiiatkalich nilsbmoe rasmusulfsnessintefno abstract increasing availability software usage influence lean startup mindset company choose innovate internal software startup startup aim developing new business model time relying resource company emerged evidence researcher practitioner indicates driving internal software startup challenging paper seek address problem asking research question make internal software startup work examined unique case venture builder company primarily focusing building internal software startup launching independent company applying grounded theory approach analyzed data four internal software startup case company result suggest four strategy drive examined startup cultural financial personnel venture arrangement interpret result drawing earlier literature intrapreneurship internal venture suggest four recommendation succeed internal software startup establish shared arena employee provide necessary resource experimentation initial phase increase incrementally build inhouse product management competence coaching harness employee motivation develop idea keywordsintrapreneurship internal venture internal software startup internal startup lean startup innovation strategy venture builder introduction innovation seen critical company capability company performance clearly seen startup even limited resource capability often able outperform established organization anthony et al demonstrated average lifespan large company continuously decreasing based thesp index largest company short lifespan make innovation essential vital many company time innovation traditional rd unit primarily used improve modify existing product always solution innovation rds sufficiently productive last two decade creating space allocating resource systematically fostering innovation culture thus solution many company giving set percentage time employee work project choosing implemented company google atlassian another strategy allocate dedicated day hackathons developer work together develop new product service lastly internal startup yet another approach utilizes startup concept foster innovation example lean startup popular way established company create innovative software product given software data ai becoming increasingly common instrument innovate make sense differentiate internal software startup concept study implementing lean startup approach established company challenging standalone startup internal startup including internal software startup bound current business strategy parent company often supported rigid bureaucratic structure bureaucracy authoritarian aspect parent company constrain internal startup deprive autonomy fundamental need startup depends much parent company regarding decision resource startup speed flexibility reduced therefore many internal startup fail transition outside parent company lokki internal software startup fsecure nevertheless internal software startup remain tempting approach numerous company seek practical advice succeeding goal study thus twofold provide insight best operate internal software startup acquire knowledge vocabulary better understand internal software startup therefore study ask research question make internal software startup work answer research question analyze practical experience company specializing creating developing internal software startup extension earlier preliminary result build additional data rigorous data analysis believe unique case provide valuable insight company need grow nurture coordinate several internal software startup researcher studying internal startup paper structured following way next chapter give overview literature shed light internal software startup chapter outline research approach case context present finding study chapter discus research question chapter related work internal software startup understand paper built upon concept standalone software startup extrapolated context entrepreneur within established company internal startup elaborate view drawing earlier literature startup generally seen temporary organization little operative history intend develop scalable repeatable business model according eric real startup human institution designed create new product service extreme uncertainty since software increased focus data ai key innovative differentiator important distinguish software startup concept software startup risktaking proactive initiative develop software product highly uncertain condition constantly searching repeatable scalable business model startup utilize softwareenabled technology rapidly grow disrupt market relying continuous agile process edge established company agility speed software startup also suffer challenge right example early stage startup may struggle develop feature interest customer build entrepreneurial team find financial resource although notion internal startup relatively new software engineering issue entrepreneur within existing company scrutinized management literature decade comprehensive literature review lengnickhall outlined four different route corporate entrepreneurship unit consisting specialist focus innovation creation knowledge primary objective individual employeesteams employee working beyond normal responsibility develop specific product process two firm pooling resource achieve innovation innovation purchase stock merger existing firm several important distinction rd internal venture according bart first internal venture dedicated outcome venture eg product innovation general participant internal venture responsible phase innovation process time continuing fulfill responsibility company gradually employee fully reassigned venture combining concept software startup internal venturesintrapreneurship one define internal software startup initiative developed inside parent company achieve software product innovation within software development crucial reduce uncertainty related developing new software product gave rise concept lean startup lean startup suggested approach iteratively develop customer problem solution buildmeasurelearn loop startup build product measure customer respond learn whether pivot continue together allows better formulate solve customer problem internal startup remain company example spinoff internal startup developed employee technology parent company later launched independent firm building upon summarized suggest following definition internal software startup temporary organization short operative history search scalable repeatable business model develops new software product service extreme uncertainty relying technology developed individual employeesteams employee working beyond normal responsibility parent firm company specialize building internal software startup thus known venture builder aka venture factory company builder venture studio venture builder provide support startup identifying business idea building team finding capital governing return receive equity certain control stake emerging startup unlike incubator accelerator venture builder operate permanent organization deeply involved startup exit trait make venture builder valuable source knowledge best initiate operate internal software startup however research intrapreneurshipinternal venture context internal software startup driven venturebuilding company seems scarce study seek address gap knowledge research approach answer research question collected data four internal software startup iterate described venture builder section describes case context research approach case context iterate technology investment company digital product development employee software engineer designer product manager business developer iterates approach development innovation continuous experimentation past ten year company named norway top three best workplacesgreat place work iterate listed among best workplace innovator world iterate three business area investment incubation employee idea helping external startup build product iterate enters investor technologistdesign partner consulting system development design behalf others combination java javascript clojure scala devops continuous deployment including corporate venture software service software tool innovator built insight gained business area iterate build call ecosystem innovation employee alternate working client assignment developing idea way company act investment fund technology partner employer many internal startup venture environmental profile cover many domain artificial intelligence maritime surveillance vake locally produced clothing woolit sustainable food production dagens rehabilitation healthcare flow technology table show overview startup examined startup completely relied software value creation allows categorize software ubiquity data collection data analysis iterate familiar u studied five year concerning innovation topic found interesting suitable study iterate part research project software development innovation turbulent context data collection internal software startup embedded unit analysis performed october august conducted interview total participant see table collected document note several meeting company representative eg kickoff meeting research project feedback session emerging result semistructured interview used interview guide slightly differed startup founder executive asked startup founder question like please tell u story
Original Title: Making Internal Software Startups Work: How to Innovate Like a Venture
  Builder?
Original Transcription: # Making Internal Software Startups Work: How to Innovate Like a Venture Builder?

Anastasiia Tkalich1[0000-0001-7391-4194], Nils Brede Moe1[0000-0003-2669-0778] and Rasmus Ulfsnes1[0000-0002-4966-8242]

1SINTEF Digital, 7034 Trondheim, Norway

{anastasiia.tkalich, nils.b.moe, rasmus.ulfsnes}@sintef.no

###### Abstract

With the increasing availability of software usage and the influence of the Lean Startup mindset, more and more companies choose to innovate through internal software startups. Such startups aim at developing new business models while at the same time relying on the resources from the companies where they emerged. The evidence from both researchers and practitioners indicates that driving internal software startups is challenging. This paper seeks to address this problem by asking the research question: _how to make internal software startups work?_ We examined a unique case of a venture builder - a company primarily focusing on building internal software startups and launching them as independent companies. Applying a Grounded Theory approach, we analyzed data on four internal software startups at the case company. The results suggest that four strategies drive the examined startups: _cultural_, _financial_, _personnel_, and _venture arrangement_. We interpret our results by drawing on earlier literature on intrapreneurship and internal ventures and suggest four recommendations to succeed with internal software startups: 1) establish shared arenas for the employees; 2) provide necessary resources for experimentation in the initial phase and increase them incrementally; 3) build up in-house product management competence through coaching, and 4) harness employees' own motivation to develop their own ideas.

**Keywords:**Intrapreneurship, Internal Venture, Internal Software Startup,

Internal Startup, Lean Startup, Innovation Strategy, Venture Builder

## 1 Introduction

Innovation is seen as the most critical company capability for company performance[1], which is clearly seen in startups that even with limited resources and capabilities are often able to outperform established organizations. Anthony et al. [2] demonstrated that the average lifespan of a large company is continuously decreasing (based on theS&P500 index of the 500 largest companies). The short lifespan makes innovation not only essential but vital for many companies. At the same time, innovation through traditional R&D units that are primarily used to improve and modify the existing products is not always a solution for innovation because R&Ds have not been sufficiently productive in the last two decades [3]. Creating space, allocating resources, and systematically fostering an innovation culture have thus been solutions for many companies. Giving a set percentage of time for employees to work on projects of their choosing has been implemented by companies such as Google, 3M, Atlassian [4; 5]. Another strategy is to allocate dedicated days (hackathons) where developers work together to develop new products and services [4; 6]. Lastly, an _internal startup_ is yet another approach that utilizes the startup concept to foster innovation. For example, Lean startup is a popular way for established companies to create innovative software products [7; 8]. Given that software, data, and AI are becoming increasingly common instruments to innovate, it makes sense to differentiate _internal software startup_ as a concept on its own, as we do in this study.

Implementing the Lean startup approach in an established company is more challenging than in a stand-alone startup. This is because internal startups, including _internal software startups_, are bound to the current business strategy of the parent company, which is often supported by rigid bureaucratic structures [9]. Bureaucracy and authoritarian aspects of the parent company constrain the internal startups and deprive them of autonomy, which is their fundamental need. When the startup depends too much on the parent company regarding decisions and resources, the startup's speed and flexibility are reduced [10; 11]. Therefore, many internal startups fail or transition outside the parent companies, as in Lokki, an internal software startup in F-secure [12].

Nevertheless, internal software startups remain a tempting approach for numerous companies who seek practical advice on succeeding. The goal of this study is thus twofold: 1) to provide insight into how to best operate internal software startups and 2) to acquire knowledge and vocabulary to better understand internal software startups. Therefore, we in this study ask the research question:

_What makes internal software startups work?_

To answer this research question, we analyze practical experience from a company specializing in creating and developing internal software startups. This is an extension of the earlier preliminary results [10] that builds on additional data and more rigorous data analysis. We believe this unique case can provide valuable insight for companies that need to grow, nurture, and coordinate several internal software startups; and researchers studying internal startups. The paper is structured in the following way. The next chapter gives an overview of the literature that sheds light on internal software startups. Chapter 3 outlines our research approach and the case context. We present the findings of the study in Chapter 4 and discuss the research question in Chapter 5.

Related work

_Internal software startup_ as we understand it in this paper is built upon the concepts of a standalone _software startup_ and extrapolated to the context of entrepreneur within an established company (_internal startups_). We will now elaborate on this view by drawing on earlier literature. _Startups_ are generally seen as temporary organizations with little or no operative history that intend to develop scalable and repeatable business models [13]. According to Eric Reis, a startup is a human institution designed to create new products and services under extreme uncertainty [14]. Since software with an increased focus on data and AI are key innovative differentiators [15], it is important to distinguish _software startup_ as a concept on its own. _Software startups_ are risk-taking and proactive initiatives that develop _software products_ under highly uncertain conditions by constantly searching for repeatable and scalable business models [16, 17]. Such startups utilize software-enabled technologies to rapidly grow and disrupt markets relying on continuous and agile processes. While having the edge over established companies in agility and speed, software startups also suffer from challenges in their own right. For example, in the early stages, the startups may struggle to develop the features that interest customers, build the entrepreneurial team, and find financial resources [18].

Although the notion of an _internal startup_ is relatively new in software engineering, the issue of entrepreneur within existing companies has been scrutinized by management literature for decades. In her comprehensive literature review Lengnick-Hall [19] outlined four different routes to corporate entrepreneurship:

* units consisting of specialists who focus on innovation and the creation of knowledge as their primary objective;
* individual employees/teams of employees working beyond their normal responsibilities to develop a specific product or process;
* two or more firms pooling their resources to achieve innovation;
* innovation through the purchase or stock merger of existing firms.

There are several important distinctions between R&D and internal venture, according to Bart [20]. First, an internal venture is dedicated to the outcome of the venture (e.g. a product) and not to innovation in general. Further, participants in the internal venture are responsible for all phases of the innovation process while at the same time continuing to fulfill their other responsibilities in the company. Gradually, such employees can be fully reassigned to the ventures.

By combining the concepts of _software startups_ and _internal ventures/intrapreneurship_, one can define _internal software startups_. These are initiatives that are developed inside of parent companies to achieve software product innovation [11]. Within software development, it is crucial to reduce the uncertainty related to developing a new software product, which gave rise to the concept of Lean startup. Lean startup [21] was suggested as an approach to iteratively develop both the customer problem and its solution through the build-measure-learn loop. A startup should build a product, measure how the customers respond, and learn whether to pivot or continue, which all together allows to better formulate and solve the customer problem. Internal startups do not have to remain in the company, for example, a _spin-off_ is an internal startup developed by an employee and with technology from the parent company and later launched as an independent firm [22].

Building upon the summarized above, we suggest the following definition of an _internal software startup_:

* a temporary organization with short or no operative history
* that searches for scalable and repeatable business model
* and develops new _software_ products or services under extreme uncertainty
* while relying on technology developed by individual employees/teams of employees working beyond their normal responsibilities in the parent firm

Some companies specialize in building up internal software startups and are thus known as _venture builders_ (aka venture factories, company builders, or venture studios) [23, 24]. Venture builders provide support to their startups, such as identifying business ideas, building teams, finding capital, and governing [24]. In return, they receive equity and certain control over the stakes in the emerging startups [23]. Unlike incubators and accelerators, venture builders operate as permanent organizations and are deeply involved with their startups up until they exit [24]. These traits make venture builders a valuable source of knowledge on how to best initiate and operate internal software startups. However, research on _intrapreneurship/internal ventures_ in the context of _internal software startups_ driven by _venture-building_ companies seems scarce. Our study seeks to address this gap of knowledge.

## 3 Research approach

To answer the research question, we collected data from four internal software startups at Iterate, which can be described as a _venture builder_[23]. This section describes our case context and our research approach.

### Case context

Iterate is a technology and investment company in digital product development. The 80 employees are software engineers, designers, product managers business developers. Iterate's approach to development and innovation is continuous experimentation. For the past ten years, the company has been named Norway's top three best workplaces(Great Place to Work), and in 2020 Iterate was listed among the 100 best workplaces for innovators in the world [25].

Iterate has three business areas: 1). **Investments**: incubation of employees' own ideas or helping external startups build their product, where Iterate enters as an investor and technologist/design partner. 2). **Consulting**: System development and design on behalf of others (combinations of Java, JavaScript, Clojure, and Scala with DevOps and Continuous Deployment), including corporate ventures. 3). **Software as a Service**: Software tools for innovators, built on insights gained in the other business areas. Iterate builds what they call an ecosystem for innovation, where employees can alternate between working in client assignments and developing their own ideas. In such a way the company acts as an investment fund, technology partner, and employer. Many of the internal startups (ventures) have an environmental profile and cover many domains, such as artificial intelligence for maritime surveillance (Vake), locally produced clothing (Woolit), sustainable food production (Dagens,) and rehabilitation in healthcare (Flow Technologies). Table 1 shows an overview of the startups that we examined. All of these startups completely relied on software for their value creation, which allows them to categorize them as _software ubiquity_[26].

### Data collection and data analysis

Iterate was familiar to us, as we had studied them for five years concerning other innovation topics and found them interesting and suitable for this study. Iterate was part of a research project on software development and innovation in turbulent contexts. The data collection on the internal software startups (the embedded units of analysis) was performed between October 2020 and August 2021. We conducted 7 interviews with a total of 9 participants (see Table 2), and collected documents and notes from several meetings with the company's representatives (e.g. kick-off meetings on the research project, feedback sessions on the emerging results). For the semi-structured interviews, we used interview guides that slightly differed for the startup founders and the executives. We asked the startup founders questions like _Please, tell us the story of

Tuple 10:
Cleaned Title: software startup research agenda
Cleaned Transcription: software startup research agenda michael unterkalmsteiner pekka abrahamsson xiaofeng wang anh nguyenduc syed shah sohaib shahid bajwa guido h baltes kieran conboy eoin cullina denis dennehy henry edison carlos fernandezsanchez juan garbajosa tony gorschek eriks klotins laura hokkanen fabio kon ilaria lunesu michele marchesi lorraine morgan markku oivo christoph selig pertti seppanen roger sweetman pasi tyrvainen christina ungerer agustin yagueblekinge institute technology sweden norwegian university science technology norway free university bolzanobozen italy norwegian university science technology norway sics sweden free university bolzanobozen italy lake constance university germany national university ireland galway ireland free university bolzanobozen italy universidad politecnica de madrid spain technical university madrid spain blekinge institute technology sweden tampere university technology finland university sao paulo brazil university cagliari italy national university ireland maynooth ireland university oulu finland hochschule konstanz germany university oulu finland national university ireland galway ireland university jyvaskyla finland hochschule konstanz germany universidad politecnica de madrid spain murbthse pekkaantnuno xiaofengwangunibzit anhnidintnuno shahsicsse bajwainfunibzit guidobaltescetinorg kieranconboynuigalwayie eoincullinaoutlookcom denisdennehynuigalwayie henryedisoninfunibzit carlosfernandezupmes jgseuiupmes tgobthse ekxbthse laurahokkanentutfi fabiokonimeuspbr ilarialunesudieeunicait micheledieeunicait lorrainemorgannuimie markkuoivooulufi cselightwgkonstanzde perttiseppanenoulufi rogersweetmannugalwayie pasityrvinainenjyufi christinaungererhtwgkonstanzde ayagueetsisiupmes abstract software startup company develop innovative softwareintensive product within limited time frame resource searching sustainable scalable business model software startup quite distinct traditional mature software company also micro small mediumsized enterprise introducing new challenge relevant software engineering research paper research agenda focus software engineering startup identifying particular research question area supporting startup engineering activity startup evolution model pattern ecosystem innovation hub human aspect software startup applying startup concept nonstartup environment methodology theory startup research connect motivate research agenda past study software startup research pointing possible future direction author research agenda main background software engineering computer science interest software startup broadens perspective challenge also opportunity emerge multidisciplinary research audience therefore primarily software engineering researcher even though aim stimulating collaboration research cross disciplinary boundary believe research agenda cover wide spectrum software startup industry current need introduction researcher naturally drawn complex phenomenon challenge understanding world software startup company intriguing phenomenon develop innovative softwareintensive product time constraint lack resource constantly search sustainable scalable business model past year software startup garnered increased research interest software engineering se community footnote iso defines softwareintensive system system software contributes essential influence design construction deployment evolution system whole encompass individual application system traditional sense subsystem system system product line product family whole enterprise aggregation interest one could argue software startup represent exceptional case software product developed brought market several factor suggest broader impact economical perspective startup contribute considerably overall wealth progress creating job innovation digital software startup responsible astonishing variety service product farming sector venture investment socalled agtech startup reached billion first half figure neared billion raised whole innovation perspective startup often pave way introduction even new disruptive innovation kickstarter changing retail finance industry spotify offering new way listen purchase music airbnb reinventing hospitality industry engineering perspective startup must inventively apply existing knowledge order open unexpected avenue improvement eg must provide education full stack engineer develop technique continuous lightweight requirement engineering develop strategy control technical debt footnote article digital startup refer specifically startup business value solution created mean software despite promising condition software startup face challenge survival even context play key role developing new technology market cloud computing challenge may arise developing product edifficult software startup face challenge developing cuttingedge product acquiring paying customer building entrepreneurial team diverse factor underscore need conduct research software startup benefit scholarly community startup leader paper research agenda driven past current work software startup outline various research track provide snapshot ongoing work preview future research creating platform identifying collaboration research startup environment ecosystem effort oneway path therefore founded research network software startup research network ssrn enables interaction collaboration among researcher interested startup ssrn envisions spread novel research finding context software startup inform entrepreneur necessary knowledge tool method minimize threat maximize opportunity success part network initiative international workshop software startup established first edition workshop held bolzano italy second took place trondheim norway paper provides research agenda based activity carried researcher network footnote httpssoftwarestartupsorghttpssoftwarestartupsorg footnote httpssuinfunibzithttpssuinfunibzit footnote httpsiwssublogwordpresscomhttpsiwssublogwordpresscom rest paper organized follows clarify meaning software startup know software startup prior research background section section introduces research topic software startup organized six main track either investigated envision investigating future wherever possible topic illustrated motivated previous study section highlight implication main track future research paper concludes section point future action establish consolidate software startup research area background software startup understand software startup must first clarify startup according ries startup human institution designed create new productservice condition extreme uncertainty similarly blank describes startup temporary organization creates hightech innovative product prior operating history definition distinguish startup established organization resource already command mature market addition blank defines startup temporary organization seek scalable repeatable profitable business model therefore aim grow blank definition highlight difference startup small business necessarily intend grow consequently lack scalable business model even though sharing common characteristic type startup resource scarcity lack operational history software startup often caught wave technological change frequently happening software industry new computing network technology increasing variety computing device also need use cuttingedge tool technique develop innovative software product service make software startup challenging endeavour meanwhile fascinating research phenomenon software engineering researcher related discipline carmel first introduced term software startup precise software package startup se literature carmel argued software increasingly becoming fully realized product since researcher offered definition software startup sutton considers software startup organization challenged limited resource immaturity multiple influence vibrant technology turbulent market hilmola et al claim software startup productoriented develop cutting edge software product coleman connor describe software startup unique company develop software various process without prescriptive methodology currently consensus definition software startup even though many share understanding software startup deal uncertain condition grow quickly develop innovative product aim scalability different definition emphasize distinct aspect consequently may varying implication study adopt designed eg qualifies study subject factor worth exploring reason despite lack single agreedupon definition software startup important recommended researcher provide explicit characterization software startup study work research track section dedicated develop software startup context model would allow characterization major challenge software startup software startup challenging endeavour due nature newly created company operating uncertain market working cutting edge technology giardino et al highlight software startup main challenge lack resource highly reactive definition new company comprised small team little experience reliance single product innovation condition uncertainty rapid evolution time pressure thirdparty dependency high risk dependency selfsustained giardino et al apply macmillan et al framework software startup context categorizing key challenge faced early stage software startup four holistic dimension product finance market team finding giardino et al reveal thriving technological uncertainty acquiring first paying customer top key challenge faced many startup another study giardino et al discover inconsistency managerial strategy execution could lead startup failure although research exists challenge software startup face study dedicated success factor block macmillans study highlight success factor new business including generating idea complete product testing completing prototype consistently redesigning making amendment researcher yet explore general factor applicability specific software startup context know software engineering software startup software development comprises software startup core activity however initial research study report lack software engineering activity software startup systematic mapping study conducted paternoster et al allows u start understanding software startup perform software development study reveals software requirement often market driven well documented software development practice partially adopted instead pair programming code refactoring session supported adhoc code metric common practice testing sometimes outsourced conducted customer acceptance focus group team member empowered encouraged adapt several role similarly giardino et al highlight common development practice used software startup company using wellknown framework quickly change product according market need evolutionary prototyping experimenting via existing component ongoing customer acceptance early adopter focus group continuous value delivery focusing core functionality engage paying customer empowerment team influence final outcome employing metric quickly learn consumer feedback demand engaging easytoimplement tool facilitate product development although study provide snapshot software engineering practice software startup state art presented literature enough base understanding software engineering practice could help software startup researcher must build comprehensive empirical knowledge base order support forthcoming software startup research agenda presented paper intends inspire facilitate researcher interested software startup related topic start building knowledge base research agenda software startup research agenda initialized june developed network researcher interested studying startup phenomenon different angle perspective variety research interest open new avenue collaboration also shed light complexity studied phenomenon initially ten researcher created mind map different research area aiming provide overview software startup research area connect period six month researcher joined network added research track continuously expanded map working session twenty researcher st workshop software startup research december devoted discussing identified area finding potential interest overlap among participant meeting author paper prepared eighteen research track description according following pattern background area motivation relevance software engineering startup research question potential impact answering research question practice figure overview software startup research agenda research potential research methodology employed answer proposed research question related past ongoing work author interacted past currently active advisory board member mentor founder team member software startup leading author paper grouped eighteen research track six major cluster based thematic similarity difference track grouping one several possible way create cluster served purpose ease presentation discussion research agenda shown figure supporting startup engineering activity section encompasses research focus address specific software engineering challenge encountered startup company startup evolution model pattern section focus progression startup time trying understand underlying mechanic drive company towards success failure human aspect software startup section cover research track investigate factor related actor involved startup research applying startup concept nonstartup environment section seek strengthen innovation extracting successful software startup practice integrating traditional environment startup ecosystem innovation hub section hand investigates whether thriving environment software startup designed finally area connected research track develop methodology theory software startup research section figure illustration research agenda includes reference research area outside paper current scope marketing business economic development direction likely relevant performance software startup area may added research agenda later edition evidence exists regarding whether interact software startup engineering ie use scientific engineering managerial systematic approach aim successfully developing software system startup company supporting startup engineering activity research track cluster share theme studying identifying transferring evaluating process method framework model tool aimed supporting software startup engineering activity context software intensive product engineering startup rapid development technology enabled small company quickly build launch softwareintensive product resource many attempt fail due market condition team breakup depletion resource bad product idea however role software engineering practice startup impact product success yet explored depth inadequacy applying engineering practice could significant contributing factor startup failure study show startup use adhoc engineering practice attempt adopt practice agile approach however practice often focus issue present larger company neglect startupspecific challenge example yau murphy report testdriven development pair programming provide increased software quality expense cost time also keeping strict backlog may hinder innovation since neglecting engineering challenge lead suboptimal product quality generate waste engineering practice specific startup context needed overarching question research track rq degree actual engineering critical success factor startup rq startup context defined informed decision engineering choice made rq engineering practice process methodsmodels used today work startup context answer rq could help practitioner decide activity focus prioritize allocation resource several study eg paternoster et al giardino et al sutton emphasize difference established company startup noting startup defined limited resource dynamic technology however characterization granular enough support comparison engineering context different company making transfer practice company company difficult thus understanding engineering context startup rq important milestone developing startup context specific engineering practice rq exists work provides systematic context classification field software engineering general model validated adapted use within startup work research track aim develop software startup context model analysing data startup experience report provided engineering context among startup established company compared fine level detail context model used identify candidate practice moreover researcher develop decision support mapping specific challenge useful practice thereby validating model helping practitioner select set engineering practice specific context set challenge technical debt management software market change rapidly discussed feng et al fast changing environment product management focus evolves traditional cost quality orientation time orientation new product development speed increasingly important organization commonly shared belief timetomarket new product build competitive advantage software startup context may vital first market order obtain customer since software startup also lack resource quality assurance often largely absent however longterm problem relevant product obtains customer short term shortterm vision may produce software code lowquality difficult change compelling company invest effort keeping system running rather increasing value adding new capability scalingup system may become obstacle prevent company gaining new customer finding viable tradeoff timetomarket demand evolution need thus vital software startup one promising approach performing tradeoff technical debt management technical debt management consists identifying source extra cost software maintenance analysing profitable invest effort improving software system hence technical debt management could assist startup making decision focus effort product development technical debt management entail identifying technical debt source impact estimation problem detected decision process whether profitable invest effort solving detected source technical debt source technical debt provide return investment resolved importantly technical debt managed project development order control internal quality developed software several research question need answered successfully manage technical debt way rq kind evolution problem relevant software startup context identify rq prioritize possible improvementschanges context software startup rq factor beyond timetomarket resource availability must considered tradeoff rq make decision implement improvementschanges within software startup roadmap rq provide agility technical debt management necessary environment plenty uncertainty change answering question impact practitioner researcher focused software startup practitioner able make better decision considering characteristic current software product implementation current implementation could make impossible reach deadline time market complexity change perform implement new feature assuming given amount qualification effort deployed furthermore also possible decide two alternative implementation different cost also different potential future assuming future previously outlined researcher answering question could help clarify role design decision software development context software product roadmap similarly happens engineering discipline technical debt context dependent since quality tradeoff context dependent technical debt important software startup mature company kind decision take consequence making wrong decision justifying research technical debt specifically software startup general lack specific study technical debt management software startup current literature review technical debt management address topic moreover several specific challenge managing technical debt special relevance software startup one study address prioritize improvement solve technical debt problem especially commercial software development addition technical debt management literature often refers timetomarket study actually address perhaps topic straddle engineering economics software product innovation assessment startup company strive create innovative product firm general software startup particular critical know soon possible product aligns market whether increase chance lead market recruit highest possible number customer need invest infrastructure measure impact innovation software highlighted oecd recently edison et al measure enable company ass impact innovation factor achieve expected business goal well improve understanding success yield high return investment innovation process product innovation assessment thus relevant product developer especially startup sensitive market reaction product innovation assessment complex particularly software product product innovation assessment reported literature combination number multidimensional factor impacting success failure software product factor measure intend engage people innovation process think deeply factor affecting product innovation factor timetomarket perceived value technology route incremental product product liability risk distribution competitive environment life cycle product strength market could grouped dimension like market organization environment term impact market business driver factor act innovation enablers blocker since factor always independent critical identify existing dependency gain better understanding factor impact would necessary relate factor characteristic specific software product limited software quality attribute proposed isoiec lack specific literature software product innovation assessment past research refers product general specifically software product leading following research question rq component software product innovation assessmentestimation model rq factor help measure innovation software product market perspective rq extent factor help measure innovation dependent software product market perspective rq relation software product innovation factor quality factor rq kind tool software product innovation estimation could support software startup decision making innovation widely studied process perspective product perspective nature addressed mainly viewpoint specific product industry however software product different compared kind product innovation software industry happen fast hence answer rqrq would provide fundamental understanding software product innovation assessment beneficial researcher practitioner software startup need fast spend resource efficient way therefore able estimate existing product design new product considering characteristic experience show relevant innovation point view essential software startup develop successful product rq empirical prototype engineering startup often start prototype serf form validate either new technology knowledge targeted customer traditionally prototyping implies quick economic approach determining final product defined concrete representation part interactive system prototype intensively researched used software engineering welldeveloped taxonomy horizontal vertical lowfidelity highfidelity prototype strategy developing prototype greatly vary due great variety prototype type development effort value produce much prototyping technique learnt se body knowledge discussion prototyping context business development process rare recent work startup methodology lean startup design thinking emphasizes adoption prototype increase chance success validated learning alternatively startup prototype need developed satisfactorily serve purpose ie technical feasibility test demonstration early customer fund raising argue prevalent software engineering practice used startup develop first product inefficiently integrate startup dynamic context hence call research understanding development usage prototype startup context rq prototyping used maximize learning experience rq prototyping used optimization rq prototyping used support communication external stakeholder rq prototype evolve multiple influence startup stakeholder early stage startup lacking actionable guideline making effective prototype serve multiple purpose believe many startup economically strategically benefit proper practice prototyping technology evaluation rq strategic planning rq customer involvement rq understand prototype development usage startup ie answering first three research question exploratory case study conducted case would selected cover different type startup prototype different phase startup progress largescale survey used understand prototype usage pattern ie answering rq despite increasing body knowledge software startup empirical research prototyping process practice rare study investigated adoption software prototype combination design thinking proposed prototyping technique however study rely limited number case moreover different constraint prototyping decision often neglected future work address antecedence factor ie involvement leadusers available human resource technological push impact prototyping strategy usage different startup context risk management tool software startup management risk namely risk failing meet one goal within given constraint budget andor time paramount importance every human activity context software startup risk management look unconventional startup naturally involve much higher risk traditional business yet perhaps even traditional context evaluating managing risk software startup context might key factor success risk factor identified checklist incident challenge face could categorized prioritized according probability impact level consequence research track aim study model quantify various aspect related risk management software startup goal providing tool based process simulation control risk able efficiently model simulate startup process dynamic would support startup timely decision making numerous approach risk control exist found previous work process simulation effective risk management therefore overarching question research track rq extent software startup explicitly manage risk rq degree feasible model software development process startup rq extent model used quantify risk exceeding project budget time rq systematic way exist understand pivot persevere might cost wrong untimely decisionfollowing previous experience software process modelling simulation gain better understanding necessary identify analyse significant activity limited software development phase software startup rq necessary able identify critical aspect startup development risk suitable simulation previous work studied application eventdriven model andor system dynamic software development process work know possible analyse project variation time budget monte carlo approach performing several simulation project varying unknown parameter according given distribution calculating resulting distribution cost time simulated project analysis allows one compute value risk var quantity given var level cocco et al concas et al provide exemplar study application technique mature agile software development context question whether approach suitable beneficial software startup condition rq simulating evolution startup process might able make prediction future development prediction result rapidly drawn simulation might crucial startup understand decision le costly andor risky rq particularly true decision related field market strategy team management financial issue product development rq startup support tool support tool help software startup get business ground le pain guidance tool generally embed crucial knowledge regarding startup process activity plethora tool mostly software tool exist meeting different need entrepreneur supporting various startup activity example webpage steve blank renowned entrepreneurship educator author researcher stanford university contains list tool welldesigned portal startupstashcom ease access supporting tool footnote httpsteveblankcomtoolsandblogsforentrepreneurshttpsteveblankcomtoolsandblogsforentrepreneurs however due lack time resource andor necessary knowledge entrepreneur easily find tool best suit need effectively utilize tool potential existing study provide limited insight entrepreneurial team could find use benefit support tool hence overarching question research track rq need software startup supported software tool rq tool support different startup activity rq support tool evaluated respect efficiency effectiveness returnoninvestment rq support tool effectively recommended entrepreneur used rq rq targeted identifying match need software startup available tool support enable robust recommendation individual startup software tool need objectively characterized allowing evaluation wrt certain quality criterion rq potential synergy research track looking context characterization software startup section answer research question also valuable input software tool vendor develop right tool needed startup addition finding useful future study develop proofofconcept prototype support startup activity investigate proposed question various research method applied including survey software startup regarding need usage support tool indepth case study adoption use support tool design science approach develop recommender system support tool rq research tooling aspect software startup context scarce edison et al argue despite fact different startup supporting tool developed published internet new entrepreneur might sufficient knowledge tool need compared experienced entrepreneur addition tool help entrepreneur certain task situation entrepreneur experience using tool serve basis evaluating recommending appropriate tool besides suggesting new categorization existing startup support tool edison et al propose new design tool portal incorporate new way recommend tool entrepreneur especially engage first time software startup endeavour supporting software testing testing software costly often compromised startup challenging startup fulfil customer need time simultaneously delivering high quality product many software startup common slogan say done better perfect indicates general tendency toward lack testing quality assurance activity however sometimes also observed startup know test lack expertise test requirement knowledge customer user therefore considering testing software startup pose following research question rq extent software testing startup company differ traditional company rq extent testing evolve time software startup company rq optimal balance costtime spent testing development activity rq software startup leverage customersusers testing answering rq would provide insight aspect differentiate software testing process startup mature company example integration testing likely important startup due fast paced product development time however startup tend work cutting edge technology requiring robust flexible test integration platform connected question whether testing need change time software startup matures answer rq rq would particularly valuable practitioner could better allocate resource user software could used different testing purpose one hand user provide valuable feedback testing assumption customer need hand early adopter robust towards deficiency help improve product quality targeting larger market answer rq would provide strategy harvest resource order answer research question various empirical research method could utilized study would devised way contrasting result anticipatable reason could expected ie different software startup company would taken account acquire broad view testing software startup best knowledge software testing software startup scarcely researched paternoster et al highlighted quality assurance activity software startup mapping study found important provide software startup effective efficient testing strategy develop execute maintain test addition highlighted importance research develop practical commercial testing solution startup user experience user experience ux described person perception response result use anticipated use product system service good ux seen providing value user well creating competitive advantage ux important software startup earliest stage firstly humancentred design method user research user testing help startup better understand provide value user customer well feature quality need testing user satisfied product combined business strategy humancentred approach help startup move towards successful sustainable business creation secondly providing initially strong ux first product version create positive word mouth well keep user interested product longer time genuine interest user product idea product still prototype help gain meaningful feedback compared established business software startup may pivot resulting new target market user group mean effort put designing ux need faster le resource consuming furthermore failing deliver satisfying ux fatal small startup cover cost redesigning overarching question research track rq useful method practice exist creating ux startup rq uxs role different phase startup lifecycle rq extent ux business model connected customer value creation answer rq provide software startup method developing strong ux first product version keep user interested product longer time genuine interest user product idea product still prototype help gain meaningful feedback business creation understanding value ux startup rq help assigning enough resource creation ux wasting resource value gained rq research startup ux limited case study report uxs role building successful startup practice method ux work startup reported framework creating strong early ux presented hokkanen et al provide result feasible beneficial ux development startup generalizable result needed startup evolution model pattern research track cluster share theme studying identifying differentiating transformation startup different stage also includes study different business technical decisionmaking practice pivot software startup difficult software startup understand start real problem solve right software solution suitable business model evidenced fact many successful software startup different started example flickr popular online photo sharing web application originally multiplayer online role playing game twitter famous microblogging application born failed attempt offer personal podcast service due dynamic nature software startup must constantly make crucial decision whether change direction stay chosen course decision known pivot orpersevere term lean startup pivot strategic decision used test fundamental hypothesis product market engine growth software startup develop technology intensive product nature due prone rapidly changing technology causing pivot similarly certain type pivot relevant software startup eg zoom pivot pivot one feature product become whole product case flickr pivot closely linked validated learning another key concept lean startup process test business hypothesis measure validate effect called validated learning whereas pivot often outcome validated learning recent study reveals startup often neglect validated learning process neglect pivoting need lead failure show importance pivoting startup survive grow eventually attain sustainable business model order better understand explore pivoting process software startup context following fundamental research question formed rq extent pivoting crucial software startup rq software startup pivot entrepreneurialstartup process rq existing processstrategiesmethods make pivoting decision startup context rq pivot occur different product development customer development life cycle answering rqrq necessary understand pivoting context software startup building fundamental framework reason pivoting type rqrq hand targeted understanding pivoting decision mechanism overall contribution answering stated research question implication researcher practitioner answer would provide empirically validated conceptual theoretical basis researcher conduct study regarding pivot phenomenon practitioner would help make informed decision regarding pivot order increase chance success due nascent nature software startup research area exploratory case study suitable approach answer research question followed case study quantitative survey also conducted generalize result regarding pivoting software startup recently study conducted pivot software startup study van der van bosch compare pivoting decision software architecture decision another study terho et al describes different type pivot may change business hypothesis lean canvas model however study lack sufficient detail understand different type pivot factor triggering pivot study bajwa et al present initial understanding different type pivot occurred different software development stage however lack deeper understanding pivoting decision achieved longitudinal study determination software startup survival capability business plan software startup highly specialized technological point view focusing economic exploitation technological innovation belong group new technologybased firm literature suggests one major challenge transformation technological knowhow marketable product new technologybased firm often struggle unlocking productmarket fit commercializing technological product applying resourcebased view thus suffice explaining survival growth software startup crucial success factor ability new technologybased firm understand interact market environment position product accordingly particularly early lifecycle stage new technologybased firm need build network relation market network theory literature suggests increasing network maturity chance survival growth increase ability transform resource response trigger resulting market interaction described dynamic capability help software startup commercialize product transformation process capture evolution new technologybased firm earlystages current research based construct venture emergence provides perspective evolutionary change process new technologybased firm venture emergence reflects interaction process agent environment business plan new technologybased firm used artefact measuring status venture emergence contain description transaction relation new technologybased firm build four market dimension customer partner investor human resource research track intends answer number research question rq reliably annotated transaction relation business plan text determine venture emergence status technologybased startup rq extent number strength level identified transaction relationship useful indicator survival capability rq pattern transaction relation used indicator evaluating strength weakness new technologybased firm thus used effectively direct support measure possible measure venture emergence status even software startup early stage predictive strength transaction relation need evaluated rqrq use network theory operationalize venture emergence construct new approach add network theory literature context survival new technologybased firm confirms business plan new technologybased firm valuable source information startup potential finally resourcebased approach explain venture survival enriched applying processoriented perspective analyse resource transformation rather looking initial resource configuration rq furthermore research contribute effectiveness innovation system investigating indicator reveal strength weakness new technologybased firm used direct support measure software startup effectively answer stated research question one use content analysis combining human computerbased coding business plan determine number strength transaction relation initial statistical test performed sample business plan new technologybased firm confirm relationship status venture emergence new technologybased firm venture survival earlier work led development concept analysing earlystage startup network relevance survival based concept coding method transaction relation business plan developed validated business plan cooperative human aspect software startup research track cluster address challenge practice related people cooperate work software startup competency competency need software startup software startup set different competency requirement personnel established company biggest difference occur two phase evolution startup impact nature software development competence need early stage rapid software development lack resource immature competency many key area rapid business growth successful startup requires management fast growing personnel amount software limited management resource competency early phase strong competition requires software startup innovate react quickly deployment systematic software engineering process many time replaced lightweight adhoc process method nature software make possible successful startup scale fast rapid softwaredriven growth requires fast scaling software production distribution maintenance required competence also quickly evolve software development move rapid greenfield prototyping professional software development management mastering demanding situation often requires broad prior skill basis startup team including ability adjust change learn quickly research specific skill competency need software startup broadens knowledge software startup also broadens knowledge software engineering conducted challenging circumstance startup focusing research early stage growth period software startup challenge software startup greatest brings valuable knowledge academia practitioner competency research also brings human factor focus reinforces result existing software startup research towards comprehensive modelling understanding research question study competency competency need software startup include rq software startup challenge competency need software development knowledge skill needed overcome challenge rq competency need specific software startup compared established software company rq competency need change evolution software startup rq competency need map onto role responsibility startup team software startup rq growth software startup managed term competency need software development practice process recruitment research software startup including research competency need provides research development software engineering new knowledge viewpoint direct work order best address specific challenge software startup rq particular difference mature software company interesting study rq considering software startup evolve survive established company knowing competency need change might turn one key factor transition rq theoretical model describing evolution path software startup created competency need map role responsibility large degree ignored rq similarly softwaredevelopment work software engineering practice also studied unclear competency need managed growing software startup rq teamwork software startup importance human aspect software development increasingly recognized software engineering researcher practitioner teamwork effectiveness crucial success product development project common definition team small number people complementary skill committed common purpose set performance goal approach hold mutually accountable startup team special wide range variety including technician entrepreneur innovative idea important formation startup startup success failure ultimately rest ability team execute entrepreneurship research showed percent startup survive longer two year founded group two individual dynamic intertwined startup activity require close collaboration among startup team member also external stakeholder mentor investor given diversity mindset skill set among founder essential work well together along startup lifecycle movement recent methodology lean startup introduces opportunity look startup team various angle ie pivoting startup culture team formation decisionmaking overarching question research track rq common cultural organizational team characteristic among successful software startup rq software startup team effectively communicate stakeholder ie mentor investor rq software startup manage team internal relationship rq common pattern competence growth among software startup team understanding software startup team behaviour internal external environment relating startup success measure would help identify characteristic teamwork pattern successful startup answering rq would provide practitioner guidance form startup team answer rqrq would provide understanding internal end external team dynamic work improved answer rq would also support work section looking however specifically competence growth pattern could valuable practitioner deciding focus competence development empirical study ie case study survey action research suitable investigate stated research question among comparative case study would first option discover difference startup teamwork pattern exists large body literature business management entrepreneurship small venture entrepreneurial team characteristic relationship startup outcome software engineering empirical study identified team factor failure software startup giardino et al found building entrepreneurial team one key challenge earlystage software startup idea conceptualization first launch crowne et al described issue founder teamwork team commitment skill shortage ensley et al investigated relative influence vertical versus shared leadership within new venture top management team performance startup team dimension explored business engineering management domain specific geography eg oechsellein analysedinfluencing variable relational capital dimension trust within startup company china generalizable influencing variable geography yet seen applying startup concept nonstartup context one lean startup principle claim entrepreneur everywhere entrepreneurial spirit approach may applied size company sector industry hand established organization face challenge innovation dilemma inertia caused organization stability maturity market therefore applying startup concept nonstartup context seems promising avenue established organization improve innovation potential internal software startup large software company internal software startup concept promoted way nurture product innovation large company internal software startup operates within corporation take responsibility everything finding business idea developing new product introducing market internal software startup help established company master challenge improving existing business simultaneously exploring new future business sometimes different existing one usually involves conflict interest term learning mode risk propensity prevented establishing dual structure within organization implementing internal software startup compared traditional rd activity larger company internal software startup develops product service faster higher market orientation help established company maintain competitiveness volatile market besides fact successful implementation internal software startup face various barrier cultural conflict fear cannibalization existing business internal software startup also benefit part established company shared resource capital human resource access corporates internal external network benefit earlier research analysing result startup value creation cycle taken place context evolution enterprise however occurs long time period useful guiding software development measuring cycle time software engineering process completion software feature also insufficient lean startup approach commonly adopted new business creation software intensive venture use learning loop discover customer value potential new product concept well find new mean produce software tyrvainen et al propose measuring cycle time development analysis customer acceptance feature enables faster learning market need addition receiving fast feedback user make changing software easier programmer yet forgotten code relevant research question regarding internal software startup formulated follows rq lean startup adopted adapted software product innovation large software company rq challenge enablers lean startup large software company rq internal software startup managed lead rq metric used evaluate software product innovation internal startup rq extent internal startup competitive advantage compared independent startup shared resource etclean startup approach gain interest scholar academic new way foster innovation since help avoid building product nobody want evidence show mature software company startup differ applying lean startup approach eg mature firm start cycle collecting data existing user generating hypothesis based data whereas software startup generate idea collect data new user validate idea however seems large extent approach used startup established enterprise answering rqrq aim defining structured guideline introduce lean startup large software company supporting practitioner answering rqrq would provide motivation approach allowing compare effectiveness quantitative level due complex nature research phenomenon intention achieve indepth understanding consider multiple case study suitable research approach case organization selected based following criterion organization develops software inhouse dedicated team responsible ideation commercialization new software software fall current main product line unit analysis study would development team study investigated lean startup leverage internal startup large software company improve competency capability product innovation initial step taken result published fill observed gap eg marijarvi et al report finnish large company experience developing new software internal startup also discus lifecycle phase innovation work large company author argue different type internal organization may take place stage new product development example problemsolution fit done internal startup company subsidiary lean startup project portfolio management open innovation building challenge proposed section propose lean startup could also applied within project portfolio management ppm coordinate multiple startup initiative within organization ii open innovation wherein internal startup involve multiple organization individual even unknown participant ppm open innovation main challenge briefly introduced followed research question require investigation lean startup principle successfully applied new context software engineering ppm describes ongoing identification selection prioritization management complete set organization software engineering project share common resource order maximize return organization achieve strategic business objective open innovation defined use purposive inflow outflow knowledge accelerate internal innovation expand market external use innovation respectively popular example open innovation include open source software development crowdsourcing inner source effective ppm critical achieving business value improving cost time saving eliminating redundancy unfortunately existing portfolio management practice based effective completion individual project episodic portfolio level review fail manage either dynamic nature contemporary project problem associated portfolio comprising many project indeed many portfolio report unwillingness cancel project longer contribute achievement strategy open innovation oi present numerous advantage organization access requisite variety expert prospective reduction overall rd spending reduced timetomarketimproved software development process integration firm new collaborative value network nonetheless adopting open innovation process significantly challenging example adopter often lack internal commitment addition challenge associated aligning innovation strategy extend beyond boundary firm moreover concern regarding intellectual property managing unknown contributorscontributions well managing higher cost risk associated managing internal external innovation role lean startup principle addressing challenge ppm oi worthy research rq lean startup implemented within portfolio management open innovation context rq lean startup initiative drive accelerate open innovation rq lean startup concept could adapted facilitate open innovation process organization rq one ensure lean startup initiative conducted across multiple project organization align strategy rq reconcile potential conflict portfolio open innovation process lean startup process rq achieve consensus defining minimum viable product mvp network comprised multiple autonomous sometime anonymous agent successful application lean startup principle rqrq potential reduce cost arising poor implementation ppm oi practice increase value achieved initiative however approach often practice led necessary academic research develop effective theory underpin practice provide empirical data support refute claim effectiveness rqrq rich human interaction heart software engineering ppm open innovation accordingly phenomenon domain examined using interpretive qualitative method semistructured interview case study ethnography principle lean applied ppm eg little research looking application lean startup principle ppm similarly interest application lean startup principle open innovation context date application predominantly driven practice software startup ecosystem innovation hub successful software startup live isolation normally inserted rich environment includes number relevant player entrepreneur developer investor scientist well business intellectual property consultant support player number support program private public sector required provide funding incubation acceleration training networking consulting element combine scholar practitioner called startup ecosystem software startup research agenda focus software startup ecosystem sse element relevant startup software key part product service studying ss created main characteristic evolve one better understand environment favour birth development successful software startup research field provide relevant stakeholder concrete action eg public policy private activity establish fruitful vibrant environment execution highgrowth innovative project within nascent software company main research question need answered following rq key element fruitful sse rq different type ss eg differentiated size technology sector country economy factor rq ss evolve time rq one measure output quality sse answering rq researcher provide better understanding way ss innovation hub work instrumenting key stakeholder taking action improve ecosystem identifying factor promote hinder development successful startup within certain sse policy maker get support decision making rq entrepreneur also able better understand environmental factor force help hinder success enterprise researcher brazil israel usa developed methodology map specific software startup ecosystem methodology applied israel sao paulo new york currently help dozen expert worldwide developing maturity model ss addressing rq rq maturity model need research validation applied real scenario help practitioner policy maker global startup ecosystem ranking crafted group expert proposing metric evaluate regional ecosystem around world compare according multiple criterion frenkel maital developed methodology map national innovation ecosystem use map propose policy promote improvement jayshree studied influence environmental factor entrepreneurial success finally sternberg researched role regional government support program regional environment success factor startup theory methodology software startup research track cluster direct research towards identifying mean better study understand software startup overview possible theoretical lens studying software startup theory important scientific field form foundation understand contemporary phenomenon better theory provide answer question therefore useful explaining certain event occur others software startup research operate vacuum rather borrow theory software engineering information system field business management literature well field organizational social science identified potential theory meaningfully applied context software startup company proposed theory huntergatherer model cynefin model effectuation theory boundary spanning theory theory briefly outlined section although human history occupied hunter gatherer forgd wild plant killed wild animal survive recently huntergatherer model rediscovered steinert leifer explain designer pursue endeavour search best design outcome model show change design process well subsequently design outcome model portrays distinction hunter aim find innovative idea gatherer aim implement idea needed achieve concrete result hunting idea ambiguous space changedriven analytical qualitative nature gathering idea across predetermined path planoriented manageable quantitative nature model recently applied software startup research explain startup evolutionary path complexity theory used frame reference analysing implication software design development eg pelrine rikkila et al software project characterized endeavour wherein dynamic network customer software designer developer rd party partner external stakeholder interact seen complex adaptive system ca reason decisionmaking different situation snowden et al proposed sensemaking framework system model five subdomains divide world two part ordered unordered main domain ordered domain one causeeffect ce relationship known known domain least knowable analysis complicate domain contrast unordered domain includes complexity situation wherein ce relationship perceived retrospect advance complex domain chaotic situation wherein behaviour completely random lacking expected consequence acted upon depending problem domain suitable approach include categorizing analysing probing acting cynefin model provides framework used analyse decision made software startuppers developing product often find unordered domain attempting make sense current situation navigate ordered domain effectuation theory simple model rooted entrepreneurship decisionmaking uncertainty effectual thinking opposite causal reasoning start desired end necessary mean topdown experienced entrepreneur reason mean end bottomup trying work meaning goal based resource hand theory embodied five principle birdinhand principle affordable loss principle crazy quilt principle lemonade principle pilotintheplane principle effectuation theory help make better sense entrepreneur decisionmaking process evolution software startup problem validation value proposition definition design mvp pivoting process good practice could discovered using effectuation theory theoretical lens startup operate dynamic environment face expectation influence many direction order survive need effectively collaborate within team also outside boundary spanning concept deal structure organization transitioning rigid hierarchical structure towards networkbased expert organization give rise informal boundary rather structural one boundary spanner people entity bridge boundary opportunity software engineering context boundary spanning studied context global software development startuppers seen boundary spanner need bridge various stakeholder boundary always unavoidable also necessary useful knowledge required crossed rearranged even dissolved considered harmful startuppers see boundary tool facilitate support making sense environment boundary spanning help discovering overcome challenge distributed global work motivation work style knowledge domain vary across boundary startuppers become knowledge broker transferring sharing knowledge theoretical lens used study software startup startup deal innovative service product often new emerging market birkinshaw et al analyse innovation theory presented propose framework management innovation process could applied startup innovation process context explore product development move problemdriven search trial error finished prototype analysis complemented van de ven pooles four view organizational change present alternate process organization transform theorizing software startup important since current lack understanding dynamic startup theoretical advancement need achieved researcher make better sense diverse context situation place startuppers strive success defining lean startup concept evaluating practice many positive driver underpin lean startup movement literature abound claim reduced risk benefit evidencedbased trial shorter timetomarket certainly know benefit needed given challenge experienced early stage software startup percentage fail indeed many software startup fail waste much time money building wrong product realising late right product challenge coupled high uncertainty make lean startup methodology attractive software startup supposedly offer integrated approach creating product service fit market research build previous research conducted dennehy kasraian oraghallaigh conboy identified significant absence framework assisted startup efficiently effectively progress minimum viable product mvp product market fit pmv theoretical advancement lean concept contemporary software engineering software development literature arrested mainly academic research community followed fad fancy characterize academic research implication arrested theoretical development lean concept listed next motivation research often case new emerging phenomenon lean startup practice led research creation promotion dissemination method almost completely due effort practitioner consultant lean startup research beginning gain momentum evident increasing number dedicated journal special issue conference conference track workshop merit adopting practiceoriented focus little research effort focused conceptual development lean startup underlying component practice lead research definition lean startup emerged used practice result lean startup adoption often defined practice adhered rather value gleaned use adaptation case abandonment see many method agile many define agile many scrum xp practice used rather value obtained use result current body software startup knowledge suffers number limitation including lack clarity broad agreement principle regarding constitutes key concept mvp assumption regarding specific definition interpretation use evaluation often unclear many existing lean startup study make critical appraisal evidencebased evaluation comparison across study extremely difficult lack cohesion cumulative tradition good concept theory cumulatively build existing research little academic research examined lean startup using concept mature substantive body research theory framework lens thoroughly tested time lean concept applied manufacturing since ww yet lean startup research see myopic limited use broad lean framework available concept influence lean startup include agility flow innovation limited applicability adherencebased measure lean startup inhibit ability apply lean startup domain originally intended research attempt apply lean startup environment large organization regulated environment become prevalent issue trend continues therefore question relevant research track include rq core concept underpin lean startup rq component higher abstract lean startup allows concept applied evaluated valuebased manner rq theory framework metric instrument existing related body knowledge applied lean startup rq effectively applied improve use lean startup practice study improvement lean startup research rq lean startup tailored suit environment originally designed support eg large organization regulated environment peer production rq lean startup enable inhibit fundamental leap business software business idea example mvp place invisible ceiling wherein reach mvp subconsciously stop looking truly significant innovation reciprocal relationship practice academia academic research informed practice practice informed academic research research would impact research practice answering rqrq research track would provide practice empirical evidence utility lean practice diverse environment also positioning lean method core academic research rqrq case study research empirical inquiry investigates contemporary phenomenon depth within reallife context would highly suited addressing theoretical limitation lean answering question listed specifically use multiplecase design would allow crosscase pattern develop sophisticated description powerful explanation lean concept challenge new product development confined software startup therefore software engineering team working distributed regulated environment financial service within multinational company would provide rich insight advancement lean concept research collaboration strategy software startup empirical research area software engineering normally requires access organization artefact company developing software intensive product service case startup access limited due several challenge startup limited resource term person hour calendar time anything working mvp startup want investment yield almost immediate result thus investment longterm potential prioritized artefact actual product often sensitive startup vulnerable reason limit empirical research reflected academic knowledge startup overall also superficial nature available reason initiative seriously collect empirical data well conduct research core challenge facing startup hasto originate strategy overcomes obstacle one possible strategy pool resource access startup essence sharing empirical data coordinating research startup software engineering coordination seen equally central enables researcher limit impact cost study project part focused small several larger issue tackled coordination concrete example joint activity include limited joint survey superficial level pooling resource collect many data point complementary survey case study partner part result combined analysis synthesis formulating complementary research agenda clear interface joint research question pooling resource relation testing solution emerging collaboration strategy open possibility share resource requirement among studied startup open question regarding implementation rq extent data different startup startup ecosystem comparable word technique exist perform metaanalysis gathered heterogeneous data rq efficiently transfer technology researcher startup measure impact transferred solution conjecture software startup context model discussed section would enabler answering rq confounding variable could easier identified allowing sample stratification robust statistical analysis particular data collected different researcher could aggregated increase strength conclusion drawn analysis ie enabling metaanalysis answering rq would allow u actually support software startup broad basis knowledge gained research proposed agenda different approach exist transfer knowledge academia industry mostly targeted mature company resource collaborate researcher longer period time think software startup ecosystem discussed section contribute technology transfer researcher active structure create winwin situation startup researcher benefit discussion section give brief overview research track relation work software engineering potential impact field conclude section discussion study limitation software startup engineering research center around core knowledge base software engineering illustrated research track proposed section encompass providing support startup engineering activity noticing considered good software engineering practice challenge software startup encounter see potential directing research towards efficient effective requirement engineering practice startup klotins et al studied experience report startup identified lack requirement validation classification enable prioritization identification requirement source identify relevant value proposition cause engineering uncertainty map earlystage startup challenge technology uncertainty delivering customer value identified giardino et al unlike large company software startup unique time resource constraint thus afford develop feature service used valued customer believe lightweight practice identify importantly analyse requirement business value help software startup decision process looking research track section several touch upon requirement engineering aspect prototype used communicate customer elicit requirement section product innovation assessment section relevant context analysing customer perceived value offered solution even optimizing effort spent requirement engineering quality assurance example using test case requirement involving product user testing section address requirement engineering aspect focus requirement software startup engineering research directly relates research track presented section startup evolution model pattern cost pivoting could reduced earlier le adhoc analysis requirement value proposition envisioned product pattern emerging research survival capability software startup proposed section could provide valuable heuristic leading lightweight analysis product value proposition research pivoting survival capability likely affect software startup practitioner strategic level providing managerial decision support draw model rooted software engineering practice example crossdiscipline approach successful valuebased software engineering research track described section grouped name cooperative human aspect software startup borrowed research area software engineering interested studying impact cognitive ability team composition workload informal communication expertise identification human aspect software construction conjecture studying understanding aspect better large potential software startup driven motivated individual rather corporate agenda lesson research benefit startup practitioner particular conjunction work software startup ecosystem section mature company example applying model competency need could emerge work presented section remaining research track described section take step back happens inside software startup research track section propose apply startup concept nonstartup context idea extracting concept one context applying another proven successful area systematic literature review open source principle premise internal startup positive trait startup wild transferred corporate environment fostering innovation faster product development overall aim research track described section evaluate whether trait startup actually produce thriving environment within mature company comparison research startup ecosystem innovation hub section take broader higher level view software startup phenomenon neither independent startup mature company adopting internal startup initiative live isolation better understanding startup ecosystem innovation hub might thereby provide key insight factor create fruitful software startup environment finally research track section look aspect relevant implementing research agenda described paper particular theory used better understand dynamic around software startup value attempting construct holistic understanding software startup various context research defining lean startup concept parallel lesson similar endeavour around research agile software development taken consideration paper followed recommendation dyba dingsoyr develop research agenda phenomenon interest howeverin order implement research agenda need also answer question enable efficient effective research collaboration software startup section limitation research agenda presented paper developed bottomup ie area interest proposed described sample software startup researcher without restriction covering certain aspect software engineering body knowledge guided past current future work field often researcher leg academia startup community either mentor founder simply part development team approach develop research agenda uncommon see eg threatened potential bias towards preference individual researcher invited large number peer contribute agenda even though research track cover many software engineering aspect beyond agenda sample potentially relevant future research software startup mean potentially interesting relevant research topic use open source software business model development legal issue intellectual property right discussed paper however expect agenda grow together research community soon work proposed research track bear fruit leading new research question outlook conclusion software startup interesting stimulating phenomenon modern economy paramount importance society today despite high failure rate community city country investing stimulating creation software startup startup may solve unemployment problem many country stimulate new type positive dynamism society encouraging people collaborate develop personal skill novel way emergence software startup research area reflects fact need better understand phenomenon learn valuable lesson accumulate valid knowledge benefit future entrepreneurial initiative research agenda described paper one first attempt establish software startup nascent yet fast growing research area depict landscape highlighting interesting research topic question explore worth emphasizing software engineering one multiple discipline relevant inform software startup practice discipline include economics entrepreneurship design finance sociology psychology therefore need collaborate researcher discipline order increase potential achieving relevant useful research result benefit practice due emerging nature field still much done establish software startup research area relevant concept need clear definition substantive theory need developed initial research finding need validated future study software startup diversified term entrepreneur varying approach startup endeavour without sound foundation mentioned research area risk asking irrelevant research question able attain rigorous result last least research agenda meant exhaustive aware may exclude important software engineering topic relevant software startup research agenda open addition new track topic research question researcher interested research area contribution commitment researchersfrom different institution background collectively establish software startup promising significant research area attracts exciting discovery contribution welcome interested joining software startup research network fostering collaboration researcher taking research agenda reference software product quality requirement evaluation square guide square isoiec technical report international organization standardization architecture description isoiecieee e revision isoiec ieee std page frequently asked question small business technical report u small business administration z anbardan raeyat open innovation creating value cocreation proceeding th world conference mass customization personalization cocreation mcpc page aalborg denmark springer r balachandra j friar factor success rd project new product innovation contextual framework ieee transaction engineering management c k bart new venture unit use wisely manage innovation sloan management review beaudouinlafon w e mackay prototyping development tool handbook humancomputer interaction page j birkinshaw g hamel j mol management innovation academy management review e bjarnason unterkalmsteiner e engstrom borg multicase study agile requirement engineering using test case requirement information software technology blank four step epiphany successful strategy product win cafepresscom blank lean startup change everything harvard business review blank b dorf startup owner manual stepbystep guide building great company k ranch there management enacts international journal project management z block c macmillan milestone successful venture planning harvard business review b boehm valuebased software engineering sigsoft softw eng note j bosch h h olsson j bjork j ljungblad early stage software startup development model framework operationalizing lean principle software startup proceeding th international conference lean enterprise software system le page galway ireland springer p bourque r e fairley editor guide software engineering body knowledge ieee rd edition brem ki voigt integration market pull technology push corporate front end innovation managementinsights german software industry technovation brown change design design thinking transforms organization inspires innovation harperbusiness new york broy challenge automotive software engineering proceeding th international conference software engineering icse page shanghai china acm c g brush manolova l f edelman property emerging organization empirical test journal business venturing e carmel timetocompletion software package startup proceeding th hawaii international conference system science hicss page ieee chandra v sinha sinha k ratakonda software service research roadmap future software engineering fose page hyderabad india acm cj chen technology commercialization incubator venture capital new venture performance journal business research h chesbrough crowther beyond high tech early adopter open innovation industry rd management h w chesbrough open innovation new imperative creating profiting technology harvard business press p clarke r v oconnor situational factor affect software development process towards comprehensive reference framework information software technology b clarysse j bruneel wright explaining growth path young technologybased firm structuring resource portfolio different competitive environment strategic entrepreneurship journal j clelandhuang c z gotel j huffman hayes p mader zisman software traceability trend future direction proceeding future software engineering page hyderabad india acm l cocco k mannaro g concas marchesi simulating kanban scrum v waterfall system dynamic proceeding th internation xp conference xp page madrid spain springer g coleman r v oconnor investigation software development process formation software startup journal enterprise information management coleman c cotei j farhat resourcebased view new firm survival new perspective role industry exit route journal developmental entrepreneurship k conboy agility first principle reconstructing concept agility information system development information system research g concas lunesu marchesi h zhang simulation software maintenance process without workinprocess limit journal software evolution process invisible success factor product innovation journal product innovation management r g cooper perspective innovation dilemma innovate market mature journal product innovation management suppl croll b yoskovitz lean analytics use data build better startup faster oreilly medium sebastopol usa st edition crossan apaydin multidimensional framework organizational innovation systematic review literature journal management study crowne software product startup fail international engineering management conference iemc page cambridge uk ieee cukier f kon n krueger designing maturity model software startup ecosystem proceeding st international workshop software startup page bolzano italy springer cukier f kon l thomas software startup ecosystem evolution new york city case study proceeding nd international workshop software startup trondheim norway ieee cusumano k nobeoka thinking beyond lean multiproject management transforming product development toyota company simon schuster dennehy l kasraian oraghallaign k conboy product market fit framework lean product development proceeding rd management conference science society innovation value creation cambridge uk g g des r ireland zahra w floyd j j janney p j lane emerging issue corporate entrepreneurship journal management dingsoyr lindsjorn team performance agile development team finding focus group proceeding th international conference agile software development page vienna austria k dovan reliability content analysis common misconception recommendation human communication research dyba sjoberg cruzes work role context empirical software engineering proceeding international symposium empirical software engineering measurement esem page lund sweden acm dyba dingsoyr empirical study agile software development systematic review information software technology h edison conceptual framework lean startup enabled internal corporate venture proceeding st international workshop software startup page bolzanobozen italy springer h edison n bin ali r torkar towards innovation measurement software industry journal system software h edison khanna bajwa v brancaleoni l bellettati towards software tool portal support startup process proceeding st international workshop software startup page bolzano italy springer h edison x wang p abrahamsson lean startup scientific workshop proceeding xp conference page helsinki finland acm social medium sap store case study proceeding european design science symposium eds page dublin ireland springer k eisenhardt j martin dynamic capability strategic management journal r eisenmann e ries dillard hypothesisdriven entrepreneurship lean startup harvard business school elo h kyngas qualitative content analysis process journal advanced nursing ensley k hmieleski c l pearce importance vertical shared leadership within new venture top management team implication performance startup leadership quarterly w eversheim innovation management technical product systematic integrated product development production planning springer science business medium c fernandezsanchez j garbajosa yague framework aid decision making technical debt management proceeding th international workshop managing technical debt mtd page bremen germany ieee c fonseca ecosystema de startup de software da cidade de sao paulo master thesis university sao paulo francis w sandberg friendship within entrepreneurial team association team venture performance entrepreneurship theory practice frenkel maital mapping national innovation ecosystem foundation policy consensus edward elgar publishing london uk j fuller r schroll e von hippel user generated brand contribution diffusion user innovation research policy j gans stern product market market idea commercialization strategy technology entrepreneur research policy garvin l c levesque meeting challenge corporate entrepreneurship harvard business review c giardino bajwa x wang p abrahamsson key challenge earlystage software startup proceeding th international xp conference xp page helsinki finland springer c giardino n paternoster unterkalmsteiner gorschek p abrahamsson software development startup company greenfield startup model transaction software engineering c giardino unterkalmsteiner n paternoster gorschek p abrahamsson know software development startup ieee software c giardino x wang p abrahamsson earlystage software startup fail behavioral framework proceeding th international conference software business icsob page paphos cyprus springer f giones f miralles strategic signaling dynamic technology market lesson three startup spain global business organizational excellence gorschek c wohlin p carre larsson model technology transfer practice ieee software c grevet e gilbert piggyback prototyping using existing largescale social computing system prototype new one proceeding rd annual acm conference human factor computing system page seoul korea acm harb c noteboom sarnikar evaluating project characteristic selecting bestfit agile software development methodology teaching case journal midwest association information system jmwais hatzakis lycett serrano programme management approach ensuring curriculum coherence higher education european journal information system w hayes research synthesis software engineering case metaanalysis proceeding th international software metric symposium page boca raton usa ieee b l herrmann jf gauthier holtschke r berman marmer global startup ecosystem ranking technical report august hill j birkinshaw ambdexterity survival corporate venture unit journal management op hilmola p helo l ojala value product development lead time software startup system dynamic review e v hippel innovation user community learning opensource software mit sloan management review l hokkanen k kuusinen k vaananen early product design startup towards ux strategy proceeding th international conference productfocused software process improvement profes page bolzanobozen italy springer l hokkanen k kuusinen k vaananen minimum viable user experience framework supporting product design startup proceeding th international xp conference xp edinburgh scotland springer press l hokkanen leppanen three pattern user involvement startup proceeding th european conference pattern language program europlop page kloster irsee germany acm l hokkanen k vaananenvainiomattila ux work startup current practice future need proceeding th international xp conference xp page helsinki finland springer b honig karlsson institutional force written business plan journal management g hu l wang fetch b bidanda multiobjective model project portfolio selection implement lean six sigma concept international journal production research international organization standardization ergonomics humansystem interaction part humancentred design interactive system iso jack j hyman f osborne small entrepreneurial venture culture change impact hrm critical review human resource management review j j p jansen p tempelaar f j van den bosch h w volberda structural differentiation ambidexterity mediating role integration mechanism organization science jayshree r ramraj entrepreneurial ecosystem case study influence environmental factor entrepreneurial success european journal business management f johne p snelson success factor product innovation selective review literature journal product innovation management johri boundary spanning knowledge broker emerging role global engineering firm proceeding th annual frontier education conference page ieee j jarvinen huomo mikkonen p tyrvainen agile software development mercury business proceeding th international conference software business icsob page paphos cyprus springer j kamm j shuman j seeger nurick entrepreneurial team new venture creation research agenda entrepreneurship theory practice karlsson b honig judging business cover institutional perspective new venture business plan journal business venturing j katz w b gartner property emerging organization academy management review j r katzenbach k smith discipline team harvard business review kelly lesson learned software testing startup eurostarsoftware testing conference amsterdam netherlands b kersten c verhoef portfolio management banker perspective cutter journal kirk macdonell categorising software context proceeding america conference information system amcis savannah usa ai electronic library kirk g macdonell investigating conceptual construct software context proceeding th international conference evaluation assessment software engineering ease page london uk acm kirsh b goldfarb gera firm substance role business plan venture capital decision making process strategic management journal b kitchenham l madeyski budgen j keung p brereton charter gibbs pohthong robust statistical method empirical software engineering empirical software engineering page b kitchenham dyba jorgensen evidencebased software engineering proceeding th international conference software engineering icse page edinburgh uk ieee e klotins unterkalmsteiner gorschek software engineering practice startup company mapping study th international conference software business page springer e klotins unterkalmsteiner gorschek software engineering startup company exploratory study startup empirical software engineering submission k klyver schenkel resource access use exploring impact resource combination nascent entrepreneurship journal small business management f kon cukier c melo hazzan h yuklea conceptual framework software startup ecosystem case israel technical report technical report rtmac department computer science university sao paulo j krebs agile portfolio management microsoft press st edition konig g baltes b katzy role valuenetwork strength indicator technologybased venture survival growth increasing innovation system efficiency leveraging transaction relation prioritize venture support proceeding international conference engineering technology innovation international technology management conference iceitmc page ieee konig c ungerer r buchele g baltes agreement venture reality presentedin business plan proceeding nd international conference engineering technology innovation ice trondheim norway ieee lavie et al lavie u stettner l tushman exploration exploitation within across organization academy management annals lefave et al r lefave b branch c brown sprint nextel reconfigured resource result mi quarterly lerner j lerner corporate venturing harvard business review levie lichtenstein j levie b b lichtenstein terminal assessment stage theory introducing dynamic state approach entrepreneurship entrepreneurship theory practice li et al z li p avgeriou p liang systematic mapping study technical debt management journal system software lichtenstein et al b b lichtenstein k j dooley g lumpkin measuring emergence dynamic new venture creation journal business venturing lichter et al h lichter schneiderhufschmidt h zullighoven prototyping industrial software projectsbridging gap theory practice proceeding th international conference software engineering icse page baltimore usa ieee lim et al e lim n taksande c seaman balancing act software practitioner say technical debt ieee software lippoldt stryszowskim lippoldt p stryszowskim innovation software sector technical report organisation economic cooperation development lofsten lindelof h lofsten p lindelof science park growth new technologybased firmsacademicindustry link innovation market research policy macmillan et al c macmillan l zemann p subbanarasimha criterion distinguishing successful unsuccessful venture venture screening process journal business venturing marijarvi et al j marijarvi l hokkanen komssi h kiljander xu raatikainen p seppanen j heininen koivulahiojala helenius j jarvinen cookbook successful internal startup digile n marlow marlow human resource management smaller firm contradiction term human resource management review maurya maurya running lean iterate plan plan work oreilly medium inc lean lean ux ux veteran lesson learned creating launching complex consumer app proceeding agile conference agile page dallas usa ieee conceptual framework international journal project management mile huberman b mile huberman qualitative data analysis expanded sourcebook sage publication inc thousand oak u mullins komisar j w mullins r komisar getting plan b breaking better business model harvard business press mulrow c mulrow rationale systematic review bmj british medical journal nambisan et al nambisan k lyytinen majchrzak song digital innovation management reinventing innovation management research digital world mi quarterly press nanda rhodeskropf r nanda rhodeskropf investment cycle startup innovation journal financial economics nazar j nazar famous business pivot available online httpwwwforbescomsitesjasonnazarfamousbusinesspivotshttpwwwforbescomsitesjasonnazarfamousbusinesspivots newbert et al l newbert gopalakrishnan b kirchhoff looking beyond resource exploring importance entrepreneurship firmlevel competitive advantage technologically intensive industry technovation newbert tornikoski l newbert e tornikoski supporter network network growth contingency model organizational emergence small business economics newman et al p newman ferrario w simm forshaw friday j whittle role design thinking physical prototyping social software engineering th ieee international conferenceon software engineering nguyen duc p abrahamsson minimum viable product multiple facet product role mvp software startup proceeding th international xp conference edinburgh uk springer nguyen duc p seppanen p k abrahamsson huntergatherer cycle conceptual model evolution software startup page tallin estonia acm c nobel teaching lean startup strategy hb working knowledge oechslein tumasjan examining trust within team startup companiesan empirical study people republic china proceeding th hawaii international conference system science hicss page maui usa c oreilly l tushman organizational ambidexterity past present future academy management perspective n paternoster c giardino unterkalmsteiner gorschek p abrahamsson software development startup company systematic mapping study information software technology j pelrine understanding software agility social complexity point view emergence complexity organization k petersen c wohlin context industrial software engineering research proceeding rd international symposium empirical software engineering measurement esem page orlando usa ieee pikkarainen w codenie n boucart j heredia alvaro editor art software innovation springer berlin germany raz e michael use benefit tool project risk management international journal project management b reyck grushkacockayne lockett r calderini moura sloper impact project portfolio management information technology project international journal project management e ries lean startup today entrepreneur use continuous innovation create radically successful business crown book j rikkila p abrahamsson x wang implication complexity perspective software engineering practice research journal computer engineering information technology sarasvathy causation effectuation toward theoretical shift economic inevitability entrepreneurial contingency academy management semrau sigmund networking ability financial performance new venture mediation analysis among younger mature firm strategic entrepreneurly journal shahid bajwa x wang nguyen duc p abrahamsson software startup pivot empirical result multiple case study th international conference software business icsob page ljubljana slovenia shontell disruptive startup business insider f shull falessi c seaman diep l layman technical debt showing way better transfer empirical result perspective future software engineering page springer j snowden e boone leader framework decision making harvard business review sommerville software engineering pearson boston th edition c r b souza h sharp j singer l cheng g venolia guest editor introduction cooperative human aspect software engineering ieee software srinivasan barchas gorenberg e simoudis venture capital fueling innovation economy computer gatherer model based wayfaring international journal engineering education r sternberg success factor universityspinoffs regional government support program versus regional environment technovation page sutton role process software startup ieee softw taipale huitablea story finnish lean startup proceeding st international conference lean enterprise software system le page helsinki finland springer j teece g pisano shuen dynamic capability strategic management strategic management journal h terho suonsyrj karisalo mikkonen way cross rubicon pivoting software startup proceeding st international workshop software startup page bolzanobozen italy springer economist cambrian moment cheap ubiquitous building block digital product service caused explosion startup special report tech startup economist economist testing testing launching startup become fairly easy follows backbreaking work special report tech startup economist economist progress without profit flock startup making cloud computing faster flexible survive economist e tom aurum r vidgen exploration technical debt journal system software r torkar p minoves j garrigos adopting freelibreopen source software practice technique method industrial use journal association information system j r turner handbook projectbased management mcgrawhill p tyrvainen saarikallio aho lehtonen r paukeri metric framework cycletime reduction software value creation proceeding th international conference software engineering advance icsea barcelona spain iaria c ungerer konig f giones g baltes measuring venture emergence survival analyzing transaction relation business plan proceeding nd international conference engineering technology innovation ice trondheim norway ieee unterkalmsteiner gorschek islam c cheng r permadi r feldt conceptual framework spi evaluation journal software evolution process v van de vrande j p de jong w vanhaverbeke de rochemont open innovation smes trend motif management challenge technovation j van der ven j bosch pivot architectural decision two side medal proceeding th international conference software engineering advance icsea page venice italy w vanhaverbeke cloodt open innovation value network open innovation researching new paradigm h v ven poole explaining development change organization academy management review e wenger community practice learning meaning identity cambridge university press j west open open enough melding proprietary open source platform strategy research policy j west gallagher challenge open innovation paradox firm investment opensource software r management r wieringa empirical research method technology validation scaling practice journal system software p williams competent boundary spanner public administration p witt entrepreneur network success startup entrepreneurship regional development wmf intelligent asset unlocking circular economy potential technical report world economic forum december j wohlin claes aurum aybuke angelis lefteris phillips laura dittrich yvonne gorschek tony grahn hakan henningsson kennet kagstrom simon low graham rovegard per tomaszewski piotr van toorn christine winter success factor powering academia collaboration ieeesoftware yague j garbajosa j perez j diaz analyzing software product innovation assessment using systematic literature review proceeding th hawaii international conference system science hicss page waikoloa usa ieee yau c murphy rigorous agile methodology best development strategy small scale tech startup technical report mscis r k yin case study research design method sage publication rd edition j zettel f maurer j munch l wong lipe lightweight process ebusiness startup company based extreme programming proceeding rd international conference productfocused software process improvement profes page springer kaiserslautern germany title software startup pivot empirical result multiple case study transcription software startup pivot empirical result multiple case study sohaib shahid bajwa free university bozenbolzano piazza domenicani bolzano italy httpwwwunibzithttpwwwunibzit xiaofeng wang free university bozenbolzano piazza domenicani bolzano italy httpwwwunibzithttpwwwunibzit anh nguyen duc norwegian university science technology trondheim norway software startup research network httpsoftwarestartupsorghttpsoftwarestartupsorg pekka abrahamsson norwegian university science technology trondheim norway software startup research network httpsoftwarestartupsorghttpsoftwarestartupsorg abstract order handle intense time pressure survive dynamic market software startup make crucial decision constantly whether change direction stay chosen course term lean startup pivot persevere existing research knowledge software startup pivot limited study focused understanding pivoting process software startup identified triggering factor pivot type achieve employed multiple case study approach analyzed data obtained four software startup initial finding show different software startup make different type pivot related business technology product development life cycle pivot triggered various factor including negative customer feedback keywordssoftware startup lean startup pivot validated learning introduction many people know twitter arguably famous microblogging platform much le aware podcast service provider back startup phase similarly instagram back early day social checkin application called burbn combining feature photo share app foursquare game mafiawars example show software startup get product business right immediately end initially started software startup intend produce cutting edge product grow fast condition extreme technology business uncertainty order obtain sustainable business model software startup change direction relentlessly make pivot lean startup approach ries defines pivot strategic change designed test fundamental hypothesis product business model engine growth pivot often considered outcome validated learning another key concept lean startup test business hypothesis measure result software startup often neglect validated learning process avoid pivot needed one reason behind many startup failure pivot considered vital software startup survive grow eventually obtain suitable business model due nascent nature software startup research previous empirical study specially focusing pivot scarce best knowledge study conducted exploring different type pivot identifying different triggering factor study attempt fill knowledge gap examining pivot software startup different product development stage concept mature product main objective study provide better understanding pivot happening software startup end main research question asked study software startup pivot different product development stage rest paper organized follows section background related work presented section describes empirical research approach finding presented detail section discussed section paper summarized section outlining future research background related work pivot core concept lean startup startup methodology focus buildmeasurelearn bml loop three step turn idea product measure effect learn result learning referred validated learning hypothesis regarding business model tested decision made accordingly whether pivot persevere pivot introducing change even though two term often used synonym pivot special kind change designed test validate assumption startup product business model engine growth ries present ten different type pivot happen startup listed table
Original Title: Software Startups -- A Research Agenda
Original Transcription: # Software Startups - A Research Agenda

Michael Unterkalmsteiner\({}^{*}\), Pekka Abrahamsson\({}^{**}\), XiaoFeng Wang\({}^{***}\), Anh Nguyen-Duc\({}^{***}\), Syed Shah\({}^{****}\), Sohaib Shahid Bajwa\({}^{****}\), Guido H. Baltes\({}^{****}\), Kieran Conboy\({}^{****}\), Eoin Cullina\({}^{****}\), Denis Dennehy\({}^{****}\), Henry Edison\({}^{****}\), Carlos Fernandez-Sanchez\({}^{****}\), Juan Garbajosa\({}^{****}\), Tony Gorschek\({}^{****}\), Eriks Klotins\({}^{****}\), Laura Hokkanen\({}^{****}\), Fabio Kon\({}^{****}\), Ilaria Lunesu\({}^{****}\), Michele Marchesi\({}^{****}\), Lorraine Morgan\({}^{****}\), Markku Oivo\({}^{****}\), Christoph Selig\({}^{****}\), Pertti Seppanen\({}^{****}\), Roger Sweetman\({}^{****}\), Pasi Tyrvainen\({}^{****}\), Christina Ungerer\({}^{****}\), Agustin Yague\({}^{****}\)\({}^{*}\)_Blekinge Institute of Technology, Sweden_

\({}^{**}\)_Norwegian University of Science and Technology, Norway_

\({}^{***}\)_Free University of Bolzano-Bozen, Italy_

\({}^{****}\)_Norwegian University of Science and Technology, Norway_

\({}^{****}\)_SICS, Sweden_

\({}^{****}\)_Free University of Bolzano-Bozen, Italy_

\({}^{****}\)_Lake Constance University, Germany_

\({}^{****}\)_National University of Ireland Galway, Ireland_

\({}^{****}\)_Free University of Bolzano-Bozen, Italy_

\({}^{****}\)_Universidad Politecnica de Madrid, Spain_

\({}^{****}\)_Technical University of Madrid, Spain_

\({}^{****}\)_Blekinge Institute of Technology, Sweden_

\({}^{****}\)_Tampere University of Technology, Finland_

\({}^{****}\)_University of Sao Paulo, Brazil_

\({}^{****}\)_University of Cagliari, Italy_

\({}^{****}\)_National University of Ireland Maynooth, Ireland_

\({}^{****}\)_University of Oulu, Finland_

\({}^{****}\)_Hochschule Konstanz, Germany_

\({}^{****}\)_University of Oulu, Finland_

\({}^{****}\)_National University of Ireland Galway, Ireland_

\({}^{****}\)_University of Jyvaskyla, Finland_

\({}^{****}\)_Hochschule Konstanz, Germany_

\({}^{****}\)_Universidad Politecnica de Madrid, Spain_

\({}^{****}\)_mur@bth.se, pekkaa@ntnu.no, xiaofeng.wang@unibz.it, anhn@idi.ntnu.no, shah@sics.se, bajwa@inf.unibz.it, guido.baltes@cetin.org, kieran.conboy@nuigalway.ie, eoin.cullina@outlook.com, denis.dennehy@nuigalway.ie, henry.edison@inf.unibz.it, carlos.fernandez@upm.es, jgs@eui.upm.es, tgo@bth.se, ekx@bth.se, laura.hokkanen@tut.fi, fabio.kon@ime.usp.br, ilaria.lunesu@diee.unica.it, michele@diee.unica.it, lorraine.morgan@nuim.ie, markku.oivo@oulu.fi, cselig@htwg-konstanz.de, pertti.seppanen@oulu.fi, roger.sweetman@nugalway.ie, pasi.tyrvinainen@jyu.fi, christina.ungerer@htwg-konstanz.de, ayague@etsisi.upm.es

###### Abstract

Software startup companies develop innovative, software-intensive products within limited time frames and with few resources, searching for sustainable and scalable business models. Software startups are quite distinct from traditional mature software companies, but also from micro-, small-, and medium-sized enterprises, introducing new challenges relevant for software engineering research. This paper's research agenda focuses on software engineering in startups, identifying, in particular, 70+ research questions in the areas of supporting startup engineering activities, startup evolution models and patterns, ecosystems and innovation hubs, human aspects in software startups, applying startup concepts in non-startup environments, and methodologies and theories for startup research. We connect and motivate this research agenda with past studies in software startup research, while pointing out possible future directions. While all authors of this research agenda have their main background in Software Engineering or Computer Science, their interest in software startups broadens the perspective to the challenges, but also to the opportunities that emerge from multi-disciplinary research. Our audience is therefore primarily software engineering researchers, even though we aim at stimulating collaborations and research that crosses disciplinary boundaries. We believe that with this research agenda we cover a wide spectrum of the software startup industry current needs.

## 1 Introduction

Researchers are naturally drawn to complex phenomena that challenge their understanding of the world. Software startup companies are an intriguing phenomenon, because they develop innovative software-intensive1 products under time constraints and with a lack of resources [142], and constantly search for sustainable and scalable business models. Over the past few years, software startups have garnered increased research interest in the Software Engineering (SE) community.

Footnote 1: ISO 42010:2011 [2] defines software-intensive systems as “any system where software contributes essential influences to the design, construction, deployment, and evolution of the system as a whole” to encompass “individual applications, systems in the traditional sense, subsystems, systems of systems, product lines, product families, whole enterprises, and other aggregations of interest”.

While one could argue that software startups represent an exceptional case of how software products are developed and brought to the market, several factors suggest a broader impact. From an economical perspective, startups contribute considerably to overall wealth and progress by creating jobs and innovation [3]. Digital software startups2 are responsible for an astonishing variety of services and products [165]. In the farming sector, venture investment in so-called "AgTech" start-ups reached $2.06 billion in just the first half of 2015; this figure neared the $2.36 billion raised during the whole of 2014 [184]. From an innovation perspective, startups often pave the way for the introduction of even more new and disruptive innovations [158]. Kickstarter is changing the retail and finance industries, Spotify is offering a new way to listen to and purchase music, and Airbnb is reinventing the hospitality industry [153]. From an engineering perspective, startups must inventively apply existing knowledge in order to open up unexpected avenues for improvement [68]; e.g., they must provide education for full stack engineers, develop techniques for continuous lightweight requirements engineering, or develop strategies to control technical debt.

Footnote 2: In our article, digital startups refer specifically to startups in which the business value of the solution is created by means of software [131].

Despite these promising conditions, software startups face challenges to survival, even in contexts where they play a key role in developing new technology and markets, such as cloud computing [167]. These challenges may arise because, while developing a product can be edifficult [166]. Software startups face other challenges, such as developing cutting-edge products, acquiring paying customers, and building entrepreneurial teams [67]. Such diverse factors underscore the need to conduct research on software startups, which will benefit both scholarly communities and startup leaders.

This paper's research agenda is driven by past and current work on software startups. We outline the various research tracks to provide a snapshot of ongoing work and to preview future research, creating a platform for identifying collaborations with both research and startup environments and ecosystems. This effort is not a one-way path. We have therefore founded a research network, the Software Startup Research Network (SSRN)3, which enables interactions and collaborations among researchers and interested startups. SSRN envisions to: (1) spread novel research findings in the context of software startups; and (2) inform entrepreneurs with necessary knowledge, tools and methods that minimize threats and maximize opportunities for success. As part of the network initiatives, an International Workshop of Software Startups was established in 2015. The first edition of the workshop was held in Bolzano4 (Italy) in 2015, and the second took place in Trondheim5 (Norway) in 2016. This paper provides a research agenda based on the activities carried out by the researchers in the network.

Footnote 3: [https://softwarestartups.org](https://softwarestartups.org)

Footnote 4: [http://ssu2015.inf.unibz.it/](http://ssu2015.inf.unibz.it/)

Footnote 5: [https://iwssublog.wordpress.com/](https://iwssublog.wordpress.com/)

The rest of the paper is organized as follows. After we clarify the meaning of _software startup_ and what we know about software startups from prior research in the Background section, Section 3 introduces the research topics on software startups, organized under six main tracks that we have either investigated or envision investigating in the future. Wherever possible, each topic is illustrated and motivated by previous studies. Section 4 highlights the implications of these main tracks for future research. The paper concludes with Section 5, which points out future actions that can establish and consolidate software startups as a research area.

## 2 Background

### What is a Software Startup?

To understand software startups, we must first clarify what a startup is. According to Ries [148], a startup is a human institution designed to create a new product/service under conditions of extreme uncertainty. Similarly, Blank [10] describes a startup as a temporary organization that creates high-tech innovative products and has no prior operating history. These definitions distinguish startups from established organizations that have more resources and already command a mature market. In addition, Blank [10, 12] defines a startup as a temporary organization that seeks a scalable, repeatable, and profitable business model, and therefore aims to grow. Blank's definition highlights the difference between a startup and a small business, which does not necessarily intend to grow, and consequently lacks a scalable business model.

Even though sharing common characteristics with other types of startups, such as resource scarcity and a lack of operational history, software startups are often caught up in the wave of technological change frequently happening in software industry, such as new computing and network technologies, and an increasing variety of computing devices. They also need to use cutting-edge tools and techniques to develop innovative software products and services [161]. All these make software startups challenging endeavours and meanwhile fascinating research phenomena for software engineering researchers and those from related disciplines.

In 1994, Carmel first introduced the term _software startup_, or, to be more precise, _software package startup_, in SE literature [22]. Carmel [22] argued that software was increasingly becoming a fully realized product. Since then, other researchers have offered their own definitions of _software startup_. Sutton [161] considers software startups as organizations that are challenged by limited resources, immaturity, multiple influences, vibrant technologies, and turbulent markets. Hilmola et al. [79] claim that most software startups are product-oriented and develop cutting edge software products. Coleman and Connor [31] describe software startups as unique companies that develop software through various processes and without a prescriptive methodology.

Currently, there is no consensus on the definition of _software startup_, even though many share an understanding that software startups deal with uncertain conditions, grow quickly, develop innovative products, and aim for scalability. Different definitions emphasize distinct aspects, and consequently may have varying implications for how studies that adopt them should be designed, e.g., who qualifies as study subjects, or which factor is worth exploring. For this reason, despite the lack of a single agreed-upon definition of _software startup_, it is important and recommended that researchers provide an explicit characterization of the software startups they study in their work. The research track in Section 3.1.1 is dedicated to develop a software startup context model that would allow for such a characterization.

### What are the Major Challenges of Software Startups?

Software startups are challenging endeavours, due to their nature as newly created companies operating in uncertain markets and working with cutting edge technology. Giardino et al. [69] highlight software startups' main challenges as: their lack of resources, that they are highly reactive, that they are by definition a new company, that they are comprised of small teams with little experience, their reliance on a single product and innovation, and their conditions of uncertainty, rapid evolution, time pressure, third-party dependency, high risk, and dependency (they are not self-sustained). Further, Giardino et al. [67] apply the MacMillan et al. [122] framework in the software startup context, categorizing the key challenges faced by early stage software startups into four holistic dimensions: product, finance, market, and team. The findings of Giardino et al. [67] reveal that thriving in technological uncertainty and acquiring the first paying customer are the top key challenges faced by many startups. In another study, Giardino et al. [70] discover that inconsistency between managerial strategies and execution could lead to startup failure.

Although research exists on the challenges software startups face, there is no study dedicated to their success factors. Block and Macmillan's [14] study highlights the success factors for any new business, including generating ideas to complete product testing, completing a prototype, and consistently re-designing or making amendments. Researchers have yet to explore these general factors' applicability to the specific software startup context.

### What do We Know about Software Engineering in Software Startups?

Software development comprises a software startup's core activity. However, some initial research studies report a lack of software engineering activities in software startups. A systematic mapping study conducted by Paternoster et al. [142] allows us to start understanding how software startups perform software development. The study reveals that software requirements are often market driven and are not very well documented. Software development practices are only partially adopted; instead, pair programming and code refactoring sessions supported by ad-hoc code metrics are common practices. Testing is sometimes outsourced or conducted through customer acceptance and focus groups, and team members are empowered and encouraged to adapt to several roles. Similarly, Giardino et al. [69] highlight the most common development practices that have been used in software startup companies, such as: using well-known frameworks to quickly change the product according to market needs, evolutionary prototyping and experimenting via existing components, ongoing customer acceptance through early adopters' focus groups, continuous value delivery, focusing on core functionalities that engage paying customers, empowerment of teams to influence final outcomes, employing metrics to quickly learn from consumers' feedback and demand, and engaging easy-to-implement tools to facilitate product development.

Although a few studies provide snapshots of software engineering practices in software startups [106, 68], the state of the art presented in literature is not enough to base an understanding of how software engineering practices could help software startups. Researchers must build a more comprehensive, empirical knowledge base in order to support forthcoming software startups. The research agenda presented in this paper intends to inspire and facilitate researchers interested in software startup related topics to start building such knowledge base.

## 3 Research Agenda

The Software Startup Research Agenda, initialized in June 2015, was developed by a network of researchers interested in studying the startup phenomenon from different angles and perspectives. This variety of research interests not only opens up new avenues for collaboration, but also sheds light on the complexity of the studied phenomenon. Initially, ten researchers created a mind map of different research areas, aiming to provide an overview of software startup research areas and how they connect to each other. Over a period of six months, more researchers joined the network, added their research tracks, and continuously expanded the map. A working session with twenty researchers at the 1st workshop on software startup research in December 2015 was devoted at discussing the identified areas and finding potential interest overlaps among the participants. After this meeting, the authors of this paper prepared eighteen research track descriptions according to the following pattern: background of the area, motivation and relevance for software engineering in startups, research questions, potential impact of answering these research questions on practice

Figure 1: Overview of the Software Startup Research Agenda

and research, potential research methodologies that can be employed to answer the proposed research questions, and related past or ongoing work. Most of the authors interacted in the past or are currently active as advisory board members, mentors, founders or team members of software startups.

The leading authors of this paper grouped the eighteen research tracks into six major clusters, based on the thematic similarities and differences of the tracks. While this grouping is one of the several possible ways to create the clusters, it served the purpose to ease the presentation and discussion of the research agenda, shown in Figure 1. Supporting Startup Engineering Activities (Section 3.1) encompasses research foci that address specific software engineering challenges encountered by startup companies. Startup Evolution Models and Patterns (Section 3.2) focuses on the progression of startups over time, trying to understand the underlying mechanics that drive a company towards success or failure. Human Aspects in Software Startups (Section 3.3) covers research tracks that investigate factors related to the actors involved in startups. The research on Applying Startup Concepts in Non-Startup Environments (Section 3.4) seeks to strengthen innovation by extracting successful software startup practices and integrating them in traditional environments. Startup Ecosystems and Innovation Hubs (Section 3.5), on the other hand, investigates whether and how a thriving environment for software startups can be designed. Finally, all of these areas are connected by research tracks that develop methodologies and theories for software startup research (Section 3.6).

Figure 1's illustration of the research agenda includes reference to research areas outside this paper's current scope. Marketing and Business and Economic Development are directions that are likely relevant for the performance of software startups. These and other areas may be added to the research agenda in later editions when more evidence exists regarding whether and how they interact with software startup engineering, i.e. the "use of scientific, engineering, managerial and systematic approaches with the aim of successfully developing software systems in startup companies" [68].

### Supporting Startup Engineering Activities

The research tracks in this cluster share the theme of studying, identifying, transferring, and evaluating processes, methods, framework, models, and tools aimed at supporting software startup engineering activities.

#### 3.1.1 The context of software intensive product engineering in startups

Rapid development technologies have enabled small companies to quickly build and launch software-intensive products with few resources. Many of these attempts fail due to market conditions, team breakup, depletion of resources, or a bad product idea. However, the role of software engineering practices in startups and their impact on product success has not yet been explored in depth. Inadequacies in applying engineering practices could be a significant contributing factor to startup failure.

Studies show that startups use ad-hoc engineering practices or attempt to adopt practices from agile approaches [187, 105]. However, such practices often focus on issues present in larger companies and neglect startup-specific challenges. For example, Yau and Murphy [187] report that test-driven development and pair programming provide increased software quality at an expense of cost and time. Also keeping to a strict backlog may hinder innovation. Since neglecting engineering challenges can lead to sub-optimal product quality and generate waste, engineering practices specific to the startup context are needed. The overarching questions in this research track are:* RQ1: To what degree is the actual engineering a critical success factor for startups?
* RQ2: How can the startup context be defined such that informed decisions on engineering choices can be made?
* RQ3: What engineering practices, processes and methods/models are used today, and do they work in a startup context?

An answer to RQ1 could help practitioners to decide on what activities to focus on and prioritize allocation of resources. Several studies, e.g Paternoster et al. [142], Giardino et al. [67] and Sutton [161], emphasize the differences between established companies and startups, noting that startups are defined by limited resources and dynamic technologies. However, these characterizations are not granular enough to support a comparison of engineering contexts in different companies, making the transfer of practices from company to company difficult [144]. Thus, understanding the engineering context of startups (RQ2) is an important milestone in developing startup context specific engineering practices (RQ3). While there exists work that provides systematic context classifications for the field of software engineering in general [144, 27, 47, 101, 100], these models are not validated and adapted for use within startups. The work in this research track aims to develop such a software startup context model by analysing data from startup experience reports [106]. Provided that engineering contexts among startups and established companies can be compared at a fine level of detail, the context model can be used to identify candidate practices. Moreover, researchers can develop decision support by mapping specific challenges with useful practices, thereby validating the model and helping practitioners select a set engineering practices for their specific context and set of challenges.

#### 3.1.2 Technical debt management

The software market changes rapidly. As discussed by Feng et al. [59], in fast changing environments, the product management focus evolves from the more traditional cost or quality orientation to a time orientation. New product development speed is increasingly important for organizations, and a commonly shared belief is that time-to-market of new products can build a competitive advantage [59]. In the software startup context, it may be vital to be the first to market in order to obtain customers. Since software startups also lack resources, quality assurance is often largely absent [142]. However, long-term problems will only be relevant if the product obtains customers in the short term [168]. This short-term vision may produce software code that is low-quality and difficult to change, compelling the company to invest all of its efforts into keeping the system running, rather than increasing its value by adding new capabilities [168]. Scaling-up the system may become an obstacle, which will prevent the company from gaining new customers. Finding a viable trade-off between time-to-market demands and evolution needs is thus vital for software startups.

One promising approach to performing such a trade-off is technical debt management. Technical debt management consists of identifying the sources of extra costs in software maintenance and analysing when it is profitable to invest effort into improving a software system [168]. Hence, technical debt management could assist startups in making decisions on when and what to focus effort on in product development. Technical debt management entails identifying the technical debt sources, the impact estimation of the problems detected, and the decision process on whether it is profitable to invest effort in solving the detected sources of technical debt [60, 116]. Only those sources of technical debt that provide return on investment should be resolved. More importantly, technical debt should be managed during project development [119] in order to control the internal quality of the developed software. Several research questions need to be answered to successfully manage technical debt in this way:* RQ1: What kind of evolution problems are relevant in the software startup context? How can we identify them?
* RQ2: How can we prioritize the possible improvements/changes in the context of software startups?
* RQ3. What factors beyond time-to-market and resource availability must be considered in trade-offs?
* RQ4: How can we make decisions about when to implement the improvements/changes within the software startup roadmap?
* RQ5: How can we provide agility to technical debt management, necessary in an environment plenty of uncertainty and changes?

Answering these questions will impact on both practitioners and researchers focused on software startups. Practitioners will be able to make better decisions considering the characteristics of the current software product implementation. The current implementation could make it impossible to reach a deadline (time to market), because of the complexity of the changes to perform to implement a new feature, assuming a given amount (and qualifications) of effort to be deployed. Furthermore, it will be also possible to decide between two alternative implementations, with different costs, but also with different potential for the future, assuming that the "future" has been previously outlined. For researchers, answering these questions could help clarify the role of design decisions in software development in the context of a software product roadmap, similarly to what happens in other engineering disciplines.

Technical debt is context dependent since quality tradeoffs are context dependent [154]. While technical debt is as important to software startups as it is to mature companies, the kind of decisions to take and the consequences of making the wrong decisions are not the same, justifying research on technical debt specifically in software startups.

In general, there is a lack of specific studies on technical debt management in software startups, and current literature reviews on technical debt management do not address this topic [60, 116]. Moreover, there are several specific challenges to managing technical debt that are of special relevance for software startups. For one, very few studies address how to prioritize improvements to solve technical debt problems, especially for commercial software development [116]. In addition, technical debt management literature often refers to time-to-market, but very few studies actually address it [60], perhaps because it is a topic that straddles engineering and economics.

#### 3.1.3 Software product innovation assessment

Startup companies strive to create innovative products. For firms in general, and software startups in particular, it is critical to know as soon as possible if a product aligns with the market, or whether they can increase their chances to lead the market and recruit the highest possible number of customers [91].

The need to invest in infrastructures to measure the impact of innovation in software was highlighted by OECD [120], and more recently by Edison et al. [50]. These measures will enable companies to assess the impact of innovation factors and achieve the expected business goals, as well as to improve the understanding of success yield high returns on investments in the innovation process [120]. Product innovation assessment is thus very relevant for product developers, and especially for startups, which are more sensitive to market reactions. Product innovation assessment is complex, particularly for software products [58].

Product innovation assessment is reported in literature as the combination of a number of multi-dimensional factors impacting the success or failure of a software product [38]. Factor's measures intend to engage people in the innovation process to think more deeply about factors affecting product innovation. Factors such as time-to-market, perceived value, technology route, incremental product, product liability, risk distribution, competitive environment, life cycle of product, or strength of market could be grouped into dimensions like market, organization, environment, or any other terms of impact on the market and business drivers [5]. These factors can act as innovation enablers or blockers [35].

Since these factors are not always independent, it is critical to identify the existing dependencies and gain a better understanding of each factor's impact. It would be necessary to relate these factors to characteristics specific to software products, such as, but not limited to, software quality attributes proposed by ISO/IEC [1].

There is a lack of specific literature on _software_ product innovation assessment; most of the past research refers to products in general, and not specifically to software products [186, 50], leading to the following research questions:

* RQ1: What should be the components of a software product innovation assessment/estimation model?
* RQ2: What factors can help measure innovation from a software product and a market perspective?
* RQ3: To what extent are factors that can help measure innovation dependent on the software product and the market perspective?
* RQ4: What is the relation between software product innovation factors and quality factors?
* RQ5: What kind of tools for software product innovation estimation could support software startups in decision making?

While innovation has been widely studied from the process perspective, the product perspective, by nature, has been addressed mainly from the viewpoint of specific products and industries. However, software products are different compared to other kinds of products [145] and innovations in the software industry happen fast. Hence, answers to RQ1-RQ4 would provide a fundamental understanding on software product innovation assessment and be beneficial for both researchers and practitioners. Software startups need to be fast and spend resources in an efficient way. Therefore, to be able to estimate existing products or design new products, considering those characteristics that experience shows that are relevant from an innovation point of view, can be essential for software startups to develop successful products (RQ5).

#### 3.1.4 Empirical prototype engineering

Startups often start with a prototype, which serves as a form to validate either a new technology or knowledge about targeted customers [142]. Traditionally, prototyping implies a quick and economic approach to determining final products [118, 7, 156]. Defined as a concrete representation of part or all of an interactive system, prototypes has been intensively researched and used in Software Engineering, with well-developed taxonomies, such as horizontal and vertical, low-fidelity and high-fidelity prototypes [156]. The strategy of developing a prototype can greatly vary due to a great variety of prototype types, their development efforts and value they can produce.

While much about prototyping techniques can be learnt from the SE body of knowledge, the discussion about prototyping in the context of business development process is rare. Recent work on startup methodologies, such as Lean Startup [148] and Design Thinking [19] emphasizes the adoption of prototypes to increase chances of success through validated learning. Alternatively, startup prototypes need to be developed to satisfactorily serve their purposes, i.e. technical feasibility test, demonstration to early customers, and fund raising. We argue that the prevalent Software Engineering practices used by startups to develop their first product inefficiently integrate into startups' dynamic contexts. Hence we call for research in understanding the development and usage of prototypes in startup contexts:

* RQ1: How can prototyping be used to maximize learning experience?
* RQ2: How can prototyping be used for optimization?
* RQ3: How can prototyping be used to support communication with external stakeholders?
* RQ4: How do prototypes evolve under the multiple influences of startups' stakeholders?

Early stage startups are lacking actionable guidelines for making effective prototypes that can serve multiple purposes. We believe that many startups will economically and strategically benefit by having proper practices in prototyping, such as technology evaluation (RQ1), strategic planning (RQ2) and customer involvement (RQ3).

To understand prototype development and its usage in startups, i.e. answering the first three research questions, exploratory case studies can be conducted. Cases would be selected to cover different types of startup prototypes at different phase of startup progress. A large-scale survey can be used to understand the prototype usage patterns, i.e. answering RQ4.

Despite an increasing body of knowledge on software startups [142], empirical research on prototyping processes and practices are rare. A few studies have investigated the adoption of software prototypes in combination with Design Thinking [53] and proposed prototyping techniques [136, 53, 73]. However, these studies rely on a very limited number of cases. Moreover, different constraints on prototyping decisions are often neglected. Future work can address antecedence factors, i.e. the involvement of lead-users, available human resources, and technological push, and how they impact prototyping strategies and usages in different startup contexts [137].

#### 3.1.5 Risk Management Tools for Software Startups

The management of risk, namely the risk of failing to meet one's goals within given constraints in budget and/or time, is of paramount importance in every human activity. In the context of software startups, risk management looks unconventional, because startups naturally involve a much higher risk than traditional businesses. Yet, perhaps even more so than in traditional contexts, evaluating and managing risk in the software startup context might be a key factor for success.

Risk factors can be identified as a check-list of the incidents or challenges to face. Each of them could be categorized and prioritized according to its probability and the impact level of its consequences. This research track aims to study, model, and quantify various aspects related to risk management in software startups, with the goal of providing tools, based on process simulation, that control risk. Being able to efficiently model and simulate the startup process and its dynamics, would support startups in timely decision making. While numerous other approaches to risk control exist [146], we have found in our previous work [30, 34] that process simulations can be effective in risk management. Therefore, the overarching questions in this research track are:

* RQ1: To what extent do software startups explicitly manage risk?
* RQ2: To what degree is it feasible to model software development processes in startups?
* RQ3: To what extent can these models be used to quantify the risk of exceeding project budget or time?
* RQ4: What systematic ways exist to understand when to pivot or persevere [148], and what might be the cost of a wrong or untimely decision?Following our previous experiences in software process modelling and simulation, to gain a better understanding is necessary to identify and analyse significant activities, not limited to the software development phase, of a software startup (RQ1). This is necessary to be able to identify the critical aspects of startup development risks that are suitable for simulation. In our previous work we studied the application of Event-Driven models and/or System Dynamics to the software development processes. From this work we know that it is possible analyse project variations in time and budget with a Monte Carlo approach, by performing several simulations of the same project, varying the unknown parameters according to given distributions, and calculating the resulting distributions of cost and time of the simulated projects. Such analysis allows one to compute the Value At Risk (VAR) of these quantities, at given VAR levels. While Cocco et al. [30] and Concas et al. [34] provide exemplar studies of the application of these techniques in mature (agile) software development contexts, the question is whether such an approach is suitable and beneficial for software startups, and under what conditions (RQ2). By simulating the evolution of a startup as a process, we might be able to make predictions on its future development. Such predictions, or a result that can be rapidly be drawn from simulations, might be crucial for startups to understand which decisions are less costly and/or risky (RQ3). This is particularly true for decisions related to fields such as market strategies, team management, financial issues or product development (RQ4).

#### 3.1.6 Startup support tools

Support tools can help software startups get their business off the ground with less pain and more guidance. These tools generally embed crucial knowledge regarding startup processes and activities. A plethora of tools (mostly software tools) exist for meeting the different needs of entrepreneurs and supporting various startup activities. For example, the web-page6 by Steve Blank, a renowned entrepreneurship educator, author, and researcher from Stanford University, contains a list of more than 1000 tools. Well-designed portals such as Startupstash.com ease access to these supporting tools.

Footnote 6: [http://steveblank.com/tools-and-blogs-for-entrepreneurs/](http://steveblank.com/tools-and-blogs-for-entrepreneurs/)

However, due to the lack of time, resources, and/or necessary knowledge, entrepreneurs cannot easily find the tools that best suit their needs, or cannot effectively utilize these tools to their potential. Existing studies provide limited insights on how entrepreneurial teams could find, use and benefit from support tools. Hence, the overarching questions in this research track are:

* RQ1: What are the needs of software startups that can be supported by software tools?
* RQ2: What are the tools that support different startup activities?
* RQ3: How can support tools be evaluated with respect to their efficiency, effectiveness, and return-on-investment?
* RQ4: How can support tools be effectively recommended to entrepreneurs and used by them?

RQ1 and RQ2 are targeted at identifying a match between the needs of software startups and the available tool support. To enable robust recommendations, both the individual startups and the software tools need to be objectively characterized allowing for their evaluation w.r.t. certain quality criteria (RQ3). There are potential synergies with the research track looking at the context characterization of software startups (Section 3.1.1). Answers to these research questions can be also valuable input for software tool vendors to develop the right tools that are needed by startups. In addition, the findings can be useful for future studies that develop proof-of-concept prototypes to support startup activities.

To investigate the proposed questions, various research methods can be applied, including survey of software startups regarding their needs and usage of support tools, in-depth case study of adoption and use of support tools, and design science approach to develop recommender systems of support tools (RQ4).

Research on tooling aspects in the software startup context is scarce. Edison et al. [51] argue that, despite the fact that different startup supporting tools have been developed and published over the Internet, new entrepreneurs might not have sufficient knowledge of what tools they need when compared to experienced entrepreneurs. In addition, not all tools will help entrepreneurs in certain tasks or situations. Entrepreneurs' experiences using the tools can serve as the basis for evaluating and recommending appropriate tools. Besides suggesting a new categorization of existing startup support tools, Edison et al. [51] propose a new design of a tool portal that will incorporate new ways to recommend tools to entrepreneurs, especially to those who engage for the first time in a software startup endeavour.

#### 3.1.7 Supporting software testing

Testing software is costly and often compromised in startups [189], as it is challenging for startups to fulfil customer needs on time, while simultaneously delivering a high quality product. In many software startups there is a common slogan that says "done is better than perfect", which indicates a general tendency toward a lack of testing and quality assurance activities [98]. However, it is sometimes also observed that startups do not know how and what to test; they lack expertise to test requirements as they do not have knowledge about their customers and users [98]. Therefore considering testing in software startups poses the following research questions:

* RQ1: To what extent does software testing in startup companies differ from traditional companies?
* RQ2: To what extent does testing evolve over time in software startup companies?
* RQ3: What is an optimal balance between cost/time spent on testing and development activities?
* RQ4: How can a software startup leverage customers/users for testing?

Answering RQ1 would provide insights on the aspects that differentiate the software testing process in startups from mature companies. For example, integration testing is likely very important for startups due to the fast paced product development. At the same time however, startups tend to work with cutting edge technologies, requiring a robust and flexible test integration platform. Connected to this is the question whether testing needs change over time, while the software startup matures. Answers to RQ2 and RQ3 would be particularly valuable for practitioners who could then better allocate resources. Users of software could be used for different testing purposes. On one hand, users provide valuable feedback in testing assumptions on customers needs. On the other hand, early adopters that are more robust towards deficiencies can help to improve product quality before targeting a larger market. Answers to RQ4 would provide strategies to harvest these resources.

In order to answer these research questions, various empirical research methods could be utilized. The studies would be devised in a way that "contrasting results but for anticipatable reasons" could be expected [188], i.e. different software startup companies would be taken into account to acquire a broad view of testing in software startups.

To the best of our knowledge, software testing in software startups has been scarcely researched. Paternoster et al. [142] highlighted the quality assurance activities in software startups in their mapping study. They found that it is important to provide software startups effective and efficient testing strategies to develop, execute, and maintain tests. In addition, they highlighted the importance of more research to develop practical, commercial testing solutions for startups.

#### 3.1.8 User experience

User experience (UX) is described as "a person's perceptions and responses that result from the use or anticipated use of a product, system or service" [87]. Good UX can be seen as providing value to users, as well as creating a competitive advantage. UX is important for software startups from their earliest stages. Firstly, human-centred design methods such as user research and user testing can help startups better understand how they can provide value to users and customers, as well as what features and qualities need testing for users to be satisfied with their product. Combined with business strategy, this human-centred approach helps startups move towards successful, sustainable business creation. Secondly, providing an initially strong UX in the first product versions can create positive word of mouth [64], as well as keep users interested in the product for a longer time [84]. Genuine interest from users for the product idea while the product is still a prototype helps gain meaningful feedback [84]. Compared to more established businesses, software startups may pivot resulting in new target markets and user groups. This means efforts put into designing UX need to be faster and less resource consuming. Furthermore, failing to deliver satisfying UX can be fatal to small startups that can not cover the costs of redesigning. The overarching questions in this research track are:

- RQ1: What useful methods and practices exist for creating UX in startups?

- RQ2: What is UX's role during different phases of a startup's life-cycle?

- RQ3: To what extent are UX and business models connected in customer value creation?

An answer to RQ1 can provide software startups methods for developing strong UX in the first product versions which can keep users interested in the product for a longer time [84]. Genuine interest from users for the product idea while the product is still a prototype helps to gain meaningful feedback [84]. For business creation, understanding the value of UX for startups (RQ2) helps assigning enough resources for creation of UX while not wasting resources where there is no value to be gained (RQ3).

Research on startups and UX has been very limited. Some case studies report UX's role in building successful startups [126, 162]. Practices and methods for UX work in startups have been reported in [84, 81, 83]. A framework for creating strong early UX was presented by Hokkanen et al. [82]. These provide some results on feasible and beneficial UX development in startups, but more generalizable results are needed.

### Startup Evolution Models and Patterns

The research tracks in this cluster share the theme of studying, identifying, and differentiating the transformation of startups in different stages. This also includes studies about different business and technical decision-making practices.

#### 3.2.1 Pivots in software startups

It is very difficult for software startups to understand from start what are the real problems to solve and what are the right software solutions and suitable business models. This is evidenced by the fact that many successful software startups are different from what they started with. For example, Flickr, a popular online photo sharing web application, originally was a multiplayer online role playing game [133]. Twitter, a famous microblogging application, was born from a failed attempt to offer personal podcast service [133].

Due to their dynamic nature, software startups must constantly make crucial decisions on whether to change directions or stay on the chosen course. These decisions are known as _pivot_ orpersevere_ in the terms of Lean Startup [148]. A pivot is a strategic decision used to test fundamental hypothesis about a product, market, or the engine of growth [148]. Software startups develop technology intensive products in nature. Due to this, these are more prone to the rapidly changing technology causing pivots. Similarly, certain types of pivots are more relevant to software startups e.g. zoom in pivot: a pivot where one feature of a product become the whole product as in the case of Flickr. Pivot is closely linked to validated learning, another key concept from Lean Startup. The process to test a business hypothesis and measure it to validate its effect is called validated learning [148], whereas pivot is often the outcome of validated learning. A recent study [70] reveals that startups often neglect the validated learning process, and neglect pivoting when they need to, which leads to failure. This shows the importance of pivoting for a startup to survive, grow, and eventually attain a sustainable business model. In order to better understand and explore the pivoting process in the software startup context, the following fundamental research questions can be formed:

* RQ1: To what extent is pivoting crucial for software startups?
* RQ2: How do software startups pivot during the entrepreneurial/startup process?
* RQ3: What are the existing process/strategies/methods to make a pivoting decision in a startup context?
* RQ4: How do pivots occur during different product development and customer development life cycles?

Answering RQ1-RQ2 is necessary to understand pivoting in the context of software startups, building a fundamental framework on reasons for pivoting and their types. RQ3-RQ4, on the other hand, are targeted at understanding pivoting decisions and mechanisms. The overall contribution of answering the stated research questions has implications for both researchers and practitioners. The answers would provide an empirically validated conceptual and theoretical basis for the researchers to conduct further studies regarding the pivot phenomenon. For the practitioners, it would help them to make informed decision regarding when and how to pivot in order to increase the chances of success.

Due to the nascent nature of software startup research area, exploratory cases studies is a suitable approach to answer the research questions. Followed by the case studies, quantitative surveys can also be conducted to further generalize the results regarding pivoting in software startups.

Recently, there were some studies conducted on pivots in software startups. A study by Van der Van and Bosch [175] compares pivoting decisions with software architecture decisions. Another study by Terho et al. [164] describes how different types of pivots may change business hypothesis on lean canvass model. However, these studies lack the sufficient detail to understand different types of pivots and the factors triggering pivots. A study by Bajwa et al. [152], presents an initial understanding of different types of pivots occurred at different software development stages, however it lacks the deeper understanding of the pivoting decision that can only be achieved by a longitudinal study.

#### 3.2.2 Determination of Software Startup Survival Capability through Business Plans

Software startups are highly specialized from a technological point of view. Focusing on the economic exploitation of technological innovations [121], they belong to the group of new technology-based firms. Literature suggests that one of their major challenges is the transformation of technological know-how into marketable products [65, 18]. New technology-based firms often struggle with unlocking the product-market fit [125] and commercializing their technological products [65]. Applying a resource-based view does thus not suffice for explaining survival and growth of software startups [107, 115]: a crucial success factor is the ability of new technology-based firms to understand and interact with the market environment to position their products accordingly [71, 28].

Particularly in early lifecycle stages, new technology-based firms need to build network relations with the market. Network theory literature suggests that with increasing network maturity, the chances for survival and growth increase [135, 151, 183]. The ability to transform resources in response to triggers resulting from market interactions can be described as a dynamic capability [54, 163, 134, 117] which helps software startups commercialize their products. This transformation process captures the evolution of new technology-based firms in their early-stages. Current research is based on the construct of "venture emergence", which provides a perspective on the evolutionary change process of new technology-based firms [71, 21]. Venture emergence reflects the interaction process with agents and their environments [96]. Business plans of new technology-based firms are used as the artefact for measuring the status of venture emergence. They contain descriptions of transaction relations [85, 102, 95] new technology-based firms build in four market dimensions: customer, partner, investor, and human resources [110]. This research track intends to answer a number of research questions:

* RQ1: How reliably can annotated transaction relations from business plan texts determine the venture emergence status of technology-based startups?
* RQ2: To what extent are the number and strength ("level") of identified transaction relationships useful as an indicator of survival capability?
* RQ3: How can patterns of transaction relations be used as an indicator for evaluating strengths and weaknesses of new technology-based firms, and thus be used to more effectively direct support measures?

While it is possible to measure the venture emergence status even in a software startup's very early stages, the predictive strength of transaction relations needs to be evaluated (RQ1-RQ2). This use of network theory to operationalize the venture emergence construct is a new approach, which adds to network theory literature in the context of the survival of new technology-based firms. It further confirms the business plans of new technology-based firms as a valuable source of information on startup potential. Finally, the resource-based approach to explain venture survival is enriched by applying a process-oriented perspective: we analyse resource transformation, rather than only looking at the initial resource configuration (RQ3). Furthermore, the research can contribute to the effectiveness of the innovation system by investigating indicators that reveal strengths and weaknesses of new technology-based firms. These can be used to direct support measures to software startups more effectively.

To answer the stated research questions, one can use content analysis [46, 56], combining human and computer-based coding of business plans, to determine the number and strength of transaction relations [111, 172].

Initial statistical tests that have been performed on a sample of 40 business plans of new technology-based firms confirm the relationship between the status of venture emergence of new technology-based firms and venture survival [172]. Earlier work led to the development of the concept for analysing early-stage startup networks and the relevance for survival [110]. Based on this concept, a coding method for transaction relations in business plans has been developed and validated with 120 business plans [111].

### Cooperative and Human Aspects in Software Startups

The research tracks in this cluster address challenges and practices related to how people cooperate and work is software startups.

#### 3.3.1 Competencies and competency needs in software startups

Software startups set different competency requirements on their personnel than more established companies. The biggest differences occur in two phases of the evolution of startups which have an impact on the nature of software development and competence needs: (1) in the early stages of rapid software development when there is a lack of resources and immature competencies in many key areas, and (2) when the rapid business growth of successful startups requires management of a fast growing personnel and amount of software with limited management resources and competencies. In the early phases strong competition requires the software startup to innovate and react quickly [142], and deployment of systematic software engineering processes is many times replaced by light-weight ad-hoc processes and methods [105, 142]. The nature of software makes it possible for successful startups to scale fast [142]. Rapid software-driven growth requires fast scaling of the software production, distribution, and maintenance. The required competences also quickly evolve when software development moves from rapid greenfield prototyping to professional software development and management. Mastering this demanding situation often requires a broad prior skill basis from the startup team, including an ability to adjust to changes, and learn quickly.

Research on specific skills and competency needs in software startups broadens not only the knowledge on software startups themselves, but also broadens the knowledge on software engineering conducted under the challenging circumstances of startups. Focusing the research on the early stages and on the growth period of the software startups, when the challenges of the software startups are the greatest [67, 70], brings the most valuable knowledge to both academia and practitioners. Competency research also brings human factors into focus [124, 88], and reinforces the results of existing software startup research towards a more comprehensive modelling and understanding. The research questions for studies on competencies and competency needs in software startups include:

* RQ1: Software startup challenges and competency needs -- what software development knowledge and skills are needed to overcome the challenges?
* RQ2: What are the competency needs specific for software startups compared to the more established software companies?
* RQ3: How do the competency needs change over the evolution of software startups?
* RQ4: How do the competency needs map onto the roles and responsibilities of the startup teams in software startups?
* RQ5: How can the growth of software startups be managed in terms of competency needs for software development practices, processes and recruitment?

Research on software startups, including research on competency needs, provides the research and development of software engineering with new knowledge and viewpoints on how to direct the work in order to best address the specific challenges of the software startups (RQ1). In particular, differences to mature software companies are interesting to study (RQ2) considering software startups evolve, if they survive, to established companies. Knowing how competency needs change might turn out as one key factor for this transition (RQ3). Theoretical models describing the evolution paths of software startups have been created [148, 16], but competency needs and how they map to roles and responsibilities have been to a large degree ignored (RQ4). Similarly, while softwaredevelopment work [142] and software engineering practices [105] have also been studied, it is unclear how competency needs can be managed in growing software startups (RQ5).

#### 3.3.2 Teamwork in software startups

The importance of human aspects in software development is increasingly recognized by software engineering researchers and practitioners. Teamwork effectiveness is crucial for the successes of any product development project [45]. A common definition of a team is "a small number of people with complementary skills who are committed to a common purpose, set of performance goals, and approach for which they hold themselves mutually accountable" [97]. A startup team is special in the wide range of variety, including both technicians and entrepreneurs.

While an innovative idea is important for the formation of a startup, startup success or failure ultimately rests on the ability of the team to execute. Entrepreneurship research showed that over 80 percent of startups that survive longer than two years were founded by a group of two or more individuals [140]. The dynamic and intertwined startups activities require the close collaboration not only among startup team members, but also with external stakeholders, such as mentors and investors. Given the diversity in mindsets and skill sets among founders, it is essential that they can work well together along with the startup life-cycle. The movement with recent methodology in Lean startup introduces an opportunity to look at startup teams from various angles, i.e. pivoting, startup culture, team formation, and decision-making. The overarching questions in this research track are:

* RQ1: Is there a common cultural / organizational / team characteristic among successful software startups?
* RQ2: How can a software startup team effectively communicate with other stakeholders, i.e. mentors and investors?
* RQ3: How can a software startup manage team internal relationships?
* RQ4: What are the common patterns of competence growth among software startup teams?

Understanding software startup team behaviour to internal and external environments and relating them to startup success measures would help to identify characteristics and teamwork patterns of successful startups. Answering RQ1 would provide practitioners some guidance on how to form startup teams while answers to RQ2-RQ3 would provide an understanding how internal end external team dynamics work and can improved. An answer to RQ4 would also support the work in Section 3.3.1, looking however specifically at competence growth patterns that could be valuable for practitioners when deciding on what to focus on in competence development. Empirical studies, i.e. case studies, surveys and action research are all suitable to investigate the stated research questions. Among them, comparative case studies would be the first option to discover the difference in startup teamwork patterns.

There exists a large body of literature in business management, entrepreneurship, and small ventures about entrepreneurial teams' characteristics and their relationship to startup outcomes [140, 94, 62]. In Software Engineering, few empirical studies identified team factors in the failure of software startups. Giardino et al. found that building entrepreneurial teams is one of the key challenges for early-stage software startups from idea conceptualization to the first launch [67]. Crowne et al. described issues with founder teamwork, team commitment and skill shortages [39]. Ensley et al. investigated the relative influence of vertical versus shared leadership within new venture top management teams on the performance of startups [57]. Other team dimensions are explored in the business and engineering management domain in specific geographies. E.g., Oechsellein analysedinfluencing variables on the relational capital dimension trust within IT startup companies in China [140]. How generalizable these influencing variables to other geographies is yet to be seen.

### Applying Startup Concepts in Non-Startup Contexts

One of the Lean Startup principles claims that entrepreneurs are everywhere, and that entrepreneurial spirits and approaches may be applied in any size company, in any sector or industry [148]. On the other hand, established organizations face the challenge of innovation dilemma and inertia caused by the organization's stability and the maturity of markets [36]. Therefore, applying startup concepts in non-startup contexts seems an promising avenue for established organizations to improve their innovation potential.

#### 3.4.1 Internal software startups in large software companies

The internal software startup concept has been promoted as a way to nurture product innovation in large companies. An internal software startup operates within the corporation and takes responsibility for everything from finding a business idea to developing a new product and introducing it to market [6]. Internal software startups can help established companies master the challenge of improving existing businesses, while simultaneously exploring new future business that sometimes can be very different from existing ones [78]. Usually, this involves a conflict of interest in terms of learning modes [89] or risk propensity [132], which can be prevented by establishing dual structures within the organization for implementing internal software startups [112]. Compared to the traditional R&D activities of larger companies, an internal software startup develops products or services faster [142] and with higher market orientation [114]. This helps established companies maintain their competitiveness in volatile markets [141].

Besides the fact that the successful implementation of internal software startups faces various barriers, such as cultural conflicts [66] or the fear of cannibalization of existing businesses [52], internal software startups can also benefit from being part of established companies. Shared resources, such as capital, human resources [24, 32], and the access to the corporates' internal and external network [44] are just some benefits.

Earlier research on analysing the results of startups' value creation cycle has taken place in the context of the evolution of the enterprise [37]. However, this occurs over too long of a time period to be useful for guiding software development. Measuring the cycle time of the software engineering process to the completion of a software feature is also insufficient. The Lean startup approach [148] has been commonly adopted to new business creation in software intensive ventures. They use the learning loop to discover the customer value and potential of the new product concept, as well as to find new means to produce software. Tyrvainen et al. [171] propose that measuring the cycle time from development to analysis of customer acceptance of the feature enables faster learning of market needs. In addition, receiving fast feedback from users makes changing the software easier for the programmers who have not yet forgotten the code. Relevant research questions regarding internal software startups can be formulated as follows:

* RQ1: How can Lean startup be adopted and adapted for software product innovation in large software companies?
* RQ2: What are the challenges and enablers of Lean startup in large software companies?
* RQ3: How should internal software startups be managed / lead?
* RQ4: What metrics can be used to evaluate software product innovation in internal startups?
* RQ5: To what extent do internal startups have a competitive advantage compared to independent startups (through shared resources, etc.)?Lean startup approach gains more interest from scholars and academics as a new way to foster innovation since it helps to avoid building products that nobody wants [55]. Some evidence shows that mature software companies and startups differ in applying Lean startup approach [93]; e.g. mature firms start the cycle by collecting data from existing users and then generating a hypothesis based on that data, whereas software startups generate ideas and collect data from new users to validate the ideas. However, it seems that, to a large extent, the approach can be used both in startups and established enterprises. By answering RQ1-RQ3 we aim at defining structured guidelines on how to introduce Lean startup in large software companies, supporting practitioners, while answering RQ4-RQ5 would provide a motivation for this approach, allowing to compare effectiveness on a quantitative level.

Due to the complex nature of the research phenomenon and the intention to achieve an in-depth understanding of it, we consider multiple case studies [188] as a suitable research approach. The case organizations can be selected based on the following criteria: (1) the organization develops software in-house, (2) a dedicated team is responsible from ideation to commercialization of a new software, and (3) the software falls out of the current main product line. The unit of analysis in this study would be a development team.

Very few studies have investigated how the Lean startup [148] can leverage internal startups in large software companies to improve their competency and capabilities of product innovation. Initial steps have been taken and some of the results have been published to fill this observed gap (e.g. [52, 49]). Marijarvi et al. [123] report on Finnish large companies' experience in developing new software through internal startups. They also discuss the lifecycle phases of innovation work in large companies. The authors argue that different types of internal organization may take place in each stage of new product development. For example, problem/solution fit can be done in an internal startup or company subsidiary.

#### 3.4.2 Lean Startup for project portfolio management and open innovation

Building on the challenges proposed in Section 3.4.1, we propose that Lean startup could also be applied within both (i) project portfolio management (PPM), to co-ordinate multiple startup initiatives within an organization, and (ii) open innovation, wherein internal startups involve multiple organizations, individuals, or even unknown participants. Both PPM and open innovation and their main challenges are briefly introduced below, followed by research questions that require investigation before Lean startup principles can be successfully applied in these new contexts.

Software engineering PPM describes the ongoing identification, selection, prioritization, and management of the complete set of an organization's software engineering projects, which share common resources in order to maximize returns to the organization and achieve strategic business objectives [127, 35, 13, 170]. Open innovation is defined as the use of "purposive inflows and outflows of knowledge to accelerate internal innovation and to expand the markets for external use of innovation, respectively" [26]. Popular examples of open innovation include open source software development, crowd-sourcing, and inner source.

Effective PPM is critical to achieving business value [75, 147], improving cost and time savings, and eliminating redundancies [99, 113]. Unfortunately, existing portfolio management practices, which are based on the effective completion of individual projects with only episodic portfolio level reviews [147], fail to manage either the dynamic nature of contemporary projects, or problems associated with portfolios comprising too many projects [109, 147]. Indeed, many portfolios report an unwillingness to cancel projects that no longer contribute to the achievement of strategy [147].

Open innovation (OI) presents numerous advantages for organizations, such as access to a requisite variety of experts, a prospective reduction in overall R&D spending, reduced time-to-market,improved software development processes, and the integration of the firm into new and collaborative value networks [26, 4, 176]. Nonetheless, adopting open innovation processes can be significantly challenging. For example, adopters often lack internal commitment, in addition to challenges associated with aligning innovation strategies to extend beyond the boundaries of the firm. Moreover, there are concerns regarding intellectual property and managing unknown contributors/contributions, as well as managing the higher costs and risks associated with managing both internal and external innovations [174, 180, 25]. The role of Lean startup principles in addressing these challenges in both PPM and OI is worthy of further research:

* RQ1: How can Lean start-up be implemented within a portfolio management or open innovation context?
* RQ2: How can Lean startup initiatives drive or accelerate open innovation?
* RQ3: What Lean startup concepts could be adapted to facilitate open innovation processes in an organization?
* RQ4: How can one ensure Lean startup initiatives conducted across multiple projects or organizations align with strategy?
* RQ5: How do you reconcile potential conflicts between portfolio / open innovation processes and Lean startup processes?
* RQ6: How do you achieve consensus in defining the minimum viable product (MVP) in networks comprised of multiple autonomous (and sometime anonymous) agents?

The successful application of Lean startup principles (RQ1-RQ3) has the potential to reduce the costs arising from the poor implementation of PPM and OI practices and increase the value achieved from these initiatives. However, because such approaches are often practice led, it is necessary for academic research to develop effective theory to underpin practice and provide empirical data to support, or refute claims of effectiveness (RQ4-RQ6). Rich human interactions are at the heart of software engineering PPM and open innovation. Accordingly, phenomena in these domains can be examined using interpretive, qualitative methods such as semi-structured interviews, case studies and ethnography.

While the principles of lean have been applied to PPM (e.g. [86, 42], there is little research looking at the application of Lean startup principles to PPM. Similarly, while there is interest in the application of Lean startup principles in open innovation contexts, to date, such applications have predominantly been driven by practice.

### Software Startup Ecosystems and Innovation Hubs

Successful software startups do not live in isolation. Normally, they are inserted in a rich environment that includes a number of relevant players, such as entrepreneurs, developers, investors, scientists, as well as business and intellectual property consultants. To support these players, a number of support programs from the private and public sectors are required to provide funding, incubation, acceleration, training, networking, and consulting. All these elements combine into what scholars and practitioners have called Startup Ecosystems [108]. In our software startups research agenda, we focus on Software Startup Ecosystems (SSE) and the elements that are relevant for startups that have software as a key part of their products or services.

By studying how SSEs are created, their main characteristics, and how they can evolve, one can better understand the environments that favour, or not, the birth and development of successful software startups. Research in this field can provide, to the relevant stakeholders, the concrete actions (e.g., public policies, private activities) that will establish a fruitful and vibrant environment for the execution of high-growth innovative projects within nascent software companies. The main research questions that need to be answered are the following:

* RQ1: What are the key elements of a fruitful SSE?
* RQ2: Are there different types of SSEs, e.g. differentiated by size, technology sectors, country economy or other factors?
* RQ3: How do SSEs evolve over time?
* RQ4: How can one measure the output and qualities of an SSE?

By answering RQ1, researchers will provide a better understanding of the way how SSEs and innovation hubs work, instrumenting key stakeholders in taking actions to improve their ecosystems. By identifying what factors promote or hinder the development of successful startups within a certain SSE, policy makers will get support in decision making (RQ2). Entrepreneurs will also be able to better understand what are the environmental factors and forces that can help or hinder the success of their enterprises.

Researchers from Brazil, Israel, and the USA have developed a methodology to map a specific software startup ecosystem; this methodology has been applied to Israel [108], Sao Paulo [61] and New York [41]. Currently, with the help of dozens of experts worldwide, they are developing a maturity model for SSEs [108, 40], addressing RQ3 and RQ4. This maturity model needs further research and validation before it can be applied in real scenarios to help practitioners and policy makers.

The Global Startup Ecosystem Ranking [77] is crafted by a group of experts that have been proposing metrics to evaluate regional ecosystems around the world and compare them according to multiple criteria. Frenkel and Maital [63] have developed a methodology to map national innovation ecosystems and use this map to propose policies to promote improvement. Jayshree has studied the influence of environmental factors on entrepreneurial success [90]. Finally, Sternberg [160] researched the role of regional government support programs and the regional environment as success factors for startups.

### Theory and Methodologies for Software Startup Research

The tracks in this cluster direct their research towards identifying means to better study and understand software startups.

#### 3.6.1 Overview of the possible theoretical lenses for studying software startups

Theories are important in any scientific field, as they form the foundation to understand a contemporary phenomenon better. Theories provide answers to the "why" questions, and are therefore useful for explaining why certain events occur while others do not. Software startup research does not operate in a vacuum, but rather can borrow theories from both the software engineering and information systems fields, business and management literature, as well as from the fields of organizational and social sciences.

We have identified a few potential theories that can be meaningfully applied in the context of software startup companies. The proposed theories are the hunter-gatherer model [159], Cynefin model [155], Effectuation theory [150] and Boundary Spanning theory [182]. These theories are briefly outlined in this section.

Although 90% of human history was occupied by hunters and gatherers, who forgd for wild plants and killed wild animal to survive, only recently was the hunter-gatherer model re-discovered by Steinert and Leifer [159] to explain how designers pursue their endeavours in search of the best design outcome. The model shows the changes in the design process, as well as subsequently in the design outcome. The model portrays a distinction between a hunter who aims to find an innovative idea, and a gatherer who aims to implement the idea. Both are needed to achieve concrete results. While hunting the idea through ambiguous spaces has a change-driven, analytical, and qualitative nature; gathering the idea across predetermined paths has a plan-oriented, manageable, and quantitative nature. The model has recently been applied in software startup research to explain startups' evolutionary paths [138].

Complexity theory has been used as a frame of reference, by analysing its implications on software design and development (e.g. Pelrine [143], Rikkila et al. [149]). Software projects can be characterized as endeavours wherein a dynamic network of customers, software designers, developers, 3rd party partners, and external stakeholders interact and can be seen as a Complex Adaptive System (CAS). To reason about decision-making in different situations, Snowden et al. [155] proposed a sense-making framework for such systems. The model has five sub-domains and divides the world in two parts - ordered and unordered main domains. The ordered domain is the one in which cause-effect (CE) relationships are known (the Known domain), or at least knowable after analysis (the Complicate domain). In contrast, the unordered domain includes a complexity situation, wherein the CE relationship can only be perceived in retrospect, but not in advance (the Complex domain), and a chaotic situation, wherein behaviours are completely random, lacking any expected consequence when acted upon. Depending on the problem domain, suitable approaches include categorizing, analysing, probing or acting [155]. The Cynefin model provides a framework that can be used to analyse the decisions made by software startuppers in developing their products. Often they find themselves in the unordered domain, attempting to make sense out of the current situation and navigate to the ordered domain.

Effectuation theory is a simple model, rooted in entrepreneurship, of decision-making under uncertainty. The effectual thinking is in the opposite of causal reasoning which starts from desired ends to necessary means (top-down). Experienced entrepreneurs reason from means to ends (bottom-up), trying to work out meanings and goals based on the resources they have at hand. The theory is embodied by five principles: the bird-in-hand principle, the affordable loss principle, the crazy quilt principle, the lemonade principle, and the pilot-in-the-plane principle [150]. The effectuation theory can help to make better sense of entrepreneurs' decision-making process in the evolution of software startups, such as problem validation, value proposition definition, design of MVPs, and pivoting processes. Good practices could be discovered using the effectuation theory as a theoretical lens.

Startups operate in a dynamic environment and face expectations and influences from many directions. In order to survive, they need to effectively collaborate within their team, but also outside it. Boundary spanning is a concept that deals with the structures of organizations that are transitioning from a rigid hierarchical structure towards a network-based expert organization, which gives rise to informal boundaries rather than structural ones [182]. Boundary spanners are those people and entities who bridge these boundaries and opportunities. In the software engineering context, boundary spanning has been studied in the context of global software development [92]. Startuppers can be seen as boundary spanners when they need to bridge between various stakeholders. While boundaries are always unavoidable, but also necessary and useful, knowledge is required on how they can be crossed, rearranged, or even dissolved when considered harmful [178]. Startuppers should see boundaries as tools that facilitate and support making sense out of the environment. Boundary spanning helps in discovering how to overcome the challenges of distributed global work, where motivations, work styles, and knowledge domains vary across boundaries. Startuppers can become knowledge brokers, transferring and sharing their knowledge.

There are other theoretical lenses that can be used to study software startups. Startups deal with innovative services and products, often for new or emerging markets. Birkinshaw et al. [8]analyse the innovation theories presented and propose a framework for management innovation process. This could be applied to the startup innovation process context to explore how product development moves from problem-driven search through trial and error to a finished prototype. The analysis can be complemented with Van de Ven and Poole's [177] four views into organizational changes, in which they present alternate processes for organizations to transform.

Theorizing software startups is important, since there is a current lack of understanding of the dynamics in startups. Theoretical advancements need to be achieved so that researchers can make better sense out the diverse contexts, situations, and places where startuppers strive for success.

#### 3.6.2 Defining the Lean Startup concept and evaluating practice

Many positive drivers underpin the Lean Startup movement. The literature is abound with claims of reduced risk [55, 148], the benefits of evidenced-based trials [11, 148], and shorter time-to-market [148]. We certainly know that these benefits are needed, given the challenges experienced by early stage software startups [70, 67] and the percentage that fail [148]. Indeed, many software start-ups fail [129, 39] because they waste too much time and money building the wrong product before realising too late what the right product should have been [139, 16]. These challenges coupled with high uncertainty make the Lean Startup Methodology attractive to software startups as it supposedly offers an integrated approach to creating products and services that fit the market [74]. This research builds on previous research conducted by Dennehy, Kasraian, O'Raghallaigh, and Conboy [43], which identified a significant absence of frameworks that assisted startups to efficiently and effectively progress their Minimum Viable Products (MVP) to a Product Market Fit (PMV). The theoretical advancement of the lean concept in contemporary software engineering and software development literature has been arrested, mainly because the academic research community has followed "fads and fancies" which characterize academic research. The implications for the arrested theoretical development of lean concept, listed next, are the motivation for this research.

As is often the case with new and emerging phenomena, Lean Startup practice has led research, with the creation, promotion, and dissemination of these methods almost completely due to the efforts of practitioners and consultants. Now, Lean Startup research is beginning to gain momentum, as is evident from the increasing number of dedicated journal special issues, conferences, conference tracks, and workshops. While there are merits to adopting such a practice-oriented focus, little if any research effort has focused on the conceptual development of Lean Startup and its underlying components. As practice has lead research, the definition of Lean Startup has emerged through how it is used in practice. As a result, Lean Startup adoption is often defined by how the practices are adhered to, rather than the value gleaned from their use, adaptation, or, in some cases, abandonment. We see this in many other methods such as in agile, where many define "being agile" as how many Scrum or XP practices are used, rather than the value obtained by their use [33]. As a result, the current body of software startup knowledge suffers from a number of limitations, including:

(1) Lack of clarity: While there is broad agreement in principle regarding what constitutes key concepts such as MVP, assumptions regarding the specific definitions, interpretations, use, and evaluations are often unclear in many existing Lean Startup studies. This makes critical appraisal, evidence-based evaluation, and comparison across studies extremely difficult.

(2) Lack of cohesion and cumulative tradition: A good concept or theory should cumulatively build on existing research. Very little academic research has examined Lean Startup using concepts that have more mature and substantive bodies of research with theories, frameworks and other lenses that have been thoroughly tested over time. The lean concept has been applied in manufacturing since WW1, and yet in Lean Startup research we see very myopic and limited use of the broad lean frameworks available. Other concepts that influence Lean Startup include agility, flow, and innovation.

(3) Limited applicability: Adherence-based measures of Lean Startup inhibit the ability to apply Lean Startup in domains other than that originally intended. Research now attempts to apply Lean Startup in other environments, such as large organizations and regulated environments, and so this will become a more prevalent issue as this trend continues. Therefore, questions relevant for this research track include:

* RQ1: What are the core concepts that underpin Lean Startup?
* RQ2: What are the components of a higher abstract Lean Startup that allows the concept to be applied and evaluated in a value-based manner?
* RQ3: What theories, frameworks, metrics, and other instruments from these existing related bodies of knowledge can be applied to Lean Startup?
* RQ4: How can these be effectively applied to improve the use of Lean Startup in practice, and the study and improvement of Lean Startup in research?
* RQ5: How can Lean Startup then be tailored to suit environments it was not originally designed to support, e.g. large organizations, regulated environments, or peer production?
* RQ6: Does Lean Startup enable or inhibit fundamental leaps in business and software business ideas? For example, does MVP place an invisible ceiling, wherein once you reach MVP you subconsciously stop looking for the truly significant innovation?

As there is reciprocal relationship between practice and academia, where academic research is informed by practice and practice is informed by academic research, this research would impact on research and on practice. By answering RQ4-RQ6, this research track would provide practice with empirical evidence on the utility of lean practices in diverse environments, while also positioning the lean method at the core of academic research (RQ1-RQ3). As case study research is an empirical inquiry that "investigates a contemporary phenomenon in depth and within its real-life context" [188], it would be highly suited to addressing the theoretical limitations of lean and for answering the questions listed above. Specifically, the use of a multiple-case design would allow a cross-case pattern to develop more sophisticated descriptions and powerful explanations [128] of the lean concept.

The challenges of new product development are not confined to software startups. Therefore, software engineering teams working in distributed or regulated environments such as financial services and within multinational companies would provide rich insights to the advancement of the lean concept.

#### 3.6.3 Research collaboration strategies with software startups

Empirical research in the area of software engineering normally requires access to organizations and artefacts from companies developing software intensive products and services [185]. In the case of startups, such access is very limited, due to several challenges:

1. startups have limited resources both in terms of person hours and calendar time for anything but working on their MVP,
2. startups want all investments to yield almost immediate results, thus investments in long-term potential are not prioritized, and
3. artefacts and actual products are often very sensitive, as the startup is very vulnerable.

These and other reasons limit empirical research, as reflected in both academic knowledge about startups overall, but also in the superficial nature of what is available. For this reason, any initiative to seriously collect empirical data as well as conduct research on core challenges facing startups hasto originate with a strategy that overcomes these obstacles. One possible strategy is to pool resources and access to startups, in essence sharing empirical data and coordinating research into startup software engineering. Coordination should be seen as equally central, as it enables researchers to limit the impact and costs as each study and project part can be focused and small, and several larger issues can be tackled through coordination. Concrete examples of joint activities include, but are not limited to:

1. joint surveys at the superficial level (pooling resources to collect many data points),
2. complementary surveys and case studies where each partner does a part only, but the results can be combined in analysis and synthesis,
3. formulating a complementary research agenda with clear interfaces and joint research questions, and
4. pooling resources in relation to testing "solutions" emerging from the collaboration. While this strategy opens the possibility to share the resource requirements among the studied startups, there are open questions regarding its implementation:

* RQ1: To what extent is data from different startups and startup ecosystems comparable? In other words, which techniques exist to perform meta-analysis of the gathered heterogeneous data?
* RQ2: How can we efficiently transfer technology between researchers and startups, and how can we measure the impact of transferred solutions?

We conjecture that the software startup context model discussed in Section 3.1.1 would be an enabler for answering RQ1. Confounding variables [173] could then be easier identified, allowing for sample stratification and robust statistical analyses [103]. In particular, data collected from different researchers could be aggregated and increase the strength of the conclusions drawn from the analysis, i.e. enabling meta-analysis [76].

Answering RQ2 would allow us to actually support software startups on a broad basis with the knowledge gained from the research proposed in this agenda. While different approaches exist to transfer knowledge from academia to industry [72, 181], they are mostly targeted at mature companies that have the resources to collaborate with researchers over a longer period of time. We think that software startup ecosystems, discussed in Section 3.5, can contribute to technology transfer if researchers are active in these structures and can create a win-win situation where both startups and researchers benefit.

## 4 Discussion

In this section we give a brief overview of the research tracks in relation to other work in software engineering and their potential impact on the field. We conclude this section with a discussion on the study's limitations.

Software startup engineering research centers around the core knowledge base in Software Engineering [17]. This is illustrated by the research tracks proposed in Section 3.1 that encompass providing support for startup engineering activities. Noticing what is considered "good" software engineering practice [17], and the challenges that software startups encounter [67, 106], we see potential in directing research towards efficient and effective requirements for engineering practices in startups. Klotins et al. [106] studied 88 experience reports from startups and identified lack of requirements validation, classification (to enable prioritization), and identification of requirements sources (to identify a relevant value proposition) as causes for engineering uncertainty, which maps to the early-stage startup challenges of technology uncertainty and delivering customer value, identified by Giardino et al. [67]. Unlike large companies, software startups have unique time and resource constraints and thus cannot afford to develop features and services that will not be used or valued by the customers. We believe that lightweight practices to identify, and, most importantly, analyse requirements for their business value can help software startups in their decision process. Looking at the research tracks in Section 3.1, several of them touch upon requirements engineering aspects. Prototypes can be used to communicate with customers to elicit requirements (Section 3.1.4), while product innovation assessment (Section 3.1.3) is relevant in the context of analysing the customers' perceived value of the offered solutions. Even optimizing the effort spent in requirements engineering and quality assurance, for example by using test cases as requirements [9], involving product users for testing (Section 3.1.7), addresses requirements engineering aspects.

The focus on requirements in software startup engineering research directly relates to the research tracks presented in Section 3.2, startup evolution models and patterns, as the cost of pivoting could be reduced by earlier and less ad-hoc analysis of requirements and value propositions of the envisioned products. The patterns emerging from the research on survival capabilities of software startups, proposed in Section 3.2.2, could provide valuable heuristics leading to a lightweight analysis of product value propositions. The research on pivoting and survival capabilities is likely to affect software startup practitioners on a strategic level by providing them managerial decision support that draws from models rooted in software engineering practice. An example where such a cross-discipline approach has been very successful is value-based software engineering [15].

The research tracks described in Section 3.3 were grouped under the name "cooperative and human aspects in software startups", borrowed from the research area in software engineering that is interested in studying the impact of cognitive abilities, team composition, workload, informal communication, expertise identification and other human aspects on software construction [157]. We conjecture that studying and understanding these aspects better has a large potential as software startups are driven by motivated individuals rather than a corporate agenda. Lessons from this research can both benefit startup practitioners, in particular in conjunction with the work on software startups ecosystems (Section 3.5), and more mature companies, for example by applying models of competency needs that could emerge from the work presented in Section 3.3.1.

The remaining research tracks described in Sections 3.4 - 3.5 take a step back from what happens _inside_ a software startup. The research tracks in Section 3.4 propose to apply startup concepts in non-startup contexts. The idea of extracting a concept from one context and applying it in another has proven successful in other areas, such as in systematic literature reviews [130, 104] and open source principles [169, 80, 179]. The premise of internal startups is that the positive traits of "startups in the wild" can be transferred to a corporate environment, fostering innovation and faster product development. The overall aim of the research tracks described in Section 3.4 is to evaluate whether the traits of startups can actually produce thriving environments within mature companies. In comparison, the research on startup ecosystems and innovation hubs (Section 3.5) takes a broader and higher level view of software startup phenomenon. Neither independent startups nor mature companies adopting internal startup initiatives live in isolation. A better understanding of startup ecosystems and innovation hubs might thereby provide key insights into the factors that create a fruitful software startup environment.

Finally, the research tracks in Section 3.6 look at aspects relevant for implementing the research agenda described in this paper. In particular, theories that can be used to better understand the dynamics in and around software startups are of value when attempting to construct a more holistic understanding of software startups in their various contexts. For the research on defining the Lean Startup concept, parallels to and lessons from similar endeavours around research on agile software development [48] should be taken into consideration. In this paper, we followed a recommendation by Dyba and Dingsoyr to develop a research agenda on the phenomenon of interest [48]. However,in order to implement this research agenda, we need to also answer the questions about how to enable efficient and effective research collaborations with software startups (Section 3.6.3).

### Limitations

The research agenda presented in this paper was developed "bottom-up", i.e. the areas of interest were proposed and described by a sample of software startup researchers without any restriction on covering certain aspects of the software engineering body of knowledge but guided by their past, current and future work in the field. Often, these researchers have both a leg in academia and in the startup community, either as mentors, founders, or simply as part of the development team. This approach to develop a research agenda is not uncommon (see e.g. [20, 23, 29]), but is threatened by a potential bias towards the preferences of individual researchers. This is why we invited a large number of our peers to contribute to the agenda. Even though the research tracks cover many software engineering aspects and beyond, the agenda is only a sample of the potentially relevant future research on software startups. This means that potentially interesting and relevant research topics, such as use of open source software, business model development, legal issues and intellectual property rights, are not discussed in this paper. However, we expect that the agenda will grow together with the research community as soon as the work on the proposed research tracks bears fruits, leading to new research questions.

## 5 Outlook and Conclusions

Software startups are an interesting and stimulating phenomenon in the modern economy and are of paramount importance for the societies of today. Despite of high failure rates, communities, cities and countries are investing on stimulating the creation of software startups. While these startups may not solve the unemployment problems of many countries they stimulate a new type of positive dynamism in societies encouraging people to collaborate and develop their personal skills in novel ways. The emergence of the software startup research area reflects the fact that we need to better understand this phenomenon to learn valuable lessons and accumulate valid knowledge to benefit future entrepreneurial initiatives. The research agenda described in this paper is one of the first attempts to establish the software startup as a nascent, yet fast growing research area, and to depict its landscape by highlighting the interesting research topics and questions to explore.

It is worth emphasizing again that software engineering is only one of the multiple disciplines that are relevant and can inform software startup practice. Other disciplines include Economics, Entrepreneurship, Design, Finance, Sociology, and Psychology. Therefore, there is a need to collaborate with researchers from these disciplines in order to increase the potential of achieving relevant and useful research results that can benefit practice.

Due to the emerging nature of the field, there is still much to be done to establish software startups as a research area. Relevant concepts need clear definitions, substantive theories need to be developed, and initial research findings need to be validated by future studies. Software startups are very diversified in terms of entrepreneurs' varying approaches to their startup endeavours. Without the sound foundation mentioned above for this research area, there are risks of asking irrelevant research questions and not being able to attain rigorous results.

Last but not least, this research agenda is not meant to be exhaustive, and we are aware that we may exclude some important Software Engineering topics relevant to software startups. The research agenda is open to additions of new tracks, topics, and research questions by other researchers interested in the research area. With contributions and commitments from researchersfrom different institutions and backgrounds, collectively we can establish software startup as a promising and significant research area that attracts more exciting discovery and contribution. We welcome those interested in joining the Software Startup Research Network in fostering the collaboration between researchers and taking the research agenda further.

## References

* software product quality requirements and evaluation (SQuaRE)
- guide to SQuaRE
- ISO/IEC 25000:2005. Technical report, International Organization for Standardization, 2005.
* Architecture description. _ISO/IEC/IEEE 42010:2011(E) (Revision of ISO/IEC 42010:2007 and IEEE Std 1471-2000)_, pages 1-46, 2011.
* [3] Frequently asked questions about small business. Technical report, U.S. Small Business Administration, 2014.
* [4] Y. Z. Anbardan and M. Raeyat. Open Innovation: Creating Value Through Co-Creation. In _Proceedings 7th World Conference on Mass Customization, Personalization, and Co-Creation (MCPC 2014)_, pages 437-447, Aalborg, Denmark, 2014. Springer.
* [5] R. Balachandra and J. Friar. Factors for success in R&D projects and new product innovation: a contextual framework. _IEEE Transactions on Engineering Management_, 44(3):276 -287, 1997.
* [6] C. K. Bart. New venture units: use them wisely to manage innovation. _Sloan Management Review_, 29(4):35-43, 1988.
* [7] M. Beaudouin-Lafon and W. E. Mackay. Prototyping development and tools. _Handbook of Human-Computer Interaction_, pages 1006-1031, 2002.
* [8] J. Birkinshaw, G. Hamel, and M. J. Mol. Management innovation. _Academy of management Review_, 33(4):825-845, 2008.
* [9] E. Bjarnason, M. Unterkalmsteiner, E. Engstrom, and M. Borg. A Multi-Case Study of Agile Requirements Engineering and Using Test Cases as Requirements. _Information and Software Technology_, 77:61-79, 2016.
* [10] S. Blank. _The Four Steps to the Epiphany: Successful Strategies for Products that Win_. Cafepress.com, 2005.
* [11] S. Blank. Why the Lean Start-Up Changes Everything. _Harvard Business Review_, 91(5), 2013.
* [12] S. Blank and B. Dorf. _The Startup Owner's Manual: The Step-By-Step Guide for Building a Great Company_. K & S Ranch, 2012.
* There's more to it than what management enacts. _International Journal of Project Management_, 26(4):357-365, 2008.
* [14] Z. Block and I. C. MacMillan. Milestones for successful venture planning. _Harvard Business Review_, 63(5):184-196, 1985.
* [15] B. Boehm. Value-based Software Engineering. _SIGSOFT Softw. Eng. Notes_, 28(2):1-12, 2003.
* [16] J. Bosch, H. H. Olsson, J. Bjork, and J. Ljungblad. The Early Stage Software Startup Development Model: A Framework for Operationalizing Lean Principles in Software Startups. In _Proceedings 4th International Conference on Lean Enterprise Software and Systems (LESS)_, pages 1-15, Galway, Ireland, 2013. Springer.
* [17] P. Bourque and R. E. Fairley, editors. _Guide to the Software Engineering Body of Knowledge_. IEEE, 3rd edition, 2014.
* [18] A. Brem and K.-I. Voigt. Integration of market pull and technology push in the corporate front end and innovation management--Insights from the German software industry. _Technovation_, 29(5):351-367, 2009.
* [19] T. Brown. _Change by Design: How Design Thinking Transforms Organizations and Inspires Innovation_. HarperBusiness, New York, 2009.
* [20] M. Broy. Challenges in Automotive Software Engineering. In _Proceedings 28th International Conference on Software Engineering (ICSE)_, pages 33-42, Shanghai, China, 2006. ACM.
* [21] C. G. Brush, T. S. Manolova, and L. F. Edelman. Properties of emerging organizations: An empirical test. _Journal of Business Venturing_, 23(5):547-566, 2008.

* [22] E. Carmel. Time-to-completion in software package startups. In _Proceedings 27th Hawaii International Conference on System Sciences (HICSS)_, pages 498-507. IEEE, 1994.
* [23] S. Chandra, V. S. Sinha, S. Sinha, and K. Ratakonda. Software Services: A Research Roadmap. In _Future of Software Engineering (FOSE)_, pages 40-54, Hyderabad, India, 2014. ACM.
* [24] C.-J. Chen. Technology commercialization, incubator and venture capital, and new venture performance. _Journal of Business Research_, 62(1):93-103, 2009.
* [25] H. Chesbrough and A. Crowther. Beyond high tech: early adopters of open innovation in other industries. _R&d Management_, 36(3):229-236, 2006.
* [26] H. W. Chesbrough. _Open innovation: The new imperative for creating and profiting from technology_. Harvard Business Press, 2006.
* [27] P. Clarke and R. V. O'Connor. The situational factors that affect the software development process: Towards a comprehensive reference framework. _Information and Software Technology_, 54(5):433-447, 2012.
* [28] B. Clarysse, J. Bruneel, and M. Wright. Explaining growth paths of young technology-based firms: structuring resource portfolios in different competitive environments. _Strategic Entrepreneurship Journal_, 5(2):137-157, 2011.
* [29] J. Cleland-Huang, O. C. Z. Gotel, J. Huffman Hayes, P. Mader, and A. Zisman. Software Traceability: Trends and Future Directions. In _Proceedings Future of Software Engineering_, pages 55-69, Hyderabad, India, 2014. ACM.
* [30] L. Cocco, K. Mannaro, G. Concas, and M. Marchesi. Simulating Kanban and Scrum vs. Waterfall with System Dynamics. In _Proceedings 12th Internation XP Conference (XP)_, pages 117-131, Madrid, Spain, 2011. Springer.
* [31] G. Coleman and R. V. O'Connor. An investigation into software development process formation in software start-ups. _Journal of Enterprise Information Management_, 21(6):633-648, 2008.
* [32] S. Coleman, C. Cotei, and J. Farhat. A Resource-based view of new firm survival: new perspectives on the role of industry and exit route. _Journal of Developmental Entrepreneurship_, 18(01):1-25, 2013.
* [33] K. Conboy. Agility from first principles: Reconstructing the concept of agility in information systems development. _Information Systems Research_, 20(3):329-354, 2009.
* [34] G. Concas, M. I. Lunesu, M. Marchesi, and H. Zhang. Simulation of software maintenance process, with and without a work-in-process limit. _Journal of Software: Evolution and Process_, 25(12):1225-1248, 2013.
* the invisible success factors in product innovation. _Journal of Product Innovation Management_, 16(2):115-133, 1999.
* [36] R. G. Cooper. Perspective: The innovation dilemma: How to innovate when the market is mature. _Journal of Product Innovation Management_, 28(SUPPL. 1):2-27, 2011.
* [37] A. Croll and B. Yoskovitz. _Lean Analytics: Use Data to Build a Better Startup Faster_. O'Reilly Media, Sebastopol, USA, 1st edition, 2013.
* [38] M. M. Crossan and M. Apaydin. A multi-dimensional framework of organizational innovation: A systematic review of the literature. _Journal of Management Studies_, 47(6):1154-1191, 2009.
* [39] M. Crowne. Why software product startups fail and what to do about it. In _International Engineering Management Conference (IEMC)_, pages 338-343, Cambridge, UK, 2002. IEEE.
* [40] D. Cukier, F. Kon, and N. Krueger. Designing a Maturity Model for Software Startup Ecosystems. In _Proceedings 1st International Workshop on Software Startups_, pages 600-606, Bolzano, Italy, 2015. Springer.
* [41] D. Cukier, F. Kon, and L. S. Thomas. Software Startup Ecosystems Evolution: The New York City Case Study. In _Proceedings 2nd International Workshop on Software Startups_, Trondheim, Norway, 2016. IEEE.
* [42] M. A. Cusumano and K. Nobeoka. _Thinking Beyond Lean: How Multi-project Management is Transforming Product Development at Toyota and Other Companies_. Simon and Schuster, 1998.
* [43] D. Dennehy, L. Kasraian, O. O'Raghallaign, and K. Conboy. Product Market Fit Frameworks for Lean Product Development. In _Proceedings R&D Management Conference 2016 "From Science to Society: Innovation and Value Creation"_, Cambridge, UK, 2016.
* [44] G. G. Dess, R. D. Ireland, S. A. Zahra, S. W. Floyd, J. J. Janney, and P. J. Lane. Emerging Issues in Corporate Entrepreneurship. _Journal of Management_, 29(3):351-378, 2003.

* [45] T. Dingsoyr and Y. Lindsjorn. Team Performance in Agile Development Teams: Findings from 18 Focus Groups. In _Proceedings 14th International Conference on Agile Software Development_, pages 46-60, Vienna, Austria, 2013.
* [46] K. Dovan. Reliability in content analysis: Some common misconceptions and recommendations. _Human Communication Research_, 30(3):411-433, 1998.
* [47] T. Dyba, D. I. Sjoberg, and D. S. Cruzes. What Works for Whom, Where, When, and Why?: On the Role of Context in Empirical Software Engineering. In _Proceedings International Symposium on Empirical Software Engineering and Measurement (ESEM)_, pages 19-28, Lund, Sweden, 2012. ACM.
* [48] T. Dyba and T. Dingsoyr. Empirical studies of agile software development: A systematic review. _Information and Software Technology_, 50(9-10):833-859, 2008.
* [49] H. Edison. A Conceptual Framework of Lean Startup Enabled Internal Corporate Venture. In _Proceedings 1st International Workshop on Software Startups_, pages 607-613, Bolzano-Bozen, Italy, 2015. Springer.
* [50] H. Edison, N. bin Ali, and R. Torkar. Towards innovation measurement in the software industry. _Journal of Systems and Software_, 86(5):1390-1407, 2013.
* [51] H. Edison, D. Khanna, S. S. Bajwa, V. Brancaleoni, and L. Bellettati. Towards a Software Tool Portal to Support Startup Process. In _Proceedings 1st International Workshop on Software Startups_, pages 577-583, Bolzano, Italy, 2015. Springer.
* [52] H. Edison, X. Wang, and P. Abrahamsson. Lean startup. In _Scientific Workshop Proceedings of the XP conference_, pages 1-7, Helsinki, Finland, 2015. ACM.
* Social Media for SAP Store: A Case Study. In _Proceedings European Design Science Symposium (EDSS)_, pages 99-110, Dublin, Ireland, 2013. Springer.
* [54] K. M. Eisenhardt and J. A. Martin. Dynamic capabilities: what are they? _Strategic Management Journal_, 21(10-11):1105-1121, 2000.
* [55] T. R. Eisenmann, E. Ries, and S. Dillard. Hypothesis-Driven Entrepreneurship: The Lean Startup. _Harvard Business School_, 2012.
* [56] S. Elo and H. Kyngas. The qualitative content analysis process. _Journal of Advanced Nursing_, 62(1):107-115, 2008.
* [57] M. D. Ensley, K. M. Hmieleski, and C. L. Pearce. The importance of vertical and shared leadership within new venture top management teams: Implications for the performance of startups. _The Leadership Quarterly_, 17(3):217-231, 2006.
* [58] W. Eversheim. _Innovation Management for Technical Products: Systematic and Integrated Product Development and Production Planning_. Springer Science & Business Media, 2008.
* 939, 2012.
* [60] C. Fernandez-Sanchez, J. Garbajosa, and A. Yague. A framework to aid in decision making for technical debt management. In _Proceedings 7th International Workshop on Managing Technical Debt (MTD)_, pages 69-76, Bremen, Germany, 2015. IEEE.
* [61] M. C. Fonseca. O ecosystema de startups de software da cidade de Sao Paulo. Master's thesis, University of Sao Paulo, 2016.
* [62] D. Francis and W. Sandberg. Friendship within entrepreneurial teams and its association with team and venture performance. _Entrepreneurship: Theory and Practice_, 25(2):5-21, 2000.
* [63] A. Frenkel and S. Maital. _Mapping National Innovation Ecosystems: Foundations for Policy Consensus_. Edward Elgar Publishing, London, UK, 2014.
* [64] J. Fuller, R. Schroll, and E. von Hippel. User generated brands and their contribution to the diffusion of user innovations. _Research Policy_, 42(6-7):1197-1209, 2013.
* [65] J. S. Gans and S. Stern. The product market and the market for "ideas": commercialization strategies for technology entrepreneurs. _Research Policy_, 32(2):333-350, 2003.
* [66] D. A. Garvin and L. C. Levesque. Meeting the challenge of corporate entrepreneurship. _Harvard business review_, 84(10):102-12, 150, 2006.
* [67] C. Giardino, S. S. Bajwa, X. Wang, and P. Abrahamsson. Key Challenges in Early-Stage Software Startups. In _Proceedings 16th International XP Conference (XP)_, pages 52-63, Helsinki, Finland, 2015.

Springer.
* [68] C. Giardino, N. Paternoster, M. Unterkalmsteiner, T. Gorschek, and P. Abrahamsson. Software Development in Startup Companies: The Greenfield Startup Model. _Transactions on Software Engineering_, 42(6):585-604, 2016.
* [69] C. Giardino, M. Unterkalmsteiner, N. Paternoster, T. Gorschek, and P. Abrahamsson. What do we know about software development in startups? _IEEE Software_, 31(5):28-32, 2014.
* [70] C. Giardino, X. Wang, and P. Abrahamsson. Why Early-Stage Software Startups Fail: A Behavioral Framework. In _Proceedings 5th International Conference on Software Business (ICSOB)_, pages 27-41, Paphos, Cyprus, 2014. Springer.
* [71] F. Giones and F. Miralles. Strategic Signaling in Dynamic Technology Markets: Lessons From Three IT Startups in Spain. _Global Business and Organizational Excellence_, 34(6):42-50, 2015.
* [72] T. Gorschek, C. Wohlin, P. Carre, and S. Larsson. A Model for Technology Transfer in Practice. _IEEE Software_, 23(6):88-95, 2006.
* [73] C. Grevet and E. Gilbert. Piggyback prototyping: Using existing, large-scale social computing systems to prototype new ones. In _Proceedings 33rd Annual ACM Conference on Human Factors in Computing Systems_, pages 4047-4056, Seoul, Korea, 2015. ACM.
* [74] Y. Harb, C. Noteboom, and S. Sarnikar. Evaluating Project Characteristics for Selecting the Best-fit Agile Software Development Methodology: A Teaching Case. _Journal of the Midwest Association for Information Systems (JMWAIS)_, 1(1), 2015.
* [75] T. Hatzakis, M. Lycett, and A. Serrano. A programme management approach for ensuring curriculum coherence in IS (higher) education. _European Journal of Information Systems_, 16(5):643-657, 2007.
* [76] W. Hayes. Research synthesis in software engineering: a case for meta-analysis. In _Proceedings 6th International Software Metrics Symposium_, pages 143-151, Boca Raton, USA, 1999. IEEE.
* [77] B. L. Herrmann, J.-F. Gauthier, D. Holtschke, R. Berman, and M. Marmer. The Global Startup Ecosystem Ranking 2015. Technical Report August, 2015.
* [78] S. A. Hill and J. Birkinshaw. Ambdexterity and Survival in Corporate Venture Units. _Journal of Management_, 40(7):1899-1931, 2014.
* [79] O.-P. Hilmola, P. Helo, and L. Ojala. The value of product development lead time in software startup. _System Dynamics Review_, 19(1):75-82, 2003.
* [80] E. v. Hippel. Innovation by User Communities: Learning from Open-Source Software. _MIT Sloan Management Review_, 42(4):82-82, 2001.
* [81] L. Hokkanen, K. Kuusinen, and K. Vaananen. Early Product Design in Startups: Towards a UX Strategy. In _Proceedings 16th International Conference on Product-Focused Software Process Improvement (PROFES)_, pages 217-224, Bolzano-Bozen, Italy, 2015. Springer.
* [82] L. Hokkanen, K. Kuusinen, and K. Vaananen. Minimum viable user experience: A framework for supporting product design in startups. In _Proceedings 17th International XP Conference (XP)_, Edinburgh, Scotland, 2016. Springer. In press.
* [83] L. Hokkanen and M. Leppanen. Three Patterns for User Involvement in Startups. In _Proceedings 20th European Conference on Pattern Languages of Programs (EuroPLoP)_, pages 51:1-51:8, Kloster Irsee, Germany, 2015. ACM.
* [84] L. Hokkanen and K. Vaananen-Vainio-Mattila. UX work in startups: current practices and future needs. In _Proceedings 16th International XP Conference (XP)_, pages 81-92, Helsinki, Finland, 2015. Springer.
* [85] B. Honig and T. Karlsson. Institutional forces and the written business plan. _Journal of Management_, 30(1):29-48, 2004.
* [86] G. Hu, L. Wang, S. Fetch, and B. Bidanda. A multi-objective model for project portfolio selection to implement lean and Six Sigma concepts. _International Journal of Production Research_, 46(23):6611-6625, 2008.
* [87] International Organization for Standardization. _Ergonomics of Human-system Interaction: Part 210: Human-centred Design for Interactive Systems_. ISO, 2010.
* [88] S. Jack, J. Hyman, and F. Osborne. Small entrepreneurial ventures culture, change and the impact on HRM: A critical review. _Human Resource Management Review_, 16(4):456-466, 2006.
* [89] J. J. P. Jansen, M. P. Tempelaar, F. A. J. van den Bosch, and H. W. Volberda. Structural Differentiation and Ambidexterity: The Mediating Role of Integration Mechanisms. _Organization Science_,20(4):797-811, 2009.
* [90] S. Jayshree and R. Ramraj. Entrepreneurial Ecosystem: Case Study on the Influence of Environmental Factors on Entrepreneurial Success. _European Journal of Business and Management_, 4(16):95-102, 2012.
* [91] F. Johne and P. A. Snelson. Success factors in product innovation: A selective review of the literature. _Journal of Product Innovation Management_, 5(2):114-128, 1988.
* [92] A. Johri. Boundary spanning knowledge broker: An emerging role in global engineering firms. In _Proceedings 38th Annual Frontiers in Education Conference_, pages 7-12. IEEE, 2008.
* [93] J. Jarvinen, T. Huomo, T. Mikkonen, and P. Tyrvainen. From Agile Software Development to Mercury Business. In _Proceedings 5th International Conference on Software Business (ICSOB)_, pages 58-71, Paphos, Cyprus, 2014. Springer.
* [94] J. Kamm, J. Shuman, J. Seeger, and A. Nurick. Entrepreneurial teams in new venture creation: A research agenda. _Entrepreneurship Theory and Practice_, 14(4):7-17, 1990.
* [95] T. Karlsson and B. Honig. Judging a business by its cover: An institutional perspective on new ventures and the business plan. _Journal of Business Venturing_, 24(1):27-45, 2009.
* [96] J. Katz and W. B. Gartner. Properties of Emerging Organizations. _Academy of Management Review_, 13(3):429-441, 1988.
* [97] J. R. Katzenbach and D. K. Smith. The discipline of teams. _Harvard Business Review_, 71(2):111-120, 1993.
* [98] M. D. Kelly. Lessons Learned from Software Testing at Startups. In _EuroStar-Software Testing Conference_, Amsterdam, The Netherlands, 2012.
* [99] B. Kersten and C. Verhoef. IT portfolio management: A banker's perspective on IT. _Cutter IT Journal_, 2003.
* [100] D. Kirk and S. MacDonell. Categorising Software Contexts. In _Proceedings 2014 Americas Conference on Information Systems (AMCIS)_, Savannah, USA, 2014. AIS Electronic Library.
* [101] D. Kirk and S. G. MacDonell. Investigating a Conceptual Construct for Software Context. In _Proceedings 18th International Conference on Evaluation and Assessment in Software Engineering (EASE)_, pages 27:1-27:10, London, UK, 2014. ACM.
* [102] D. Kirsh, B. Goldfarb, and A. Gera. Firm or substance: the role of business plans in venture capital decision making process. _Strategic Management Journal_, (30):487-515, 2009.
* [103] B. Kitchenham, L. Madeyski, D. Budgen, J. Keung, P. Brereton, S. Charters, S. Gibbs, and A. Pohthong. Robust Statistical Methods for Empirical Software Engineering. _Empirical Software Engineering_, pages 1-52, 2016.
* [104] B. A. Kitchenham, T. Dyba, and M. Jorgensen. Evidence-Based Software Engineering. In _Proceedings 26th International Conference on Software Engineering (ICSE)_, pages 273-281, Edinburgh, UK, 2004. IEEE.
* [105] E. Klotins, M. Unterkalmsteiner, and T. Gorschek. Software engineering practices in start-up companies: A mapping study. In _6th International Conference on Software Business_, pages 245-257. Springer, 2015.
* [106] E. Klotins, M. Unterkalmsteiner, and T. Gorschek. Software Engineering in Start-up Companies: an Exploratory Study of 88 Startups. _Empirical Software Engineering_, 2016. In Submission.
* [107] K. Klyver and M. T. Schenkel. From Resource Access to Use: Exploring the Impact of Resource Combinations on Nascent Entrepreneurship. _Journal of Small Business Management_, 51(4):539-556, 2013.
* [108] F. Kon, D. Cukier, C. Melo, O. Hazzan, and H. Yuklea. A conceptual framework for software startup ecosystems: the case of israel. Technical report, Technical Report RT-MAC-2015-01, Department of Computer Science, University of Sao Paulo, 2015.
* [109] J. Krebs. _Agile portfolio management_. Microsoft Press, 1st edition, 2008.
* [110] M. Konig, G. Baltes, and B. Katzy. On the role of value-network strength as an indicator of technology-based venture's survival and growth: Increasing innovation system efficiency by leveraging transaction relations to prioritize venture support. In _Proceedings International Conference on Engineering, Technology and Innovation/ International Technology Management Conference (ICE/ITMC)_, pages 1-9. IEEE, 2015.
* [111] M. Konig, C. Ungerer, R. Buchele, and G. Baltes. Agreement on the Venture's Reality Presentedin Business Plans. In _Proceedings 22nd International Conference on Engineering, Technology and Innovation (ICE)_, Trondheim, Norway, 2016. IEEE.
* Lavie et al. [2010] D. Lavie, U. Stettner, and M. L. Tushman. Exploration and Exploitation Within and Across Organizations. _The Academy of Management Annals_, 4(1):109-155, 2010.
* LeFave et al. [2008] R. LeFave, B. Branch, and C. Brown. How Sprint Nextel Reconfigured IT Resources for Results. _MIS Quarterly_, 2008.
* Lerner [2013] J. Lerner. Corporate venturing. _Harvard Business Review_, 91(10):86-94, 2013.
* Levie and Lichtenstein [2010] J. Levie and B. B. Lichtenstein. A Terminal Assessment of Stages Theory: Introducing a Dynamic States Approach to Entrepreneurship. _Entrepreneurship Theory and Practice_, 34(2):317-350, 2010.
* Li et al. [2015] Z. Li, P. Avgeriou, and P. Liang. A systematic mapping study on technical debt and its management. _Journal of Systems and Software_, 101:193-220, 2015.
* Lichtenstein et al. [2006] B. B. Lichtenstein, K. J. Dooley, and G. T. Lumpkin. Measuring emergence in the dynamics of new venture creation. _Journal of Business Venturing_, 21(2):153-175, 2006.
* Lichter et al. [1993] H. Lichter, M. Schneider-Hufschmidt, and H. Zullighoven. Prototyping in Industrial Software Projects--Bridging the Gap Between Theory and Practice. In _Proceedings 15th International Conference on Software Engineering (ICSE)_, pages 221-229, Baltimore, USA, 1993. IEEE.
* Lim et al. [2012] E. Lim, N. Taksande, and C. Seaman. A balancing act: What software practitioners have to say about technical debt. _IEEE Software_, 29(6):22-27, 2012.
* Lippoldt and Stryszowskim [2009] D. Lippoldt and P. Stryszowskim. Innovation in the software sector. Technical report, Organisation for Economic Co-operation and Development, 2009.
* Lofsten and Lindelof [2002] H. Lofsten and P. Lindelof. Science Parks and the growth of new technology-based firms--academic-industry links, innovation and markets. _Research Policy_, 31(6):859-876, 2002.
* Macmillan et al. [1987] I. C. Macmillan, L. Zemann, and P. Subbanarasimha. Criteria distinguishing successful from unsuccessful ventures in the venture screening process. _Journal of Business Venturing_, 2(2):123-137, 1987.
* Marijarvi et al. [2016] J. Marijarvi, L. Hokkanen, M. Komssi, H. Kiljander, Y. Xu, M. Raatikainen, P. Seppanen, J. Heininen, M. Koivulahi-Ojala, M. Helenius, and J. Jarvinen. _The Cookbook for Successful Internal Startups_. DIGILE and N4S, 2016.
* Marlow [2006] S. Marlow. Human resource management in smaller firms: A contradiction in terms? _Human Resource Management Review_, 16(4):467-477, 2006.
* Maurya [2012] A. Maurya. _Running Lean: Iterate from Plan A to a Plan That Works_. O'Reilly Media, Inc., 2012.
* Lean & Lean UX by a UX Veteran: Lessons Learned in Creating & Launching a Complex Consumer App. In _Proceedings Agile Conference (AGILE)_, pages 141-147, Dallas, USA, 2012. IEEE.
* A conceptual framework. _International Journal of Project Management_, 28(8):807-817, 2010.
* Miles and Huberman [1994] M. B. Miles and A. Huberman. _Qualitative data analysis: An expanded sourcebook_. Sage Publications, Inc, Thousand Oaks, US, 1994.
* Mullins and Komisar [2009] J. W. Mullins and R. Komisar. _Getting to Plan B: Breaking Through to a Better Business Model_. Harvard Business Press, 2009.
* Mulrow [1994] C. D. Mulrow. Rationale for systematic reviews. _BMJ : British Medical Journal_, 309(6954):597-599, 1994.
* Nambisan et al. [2016] S. Nambisan, K. Lyytinen, A. Majchrzak, and M. Song. Digital Innovation Management: Reinventing Innovation Management Research in a Digital World. _MIS Quarterly_, 2016. In press.
* Nanda and Rhodes-Kropf [2013] R. Nanda and M. Rhodes-Kropf. Investment cycles and startup innovation. _Journal of Financial Economics_, 110(2):403-418, 2013.
* Nazar [2013] J. Nazar. 14 famous business pivots. _[AVAILABLE ONLINE] [http://www.forbes.com/sites/jasonnazar/2013/10/08/14-famous-business-pivots/_](http://www.forbes.com/sites/jasonnazar/2013/10/08/14-famous-business-pivots/_), 2013.
* Newbert et al. [2008] S. L. Newbert, S. Gopalakrishnan, and B. A. Kirchhoff. Looking beyond resources: Exploring the importance of entrepreneurship to firm-level competitive advantage in technologically intensive industries. _Technovation_, 28(1-2):6-19, 2008.
* Newbert and Tornikoski [2010] S. L. Newbert and E. T. Tornikoski. Supporter networks and network growth: a contingency model of organizational emergence. _Small Business Economics_, 39(1):141-159, 2010.
* Newman et al. [2016] P. Newman, M. A. Ferrario, W. Simm, S. Forshaw, A. Friday, and J. Whittle. The role of design thinking and physical prototyping in social software engineering. _37th IEEE International Conferenceon Software Engineering_, 2015.
* [137] A. Nguyen Duc and P. Abrahamsson. Minimum viable product or multiple facet product? The Role of MVP in software startups. In _Proceedings 17th International XP Conference_, Edinburgh, UK, 2016. Springer.
* [138] A. Nguyen Duc, P. Seppanen, and P. K. Abrahamsson. Hunter-gatherer cycle: a conceptual model of the evolution of software startups. pages 199-203, Tallin, Estonia, 2015. ACM.
* [139] C. Nobel. Teaching a 'Lean Startup' Strategy. _HBS Working Knowledge_, 2011.
* [140] O. Oechslein and A. Tumasjan. Examining Trust within the Team in IT Startup Companies-An Empirical Study in the People's Republic of China. In _Proceedings 45th Hawaii International Conference on System Science (HICSS)_, pages 5102-5111, Maui, USA, 2012.
* [141] C. A. O'Reilly and M. L. Tushman. Organizational Ambidexterity: Past, Present, and Future. _Academy of Management Perspectives_, 27(4):324-338, 2013.
* [142] N. Paternoster, C. Giardino, M. Unterkalmsteiner, T. Gorschek, and P. Abrahamsson. Software Development in Startup Companies: A Systematic Mapping Study. _Information and Software Technology_, 56(10):1200-1218, 2014.
* [143] J. Pelrine. On Understanding Software Agility: A Social Complexity Point Of View. _Emergence: Complexity & Organization_, 13(1/2):26-37, 2011.
* [144] K. Petersen and C. Wohlin. Context in Industrial Software Engineering Research. In _Proceedings 3rd International Symposium on Empirical Software Engineering and Measurement (ESEM)_, pages 401-404, Orlando, USA, 2009. IEEE.
* [145] M. Pikkarainen, W. Codenie, N. Boucart, and J. A. Heredia Alvaro, editors. _The Art of Software Innovation_. Springer, Berlin, Germany, 2011.
* [146] T. Raz and E. Michael. Use and benefits of tools for project risk management. _International Journal of Project Management_, 19(1):9-17, 2001.
* [147] B. D. Reyck, Y. Grushka-Cockayne, M. Lockett, S. R. Calderini, M. Moura, and A. Sloper. The impact of project portfolio management on information technology projects. _International Journal of Project Management_, 23(7):524-537, 2005.
* [148] E. Ries. _The lean startup: How today's entrepreneurs use continuous innovation to create radically successful businesses_. Crown Books, 2011.
* [149] J. Rikkila, P. Abrahamsson, and X. Wang. The Implications of a Complexity Perspective for Software Engineering Practice and Research. _Journal of Computer Engineering & Information Technology_, 2012.
* [150] S. D. Sarasvathy. Causation and Effectuation: Toward a Theoretical Shift from Economic Inevitability to Entrepreneurial Contingency. _Academy of Management_, 26(2):243-263, 2001.
* [151] T. Semrau and S. Sigmund. Networking Ability and the Financial Performance of New Ventures: A Mediation Analysis among Younger and More Mature Firms. _Strategic Entrepreneurly Journal_, 6(4):335-354, 2012.
* [152] S. Shahid Bajwa, X. Wang, A. Nguyen Duc, and P. Abrahamsson. How Do Software Startups Pivot? Empirical Results from a Multiple Case Study. In _7th International Conference on Software Business (ICSOB 2016)_, pages 169-176, Ljubljana, Slovenia, 2016.
* [153] A. Shontell. The 11 most disruptive startups. _Business Insider_, 07/12 2012.
* [154] F. Shull, D. Falessi, C. Seaman, M. Diep, and L. Layman. Technical Debt: Showing the Way for Better Transfer of Empirical Results. In _Perspectives on the Future of Software Engineering_, pages 179-190. Springer, 2013.
* [155] D. J. Snowden and M. E. Boone. A leader's framework for decision making. _Harvard Business Review_, 85(11):69-76, 2007.
* [156] I. Sommerville. _Software Engineering_. Pearson, Boston, 9th edition, 2010.
* [157] C. R. B. d. Souza, H. Sharp, J. Singer, L. T. Cheng, and G. Venolia. Guest Editors' Introduction: Cooperative and Human Aspects of Software Engineering. _IEEE Software_, 26(6):17-19, 2009.
* [158] S. Srinivasan, I. Barchas, M. Gorenberg, and E. Simoudis. Venture Capital: Fueling the Innovation Economy. _Computer_, 47(8):40-47, 2014.
* Gatherer Model based on Wayfaring. _International Journal of Engineering Education_, 28(2):251-252, 2012.
* [160] R. Sternberg. Success factors of university-spin-offs: Regional government support programs versus regional environment. _Technovation_, pages 1-12, 2013.
* [161] S. M. Sutton. The Role of Process in a Software Start-up. _IEEE Softw._, 17(4):33-39, 2000.
* [162] M. Taipale. Huitable-A Story of a Finnish Lean Startup. In _Proceedings 1st International Conference on Lean Enterprise and Software Systems (LESS)_, pages 111-114, Helsinki, Finland, 2010. Springer.
* [163] D. J. Teece, G. Pisano, and A. Shuen. Dynamic capabilities and strategic management. _Strategic Management Journal_, 18(7):509-533, 1997.
* [164] H. Terho, S. Suonsyrj, A. Karisalo, and T. O. Mikkonen. Ways to cross the rubicon: Pivoting in software startups. In _Proceedings 1st International Workshop on Software Startups_, pages 555-568, Bolzano-Bozen, Italy, 2015. Springer.
* [165] The Economist. A cambrian moment cheap and ubiquitous building blocks for digital products and services have caused an explosion in startups. special report: Tech startups. _The Economist_, 01/18 2014.
* [166] The Economist. Testing, testing launching a startup has become fairly easy, but what follows is back-breaking work. special report: Tech startups. _The Economist_, 01/18 2014.
* [167] The Economist. Progress without profits. a flock of startups is making cloud computing faster and more flexible, but most of them will not survive. _The Economist_, 09/19 2015.
* [168] E. Tom, A. Aurum, and R. Vidgen. An exploration of technical debt. _Journal of Systems and Software_, 86(6):1498-1516, 2013.
* [169] R. Torkar, P. Minoves, and J. Garrigos. Adopting free/libre/open source software practices, techniques and methods for industrial use. _Journal of the Association for Information Systems_, 12(1):88, 2011.
* [170] J. R. Turner. _The handbook of project-based management_. McGraw-hill, 2014.
* [171] P. Tyrvainen, M. Saarikallio, T. Aho, T. Lehtonen, and R. Paukeri. Metrics Framework for Cycle-Time Reduction in Software Value Creation. In _Proceedings 10th International Conference on Software Engineering Advances (ICSEA)_, Barcelona, Spain, 2015. IARIA.
* [172] C. Ungerer, M. Konig, F. Giones, and G. Baltes. Measuring Venture Emergence and Survival by Analyzing Transaction Relations in Business Plans. In _Proceedings 22nd International Conference on Engineering, Technology and Innovation (ICE)_, Trondheim, Norway, 2016. IEEE.
* [173] M. Unterkalmsteiner, T. Gorschek, A. Islam, C. Cheng, R. Permadi, and R. Feldt. A conceptual framework for SPI evaluation. _Journal of Software: Evolution and Process_, 26(2):251-279, 2014.
* [174] V. van de Vrande, J. P. de Jong, W. Vanhaverbeke, and M. de Rochemont. Open innovation in SMEs: Trends, motives and management challenges. _Technovation_, 29(6):423-437, 2009.
* [175] J. S. van der Ven and J. Bosch. Pivots and Architectural Decisions: Two Sides of the Same Medal? In _Proceedings 8th International Conference on Software Engineering Advances (ICSEA)_, pages 310-317, Venice, Italy, 2013.
* [176] W. Vanhaverbeke and M. Cloodt. Open innovation in value networks. _Open innovation: Researching a New Paradigm_, 2006.
* [177] A. H. V. D. Ven and M. S. Poole. Explaining Development and Change in Organizations. _Academy of Management Review_, 20(3):510-540, 1995.
* [178] E. Wenger. _Communities of Practice: Learning, Meaning, and Identity_. Cambridge University Press, 1998.
* [179] J. West. How open is open enough?: Melding proprietary and open source platform strategies. _Research Policy_, 32(7):1259-1285, 2003.
* [180] J. West and S. Gallagher. Challenges of open innovation: the paradox of firm investment in open-source software. _R & D Management_, 36(3):319-331, 2006.
* [181] R. Wieringa. Empirical research methods for technology validation: Scaling up to practice. _Journal of Systems and Software_, 95:19-31, 2014.
* [182] P. Williams. The Competent Boundary Spanner. _Public Administration_, 80(1):103-124, 2002.
* [183] P. Witt. Entrepreneurs' networks and the success of start-ups. _Entrepreneurship & Regional Development_, 16(5):391-412, 2004.
* [184] WMF. Intelligent assets unlocking the circular economy potential. Technical report, World Economic Forum, December 2015.
* [185] J. Wohlin, Claes; Aurum, Aybuke; Angelis, Lefteris; Phillips, Laura; Dittrich, Yvonne; Gorschek, Tony; Grahn, Hakan; Henningsson, Kennet; Kagstrom, Simon; Low, Graham; Rovegard, Per; Tomaszewski, Piotr; van Toorn, Christine; Winter. The Success Factors Powering Academia Collaboration. _IEEESoftware_, 29(2):67-73, 2012.
* [186] A. Yague, J. Garbajosa, J. Perez, and J. Diaz. Analyzing Software Product Innovation Assessment by Using a Systematic Literature Review. In _Proceedings 47th Hawaii International Conference on System Sciences (HICSS)_, pages 5049-5058, Waikoloa, USA, 2014. IEEE.
* [187] A. Yau and C. Murphy. Is a Rigorous Agile Methodology the Best Development Strategy for Small Scale Tech Startups? Technical Report MS-CIS-13-01, 2013.
* [188] R. K. Yin. _Case Study Research: Design and Methods_. Sage Publications, 3rd edition, 2003.
* [189] J. Zettel, F. Maurer, J. Munch, and L. Wong. LIPE: a lightweight process for e-business startup companies based on extreme programming. In _Proceedings 3rd International Conference on Product-Focused Software Process Improvement (PROFES)_, pages 255-270. Springer, Kaiserslautern, Germany, 2001.

Title: How Do Software Startups Pivot? Empirical Results from a Multiple Case
  Study
Transcription: # How do Software Startups Pivot? Empirical Results from a Multiple Case Study

Sohaib Shahid Bajwa

1 Free University of Bozen-Bolzano, Piazza Domenicani 3, 39100, Bolzano, Italy,

[http://www.unibz.it1](http://www.unibz.it1)

Xiaofeng Wang

1 Free University of Bozen-Bolzano, Piazza Domenicani 3, 39100, Bolzano, Italy,

[http://www.unibz.it1](http://www.unibz.it1)

Anh Nguyen Duc

2Norwegian University of Science and Technology, NO-7491 Trondheim, Norway 23 Software Startups Research Network [http://softwarestartups.org3](http://softwarestartups.org3)

Pekka Abrahamsson

2Norwegian University of Science and Technology, NO-7491 Trondheim, Norway 23 Software Startups Research Network [http://softwarestartups.org3](http://softwarestartups.org3)

###### Abstract

In order to handle intense time pressure and survive in dynamic market, software startups have to make crucial decisions constantly on whether to change directions or stay on chosen courses, or in the terms of Lean Startup, to pivot or to persevere. The existing research and knowledge on software startup pivots are very limited. In this study, we focused on understanding the pivoting processes of software startups, and identified the triggering factors and pivot types. To achieve this, we employed a multiple case study approach, and analyzed the data obtained from four software startups. The initial findings show that different software startups make different types of pivots related to business and technology during their product development life cycle. The pivots are triggered by various factors including negative customer feedback.

Keywords:Software Startup, Lean Startup, Pivot, Validated Learning

## 1 Introduction

Many people know Twitter as arguably the most famous microblogging platform. Much less are aware that it was a podcast service provider back in its startup phase in 2005 [8]. Similarly, Instagram back in its early days was a social check-in application called Burbn, combining features of a photo share app (Foursquare) and a game (Mafiawars) [7]. As the examples show, very few software startups get their products or business right immediately, and most do not end up with what they had initially started.

This is because software startups intend to produce cutting edge products and grow fast under the condition of extreme technology and business uncertainty. In order to obtain a sustainable business model, software startups change their direction relentlessly, or make a _pivot_ in Lean Startup approach [1]. Ries [1] defines _pivot_ as a strategic change, designed to test a fundamental hypothesis about a product, business model or engine of growth. Pivot is often considered the outcome of validated learning, another key concept of the Lean Startup to test a business hypothesis and measure the result. Software startups often neglect the validated learning process and avoid pivot when needed, which is one of the reasons behind many startup failures[2]. Pivot is considered vital for software startups to survive, grow, and eventually obtain a suitable business model.

Due to the nascent nature of software startup research, previous empirical studies specially focusing on pivot are scarce. To the best of our knowledge, no study has been conducted exploring different types of pivots and identifying different triggering factors. This study attempts to fill this knowledge gap, examining pivots in software startups during different product development stages, from concept to mature product. The main objective of our study is to provide a better understanding of pivots happening in software startups. To this end, the main research question asked in the study is: _How do software startups pivot during different product development stages_?

The rest of this paper is organized as follows. In Section 2, background and related work is presented. Section 3 describes the empirical research approach. The findings are presented in detail in Section 4 and further discussed in Section 5. The paper is summarized in Section 6 outlining the future research.

## 2 Background and Related Work

Pivot is a core concept of Lean Startup [1], a startup methodology that focuses on the Build-Measure-Learn (BML) loop with three steps: turn idea into product, measure its effect, and learn from the result. This learning is referred to as validated learning [1]. Each hypothesis regarding the business model is tested, and a decision is made accordingly on whether to pivot or persevere. Pivot is not about introducing just any change, even though the two terms are often used as synonyms. Pivot is a special kind of change designed to test and validate the assumptions a startup has about its product, business model, and the engine of growth [1]. Ries presents ten different types of pivots that can happen in a startup [1], listed in Table 1.

Tuple 11:
Cleaned Title: towards understanding startup product development effectual entrepreneurial behavior
Cleaned Transcription: application entrepreneurial theory study software development startup anh nguyen duc norwegian university science technology trondheim norwaysoftware startup research network httpsoftwarestartupsorghttpsoftwarestartupsorg yngve dahle norwegian university science technology trondheim norway martin steinert norwegian university science technology trondheim norway pekka abrahamsson norwegian university science technology trondheim norwaysoftware startup research network httpsoftwarestartupsorghttpsoftwarestartupsorg abstract software startup face multiple technical business challenge could make startup journey longer even become failure little known entrepreneurial decision making direct force startup development outcome study attempted apply behavior theory entrepreneurial firm understand rootcause software startup challenge six common challenge related prototyping product development twenty software startup identified found behavior theory useful theoretical lens explain technical challenge software startup search local optimal solution emphasize shortrun feedback rather longrun strategy result vague prototype planning paradox demonstration evolving throwaway prototype finding implies effectual entrepreneurial process might require suitable product development approach current stateofpractice keywords effectuation entrepreneurial behavior theory software development software startup prototyping empirical study introduction software industry witnessed growing trend software product developed startup company limited resource little operating history advancement technology development seems everyone business idea website pitch launch new company however many business idea realized concrete prototype furthermore even smaller portion prototype transformed commercialized product difficult repeat success startup operate chaotic situation link startup behavior effect often detectable decision made entrepreneur direct force leading success failure startup startup unique characteristic ie dynamic bootstrapping multipleinfluenced environment make decisionmaking task entrepreneur different project manager established company entrepreneur often make decision little information market customer product whether accepted entrepreneurial literature offersseveral way understand startup decision behaviour one approach behaviour theory entrepreneurial firm assumes effectuation approach developing startup business recent ideologist encourage codevelopment business product startup combination two line thought inspires u explore effectual behavior startup product development aspect interested understanding theory entrepreneurial behavior could help explain challenge faced product development research question theory entrepreneurial behavior applicable explain startup product development process paper organized follows firstly present related work behavior theory entrepreneur firm section describe research methodology section finding presented section finally discus conclude paper section behavioral theory entrepreneurial firm entrepreneurship literature intensive understanding formation development influencing factor startup increased attention effectuation theory explaining entrepreneurial behaviour effectuation process take set mean given focus selecting possible outcome realized alternatively entrepreneurial firm seen heterogeneous bounded rational entity face environmental uncertainty therefore bounded rational firm form expectation based available mean information dew et al proposed behavioral theory entrepreneurial firm btef assuming entrepreneur effectual unit dew et al propose four construct related entrepreneurial decisionmaking meansdriven transformation startup company tend effectual available resource drive action effectual action involves transforming extant mean new possibility including new problem interest transformation process actorcentric come board determines goal vice versa transformation appeared search activity aiming solving pressing problem rather developing longrun strategy docility conflict difference among stakeholder avoided stakeholder docility goal residual process simon et al defined docility tendency depend suggestion recommendation persuasion information obtained social channel major basic choice decision made startup instance done cooperating others idea necessary going conflict resolution author version work selfarlived arxiv definite version published nguyen duc dahle steinert abrahamsson p towards understanding startup product development effectual entrepreneurial behavior ojala holmstrom olsson h werder k ed software business icsob lecture note business information processing vol springer cham httpsdoiorghttpsdoiorg leveraging contingency avoiding uncertainty short run feedback also encouraging surprise startup even bad surprise leveraged provide new mean new opportunity action emphasize commitment contingency choice determinacy technology foolishness insulation learning sought allowing experimental action regard affordable lost technology foolishness allows startup relax primacy functional rationality temporarily suspend intentionality promote openness new action objective understanding research approach conducted study using multiplecase study design software startup unit analysis contact startup searched via four channel startup within professional network paper author startup town author startup listed startup norway website crunchbase database twenty startup eventually selected investigation startup case represent different startup phase prototyping commercialization scaling application domain range marketplace education commerce transportation internetofthing regard software development approach startup five people mostly adopt agile iterative software development sample dominated norwegian software startup small team bootstrap financing model consider type startup example internal cooperate startup venture capital invested startup usabased startup major data collection instrument semistructured interview interviewee focused exploring startup decision making behavior related business product development interview guideline published online used thematic analysis analyze data common technique identifying analyzing reporting conceptual theme found qualitative data support data analysis used tool namely nvivo code categorize code higher order level representing different technical challenge going idea commercialized product several theoretical framework considered cynefin model boundary spanning object theory btef focus exploring decision making process behind startup behavior attempted apply four principle btef explain startup face technical challenge footnote wwwgooglrokcu footnote wwwqsrinternationalcomproductthis author version work selfarributed arxiv definite version published nguyen duc dahle steinert abrahamsson p towards understanding startup product development effectual entrepreneurial behavior ojala holmstrom olsson h werder k ed software business icsob lecture note business information processing vol springer cham httpsdoiorghttpsdoiorg theory entrepreneurial behavior applicable explain startup product development process six identified theme directly related startup decision making found btef useful explain theme shown table challenge name description given along theoretical explanation table
Original Title: Towards understanding startup product development as effectual
  entrepreneurial behaviors
Original Transcription: # The application of an entrepreneurial theory to study software development in startups

Anh Nguyen Duc

1Norwegian University of Science and Technology, NO-7491 Trondheim, Norway12Software Startups Research Network [http://softwarestartups.org](http://softwarestartups.org)

Yngve Dahle

1Norwegian University of Science and Technology, NO-7491 Trondheim, Norway1

Martin Steinert

1Norwegian University of Science and Technology, NO-7491 Trondheim, Norway1

 Pekka Abrahamsson

1Norwegian University of Science and Technology, NO-7491 Trondheim, Norway12Software Startups Research Network [http://softwarestartups.org](http://softwarestartups.org)

###### Abstract

Software startups face with multiple technical and business challenges, which could make the startup journey longer, or even become a failure. Little is known about entrepreneurial decision making as a direct force to startup development outcome. In this study, we attempted to apply a behavior theory of entrepreneurial firm to understand the root-cause of some software startup's challenges. Six common challenges related to prototyping and product development in twenty software startups were identified. We found the behavior theory as a useful theoretical lens to explain the technical challenges. Software startups search for local optimal solutions, emphasize on short-run feedback rather than long-run strategies, which results in vague prototype planning, paradox of demonstration and evolving throw-away prototypes. The finding implies that effectual entrepreneurial processes might require a more suitable product development approach than the current state-of-practice.

**Keywords:** effectuation, entrepreneurial behavior theory, software development, software startups, prototyping, empirical study

## 1 Introduction

The software industry has witnessed a growing trend, where software products are developed by startup companies with limited resources and little operating history. With the advancement of technology development, it seems that everyone with a business idea, a website and a pitch can launch a new company. However, not so many business ideas are realized as concrete prototypes. Furthermore, even a smaller portion of prototypes is transformed into commercialized products. It is difficult to repeat successes, as startups operate in chaotic situations, where the links between startups' behaviors and their effects are often not detectable [1].

Decisions made by entrepreneurs is the direct force leading to the success or failure of the startup [3]. Startup's unique characteristics, i.e. dynamic, bootstrapping and multiple-influenced environments, make the decision-making tasks for entrepreneurs are different for project managers in more established companies [1]. Entrepreneurs often have to make decisions with little information about market, customer and product, and whether they will be accepted [2]. Entrepreneurial literature offersseveral ways to understand the startup's decisions and behaviours [3; 4; 8]. One approach is the behaviour theory of entrepreneurial firms, which assumes the effectuation approach when developing startups' business [4]. Recent ideologists [5; 6; 7] encourage the co-development of business and product in startups. The combination of the two line of thoughts inspires us to explore the effectual behavior of startups from product development aspect. We are interested in understanding how the theory of entrepreneurial behaviors could help to explain the challenges faced during the product development. Our research question is "_How are theories of entrepreneurial behaviors applicable to explain for startup product development process?_"

The paper is organized as follows; firstly, we present related work about a behavior theory of entrepreneur firm (Section 2). Then, we describe our research methodology (Section 3). After that, findings are presented (Section 4). Finally, we will discuss and conclude the paper (Section 5 and 6).

## 2 Behavioral Theory of the Entrepreneurial Firm

Entrepreneurship literature is intensive on understanding the formation, development and influencing factors to startups. There has been an increased attention on the effectuation theory in explaining entrepreneurial behaviours [8]. Effectuation processes take a set of means as given and focus on selecting between possible outcomes that can be realized [8]. Alternatively, entrepreneurial firms are seen as heterogeneous, bounded rational entities [4]. In the face of environmental uncertainty, therefore, these bounded rational firms form expectations based on available means and information. Dew et al. proposed a behavioral theory of the entrepreneurial firm (BTEF) [4]. Assuming entrepreneurs as an effectual unit, Dew et al. [4] propose four constructs related to entrepreneurial decision-making:

* Means-driven transformation: startup companies tend to be effectual, and available resources drive their action. Effectual action involves transforming extant means into new possibilities, including new problems of interest. Transformation processes are actor-centric, as who comes on board determines goals, not vice versa. The transformation is appeared as a search activity, aiming at solving pressing problems rather than developing long-run strategies.
* Docility: conflict and difference among stakeholders is avoided through stakeholder docility, goals are residual of the process. Simon et al. defined docility as "_the tendency to depend on suggestions, recommendation, persuasion and information obtained through social channels, as a major basic of choice_" [9]. The decisions made by startups, for instance, can be done by in cooperating other's ideas and not necessary by going through conflict resolution.

_This is the author's version of the work. It is self-arlived at Arxiv. The definite version was published in: Nguyen Duc A., Dahle Y., Steinert M., Abrahamsson P. (2017) Towards Understanding Startup Product Development as Effectual Entrepreneurial Behaviors. In: Ojala A., Holmstrom Olsson H., Werder K. (eds) Software Business. ICSOB 2017. Lecture Notes in Business Information Processing, vol 304. Springer, Cham, [https://doi.org/10.1007/978-3-319-69191-6.15_](https://doi.org/10.1007/978-3-319-69191-6.15_)

* Leveraging contingency: avoiding uncertainty by short run feedbacks, but also encouraging surprise. For startups, even '_bad_' surprises can be leveraged to provide new means and new opportunities. Actions emphasize commitment and contingency, not choice and determinacy.
* Technology of foolishness: insulation from learning sought through allowing experimental actions with regard to affordable lost. The technology of foolishness allows startups to relax the primacy of functional rationality, to temporarily suspend intentionality, and promote the openness to new actions, objectives and understandings.

## 3 Research Approach

We conducted this study by using a multiple-case study design with software startup as a unit of analysis [10]. Contacts for startups were searched via four channels, (1) startups within professional networks of papers' authors, (2) startups in the same town with the authors, (3) startups listed in the Startup Norway website and (4) the Crunchbase database. Twenty startups were eventually selected for investigation. The startup cases represent different startup phases, from prototyping to commercialization and scaling. Application domains range from marketplace, education, commerce, transportation, and Internet-of-Thing. Regards to software development approaches, startups with five or more people mostly adopt Agile and iterative software development. The sample is dominated by Norwegian software startups, with small teams and bootstrap financing models. We do not consider other types of startups, for example, internal cooperate startups, venture capital invested startups, and USA-based startups.

The major data collection instrument is semi-structured interviews. The interviewees were focused on exploring startup's decision making and their behaviors related to their business and product development. The interview guideline is published online1. We used a thematic analysis to analyze the data, a common technique for identifying, analyzing, and reporting conceptual themes found from qualitative data [17]. To support the data analysis, we used a tool namely NVivo 112, to code, and to categorize such codes in higher order levels, representing different technical challenges when going from ideas to commercialized product. Several theoretical frameworks were considered, such as Cynefin model [11], boundary spanning object theory [12] and BTEF [4]. With the focus on exploring the decision making process behind startup's behaviors, we attempted to apply the four principle of BTEF to explain for how do startups face with such technical challenges.

Footnote 1: www.goo.gl/r9okCu

Footnote 2: www.qsrinternational.com/product_This is the author's version of the work. It is self-arributed at Arxiv. The definite version was published in: Nguyen Duc A., Dahle Y., Steinert M., Abrahamsson P. (2017) Towards Understanding Startup Product Development as Effectual Entrepreneurial Behaviors. In: Ojala A., Holmstrom Olsson H., Werder K. (eds) Software Business. ICSOB 2017. Lecture Notes in Business Information Processing, vol 304. Springer, Cham, [https://doi.org/10.1007/978-3-319-69191-6](https://doi.org/10.1007/978-3-319-69191-6) 15_

How are theories of entrepreneurial behaviors applicable to explain for startup product development process?

Six identified themes were directly related to startup's decision making. We found that BTEF can be useful to explain for such themes, as shown in Table 1. The challenge name and description were given along with the theoretical explanation in the table.

Tuple 12:
Cleaned Title: preliminary study agility business production case earlystage hardware startup
Cleaned Transcription: author version work selfarrived arxiv definite version published anh nguyenduc xiaofang weng pekka abrahamsson preliminary study agility business production case earlystage hardware startup accepted present upcoming esem conference oulu finland introduction startup landscape includes pure software product web platform mobile apps desktop application also product composed software hardware unit industry revolution increasing amount hardwarerelated product domain internetofthings iot cyberphysical system advanced robot entry threshold starting business around hardwarerelated product never lower due popularity hardware ecosystem software engineering becoming relevant hardware startup two way firstly many hardware startup build value proposition based comprehensive system software hardware component socalled hardwarerelated product instance wearable device business value come physical device also service collecting storing analyzing personal data extracted device context development operation maintenance hardwarerelated product involve software engineering process practice secondly advancement hardware prototyping manufacturing earlystage hardware engineering becomes agile similar agile software movement initiated almost decade ago instead heavy design upfront using tool printing allows shorter cycle prototyping rigorous analysis productmarket fit consequently approach popular software development agile lean startup design thinking considered hardware development general production whole hardwarerelated product startup face many challenge survive early stage many found related engineering activity every startup us certain approach develop product extent direct impact business objective activity instance product might need developed fast way satisfy timetomarket demand speed product development need agile enough support entrepreneur responding sudden opportunity threat arriving agility startup considered special context traditional software engineering approach might directly applicable hardware startup even remarkable due special characteristic combination hardware software development although research community increasingly interested product business development paradigm software startup context empirical research hardware startup limited aim investigating characteristic earlystage hardwarerelated product development aligned business development intend address ability startup respond change external environment conductedthis author version work selfarrived arxiv definite version published anh nguyenduc et al xiaofang weng pekka abrahamsson preliminary study agility business production case earlystage hardware startup accepted present upcoming esem conference oulu finland multiple case study provide insight agility hardwarerelated product development focus earlystage development activity laterstage startup might easier relate existing hardware development approach research question rq agile mean hardware startup rq hardware startup achieve agility early stage product development study organized follows section present background hardware startup agility startup hardware development section describes research methodology section present preliminary finding section contains discussion future work related work emergence agile method response inability heavyweight waterfalllike development methodology equip product development responsiveness change according agile manifesto agile development value individual interaction process tool working software comprehensive documentation customer collaboration contract negotiation responding change following plan abrahamsson et al reviewed literature software development clarified agile development focusing simplicity speed teamwork customer especially working code general sense agility defined capability react adapt expected unexpected change within dynamic environment constantly quickly use change possible advantage agile adoption software startup common nguyenduc et al reported four five startup studied adopted agile development process pantiuchina et al surveyed software startup found speed related agile practice used greater extent comparison quality practice giardino et al observe quickly validate product market software startup tend use agile method adhoc manner finding reported context software startup without explicit investigation hardware development despite popularity agile software development study value practice agile hardware development yet established kaisti et al suggested agile practice could used embedded domain practice need adapted fit constrained field embedded product development ronkainen et al framed development embedded system hardwarerelated software development greene reported positive experience applying agile approach firmware development intel gustavsson reported positive experience first time adopting agile approach hardware development eriksson study infer potential benefit adopting agile hardware development investigated context established company cooperates work explores startup context present distinct environment large company smes due lack necessary resource temporal evolving organization multiple influence research approach data collection analysis given unexplored nature agile hardware development startup context conducted multiple exploratory case study selected startup currently work team business developer product developer operate least six month least running prototype develop either wearable device iot application embedded system total selected hardware startup case selection data collection done two phase phase aimed collecting pilot case study hardware startup case focus early stage activity prototyping agile practice business development phase case selected conveniently professional network startup come various country ie norway finland pakistan phase aimed collecting hardware startup case focus practice rapid agile development prototyping technical debt quality assurance selected startup mainly norway empirical data collected semistructured interview key people startup ceo cto chief software hardware engineer interview guideline slightly different two phase due different study scope however guideline cover topic business development approach engineering approach prototyping agile adoption current challenge wish ensure sufficient data address rqs interview recorded transcribed phase participant signed consent form participation interview conducted total length interview varied minute due limited understanding topic adopted inductive approach order generate new knowledge applied thematic synthesis process common qualitative research software engineering started reading interview transcript identified relevant segment text labeled code code merged theme later grouped higherorder theme hierarchy theme presented thematic map answering rqs rq asked apply agile development company ie srum kanban etc followup question reveals entrepreneur understand agile value rq asked general capacity startup fast market adaptive react change qualitative map mainly data collected phase research author version work selfarrived arxiv definite version published anh nguyenduc xiaofang weng pekka abrahamsson preliminary study agility business production case earlystage hardware startup accepted present upcoming esem conference oulu finland case description whole sample includes hardware startup norway finland pakistan netherland italy startup developed developing hardwarerelated product falling four category personal tracking device patient monitoring muscle operation measure machine interaction device smart board smart home solution wheel chair controller utility camera camera accessory interactive toy noise cancelling industrial iot application aerospace utility aquaculture tracking system ship tracking shown figure median year operation two year sample number employee range three median seven three startup currently scaling phase rest early stage preliminary result rq agile mean hardware startup preliminary analysis reveals interviewee perception agile development varied lot concept agile reflected principle practice scope shown figure regarding principle entrepreneur relate agile development le upfront planning shortterm driven evolution startup also mentioned speed prototyping development fast timetomarket asked agile entrepreneur state full control development activity partnership prepare respond unexpected change startup also highlighted importance internal collaboration defined process regarding practice entrepreneur mention practice different agile framework scrum xp kanban formal way adopting agile practice rather customized adoption certain practice mentioned different interviewee frequent delivery sprint planning kanban product owner practice mentioned tailored version instance weekly meeting instead daily standup meeting regarding scope entrepreneur relate agile engineering activity achieving rapid prototyping agile product development also business level startup development pivot table describes extent agile adopted hardware startup found none investigated startup applies agile framework properly half case adopt agile practice mentioned table seven startup considered agile decided adopt two startup know agile methodology rq hardware startup achieve agility early stage product development
Original Title: A preliminary study of agility in business and production - Cases of
  early-stage hardware startups
Original Transcription: This is the author's version of the work. It is self-arrived at Arxiv. The definite version was published in: Anh Nguyen-Duc, Xiaofang Weng, Pekka Abrahamsson, A preliminary study of agility in business and production - Cases of early-stage hardware startups, accepted to present in the upcoming ESEM conference 2018, Oulu, Finland

## 1. Introduction

The startup landscape includes not only pure software products, such as web platforms, mobile apps and desktop applications, but also products that are composed of both software and hardware units. With the Industry 4.0 revolution [1], there is an increasing amount of hardware-related products in the domain of Internet-of-things (IoT), cyber-physical systems and advanced robots. The entry threshold for starting a business around hardware-related products has never been lower due to the popularity of hardware ecosystems.

Software engineering is becoming relevant to hardware startups in two ways. Firstly, many hardware startups build their value propositions based on comprehensive systems of both software and hardware components, so-called hardware-related products. For instance, in a wearable device, the business value comes from not only the physical devices, but also the services of collecting, storing and analyzing personal data extracted from the devices. In such a context, development, operation and maintenance of hardware-related products involve software engineering processes and practices. Secondly, with the advancement in hardware prototyping and manufacturing, early-stage hardware engineering becomes more agile, similar to the agile software movement initiated almost a decade ago. Instead of a heavy design upfront, using tools and 3D printing allows shorter cycles of prototyping and more rigorous analysis of the product-market fit. Consequently, the approaches that are popular in software development, such as Agile, Lean Startup and Design Thinking, can be considered in hardware development and in general the production of the whole hardware-related products.

Startups face with many challenges to survive in early stages, in which many are found to be related to engineering activities [3]. Every startup uses a certain approach to develop their product, and that, to some extent, has a direct impact on business objective and activities. For instance, products might need to be developed in a fast way to satisfy time-to-market demands (speed). Product development needs to be agile enough to support entrepreneurs in responding to sudden opportunities and threats when arriving (agility). While startups are considered a special context where traditional software engineering approaches might not be directly applicable, hardware startups are even more remarkable due to the special characteristics of the combination of hardware and software development. Although the research community is increasingly interested in product and business development paradigms in software startup contexts [4], empirical research on hardware startups is very limited.

We aim at investigating the characteristics of early-stage hardware-related product development and how they are aligned with business development. We intend to address the ability of startups to respond to changes from external environments. We conductedThis is the author's version of the work. It is self-arrived at Arxiv. The definite version was published in: Anh Nguyen-Duc et al. Xiaofang Weng, Pekka Abrahamsson, A preliminary study of agility in business and production - Cases of early-stage hardware startups, accepted to present in the upcoming ESEM conference 2018, Oulu, Finland

a multiple case study to provide insights on agility in hardware-related product development. The focus is on early-stage development activities, because later-stage startups might be easier to relate to existing hardware development approaches. Our research questions are:

RQ1: What do agile mean to hardware startups?

RQ2: How do hardware startups achieve agility in early stage product development?

The study is organized as follows: Section 2 presents a background about hardware startups, agility in startups and hardware development. Section 3 describes our research methodology, Section 4 presents our preliminary findings, and Section 5 contains discussions and future work.

## 2. Related Work

The emergence of agile methods was a response to the inability of heavyweight, waterfall-like development methodologies to equip product development the responsiveness to change [5]. According to the Agile Manifesto, agile development values individuals and interactions over processes and tools, working software over comprehensive documentation, customer collaboration over contract negotiation, and responding to change over following a plan [6]. Abrahamsson et al. reviewed the literature in software development and clarified that agile development focusing on simplicity and speed, teamwork, customers and especially, working code [7]. In a general sense, agility can be defined as "_the capability to react and adapt to expected and unexpected changes within a dynamic environment constantly and quickly; and to use those changes (if possible) as an advantage_" [8].

Agile adoption in software startups is common. Nguyen-Duc et al. [9] reported that four out of five startups they studied have adopted agile development processes. Pantiuchina et al. surveyed 1526 software startups and found that speed related agile practices are used to a greater extent in comparison to quality practices [10]. Giardino et al. [4] observe that, to quickly validate the product in the market, software startups tend to use agile methods, but in an ad-hoc manner. These findings are reported in the context of software startups without any explicit investigation of hardware development.

Despite of the popularity of agile software development, the study of value and practices of agile in hardware development is not yet established [11]. Kaisti et al. suggested that Agile practices could be used in the embedded domain, but the practices need to be adapted to fit to the more constrained field of embedded product development [12]. Ronkainen et al. framed the development of embedded systems as 'hardware-related' software development [13]. Greene reported a positive experience of applying Agile approaches in firmware development in Intel [14]. Gustavsson reported a positive experience in first time adopting Agile approaches in hardware development in Eriksson [15]. While these studies infer potential benefits of adopting Agile in hardware development, the investigated context is established companies or cooperates. Our work explores startup contexts, which presents a distinct environment from large companies or SMEs, due to their lack of necessary resources, temporal and evolving organizations and multiple influences [17].

## 3. Research Approach

### Data collection and analysis

Given the unexplored nature of agile hardware development in startup context, we conducted a multiple exploratory case study [16]. We selected startups that (1) currently work in teams of both business developers and product developers, (2) operate at least six months and have at least a running prototype, (3) develop either wearable devices, IoT applications or embedded systems. In total, we selected 20 hardware startups.

Case selection and data collection were done in two phases. Phase 1 aimed at collecting pilot case studies and hardware startup cases with the focus on early stage activities, such as prototyping, agile practices and business development. In this phase, the cases were selected conveniently from our professional networks. Startups come from various countries, i.e. Norway, Finland, and Pakistan. Phase 2 aimed at collecting hardware startup cases with the focus on their practices of rapid and agile development, prototyping, technical debt and quality assurance. The selected startups were mainly from Norway.

The empirical data was collected from semi-structured interviews with key people of the startups, such as CEO, CTO and chief software/ hardware engineers. The interview guidelines are slightly different between two phases due to the different study scopes. However, both of the guidelines cover topics such as (1) business development approaches (2) engineering approaches, (3) prototyping, (4) agile adoption and (4) current challenges and wishes. These ensure sufficient data to address our RQs. All interviews were recorded and transcribed. In Phase 2, all participants signed consent forms before participation. There were 24 interviews conducted in total. The length of the interviews varied from 30 to 75 minutes.

Due to the limited understanding about the topic, we adopted an inductive approach in order to generate new knowledge. We applied a thematic synthesis process which is common for qualitative research in Software Engineering [2]. We started with reading through interview transcripts, identified relevant segment of texts and labeled them with codes. Codes were merged into themes, which later grouped into higher-order themes. The hierarchies of themes are presented by the thematic maps answering the RQs. For RQ1, we asked "Do you apply agile development in your company, i.e. Srum, Kanban, etc?" and follow-up questions that reveals how entrepreneurs understand about Agile and its value. For RQ2, we asked in general the capacity of startups to be fast in the market, adaptive and react to changes. The qualitative maps are mainly from the data collected in Phase 1 of the research.

This is the author's version of the work. It is self-arrived at Arxiv. The definite version was published in: Anh Nguyen-Duc, Xiaofang Weng, Pekka Abrahamsson, A preliminary study of agility in business and production - Cases of early-stage hardware startups, accepted to present in the upcoming ESEM conference 2018, Oulu, Finland

### Case description

The whole sample includes 20 hardware startups from Norway (60%), Finland (15%), Pakistan (15%), Netherland (5%) and Italy (5%). All of the startups developed or are developing hardware-related products, falling into four categories:

* Personal tracking devices: patient monitoring, muscle operation measure.
* Machine interaction devices: smart board, smart home solutions, wheel chair controller.
* Utilities: camera, and camera's accessories, interactive toys, noise cancelling.
* Industrial IoT application: aerospace utilities, aquaculture tracking systems, ship tracking.

As shown in Figure 2, the median years of operation is two years in our sample. The number of employees ranges from three to 85, with the median of seven. There are three startups (15%) currently in the scaling phase and the rest in early stages (85%).

## 4 Preliminary results

### Rq1: What do agile mean to hardware startups?

Our preliminary analysis reveals that interviewees' perceptions on agile development varied a lot. The concept of being agile is reflected in (1) principles, (2) practices and (3) scope, as shown in Figure 2.

Regarding the principles, entrepreneurs relate agile development with less upfront planning, short-term driven evolution of the startups. They also mentioned about the speed of prototyping, development and fast time-to-market when asked about agile. Entrepreneurs state that full controls of development activities and partnership will prepare themselves to respond to unexpected changes. Some startups also highlighted the importance of internal collaboration over defined processes.

Regarding the practices, entrepreneurs mention practices from different Agile frameworks, such as Scrum, XP and Kanban. There is no formal way of adopting Agile practices, but rather customized adoptions. Certain practices are mentioned by different interviewee, such as frequent delivery, sprint planning, Kanban and product owners. Some practices are mentioned by its tailored version, for instance, weekly meetings instead of daily standup meetings.

Regarding the scope, entrepreneurs relate agile to not only engineering activities, such as achieving rapid prototyping and agile product development, but also business level, with startup development and pivots.

Table 1 describes the extent that agile is adopted in hardware startups. We found that none of the investigated startups applies any Agile frameworks properly. More than half of the cases adopt some Agile practices, as mentioned in Table 1. Seven startups had considered about Agile and decided not to adopt it. There are two startups that do not know about Agile methodologies.

### RQ2: How do hardware startups achieve agility in early stage product development?

Tuple 13:
Cleaned Title: exploring outsourcing relationship software startup multiple case study
Cleaned Transcription: author version work selfarrived arxiv definite version published nguyenduc p abrahamsson exploring outsourcing relationship software startup multiple case study proceeding st international conference evaluation assessment software engineering karlskrona sweden acm httpsdoiorghttpsdoiorg introduction software industry witnessed growing trend software product developed small entrepreneurial team aiming scalable business model typical early stage startup often financially bootstrapping starting form initial selffunding sweat equity credit saving etc rarely necessary financial human resource complete task required journey ideation commercialization situation force reach external resource performing engineering task design prototyping manufacturing relationship could take form outsourcing partnership later acquisition joint venture outsource controversial topic among startup enthusiast one hand practitioner argue outsourcing core competence ie technical development technologybased startup risky illustrated penny wise pound foolish moreover hidden cost outsourcing project known geographical temporal cultural gap among project location hand witness successful story adopting outsourcing strategy unicorn early stage slack billion usd valued startup started product development outsourced team early version skype video messaging platform acquired microsoft billion usd initially built outsourced team estonia generally stated outsourcing considered strategy innovation radical change organization argued case demonstrate viability adopting outsourcing external sourcing strategy software startup outsourcing predetermined unavoidable awareness common pitfall challenge would save entrepreneur serious managerial mistake understanding rise evolution relationship outsourcing arrangement vital help operationalization agreement also issue dependency global software development gsd rich experience report best practice outsourcing project biased established company software development process place review empirical evidence show ten primary study addressing gsd collaboration among small company none purposefully target contextual factor unique startup unique characteristic startup context experimental nature process business product development startup searching scalable business model often face rapid change business idea requirement product level product development startup considered set opportunistic activity focus providing value constrained condition startup software startup context employed development team need able cope many uncertainty unknown author version work selfarrived arov definite version published nguyenduc p abrahamsson exploring outsourcing relationship software startup multiple case study proceeding st international conference evaluation assessment software engineering karlskrona sweden acm httpsdoiorghttpsdoiorg work focus understanding entrepreneur experience outsourcing team competence strategy study performed largescale multiple case study research state practice software startup study insight gathered six company adopted outsourcing strategy various startup stage specific research question rq type task outsourced software startup rq outsourcing relationship evolve progression software startup rest paper structured follows section ii present related literature section iii describes research approach section iv present finding section v discus result section vi concludes paper ii related work distinction startup smes consensus definition startup lean startup customer development approach steve blank et al refer startup organization formed search repeatable scalable business model startup typically carry business model repeatable applicable large market volume u small business administration describes startup business typically technology oriented high growth potential term technology applied software hardware part scope work focused software startup develop product significant software part fundamentally difference startup sme term business organization product dimension shown table u small business administration describes sme independently owned operated organized profit dominant field startup designed grow fast smes focus stable business year another difference lie product market certainty smes generally sell known product known customer known local market startup customer product often unknown beginning lot change customer product would expected startup journey rather formal organization startup likely taskoriented group entrepreneur central organization whole carry task software startup life cycle exist several framework model characterizing evolution startup reynolds et al describe entrepreneurial cycle four phase conception gestation infancy adolescence cooper stagegate model consists five stage idea product lunch namely discovery scoping build business case development testing evaluation eric ries state startup need go three abstract step problemsolution fit productmarket fit scaling previous work proposed framework analyze software engineering se activity software startup demand se activity observed varied across idea phase pre startup phase startup phase scaling phase idea phase characterizes business opportunity firstly identified refined planning initial idea validation proposal writing prestartup phase minimal viable competence gathered startup team construction prototype approaching early customer funding organization startup phase marked introducing formal legislation involving management serving customer product development startup considered opportunistic activity focus providing value constrained condition startup scaling phase marked rapid growth user revenue team transferring stable organizational structure sme engineering aspect gsd gsd becomes part everyday business use different term related sourcing strategy ie outsourcing offshoring nearshoring farshoring rightshoring bestshoring etc smite et al described four type sourcing arrangement based whether outsourced task happen company insourcing outsourcing happen country onshoring offshoring success failure outsourcing experience viewed technical perspective relating quality delivered code communication customer satisfaction outsourcing considered beneficial small company direct indirect way cost saving proximity market skilled work force improving teamwork process distributed context collaboration coordination collaboration recognized project success factor practice managing coordination communication team identity trust effective use tool human factor reported gsd project participant smes study european smes
Original Title: Exploring the outsourcing relationship in software startups: A multiple
  case study
Original Transcription: This is the author's version of the work. It is self-arrived at Arxiv. The definite version was published in: Nguyen-Duc A. and P. Abrahamsson (2017). Exploring the outsourcing relationship in software startups: A multiple case study. Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering. Karlskrona, Sweden, ACM: 134-143., [https://doi.org/10.1145/3084226.3084248](https://doi.org/10.1145/3084226.3084248)

## 1 Introduction

Software industry has witnessed a growing trend of software products developed by small entrepreneurial teams aiming at a scalable business model [1]. A typical early stage startup is often financially bootstrapping, starting with some forms of initial self-funding (sweat equity, credit, savings, etc.) [7]. They rarely have both the necessary financial and human resources to complete the tasks required in the journey from ideation to commercialization. The situation forces them to reach out to external resources in performing engineering tasks such as design, prototyping, and manufacturing [11, 12]. These relationships could take a form of outsourcing, partnership, and later as acquisitions, and joint ventures [13].

To outsource or not is a controversial topic among startup enthusiasts [4-6]. In one hand, practitioners argue that outsourcing core competence, i.e. technical development in a technology-based startup is risky and can be illustrated as "_penny wise and pound foolish_" [5,6]. Moreover, hidden cost of outsourcing projects are known with geographical, temporal and cultural gaps among project locations. [9, 10]. On the other hand, we witness successful stories about adopting outsourcing strategies in unicorns at their early stages. Slack, the 3.8 billion USD valued startup, started their product development with an outsourced team [4]. Early versions of Skype, the video messaging platform acquired by Microsoft with 8.5 billion USD, was initially built by an outsourced team in Estonia [14]. More generally stated, outsourcing is considered as a strategy for innovation and radical changes in organizations [3]. It can be argued that these cases demonstrate for the viability of adopting outsourcing as an external sourcing strategy for software startups.

When outsourcing is predetermined or unavoidable, the awareness of common pitfalls and challenges would save entrepreneurs from serious managerial mistakes. Understanding the rise and evolution of the relationship in outsourcing arrangements is vital, because it not only helps through the operationalization of the agreement but also in the issues of dependency [16]. While Global software development (GSD) is rich with experience reports and best practices for outsourcing projects, it is biased to more established companies with software development processes in place [9, 10]. A review of empirical evidence shows only ten primary studies addressing GSD in the collaboration among small companies [9]. None of them purposefully target the contextual factors that are unique to startups.

A unique characteristic of a startup context is the experimental nature in the processes of both business and product development. Startup is searching for a scalable business model and often faces rapid changes at business idea, requirement and product levels. Product development in startups is considered as a set of opportunistic activities, which focus on providing value under constrained conditions of startups [23]. In a software startup context, the employed development team needs to be able to cope with many uncertainties and unknowns.

This is the author's version of the work. It is self-arrived at Arov. The definite version was published in: Nguyen-Duc A. and P. Abrahamsson (2017). Exploring the outsourcing relationship in software startups: A multiple case study. Proceedings of the 21st International Conference on Evaluation and Assessment in Software Engineering. Karlskrona, Sweden, ACM: 134-143., [https://doi.org/10.1145/3084226.3084248](https://doi.org/10.1145/3084226.3084248)

This work focuses on understanding entrepreneurs' experience with outsourcing as a team competence strategy. The study was performed under a large-scale multiple case study research about the state of practice in software startups. For this study, the insight was gathered from six companies that had adopted outsourcing strategies at various startup stages. Our specific research questions are:

* RQ1: What types of tasks are outsourced in software startups?
* RQ2: How do the outsourcing relationships evolve during the progression of a software startup?

The rest of the paper is structured as follows: Section II presents related literature, Section III describes the research approach, Section IV presents the findings, Section V discusses the results and Section VI concludes the paper.

## II Related work

### _The distinction between startups and SMEs_

There is no consensus definition about what a startup is. With Lean Startup and Customer Development approaches, Steve Blank et al. refer to a startup as an "_organization formed to search for a repeatable and scalable business model_" [18]. A startup typically carries on a business model, which is repeatable and applicable to a large market volume. U.S. Small Business Administration describes a startup as a "_business that is typically technology oriented and has high growth potential_" [19]. The term _technology_ can be applied to both software and hardware parts. In the scope of this work, we focused on software startups, who develop products with significant software parts.

There are fundamentally differences between a startup and an SME in term of business, organization and product dimensions, as shown in Table 1. U.S. Small Business Administration describes SME as "_independently owned and operated, organized for profit_, _and not dominant in its field_." [19]. Startups are designed to grow fast while SMEs focus on doing stable business for years. Another difference lies on the product and market certainty. SMEs generally sell known products to known customers in known local markets. In startups, customer and product are often unknown from the beginning. A lot of changes to both customers and products would be expected during the startup journey. Rather than a formal organization, a startup is likely to be a task-oriented group. Entrepreneurs are central to the organization as a whole and they carry out most of tasks [20].

### _Software startup life cycle_

There exist several frameworks and models characterizing the evolution of a startup [21-24]. Reynolds et al. describe an entrepreneurial cycle with four phases, conception, gestation, infancy and adolescence [24]. Cooper's stage-gate model [21] consists of five stages from an idea to the product lunch, namely, (1) discovery, (2) scoping, (3) build business case, (4) development, (5) testing and evaluation. Eric Ries states that that startups will need to go through three abstract steps, problem-solution fit, product-market fit and scaling up [22].

In a previous work, we proposed a framework to analyze Software Engineering (SE) activities in software startups [2]. The demand of SE activities is observed to be varied across (1) idea phase, (2) pre startup phase, (3) startup phase and (4) scaling phase. Idea phase characterizes by business opportunities firstly identified, and refined through planning, initial idea validation and proposal writing. Pre-start-up phase is when minimal viable competence was gathered in a startup team, construction of prototypes and approaching early customers and funding organizations. Startup phase is marked by introducing formal legislation, involving more management and serving customers. The product development in startups is considered as opportunistic activities, which focus on providing value under constrained conditions of startups [23]. Scaling phase is marked with rapid growth of users, revenues, team and transferring into a stable organizational structure.

### _SME engineering aspects of GSD_

GSD becomes a part of everyday business with the use of different terms related to sourcing strategies, i.e. outsourcing, offshoring, near-shoring, far-shoring, right-shoring, best-shoring, etc. Smite et al. described four types of sourcing arrangements based on whether outsourced tasks happen in the same company (insourcing or outsourcing) and if they happen in the same country (on-shoring or offshoring) [26]. The success or failure of an outsourcing experience is viewed from a technical perspective, relating to the quality of delivered code, communication and customer satisfaction [34]

Outsourcing is considered as beneficial for small companies in both direct and indirect ways, by cost saving, proximity to market, skilled work forces, improving teamwork and processes [27]. In a distributed context, collaboration, coordination and collaboration are recognized as project success factors [28]. Practices of managing coordination, communication, team identity, trust, effective use of tools, and other human factors are reported for GSD projects with the participants of SMEs [29-32]. A study of European SMEs

Tuple 14:
Cleaned Title: employeedriven innovation fuel internal software startup preliminary finding
Cleaned Transcription: missingpageempty disconnected crucial part organization software development unit something may hinder coordination thus render development process unstable finally part larger corporation typically reduces innovator autonomy need take account external customer also corporate management situation innovator may lose freedom pivot experiment considered crucial startup one approach argued strengthen innovation within existing company known employeedriven innovation edi edi assumes employee skill experience increase organization overall capacity innovate favorable condition also aligned one principle lean startup entrepreneur everywhere today practice software product innovation imply employee take active role driving new product one thus expect company increased role employee innovation also successful internal software startup despite seeming potential edi strengthen internal software startup research topic starting emerge software engineering therefore ask following research question company employeedriven innovation edi drive internal software startup answer reporting preliminary finding data collected two norwegian company edi strong focus innovation related work traditionally startup understood temporary organization focused innovative product little operative history aiming grow aggressively scaling business increasing availability software usage influence lean startup software startup become widespread rapidly find scalable business model build new product pivot necessary creates pressure established softwareintensive company response established company increasingly adopting socalled internal software startup regular external startup internal software startup risktaking proactive initiative develop software highly uncertain condition constantly searching repeatable scalable business model main difference however internal software startup nested within existing parent company unlike external startup rely limited resource internal startup benefit several existing resource eg salary external startup mainly driven need external customer internal startup also must consider corporate management however various type internal startup may differ much depend parent company example internal venture typically entirely supported resource parent company contrast spinoffs based technology parent company entirely rely resource eventually become independent new company fuel development new product business internal software startup company often rely specific innovation strategy examplegoogle relies practice like design sprint developer given one day showcase proof concept believe part product whereas atlassian applies method time allow ambitious innovation project undertaken one common trait practice described employee initiative entrepreneurial skill play central role internal startup characteristic employeedriven innovation edi edi seen informal innovation process meaning employee formally assigned innovation task therefore edi approach different traditional research development rd novel product developed dedicated formalized unit contrast edi approach allows innovation driven employee unit employee whether engage process organization systematically engage edi seem share set cultural characteristic based study company aasen et al identified nine shared feature commitment cooperative orientation pride trust tolerance feeling security development orientation openness autonomy study specifically focus three feature central data commitment cooperative orientation autonomy see table definition even though described edi practiced context term adopted field information system sufficiently studied software engineering study seek address knowledge gap examining company aligned principle edi focus innovating internal software startup method answer rq collected data two case internal software startup two norwegian company table selected company internal software startup employee first involved innovation process taking informal innovator role initiative edi company technologyintensive strong focus innovation first company iterate listed among best workplace innovator second company marcomp real name suppressed anonymity since actively training personnel management software product innovation company conducted semistructured interview collected document meeting note
Original Title: Employee-Driven Innovation to Fuel Internal Software Startups:
  Preliminary Findings
Original Transcription: [MISSING_PAGE_EMPTY:1]

disconnected from other crucial parts of the organizations, such as software development units, something that may hinder coordination and thus render the development process unstable [5]. Finally, being a part of a larger corporation typically reduces the innovator's autonomy because they need to take into account not only external customers but also the corporate management [6]. In such a situation, the innovators may lose the freedom to pivot and experiment, which is considered crucial for all startups [3].

One approach that is argued to strengthen innovation within existing companies is known as employee-driven innovation (EDI) [7]. EDI assumes that all employees have skills and experience that can increase the organization's overall capacity to innovate under favorable conditions, which is also aligned with one of the principles of Lean Startup "Entrepreneurs are everywhere" [8]. Today's practices in software product innovation imply that employees take an active role in driving new products [9]. One can thus expect that companies with the increased role of employees in innovation will also be more successful in internal software startups. Despite the seeming potential of EDI to strengthen internal software startups, research on this topic is only starting to emerge in software engineering. We, therefore, ask the following research question: _How do companies with employee-driven innovation (EDI) drive their internal software startups?_ To answer, we are reporting preliminary findings from data collected in two Norwegian companies with EDI and with a strong focus on innovation.

## 2 Related work

Traditionally, startups are understood as temporary organizations focused on innovative products with little or no operative history, aiming to grow by aggressively scaling their businesses [10]. With the increasing availability of software usage and the influence of Lean Startups, software startups have become more and more widespread [11]. They rapidly find scalable business models, build new products, and pivot if necessary, which creates pressure for established software-intensive companies.

As a response, the established companies are increasingly adopting so-called internal software startups. Just as regular (external) startups, internal software startups are risk-taking and proactive initiatives that develop software under highly uncertain conditions by constantly searching for repeatable and scalable business models [11, 12]. The main difference is, however, that internal software startups are nested within the existing parent companies [6]. Unlike external startups that rely on limited resources, internal startups benefit from several existing resources (e.g., salary) [13]. Further, if the external startups are mainly driven by the needs of their external customers, the internal startups also must consider their corporate management [13]. However, various types of internal startups may differ in how much they depend on their parent company. For example, internal ventures are typically entirely supported by the resources from the parent company. In contrast, spin-offs are based on the technology from the parent company but do not entirely rely on it for the resources and eventually become independent new companies [14].

To fuel the development of new products and businesses through internal software startups, companies often rely on specific innovation strategies [15]. For example,Google relies on practices like design sprints [9], where developers are given one day to showcase a proof of concept they believe should be part of the product, whereas Atlassian applies the method "20% Time" to allow more ambitious innovation projects to be undertaken [15]. One common trait in the practices described above is that the employees' own initiative and entrepreneurial skills play a central role for the internal startups, which is characteristic of _employee-driven innovation_ (EDI) [7]. EDI is seen as an informal innovation process [16], meaning that the employees are not formally assigned to innovation tasks. Therefore the EDI approach is different from traditional research and development (R&D) when novel products are developed by a dedicated formalized unit [7]. In contrast, the EDI approach allows the innovation to be driven by employees from any unit, and it is up to the employee whether to engage in the process or not.

Organizations that systematically engage in EDI seem to share a set of cultural characteristics. Based on a study of 20 companies, Aasen et al. [16] have identified nine shared features: commitment, cooperative orientation, pride, trust, tolerance, feeling of security, development orientation, openness, and autonomy. In this study, we specifically focus on the three features that were central in our data: _commitment_, _cooperative orientation_, and _autonomy_ (see Table 1 for the definitions).

Even though it has been described how EDI is practiced in other contexts [16] and the term has been adopted by the field of Information Systems [17], it is not sufficiently studied in software engineering. Our study seeks to address this knowledge gap by examining the companies that are both aligned with the principles of EDI and focus on innovating through internal software startups.

## 3 Methods

To answer the RQ, we collected data from two cases of internal software startups in two Norwegian companies (Table 2). We selected companies with internal software startups and where employees were first involved in the innovation process by taking an informal innovator role on their own initiative (EDI). Both companies are technology-intensive with a strong focus on innovation. The first company is Iterate that was listed among the 100 best workplaces for innovators in 2020 [18]. The second company is MarComp (real name suppressed for anonymity), which has since 2018 been actively training personnel and management in software product innovation. In both companies, we conducted semi-structured interviews and collected documents and meeting notes

Tuple 15:
Cleaned Title: businesscycles cashonmarket premoney startup valuation macroeconomic environment
Cleaned Transcription: businesscycles cashonmarket premoney startup valuation macroeconomic environment footnote article sponsored partner finance innovation chair audencia business school especially early metric sowefund provided financial support max berre phd course author wish express sincere gratitude support additionally author want thank underlinetextxtextx editor charge paper underlinetextn anonymous referee helpful comment moreover thanks dimitris petmezas aristrogens iazos paul olivier klein well attendee entfin feb fem conference fruitful comment max berre benjamin le pendeven article sponsored partner finance innovation chair audencia business school especially early metric sowefund provided financial support max berre phd course author wish express sincere gratitude support additionally author want thank underlinetextxtextx editor charge paper underlinetextn anonymous referee helpful comment moreover thanks dimitris petmezas aristrogens iazos paul olivier klein well attendee entfin feb fem conference fruitful comment phd candidate audencia business school nantes france universite de lyon naydon magellan lyon france associate professor head finance innovation chair audencia business school nantes france kcpendevcnaudenciacom introduction worldwide venture capital vc market reached record term value invested number deal q vc market hosted deal value around billion deal count around pitchbook record also shattered term startupvaluations example quantity unicorn growing wall street journal hurun research institute meanwhile expert industryreports document dramatic increase valuation funded startup median u premoney valuation ranging million angelfinancing billion roundd financing million angel financing billion roundd financing europe pitchbook question causalitystructure appear critical practitioner payne berkus policymakers dieppe al popov academic kaplan et al gompers et al entrepreneur finance literature related startup valuation deeply investigated stakeholderfactors entrepreneur investor side dealconditions dedicated limited attention macroenvironmental factor berre le pendeven kohn even though longunderstood vc market deeplyprocyclical investmentintermediaries channeling investmentfunds entrepreneurial landscape boom market recover aftermath recession limited understanding consequence premoney valuation funded startup selection stage heughcheaert manigart find moresuccessful vcdeals occur domestic economicgrowth stronger schwienbacher outline market vc financing subject large variation capitalsupply businesscycle institutional investor channel large amount capital vcfunds boom nonbank financialintermediaries vcfunds might responsive macroeconomic condition bankingsector many part economy reputationalcosts onvc market lower boom due increased capitalavailability schwienbacher valuationimpacts financial variable businesscycle dependent gavious schwartz principle mean nuanced macroeconomic distributionchannels work phenomenon grant opportunity draw novel insight wider theory synthesizing macro entrepreneurial finance literature gap explicitly pointedout budhwar et al gap especially pertinent since couple finance study examined nature businesscycle macroeconomic driverimpact vc startup market directly include fitza et al korteweg sorensen empirically find businesscycle impact valuation phenomenon need modeling research addressing gap critical understanding vc market dynamic well balance investor entrepreneur valueholdings gave rise attentiongrabbing headline recent year unicorn emerged several world key market using bespoke vcdataset consisting european union eu european economic area eea deal study explores impact macroeconomic businesscycle valuationfactors startupvaluations range macroeconomic outputgap drypowder well countryriskpremiums venture capital cashonmarket european union supranational decisionmaking regulatory power focus mainly tradepolicy economicregulation macrofinancialregulation jopp examining mathrmeea marketdata grant rare opportunity insight market combine divergent macroeconomic macrofinancial landscape unified financialregulatory landscape outline many traditional valuationdrivers classically demonstrated impact firmvaluation startupvaluation ranging macrofinancial indicator intermediarymarket indicator fact mediatingvariables channeling businesscycle effect entrepreneurial landscape essentially many startupvaluation driver actually distributionchannels rather independent valuation factor startupvaluations known driven discountedcashflow model dcf control discountedcashflowbased firm performancecharacteristics addition marketcondition valuationfactors lead viable factorbased startupvaluation model examine externalinformation sectoral marketstructure macroeconomic situation examination contextual detail including interactioneffects indirecteffects contribution twofold first study address gap linking entrepreneurial finance macroeconomic theory outlined budhwar et al second result describe relationship businesscycles startupvaluations nonlinear relationship consisting multiple independent valuationchannels connecting valuation businesscycles via partiallymediating intermediatevariables represents new way conceptualizing startup premoney valuation essentially empirical result obtained structuralequation modeling contribute entrepreneurship financialintermediary literature describing empiricallysupported model demonstrating businesscycles impact startupvaluations directly via multiple independent macrolevel valuation channel paper develops follows section two examines literature exploring vc startupmarket impact countrylevel macroeconomic factor role describing determination premoney startupvaluations section three describes dataset well keyvariables empiricalapproaches used develop insight impact macroeconomic businesscycle marketconditions startupvaluations section four describes empirical result baselinescenario ols model fixedeffects model used section five discus key finding detail section six outline findingsimplications well conclusion avenue future research literature review demonstrated several systematic literature review premoney startup valuation kohn wessendorf berre le pendeven published paper field mostly investigate entrepreneur investor dealrelated factor valuation macroeconomic determinant attract limited attention fact aforementioned author describe many paper include macroeconomic driver primarily control variable mean study examine role macroeconomic market condition detail thereby constituting noticeable gap research rarer still study explore indirect effect valuation within entrepreneurial field deterministic impact macroeconomic macrofinancial indicator driving startupinvestment long storied idea within economic literature traced several author established overall vc market behave highlyprocyclical financial intermediary bygrave timmons korteweg sorensen macroeconomic impact funding availability vc intermediary role venture capital market financial intermediary market driven businesscycles macroeconomic condition even drive startupvaluations early chan proposes theoretical model outlining investmentallocation macrolevel depends vc intermediary role manage sectorspecific informationasymmetries intermediary role vc market wellunderstood focusing vc fundavailability gompers lerner employ twostage heckman model estimating probability fund raised followed amount fund raised find firmcharacteristics strongest effect fundraising commitment vcfunds also directly impacted gdpgrowthrates capitalgains tax affect amount raised fundingprobability stated otherwise impactof vc funding influenced external marketconditions vc fundavailability driven growthrates meanwhile total value stock traded one significant determinant explaining divergence vc intensity according bonini alkan test impact gdp inflation rate real interest rate total number stock traded well corporate income taxrates business expenditure rd key determinant inflation rate total entrepreneurial activity bonini alkan meaning vc market may driven macroeconomic factor also startupmarket activity private equity activity driven institutional legal environment well economic activity unemployment rate equity market capitalization unit labor cost bernoth colavecchio using countrylevel fixedeffects dividing sample westerneurope easterneurope find institutional legal environment substantial individual explanatorypower overall intuitive separatelyexamining eastern western european market period euenlargement find institutional political variable well inflation highlydeterministic european private equity market principle indicates countrylevel variable influence overall impact private equity economy nevertheless noted privateequityinvestment measured relative gdp indicates investorconfidence might necessarily indicate return valuation market concerning funding availability inflow capital vcfunds increase valuation investmenttargets gompers lerner activity private equity market highly deterministic influencing startupvaluations inderst muller hellmann thiele addition cashonmarket inderst muller make several key insight describing endogeneity vc fundsscarcity entrycosts investmentprofitability theorizing investmentprofitability drive startupvaluation well vc marketentry statedotherwise cashonmarket drive startupvaluations relationship functional form might subject endogeneity indirect valuationimpacts essentially investigation specific nuance variability valuationimpacts give rise research debate business cycle mathrmgdpgrowth businesscycle dynamic known play role determining startupvaluation dieppe al example moresuccessful vc deal occur belgian economic growth stronger heughchebart manigart general level dicppe al european central bank ecb study describing ecbs global macroeconomic spilloveranalysis model describe financialvariables keydeterminants domesticoutput financialspillovertransmission occurring via four channel equityprices interbankratespread lendingtightness sovereignriskpremium relationship lendingtightness turn driven momentum expectedgdpgrowth intermediaryrole played lendingtightness deterministiceffect realeconomy impacted key macroeconomic variable informative understanding structural relationship macrolevel variable realeconomy dees another ecb study us gvar modelapproach describe transmission financialshocks realeconomy find financialvariable impact realeconomy remains broadlyunchanged time businesscycle progress finding financialvariable impactstability informative understanding structural relationship surrounding impact valuation nevertheless vcfinancing market subject large variation capitalsupply businesscycle seeing large inflow institutionalinvestors boomperiods schwienbacher financialintegration drive businesscyclesynchronization via indirecteffects promoting tradeintegration economic structuralsimilarity even direct qualitative quantitative financialintegrationeffects indicate otherwise trancoso gomes study highlyrelevant due separation direct indirect impact businesscycles demonstrating inherent complexity relationship businesscycles overall economic situation demonstrating possible need structuralequationmodel approach literature describing direct indirect impact businesscycles according potentiallycomplex causalarchitecture give rise question exactly architecture actually look like relationship direct indirect determinant area one seldom investigated macrofinancial interaction effect macroeconomic businesscycle indicator play key deterministic role startup market also interactioneffects macroeconomic indicator industrylevel indicator also likely play role demonstrating vc market play highlyvariable financial intermediary role popov corroborates focusing relationship vc market firmsize proposing model describes firm size product industrylevel firmsensitivity vc finance bank finance well vc marketsize author highlight industrylevel sensitivity vc market drive firmlevel employee size establishes relationship exist financialmarketconditions startup also relationship industryspecific ie relationship influenced sectoral variable subject multivariate functionalform meanwhile firm characteristic ebitda weighed differently country country lockett et al lower riskfreerate drive overvaluation illiquidity premium reduces overvaluation meaning fundamentally valuation discountfactors driven overall cyclical macrofinancial condition gornall strebulaev demonstrates valuationeffect dcf valuationfactors ie revenue discountfactors impacted macroeconomic cyclical marketconditions however raise question specifically effect occur existing literature establishes relationship vc market input startupvalue ic firm entrepreneurcharacteristics startup valuation influenced marketconditions via direct indirect interactive influence sectoral macroeconomic condition whose functional form complex bear investigation background research hypothesis marketconditions macrolevel indicator sectoral cyclical indicator hsu us yeardummies observes valuation tend higher fund inflow high well armstrong et al control benchmark financialindex finding valuationimpact positive significant addition interactioneffects marketconditions firmcharacteristics create additional valuationsynergies example literature include gavious schwartz find valuationimpact firm balance sheet financials evolves along businesscycle growing importance postbubble recession similar vein gomers et al find interaction effect exist sectoral market condition investor characteristic general level startupvaluation may driven overall economic cyclical activity several study suggest case example moresuccessful vc deal occur boom period heughebaert manigart moreover businesscycle impact valuation fitza et al korteweg sorensen overall economic activity directly impact privateequity activity share macroeconomy bernoth colavecchio several way businesscycles directly impact valuation revenue discountfactors ie beta countryriskpremium controlled directly businesscycles might directly impact valuation due potential future revenuegrowth industrygrowth macroeconomicgrowth may serve attract investor influencing investor selection startupvaluation wessendorf meanwhile businesscycle growth impact valuation mean growth business network partnership relationship streletzki schulte alternatively macroeconomic businesscycle condition also serve inflate startupvaluations shortrun boom albeit shortlived based may later corrected described michel thus expected macroeconomic indicator drive overall activity also valuation hand valuation startup driven marketconditions morespecific vc market study elaborate venture capital cashonmarket directly priori influence premoney valuation described inderst muller also influence entrepreneureffort described fulghieri sevilir increase valuation directly also serve valuesignal investor europeanmarket deal captured dataset tested measuring impact businesscycles macroeconomic indicator countrylevel vcsector size startupvaluations lead u hypothesis market condition macrolevel condition financialintermediary condition ha macro drive market startupvaluations driven macroeconomic macrofinancial macrolevel indicator basis revenue discountrate projection direct valuationimpacts exist hb startupvaluations driven vc asbonmarket domesticasbonmarket impact indicate relativelyinsular vc market globalasbonmarket impact indicate crossborder valuationeffects meanwhile condition vc market may driven businesscycle condition impacting startupvaluations several study describe nonbank financial intermediary market includes vc market investment market influenced businesscycles procyclical manner macroeconomic activity impact overall privateequity activity meaning macroeconomy grows investment emergent firm grows well bernoth colavecchio financialspillovertransmission occurs via equityprices interbankratespread lendingtightness sovereignriskpremium relationship fundamentally mean cashonmarket likely transmits financial spillover businesscycle originating elsewhere wider macroeconomy dieppe al meanwhile lending subject macroeconomiclevel variation driven macrolevel tailrisks chu zhang vcfinancing market subject substantial variation capitalsupply businesscycle schwienbacher conjunction dieppe al mean vc market function manifestation financialspillovertransmission channel line equityprices lendingtightness cashonmarket capture vcsector size country bear testing whether deterministicallyinfluenced macroeconomic businesscycle indicator leading u hypothesis financial intermediary market cashonmarket h cashonmarket driven macroeconomic syticalindiators direct valuationimpact cashonmarket macrofinancial indicator exist may create secondorder valuationimpact effect principle startupvaluations known driven revenue parseable riskpremiums damodaran manner degree impact startupvaluations country industryspecific damodaran else influenced condition country city industry specifically nature scale impact dcf valuationfactors influenced macrolevel market condition might either regulatory macroeconomic nature gompers lerner lockett et al bernoth colavecchio alternatively influenced industrylevel effect chan damodaran corroborating manigart et al identify valuationimpactdifferences sector geographic setting investorcontexts handalternate view describe nationallevel economiceffects driven locallevel investorside supplychain effect porter combination factor impacting relationship startupvaluation valuationdrivers also observed vcs across different country focusing fintechindustry startup term functionalform describes divergence impact dcf valuation factor across city country industry investor jointcombination thereof might specific industry city investor country whose valuationdivergences might driven difference functionally industry fixedeffects explain difference valuation capturing industry level businessrelationships business model firmsurvivability difference damodaran meanwhile countrylevel fixed effect may capture nationallevel difference macroeconomic fundamental also governance economic policy difference gompers lerner bernoth colavecchio governance policy difference lead divergence valuation approach relativeimportance valuationdrivers rojoramirez lastly city fixedeffects capture economic clustering well citylevel investor industryconcentration porter fundamentally since literature describes impact dcf valuationfactors influenced countrylevel industrylevel locallevel dynamic important compare also examine specific nature functional form specific influence valuationimpact dcf valuationfactors principle measured controlling categoricals country industry city via fixedeffects leading u hypothesis subset among startup vcs h macroeconomic situation affect vc investor startup subset dataset others therefore fixedeffects regression may tell dramatically different story baseline macroeconomic macrolevel regressionsconcerning influence marketconditions valuationimpact dcffactors alternate approach functionalform question model indirect effect relationship role businesscycles particular boom valuation impact variable ranging financial variable described gavious schwartz reputational cost described schwienbacher indicate clearly businesscycle valuationimpacts direct indirect valuationimpact well businesscycle influencing intermediate valuationfactors vcindustry variable countryriskpremiums macroeconomic determinant influence valuation study far first model indirect effect empirical literature outline formal entrepreneurship driven availability economic opportunity inturn driven macrolevel resourceavailability thai turkina financialvariables act keydeterminants domesticoutput financialspillovertransmission occurring via four channel equityprices interbankratespread lendingtightness sovereignriskpremium relationship lendingtightness turn driven momentum expectedgdpgrowth dieppe al principle overall relationship startup macroeconomiccycles intermediary financial valuationimpact channel likely follows similar pattern pattern explored dees using gvar modelapproach capture relationship valuation intermediate variable might indicate endogenous fully partiallycircular causalrelationships similar pattern corroborated trancoso gomes examine direct indirecteffects linking financialindicators businesscycle synchronization affirms structuralequationmodel approach particularly wellsuited examination businesscycle dynamic relationship additionally beyond capturing indirect effect semapproaches facilitate capture endogenous fully partiallycircular relationship among dependent independent mediatingvariables essentially group study lead u conclude indirecteffects valuation intermediatevariables wider macrocyclical condition captured multistage econometric model thai turkina dees trancoso gomes remains seen precise shape architecture direct indirect relationship well whether part relationshiparchitecture endogenous nature principle relationshiparchitecture shape tested via structuralequation model technique specific structure indirecteffects modelled detail leading u hypothesis direct indirect effect structure functional form ha businesscycles financialintermediary marketconditions impact startupvaluations directly independently oneanother hb businesscycleinputs startupvaluations noncircular full partialmediation effect impacting valuation directly case partialmediation via market condition hc businesscycleinputs startupvaluations circular full partialmediation effect impacting startupvaluations endogenous circular relationship mediating financialmarket condition startupvaluations data methodology section outline key modelling approach used capture describe indirect contextualeffects literature describes market condition valuationimpact dcfrelated valuationdrivers literature describes indirect contextual impact effect valuationdeterminants specific nature relationship remained matter debate scorecardbased valuation premoney startupvaluations price price share paid equity investor earlystage investment cumming dai scorecardvaluation method modular relatively straightforward valuationapproaches based summation key characteristic market condition dealconditions developed mainly industry practitioner meanwhile economic literature concept appears summationbased valuation model hand sievers et al principle scorecard approach model indirect valuationinfluences several way well incorporating nonfinancial dealcharacteristics prevalent given market subset thereof startupvaluation metamodel berre le pendeven develop model outlining contextuallyadjusted startupvaluationprocess assigning factor appropriate processchronologicalpositions essentially startupvalueinputs navigate external marketconditions part valuationforming process implies directeffects interactioneffects marketconditions startupvaluation textbfpre money valuationtextbffsumtextbfstartup valuesumtextbfbeat valuesumtextbfbeat valuation order approach clear view explanatory power valuationimpact macroeconomic factor macrofinancial factor startup ecosystem factor used classical firm valuation model particular dcfrelated factor included empirical model inclusion classical factor serf two purpose first inclusion used test establish conceptual theoretical soundness dataset second inclusion classical valuationfactors serf key control factor need taken account order isolate macroeconomic macrofinancial effect subsequently empirical approach focus examination startup valuationimpact key macroeconomic macrofinancial factor including indicator policy factor include macroeconomic outputgap macrolevel taxrates total cashonmarket level available domestically world vc market structuralequationmodelapproach scorecardvaluation functional form notwithstanding accuratemeasurement valuationimpacts marketconditions face two principal modelingobstacles endogeneity indirecteffects eg partial fullmediationeffects order address obstacle employ partialleastsquares structuralequation modeling sem approach several relevant advantage given context examined adopting sem approach allows u analyze complex indirectrelationships gefen et al feature direct indirecteffects little et al appropriate exploratory theorybuilding prediction nonparametric estimationtechnique wold approach provides iterative combination empiricalanalyses relates measure construct path analysis capture structural model represents direct indirect relationship among key valuationdrivers indirecteffects businesscycle impact startupvaluation likely indirect acting via effect financingcosts condition direct acting directly firmrevenues businessopportunities localmarketdemand firmlevel assetvalues tie firm fortune directly businesscycle structuralequationmodelapproaches allow simultaneous measurement direct indirecteffects including full partial inconsistent mediation well latent unobserved variable observed relationship might part complex qualified relationshipsystem little et al structuralequationmodelapproaches particularly wellsuited investigating businesscycleeffects dynamic driver trancoso gomes endogeneity wooldridge outline principle endogeneity arises due one three cause omittedvariablebias simultaneity measurementerror principle endogeneitytesting indicatewhether causalrelationship either morecomplex detected atfirstglance whether causal relationship influenced either additional explanatoryvariables measurementerror directlycircular endogenous relationship businesscycle startupvaluation unlikely given dataset dominated startup large historicallyestablished european economy relationship businesscycles cashonmarket startupvaluation may give rise circular cashonmarketrelationships whereby businesscycles cashonmarket may endogenouslyrelated additionally cashonmarket might endogenouslyrelated valuation alternately endogeneity might driven hiddenvariablebias wooldridge might found acting upon model dependentvariables explanatoryvariables use twostageleastsquares wellestablished modelapproach accounting endogeneity selection variable well relationship dependentvariables explanatoryvariables must given careful consideration addressing concern structuralequation model proposed figure principle twostage least square regression analysis used analysis structural equation gefen et al essentially extension ols method useful dependentvariables error term correlated independentvariables wooldridge figure valuationimpact direct businesscycle effect well indirecteffects via financingconditions modeled panel describes businesscyclevaluation relationship noncircular relationship subject partialmediation via financing condition panel b describes businesscyclevaluation relationship subject partialmediation via financing condition endogenous relationship businesscycle cashonmarket valuation cashonmarket equation structure term equationstructure figure describes twotiered structuralequation model subject partialmediation involving countryriskpremium cashonmarket mediatingvariables follows cashonmarkettsumttbetaitoutputgaptsumtt betaitcreditriskpremiumtvarepsilonit valuationtsumttbetaitreverunetsumttbetait sectoralriskbetatsumttbetaitcreditriskpremiumt varepsilonit circularrelationships businesscycle indicator cashonmarket might possible principle unlikely given composition dataset ie deal established highlyindustrial mathrmeea market whose vc market comparatively smaller share gdp whose businesscycles often driven europeanlevel cyclical transmission channel weyerstrass et al difficulttomeasure given need instrumental figure structuralequationmodel valuationrelationhip pathdiagram nongranular circular modelsvariable would impact businesscycles cashonmarket hand partialendogeneity involving endogenous relationship valuation cashonmarket measurable supported economic theory term equationstructure figure b describes partiallycircular relationship featuring endogenous relationship cashonmarket contemporaneousendogeneity startupvaluation follows cashonmarkettsumttbetaitoutputgaptsumtt betaitvaluationtsumttbetaitcreditriskpremiumt varepsilonit valuationtsumttbetaitrevenuetsumttbetait sectoralriskbetaiotasumttbetaitcreditriskpremiumt varepsilonit dataset first piece dataset consists proprietary vc dealdata shared early metric parisbased startup rating research agency observation add euand mathrmeealocated startupdeals drawn eikon crunchbase valuation disclosed deal respectively observation supplementary source chosen due contentsimilarity early metric data regular use entrepreneurial finance research enrich dataset deal crossreferenced firmperformance industrylevel municipal nationallevel macroeconomic data including proprietary commerciallyavailable data also boasting extensive variety valueadding categoricalvariables categoricalvariables substantial explanatorypower right also add value virtue interaction firmcharacteristics well macroeconomic businesscycle marketconditions study focus selection european data give study numerous strength ranging institutional macroeconomic diversity sufficient meaningful geographic fixedeffects marketexamination taking taking account distinct contextual geographic factor line within dataset specific perinvestorperdcal deal multiple investor occupy multiple line within dataset identifying data startup investor since startup several investor multiple observation regression analysis reflecting unique investorstartup pair structure borrowed masulis nahata observation representing deal across startup ranging q q datasetsize substantial although observation contain firmlevel revenue figure nevertheless yield regression substantial degree freedom compared prominent study entrepreneurial finance startup field masulis nahata greenberg gompers et al examine observation respectively dependent variable primary dependent variable used study premoney startupvaluation reflects product share price funding round multiplied number outstanding startup share since dataset drawn eu eea data valuation expressed eur data drawn outside eurozone uk poland norway sweden switzerland converted eur table b outline summary statistic premoney valuation data data time sectoral distribution somewhat uneven cover several major event including end dotcom bubble eurozone crisis start covid pandemic independent variable macroeconomic macrofinancial marketconditions line gompers lerner bonini alkan find valuation driven macroeconomic indicator cyclical indicator taxrates study macroeconomic data also consist countryriskpremiums cyclical indicator taxrates gdp growth would hypothetically constitute viable way keep track businesscycle condition dataset consists mainly recessionaryperiod data feature positive belowtrend gdpgrowth figure well smaller deterministic effect boom recession need cyclicalcontextualization order reliable explanatory variable therefore select macroeconomic outputgap drawn oecd figure primary macroeconomic marketcondition indicator additionally macroeconomic level include imf taxrate figure tax revenue share gdp well countryriskpremium drawn nyustern database countryriskpremiums corecomponents riskadjusted discountrates damodaran also included baselinescenario driven discountedcashflow valuation model add total vc marketsize available country level global market inderst muller describe key determinant startup valuation well dry powder may act intermediate variable valuation process former drawn oecd annual data total vc investment per country meanwhile latter drawn invest europe provides annual drypowder figure six multicountry region europe subsequently nationallevel annual drypower figure estimated basis country fraction total vc investment region alternative capturing businesscycle macroeconomic outputgap also use eurozone growth cycle coincident indicator gcci robustnesscheck whose result outlined appendix iii valuationdriver interaction addition direct valuationimpacts dcfrelated valuationfactors well macrolevel driver startupvaluation impact variable oneanother demand consideration overall impact economicindicators vary businesscycles progress blanchard leigh notable example sort impact existing within published entrepreneurial finance literature include gompers et al find interaction effect investorexperience macroeconomic indicator well gavious schwarz find evidence interactioneffects businesscycle startup firm characteristic mean regression including interactioneffects justified theory existing literature end interaction variable established potential interaction dcfrelated variable cashonmarket businesscycle baseline model control scenario classically depending valuationapproach valuation driven firmperformance revenue indicator sale revenue net income cash flow operation ebit ebitda discounted riskfactors industryriskpremiums countryriskpremiums wacc capmbetas per dcf model contextualized balance sheet income statement figure per multiple valuation model moderated growthrates gordon growth model damodaran functionally dcfapproach approximated using olsregressions regressing valuation revenue indicator well dcf discountfactors sectorlevel unleveredbeta countryriskpremium fundamentally damodaran hold existing valuation approach either apply dcf directly else borrow dcf assessment caried others damodaran relative multiple valuation approach valuationimpact dcf valuationdeterminants need controlledfor mean establishing theoreticalconsistency dataset well determine concrete valueadded nondcf valuation factor macroeconomic market condition financialintermediaries market condition businesscycle condition startup revenue included early metric deal dataset well minority deal drawn eikon additional revenue figure drawn dun bradstreet well zoominfo thereby fillingin revenue figure approximately half dataset sectoral unleveredbeta industrylevel measure systemicrisk drawn damodarans nyustern dataset communicates industrylevel sensitivity financialmarket benchmarkvolatility figure used damodaran input riskadjusted discountrates used dcfbased valuationmodels countryriskpremium drawn damodarans nyustern datasets country defaultspreads riskpremiums page accessed january principle represents sovereign bond rating appropriate default spread different country figure used damodaran input riskadjusted discountrates used dcfbased valuationmodels dcfrelated valuationfactors used construct dcfbased regression test datasetsoundness subsequent regressionanalysis dcfrelated regressionvariables also serve controlvariables categorical variable fixedeffects addition dcfrelated controlvariables macroeconomic macrofinancial variable several categorical variable may also deterministic effect startup valuation furthermore likely least variable may also serve modulate valuationimpact macrolevel variable dcflinked control variable specifically nature scale impact dcf valuationfactors influenced macrolevel market condition might either regulatory macroeconomic nature gompers lerner lockett et al bernoth colavecchio industrylevel effect chan manigart et al damodaran locallevel investorside supplychain effect porter additionally combination factor impacting relationship startupvaluation valuationdrivers also observed vcs across different country focusing fintechindustry startup therefore inclusion justified include firm industry country city year investortype drawn primarily eikon deal data well secondary source uk companics house corroborates uk firmlevel data also contributing geographic data substantial level detail missingpagefail missingpagefail examination directeffects valuation also demand examination businesscycleinteractioneffects table examines interactioneffects dcffactors macroeconomic factor valuation panel examines dcfoutputgap interactioneffects addition outputgap demonstrating outputgaps significant interactioneffects riskadjusted financing cost acting countryriskpremium sectoralbeta panel b includes dcfdrypowder interaction effect find dry powder slight interactioneffects countryriskpremium meanwhile panel c examines dcfcashonmarket interactioneffects demonstrating cashonmarket mainly interactioneffects countryriskpremium indicates cashonmarket likely play larger role determining countryriskpremiums impact startupvaluation meanwhile panel demonstrates interactioneffects worldcashonmarket negligible mean interactioneffects driven domestic economictrends rather international one missingpageempty finding demonstrate evidence confirming directeffects startupvaluations outlined hypothesis b goodnessoffit figure outlined table demonstrate substantial increase goodnessoffit taken evidence directeffect valuationimpacts cashonmarket addition valuationimpact driver startup businesscycle might also drive cashonmarket cashonmarket demonstrably play deterministic role premoney startup valuation impact macrolevel cashonmarket considered secondorder effect table examines impact macrolevel factor domestic cashonmarket panel examining univariateregressions panel b multivariateregressions overall goodnessoffit indicator demonstrate outputgap world cashonmarket strongest explanatory power followed countryriskpremium tax rate countryriskpremiums negative impact domestic cashonmarket line economic theory panel b regression combining driver indicate businesscycle fundingcosts drive domesticcashonmarket inclusion world cashonmarket double regression goodnessoffit indicating strong evidence crossborder impact cashonmarket
Original Title: Business-cycles and Cash-on-Market: Pre-money Startup Valuation in the
  Macroeconomic Environment
Original Transcription: Business-cycles and Cash-on-Market:

Pre-money Startup Valuation in the Macroeconomic Environment1

Footnote 1: This article has been sponsored by the Partners of the “Finance for innovation” Chair at Audencia Business School, especially Early Metrics and Sowefund, who provided financial support to Max Berre during his PhD course. The authors wish to express their sincere gratitude for this support. Additionally, the authors want to thank \(\underline{\text{X}\text{X}}\) as editor in charge of this paper, and the \(\underline{\text{N}}\) anonymous referees for their helpful comments. Moreover, thanks to Dimitris Petmezas, Aristrogens Iazos and Paul Olivier Klein, as well as the attendees to the ENTFIN 2021, FEBS 2021, and FEM 2022 conferences for their fruitful comments.

Max Berre\({}^{2}\) and Benjamin Le Pendeven\({}^{3}\)

\({}^{1}\)This article has been sponsored by the Partners of the "Finance for innovation" Chair at Audencia Business School, especially Early Metrics and Sowefund, who provided financial support to Max Berre during his PhD course. The authors wish to express their sincere gratitude for this support. Additionally, the authors want to thank \(\underline{\text{X}\text{X}}\) as editor in charge of this paper, and the \(\underline{\text{N}}\) anonymous referees for their helpful comments. Moreover, thanks to Dimitris Petmezas, Aristrogens Iazos and Paul Olivier Klein, as well as the attendees to the ENTFIN 2021, FEBS 2021, and FEM 2022 conferences for their fruitful comments.

\({}^{2}\)PhD Candidate, Audencia Business School, Nantes, France and Universite de Lyon, naydon, Magellan, Lyon, France \({}^{3}\) Associate Professor, Head of "Finance for innovation" Chair, Audencia Business School, Nantes, France, \({}^{3}\)kcpendevcn@audencia.com

## 1 Introduction

In 2020 and 2021, worldwide Venture Capital (VC) markets reached records both in terms of value invested and in number of deals. In Q4 2021, VC markets hosted deal values around $191 Billion, and deal counts around 11,000 (Pitchbook, 2022). Records were also shattered in terms of startup-valuations, with for example quantity of unicorns growing from 45 in 2014 (Wall Street Journal, 2014) to 1,056 in 2021 (Hurun Research Institute, 2021). Meanwhile, experts and industry-reports document dramatic increases of valuation of funded startups, with median US pre-money valuations ranging from $11.4 Million for angel-financing to $1.22 Billion for Round-D financing and $5.08 Million for angel financing to $1.73 Billion for Round-D financing in Europe (Pitchbook, 2022). Questions of causality-structure now appear critical for practitioners (Payne, 2011; Berkus, 2016), policy-makers (Dieppe at al., 2017; Popov, 2009) and academics (Kaplan et al., 2009; Gompers et al., 2020).

Entrepreneur finance literature related to startup valuations deeply investigated stakeholder-factors (both entrepreneur and investors sides) and deal-conditions, but dedicated limited attention to macro-environmental factors (Berre and Le Pendeven, 2022; Kohn, 2018).

Even though it has been long-understood that VC markets are deeply-procyclical investment-intermediaries, channeling investment-funds into the entrepreneurial landscape both during booms and as markets recover in aftermath of recessions, we have a limited understanding of their consequences on pre-money valuation of funded startups, after the selection stage. Heughcheaert and Manigart (2012) find that more and more-successful VC-deals occur when domestic economic-growth is stronger, while Schwienbacher (2013) outlines that markets for VC financing are subject to large variations in capital-supply over the business-cycle, institutional investors channel large amounts of capital to VC-funds during booms.

As non-bank financial-intermediaries, VC-funds might be more responsive to macroeconomic conditions than is the banking-sector or many other parts of the economy. Reputational-costs onVC markets are lower during booms due to increased capital-availability (Schwienbacher, 2013), while valuation-impacts of financial variables are business-cycle dependent (Gavious and Schwartz, 2011).

In principle, this means that nuanced macroeconomic distribution-channels are at work. This phenomenon grants opportunity to draw in novel insights from wider theories by synthesizing between macro and entrepreneurial finance, a literature gap explicitly pointed-out by Budhwar et al. (2022). This gap is especially pertinent since just a couple of finance studies examined the nature of business-cycle and macroeconomic driver-impact on VC and startup markets directly. These include Fitza et al. (2004) and Korteweg and Sorensen (2010), which both empirically find business-cycle impact on valuation, a phenomenon which needs further modeling and research.

Addressing this gap is critical to understanding VC market dynamics, as well as the balance between investors and entrepreneurs' value-holdings, which gave rise to attention-grabbing headlines in recent years, as unicorns emerged in several of the world's key markets.

Using a bespoke VC-dataset consisting of 1045 European Union (EU) and European Economic Area (EEA) deals from 2000 to 2020, this study explores impacts of macroeconomic and business-cycle valuation-factors on startup-valuations. These range from macroeconomic output-gap to dry-powder, as well as country-risk-premiums and venture capital cash-on-market. Because European Union supranational decision-making and regulatory powers focus mainly on trade-policy, economic-regulation and macrofinancial-regulation (Jopp, 2017), examining \(\mathrm{EEA}\) market-data grants rare opportunity to have insight into markets which combine divergent macroeconomic and macrofinancial landscapes with unified financial-regulatory landscapes.

We outline that many traditional valuation-drivers classically demonstrated to impact firm-valuation and startup-valuation ranging from macrofinancial indicators to intermediary-market indicators are, in fact, mediating-variables channeling business-cycle effects into the entrepreneurial landscape. Essentially, many startup-valuation drivers are actually distribution-channels rather than independent valuation factors.

Because startup-valuations are known to be driven by discounted-cashflow models (DCF), we control for discounted-cashflow-based firm and performance-characteristics in addition to market-condition valuation-factors. This leads to a viable factor-based startup-valuation model which can examine both external-information, such as sectoral market-structure or macroeconomic situation, and examinations of contextual detail, including interaction-effects and indirect-effects.

Our contributions are twofold. First, this study addresses the gap linking entrepreneurial finance and macroeconomic theory outlined by Budhwar et al. (2022). Second, our results describe the relationship between business-cycles and startup-valuations as a nonlinear relationship consisting of multiple independent valuation-channels connecting valuations with business-cycles via partially-mediating intermediate-variables. This represents a new way of conceptualizing startup pre-money valuation. Essentially, our empirical results obtained through structural-equation modeling contribute to entrepreneurship and financial-intermediary literature by describing an empirically-supported model demonstrating how business-cycles impact startup-valuations both directly and via multiple independent macro-level valuation channels.

Our paper develops as follows: section two examines literature exploring VC and startup-market impact of both country-level and macroeconomic factors, and their role in describing the determination of pre-money startup-valuations. Section three describes our dataset, as well as key-variables and empirical-approaches used to develop insight on the impact of macroeconomic and business-cycle market-conditions on startup-valuations. Section four describes empirical results of our baseline-scenario, OLS models and fixed-effects models used. Section five discusses key findings in detail, while section six outlines findings-implications, as well as conclusions and avenues for future research.

## 2 Literature Review

As demonstrated by several systematic literature reviews on pre-money startups valuations such as Kohn (2018), Wessendorf (2019), and Berre and Le Pendeven (2022), published papers in the field mostly investigate entrepreneurs, investors and deal-related factors on valuations, while macroeconomic determinants attract limited attention. In fact, the aforementioned authors describe that many papers who include macroeconomic drivers do so primarily as control variables. This means that few studies examine the role of macroeconomic market conditions in detail, thereby constituting a noticeable gap in the research. Rarer still, are studies that explore indirect effects on valuation within the entrepreneurial field.

The deterministic impact of macroeconomic and macrofinancial indicators in driving startup-investment is a long and storied idea within economic literature and can be traced to several authors, who established overall that VC markets behave as highly-procyclical financial intermediaries (Bygrave and Timmons, 1985; Korteweg and Sorensen, 2010).

### Macroeconomic Impact of Funding Availability: The VC Intermediary Role

Venture capital markets are financial intermediary markets which are driven by business-cycles and macroeconomic conditions, even as they drive startup-valuations. As early as Chan (1983), who proposes a theoretical model outlining that investment-allocation at the macro-level depends on the VC intermediary role to manage sector-specific information-asymmetries, the intermediary role of VC markets has been well-understood. Focusing on VC fund-availability, Gompers and Lerner (1998) employ a two-stage Heckman model, estimating probability that funds are raised, followed by the amounts of funds raised. They find that while firm-characteristics have strongest effect on fundraising, commitments to VC-funds are also directly impacted by GDP-growth-rates, while capital-gains taxes affect amounts raised, but not funding-probability. Stated otherwise, the impactof VC funding is influenced by external market-conditions, while VC fund-availability is driven by growth-rates.

Meanwhile, total value of stocks traded is one of the most significant determinants in explaining divergences of VC intensity, according to Bonini and Alkan (2009), who test impacts of GDP, inflation rates, real interest rates, total number of stocks traded, as well as corporate income tax-rates and business expenditures on R&D. Other key determinants are inflation rate and total entrepreneurial activity (Bonini and Alkan, 2009), meaning that VC markets may be driven by both macroeconomic factors and also startup-market activity.

Private equity activity is driven by institutional and legal environment, as well as economic activity, unemployment rate, equity market capitalization, and unit labor costs (Bernoth and Colavecchio, 2014). By using country-level fixed-effects and dividing their sample between Western-Europe and Eastern-Europe, they find that institutional and legal environment have substantial individual explanatory-power. Overall, it is intuitive that separately-examining Eastern and Western European -markets during periods of EU-enlargement find institutional and political variables, as well as inflation to be highly-deterministic on European private equity markets. In principle, this indicates that country-level variables influence the overall impact of private equity in an economy. Nevertheless, it should be noted that while private-equity-investment measured relative to GDP indicates investor-confidence, it might not necessarily indicate returns or valuations in these markets.

Concerning funding availability, inflows of capital into VC-funds increases the valuation of their investment-targets (Gompers and Lerner, 2000), and activities in private equity markets is highly deterministic in influencing startup-valuations (Inderst and Muller, 2004; Hellmann and Thiele, 2015). In addition to cash-on-market, Inderst and Muller (2004) make several key insights, describing endogeneity between VC funds-scarcity, entry-costs, and investment-profitability, theorizing that investment-profitability drives startup-valuation as well as VC market-entry. Statedotherwise, while cash-on-market drives startup-valuations, the relationship's functional form might be subject to endogeneity and indirect valuation-impacts. Essentially, further investigation into the specific nuance of the variability of valuation-impacts gives rise to further research and debate.

### Business Cycles

\(\mathrm{GDP}\)-growth and business-cycle dynamics are known to play roles in determining startup-valuation (Dieppe at al., 2017). For example, more and more-successful VC deals occur when Belgian economic growth is stronger (Heughchebart and Manigart, 2012). On a general level, Dicppe at al. (2017), a European Central Bank (ECB) study describing the ECB's global macroeconomic spillover-analysis model, describe financial-variables as key-determinants of domestic-output, with financial-spillover-transmission occurring via four channels: equity-prices, interbank-rate-spread, lending-tightness, and sovereign-risk-premium relationship. Lending-tightness in turn is driven by momentum and expected-GDP-growth. The intermediary-role played by lending-tightness, having deterministic-effect on the real-economy, while itself being impacted by key macroeconomic variables is informative to understanding structural relationships between macro-level variables and the real-economy.

Dees (2016), another ECB study uses a GVAR model-approach to describe transmission of financial-shocks to the real-economy, finds that financial-variable impact on the real-economy remains broadly-unchanged over time, as the business-cycle progresses. This finding of financial-variable impact-stability is informative to understanding structural relationships surrounding the impact on valuations.

Nevertheless, VC-financing markets are subject to large variations in capital-supply over the business-cycle, seeing large inflows from institutional-investors during boom-periods (Schwienbacher, 2013), while financial-integration drives business-cycle-synchronization via indirect-effects, by promoting trade-integration and economic structural-similarity, even as direct qualitative and quantitative financial-integration-effects indicate otherwise (Trancoso and Gomes, 2020). This study is highly-relevant due to its separation of direct and indirect impacts on business-cycles, demonstrating the inherent complexity of the relationship between business-cycles and the overall economic situation, demonstrating the possible need for a structural-equation-model approach.

Literature describing direct and indirect impacts on business-cycles, according to potentially-complex causal-architecture gives rise to the question of what exactly this architecture actually looks like. The relationship between direct and indirect determinants in this area is one seldom investigated.

### Macrofinancial Interaction Effects

Not only do macroeconomic and business-cycle indicators play a key deterministic role in startup markets, but also that interaction-effects between macroeconomic indicators and industry-level indicators also likely play a role, demonstrating that VC markets play a highly-variable financial intermediary role.

Popov (2009) corroborates this by focusing on the relationship between VC markets and firm-size, proposing a model which describes firm size as a product of industry-level firm-sensitivity to VC finance and to bank finance, as well as to VC market-size. This author highlights that industry-level sensitivity to VC markets drives firm-level employee size and establishes that relationships exist not only between financial-market-conditions and startups, but also that this relationship is industry-specific (ie, that this relationship is influenced by sectoral variables and is subject to multivariate functional-form).

Meanwhile, firm characteristics such as EBITDA are weighed differently from country to country (Lockett et al., 2002), while lower risk-free-rate drives overvaluation, while illiquidity premium reduces overvaluation, meaning fundamentally that valuation discount-factors are driven by overall cyclical and macrofinancial conditions (Gornall and Strebulaev, 2020). This demonstrates that the valuation-effect of DCF valuation-factors (i.e., revenues and discount-factors) are impacted by macroeconomic and cyclical market-conditions. This however raises question of specifically where and how these effects occur.

While the existing literature establishes the relationship between VC markets, inputs to startup-value (ic, firm and entrepreneur-characteristics) and startup valuations, is influenced by market-conditions via direct, indirect, and interactive influence from sectoral and macroeconomic conditions, whose functional form is complex and bears further investigation.

### Background and Research Hypotheses

Market-conditions are macro-level indicators, to sectoral and cyclical indicators. Hsu (2007), who uses year-dummies, observes that valuations tend to be higher when fund inflows are high, as well as Armstrong et al. (2006), who control for a benchmark financial-index, finding its valuation-impact positive and significant. In addition, interaction-effects between market-conditions and firm-characteristics can create additional valuation-synergies. Examples in literature include Gavious and Schwartz (2011), who find that the valuation-impact of a firm's balance sheet financials evolves along with the business-cycle, growing in importance during a post-bubble recession. In a similar vein, Gomers et al. (2008) find that interaction effects exist between sectoral market conditions and investor characteristics.

At a general level, startup-valuation may be driven by overall economic and cyclical activity. Several studies suggest this to be the case: for example, more and more-successful VC deals occur during boom periods (Heughebaert and Manigart, 2012). Moreover, business-cycle impacts on valuation (Fitza et al., 2004; Korteweg and Sorensen, 2010), while overall economic activity directly impacts private-equity activity's share of the macroeconomy (Bernoth and Colavecchio, 2014).

While there are several ways that business-cycles can directly impact valuation, both revenues and discount-factors (i.e., beta, country-risk-premium) are controlled for directly. Business-cycles might directly impact valuations due to potential future revenue-growth, industry-growth, or macroeconomic-growth, all of which may serve to attract investors, influencing both investor selection and startup-valuation (Wessendorf, 2019). Meanwhile, business-cycle growth can impact valuations by means of growth of business networks, partnerships, and relationships (Streletzki and Schulte, 2013). Alternatively, macroeconomic business-cycle conditions can also serve to inflate startup-valuations in the short-run during a boom, albeit on a short-lived based which may later be corrected, as described by Michel (2014). Thus, it can be expected that macroeconomic indicators drive not only overall activity but also valuations.

On the other hand, the valuation of startups can be driven by market-conditions more-specific to VC markets. Studies elaborate that not only does venture capital cash-on-market directly a priori influences pre-money valuations, as described by Inderst and Muller (2004), but also influences entrepreneur-effort, as described by Fulghieri and Sevilir (2009), which both increase valuations directly, and also serve as value-signal to investors. For European-market deals captured by our dataset, this can be tested by measuring the impact of business-cycles, macroeconomic indicators, and country-level VC-sector size on startup-valuations. This leads us to:

Hypothesis 1: Market Conditions. Macro-level conditions or financial-intermediary conditions

_H1a: The macro drives the market. Startup-valuations are driven by macroeconomic, macrofinancial, and macro-level indicators. Because are the basis for revenue and discount-rate projections, direct valuation-impacts exist._

_H1b: Startup-valuations are driven by \(VC\) asb-on-market. Domestic-asb-on-market impacts indicate relatively-insular \(VC\) markets. Global-asb-on-market impacts indicate cross-border valuation-effects._

Meanwhile, these conditions on VC markets may themselves be driven by the same business-cycle conditions impacting startup-valuations. Several studies describe that non-bank financial intermediary markets (which includes both VC markets and other investment markets) are influenced by business-cycles in a procyclical manner, with macroeconomic activity impacts overall private-equity activity, meaning that as a macroeconomy grows, investment in its emergent firms grows as well (Bernoth and Colavecchio, 2014).

Financial-spillover-transmission occurs via equity-prices, interbank-rate-spread, lending-tightness, and sovereign-risk-premium relationships. Fundamentally, this means that cash-on-market likely transmits financial spillovers of the business-cycle originating elsewhere in the wider macroeconomy (Dieppe at al., 2017). Meanwhile, lending is subject to macroeconomic-level variations driven by (macro-level) tail-risks (Chu and Zhang, 2022), while VC-financing markets are subject to substantial variations in capital-supply over the business-cycle (Schwienbacher, 2013). In conjunction with Dieppe at al. (2017), this means that VC markets function as a manifestation of financial-spillover-transmission channel, in line with equity-prices and lending-tightness. Because cash-on-market captures VC-sector size in a country, it bears testing whether it is deterministically-influenced by macroeconomic and business-cycle indicators, leading us to:

Hypothesis 2: The Financial Intermediaries Market. Cash-on-Market

\(H2\)_: Cash-on-market is driven by macroeconomic and sytical-indiators. Because direct valuation-impact of both cash-on-market and macrofinancial indicators exist, this may create a second-order valuation-impact effect._

In principle, while startup-valuations are known to be driven by revenue and by parseable risk-premiums (Damodaran, 2009), the _manner in which_ and _degree to which_ they impact startup-valuations can themselves be country or industry-specific (Damodaran, 2010), or else influenced by conditions in countries, cities, and industries. Specifically, the nature and scale of the impact of DCF valuation-factors can be influenced by macro-level market conditions, which might be either regulatory or macroeconomic in nature (Gompers and Lerner, 1998; Lockett et al., 2002; Bernoth and Colavecchio, 2014). Alternatively, they can be influenced by industry-level effects (Chan, 1983; Damodaran, 2009), Corroborating this, Manigart et al. (1997, 2000), identify that valuation-impact-differences between sectors, geographic settings, and investor-contexts. On the other hand,alternate views describe that national-level economic-effects can be driven by local-level, investor-side, or supply-chain effects (Porter, 1990). Combinations of these factors impacting the relationship between startup-valuation and valuation-drivers have also been observed for VCs across different countries focusing on fintech-industry startups.

In terms of functional-form, what this describes are divergences in the impact of DCF valuation factors across cities, countries, industries, and investors, or joint-combination thereof, which might be specific to those industries, cities, investors, and countries, or whose valuation-divergences might be driven by these differences. Functionally, industry fixed-effects can explain differences in valuations by capturing industry level business-relationships, business models and firm-survivability differences (Damodaran, 2009).

Meanwhile, country-level fixed effects may capture national-level differences not only in macroeconomic fundamentals, but also in governance and economic policy differences (Gompers and Lerner, 1998; Bernoth and Colavecchio, 2014). Governance and policy differences lead to divergences in valuation approaches and in relative-importance of valuation-drivers (Rojo-Ramirez, 2013). Lastly, city fixed-effects can capture economic clustering, as well as city-level investor and industry-concentration (Porter, 1990).

Fundamentally, since literature describes that impact of DCF valuation-factors can be influenced by country-level, industry-level or local-level dynamics, it is important to not only compare these, but also to examine the specific nature of the functional form by which each of these has their specific influence on the valuation-impact of the DCF valuation-factors. In principle, this can be measured by controlling for categoricals such as country, industry, and city, via fixed-effects, leading us to:

Hypothesis 3: Subsets Among Startups and VCs

_H3: The macroeconomic situation affects \(VC\) investors and startups in some subsets of the dataset more than others. Therefore, fixed-effects regressions may tell a dramatically different story than baseline macroeconomic and macro-level regressions._Concerning the influence of market-conditions on the valuation-impact of DCF-factors, an alternate approach to the functional-form question models indirect effects and relationships. The role of business-cycles - in particular booms -on the valuation impact of other variables, ranging from financial variables (as described by Gavious and Schwartz, 2011) to reputational costs (as described by Schwienbacher, 2013), indicate clearly that business-cycle has valuation-impacts have not only direct, but indirect valuation-impact as well, with business-cycle influencing intermediate valuation-factors such as VC-industry variables, country-risk-premiums, and macroeconomic determinants to further influence valuation.

Our study is far from the first to model indirect effects. Empirical literature outlines that formal entrepreneurship is driven by availability of economic opportunities, which is in-turn driven by macro-level resource-availability (Thai and Turkina, 2014), while financial-variables act as key-determinants of domestic-output, with financial-spillover-transmission occurring via four channels, equity-prices, interbank-rate-spread, lending-tightness, and sovereign-risk-premium relationship, with lending-tightness in turn being driven by momentum and expected-GDP-growth (Dieppe at al., 2017). In principle, the overall relationship between startups, macroeconomic-cycles, and intermediary financial valuation-impact channels likely follows a similar pattern.

This pattern is explored by Dees (2016), using a GVAR model-approach to capture the relationship between valuations and intermediate variables, which might indicate endogenous fully or partially-circular causal-relationships. A similar pattern is corroborated by Trancoso and Gomes (2020), who examine direct and indirect-effects linking financial-indicators and business-cycle synchronization, affirms that structural-equation-model approaches are particularly well-suited to examinations of business-cycle dynamics and relationships. Additionally, beyond capturing indirect effects, SEM-approaches facilitate capture of endogenous fully or partially-circular relationships among dependent, independent, and mediating-variables.

Essentially, a group of studies lead us conclude that indirect-effects between valuations, intermediate-variables and wider macro-cyclical conditions can be captured by multistage econometric models (Thai and Turkina, 2014; Dees, 2016; Trancoso and Gomes, 2020). What remains to be seen is the precise shape and architecture of the direct and indirect relationship, as well as whether any parts of the relationship-architecture are endogenous in nature. In principle, relationship-architecture shape can be tested via structural-equation model techniques, so that the specific structure of indirect-effects can be modelled in detail, leading us to:

Hypothesis 4: Direct and Indirect Effects. Structure and Functional Form

_H4a: Business-cycles and financial-intermediary market-conditions impact startup-valuations directly and independently of one-another._

_H4b: Business-cycle-inputs on startup-valuations are non-circular full or partial-mediation effects, impacting valuations both directly (in the case of partial-mediation), and via other market conditions._

_H4c: Business-cycle-inputs on startup-valuations are circular full or partial-mediation effects, impacting startup-valuations with an endogenous circular relationship between mediating financial-market conditions and startup-valuations._

## 3 Data and Methodology

In this section, we outline key modelling approaches that are used to capture and describe indirect and contextual-effects the literature describes market conditions as having on valuation-impact of the DCF-related valuation-drivers. While literature describes indirect and contextual impact on the effect of these valuation-determinants, the specific nature of the relationship has remained a matter of debate.

### Scorecard-Based Valuation

Pre-money startup-valuations are prices (or prices of their shares) paid by equity investors for early-stage investments (Cumming and Dai, 2010). Scorecard-valuation methods are modular and relatively straightforward valuation-approaches based on summation of key characteristics, market conditions, and deal-conditions developed mainly by industry practitioners. Meanwhile, in the economic literature, this same concept appears as summation-based valuation models (Hand, 2005; Sievers et al., 2013). In principle, scorecard approaches can model indirect valuation-influences in several ways, as well as incorporating non-financial and deal-characteristics prevalent in a given market or subset thereof.

### Startup-Valuation Meta-Model

Berre and Le Pendeven (2022) develop a model outlining the contextually-adjusted startup-valuation-process, assigning factors to appropriate process-chronological-positions. Essentially, startup-value-inputs navigate external market-conditions as part of the valuation-forming process. This implies both direct-effects and interaction-effects of market-conditions on startup-valuation.

\[\textbf{{Pre - Money Valuation}}=\textbf{{f}}((\sum\textbf{{startup Value}})\sum\textbf{{beat Value}})\sum\textbf{{beat Valuation}})\]

In order to approach a clear view on the explanatory power and valuation-impact of macroeconomic factors and macro-financial factors in the startup ecosystem, factors used in classical firm valuation models - in particular, DCF-related factors -should be included empirical models. The inclusion of classical factors serves two purposes. First, their inclusion can be used to test and establish the conceptual and theoretical soundness of our dataset. Second, inclusion of classical valuation-factors serves as key control factor that need to be taken into account, in order to isolate macroeconomic and macro-financial effects.

Subsequently, our empirical approach focuses on the examination of the startup valuation-impact of key macroeconomic and macrofinancial factors, including both indicators and policy factors. These include macroeconomic output-gap, macro-level tax-rates, and total cash-on-market levels available both domestically and on the world VC market.

### Structural-Equation-Model-Approach

Scorecard-valuation functional form notwithstanding, accurate-measurement of valuation-impacts of market-conditions face two principal modeling-obstacles: endogeneity and indirect-effects (e.g. partial and full-mediation-effects). In order to address these obstacles, we employ partial-least-squares structural-equation modeling (SEM), an approach which has several relevant advantages given the context examined. Adopting an SEM approach allows us to analyze complex indirect-relationships (Gefen et al., 2000, 2011), which feature both direct and indirect-effects (Little et al., 2007), and which are appropriate for exploratory theory-building and prediction. As a nonparametric estimation-technique (Wold, 1982), this approach provides an iterative combination of empirical-analyses that relates measures to constructs and a path analysis that captures the structural model represents the direct and indirect relationships among key valuation-drivers.

### Indirect-Effects

Business-cycle impact on startup-valuation is as likely to be indirect, acting via effects on financing-costs and conditions, as it is direct, acting directly on firm-revenues, business-opportunities, local-market-demand, and firm-level asset-values, all of which tie the firm's fortunes directly to the business-cycle.

Structural-equation-model-approaches allow simultaneous measurement of direct and indirect-effects, including full, partial, and inconsistent mediation, as well as latent and unobserved variables, while observed relationships might be part of a complex, qualified relationship-system (Little et al., 2007). Structural-equation-model-approaches are particularly well-suited to investigating business-cycle-effects, dynamics, and drivers (Trancoso and Gomes, 2020).

### Endogeneity

Wooldridge (2010) outlines that in principle, endogeneity arises due to one of three causes; omitted-variable-bias, simultaneity, or measurement-error. In principle, endogeneity-testing can indicatewhether the causal-relationship is either more-complex than detected at-first-glance, or whether the causal relationship is influenced by either additional explanatory-variables or measurement-error.

While directly-circular endogenous relationships between business-cycle and startup-valuation are unlikely, given a dataset dominated by startups in large, historically-established European economies, relationships between business-cycles, cash-on-market, and startup-valuation may give rise to circular cash-on-market-relationships whereby business-cycles and cash-on-market may be endogenously-related. Additionally, cash-on-market might be endogenously-related to valuation.

Alternately, endogeneity might be driven by hidden-variable-bias (Wooldridge, 2010), which might be found acting upon the model's dependent-variables, its explanatory-variables, or both. While use of two-stage-least-squares is a well-established model-approach in accounting for endogeneity, selection of the variable, as well as relationships with both dependent-variables and other explanatory-variables must be given careful consideration.

Addressing these concerns, structural-equation models are proposed in Figure 1. In principle, two-Stage least squares regression analysis, used in the analysis of structural equations (Gefen et al., 2011), is essentially an extension of the OLS method, useful when the dependent-variable's error terms are correlated with the independent-variables (Wooldridge, 2010).

In Figure 1, valuation-impact of direct business-cycle effects, as well as indirect-effects via financing-conditions are modeled. Panel A describes the business-cycle-valuation relationship as a non-circular relationship subject to partial-mediation via financing conditions, while Panel B describes the business-cycle-valuation relationship subject to partial-mediation via financing conditions and with endogenous relationships between business-cycle and cash-on-market and between valuation and cash-on-market.

### Equation Structure

In terms of equation-structure, Figure 1A describes a two-tiered structural-equation model subject to partial-mediation involving both country-risk-premium and cash-on-market as mediating-variables, as follows:

\[[1]\,Cash-on-Market_{t}=\sum_{t=1}^{T}\beta_{it}(Output\,Gap_{t})+\sum_{t=1}^{T} \beta_{it}(Credit-Risk-Premium_{t})+\varepsilon_{it}\]

\[[2]\,Valuation_{t}=\sum_{t=1}^{T}\beta_{it}(Reverune_{t})+\sum_{t=1}^{T}\beta_{it }(Sectoral-Risk-Beta_{t})+\sum_{t=1}^{T}\beta_{it}(Credit-Risk-Premium_{t})+ \varepsilon_{it}\]

While circular-relationships between business-cycle indicators and cash-on-market might be possible in principle, they are both unlikely given the composition of our dataset (i.e., deals in established and highly-industrial \(\mathrm{EEA}\) markets, whose VC markets are comparatively smaller as a share of GDP, and whose business-cycles are often driven by European-level cyclical transmission channels (Weyerstrass et al., 2006), and difficult-to-measure, given the need for an instrumental-

Figure 1: Structural-Equation-Model \(Valuation-Relationhip Path-Diagram: Non-Granular and Circular Modelsvariable which would impact business-cycles but not cash-on-market. On the other hand, partial-endogeneity, involving an endogenous relationship between Valuation and Cash-on-Market, is both measurable and supported by economic theory. In terms of equation-structure, Figure 1B describes a partially-circular relationship, featuring an endogenous relationship between cash-on-market and contemporaneous-endogeneity of startup-valuation, as follows:

\[[1]\,Cash-on-Market_{t}=\sum_{t=1}^{T}\beta_{it}(Output\,Gap_{t})+\sum_{t=1}^{T} \beta_{it}(Valuation_{t})+\sum_{t=1}^{T}\beta_{it}(Credit-Risk-Premium_{t})+ \varepsilon_{it}\]

\[[2]\,Valuation_{t}=\sum_{t=1}^{T}\beta_{it}(Revenue_{t})+\sum_{t=1}^{T}\beta_{it }(Sectoral-Risk-Beta\,\iota)+\sum_{t=1}^{T}\beta_{it}(Credit-Risk-Premium_{t})+ \varepsilon_{it}\]

### Dataset

The first piece of the dataset consists of proprietary VC deal-data shared by Early Metrics, a Paris-based startup ratings and research agency (\(80\) observations). To this, we add EU-and \(\mathrm{EEA}\)-located startup-deals drawn from EIKON and Crunchbase (for the valuation disclosed deals, respectively \(397\) and \(614\) observations). These supplementary sources were chosen due to their content-similarity to Early Metrics data and regular use in entrepreneurial finance researches. To further enrich the dataset, each deal was cross-referenced with firm-performance, industry-level, municipal, and national-level macroeconomic data, and including both proprietary, and commercially-available data, while also boasting extensive variety of value-adding categorical-variables. While our categorical-variables have substantial explanatory-power in their own right, they also add value by virtue of their interaction with both firm-characteristics, as well as macroeconomic and business-cycle market-conditions that are this study's focus.

Selection of European data gives our study numerous strengths, ranging from institutional and macroeconomic diversity sufficient for meaningful geographic fixed-effects to market-examination taking into taking into account of distinct contextual and geographic factors.

Because each line within our dataset is specific per-investor-per-dcal, deals with multiple investors occupy multiple lines within the dataset, identifying data for startup and investor. Since a startup can have several investors, it can have multiple observations in the regression analysis, reflecting each unique investor-startup pair. This structure is borrowed from Masulis and Nahata (2009).

With 1,089 observations representing 1,042 deals across 673 startups ranging from Q1-2000 to Q1-2020, our dataset-size is substantial, although only 582 observations contain firm-level revenue figures. Nevertheless, this yields regressions with substantial degrees of freedom compared to prominent studies in the entrepreneurial finance and startup field, such as Masulis and Nahata (2009), Greenberg (2013), and Gompers et al. (2020), who examine 273, 317, and 444 observations respectively.

### Dependent Variable

The primary dependent variable used in this study is pre-money startup-valuation. This reflects the product of share price before a funding round multiplied by the number of outstanding startup shares. Since the dataset is drawn from EU and EEA data, valuations are expressed in EUR. Data drawn from outside the Eurozone, such as from the UK, Poland, Norway, Sweden, and Switzerland were converted into EUR. Table 1b outlines the summary statistics of our pre-money valuations data. While the data's time and sectoral distribution is somewhat uneven, it does cover several major events, including the end of the dotcom bubble, the Eurozone crisis, and the start of the Covid-19 Pandemic.

### Independent Variables: Macroeconomic and Macrofinancial Market-Conditions

In line with Gompers and Lerner (1998) and Bonini and Alkan (2006), which find valuations to be driven by macroeconomic indicators, cyclical indicators and tax-rates, this study's macroeconomic data also consist of country-risk-premiums, cyclical indicators and tax-rates. While GDP growth would hypothetically constitute a viable way to keep track of business-cycle conditions, our dataset, which consists mainly of recessionary-period data (which features positive, but below-trend GDP-growth figures, as well as having smaller deterministic effect during booms than during recessions), needs cyclical-contextualization in order to be a reliable explanatory variable. Therefore, we select macroeconomic output-gap, which is drawn from OECD figures as our primary macroeconomic market-condition indicator. Additionally, at the macroeconomic level, we include an IMF tax-rate figure, tax revenue as a share of GDP, as well as country-risk-premium, drawn from the NYU-Stern database. Because country-risk-premiums are core-components of risk-adjusted discount-rates (Damodaran, 2009), they are also included in the baseline-scenario, which is driven by discounted-cashflow valuation models.

To this, we add total VC market-size available at both country level and on global markets, which Inderst and Muller (2004) describe as being a key determinant of startup valuations, as well as dry powder, both of which may act as intermediate variables in the valuation process. The former are drawn from OECD annual data on total VC investments per country, Meanwhile, the latter are drawn from Invest Europe, which provides annual dry-powder figures for six multi-country regions in Europe. Subsequently, national-level annual dry-power figures are estimated on the basis on each country's fraction of total VC investments in that region.

As an alternative to capturing business-cycle with macroeconomic output-gap, we also use Eurozone Growth Cycle Coincident Indicator (GCCI) as a robustness-check, whose results are outlined in Appendix III.

### Valuation-Driver Interaction

In addition to direct valuation-impacts of DCF-related valuation-factors, as well as macro-level drivers on startup-valuation, impacts those variables have on one-another demand consideration.

The overall impact of economic-indicators can vary in as business-cycles progress (Blanchard and Leigh, 2013). Notable examples of these sorts of impacts existing within published entrepreneurial finance literature include Gompers et al. (2010), which find interaction effects between investor-experience and macroeconomic indicators, as well as Gavious and Schwarz (2011), who find evidence of interaction-effects between business-cycle and a startup's firm characteristics.

This means regressions including interaction-effects are justified by both theory and existing literature. To this end, interaction variables have been established for the potential interaction of each of the DCF-related variables with cash-on-market, and business-cycle.

### Baseline Model: Control Scenario

Classically, depending on the valuation-approach, valuations are driven by firm-performance and revenue indicators, such as sales revenue, net income, cash flow from operations, EBIT or EBITDA, discounted by risk-factors such as industry-risk-premiums, country-risk-premiums, WACC, and CAPM-betas, as per DCF models, contextualized by balance sheet or income statement figures, as per multiples valuation models, and moderated by growth-rates such as in the Gordon growth model (Damodaran, 2005; 2009; 2010).

Functionally, the DCF-approach can be approximated using OLS-regressions by regressing valuation against revenue indicators, as well as DCF discount-factors, such as sector-level unlevered-beta, and country-risk-premium. Fundamentally, because Damodaran holds that existing valuation approaches either apply DCF directly, or else borrow from DCF assessments caried out by others (Damodaran, 2005; 2009; 2010), as with relative and multiples valuation approaches, valuation-impact of DCF valuation-determinants need to be controlled-for, both as a means of establishing the theoretical-consistency of the dataset, as well as to determine the concrete value-added of non-DCF valuation factors such as macroeconomic market conditions, financial-intermediaries market conditions, and business-cycle conditions.

While startup revenues are included in the Early Metrics deals dataset, as well as a minority of deals drawn from EIKON, additional revenue figures were drawn Dun and Bradstreet as well as Zoominfo, thereby filling-in revenue figures for approximately half of the dataset.

Sectoral unlevered-beta, an industry-level measure of systemic-risk, is drawn from Damodaran's NYU-Stern dataset, and communicates industry-level sensitivity to financial-market benchmark-volatility. These figures are used by Damodaran (2009), as inputs for risk-adjusted discount-rates used in DCF-based valuation-models.

_Country-risk-Premium_ is drawn from Damodaran's NYU-Stern dataset's Country Default-Spreads and Risk-Premiums page, which was accessed on 31 January 2021. While this, in principle represents sovereign bond ratings and appropriate default spreads for different countries, these figures are used by Damodaran (2009), as inputs for risk-adjusted discount-rates used in DCF-based valuation-models.

While DCF-related valuation-factors are used to construct DCF-based regressions to test dataset-soundness, for subsequent regression-analysis, DCF-related regression-variables also serve as control-variables.

### Categorical Variables and Fixed-Effects

In addition to DCF-related control-variables and macroeconomic and macrofinancial variables, several categorical variables may also have deterministic effect on startup valuations. Furthermore, it is likely that at least some of these variables may also serve to modulate the valuation-impact of both macro-level variables and DCF-linked control variables.

Specifically, the nature and scale of the impact of DCF valuation-factors can be influenced by macro-level market conditions, which might be either regulatory or macroeconomic in nature (Gompers and Lerner, 1998; Lockett et al., 2002; Bernoth and Colavecchio, 2014), or by industry-level effects (Chan, 1983; Manigart et al., 1997, 2000; Damodaran, 2009), or by local-level, investor-side, or supply-chain effects (Porter, 1990). Additionally, combinations of these factors impacting the relationship between startup-valuation and valuation-drivers have also been observed for VCs across different countries focusing on fintech-industry startups. Therefore, their inclusion is justified. These include firm, industry, country, city, year, and investor-type drawn primarily from EIKON deals data, as well as from secondary sources such as UK Companics House, which corroborates UK firm-level data, while also contributing geographic data to a substantial level of detail.

[MISSING_PAGE_FAIL:26]

[MISSING_PAGE_FAIL:27]

Examination of direct-effects on valuation also demands examination of business-cycle-interaction-effects. Table 4 examines interaction-effects between DCF-factors and macroeconomic factors on valuation.

Panel A examines DCF-output-gap interaction-effects in addition to output-gap, demonstrating output-gaps to have significant interaction-effects on risk-adjusted financing costs, acting on both country-risk-premium and sectoral-beta. Panel B, which includes DCF-dry-powder interaction effects, finds that dry powder only has (very slight) interaction-effects with country-risk-premium. Meanwhile, Panel C examines DCF-cash-on-market interaction-effects, demonstrating cash-on-market to mainly have interaction-effects with country-risk-premium. This indicates that cash-on-market likely plays a larger role in determining country-risk-premium's impact on startup-valuation. Meanwhile, Panel D demonstrates interaction-effects of world-cash-on-market to be negligible. This means that interaction-effects are driven by domestic economic-trends rather than by international ones.

[MISSING_PAGE_EMPTY:29]

These findings demonstrate evidence confirming the direct-effects on startup-valuations outlined by Hypothesis 1a and 1b. Goodness-of-fit figures outlined in Tables 3 and 4 demonstrate substantial increases in goodness-of-fit, which can be taken as evidence of direct-effect valuation-impacts.

### Cash-on-Market

In addition to the valuation-impact of drivers on startups, business-cycle might also drive cash-on-market. Because cash-on-market demonstrably plays a deterministic role in pre-money startup valuation, impacts macro-level on cash-on-market can be considered _second-order effects_.

Table 5 examines impacts of macro-level factors on domestic cash-on-market, with Panel A examining univariate-regressions and Panel B multivariate-regressions. Overall, goodness-of-fit indicators demonstrate that output-gap and world cash-on-market have the strongest explanatory power. This is followed by country-risk-premium. Both tax rates and Country-risk-Premiums have negative impacts on domestic cash-on-market, in line with economic theory.

Panel B regressions combining these drivers indicate that while business-cycle and funding-costs drive domestic-cash-on-market, inclusion of world cash-on-market more than doubles the regression's goodness-of-fit, indicating strong evidence of cross-border impact on cash-on-market.

Tuple 16:
Cleaned Title: software engineering knowledge area startup company mapping study
Cleaned Transcription: software engineering knowledge area startup company mapping study eriks klotins blekinge institute technology se karlskrona sweden michael unterkalmsteiner blekinge institute technology se karlskrona sweden tony gorschek blekinge institute technology se karlskrona sweden footnote email eriksklotins michaelunterkalmsteiner tonygorschekbthse abstract background startup company becoming important supplier innovative software intensive product failure rate among startup high due lack resource immaturity multiple influence dynamic technology however software product engineering core activity startup therefore inadequacy applied engineering practice might significant contributing factor high failure rate aim study identifies categorizes software engineering knowledge area utilized startup map stateofart identifying gap research method perform systematic literature mapping study applying snowball sampling identify relevant primary study result identified practice study although main knowledge area swebok covered large part category conclusion existing research provide reliable support software engineering phase startup life cycle transfer result startup difficult due low rigor current study keywords startup software engineering mapping engineering practice agile lean small company development software intensive product introduction recent development technology created increasing demand innovative software product startup company addressing need gain importance supplier softwareintensive product innovation inherent nature software enables small company produce launch software product fast resource however startup company fail realizing significant achievement partially due market factor financial issue however impact software product engineering inadequacy applied engineering practice fully explored might significant contributing factor high failure rate chorev et al identify key factor successful startup political economical environment marketing idea funding product development among others many author address general issue startup focus software engineering done startup yau et al argue scaled engineering practice solve problem present larger established company ignoring specific challenge emerge startup companiesstating different approach altogether needed software engineering context startup paper aim identifying softwareintensive product engineering practice utilized startup company mapping software engineering body knowledge swebok knowledge area category describing stateofthe art gap research startup software engineering furthermore analyze identified software engineering knowledge area support startup life cycle use four phase model proposed crowne map identified knowledge area different phase startup lifecycle use wellestablished taxonomy show stateoftheart expose gap research clear distinct focus software engineering perspective paper structured follows section give overview field motivates study section detail research methodology applied identify map relevant paper section report result mapping section answer research question discus result section concludes paper background related work startup company share many feature small medium enterprise youth market pressure dynamic technology however startup different due aim challenge face contrast established company regardless size focus optimizing existing business model startup focus finding one sutton defines startup organization challenged youth immaturity extremely limited resource multiple influence dynamic technology market crowne proposed four phase startup lifecycle model successfully transferring first phase last indicates startup become established company model identifies distinct challenge phase startup must address advance next stage seek identify knowledge area supporting transfer trough startup life cycle addressing challenge identified crowne paternoster et al conducted mapping study characterize stateof theart research startup conclude minority study area dedicated software engineering since gap first identified partially filled coleman et al conducted grounded theory study explore software process formed startup study concludes enough resource explore best way develop software startup use whatever software process support immediate business objective consequently development process heavily influenced previous experience person acting development manager pino et al conducted systematic review software process improvement spi small medium organization study aimed discovering approach spi smallmedium company exist although study aimed startup organization conclude prescriptive approach cmm spice suitable small organization therefore emphasize need lightweight tailored approach several startup specific process model addressed need example lipe address immaturity adhoc approach scalability engineering process essdm proposes iterative approach build validate multiple product idea simultaneously helical model support innovation experimentation multiple product idea frequent release synchronization organizational process software engineering body knowledge swebok characterizes content software engineering discipline promotes consistent view software engineering swebok organized main knowledge area knowledge area organized subcategories although swebok specifically aimed startup widely recognized within software engineering community understand degree research support software engineering startup useful map existing study one recent contribution mapping study paternoster et al describing research startup providing characterization software development startup context however work classify identified work practice understood software engineering problem actually addressed contrast study aim identifying classifying software engineering knowledge area startup company enabling analysis improvement existing practice b revealing opportunity investigation research methodology mapping process consists three activity identification relevant publication data extraction data mapping identify relevant publication emerging systematic literature review method snowball sampling data mapping follow recommendation petersen et al research question study driven goal understand extent engineering startup company supported research pursue goal seek answer following research question rq stateofpractice term utilization software engineering knowledge area startup rq relevance rigor study reporting experience software engineering startup order structure identified practice knowledge area well identify gap knowledge rq use swebok software engineering dictionary although swebok created startup lack alternative swebok considered accepted se subject area overview provide account whether practice transferred industry rq ass rigor relevance identified study mapping study design overview identification primary study used snowball sampling defining starting set earlier broader mapping study startup performed forward snowball sampling starting set earlier paper likely covered previous study paternoster et al screened sampled paper select study report primary research focused software engineering practice startup first paper applied sanity check filtering duplicate nonenglish nonpeerreviewed paper used title abstract screening ambiguous case read full text screening criterion summarized table used google scholar identify referencing paper ie perform forward snowball sampling first author performed screening paper result process organized spreadsheet reviewed second third author data extraction post identification relevant study data extraction performed primary goal extract information indicating knowledge area explored study also extracted information pertaining rigor context description description study design validity discussion relevance information subject study context scale research method according assessment method ivarsson et al analysis answer first research question rq stateofpractice term utilization software engineering knowledge area startup map extracted practice swebok knowledge area category
Original Title: Software Engineering Knowledge Areas in Startup Companies: A Mapping
  Study
Original Transcription: # Software Engineering Knowledge Areas in Startup Companies: a mapping study

Eriks Klotins

Blekinge Institute of Technology, SE-37179, Karlskrona, Sweden

1

Michael Unterkalmsteiner

Blekinge Institute of Technology, SE-37179, Karlskrona, Sweden

1

Tony Gorschek

Blekinge Institute of Technology, SE-37179, Karlskrona, Sweden

1

Footnote 1: email: {eriks.klotins, michael.unterkalmsteiner, tony.gorschek}@bth.se

###### Abstract

_Background_ - Startup companies are becoming important suppliers of innovative and software intensive products. The failure rate among startups is high due to lack of resources, immaturity, multiple influences and dynamic technologies. However, software product engineering is the core activity in startups, therefore inadequacies in applied engineering practices might be a significant contributing factor for high failure rates. _Aim_ - This study identifies and categorizes software engineering knowledge areas utilized in startups to map out the state-of-art, identifying gaps for further research. _Method_ - We perform a systematic literature mapping study, applying snowball sampling to identify relevant primary studies. _Results_ - We have identified 54 practices from 14 studies. Although 11 of 15 main knowledge areas from SWEBOK are covered, a large part of categories is not. _Conclusions_ - Existing research does not provide reliable support for software engineering in any phase of a startup life cycle. Transfer of results to other startups is difficult due to low rigor in current studies.

**Keywords:** Startup, software engineering, mapping, engineering practice, agile, lean, small companies, development of software intensive products

## 1 Introduction

Recent developments in technologies have created an increasing demand for innovative software products. Startup companies are addressing this need and gain importance as suppliers of software-intensive products and innovation. The inherent nature of software enables small companies to produce and launch software products fast with few resources. However, most of startup companies fail before realizing any significant achievements [11]. Partially this is due to market factors or financial issues, however the impact of software product engineering and inadequacies in applied engineering practices is not fully explored, and might be a significant contributing factor for the high failure rates.

Chorev et al. [8] identify 16 key factors for a successful startup, such as political and economical environment, marketing, idea, funding and product development among others. Many authors [2, 3, 8, 12, 26, 41] address general issues of startups. Only a few focus on how software engineering is done in startups. Yau et al. argue that scaled down engineering practices solve problems present in larger, established companies while ignoring specific challenges that emerge only in startup companies,stating that different approaches altogether are needed for software engineering in the context of startups [20].

In this paper we aim at identifying software-intensive product engineering practices utilized in startup companies and mapping them to Software Engineering Body of Knowledge (SWEBOK) [31] knowledge areas and categories, describing both state-of-the art, and gaps in research on startup software engineering. Furthermore, to analyze how identified software engineering knowledge areas support the startup life cycle we use the four phase model proposed by Crowne [11] and map identified knowledge areas to different phases in the startup life-cycle. By use of these well-established taxonomies [2], [10] we show state-of-the-art and expose gaps for further research, but with a clear and distinct focus on the software engineering perspective.

This paper is structured as follows. Section 2 gives an overview of the field and motivates the study. Section 3 details the research methodology we applied to identify and map relevant papers. Section 4 reports results from the mapping. Section 5 answers the research questions and discusses the results. Section 6 concludes the paper.

## 2 Background and related work

A startup company shares many features with small or medium enterprises such as youth, market pressure and dynamic technologies [33]. However startups are different due to their aim and the challenges they face [33]. In contrast to established companies, who regardless of their size focus on optimizing an existing business model, startups focus of finding one [26]. Sutton [33] defines a startup as an organization that is challenged by youth and immaturity, extremely limited resources, multiple influences and dynamic technologies and markets.

Crowne [11] had proposed a four phase start-up life-cycle model. Successfully transferring from first phase to the last indicates that a startup has become an established company. The model identifies distinct challenges at each phase that a start-up must address to advance to the next stage. We seek to identify knowledge areas supporting transfer trough start-up life cycle by addressing challenges identified by Crowne [11].

Paternoster et al. [23] conducted a mapping study to characterize state-of the-art research in startups. They conclude that only a minority of studies in the area are dedicated to (software) engineering, and since 2000 when this gap was first identified [33] it has been only partially filled.

Coleman et al. [9] conducted a grounded theory study to explore how software processes are formed in a startup. This study concludes that there is not enough resources to explore the best way to develop the software and startups use whatever software process that supports their immediate business objective. Consequently, the development process is heavily influenced by previous experiences of a person acting as development manager [9].

Pino et al. [25] conducted a systematic review on software process improvement (SPI) in small and medium organizations. The study is aimed at discovering what approaches to SPI in small-medium companies exist. Although their study was not aimed at startup organizations, they conclude that prescriptive approaches, such as CMM and SPICE, are not suitable for small organizations. Therefore, they emphasize the need for more lightweight and tailored approaches.

Several startup specific process models have addressed this need. For example, LIPE [40] addresses immaturity, ad-hoc approaches and scalability of engineering processes. ESSDM [4] proposes an iterative approach to build and validate multiple product ideas simultaneously. The Helical model [13] supports innovation by experimentation of multiple product ideas, frequent releases and synchronization with other organizational processes.

Software Engineering Body of Knowledge (SWEBOK) characterizes content of software engineering discipline and promotes consistent view to software engineering. SWEBOK is organized in 15 main knowledge areas; each knowledge area is organized in sub-categories. Although, SWEBOK is not specifically aimed at startups it is widely recognized within software engineering community [31].

To understand the degree to which research supports software engineering in startups, it is useful to map existing studies. One recent contribution is the mapping study by Paternoster et al. [23], describing research on startups and providing a characterization of software development in the startup context. However, their work does not classify the identified work practices such that it can be understood what software engineering problem is actually addressed. In contrast, our study aims at identifying and classifying software engineering knowledge areas in startup companies, enabling a) analysis and improvement of existing practices and b) revealing opportunities for further investigation.

## 3 Research methodology

The mapping process consists of three activities: identification of relevant publications, data extraction, and data mapping. We identify relevant publications by an emerging systematic literature review method - snowball sampling [38]. For data mapping we follow the recommendations by Petersen et al. [24].

### Research questions

Our study is driven by the goal to understand to what extent engineering in startup companies is supported by research. To pursue this goal we seek answers to the following research questions:

**RQ1:** What is state-of-practice in terms of utilization of software engineering knowledge areas in startups?

**RQ2:** What is the relevance and rigor of the studies reporting experiences from software engineering in startups?

In order to structure the identified practices into knowledge areas, as well as identify gaps in knowledge (RQ1) we use SWEBOK [31] as a software engineering dictionary. Although SWEBOK was not created for startups, we lack alternatives, and SWEBOK is considered the accepted SE subject area overview [6, 28]. To provide an account whether the practices can be transferred to industry (RQ2) we assess rigor and relevance [17] of the identified studies.

### Mapping study design overview

**Identification of primary studies:** We used snowball sampling [38], defining the starting set from an earlier and broader mapping study on startups [23]. We performed only forward snowball sampling from the starting set, as earlier papers are likely to be covered by the previous study by Paternoster et al. [23].

We screened the sampled papers to select studies that report on primary research focused on software engineering practices in startups. At first, for each paper we applied a sanity check filtering out duplicates, non-English and non-peer-reviewed papers. We used titles and abstracts for screening; in ambiguous cases, we read the full text. The screening criteria are summarized in table 1.

We used Google Scholar to identify referencing papers, i.e. to perform forward snowball sampling. The first author performed the screening of papers. Results of the process were organized in a spreadsheet that was reviewed by the second and third author.

**Data extraction:** Post identification of relevant studies data extraction was performed with the primary goal to extract information indicating which knowledge areas are explored in the study. We also extracted information pertaining to rigor - context description, description of study design, validity discussion, and relevance - information on subjects, study context, scale and research method according to the assessment method by Ivarsson et al. [17].

### Analysis

To answer our first research question (RQ1: What is state-of-practice in terms of utilization of software engineering knowledge areas in startups?) we map the extracted practices to SWEBOK [31] knowledge areas and categories. In the

Tuple 17:
Cleaned Title: software startup practice software development startup lens essence theory software engineering
Cleaned Transcription: preprint article published proceeding profes productfocused software process improvement final authenticated version available online httpsdoiorghttpsdoiorg article title software startup practice software development startup lens essence theory software engineering author kaikristian kemell ville ravaska anh nguyenduc pekka abrahamsson year please cite original version citing article kemell kk ravaska v nguyenduc abrahamsson p software startup practice software development startup lens essence theory software engineering morisio torchiano jeditschka ed productfocused software process improvement profes lecture note computer science vol springer cham httpsdoiorghttpsdoiorgsoftware startup practice software development startup lens essence theory software engineering kaikristian kemell university jyvaskyla jyvaskyla finland university jyvaskyla jyvaskyla finland university southeast norway norway kaikristianokemelljvufi ville ravaska missingpagepost se practice software startup still scarce study software development software startup general still needed highprofile practice utilized startup five why commonly discussed eg startup education systematic study topic lacking thus better understand software development software startup might differ software development mature software organization study practice paper specifically seek understand practice commonly used software startup rq addition approach topic lens essence theory software engineering seek understand theory fit context software startup end study seven alpha theory discus second section suited context software startup whether alpha would needed make theory better suited startup context rq background software startup software development practice essence theory software engineering section split three subsection first briefly discus software startup relation software development define refer software development practice software development software startup typically software startup strictly follow formal software development method instead combine practice different method suit need moment simply use ad hoc practice aim study uncover software development practice universal software startup notable study dande et al dande et al studied software startup finland switzerland devised list practice commonly utilized software startup however practice solely software development one also include practice related customer business kamulegeya et al studied practice reported seemed apply ugandan startup context well providing validity practice however add consider listed practice universal might vary different location culture study focusing practice aimed create extensive list practice nonetheless studied software startup practice different context klotins unterkalmsteiner gorschek example created framework categorizing software startup practice differs one proposed dande et al giardino et al propose greenfield startup model explain software development earlystage software startup process uncovered various practice supplement confirm finding dande et al paternoster et al study software startup develop software discus found practice however listed paper nonetheless finding lend support dande et al software development practice jacobson et al suggest set practice form method context se method according describe waysofworking ie work carried whether formal se method employed wayofworking exists form informal method could nonetheless described necessary logic practice atomic unit describe work carried historically academic literature particularly information system construct technique used purpose context method engineering tolvanen definesa technique set step rule define representation information system derived handled using conceptual structure related notation tool context refers computerbased application supporting use technique essence theory software engineering essence theory software engineering provides way describing method practice consists notational language used achieve well socalled kernel includes building block one use basis constructing method kernel author argue contains basic element universal se project essence kernel contains three type object alpha ie thing work activity ie thing competency skill required carry work study focus alpha context software startup seven essence alpha follows stakeholder opportunity requirement software system team way working work alpha split three area concern first two belong customer area concern number three four solution area concern last three endeavor area concern furthermore alpha alpha state used track progress alpha author essence posit essential element present every se project every project unique context likely contains thing work universal every project order reap benefit essence user would extend basic kernel essence language include unique feature particular project company describe method paper role essence twofold first serf framework analyzing data utilize alpha sort software startup practice discover category secondly process study whether uncovered practice fit seven alpha ie alpha also present essential element software development software startup study design aim study better understand software startup develop software focusing practice approach topic using qualitative approach study utilizes empirical data list startup practice presented dande et al list software startup practice data seek validate list practice potentially uncover new one data collection empirical data study collected mean multiple case study n table utilized qualitative approach data case collected thematic interview chose thematic approach software startup develop software ad hoc use different terminology academia present challenge structured interview approach
Original Title: Software Startup Practices -- Software Development in Startups through
  the Lens of the Essence Theory of Software Engineering
Original Transcription: **This is a pre-print of an article published in the Proceedings of PROFES 2020: Product-Focused Software Process Improvement. The final authenticated version is available online at: [https://doi.org/10.1007/978-3-030-64148-1_25](https://doi.org/10.1007/978-3-030-64148-1_25).**

**Article Title: Software Startup Practices - Software Development in Startups through the Lens of the Essence Theory of Software Engineering**

**Authors: Kai-Kristian Kemell, Ville Ravaska, Anh Nguyen-Duc, and Pekka Abrahamsson**

**Year: 2020**

**Please cite the original version when citing this article: Kemell KK., Ravaska V., Nguyen-Duc A., Abrahamsson P. (2020) Software Startup Practices - Software Development in Startups Through the Lens of the Essence Theory of Software Engineering. In: Morisio M., Torchiano M., Jeditschka A. (eds) Product-Focused Software Process Improvement. PROFES 2020. Lecture Notes in Computer Science, vol 12562. Springer, Cham. [https://doi.org/10.1007/978-3-030-64148-1_25](https://doi.org/10.1007/978-3-030-64148-1_25)**Software Startup Practices - Software Development in Startups through the Lens of the Essence Theory of Software Engineering

Kai-Kristian Kemell

1 University of Jyvaskyla, Jyvaskyla 40014, Finland 10000-0002-0225-4560

1 University of Jyvaskyla, Jyvaskyla 40014, Finland 10000-0002-4380-2228

2 University of Southeast Norway, Norway

2 kai-kristian.o.kemell@jvu.fi

Ville Ravaska

[MISSING_PAGE_POST]

(SE) practices in software startups are still scarce, and studies into software development in software startups in general are still needed [20]. Some high-profile practices utilized by startups such as the Five Whys are commonly discussed in e.g. startup education, but systematic studies into the topic are lacking.

Thus, to better understand how software development in software startups might differ from software development in more mature software organizations, we study practices in this paper. Specifically, we seek to understand what practices are commonly used by software startups (**RQ1**). In addition, we approach this topic through the lens of the Essence Theory of Software Engineering and seek to understand how this theory fits into the context of software startups. To this end, we study how the seven alphas of the theory - which we discuss in the second section - are suited for the context of software startups, and whether other alphas would be needed to make the theory better suited for the startup context (**RQ2**).

Background - Software Startups, Software Development Practices, and the Essence Theory of Software Engineering

This section is split into three subsections. First, we briefly discuss software startups in relation to software development. Then, we define what we refer to with software development practices.

### _Software Development in Software Startups_

Typically, software startups do not strictly follow any formal software development method [18]. Instead, they combine practices from different methods that suit their needs at the moment or simply use ad hoc practices [15].

As the aim of this study is to uncover software development practices universal to (most) software startups, a notable study is that of Dande et al. [5]. Dande et al. [5] studied software startups in Finland and Switzerland and devised a list of 63 practices commonly utilized by software startups. However, these practices are not solely software development ones but also include practices related to customers and business. Kamulegeya et al. [9] studied these practices and reported that they seemed to apply in the Ugandan startup context as well, providing further validity to the practices. However, they do add that while they consider most of the listed practices to be universal, some might vary in different locations or cultures.

Other studies focusing on practices have not aimed to create such extensive lists of practices but have nonetheless studied software startup practices in different contexts. Klotins, Unterkalmsteiner, and Gorschek [13], for example, created a framework for categorizing software startup practices that differs from the one proposed by Dande et al. [5]. Giardino et al. [7] propose the Greenfield Startup Model to explain software development in early-stage software startups. In the process, they uncovered various practices that supplement and confirm the findings of Dande et al. [5]. Paternoster et al. [18] in their study on how software startups develop software discuss having found 213 practices, which, however, were not listed in their paper. Nonetheless, their findings to lend support to those of Dande et al. [5].

### _Software Development Practices_

Jacobson et al. [8] suggest that a set of practices is what forms a method in the context of SE. Methods, according them, describe ways-of-working, i.e. how work should be carried out. Whether or not formal SE method is employed, a way-of-working exists in the form of an informal method that could nonetheless be described if necessary [8]. In this logic, practices are more atomic units that describe how work is carried out.

Historically, in academic literature and particularly in Information Systems, the construct _technique_ has been used for the same purpose in the context of method engineering [19]. Tolvanen [19] definesa technique to be a set of steps and rules that define how a representation of information system is derived and handled using conceptual structure and related notation. A tool, in this context, refers to a computer-based application supporting the use of a technique.

### _The Essence Theory of Software Engineering_

The Essence Theory of Software Engineering [8] provides a way of describing methods and practices. It consists of a notational language, which is used to achieve this, as well as a so-called kernel, which includes building blocks which one can use as a basis for constructing methods. The kernel, its authors argue [8], contains basic elements that are universal in any SE project.

The Essence kernel contains three types of objects: alphas (i.e. things to work with), activities (i.e. things to do), and competencies (skills required to carry out the work). In this study, we focus on the alphas in the context of software startups. The seven Essence alphas are as follows: (1) Stakeholders, (2) Opportunity, (3) Requirements, (4) Software System, (5) Team, (6) Way of Working, and (7) Work. These alphas are split into three areas of concern. The first two belong in the customer area of concern, numbers three and four in the solution area of concern, and the last three in the endeavor area of concern. Furthermore, each alpha has alpha states used to track progress on the alpha. [8]

The authors of Essence posit [8] that these are the essential elements that are present in every SE project. Every project, then, has its own unique context, which most likely contains more things to work with, but those are not universal to every project. In order to reap the most benefits out of Essence, its users would then extend this basic kernel with the Essence language to include these unique features of their particular project or company to describe their method(s) with it.

In this paper, the role of Essence is two-fold. First, it serves as a framework for analyzing our data. We utilize the alphas to sort the software startup practices we discover into categories. Secondly, in the process of doing so, we study whether all the uncovered practices fit into these seven alphas. I.e., do the alphas also present all the essential elements of software development in software startups?

## 3 Study Design

The aim of this study is to better understand how software startups develop software by focusing on practices. We approach this topic using a qualitative approach. This study utilizes both empirical data and the list of startup practices presented by Dande et al. [5] who list 63 software startup practices. With the data, we seek to both further validate this list of 63 practices, and to potentially uncover new ones.

### _Data Collection_

The empirical data for this study was collected by means of a multiple case study (n=13) (Table 1). We utilized a qualitative approach and data from the cases were collected with thematic interviews. We chose a thematic approach because most software startups develop software ad hoc [15][18] and use different terminology than the academia, which presents challenges for a structured interview approach.

Tuple 18:
Cleaned Title: software development startup company systematic mapping study
Cleaned Transcription: software development startup company systematic mapping study nicolo paternoster carmine giardino michael unterkalmsteiner tony gorschek pekka abrahamsson bikelng institute technology se karlskrona sweden free university bolzanobozen bolzanobozen italy abstract context software startup newly created company operating history fast producing cuttingedge technology company develop software highly uncertain condition tackling fastgrowing market severe lack resource therefore software startup present unique combination characteristic pose several challenge software development activity objective study aim structure analyze literature software development startup company determining thereby potential technology transfer identifying software development work practice reported practitioner researcher method conducted systematic mapping study developing classification schema ranking selected primary study according rigor relevance analyzing reported software development work practice startup result total primary study identified mapped synthesizing available evidence software development startup study entirely dedicated software development startup result weak contribution advice implication lesson learned tool nineteen study focus managerial organizational factor moreover study exhibit high scientific rigor relevance reviewed primary study software engineering work practice extracted categorized analyzed conclusion mapping study provides first systematic exploration stateofart software startup research existing body knowledge limited high quality study furthermore result indicate software engineering work practice chosen opportunistically adapted configured provide value constrains imposed startup context keywords software development startup systematic mapping study footnote journal information software technology introduction wide body knowledge created recent year several empirical study investigating company leverage software engineering se however research software development activity newly created company scarce past publication identified characterized mapped work practice software startup structured investigation area performed indeed none systematic literature review mapping study software engineering see tertiary review zhang babar address startup phenomenon understanding startup take advantage work practice essential support number new business launched everyday new software venture facebook linkedin spotify pinterest instagram dropbox name example startup evolved successful business startup typically aim create hightech innovative product grow aggressively expanding business highly scalable market footnote according recent study solely u startup create average million new job annually despite many successful story selfdestruction rather competition drive majority startup failure within two year creation software startup face intense timepressure market exposed tough competition operating chaotic rapidly evolving uncertain context choosing right feature build adapting quickly new request constrained limited resource crucial success environment software engineering perspective startup unique since develop software context process hardly follow prescriptive methodology startup share characteristic context small company web engineering present combination different factor make development environment different established company therefore research needed support startup engineering activity guiding practitioner taking decision avoiding choice could easily lead business failure goal paper identify understand main contribution stateofart towards software engineering startup end perform systematic mapping study sm aimed characterizing stateofart research startup understanding context characterizes startup determining potential technology transfer stateofart research startup extracting analyzing software development work practice used startup systematic map consists primary study identified initial set paper practitioner may take advantage identified software engineering work practice considering however study respectiverigor relevance assessment furthermore first systematic exploration software startup provides researcher direction future work remainder paper structured follows section describes background related work section illustrates research methodology discus validity threat section introduces classification schema developed gathered data section present result mapping study stateofart software development startup discussed section whereas section reported software development work practice analyzed section concludes paper answering posed research question providing outlook future work background related work modern entrepreneur born thirty year ago boosted advent consumer internet market middle ninety culminated notorious dotcom bubble burst today omnipresence internet mobile device assisting impressive proliferation software venture metaphorically referred startup bubble fact easy access potential market low cost service distribution appealing condition modern entrepreneur inspired success story large number software business created every day however great majority company fail within two year creation software startup early account term startup se literature found carmel studied timetocompletion young package firm noticed company particularly innovative successful advocating need research software development practice replicate success try transfer technology sector sutton provides characterization software startup defined challenge faced startup little accumulated experience development process organization management startup typically focus getting product promoting product building strategic alliance pressure investor customer partner competitor impact decisionmaking company although individually important overall might inconsistent newness software company often require develop operate disruptive technology enter highpotential target market footnote new technology unexpectedly displaces established technology rely incremental improvement already established technology rather tackle radical technical change innovation one objective sm understand context characterizes startup extent suttons definition adopted broadened startup lifecycle lifetime startup company idea conception maturity level identified reported different perspective eg market innovation prominent contribution se viewpoint model presented crowne synthesized startup lifecycle four stage startup stage time startup create refine idea conception first sale time frame characterized need assemble small executive team necessary skill start build product stabilization phase begin first sale last product stable enough commissioned new customer without causing overhead product development growth phase begin stable product development process last market size share growth rate established finally startup evolves mature organization product development becomes robust predictable proven process new product invention software development startup implementation methodology structure control development activity startup major challenge engineer general management software development achieved introduction software process defined coherent set policy organizational structure technology procedure artifact needed conceive develop deploy maintain software product several model introduced drive software development activity startup however without achieving significant benefit startup context software engineering se face complex multifaceted obstacle understanding manage development process startup creative flexible nature reluctant introduce process bureaucratic measure may hinder natural attribute furthermore startup limited resource typically wish use support product development instead establishing process attempt tailor lightweight process startup reported basic failure application rejecting notion repeatable controlled process startup prominently take advantage unpredictable reactive lowprecision engineering practice productoriented practice help startup flexible team workflow leave ability quickly change direction according targeted market therefore many startup focus team productivity asserting control employee instead providing rigid guideline startup often develop application tackle highpotential target market rather developing software specific client issue related market type addressedin literature marketdriven software development regard researcher emphasize importance timetomarket key strategic objective fact startup usually operate fastmoving uncertain market need cope shortage resource peculiar aspect influencing software development marketdriven context related requirement reported often invented software company rarely documented validated product released market circumstance failure product launch largely due product meeting customer need related work prospect evidencebased software engineering motivated researcher conduct systematic literature review mapping study zhang babar report slrs sm published however none review review conducted february investigated software engineering context startup nevertheless exist review studied software engineering topic pertinent specific context environment opposed review investigated individual software engineering technology eg feature location searchbased software testing consider related work small mediumsized enterprise smes startup possibly share characteristic low number employee fewer limited resource hence review study literature smes relevant related work footnote performed automatic search search string published zhang babar pino et al studied adoption software process improvement approach smes point smes part reviewed study achieve one pursued certification concluding standarddriven tailored improvement initiative suitable small company confirming also staple et al finding taticchi et al observe similar situation area business performance measure management pmm review identifies lack pmm model specifically adapted smes speculating nonadoption stem fear cost benefit incomprehension thorpe et al reviewed literature using knowledge within smes managersentrepreneurs important organizational resource smes driver creating knowledge knowledge best encoded organized routine allow widespread sharing within firm challenge provide enough structure allowing knowledge creation sharing scale without limiting creativity learning rosenbusch et al studied innovationperformance relationship smes conducting metaanalysis empirical study cover firm interesting studied context finding innovation stronger impact younger firm established smes furthermore evidence suggests small young firm beneficial conduct internal innovation project seeking innovation collaborating external partner common review looking different aspect smes recognition property small firm require solution technology adapted specific context similarly argue startup differing smes term operating history outside influence market dynamism require software development solution adapted context sm seek evaluate synthesize present empirical finding software development startup date provide overview researched topic finding strength evidence implication research practice research methodology chose perform systematic mapping study sm capable dealing wide poorlydefined area systematic literature review slr would le viable option due breadth overall research question stateofart literature pertaining software engineering startup review paper follows guideline developed kitchenham charter implement systematic mapping process proposed petersen et al figure illustrates adopted process whereas individual step explained subsection note rigor relevance assessment extension attributed ivarsson gorschek synthesis based constant comparison method proposed strauss corbin sm procedure led first second author performed step figure colocated environment ie working together single computer screen notetaking screening paper keywording alleviated resolution conflict among reviewer data extraction rigor relevance assessment disagreement persisted indepth review paper performed necessary third fourth author consulted take final decision definition research question research question driving mapping study stateofart literature pertaining software engineering startup answer question state following subquestions rq context characterizes software development startup rq extent research startup provide reliable transferable result industry rq reported work practice association software engineering startup rq intend understand property characterize nature software development startup sucha characterization illustrates dimension startup defined stateofart rq intend determine scientific evidence result reported stateofart allowing researcher identify worthwhile avenue work providing practitioner tool navigate within stateofart rq intend identify software engineering practice applied startup providing basis determining necessary research conduct search identified primary study exercising search string scientific database search string structured according population intervention comparison proposed kitchenham charter omitted however outcome context facet search string structure research question warrant restriction result particular outcome eg effectivenot effective work practice context eg startup specific product domain table list final used keywords core concept representing population intervention comparison derived research question following rumseys guideline identified synonymous relatedbroaderwider concept alternative spelling part speech core concept note include specific keywords existing startup definition eg sutton discussed section population set term could biased search selected scientific database performed search shown table along number publication retrieved database december selected database considering coverage use domain software engineering ability handle advanced query following example barney et al increase publication coverage also used google scholar index large set data peer nonpeer reviewed proceeded customization search string adapting syntax particular database footnote individual search string available supplementary material screening relevant paper criterion guided inclusion paper study presented contribution body knowledge software development startup contribution form experience report applied engineering practice development model lesson learned excluded search result peerreviewed grey literature book presentation blog post etc written english clearly obsolete year old related nonsoftware company biotech manufacturing electronics etc related established company vse sme research spinf
Original Title: Software development in startup companies: A systematic mapping study
Original Transcription: # Software Development in Startup Companies: A Systematic Mapping Study

Nicolo Paternoster

Carmine Giardino

Michael Unterkalmsteiner

Tony Gorschek

Pekka Abrahamsson

Bikelng Institute of Technology, SE-371 79 Karlskrona, Sweden Free University of Bolzano-Bozen, I-39100 Bolzano-Bozen, Italy

###### Abstract

_Context_: Software startups are newly created companies with no operating history and fast in producing cutting-edge technologies. These companies develop software under highly uncertain conditions, tackling fast-growing markets under severe lack of resources. Therefore, software startups present an unique combination of characteristics which pose several challenges to software development activities. _Objective:_ This study aims to structure and analyze the literature on software development in startup companies, determining thereby the potential for technology transfer and identifying software development work practices reported by practitioners and researchers. _Method:_ We conducted a systematic mapping study, developing a classification schema, ranking the selected primary studies according their rigor and relevance, and analyzing reported software development work practices in startups. _Results:_ A total of 43 primary studies were identified and mapped, synthesizing the available evidence on software development in startups. Only 16 studies are entirely dedicated to software development in startups, of which 10 result in a weak contribution (advice and implications (6); lesson learned (3); tool (1)). Nineteen studies focus on managerial and organizational factors. Moreover, only 9 studies exhibit high scientific rigor and relevance. From the reviewed primary studies, 213 software engineering work practices were extracted, categorized and analyzed. _Conclusion:_ This mapping study provides the first systematic exploration of the state-of-art on software startup research. The existing body of knowledge is limited to a few high quality studies. Furthermore, the results indicate that software engineering work practices are chosen opportunistically, adapted and configured to provide value under the constrains imposed by the startup context.

keywords: Software Development, Startups, Systematic Mapping Study +
Footnote †: journal: Information and Software Technology

## 1 Introduction

A wide body of knowledge has been created in recent years through several empirical studies, investigating how companies leverage software engineering (SE) [1; 2]. However, research on software development activities in newly created companies is scarce. In the past, very few publications have identified, characterized and mapped work practices in software startups [3] and no structured investigation of the area has been performed. Indeed, none of the systematic literature reviews [4] or mapping studies [5] in software engineering (see the tertiary review by Zhang and Babar [6]) address the startup phenomenon.

Understanding how startups take advantage from work practices is essential to support the number of new businesses launched everyday1. New software ventures such as _Facebook_, _Linkedin_, _Spotify_, _Pinterest_, _Instagram_, and _Dropbox_, to name a few, are examples of startups that evolved into successful businesses. Startups typically aim to create high-tech and innovative products, and grow by aggressively expanding their business in highly scalable markets.

Footnote 1: According to a recent study, solely in the US _“startups create an average of 3 million new jobs annually”_[7].

Despite many successful stories, self-destruction rather than competition drives the majority of startups into failure within two years from their creation [8]. Software startups face intense time-pressure from the market and are exposed to tough competition, operating in a chaotic, rapidly evolving and uncertain context [9; 10]. Choosing the right features to build and adapting quickly to new requests, while being constrained by limited resources, is crucial to the success in this environment [3].

From a software engineering perspective startups are unique, since they develop software in a context where processes can hardly follow a prescriptive methodology [11]. Startups share some characteristics with other contexts such as small companies and web engineering, and present a combination of different factors that make the development environment different from established companies [12]. Therefore, research is needed to support startups' engineering activities, guiding practitioners in taking decisions and avoiding choices that could easily lead business failure [13; 14].

The goal of this paper is to identify and understand the main contributions of the state-of-art towards software engineering in startups. To this end, we perform a systematic mapping study (SMS) [5; 15] aimed at:

* characterizing the state-of-art research on startups
* understanding the context that characterizes startups
* determining the potential for technology transfer of the state-of-art research on startups
* extracting and analyzing software development work practices used in startups

The systematic map consists of 43 primary studies that were identified from an initial set of 1053 papers. Practitioners may take advantage of the 213 identified software engineering work practices, while considering however the studies' respectiverigor and relevance assessments. Furthermore, this first systematic exploration on software startups provides researchers with directions for future work.

The remainder of this paper is structured as follows: Section 2 describes background and related work; Section 3 illustrates the research methodology and discusses validity threats; Section 4 introduces the classification schema, developed from the gathered data; Section 5 presents the results of the mapping study. The state-of-art of software development in startups is discussed in Section 6, whereas in Section 7 the reported software development work practices are analyzed. Section 8 concludes the paper, answering the posed research questions and providing an outlook for future work.

## 2 Background and Related Work

Modern entrepreneur, born more than thirty years ago [16], has been boosted by the advent of the consumer Internet markets in the middle of the nineties and culminated with the notorious dot-com bubble burst of 2000 [17]. Today, with the omnipresence of the Internet and mobile devices, we are assisting to an impressive proliferation of software ventures - metaphorically referred as the startup bubble. In fact, easy access to potential markets and low cost of services distribution are appealing conditions for modern entrepreneurs [18]. Inspired by success stories, a large number of software businesses are created every day. However, the great majority of these companies fail within two years from their creation [8].

### Software Startups

An early account for the term _startup_ in the SE literature can be found in Carmel [19] who studied in 1994 the time-to-completion in a young package firm. He noticed how these companies were particularly innovative and successful, advocating the need for more research on their software development practices so as to replicate success and try to transfer it to other technology sectors.

Sutton [3] provides a characterization of software startups, defined by the challenges they are faced with:

* startups have little accumulated experience in development processes and organization management.
* startups typically focus on getting the product out, promoting the product and building up strategic alliances.
* pressure from investors, customers, partners and competitors impact the decision-making in a company. Although individually important, overall they might be inconsistent.
* newness of software companies often require to develop or operate with disruptive technologies2 to enter into a high-potential target market.

Footnote 2: A new technology that unexpectedly displaces an established technology. It does not rely on incremental improvements to an already established technology, but rather tackles radical technical change and innovation [20].

One of the objectives of this SMS is to understand the context that characterizes startups and to what extent Sutton's definition from 2000 has been adopted or broadened.

### Startup Lifecycle

The lifetime of a startup company, from idea conception to the maturity level, has been identified and reported from different perspectives (e.g. market [21] and innovation [22]). A prominent contribution, from a SE viewpoint, is the model presented by Crowne [8], who synthesized the startup lifecycle in four stages. The startup stage is the time when startups create and refine the idea conception, up to the first sale. This time frame is characterized most from the need to assemble a small executive team with the necessary skills to start to build the product. The stabilization phase begins from the first sale, and it lasts until the product is stable enough to be commissioned to a new customer without causing any overhead on product development. The growth phase begins with a stable product development process and lasts until market size, share and growth rate have been established. Finally, the startup evolves to a mature organization, where the product development becomes robust and predictable with proven processes for new product inventions.

### Software Development in Startups

The implementation of methodologies to structure and control the development activities in startups is a major challenge for engineers [11]. In general, the management of software development is achieved through the introduction of software processes, which can be defined as "the coherent set of policies, organizational structures, technologies, procedures, and artifacts that are needed to conceive, develop, deploy and maintain a software product" [23]. Several models have been introduced to drive software development activities in startups, however without achieving significant benefits [24; 11; 3].

In the startup context, software engineering (SE) faces complex and multifaceted obstacles in understanding how to manage development processes. Startups are creative and flexible in nature and reluctant to introduce process or bureaucratic measures which may hinder their natural attributes [3; 25]. Furthermore, startups have very limited resources and typically wish to use them to support product development instead of establishing processes [11; 26]. Some attempts to tailor lightweight processes to startups reported basic failure of their application [27]. Rejecting the notion of repeatable and controlled processes, startups prominently take advantage of unpredictable, reactive and low-precision engineering practices [3; 28; 29; 30].

Product-oriented practices help startups in having a flexible team, with workflows that leave them the ability to quickly change the direction according to the targeted market [26; 3]. Therefore, many startups focus on team productivity, asserting more control to the employees instead of providing them rigid guidelines [28; 29; 30].

Startups often develop applications to tackle a high-potential target market rather than developing software for a specific client [18; 31]. Issues related to this market type are addressedin literature by market-driven software development [32]. In this regard, researchers emphasize the importance of time-to-market as a key strategic objective [33; 34]. In fact, start-ups usually operate in fast-moving and uncertain markets and need to cope with shortage of resources. Other peculiar aspects influencing software development in the market-driven context are related to requirements, which are reported to be often "invented by the software company" [35], "rarely documented" [36], and can be validated only after the product is released to market [37; 38]. Under these circumstances, failure of product launches are largely due to "products not meeting customer needs" [32].

### Related work

The prospects of evidence-based software engineering [39] have motivated researchers to conduct systematic literature reviews and mapping studies. Zhang and Babar [6] report on 148 SLR's and SMS's published between 2004 and 2010. However, none of these reviews nor the reviews conducted up to February 20143, investigated software engineering in the context of startups. Nevertheless, there exist reviews that studied software engineering topics pertinent to specific contexts or environments (as opposed to reviews that investigated individual software engineering technologies, e.g. feature location [40] or search-based software testing [41]) that we consider as related work. Small and medium-sized enterprises (SMEs) and startups possibly share some characteristics, such as the low number of employees (fewer than 250 [42]) and limited resources [43; 44]. Hence, reviews that study the literature on SMEs are relevant related work.

Footnote 3: We performed an automatic search with the search string published by Zhang and Babar [6].

Pino et al. [45] studied the adoption of software process improvement approaches in SMEs [46]. They point out that very few of the SMEs that were part of the reviewed studies did achieve one of the pursued certifications, concluding that standard-driven, not tailored improvement initiatives are not suitable for small companies, confirming also Staples' et al. findings [47]. Taticchi et al. [48] observe a similar situation in the area of business performance measures and management (PMM). Their review identifies a lack of PMM models specifically adapted to SMEs, speculating that non-adoption stems from fear of costs and benefits incomprehension.

Thorpe et al. [49] reviewed the literature on using knowledge within SMEs. Managers/entrepreneurs are an important organizational resource in SMEs as they are drivers for creating knowledge. This knowledge is best encoded in organized routines that allow widespread sharing within the firm. The challenge is to provide enough structure, allowing knowledge creation and sharing to scale, without limiting creativity and learning.

Rosenbusch et al. [50] studied the innovation-performance relationship in SMEs by conducting a meta-analysis of 42 empirical studies that cover 21,270 firms. Interesting to our studied context is their finding that innovation has a stronger impact on younger firms than on more established SMEs. Furthermore, evidence suggests that for small and young firms it is more beneficial to conduct internal innovation projects than seeking innovation by collaborating with external partners.

Common to these reviews, looking at different aspects of SMEs, is the recognition that properties of small firms require solutions and technologies that are adapted to that specific context. Similarly, we argue that startups, differing from SMEs in terms of their operating history, outside influences and market dynamism, require software development solutions adapted to their context. This SMS seeks to evaluate, synthesize and present the empirical findings on software development in startups to date and provide an overview of researched topics, findings, strength of evidence, and implications for research and practice.

## 3 Research methodology

We chose to perform a systematic mapping study (SMS), which is capable of dealing with wide and poorly-defined areas [15; 4]. A systematic literature review (SLR) [4] would have been a less viable option due to the breadth of our overall research question: _What is the state-of-art in literature pertaining to software engineering in startups?_

The review in this paper follows the guidelines developed by Kitchenham and Charters [4] and implements the systematic mapping process proposed by Petersen et al. [15]. Figure 1 illustrates the adopted process, whereas the individual steps are explained in Subsections 3.1- 3.7. Note that rigor and relevance assessment is an extension attributed to Ivarsson and Gorschek [51] and synthesis is based on the constant comparison method proposed by Strauss and Corbin [52].

The SMS procedure was led by the first and second authors, who performed the steps in Figure 1 in a co-located environment, i.e. working together on a single computer screen. Note-taking during screening of papers and keywording alleviated the resolution of conflicts among the reviewers during data extraction and rigor and relevance assessment. If disagreement persisted, an in-depth review of the paper was performed and, if necessary, the third and fourth authors were consulted to take a final decision.

### Definition of Research Questions

The research question driving this mapping study is: _What is the state-of-art in literature pertaining to software engineering in startups?_ To answer this question, we state the following sub-questions:

* RQ1 What is the context that characterizes software development in startups?
* RQ2 To what extent does the research on startups provide reliable and transferable results to industry?
* RQ3 What are the reported work practices in association with software engineering in startups?

With RQ1 we intend to understand the properties that characterize the nature of software development in startups. Sucha characterization illustrates the dimensions by which startups are defined in the state-of-art. With RQ2 we intend to determine the scientific evidence of the results reported in the state-of-art, allowing researchers to identify worthwhile avenues for further work and providing practitioners a tool to navigate within the state-of-art. With RQ3 we intend to identify the software engineering practices applied in startups, providing a basis for determining necessary further research.

### Conduct Search

We identified the primary studies by exercising a search string on scientific databases. The search string is structured according to population, intervention and comparison, as proposed by Kitchenham and Charters [4]. We omitted however the outcome and context facet from the search string structure as our research questions do not warrant a restriction of the results to a particular outcome (e.g. effective/not effective work practices) or context (e.g. startups in a specific product domain).

Table 1 lists the final used keywords. The core concepts, representing population, intervention and comparison, are derived from our research questions. Following Rumsey's guidelines [53], we identified synonymous, related/broader/wider concepts, alternative spelling and part of speech for each core concept. Note that we did not include specific keywords from existing startup definitions (e.g. Sutton [3], discussed in Section 2.1) to the population set of terms as this could have biased the search.

The selected scientific databases on which we performed the search are shown in Table 2, along with the number of publications retrieved from each database (up to December 2013). We selected the databases considering their coverage and use in the domain of software engineering, and their ability to handle advanced queries, following the example of Barney et al. [54].

To increase publication coverage we also used Google Scholar, which indexes a large set of data, both peer and non-peer reviewed. Then, we proceeded to the customization of the search string, adapting the syntax to the particular database4.

Footnote 4: The individual search strings are available in the supplementary material [55].

### Screening of Relevant Papers

The criterion that guided the inclusion of a paper was that the study presented a contribution to the body of knowledge on software development in startups. A contribution can be in the form of an experience report, applied engineering practices, development models or lessons learned. We excluded search results that were:

* not peer-reviewed (grey literature, books, presentations, blog posts, etc.)
* not written in English
* clearly obsolete (more than 20 years old)
* related to non-software companies (biotech, manufacturing, electronics, etc.)
* related to established companies (VSE, SME, research spinf

Tuple 19:
Cleaned Title: lean internal startup software product innovation large company enablers inhibitor
Cleaned Transcription: lean internal startup software product innovation large company enablers inhibitor footnote author version manuscript accepted publication journal system software copyright owner version accessed httpsdoiorgjjsshttpsdoiorgjjss manuscript version made available ccbyncnd license henry edison nina smorsgard xiaofeng wang pekka abrahamsson free university bozenbolzano piazza domenicani bolzano italy norwegian university science technology hogskoleringen trondheim norway faculty information technology po box fi university jyvaskyla finland software startup research network httpssoftwarestartupsorghttpssoftwarestartupsorg footnote please cite edison h smorsgard n wang x abrahamsson p lean internal startup software product innovation large company enablers inhibitor journal system software abstract context startup disrupting traditional market replacing wellestablished actor innovative productsto compete age disruption large established company rely traditional way advancement focus cost efficiency lead time reduction quality improvement corporate management looking possibility innovate like startup along awareness use lean startup approach grown rapidly amongst software startup community large company recent year objective aim study investigate lean internal startup facilitates software product innovation large company study also identifies enablers inhibitor lean internal startup method multiple case study approach followed investigation two software product innovation project two different large company examined using conceptual framework based methodinaction framework extended previously developed leaninternal corporate venture model seven facetoface indepth interview employee different role responsibility conducted collected data analysed careful coding process withincase analysis crosscase comparison applied draw finding two case result generic process flow summarises common key process lean internal startup context large company finding suggest internal startup initiated topdown management bottomup employee face different challenge list enablers inhibitor applying lean startup large company identified including top management support crossfunctional team key enablers case face different inhibitor due different process inception objective team type product conclusion contribution study research threefold first study one first attempt investigate use lean startup approach context large company empirically second study show potential methodinaction framework investigate lean startup approach nonstartup context third contribution general process lean internal startup evidence enablers inhibitor implementing theoryinformed empirically grounded future study could extend study addressing limitation research approach undertaken study keywords lean startup internal startup software product innovation large company methodinaction lean internal startup footnote journal journal lean introduction today software startup become one key driver economy innovation new business startup established month u fairlie et al even though inexperienced young immature sutton product disrupting traditional market putting wellestablished actor pressure uber spotify airbnb name example software startup grown rapidly startup offer new product new business model new business value high speed cutting edge technology continuously talk potential customer discover gap existing offer iterate conduct experiment find repeatable scalable business model willing pivot immediately opportunity prove viable compete age disruption large established company rely traditional way advancement focus cost efficiency lead time reduction quality improvement rejeb et al corporate management looking new way keep leading position fast moving market innovate like startup greater resource inhouse hope bring innovative product new customer value market startup along awareness use lean startup approach grown rapidly amongst software startup community recent year similar many precedent method development promotion lean startup almost entirely driven practitioner consultant little participation research community early stage evolution however focus research effort unterkalmsteiner et al even though lean startup approach originated software startup also gained interest large company general electric intuit etc recent survey corporate executive reveals using element lean startup context kirsner marijarvi et al report experience large finnish large company developing new software internal startup large company adopted lean startup approach hoping help generate successful software product innovation ries argues core idea behind lean startup offer benefit large company well obstacle minimised opportunity beneficial support software product innovation hence evidence understanding enablers inhibitor lean internal startup large company need gathered however scientific empirical study regarding leverage lean startup approach software product innovation large software organisation rare based observation main research question investigated study could large company run effectively lean internal startup software product innovation project answer main research question divided two subquestionsas follows rq lean internal startup run large company software product innovation project rq enablers inhibitor running lean internal startup large company remainder paper structured follows section discus background related work section present theoretical framework used study whilst section describes research methodology employed key process lean internal startup reported section section present enablers inhibitor lean internal startup context large company discussed section conclusion future work covered section background related work software product innovation software product innovation creation introduction new software product existing new market lippoldt stryszowski new product developed respond either technology market opportunity krishnan ulrich newer technology used improve current offer completely new functionality example use cloud computing online storage implementation new electronic payment method new product may triggered unmet customer need current solution address newly revealed customer need software industry majority innovation could either process product simonetti et al software process innovation refers implementation new process tool method develop software eg objectoriented development fichman kemerer case computeraided software engineering tool orlikowski open source software feller fitzgerald software process improvement initiative bygstad fagerstrom however use innovative tool process necessary lead innovative product carlo et al highsmith cockburn claim agile development support software process innovation focusing people team agile seemsable prescribe develop working software faster still unable give answer product developed bosch et al although agile also advocate build software iteratively work problem known stakeholder case product innovation problem solution unknown product innovation software industry influenced either new hardware software development raise strategic challenge software company kalternecker et al shift mainframe personal computer created new market standalone operating system microsoft new startup time emerged offered new operating system called do decade popularity mobile device attracted new startup develop various mobile apps including new mobile operating system eg android io etc another example shift proprietary software open source software bonaccorsi et al allows new startup enter market challenge market leader eg linux v microsoft window mozilla v internet explorer large hightech company innovative activity performed specialised dedicated entity typically rd department rd innovation scientific andor technological based involvement company rd activity driven need improve current process product researching new process technology specific user need technology becomes advanced complex rd demanded bring innovative product however technology produced rd inline directly support business goal technology called misfit technology anokhin et al happens company three option keep scientific research sell technology outside introduce spinoff abetiti anokhin et al previous work show current research software product innovation scattered different area early user integration continuous experimentation open innovation edison et al research early user integration focus capturing new idea outside company ie user customer competitor etc turn real product bailey horvitz blohm et al kauppinen et al gassmann et al rather developing new product internally research open innovation suggests collaborate external entity eg living lab emergent research area software product innovation startup ex perimentation approach inspired lean startup approach fagerholm et al lindgren munch approach software developed validated experiment stakeholder bosch proposes innovation experimentation system minimise research development rd investment increase customer satisfaction system rd run week sprint based customer feedback however method limited saas softwareasaservice embedded system based bosch study fagerholm et al lindgren munch propose continuous experimentation system continuously test value product user study emphasise product development capture product value endtoend view software product innovation ie generation innovative product idea realisation market potential rarely seen existing study lean startup approach lean startup approach introduced new way entrepreneur bear potential product innovation extreme situation problem solution unknown ries instead emphasising business plan lean startup advocate build product iteratively deliver fast market early feedback however since customer often unknown beginning customer could perceive value also unknown thus entrepreneur get building day one identify validate problem intend solve discover customer blank lean startup approach built upon customer development model blank consists four step customer discovery customer validation customer creation organisation building first two step concerned identifying customer value last two step aim create market product scale business model teach focus scale something proven work based lean startup structured process validate business hypothesis engineering method fig present key process lean startup approach perceive customer value entrepreneur start feedback loop buildmeasurelearn bml turn business idea product done developing minimum viable product mvp using agile method tool collect customer feedback product feedbackor pivot new direction perish renounce business product eisenmann et al ries key practice lean startup summarised table current research lean startup approach centred applying method standalone startup context develop new product eg haniiotis may efeoglu et al peerreviewed study investigate lean startup approach support software product innovation large company previous study based single case study find internal startup share characteristic standalone startup aiming product innovation edison et al study extend previous research investigating two internal startup two different company internal corporate venture icv icvs corporate entrepreneurial effort originate within corporation intended inception new business corporation kuratko et al icvs operate semiautonomous corporate startup simon et al innovation hub ohare et al internal startup ylihuumo et al introduction new internal venture may consequence following leading product market innovation sharma chrisman block macmillan degree figure lean startup process step edison
Original Title: Lean Internal Startups for Software Product Innovation in Large
  Companies: Enablers and Inhibitors
Original Transcription: # Lean Internal Startups for Software Product Innovation in Large Companies: Enablers and Inhibitors1
Footnote 1: This is the authors’ version of the manuscript accepted for publication in the Journal of Systems and Software. Copyright owner’s version can be accessed at [https://doi.org/10.1016/j.jss.2017.09.034](https://doi.org/10.1016/j.jss.2017.09.034). ©2018. This manuscript version is made available under the CC-BY-NC-ND 4.0 license.

Henry Edison

Nina M. Smorsgard

Xiaofeng Wang

Pekka Abrahamsson

Free University of Bozen-Bolzano, Piazza Domenicani 3, Bolzano 39100, Italy Norwegian University of Science and Technology, Hogskoleringen 1, 7491 Trondheim, Norway Faculty of Information Technology, P.O. Box 35, FI-40014, University of Jyvaskyla, Finland Software Startup Research Network [https://softwarestartups.org/](https://softwarestartups.org/)

Footnote 2: Please cite as: Edison. H, Smorsgard, N. M., Wang, X. and Abrahamsson, P. (2018). Lean Internal Startups for Software Product Innovation in Large Companies: Enablers and Inhibitors. _Journal of Systems and Software_, 135:69–87.

###### Abstract

_Context:_ Startups are disrupting traditional markets and replacing well-established actors with their innovative products.To compete in this age of disruption, large and established companies cannot rely on traditional ways of advancement, which focus on cost efficiency, lead time reduction and quality improvement. Corporate management is now looking for possibilities to innovate like startups. Along with it, the awareness and the use of the Lean startup approach have grown rapidly amongst the software startup community and large companies in recent years.

_Objective:_ The aim of this study is to investigate how Lean internal startup facilitates software product innovation in large companies. This study also identifies the enablers and inhibitors for Lean internal startups.

_Method:_ A multiple case study approach is followed in the investigation. Two software product innovation projects from two different large companies are examined, using a conceptual framework that is based on the method-in-action framework and extended with the previously developed Lean-Internal Corporate Venture model. Seven face-to-face in-depth interviews of the employees with different roles and responsibilities are conducted. The collected data is analysed through a careful coding process. Within-case analysis and cross-case comparison are applied to draw the findings from the two cases.

_Results:_ A generic process flow summarises the common key processes of Lean internal startups in the context of large companies. The findings suggest that an internal startup can be initiated top-down by management, or bottom-up by employees, which faces different challenges. A list of enablers and inhibitors of applying Lean startup in large companies are identified, including top management support and cross-functional team as key enablers. Both cases face different inhibitors due to the different process of inception, objective of the team and type of the product.

_Conclusions:_ The contribution of this study for research is threefold. First, this study is one of the first attempt to investigate the use of Lean startup approach in the context of large companies empirically. Second, the study shows the potential of the method-in-action framework to investigate the Lean startup approach in non-startup context. The third contribution is a general process of Lean internal startup and the evidence of the enablers and inhibitors of implementing it, which are both theory-informed and empirically grounded. Future studies could extend our study by addressing the limitations of the research approach undertaken in this study.

keywords: Lean startup, internal startup, software product innovation, large companies, method-in-action, Lean internal startup +
Footnote †: journal: Journal of Lean

## 1 Introduction

Today, software startups have become one of the key drivers of economy and innovation. In 2016, 550,000 new businesses or startups have been established each month in the US only (Fairlie et al., 2016). Even though they are inexperienced, young and immature (Sutton, 2000), their products are disrupting traditional markets and are putting well-established actors under pressure. Uber, Spotify, and Airbnb, to name just a few, are examples of software startups that have grown rapidly. Startups offer new product, new business model, and new business value at high speed, and with cutting edge technology. They continuously talk to their potential customers to discover gaps in the existing offers, iterate, and conduct experiments to find repeatable and scalable business models. They are willing to pivot immediately if the opportunity does not prove viable.

To compete in this age of disruption, large and established companies cannot rely on traditional ways of advancement, which focus on cost efficiency, lead time reduction or quality improvement (Rejeb et al., 2008). Corporate management is now looking for new ways to keep their leading positions in a fast moving market, and to innovate like startups. With greater resource in-house, they hope that they can bring innovative products with new customer values to market as startups do.

Along with it, the awareness and use of the Lean startup approach have grown rapidly amongst the software startup community in recent years. Similar to many precedent methods, the development and promotion of Lean startup have been almost entirely driven by practitioners and consultants, with little participation from the research community during the early stage of its evolution. However now it is the focus of more and more research efforts (Unterkalmsteiner et al., 2016).

Even though the Lean startup approach is originated in software startups, it has also gained interest from large companies as General Electric, 3M, Intuit, etc. A recent survey on 170 corporate executives reveals that 82% of them are using some elements of Lean startup in their context (Kirsner, 2016). Marijarvi et al. (2016) report on the experience of large Finnish large companies in developing new software through internal startups. More and more large companies adopted the Lean startup approach, hoping that it will help them to generate successful software product innovation.

Ries (2011) argues that the core ideas behind Lean startup can offer benefits for large companies as well. If the obstacles can be minimised, the opportunities can be very beneficial to support software product innovation. Hence, evidence for understanding the enablers and inhibitors for Lean internal startups in large companies needs to be gathered. However, scientific and empirical studies regarding the leverage of the Lean startup approach for software product innovation in large software organisations are rare. Based on this observation, the main research question investigated in this study is: _How could large companies run effectively Lean internal startups for their software product innovation projects?_

To answer the main research question, we divided it into two sub-questionsas follows:

* RQ1: How are Lean internal startups run in large companies for their software product innovation projects?
* RQ2: What are the enablers and inhibitors of running Lean internal startups in large companies?

The remainder of this paper is structured as follows. Section 2 discusses the background and related work. Section 3 presents the theoretical frameworks used in this study, whilst Section 4 describes the research methodology employed. The key processes of Lean internal startups are reported in Section 5. Section 6 presents the enablers and inhibitors for Lean internal startups in the context of large companies, which are further discussed in Section 7. The conclusions and future work are covered in Section 8.

## 2 Background and Related Work

### Software Product Innovation

Software product innovation is the creation and introduction of a new software product to an existing or new market (Lippoldt and Stryszowski, 2009). The new product is developed to respond to either a technology or market opportunity (Krishnan and Ulrich, 2001). Newer technology is used to improve the current or to offer completely new functionalities, for example, the use of cloud computing as the online storage or the implementation of new electronic payment method. New products may be triggered by the unmet customer needs from current solutions or to address newly revealed customer needs.

In software industry, the majority of innovation could be either process or product (Simonetti et al., 1995). Software process innovation refers to the implementation of new processes, tools or methods to develop software, e.g., object-oriented development (Fichman and Kemerer, 1993), CASE (Computer-Aided Software Engineering) tools (Orlikowski, 1993), open source software (Feller and Fitzgerald, 2000), and software process improvement initiatives (Bygstad and Fagerstrom, 2005). However, the use of innovative tools or processes does not necessary lead to innovative products (Carlo et al., 2011).

Highsmith and Cockburn (2001) claim that agile development support software process innovation by focusing on people and team. Agile seemsable to prescribe on how to develop a working software faster, but is still unable to give answer what product should be developed (Bosch et al., 2013). Although agile also advocates to build the software iteratively, it only works when the problem is known to the stakeholders. This is not the case in product innovation, where the problem and solution are unknown.

Product innovation in software industry which is influenced either by new hardware or software development raises strategic challenges for software companies (Kalternecker et al., 2015). The shift from mainframe to personal computers created new market for standalone operating system. Microsoft, a new startup at that time, emerged and offered new operating system called DOS. For over a decade, the popularity of mobile devices has attracted new startups to develop various mobile apps, including new mobile operating systems, e.g., Android, iOS, etc.. Another example is the shift from proprietary software to open source software (Bonaccorsi et al., 2006), which allows new startups to enter a market and challenge market leaders, e.g., Linux vs. Microsoft Windows or Mozilla vs. Internet Explorer.

In large and high-tech companies, innovative activities are performed by a specialised and dedicated entity, typically R&D department. In R&D, most innovations are scientific and/or technological based. The involvement of companies in R&D activities are driven by the need to improve current process or products, researching new process or technology or specific user need. When the technology becomes more advanced and complex, R&D are demanded to bring more innovative products. However, not all technologies produced by R&D are inline with and directly support the business goal. These technologies are called misfit technologies (Anokhin et al., 2011). When this happens, the company has three options: keep scientific research, sell the technologies outside or introduce spin-off (Abetiti, 2002; Anokhin et al., 2011).

Our previous work shows that the current research on software product innovation is scattered in different areas: early user integration, continuous experimentation, and open innovation (Edison et al., 2016). Research on early user integration focuses on capturing new ideas from outside companies, i.e. users, customers, competitors etc., and turn them into real products (Bailey and Horvitz, 2010; Blohm et al., 2011; Kauppinen et al., 2007; Gassmann et al., 2006). Rather than developing new products internally, research on open innovation suggests to collaborate with external entities, e.g., through living lab.

An emergent research area in software product innovation is startup ex perimentation approach, which is inspired by the Lean startup approach (Fagerholm et al., 2014; Lindgren and Munch, 2015). In this approach, software is developed and validated through experiments with all stakeholders. Bosch (2012) proposes an innovation experimentation system to minimise research and development (R&D) investment and increase customer satisfaction. In this system, R&D runs a 2-4 week sprint based on customer feedback. However, the method is limited to SaaS (Software-as-a-Service) and embedded systems. Based on Bosch's study, Fagerholm et al. (2014) and Lindgren and Munch (2015) propose a continuous experimentation system, which continuously tests the value of a product to its users. These studies emphasise more on product development itself and how to capture a product's value. An end-to-end view of software product innovation, i.e., from the generation of an innovative product idea to the realisation of its market potential, is rarely seen in the existing studies.

### Lean startup approach

The Lean startup approach was introduced as a new way of entrepreneur and bears the potential for product innovation in the extreme situation, where the problem and solution are unknown (Ries, 2011). Instead of emphasising a business plan, Lean startup advocates to build the product iteratively and deliver it fast to the market for early feedback. However, since customers are often unknown in the beginning, what customers could perceive as value is also unknown. Thus, entrepreneur should "get out of the building" from day one to identify and validate the problem they intend to solve and discover who their customers are (Blank, 2007).

The Lean startup approach is built upon the Customer Development Model (Blank, 2007) which consists of four steps: customer discovery, customer validation, customer creation and organisation building. The first two steps are concerned with identifying what customers value most. The last two steps aim to create a market for the product and scale the business. The model teaches to focus on and scale something that has been proven to work. Based on it, Lean startup is a structured process to validate business hypotheses through an engineering method. Fig. 1 presents the key processes of the Lean startup approach.

To perceive customer value, an entrepreneur starts a feedback loop (Build-Measure-Learn or B-M-L) that turns a business idea into a product. This can be done by developing a minimum viable product (MVP) using agile methods as a tool to collect customer feedback on the product. Through the feedback,or to pivot to a new direction, or to perish - renounce the business and the product (Eisenmann et al., 2013; Ries, 2011). The key practices of Lean start-up are summarised in Table 1.

Current research on the Lean startup approach is centred on applying the method in a standalone startup context to develop new product, e.g., (Haniiotis, 2011; May, 2012; Efeoglu et al., 2014). Very few peer-reviewed studies investigate how the Lean startup approach supports software product innovation in large companies. Our previous study based on a single case study finds that internal startups share the same characteristics as standalone startups, which is aiming at product innovation (Edison et al., 2015). In this study we extend our previous research by investigating two internal startups in two different companies.

### Internal Corporate Venture (ICV)

ICVs are corporate entrepreneurial efforts that originate within a corporation and are intended from inception as new business for the corporation (Kuratko et al., 2009). ICVs operate as semi-autonomous corporate startups (Simon et al., 1999) or innovation hubs (O'Hare et al., 2008) or internal startups (Yli-Huumo et al., 2015). The introduction of a new internal venture may be the consequence of following or leading to product or market innovation (Sharma and Chrisman, 1999; Block and MacMillan, 1993). The degree

Figure 1: Lean startup process steps (Edison, 2015)

Tuple 20:
Cleaned Title: natural disaster entrepreneurship activity moderating role country governance
Cleaned Transcription: natural disaster entrepreneurship activity moderating role country governance christopher j boudreaux florida atlantic university college business glade road boca raton fl cboudreauxfauedu anand jha wayne state university mike ilitch school business woodward ave detroit mi anandjhawayneedu monica escaleras florida atlantic university college business glade road boca raton fl mescalerasfauedu abstract purpose paper investigate country quality governance moderate effect natural disaster startup activity within country test hypothesis using panel country finding suggest natural disaster discourage startup activity country lowquality governance encourage startup activity country highquality governance moreover estimate reveal natural disaster effect startup activity persist short term year long term finding provide new insight natural disaster affect entrepreneur activity highlight importance country governance event plain english summary natural disaster encourage startup activity country highquality governance country lowquality governance natural disaster discourage startup activity moreover estimate reveal natural disaster effect startup activity persist short term year long term finding provide new insight natural disaster affect entrepreneur activity highlight importance country governance event finding important implication researcher policymakers researcher note effect natural disaster entrepreneur activity nuanced contingent upon country governance study also useful policymakers want limit adverse impact natural disaster startup activity policymakers recognize new firm backbone new job creation likely invest potential innovative breakthrough leading employment future keywords country governance entrepreneur institution natural disaster startup jel classification l q introduction fewer natural disaster year number approached although number death due natural disaster decreasing loss due disaster according report world bank dedicated understanding financial economic impact natural disaster reported global cost natural disaster increased fold major natural catastrophe caused economic loss estimated average billion per year price benson clay natural disaster cost world billion footnote people increasingly living buying property natural disasterprone area feel safer due better technology predict timing disaster availability insurance sadowski sutter footnote httpsweathercomscienceenvironmentnewsdisasterscostdamageclimatechangehttpsweathercomscienceenvironmentnewsdisasterscostdamageclimatechange despite increasing cost natural disaster impose economy academic research seldom investigated mitigate negative impact natural disaster however one notable exception examined whether country governance quality mitigates adverse impact disaster multinational corporation mncs subsidiary investment oh oetzel author examined impact different type disastersincluding natural disasterson mncs subsidiary investment investigate whether quality governance mitigates adverse effect disaster mncs investment found host country better regulatory quality natural disaster appear increase number subsidiary suggesting highquality regulation help mncs exploit business opportunity arising natural disaster aspect governance government effectiveness rule oflaw voice accountability political stability control corruption matter one explanation mncs better position deal natural disaster likely insured often option channeling resource part world exploit opportunity natural disaster create contrast mncs new entrepreneur often limited resource thus ill equipped deal disaster natural disaster disrupt network destroy infrastructure making daytoday operation costly boehm flaanen pandalainayar also present new opportunity cuaresma hlouskova obersteiner know prior literature quality institution incentivizes entrepreneur start new business nikolaev et al baumol sobel estrin et al whether entrepreneur exploit opportunity limit cost associated natural disaster may depend quality governance country highquality governance might lessen natural disaster adverse impact grease positive impact starting new business example country resident free voice public concern entrepreneur anticipate quicker recovery damage done infrastructure moreover entrepreneur might anticipate relief material better access credit effective governance country governance facilitates disaster recovery grease entrepreneur desire exploit opportunity expect number startup increase following natural disaster country highquality governance however expect effect country lack good governance motivated line thought goal understanding country quality institution might affect startup activity following natural disaster begin investigating association natural disaster rate startup activity next investigate whether quality governance affect rate startup activity focus central question study quality governance country moderate relationship natural disaster startup activity hypothesize adverse effect natural disaster rate startup activity severe country lowquality governance effect le severe even positive country highquality governance develop hypothesis using three strand literature regarding entrepreneurship natural disaster role countrylevel governance fostering business activity test hypothesis collected data world bank entrepreneurship survey database provides data annual rate new startup country next using data form emergency event database constructed measure natural disaster intensity adding total number people affected injured made homeless due natural disaster merged variable world bank data finally merged variable measure governance world governance indicator government effectiveness regulatory quality rule law voice accountability political stability control corruption sample comprised country includes country highquality institution norway finland switzerland well country lowquality institution saudi arabia belarus lao tajikistan result reveal negative typically insignificant relationship natural disaster intensity startup activity found two country governance characteristicsvoice accountability regulatory qualityhave positive association startup activity importantly tested found support central hypothesis study quality governance country moderate effect natural disaster startup activity specifically highquality governance positively moderate association natural disaster entrepreneurship startup activity word country lowquality governance expect entrepreneur establish new business promptly following disaster however country governance higher quality entrepreneur take advantage business opportunity disaster might create finding important several reason first finding useful entrepreneur eager exploit opportunity natural disaster create study offer idea expect following natural disaster given quality governance country second study useful policymakers want limit adverse impact natural disaster startup activity policymakers recognize new firm backbone new job creation likely invest potential innovative breakthrough leading employment future finally business startup natural disaster might help economy recover quickly discus finding policy implication detail later paper footnote roughly two three million new job almost new job created startup u httpswwwforbescomsitespetercohanwhystartupsmatterehttpswwwforbescomsitespetercohanwhystartupsmattere theory hypothesis natural disaster entrepreneurship activity unclear priori exactly natural disaster affect startup activity one hand crisis create opportunity scholar pointed chinese symbol crisis combine two simpler symbolsthe symbol danger one opportunity crisis time danger also time opportunity starbuck et al winston churchill reportedly said never let good crisis go waste therefore surprising entrepreneur often view crisis opportunity new business venture bruck et al research topic highlight loan demand spike natural disaster people attempt recover loss lending activity increase consumption investment increasing general business activity process create room new type business hence number startup might increase monllor murphy hand uncertainty often accompanies natural disaster given uncertainty entrepreneur find difficult navigate disequilibriaschultz increase risk failing might discourage new startup example natural disaster result breakdown supply chain network carvalho affect safety worker make difficult return normal operation chamleewright storr grube storr therefore decrease productivity boehm et al although new opportunity might available cost taking advantage opportunity might increase research show difficult entrepreneur receive loan berg schrader example found although demand credit increase disaster many household want borrow cope disaster access restricted risk preference affected disaster might also change cassar et al conducted experiment thai subject province worst affected tsunami found natural disaster make people risk averse important ramification entrepreneur inherently risky knight despite theoretical underpinnings empirical literature topic sparse study aware tested effect natural disaster entrepreneur activity boudreaux et al found natural disaster event decrease entrepreneur activity year immediately following natural disaster related study example escaleras register examined impact natural disaster foreign direct investment found natural disaster decrease foreign direct investment another related study found natural disaster impact mncs number subsidiary oh oetzel natural hazard devastate physical capital labor stock social infrastructure necessary commerce eg transportation communication network argue uncertainty effect likely dominate increased opportunity effect therefore make following hypothesis h natural disaster decrease startup activity country governance entrepreneur activity good governance country level affect business activity economist increasingly interested understanding role economy presidential address american economic association avinash dixit mentioned econlit show mention word governance end mentioned time dixit kaufmann et al postulated six different aspect good governance government effectiveness regulatory quality rule law voice accountability political stability control corruption effective government mean public civil service largely independent political pressure implementing policy highquality regulation mean rule formulated state promote private sector development rule law implies public confidence everyone treated equally law country higherquality rule law citizen perceive large contract enforced property right valued court provide justice level criminal activity also lower country voice accountability mean citizen express freely access free medium political stability mean le politically motivated violence terrorism within country finally lower corruption implies politician wellgoverned country le likely use power appropriate rent business bribery le common elite le likely capture state though different aspect good governance distinctly different concept interrelated example effective government also le corrupt inbuilt check balance nurture rule law dixit explained countrylevel governance necessary properly functioning market economy posited good governance associated security property enforcement contract facilitation collective action property right protection weak individual fear others take fruit endeavor also spend time guarding property country lax contract enforcement higher probability one participant business endeavor act opportunistically similarly lack infrastructure facilitate collective action eg quick justice punishment deviant behavior eg embezzlement extortion deters proper functioning market since good business requires cooperation many player unsurprisingly researcher international business theorized poor quality institution associated market failure peng et al influence mncs business strategy pinkse kolk research specifically examined connection entrepreneur countrylevel governance webb et al theorize effect formal informal institutional void entrepreneurship suggest lack quality formal institution discourage legal taxpaying entrepreneurship specifically posited society characterized severe formal institutional void entrepreneur incur relatively high cost gaining formal status receive minimal benefit return given minimal constraint imposed pursuing informal activity entrepreneur create value relatively le risk page mickiewicz olarewaju conducted case study farm run migrant nigeria noticed cost business higher lack quality institution anokhin wincent used indirect proxy measure country governance ie stage development found positively moderate effect startup rate innovation suggesting easier reap benefit entrepreneur country governance high quality aidis et al blamed weak institution stunting startup activity russia using data country nikolaev et al demonstrated institutional variablesparticularly related economic freedomare strongly correlated entrepreneurial activity footnote many study examine association institutional context entrepreneur activity conclude quality institution make easier foster new business eg bjrnskov fo boudreaux boudreaux et al b chowdhury et al estrin et al hwang powell stephan et al urbano et al based aforementioned study eg nikolaev et al believe lowquality countrylevel governance measure lead greater uncertainty ultimately higher cost capital holding variable net present value npv calculation constant higher cost capital reduces npv project would otherwise undertaken empirical research support conjecture globerman shapiro oh oetzel footnote globerman shapiro find country fail meet minimum threshold good governance unlikely receive fdi u multinational corporation among firm receive fdi find one better governance receive fdi oh oetzel find six measure countrygovernance associated foreign subsidiary unsurprisingly country good governance productive grow faster keefer knack hall jones startup particularly sensitive uncertainty fewer resource opaque fewer tool navigate ineffectivencumbersome regulation satisfy demand powerful public official also difficulty raising capital compared mncs reason propose following hypothesis h highquality governance increase startup activity quality governance moderate relationship natural disaster entrepreneurship activity entrepreneur expect country highquality governance quickly recover natural disaster country effective stable le corrupt government easier coordinate organize common good recovery process proceed much smoothly berke et al reviewed key finding literature regarding disaster recovery summarized key better recovery strong structural functional relation among various social unit capacity diffuse adapt implement plan policy innovation page country ineffective corrupt government political interference often delay policy implementation moreover communication various unit often problematic country lack infrastructure collective action dixit boudreaux et al find quality institution moderate effect foreign aid starting new business disaster footnote market process alone lead faster recovery process unless government play active role chamleewright sutter lowquality governance compromise proper deliberation planning implementation disaster recovery johnson olshansky drawn decade research disaster recovery compared disaster recovery effort china japan new zealand india indonesia u also compared response earthquake china japan china magnitude earthquake killed people displaced million china government tried reconstruct everything three year effort largely led central government without proper deliberation quality recovery suffered result highprofile development fell apart completion rural resident lost livelihood government relocated city contrast japan earthquake local government largely led recovery effort using funding national leader process involved many vigorous deliberation recovery effort made hastily infrastructure local government developed earthquakeproof considerably fewer cost resident reasonable argue free press rule law proper enforcement implicit explicit contract japanese government people lead proper deliberation planning thus country highquality governance entrepreneur likely expect le chaotic recovery involves proper planning implementation hence entrepreneur risk assessment future business opportunity lower furthermore country highquality governance private endeavor exploit opportunity disaster likely proceed much quickly without political interference country regulation encourage private sector development therefore entrepreneur le likely fear political extortion establishing new business together lower assessment risk lower implicit explicit cost starting business encourage entrepreneur establish new startup demand increase following disaster based reasoning posit following hypothesis h highquality country governance positively moderate effect natural disaster startup activity rate data method data source sample test hypothesis gathered data variety source began sample collecting data new business startup rate world bank entrepreneurship survey database merged sample country governance data world governance indicator wgi wgi include observation sample period observation remained merge world bank data next merged sample natural disaster data emergency event database emdat emdat includes observation sample period observation remained merge finally merged sample set control variable gathered world bank world bank business survey merge observation remained final sample includes data panel country report definition data source variable table report summary statistic key variable country table important note follow recent call entrepreneur management literature urging scholar focus le statistical significance effect size eg anderson et al meyer et al specifically report exact pvalues report asterisk regression table indicating statistical significance however use p threshold hypothesis testing lastly report effect size graphically using confidence interval dependent variable dependent variable new business startup rate number newly registered limitedliability firm percentage country workingage population age normalized variable come world bank entrepreneurship survey database used histogram examine variable distribution found powerlaw distributed consistent recent evidence entrepreneurship study crawford et al crawford et al result used natural logarithm transform measure resulted normal distribution see figure footnote power law distribution refers highly skewed distribution outlier account disproportionate amount total distribution output crawford et al explanatory variable particularly interested two explanatory variable natural disaster country governance data natural disaster came emdat maintained centre research epidemiology disaster cred disaster included database satisfies least one following criterion person killed person affected injured left homeless appeal international assistance official declaration state emergency analysis includes following natural disaster earthquake flood slide volcanic eruption windstorm disaster data available present used data overlapped data oursample period study including attempt quantify intensity disaster use measure based number people affected injured killed eddat example see loayza et al klomp valckx noy boudreaux et al therefore define intensity natural disaster sum total number people affected injured homeless due natural disaster transform variable using natural logarithm add one account observation zero footnote affected requiring immediate assistance period emergency injured suffering physical injury trauma illness requiring immediate medical assistance direct result disaster homeless people whose house destroyed heavily damaged therefore need shelter event footnote log undefined dropped therefore use transformation log log gathered data wgi measure variable country governance wgi measure country governance using six different measure voice accountability political stability government effectiveness regulatory quality rule law control corruption six indicator based opinion country expert scaled standard normal distribution mean sd indicator higher score reflect higherquality country governance lower score reflect lowerquality country governance increase robustness finding included six measure model table provides detail regarding variable definition control variable addition explanatory variable also included several control variable mitigate omitted variable bias concern including control variable adjusted effect explanatory variable dependent variable gathered control variable world bank business survey first gathered data economic financial indicator gdp per caput gdp growth financial credit trade influence entrepreneurship activity country governance economic indicator like gdp per caput gdp growth capture economic activity country used natural logarithm transform gdp per caput measured gdp growth annual growth rate gross domestic product per caput thus log real gdp per caput using purchasing power parity gdp growth measured annual percentage change gdp similarly financial indicator financial credit capture country economic activity since measure domestic credit provided financial sector variable expressed percentage gdp final economic indicator trade capture trade openness economy country larger amount trade others expressed percentage gdp likely developed also adjusted model reflect fact different country varying entry regulation associated starting new business based work djankov et al variable capture ease difficulty starting new business gathered variable world bank business survey cost business startup procedure measure total cost required complete procedure percentage gross national income gni per caput time required start business measured number day finally number startup procedure measure total number procedure required register business idea behind business indicator expect business creation le costly requires le time requires fewer procedure de soto originally found took team eighthour day open business peru variable range half day new zealand day suriname finally included three demographic variable might influence either entrepreneurship activity country governance largest population measured largest city population expressed percentage country total population populationdensity measure people per square kilometer defined population divided land area land area measure area land square kilometer using log transformation three demographic indicator might influence entrepreneurship activity entrepreneurship likely located densely populated urban area table report descriptive statistic correlation matrix variable negative significant correlation natural disaster new business startup activity significant positive correlation six country governance indicator new business startup activity provides preliminary evidence support hypothesis hypothesis require sophisticated test reaching conclusion additionally take average day start business almost eight procedure cost roughly percent gni clearly starting business trivial task many location also significant correlation six governance indicator many variable modestly correlated gdp per caput six governance indicator often strongly correlated additional robustness test appendix table excluded gdp per caput model found result qualitatively similar model empirical model represented followsstartupitalphabetadisastersitsumjgammaj governit sumjdeltajleftdisastersit time governit rightsumkmukcontrolsit sumletalregionsl sumtlambdatyeart varepsilonit startup natural logarithm new business startup rate number new firm divided working age population country disaster natural logarithm natural disaster intensity govern vector six country governance indicator disaster time govern vector interaction six country governance indicator control vector previously described control variable region vector region dummy year set year dummy varepsilon idiosyncratic error term included region year dummy adjust regionspecific yearspecific difference country time estimated model using linear regression model ie ordinary least square model assume homoscedasticity error term independently identically distributed adjusted assumption two way first dependent variable logtransformed greatly reduces heteroscedasticity concern second used white robust standard error consistent presence heteroscedasticity white footnote consistent oh oetzel use country fixed effect countrygovernance change much span year therefore using countryfixed effect would throw away time invariant component governance measure would equivalent academic call throwing baby water angrist pischke missingpagefail startup activity four six indicator positively associated rate startup activity remaining two indicator negatively associated rate startup activity however two indicatorsvoice accountability beta p regulatory quality beta p positive statistically significant association rate startup activity thus evidence support hypothesis fully supported therefore explore relationship detail table discus implication discussion section moderating effect quality governance hypothesis table included interaction term natural disaster six governance indicator model test hypothesis country quality governance moderate relationship natural disaster entrepreneur activity found overall support hypothesis result suggest natural disaster discourage entrepreneur activity quality governance attenuates adverse effect example column table report natural disaster negatively though significantly associated new business startup rate beta p voice accountability beta p attenuates effect consistent relationship remaining governance indicator political stability government effectiveness regulatory quality rule law control corruption result indicate country quality governance higher natural disaster positive effect new business startup activity word number startup increase following disaster country good governance quality number startup decrease following disaster country lower governance quality thus hypothesis supported missingpageempty figure plot moderating effect two governance indicator government effectiveness regulatory quality result indicate natural disaster negatively associated new business startup activity effect becomes smaller positive quality government effectiveness regulatory quality increase specifically estimate suggest ten percent increase natural disaster activity associated one percent decrease new business startup activity government effectiveness low percent increase new business startup activity government effectiveness high regarding regulatory quality indicator estimate suggest ten percent increase natural disaster activity associated one percent decrease new business startup activity regulatory quality low percent increase new business startup activity regulatory quality high figure plot moderating effect last two governance indicator namely rule law control corruption result indicator similar previous finding natural disaster negatively associated new business startup activity effect becomes smaller positive rule law score control corruption quality score increase estimate suggest ten percent increase natural disaster activity associated percent decrease new business startup activity rule law low percent increase new business startup activity rule law high regarding control corruption indicator estimate suggest ten percent increase natural disaster activity associated one percent decrease new business start activity control corruption low percent increase new business startup activity control corruption high analytic extension shortterm longterm effect focus study natural question arises whether moderating role country quality governance persists year examine short longterm effect lagging natural disaster variable two three four year including lag model better able examine rate startup activity two three four year natural disaster instance oneyear lag suggests natural disaster effect next year year true two three four year result table indicate natural disaster effect startup activity persist short term year long term also found similar weaker evidence regarding fouryear lag structure nevertheless found country governance positively moderate relationship natural disaster startup activity two year three year possibly four year finding also indicate type country governance matter found evidence government effectiveness regulatory quality rule law control corruption evidence weaker voice accountability political stability finding differ disaster type another extension finding consider whether finding differ disaster type disaster similar effect startup activity heterogenous address question separated disaster climatic geologic category following literature boudreaux et al crespo cuaresma et al skidmore toya climatic disaster include flood cyclone hurricane blizzard typhoon tornado storm geologic disaster include volcanic eruption natural explosion landslide avalanche earthquake result available supplemental appendix table suggest moderating effect statistically significant geologic disaster climatic disaster however result likely nuanced instance comparison moderating figure disaster type suggests primarily negative effect climatic disaster rate startup activity figure aa yet primarily positive effect geologic disaster rate startup activity figure aa marginal effect climatic disaster become positive becomes positive highquality institution typically score greater contrast geologic disaster primarily positive marginal effect disaster rate startup activity negative almost opposite fashion marginal effect negative lowquality institution thus observe statistically significant moderating effect geologic disaster table believe finding bit nuanced discussion conclusion purpose paper investigate whether country quality governance moderate relationship exogenous natural disaster new business startup activity study contributes literature demonstrating country quality governance matter relationship natural disaster likelihood new business startup activity highquality countrylevel governance make country resilient natural disaster result suggest two possibility country governance quality high entrepreneur expect country quickly recover natural disaster entrepreneur better position take advantage new business opportunity aftermath natural disaster finding important contribution although natural disaster devastating frequency increasing know little make one country resilient others dealing disaster following quotation illustrates point organization society successfully adjust even thrive amid adversity others fail editorial would like inspire management scholar take grand challenge studying role functioning organization adverse natural social event van der vegt et al recently researcher pointed lack research topic eg williams shepherd documenting highquality countrylevel governance associated new business startup natural disaster research suggests formal institution government effectiveness lower corruption private sectorfriendly regulation rule law citizen ability voice opinion freely help country recover also allow entrepreneur thrive postdisaster period fresh perspective study focusing line research suggest informal institution cultural trait like social capitalthe norm network society enable cooperationplay major role country recovery natural disaster aldrich however role formal institution largely ignored study fill gap highlighting formal institution also play important role facilitating postdisaster recovery startup activity birkmann et al theorized extreme event disaster create window opportunity change study suggests may possible country formal governance strong otherwise business activity might suffer mentionedin introduction oh oetzel found one aspect formal institutionregulatory qualitypositively moderate effect natural disaster mncs subsidiarylevel investment contrast found aspect highquality countrylevel governance positively moderate effect natural disaster startup activity specifically based oh oetzels study government effectiveness rule law level corruption affect mncs decision increase number foreign subsidiary year disaster however research demonstrates aspect country governance positively affect number new business startup year following disaster result consistent idea business bear cost lowquality governance disaster startup disproportionately affected since often ill equipped navigate poor governance natural disaster strike oh oetzel noted possibility entrepreneurial firm likely different decisionmaking rule process disaster due difference risktaking behavior organizational responsiveness page result confirm oh oetzels suspicion effect institution moderating natural disaster effect new business startup even stronger entrepreneurship researcher found institutional quality especially regulatory framework positively affect number startup regulatory framework appears affect replicative entrepreneurship highimpact entrepreneurship stenholm et al study extends stream literature demonstrating regulatory quality impact number startup type institutional quality affect entrepreneurship aftermath natural disaster therefore result suggest impact institution might particularly valuable event negative shock economy although investigate likelihood starting new business implication study also related topicthe survival small business respect extend several recent piece research entrepreneurship examine survival small firm davlasheridze geylani find small business likely thrive better loan access struck natural disaster hadjielias et al suggest psychological resilience small business owner increase possibility business survival disaster grozinger et al echo similar thought empirically document organization psychological capital captured solidarity cooperation citizenship behavior employee positively associated innovation survival disaster extend study study suggests higherquality formal institution might another factor help survival small business thrive natural disaster study also managerial implication churchill lewis classified five stage new business startup activity theorized first stage entrepreneur ask following question get enough customer deliver product provide service well enough become viable business expand one key customer pilot production process much broader sale base enough money cover considerable cash demand startup phase page result indirectly suggest country highquality governance entrepreneur expect infrastructure improve quickly able reach customer provide service expand quickly confident obtaining resource loan bank grow easily policy perspective study highlight importance designing policy strengthen country governance quality research demonstrates highquality institution positively associated foreign direct investment fdi globerman shapiro highgrowth entrepreneurial activity bowen de clercq also better withstand initial disaster shock gdp growth rate noy raschky research show highquality country governance make country resilient adverse effect natural disaster startup activity limitation future research one limitation unit analysis measure new business startup activity country governance countryyear level therefore claim supply chain network disrupted implicitly assume disruption occurred entire country however accurate particularly country large example hurricane katrina caused severe damage louisiana rest country affected believe one limitation study albeit one difficult solve variation institutional quality country level ie country governance case alternative way address question investigated would use singlecountry study variation institutional quality different region approach would precise capturing cost natural disaster opportunity create could provide additional insight hypothesis downside strategy le heterogeneity institutional quality within country country thus certain benefit broadening perspective conduct multicountry study due data limitation also unable examine type new startup likely moderated quality governance dataset provides information type startup characteristic entrepreneur could used better understand moderating role quality governance disaster another limitation assumed quality institution affected natural disaster largely true short term assumption inaccurate long term natural disaster strike often inflow aid government nongovernment organization foreign country partly altruistic reason partly political reason garrett sobel sobel leeson sudden inflow capital various source increase corruption leeson sobel posit part u may corrupt struck natural disaster often idea disaster trigger federally funded relief increase chance theft make culture corrupt time inflow cash different source susceptibility corruption may lead regulation region prone natural disaster however adverse impact disaster culture regulation gradual nevertheless examining level corruption regulation change natural disaster change affect subsequent likelihood startup long term possible avenue future research also want reiterate result indicate quality institution shortterm increase number new firm registered natural disaster limitation caveat bastiat famous broken window fallacy postulated shopkeeper son break glass father store society worse better simply resource spent replacing glass could used elsewhere idea extension natural disaster mean country worse natural disaster however diaz larroulet point economist agree example natural disaster lead significant innovation considerably impact economy one could argue may longterm benefit harbinger creative destruction predicts higher growth rate thus new business getting established hallegatte duma theory plausible extent likelihood longterm benefit due natural disaster hard ass focus study future research could examine question greater depth example benefit may incur welldeveloped country access credit venture capital accessible demonstrating country quality governance make country resilient natural disaster study raise new question example recent study shown natural disaster risk affect firm financing policy amount cash type debt firm performance huang et al study indirectly suggests effect natural disaster may moderated quality countrylevel governance another possible extension study would compare moderating role quality governance investment decision foreign domestic firm natural disaster ability foreign domestic firm navigate changing landscape disaster might differ good country governance might moderate effect research also raise similar question emerging strand literature natural disaster economic growth unclear exactly natural disaster affect economic growth economic model use schumpeter theory creative destruction argue disaster catalyst upgrading destroyed capital stock hence result longterm economic growth crespo cuaresma et al toya skidmore toya skidmore found climatic disaster positively correlated economic growth others disagree arguing natural disaster lead permanent destruction physical human capital negative deviation previous growth trajectory romer felbermayr groschl used disaster data geophysical meteorological source rather insurance company regarding country spanning three decade found worst five percent disaster year characterized growth damage least percent bergholt lujala also found negative effect natural disaster growth considerable study indirectly raise possibility natural disaster impact economic growth might moderated quality country governance factor rule law corruption voice accountability regulatory quality reference aidis r estrin mickiewicz institution entrepreneurship development russia comparative perspective journal business venturing doihttpsdoiorgjjbusventhttpsdoiorgjjbusvent aldrich p building resilience social capital postdisaster recovery university chicago press anderson b wennberg k mcmullen j enhancing quantitative theorytesting entrepreneurship research journal business venturing doihttpsdoiorgjjbusventhttpsdoiorgjjbusvent angrist j pischke j mostly harmless econometrics empiricist companion princeton university press anokhin wincent j startup rate innovation crosscountry examination journal international business study doihttpsdoiorgijbshttpsdoiorgijbs bastiat f economic harmony irvingtononhudson ny foundation economic education baumol w j entrepreneurship productive unproductive destructive journal political economy doihttpsdoiorghttpsdoiorgx benson c clay e understanding economic financial impact natural disaster world bank publication doihttpsdoiorghttpsdoiorg berg g schrader j access credit natural disaster relationship lending journal financial intermediation doihttpsdoiorgjjfihttpsdoiorgjjfi bergholt lujala p climaterelated natural disaster economic growth armed civil conflict journal peace research doihttpsdoiorghttpsdoiorg berke p r kartez j wenger recovery disaster achieving sustainable development mitigation equity disaster doihttpsonlinelibrarywileycomdoijtbxhttpsonlinelibrarywileycomdoijtbx birkmann j buckle p jaeger j pelling setiadi n garschagen et al extreme event disaster window opportunity change analysis organizational institutional political change formal informal response megadisasters natural hazard doihttpsdoiorgshttpsdoiorgs bjornskov c fo n j institution entrepreneurship economic growth know still need know academy management perspective doihttpsdoiorgamphttpsdoiorgamp boehm c e flaaen pandalainayar n input linkage transmission shock firmlevel evidence tohoku earthquake review economics statistic doihttpsdoiorgresthttpsdoiorgrest boudreaux c j jumping great gatsby curve institution facilitate entrepreneurship intergenerational mobility journal institutional economics doihttpsdoishttpsdois boudreaux c j escaleras p skidmore natural disaster entrepreneurship activity economics letter doihttpsdoiorgjeconlethttpsdoiorgjeconlet boudreaux c j jha escaleras weathering storm foreign aid institution affect entrepreneurship activity following natural disaster entrepreneurship theory practice forthcoming doihttpsdoiorghttpsdoiorg boudreaux nikolaev kleinboudreaux et alb boudreaux c j nikolaev b n klein p b sociocognitive trait entrepreneurship moderating role economic institution journal business venturing doihttpsdoiorgjjbusventhttpsdoiorgjjbusvent bowen de clercqbowen de clercq bowen h p de clercq institutional context allocation entrepreneurial effort journal international business study doihttpsdoiorgpalgravejibshttpsdoiorgpalgravejibs bruck lussa tavaresbruck et al bruck lussa f tavares j entrepreneurship role extreme event european journal political economy doihttpsdoiorgshttpsdoiorgs carvalhocarvalho carvalho v micro macro via production network journal economic perspective doihttpsdoiorgjephttpsdoiorgjep cassar healy von kesslercassar et al cassar healy von kessler c trust risk time preference natural disaster experimental evidence thailand world development doihttpsdoiorgjworlddevhttpsdoiorgjworlddev chamleewrightchamleewright chamleewright e cultural political economy recovery social learning postdisaster environment routledge chamleewright storr chamleewright e storr v h there place like new orleans sense place community recovery ninth ward hurricane katrina journal urban affair doihttpsdoiorgjxhttpsdoiorgjx chowdhury audretsch belitskichowdhury et al chowdhury f audretsch b belitski institution entrepreneur quality entrepreneurship theory practice doihttpsdoiorghttpsdoiorg churchill lewischurchill lewis churchill n c lewis v l five stage small business growth harvard business review crawford aguinis lichtenstein davidsson mckelvey crawford c aguinis h lichtenstein b davidsson p mckelvey b power law distribution entrepreneurship implication theory research journal business venturing doihttpsdoiorgjjbusventhttpsdoiorgjjbusvent crawford mckelvey lichtensteincrawford et al crawford c mckelvey b lichtenstein b b empirical reality entrepreneurship power law distributed outcome call new theory method journal business venturing insight doihttpsdoiorgjjbvihttpsdoiorgjjbvi crespo cuaresma hlouskova obersteincrespo cuaresma et al crespo cuaresma j hlouskova j obersteiner natural disaster creative destruction evidence developing country economic inquiry doihttpsdoiorgjxhttpsdoiorgjx davlasheridze geylandavlasheridze geylan davlasheridze geylan p c small business vulnerability flood effect disaster loan small business economics doihttpsdoiorgshttpsdoiorgs de sotode soto de soto h mystery capital capitalism triumph west fails everywhere else basic civitas book diaz larrouletdiazroulet diaz larroulet c impact institution aftermath natural disaster cato j doihttpsdoiorgcjhttpsdoiorgcj diazroulet dixitdixit dixit governance institution economic activity american economic review doihttpsdoiorgaerhttpsdoiorgaer djankov la porta lopezdesilanesdjankov et al djankov la porta r lopezdesilanes f shleifer regulation entry quarterly journal economics doihttpsdoiorghttpsdoiorg escalerasrescalerasregister escaleras register c natural disaster foreign direct investment land economics doihttpsdoiorglehttpsdoiorgle estrin korosteleva nickiewiczestrin et al estrin korosteleva j nickiewicz institution encourage entrepreneurial growth aspiration journal business venturing doihttpsdoiorgjjbusventhttpsdoiorgjjbusvent felbermayrgroschlfelbermayrgroschl felbermayr g nickiewicz j naturally negative growth effect natural disaster journal development economics doihttpsdoiorgjidevecohttpsdoiorgjideveco garrettsobel garrett sobel r political economy fema disaster payment economic inquiry doihttpsdoiorgeicbighttpsdoiorgeicbig globermanshapiroglobermanshapiro globerman shapiro governance infrastructure u foreign direct investment journal international business study doihttpsdoiorgpalgravejibshttpsdoiorgpalgravejibs grozinger wolff ruf mooggrozinger et al grozinger ac wolff ruf p j moog p power shared positivity organizational psychological capital firm performance exogenous crisis small business economics doihttpsdoiorgshttpsdoiorgs grubestorrgrube grube l e storr v h embedded entrepreneur postdisaster community recovery entrepreneurship regional development doihttpsdoiorghttpsdoiorg hadjielias christofi tardahadjielias et al hadjielias e christofi tarda contextualizing small business resilience covid pandemic evidence small business ownermanagers small business economics doihttpsdoiorgshttpsdoiorgs halljoneshalljonesjones hall r e jones c country produce much output per worker others quarterly journal economics doihttpsdoiorghttpsdoiorg hallegattedumashallegatte hallegatte duma p natural disaster positive consequence investigating role embodied technical change ecological economics doihttpsdoiorgjecoleconhttpsdoiorgjecolecon huang kerstein wanghuang et al huang h h kerstein j wang c impact climate risk firm performance financing choice international comparison journal international business study doihttpsdoiorgshttpsdoiorgs hwang powellhwang powell hwang h powell w w institution entrepreneurship handbook entrepreneurship research pp springer johnsonolshanskyolshansky johnson l olshansky r b great disaster indepth analysis six country managed community recovery lincoln institute land policy kaufmann kraay zoidokaufmann et al kaufmann kraay zoido p governance matter world bank policy research working paper doihttpsdoiorghttpsdoiorg keeferknackkeeferknack keefer p knack dont poor country catch crossnational test institutional explanation economic inquiry doihttpsdoiorgjtbxhttpsdoiorgjtbx kaufmannkaufmann et alklomp j valckx k natural disaster economic growth metaanalysis global environmental change doihttpsdoiorgjgloenvchahttpsdoiorgjgloenvcha knight knight f h risk uncertainty profit vol houghton mifflin leeson sobel leeson p sobel r weathering corruption journal law economics doihttpsdoiorghttpsdoiorg loayza et al loayza n v olaberria e rigolini j christiaensen l natural disaster growth going beyond average world development doihttpsdoiorgjworlddevhttpsdoiorgjworlddev meyer et al meyer k e van witteloostuijn beugelsdijk whats p reassessing best practice conducting reporting hypothesistesting research journal international business study doihttpsdoiorgshttpsdoiorgs mickiewicz olarewaju mickiewicz olarewaju new venture evolution migrant institutional void lesson shonga farm nigeria international small business journal doihttpsdoiorghttpsdoiorg monllor murphy monllor j murphy p j natural disaster entrepreneurship creation destruction conceptual approach international journal entrepreneurial behavior research doihttpsdoiorgijebrhttpsdoiorgijebr nikolaev et al nikolaev b n boudreaux c j palich l crosscountry determinant earlystage necessity opportunitymotivated entrepreneurship accounting model uncertainty journal small business management doihttpsdoiorgjsbmhttpsdoiorgjsbm noy noy macroeconomic consequence disaster journal development economics doihttpsdoiorgjjdevecohttpsdoiorgjjdeveco oh oetzel oh c h oetzel j multinationals response major disaster subsidiary investment vary response type disaster quality country governance strategic management journal doihttpsdoiorgsmjhttpsdoiorgsmj peng et al peng w wang jiang institutionbased view international business strategy focus emerging economy journal international business study doihttpsdoiorgpalgravejibshttpsdoiorgpalgravejibs pinkse kolk pinkse j kolk multinational enterprise climate change exploring institutional failure embeddedness journal international business study doihttpsdoiorgijbshttpsdoiorgijbs raschky raschky p institution loss natural disaster natural hazard earth system science doihttpsdoiorgnhesshttpsdoiorgnhess romer romer p endogenous technological change journal political economy part s doihttpsdoiorgwhttpsdoiorgw sadowski sutter sadowski n c sutter hurricane fatality hurricane damage safer hurricane damaging southern economic journal doihttpsdoiorgjtbxhttpsdoiorgjtbx schultz schultz w value ability deal disequilibria journal economic literature skidmore toya skidmore toya h natural disaster promote longrun growth economic inquiry doihttpsdoiorgeihttpsdoiorgei skidmore toya sobel sobel r testing baumol institutional quality productivity entrepreneurship journal business venturing doihttpsdoiorgjjbusventhttpsdoiorgjjbusvent sobel leeson sobel r leeson p government response hurricane katrina public choice analysis public choice doihttpsdoiorgshttpsdoiorgs starbuck et al starbuck w h greve hedberg b respondonding crisis journal business administration stenholm et al stenholm p ac z j wuebker r exploring countrylevel institutional arrangement rate type entrepreneurial activity journal business venturing doihttpsdoiorgjjbusventhttpsdoiorgjjbusvent stephan et al stephan u uhlaner l stride c institution social entrepreneur role institutional void institutional support institutional configuration journal international business study doihttpsdoiorgjibshttpsdoiorgjibs sutter sutter culture economics recovery disaster study emergent order toya skidmore toya h skidmore economic development impact natural disaster economics letter doihttpsdoiorgjeconlethttpsdoiorgjeconlet urbano et al urbano aparicio audretsch twentyfive year research institution entrepreneurship economic growth learned small business economics doihttpsdoiorgshttpsdoiorgs van der vegt et al van der vegt g essen p wahlstrom george g managing risk resilience academy management doihttpsdoiorgamjhttpsdoiorgamj webb et al webb j w khoury hitt influence formal informal institutional void entrepreneurship entrepreneurship theory practice doihttpsdoiorghttpsdoiorg white white h heteroskedasticityconsistent covariance matrix estimator direct test heteroskedasticity econometrica doihttpsdoiorghttpsdoiorg williams shepherd williams shepherd building resilience providing sustenance different path emergent venture aftermath haiti earthquake academy management journal doihttpsdoiorgamjhttpsdoiorgamj missingpageempty figure dependent variable startup rate normally distributed logtransformation figure effect disaster startup rate moderated voice accountability political stability confidence interval figure effect disaster startup rate moderated government effectiveness regulatory quality confidence interval figure effect disaster startup rate moderated rule law control corruption confidence interval
Original Title: Natural Disasters, Entrepreneurship Activity, and the Moderating Role of
  Country Governance
Original Transcription: Natural Disasters, Entrepreneurship Activity, and the

Moderating Role of Country Governance

**Christopher J. Boudreaux**

Florida Atlantic University

College of Business

777 Glades Road, Boca

Raton, FL 33431

cboudreaux@fau.edu

**Anand Jha**

Wayne State University

Mike Ilitch School of

Business

2771 Woodward Ave,

Detroit, MI 48201

anand.jha@wayne.edu.

**Monica Escaleras**

Florida Atlantic University

College of Business

777 Glades Road, Boca

Raton, FL 33431

mescaleras@fau.edu

**ABSTRACT**

The purpose of this paper is to investigate if a country's quality of governance moderates the effect of natural disasters on start-up activity within that country. We test our hypotheses using a panel of 95 countries from 2006 to 2016. Our findings suggest that natural disasters discourage start-up activity in countries that have low-quality governance but encourage start-up activity in countries that have high-quality governance. Moreover, our estimates reveal that natural disasters' effects on start-up activity persist for the short term (1-3 years) but not the long term. Our findings provide new insights into how natural disasters affect entrepreneur activity and highlight the importance of country governance during these events.

**PLAIN ENGLISH SUMMARY**

Natural disasters encourage more start-up activity, but only in countries that have high-quality governance. In countries with low-quality governance, natural disasters discourage start-up activity. Moreover, our estimates reveal that natural disasters' effects on start-up activity persist for the short term (1-3 years) but not the long term. Our findings provide new insights into how natural disasters affect entrepreneur activity and highlight the importance of country governance during these events. These findings have important implications for both researchers and policymakers. Researchers should note the effect of natural disasters on entrepreneur activity is nuanced and contingent upon country governance. Our study is also useful to policymakers who want to limit the adverse impact of natural disasters on start-up activity. Policymakers recognize these new firms are the backbone of new job creation, and they are more likely to invest in potential innovative breakthroughs, leading to more employment in the future.

**Keywords:** country governance, entrepreneur, institutions, natural disasters, start-ups

**JEL Classifications:** L26, M13, O11, O43, Q54

## 1 Introduction

In the 1970s, there were fewer than 100 natural disasters in a year. In 2010, this number approached 400. Although the number of deaths due to natural disasters is decreasing, losses due to these disasters are not.1 According to a report by the World Bank dedicated to understanding the financial and economic impacts of natural disasters, "Between the 1950s and the 1990s, the reported global cost of natural disasters increased 15-fold. Major natural catastrophes in the 1990s caused economic losses estimated at an average $66 billion per year (in 2002 prices)" (Benson and Clay 2004). In 2018, natural disasters cost the world $160 billion.2

Footnote 1: People are increasingly living and buying property in natural disaster-prone areas as they feel safer due to better technology to predict the timings of these disasters and the availability of insurance (Sadowski and Sutter 2005).

Footnote 2: [https://weather.com/science/environment/news/2019-01-09-disasters-cost-damage-climate-change](https://weather.com/science/environment/news/2019-01-09-disasters-cost-damage-climate-change)

Despite the increasing costs that natural disasters impose on an economy, academic research has seldom investigated how to mitigate the negative impact of a natural disaster. However, one notable exception has examined whether the country's governance quality mitigates the adverse impact of disasters on multi-national corporation (MNC)'s subsidiary investment (Oh and Oetzel 2011). The authors examined the impact of different types of disasters--including natural disasters--on the MNC's subsidiary investment to investigate whether the quality of governance mitigates the adverse effect of disasters on the MNC's investment.3 They found that when the host country has better regulatory quality, natural disasters appear to increase the number of subsidiaries, suggesting that high-quality regulations help MNCs exploit business opportunities arising after a natural disaster. Other aspects of governance (government effectiveness, the rule oflaw, voice and accountability, political stability and control of corruption) did not matter. One explanation is that MNCs are in a better position to deal with a natural disaster, they are likely to be insured, and they often have the option of channeling resources from other parts of the world to exploit opportunities that natural disasters create.

In contrast with MNCs, new entrepreneurs often have limited resources and are thus ill equipped to deal with disasters. Natural disasters not only disrupt networks and destroy infrastructure, making day-to-day operations costly (Boehm, Flaanen, & Pandalai-Nayar, 2018), but they also present new opportunities (Cuaresma, Hlouskova, & Obersteiner, 2008). And we know from prior literature that the quality of institutions incentivizes entrepreneurs to start new businesses (Nikolaev et al. 2018; Baumol 1990; Sobel 2008; Estrin et al. 2013). Whether entrepreneurs can exploit the opportunities and limit the costs associated with natural disasters may depend on the quality of governance in the country. High-quality governance might lessen a natural disaster's adverse impact and grease its positive impact on starting a new business. For example, if a country's residents are free to voice public concerns, entrepreneurs will anticipate a quicker recovery from the damage done to infrastructure. Moreover, entrepreneurs might anticipate more relief material and better access to credit with more effective governance. If a country's governance facilitates disaster recovery and greases entrepreneurs' desires to exploit opportunities, we expect the number of start-ups to increase following a natural disaster in a country with high-quality governance. However, we expect no such effect in countries that lack good governance.

Motivated by this line of thought, and with the goal of understanding how a country's quality of institutions might affect start-up activity following a natural disaster, we begin by investigating the association between natural disasters and the rate of start-up activity. Next, we investigate whether the quality of governance affects the rate of start-up activity. We then focus on the central question of this study: does the quality of governance in a country moderate the relationship between natural disasters and start-up activity? We hypothesize the adverse effect of natural disasters on the rate of start-up activity is more severe when countries have low-quality governance, but that the effect is less severe or even positive when countries have high-quality governance. We develop hypotheses using three strands of literature regarding entrepreneurship, natural disasters, and the role of country-level governance in fostering business activity. To test these hypotheses, we collected data from the World Bank's Entrepreneurship Survey and Database, which provides data on the annual rate of new start-ups in a country. Next, using data form the Emergency Events Database we constructed a measure of natural disaster intensity by adding the total number of people affected, injured, and made homeless due to a natural disaster, and then merged this variable with the World Bank data. Finally, we merged these variables with measures of governance from the World Governance Indicators (government effectiveness, regulatory quality, rule of law, voice and accountability, political stability, and control of corruption). Our sample is comprised of 95 countries from 2006 to 2016 and includes countries with high-quality institutions such as Norway, Finland, and Switzerland as well as countries with low-quality institutions such as Saudi Arabia, Belarus, Laos, and Tajikistan.

Our results reveal a negative but typically insignificant relationship between natural disaster intensity and start-up activity. We found that only two country governance characteristics--voice and accountability and regulatory quality--have a positive association with start-up activity. More importantly, we tested and found support for the central hypothesis of our study: the quality of governance in a country moderates the effect of natural disasters on start-up activity. Specifically, high-quality governance _positively_ moderates the association between natural disasters and entrepreneurship start-up activity. In other words, when countries have low-quality governance, we cannot expect entrepreneurs to establish a new business promptly following a disaster. However, when a country's governance is of higher quality, entrepreneurs can take advantage of the business opportunities a disaster might create.

These findings are important for several reasons. First, our findings are useful for entrepreneurs who are eager to exploit the opportunities that natural disasters create. Our study offers an idea of what to expect following a natural disaster given the quality of governance in the country. Second, our study is useful to policymakers who want to limit the adverse impact of natural disasters on start-up activity. Policymakers recognize that these new firms are the backbone of new job creation,4 and they are more likely to invest in potential innovative breakthroughs, leading to more employment in the future. Finally, more business start-ups after a natural disaster might help the economy to recover more quickly. We discuss these findings and their policy implications in more detail later in the paper.

Footnote 4: Between 1977 and 2009 roughly two to three millions new jobs (almost all of the new jobs) were created by startups in the U.S. [https://www.forbes.com/sites/petercohan/2011/06/27/why-start-ups-matter/#59238e143620](https://www.forbes.com/sites/petercohan/2011/06/27/why-start-ups-matter/#59238e143620)

## 2 Theory and Hypotheses

### Natural disasters and entrepreneurship activity

It is unclear _a priori_ exactly how natural disasters affect start-up activity. On the one hand, crises create opportunities. As scholars have pointed out, "The Chinese symbol for crisis combines two simpler symbols--the symbol for danger and the one for opportunity. Crises are times of danger, but they are also times of opportunity" (Starbuck et al. 1978). Winston Churchill reportedly said, "Never let a good crisis go to waste."5 It is therefore not surprising that entrepreneurs often view a crisis as an opportunity for new business ventures (Bruck et al. 2011). Research on the topic highlights how loan demand spikes after a natural disaster as people attempt to recover their losses. This lending activity increases consumption and investment, increasing general business activity in the process. This can create room for new types of businesses; hence, the number of start-ups might increase (Monllor and Murphy 2017).

On the other hand, uncertainty often accompanies natural disasters. Given this uncertainty, entrepreneurs find it more difficult to navigate _disequilibria_(Schultz 1975) which increases the risk of failing and might discourage new start-ups. For example, a natural disaster can result in the breakdown of supply chain networks (Carvalho 2014), affect the safety of workers, make it difficult to return to normal operation (Chamlee-Wright and Storr 2009; Grube and Storr 2018), and therefore decrease productivity (Boehm et al. 2019). Although new opportunities might be available, the cost of taking advantage of those opportunities might increase. Research shows that it can be difficult for entrepreneurs to receive a loan. Berg and Schrader (2012), for example, have found that although the demand for credit increases after a disaster, just when many households want to borrow to cope with the disaster, their access is restricted. The risk preference of those affected by the disaster might also change. Cassar et al. (2017), who conducted experiments with 334 Thai subjects in the province worst affected by the 2004 tsunami, have found that natural disasters can make people more risk averse. This has important ramifications for entrepreneur, which is inherently risky (Knight 1921).

Despite these theoretical underpinnings, the empirical literature on this topic is sparse. The only study we are aware of that has tested the effect of natural disasters on entrepreneur activity is Boudreaux et al. (2019a, 2021) which found that natural disaster events decrease entrepreneur activity in the year immediately following a natural disaster. There are a few related studies. For example, Escaleras and Register (2011) have examined the impact of natural disasters on foreign direct investment. They have found that natural disasters decrease foreign direct investment. Another related study has found that natural disasters have no impact on MNCs' numbers of subsidiaries (Oh and Oetzel 2011). Natural hazards can devastate physical capital, labor stocks, and the social infrastructure necessary for commerce (e.g., transportation and communication networks).

We argue that the uncertainty effect will likely dominate the increased opportunity effect, and therefore we make the following hypothesis:

_H1: Natural disasters decrease start-up activity._

**2.2. Country governance and entrepreneur activity**

Good governance at the country level affects business activity, and economists are increasingly interested in understanding its role in the economy. In his presidential address to the American Economic Association in 2009, Avinash Dixit mentioned that "EconLit shows only 5 mentions of the word governance in the 1970s; by the end of 2008, it was mentioned 33,177 times" (Dixit 2009).

Kaufmann et al. (1999) have postulated six different aspects of good governance: government effectiveness, regulatory quality, rule of law, voice and accountability, political stability, and control of corruption. An effective government means that the public and civil service are largely independent of political pressures in implementing policy. High-quality regulation means that the rules formulated by the state promote private sector development. The rule of law implies that the public has confidence that everyone will be treated equally under the law. In countries with a higher-quality rule of law, citizens perceive that by and large, contracts are enforced, property rights are valued, and courts provide justice. The level of criminal activity is also lower. For a country to have voice and accountability means that the citizens can express themselves freely and have access to free media. Political stability means that there is less politically motivated violence and terrorism within a country. Finally, lower corruption implies that politicians from well-governed countries are less likely to use their power to appropriate rents from business, bribery is less common, and the elite are less likely to capture the state. Though these different aspects of good governance are distinctly different concepts, they are interrelated. For example, an effective government is also less corrupt and has more inbuilt checks and balances, which nurtures the rule of law.

Dixit (2009) has explained why country-level governance is necessary for a properly functioning market economy. He has posited good governance is associated with the security of property, enforcement of a contract, and facilitation of collective action. When property rights protection is weak, individuals fear others will take the fruits of their endeavors. They also spend more time guarding their property. In countries with lax contract enforcement, there is a higher probability one of the participants in the business endeavor will act opportunistically. Similarly, a lack of infrastructure to facilitate collective action (e.g., quick justice) such as punishment for deviant behavior (e.g., embezzlement, extortion) deters the proper functioning of the market since good business requires cooperation from many players. Unsurprisingly, researchers in international business have theorized poor quality of institutions is associated with market failures (Peng et al. 2008) and influences an MNC's business strategy (Pinkse and Kolk 2012).

Research has specifically examined the connection between entrepreneur and country-level governance. Webb et al. (2020) theorize about the effect of formal and informal institutional voids on entrepreneurship and suggest that a lack of quality formal institutions can discourage legal tax-paying entrepreneurship. Specifically, they posited that "in societies characterized by more severe formal institutional voids, entrepreneurs can incur relatively high costs in gaining formal status but receive minimal benefits in return; and given minimal constraints imposed on pursuing more informal activities, entrepreneurs can create value for themselves with relatively less risk" (page 512). Mickiewicz and Olarewaju (2020) conducted a case study of a farm run by migrants in Nigeria and noticed that cost of doing business is higher when there is a lack of quality institutions. Anokhin and Wincent (2012) have used an indirect proxy measure of country governance (i.e., the stage of development) and found that it positively moderates the effect of start-up rates and innovation, suggesting it is easier to reap the benefits of entrepreneur when country governance is of high quality. Aidis et al. (2008) have blamed weak institutions for stunting start-up activity in Russia. Using data from over 70 countries, Nikolaev et al. (2018) have demonstrated that institutional variables--particularly those related to economic freedom--are strongly correlated with entrepreneurial activity.6

Footnote 6: There are many other studies that examine the association between the institutional context and entrepreneur activity and conclude that quality institutions can make it easier to foster new business. (e.g., Björnskov and Foss 2016; Boudreaux 2014; Boudreaux, et al. 2019b; Chowdhury et al. 2019; Estrin et al. 2013; Hwang and Powell 2005; Stephan et al. 2015; Urbano et al. 2019).

Based on the aforementioned studies (e.g., Nikolaev et al. 2018), we believe that low-quality country-level governance measures lead to greater uncertainty and ultimately higher costs of capital. Holding other variables in the net present value (NPV) calculation constant, a higher cost of capital reduces the NPV, and a project that would have otherwise been undertaken is not. Empirical research supports this conjecture (Globerman and Shapiro 2003; Oh and Oetzel 2011).7

Footnote 7: Globerman and Shapiro (2003) find that countries that fail to meet the minimum threshold of good governance are unlikely to receive any FDI from U.S. multinational corporations. Further, among the firms that do receive FDI, they find the ones with better governance receive more FDI. Oh and Oetzel (2011) find that all six measures of country-governance are associated with more foreign subsidiaries. Unsurprisingly, countries with good governance are more productive and grow faster (Keefer and Knack 1997; Hall and Jones 1999).

Start-ups are particularly sensitive to uncertainty because they have fewer resources, they are opaque, and they have fewer tools to navigate the ineffectivencumbersome regulations and satisfy the demands of powerful public officials. They also have more difficulty raising capital compared to MNCs. For these reasons, we propose the following hypothesis:

_H2: High-quality governance increases start-up activity._

Quality of governance moderates the relationship between natural disasters and entrepreneurship activity

Entrepreneurs expect a country with high-quality governance to quickly recover from a natural disaster.8 When a country has an effective, stable, and less corrupt government, it is easier to coordinate and organize for the common good, and the recovery process can proceed much more smoothly. Berke et al. (1993) have reviewed the key findings in the literature regarding disaster recovery. They have summarized that the key to better recovery is strong structural and functional relations among various social units and the capacity to "diffuse, adapt, implement plans, and policy innovation" (page 107). In countries that have an ineffective, corrupt government, political interference often delays policy implementation. Moreover, the communication between various units is often problematic because these countries lack the infrastructure for collective action (Dixit 2009). Boudreaux et al. (2021) find the quality of institutions moderates the effect of foreign aid on starting a new business after a disaster.

Footnote 8: The market process alone cannot itself lead to a faster recovery process unless the government plays an active role (Chamlee-Wright 2010; Sutter 2011).

Low-quality governance compromises the proper deliberation, planning, and implementation of disaster recovery. Johnson and Olshansky (2017) have drawn on decades of research on disaster recovery and compared disaster recovery efforts in China, Japan, New Zealand, India, Indonesia, and the U.S. They have also compared responses to earthquakes in China and Japan. In China, a 7.9 magnitude earthquake killed 70,000 people and displaced 1.5 million in 2008. China's government tried to reconstruct everything in three years in an effort that was largely led by the central government without proper deliberation. The quality of recovery suffered as a result. High-profile developments fell apart before completion. Rural residents lost their livelihoods as the government relocated them to cities. In contrast, after Japan's 1995 earthquake, local government largely led the recovery effort using funding from national leaders. The process involved many vigorous deliberations, and the recovery efforts were not made hastily. The infrastructure the local governments developed is earthquake-proof, with considerably fewer costs to residents. It is reasonable to argue that the free press, the rule of law, and proper enforcement of implicit and explicit contracts between the Japanese government and its people lead to proper deliberation and planning.

Thus, in countries with high-quality governance, entrepreneurs are likely to expect less chaotic recovery that involves proper planning and implementation. Hence, an entrepreneur's risk assessment of a future business opportunity will be lower. Furthermore, in countries with high-quality governance, private endeavors to exploit the opportunities after a disaster are likely to proceed much more quickly without political interference. These countries have regulations that encourage private sector development. Therefore, entrepreneurs are less likely to fear political extortion when establishing a new business.

Together, the lower assessment of risk and lower implicit and explicit costs of starting a business should encourage entrepreneurs to establish new start-ups as demand increases following a disaster. Based on this reasoning, we posit the following hypothesis:

_H3: High-quality country governance positively moderates the effect of natural disasters on the start-up activity rate._

## 3 Data and Methods

### Data sources and sample

To test our hypotheses, we gathered data from a variety of sources. We began our sample by collecting data on 1,831 new business start-up rates from the World Bank's Entrepreneurship Survey and Database from 2006 to 2016. We then merged this sample with country governance data from the World Governance Indicators (WGI). The WGI include 2,169 observations over the sample period, but only 1,280 observations remained after the merge with the World Bank data. Next, we merged this sample with natural disaster data from the Emergency Events Database (EM-DAT). The EM-DAT includes 1,881 observations over the sample period, but only 1,162 observations remained after the merge. Finally, we merged our sample with our set of control variables gathered from the World Bank and the World Bank's Doing Business Survey. After the merge, 701 observations remained. This final sample includes data from 2006 to 2016 from a panel of 95 countries. We report the definitions and data sources for each variable in Table 1 and report the summary statistics of the key variables by country in Table 2.

It is important to note that we follow recent calls in the entrepreneur and management literature urging scholars to focus less on statistical significance and more on effect sizes (e.g., Anderson et al., 2019; Meyer et al., 2017). Specifically, we report exact p-values and do not report asterisks in regression tables indicating statistical significance. However, we use a \(p<0.10\) threshold for hypothesis testing. Lastly, we report our effect sizes graphically using 95% confidence intervals.

**3.2. Dependent variable**

Our dependent variable, the new business start-up rate, is the number of newly registered limited-liability firms as a percentage of a country's working-age population (ages 15-64) normalized by 1,000. This variable comes from the World Bank's Entrepreneurship Survey and Database. We used a histogram to examine this variable's distribution and found that it was power-law distributed9, which is consistent with recent evidence from entrepreneurship studies (Crawford et al. 2014; Crawford et al. 2015). As a result, we used the natural logarithm to transform this measure, which resulted in a normal distribution (see Figure 1).

Footnote 9: Power law distribution refers to a highly skewed distribution where a few outliers account for a disproportionate amount of the total distribution’s output (Crawford et al., 2015).

**3.3. Explanatory variables**

We are particularly interested in two explanatory variables: natural disasters and country governance. The data on natural disasters came from the EM-DAT maintained by the Centre for Research on the Epidemiology of Disasters (CRED). A disaster is included in the database if it satisfies at least one or more of the following criteria: (1) 10 or more persons killed; (2) 100 or more persons affected, injured, or left homeless; (3) an appeal for international assistance; or (4) an official declaration of a state of emergency. Our analysis includes the following natural disasters: earthquakes, floods, slides, volcanic eruptions, and windstorms. Disaster data are available from 1900 to present, but we only used the data that overlapped with the data from oursample period (2006-2016). Most studies, including ours, that attempt to quantify the intensity of the disasters use a measure based on the number of people affected, injured, or killed from EDDAT (for example, see Loayza et al. 2012; Klomp and Valckx 2014; Noy 2009; Boudreaux et al. 2021). Therefore, we define the "intensity of natural disaster" as the sum of the total number of people affected, injured, and homeless due to a natural disaster.10 We transform this variable using the natural logarithm and add one to account for observations with zeros.11

Footnote 10: Affected are those requiring immediate assistance during a period of emergency. Injured are those suffering from physical injuries, trauma, or an illness requiring immediate medical assistance as a direct result of a disaster. Homeless are those people whose house is destroyed or heavily damaged and therefore need shelter after an event.

Footnote 11: Log (0) is undefined so it will be dropped. Therefore, we use the transformation, Log (0+1) = log(1) = 0.

We gathered data from the WGI to measure our variable: country governance. The WGI measure country governance using six different measures: voice and accountability, political stability, government effectiveness, regulatory quality, rule of law, and control of corruption. These six indicators are based on the opinions of country experts and are scaled from -2.5 to 2.5 with a standard normal distribution (mean = 0; SD = 1). For these indicators, higher scores reflect higher-quality country governance and lower scores reflect lower-quality country governance. To increase the robustness of our findings, we included each of the six measures in our models. Table 1 provides more details regarding each variable's definition.

### Control variables

In addition to our explanatory variables, we also included several control variables to mitigate omitted variable bias concerns. Including these control variables adjusted for their effects on our explanatory variables, dependent variables, or both. We gathered these control variables from the World Bank's Doing Business Survey. First, we gathered data on economic and financial indicators (GDP per capita, GDP growth, financial credit, and trade) that influence entrepreneurship activity or country governance. Economic indicators like GDP per capita and GDP growth capture economic activity in each country. We used the natural logarithm to transform GDP per capita, and we measured GDP growth as the annual growth rate. Gross domestic product per capita is thus the log of real GDP per capita using purchasing power parity, and GDP growth is measured as the annual percentage change in GDP. Similarly, our financial indicator, financial credit, captures a country's economic activity since it measures the domestic credit provided by the financial sector. This variable is expressed as a percentage of GDP. Our final economic indicator, trade, captures the trade openness of an economy. Countries with larger amounts of trade with others, which is expressed as a percentage of GDP, are likely to be more developed.

We also adjusted our model to reflect the fact that different countries have varying entry regulations associated with starting a new business based on work by Djankov et al. (2002).These variables capture the ease (or difficulty) of starting a new business. We gathered these variables from the World Bank's Doing Business Survey. The cost of business start-up procedures measures the total cost required to complete these procedures as a percentage of gross national income (GNI) per capita. The time required to start a business is measured in the number of days. Finally, the number of start-up procedures measures the total number of procedures required to register a business. The idea behind these Doing Business indicators is that we should expect more business creation when it is less costly, requires less time, and requires fewer procedures. De Soto (2000) originally found that it took his team 278 eight-hour days to open a business in Peru. This variable ranges from half a day in New Zealand to 690 days in Suriname.

Finally, we included three demographic variables that might influence either entrepreneurship activity or country governance. The largest population was measured as the largest city population expressed as a percentage of the country's total population. Populationdensity measures the people per square kilometer, which we defined as the population divided by the land area. Land area measures the area of land in square kilometers using the log transformation. These three demographic indicators might influence entrepreneurship activity, such as if entrepreneurship is more likely to be located in densely populated and urban areas.

Table 3 reports the descriptive statistics and correlation matrix for these variables. There is a negative and significant correlation between natural disasters and new business start-up activity and significant positive correlations between our six country governance indicators and new business start-up activity. This provides some preliminary evidence to support Hypothesis 1 and Hypothesis 2, but we require more sophisticated tests before reaching that conclusion. Additionally, it takes an average of 23 days to start a business with almost eight procedures, which costs roughly 28 percent of GNI. Clearly, starting a business is not a trivial task in many locations. There are also significant correlations between our six governance indicators. While many of our variables are modestly correlated, GDP per capita and the six governance indicators are often very strongly correlated. In additional robustness tests (Appendix, Table A1), we excluded GDP per capita from our model and found the results to be qualitatively similar.

### Model

Our empirical model can be represented as follows:\(STARTUP_{it}=\alpha+\beta_{1}DISASTERS_{it-1}+\sum_{j=1}^{6}\gamma_{j}\ GOVERN_{it-1}\)

\[+\sum_{j=1}^{6}\delta_{j}\left(DISASTERS_{it-1}\ \times\ GOVERN_{it-1} \right)+\sum_{k=1}^{10}\mu_{k}CONTROLS_{it}\] \[+\ \sum_{l=1}^{7}\eta_{l}REGIONS_{l}\ +\sum_{t=2006}^{2016}\lambda_{t}YEAR_{t}\ +\ \varepsilon_{it},\]

where STARTUP is the natural logarithm of the new business start-up rate (the number of new firms divided by the working age population) in a country, DISASTERS is the natural logarithm of natural disaster intensity, GOVERN is a vector of the six country governance indicators, DISASTERS \(\times\) GOVERN is a vector of interactions for each of the six country governance indicators, CONTROLS is a vector of the 10 previously described control variables, REGIONS is a vector of region dummies, YEAR is a set of year dummies, and \(\varepsilon\) is an idiosyncratic error term. We included region and year dummies to adjust for region-specific and year-specific differences between countries and over time.12 We estimated this model using linear regression models (i.e., ordinary least squares). These models assume homoscedasticity where the error term is independently and identically distributed. We adjusted for this assumption in two ways. First, our dependent variable is log-transformed, which greatly reduces heteroscedasticity concerns. Second, we used White's robust standard errors, which are consistent in the presence of heteroscedasticity (White 1980).

Footnote 12: Consistent with Oh and Oetzel (2011) we do not use country fixed effect as country-governance do not change much over a span of 10 years and therefore using country-fixed effect would throw away all the time invariant component of governance measure. It would be equivalent what some academic call “throwing the baby out of the water (Angrist and Pischke 2009)”

[MISSING_PAGE_FAIL:18]

start-up activity. Four of the six indicators are positively associated with the rate of start-up activity, and the remaining two indicators are negatively associated with the rate of start-up activity. However, only two indicators--voice and accountability (\(\beta\) = 0.351; \(p\) =.000) and regulatory quality (\(\beta\) = 0.269; \(p\) = 0.008)--have both positive and statistically significant associations with the rate of start-up activity. Thus, while there is some evidence to support Hypothesis 2, it is not fully supported. We therefore explore this relationship in more detail in Table 5 and discuss the implications in the discussion section.

**4.3. Moderating effects of quality of governance (Hypothesis 3)**

In Table 5, we included an interaction term between natural disasters and the six governance indicators. These models test our hypothesis that a country's quality of governance moderates the relationship between natural disasters and entrepreneur activity. We found overall support for Hypothesis 3; that is, the results suggest that natural disasters discourage entrepreneur activity, but the quality of governance attenuates this adverse effect. For example, Column 1 of Table 5 reports that natural disasters are negatively (though not significantly) associated with the new business start-up rate (\(\beta\) = -0.008; \(p\) =.339), but voice and accountability (\(\beta\) = 0.014; \(p\) =.064) attenuates this effect. There is a very consistent relationship for each of the remaining governance indicators (political stability, government effectiveness, regulatory quality, rule of law, and control of corruption). These results indicate that in countries where the quality of governance is higher, natural disasters have a positive effect on new business start-up activity. In other words, the number of start-ups increases following a disaster when countries have good governance quality, but the number of start-ups decreases following a disaster when countries have lower governance quality. Thus, Hypothesis 3 is supported.

[MISSING_PAGE_EMPTY:20]

Figure 3 plots the moderating effects of the two governance indicators of government effectiveness and regulatory quality. The results indicate that natural disasters are negatively associated with new business start-up activity, but this effect becomes smaller or positive as the quality of government effectiveness and regulatory quality increase. Specifically, our estimates suggest a ten percent increase in natural disaster activity is associated with an one percent decrease in new business start-up activity when government effectiveness is low (-2.5) and a 0.82 percent increase in new business start-up activity when government effectiveness is high (2.5). Regarding the regulatory quality indicator, our estimates suggest that a ten percent increase in natural disaster activity is associated with a one percent decrease in new business start-up activity when regulatory quality is low (-2.5) and a 0.66 percent increase in new business start-up activity when regulatory quality is high (2.5).

Figure 4 plots the moderating effects of the last two governance indicators, namely rule of law and control of corruption. The results of these indicators are very similar to the previous findings; that is, natural disasters are negatively associated with new business start-up activity, but this effect becomes smaller or positive as the rule of law score and control of corruption quality score increase. Our estimates suggest that a ten percent increase in natural disaster activity is associated with a 0.82 percent decrease in new business start-up activity when the rule of law is low (-2.5) and a 0.64 percent increase in new business start-up activity when the rule of law is high (2.5). Regarding the control of corruption indicator, our estimates suggest that a ten percent increase in natural disaster activity is associated with a one percent decrease in new business start

up activity when control of corruption is low (-2.5) and a 0.87 percent increase in new business start-up activity when control of corruption is high (2.5).

### Analytic Extensions

#### 4.4.1 Are these short-term or long-term effects?

While it is not the focus our study, a natural question that arises is whether the moderating role of a country's quality of governance persists for more than a year. We examine these short- and long-term effects by lagging our natural disaster variable by two, three, and four years. By including lags in the model, we are better able to examine the rate of start-up activity two, three, and four years after a natural disaster. For instance, a one-year lag suggests that natural disasters have an effect in the next year, not the same year. The same is true for two, three, or four years. Our results in Tables 6, 7, and 8 indicate that natural disasters' effects on start-up activity persist for the short term (1-3 years) but not the long term. We also found similar but weaker evidence regarding a four-year lag structure. Nevertheless, we found that country governance positively moderates the relationship between natural disasters and start-up activity for two years, three years, and possibly four years. These findings also indicate that the type of country governance matters: we found evidence for government effectiveness, regulatory quality, rule of law, and control of corruption. The evidence is weaker for voice and accountability and political stability.

#### 4.4.2 Do the findings differ by disaster type?

Another extension of our findings is to consider whether our findings differ by disaster type. That is, do all disasters have similar effects on start-up activity, or is it more heterogenous than that? To address this question, we separated disasters into climatic and geologic categories, following the literature (Boudreaux et al. 2019a; Crespo Cuaresma et al. 2008; Skidmore and Toya 2002). Climatic disasters include floods, cyclones, hurricanes, blizzards, typhoons, tornadoes, and storms. Geologic disasters include volcanic eruptions, natural explosions, landslides, avalanches, and earthquakes.

The results, which are available in a supplemental appendix (Tables A1 and A2), suggest that the moderating effect is statistically significant for geologic disasters but not climatic disasters. However, the results are likely more nuanced than that. For instance, a comparison of the moderating figures by disaster type suggests there is primarily a negative effect of climatic disasters on the rate of start-up activity (Figures A1-A3) yet primarily a positive effect of geologic disasters on the rate of start-up activity (Figures A4-A6). The marginal effect of climatic disasters does become positive, but it becomes positive for high-quality institutions only, typically at a score of 1.25 or greater. In contrast for geologic disasters, there is primarily a positive marginal effect of disasters on the rate of start-up activity, not negative. In almost an opposite fashion, the marginal effect is negative for low-quality institutions only. Thus, while we only observe a statistically significant moderating effect for geologic disasters (Table A2), we believe the findings are a bit more nuanced than that.

## 5 Discussion and Conclusions

The purpose of this paper is to investigate whether and how a country's quality of governance moderates the relationship between exogenous natural disasters and new business start-up activity. This study contributes to the literature by demonstrating that a country's quality of governance matters in the relationship between a natural disaster and the likelihood of a new business start-up activity. High-quality country-level governance makes a country more resilient to natural disasters. Our results suggest two possibilities: when a country's governance quality is high: 1) entrepreneurs expect the country to quickly recover from a natural disaster, and 2) entrepreneurs are in a better position to take advantage of new business opportunities in the aftermath of natural disasters.

This finding is an important contribution because although natural disasters are devastating and their frequency is increasing, we know little about what makes one country more resilient than others in dealing with these disasters. The following quotation illustrates this point:

Why do some organizations and societies successfully adjust and even thrive amid adversity while others fail to do so? With this editorial, we would like to inspire management scholars to take up the "grand challenge" of studying the role and functioning of organizations during adverse natural or social events" (Van Der Vegt et al. 2015).

Recently, researchers have pointed to the lack of research on this topic (e.g., Williams and Shepherd 2016). By documenting that high-quality country-level governance is associated with more new business start-ups after a natural disaster, our research suggests that formal institutions such as government effectiveness, lower corruption, private sector-friendly regulations, the rule of law, and citizens' ability to voice their opinion freely not only help countries recover but also allow entrepreneurs to thrive in post-disaster periods. This is a fresh perspective. The few studies focusing on this line of research suggest informal institutions such as cultural traits like social capital--the norms and networks of a society that enable co-operation--play a major role in a country's recovery after a natural disaster (Aldrich 2012). However, the role of formal institutions has largely been ignored. Our study fills this gap by highlighting how formal institutions also play an important role in facilitating post-disaster recovery through start-up activity.

Birkmann et al. (2010) have theorized that extreme events such as disasters can create a window of opportunity for change; our study suggests that this may only be possible if the country's formal governance is strong. Otherwise, business activity might suffer. As we mentionedin the introduction, Oh and Oetzel (2011) have found that only one aspect of a formal institution--regulatory quality--positively moderates the effect of natural disasters on MNCs' subsidiary-level investment. In contrast, we found that _all_ aspects of high-quality country-level governance positively moderate the effect of natural disasters on start-up activity. More specifically, based on Oh and Oetzel's study, government effectiveness, the rule of law, and the level of corruption do not affect MNCs' decisions to increase the number of foreign subsidiaries in the year after a disaster. However, as our research demonstrates, these aspects of country governance positively affect the number of new business start-ups in the year following a disaster.

Our results are consistent with the idea that while all businesses bear the cost of low-quality governance after a disaster, start-ups are disproportionately affected since they are often ill equipped to navigate poor governance when a natural disaster strikes. Oh and Oetzel (2011) have noted this possibility, "entrepreneurial firms are likely to have different decision-making rules and processes against disasters due to the differences in risk-taking behaviors and organizational responsiveness" (page 678). Our results confirm Oh and Oetzel's suspicion that the effect of institutions on moderating a natural disaster's effect on new business start-ups is even stronger.

Entrepreneurship researchers have found that institutional quality, especially the regulatory framework, positively affect the number of start-ups. The regulatory framework appears to affect replicative entrepreneurship more than high-impact entrepreneurship (Stenholm et al. 2013). Our study extends this stream of literature by demonstrating that regulatory quality has an impact on the number of start-ups and that all types of institutional quality affect entrepreneurship in the aftermath of a natural disaster. Therefore, our results suggest that the impact of institutions might be particularly valuable in the event of a negative shock to the economy.

Although we investigate the likelihood of starting a new business, the implication of our study is also to a related topic--the survival of small businesses. In this respect, we extend several recent pieces of research on entrepreneurship that examine the survival of small firms. Davlasheridze and Geylani (2017) find that small businesses are more likely to thrive if they have better loan access after being struck by natural disasters. Hadjielias et al. (2022) suggest that the psychological resilience of the small business owner increases the possibility of business survival during a disaster. Grozinger et al. (2022) echo a similar thought. They empirically document that organization psychological capital captured by solidarity, co-operation, and citizenship behavior of the employees is positively associated with innovation for survival during a disaster. We extend this study because our study suggests that higher-quality formal institutions might be another factor that can help the survival of small businesses thrive during a natural disaster.

Our study also has managerial implications. Churchill and Lewis (1983) have classified the five stages of new business start-up activity. They have theorized that in the first stage, entrepreneurs ask the following questions:

"Can we get enough customers, deliver our products, and provide services well enough to become a viable business? Can we expand from that one key customer or pilot production process to a much broader sales base? Do we have enough money to cover the considerable cash demands of this start-up phase?" (page 3)

Our results indirectly suggest that in countries with high-quality governance, entrepreneurs should expect that the infrastructure will improve quickly; that they will be able to reach customers, provide services, and expand quickly; and that they can be confident about obtaining resources such as loans from banks to grow more easily.

From a policy perspective, our study highlights the importance of designing policies that strengthen a country's governance quality. Research demonstrates that high-quality institutions are positively associated with foreign direct investment (FDI) (Globerman and Shapiro 2003) and high-growth entrepreneurial activity (Bowen and De Clercq 2008). They can also better withstand the initial disaster shock on the GDP growth rate (Noy 2009; Raschky 2008). Our research shows high-quality country governance makes a country resilient to the adverse effect of a natural disaster on start-up activity.

**5.1. Limitations and future research**

One of our limitations is the unit of analysis. Our measures of new business start-up activity and country governance are all at the country-year level. Therefore, when we claim that supply chain networks are disrupted, we implicitly assume that disruption occurred in the entire country. However, this is not accurate, particularly if the country is large. For example, Hurricane Katrina caused severe damage in Louisiana, but the rest of the country was not affected. We believe that this is one of the limitations of our study, albeit one that is difficult to solve, because most variations in institutional quality are at the country level (i.e., country governance). In any case, an alternative way to address the question we investigated would be to use a single-country study with variation in institutional quality in different regions. This approach would be more precise in capturing the cost of natural disasters and the opportunities they create and could provide additional insight into our hypotheses. The downside of this strategy is that there is less heterogeneity in institutional quality _within_ a country than there is _between_ countries. Thus, there were certain benefits to broadening our perspective to conduct a multi-country study.

Due to data limitations, we were also unable to examine what types of new start-ups are likely to be moderated by the quality of governance. A dataset that provides information about the types of start-ups and the characteristics of the entrepreneurs could be used to better understand the moderating role of the quality of governance after a disaster.

Another limitation is that we have assumed that the quality of institutions is not affected by the natural disaster. While largely true in the short term, this assumption is inaccurate in the long term. When a natural disaster strikes, there is often an inflow of aid from the government, non-government organizations, and foreign countries, partly for altruistic reasons and partly for political reasons (Garrett and Sobel, 2003; Sobel and Leeson, 2006). This sudden inflow of capital from various sources can increase corruption. Leeson and Sobel (2008) posit that some parts of the US may be more corrupt because they are struck by natural disasters often. The idea is that disasters trigger federally funded relief, which increases the chance of theft, and makes the culture more corrupt over time. The inflow of cash from different sources and susceptibility to corruption may lead to more regulations in regions prone to natural disasters. However, the adverse impact of the disaster on the culture and regulations will be gradual. Nevertheless, examining how the level of corruption and regulations changes after a natural disaster and how these changes affect the subsequent likelihood of startups in the long term is a possible avenue for future research.

We also want to reiterate that our results indicate that quality institutions have a _short-term_ increase in the number of new firms registered after a natural disaster. This limitation is a caveat. Bastiat (1964) famous broken window fallacy postulated that when a shopkeeper's son breaks a glass in his father's store, the society will be worse off, not better off, simply because the resource spent on replacing the glass could have been used elsewhere. The idea's extension to a natural disaster means that the country is worse off after a natural disaster. However, as Diaz and Larroulet (2021) point out, not all economists agree. For example, if a natural disaster leads to a significant innovation that considerably impacts the economy, one could argue that there may be long-term benefits. This harbinger of creative destruction predicts a higher growth rate and, thus, more new businesses getting established (Hallegatte and Dumas, 2009). While the theory is plausible, the extent and the likelihood of long-term benefits due to a natural disaster are hard to assess and are not the focus of our study. Future research could examine these questions in greater depth. For example, such benefits may only incur in well-developed countries where access to credit and venture capital is more accessible.

By demonstrating that a country's quality of governance makes that country more resilient to natural disasters, our study raises new questions. For example, recent studies have shown that natural disaster risk can affect a firm's financing policies, such as the amount cash, the type of debt, and firm performance (Huang et al. 2018). Our study indirectly suggests that these effects of natural disasters may be moderated by the quality of country-level governance.

Another possible extension of our study would be to compare the moderating role of the quality of governance in the investment decisions of foreign and domestic firms after a natural disaster. The abilities of foreign and domestic firms to navigate the changing landscape after a disaster might differ, and good country governance might moderate such an effect.

Our research also raises similar questions in emerging strands of literature about natural disasters and economic growth. It is unclear exactly how natural disasters affect economic growth. Some economic models use Schumpeter's theory of creative destruction to argue that disasters can be a catalyst in upgrading destroyed capital stock and hence result in long-term economic growth (Crespo Cuaresma et al. 2008; Toya and Skidmore 2007). Toya and Skidmore (2007) have found that climatic disasters are positively correlated with economic growth. Others disagree, arguing that natural disaster can lead to permanent destruction of physical or human capital and negative deviation from a previous growth trajectory (Romer 1990). Felbermayr and Groschl (2014) have used disaster data from geophysical and meteorological sources rather than insurance companies regarding more than 100 countries and spanning three decades. They found that the worst five percent of disaster years were characterized by growth damage of at least 0.46 percent. Bergholt and Lujala (2012) have also found that the negative effect of natural disasters on growth is considerable. Our study indirectly raises the possibility that natural disasters' impact on economic growth might be moderated by the quality of country governance factors such as the rule of law, corruption, voice and accountability, and regulatory quality.

## References

* [1]Aidis, R., Estrin, S., & Mickiewicz, T. (2008). Institutions and entrepreneurship development in Russia: A comparative perspective. _Journal of Business Venturing, 23_(6), 656-672, doi:[https://doi.org/10.1016/j.jbusvent.2008.01.005](https://doi.org/10.1016/j.jbusvent.2008.01.005).
* [2]Aldrich, D. P. (2012). _Building resilience: Social capital in post-disaster recovery_: University of Chicago Press.
* [3]Anderson, B. S., Wennberg, K., & McMullen, J. S. (2019). Enhancing quantitative theory-testing entrepreneurship research. _Journal of Business Venturing, 34_(5), 105928, doi:[https://doi.org/10.1016/j.jbusvent.2019.02.001](https://doi.org/10.1016/j.jbusvent.2019.02.001).
* [4]Angrist, J., & Pischke, J.-S. (2009). Mostly harmless econometrics: an empiricist's companion. Princeton University Press.
* [5]Anokhin, S., & Wincent, J. (2012). Start-up rates and innovation: A cross-country examination. _Journal of International Business Studies, 43_(1), 41-60, doi:[https://doi.org/10.1057/ijbs.2011.47](https://doi.org/10.1057/ijbs.2011.47).
* [6]Bastiat, F. (1964). Economic harmonies. _Irvington-on-Hudson, NY: Foundation for Economic Education_.
* [7]Baumol, W. J. (1990). Entrepreneurship: Productive, unproductive, and destructive. _Journal of Political Economy, 98_(5), 893-921, doi:[https://doi.org/10.1016/0883-9026](https://doi.org/10.1016/0883-9026)(94)00014-X.
* [8]Benson, C., & Clay, E. (2004). Understanding the economic and financial impacts of natural disasters. _World Bank Publications_, doi:[https://doi.org/10.1596/0-8213-5685-2](https://doi.org/10.1596/0-8213-5685-2).
* [9]Berg, G., & Schrader, J. (2012). Access to credit, natural disasters, and relationship lending. _Journal of Financial Intermediation, 21_(4), 549-568, doi:[https://doi.org/10.1016/j.jfi.2012.05.003](https://doi.org/10.1016/j.jfi.2012.05.003).
* [10]Bergholt, D., & Lujala, P. (2012). Climate-related natural disasters, economic growth, and armed civil conflict. _Journal of Peace Research, 49_(1), 147-162, doi:[https://doi.org/10.1177/0022343311426167](https://doi.org/10.1177/0022343311426167).
* [11]Berke, P. R., Kartez, J., & Wenger, D. (1993). Recovery after disaster: achieving sustainable development, mitigation and equity. _Disasters, 17_(2), 93-109, doi:[https://onlinelibrary.wiley.com/doi/10.1111/j.1467-7717.1993.tb01137.x](https://onlinelibrary.wiley.com/doi/10.1111/j.1467-7717.1993.tb01137.x).
* [12]Birkmann, J., Buckle, P., Jaeger, J., Pelling, M., Setiadi, N., Garschagen, M., et al. (2010). Extreme events and disasters: a window of opportunity for change? Analysis of organizational, institutional and political changes, formal and informal responses after mega-disasters. _Natural Hazards, 55_(3), 637-655, doi:[https://doi.org/10.1007/s11069-008-9319-2](https://doi.org/10.1007/s11069-008-9319-2).
* [13]Bjornskov, C., & Foss, N. J. (2016). Institutions, entrepreneurship, and economic growth: what do we know and what do we still need to know? _Academy of Management Perspectives, 30_(3), 292-315, doi:[https://doi.org/10.5465/amp.2015.0135](https://doi.org/10.5465/amp.2015.0135).
* [14]Boehm, C. E., Flaaen, A., & Pandalai-Nayar, N. (2019). Input linkages and the transmission of shocks: Firm-level evidence from the 2011 Tohoku earthquake. _Review of Economics and Statistics, 101_(1), 60-75, doi:[https://doi.org/10.1162/rest](https://doi.org/10.1162/rest) a 00750.
* [15]Boudreaux, C. J. (2014). Jumping off of the Great Gatsby curve: how institutions facilitate entrepreneurship and intergenerational mobility. _Journal of Institutional Economics, 10_(2), 231-255, doi:[https://doi.10.1017/S1744137414000034](https://doi.10.1017/S1744137414000034).
* [16]Boudreaux, C. J., Escaleras, M. P., & Skidmore, M. (2019a). Natural disasters and entrepreneurship activity. _Economics Letters_(182), 82-85, doi:[https://doi.org/10.1016/j.econlet.2019.06.010](https://doi.org/10.1016/j.econlet.2019.06.010).
* [17]Boudreaux, C. J., Jha, A., & Escaleras, M. (2021). Weathering the Storm: How Foreign Aid and Institutions Affect Entrepreneurship Activity Following Natural Disasters. _Entrepreneurship Theory and Practice_, forthcoming, doi:[https://doi.org/10.1177/10422587211002185](https://doi.org/10.1177/10422587211002185).
* [Boudreaux, Nikolaev, KleinBoudreaux et al.2019b] Boudreaux, C. J., Nikolaev, B. N., & Klein, P. (2019b). Socio-cognitive traits and entrepreneurship: The moderating role of economic institutions. _Journal of Business Venturing, 34_(1), 178-196, doi:[https://doi.org/10.1016/j.jbusvent.2018.08.003](https://doi.org/10.1016/j.jbusvent.2018.08.003).
* [Bowen & De ClercqBowen & De Clercq2008] Bowen, H. P., & De Clercq, D. (2008). Institutional context and the allocation of entrepreneurial effort. _Journal of International Business Studies, 39_(4), 747-767, doi:[https://doi.org/10.1057/palgrave.jibs.8400343](https://doi.org/10.1057/palgrave.jibs.8400343).
* [Bruck, Lussa, TavaresBruck et al.2011] Bruck, T., Lussa, F., & Tavares, J. A. (2011). Entrepreneurship: The role of extreme events. _European Journal of Political Economy, 27_, 78-88, doi:[https://doi.org/10.1007/s41885-021-00089-0](https://doi.org/10.1007/s41885-021-00089-0).
* [CarvalhoCarvalho2014] Carvalho, V. M. (2014). From micro to macro via production networks. _Journal of Economic Perspectives, 28_(4), 23-48, doi:[https://doi.org/10.1257/jep.28.4.23](https://doi.org/10.1257/jep.28.4.23).
* [Cassar, Healy, Von KesslerCassar et al.2017] Cassar, A., Healy, A., & Von Kessler, C. (2017). Trust, risk, and time preferences after a natural disaster: experimental evidence from Thailand. _World Development, 94_, 90-105, doi:[https://doi.org/10.1016/j.worlddev.2016.12.042](https://doi.org/10.1016/j.worlddev.2016.12.042).
* [Chamlee-WrightChamlee-Wright2010] Chamlee-Wright, E. (2010). _The cultural and political economy of recovery: Social learning in a post-disaster environment_: Routledge.
* [Chamlee-Wright Storr2009] Chamlee-Wright, E., & Storr, V. H. (2009). "There's no place like New Orleans": sense of place and community recovery in the Ninth Ward after Hurricane Katrina. _Journal of Urban Affairs, 31_(5), 615-634, doi:[https://doi.org/10.1111/j.1467-9906.2009.00479.x](https://doi.org/10.1111/j.1467-9906.2009.00479.x).
* [Chowdhury, Audretsch, BelitskiChowdhury et al.2019] Chowdhury, F., Audretsch, D. B., & Belitski, M. (2019). Institutions and entrepreneur quality. _Entrepreneurship Theory and Practice, 43_(1), 51-81, doi:[https://doi.org/10.1177/1042258718780431](https://doi.org/10.1177/1042258718780431).
* [Churchill LewisChurchill Lewis1983] Churchill, N. C., & Lewis, V. L. (1983). The five stages of small business growth. _Harvard Business Review, 61_(3), 30-50.
* [Crawford, Aguinis, Lichtenstein, Davidsson McKelvey2015] Crawford, C., Aguinis, H., Lichtenstein, B., Davidsson, P., & McKelvey, B. (2015). Power law distributions in entrepreneurship: Implications for theory and research. _Journal of Business Venturing, 30_(5), 696-713, doi:[https://doi.org/10.1016/j.jbusvent.2015.01.001](https://doi.org/10.1016/j.jbusvent.2015.01.001).
* [Crawford, McKelvey, LichtensteinCrawford et al.2014] Crawford, C., McKelvey, B., & Lichtenstein, B. B. (2014). The empirical reality of entrepreneurship: How power law distributed outcomes call for new theory and method. _Journal of Business Venturing Insights, 1_, 3-7, doi:[https://doi.org/10.1016/j.jbvi.2014.09.001](https://doi.org/10.1016/j.jbvi.2014.09.001).
* [Crespo Cuaresma, Hlouskova, ObersteinCrespo Cuaresma et al.2008] Crespo Cuaresma, J., Hlouskova, J., & Obersteiner, M. (2008). Natural disasters as creative destruction? Evidence from developing countries. _Economic Inquiry, 46_(2), 214-226, doi:[https://doi.org/10.1111/j.1465-7295.2007.00063.x](https://doi.org/10.1111/j.1465-7295.2007.00063.x).
* [Davlasheridze & GeylanDavlasheridze & Geylan2017] Davlasheridze, M., & Geylan, P. C. (2017). Small Business vulnerability to floods and the effects of disaster loans. _Small Business Economics, 49_(4), 865-888, doi:[https://doi.org/10.1007/s11187-017-9859-5](https://doi.org/10.1007/s11187-017-9859-5).
* [De SotoDe Soto2000] De Soto, H. (2000). _The mystery of capital: Why capitalism triumphs in the West and fails everywhere else_: Basic Civitas Books.
* [Diaz LarrouletDiazroulet2021] Diaz, D. A., & Larroulet, C. (2021). Impact of Institutions in the Aftermath of Natural Disasters. _Cato J., 41_, 65, doi:[https://doi.org/0.36009/CJ.41.1.4](https://doi.org/0.36009/CJ.41.1.4).
* [Diazroulet2021]* [DixitDixit2009] Dixit, A. 2009. Governance institutions and economic activity. American Economic Review, 99(1), 5-24, doi:[https://doi.org/10.1257/aer.99.1.5](https://doi.org/10.1257/aer.99.1.5).
* [Djankov, La Porta, Lopez-de-SilanesDjankov et al.2002] Djankov, S., La Porta, R., Lopez-de-Silanes, F., Shleifer, A. 2002. The regulation of entry. The Quarterly Journal of Economics, 117(1), 1-37, doi:[https://doi.org/10.1162/003355302753399436](https://doi.org/10.1162/003355302753399436).
* [EscalerasRescalerasRegister2011] Escaleras, M., Register, C. A. 2011. Natural disasters and foreign direct investment. Land Economics, 87(2), 346-363, doi:[https://doi.org/10.3368/le.87.2.346](https://doi.org/10.3368/le.87.2.346)
* [Estrin, Korosteleva, NickiewiczEstrin et al.2013] Estrin, S., Korosteleva, J., Nickiewicz, T. 2013. Which institutions encourage entrepreneurial growth aspirations? Journal of Business Venturing, 28(4), 564-580, doi:[https://doi.org/10.1016/j.jbusvent.2012.05.001](https://doi.org/10.1016/j.jbusvent.2012.05.001).
* [FelbermayrGroschlFelbermayrGroschl2014] Felbermayr, G., Nickiewicz, J. 2014. Naturally negative: The growth effects of natural disasters. Journal of Development Economics, 111, 92-106, doi:[https://doi.org/10.1016/j.ideveco.2014.07.004](https://doi.org/10.1016/j.ideveco.2014.07.004).
* [GarrettSobel2003] Garrett, T. A., Sobel, R. S. 2003. The political economy of FEMA disaster payments. Economic inquiry, 41(3), 496-509, doi:[https://doi.org/10.1093/ei/cbig023](https://doi.org/10.1093/ei/cbig023).
* [GlobermanShapiroGlobermanShapiro2003] Globerman, S., Shapiro, D. 2003. Governance infrastructure and US foreign direct investment. Journal of International Business Studies, 34(1), 19-39, doi:[https://doi.org/10.1057/palgrave.jibs.8400001](https://doi.org/10.1057/palgrave.jibs.8400001).
* [Grozinger, Wolff, Ruf MoogGrozinger et al.2022] Grozinger, A.-C., Wolff, S., Ruf, P. J., Moog, P. 2022. The power of shared positivity: organizational psychological capital and firm performance during exogenous crises. Small Business Economics, 58(2), 689-716, doi:[https://doi.org/10.1007/s11187-021-00506-4](https://doi.org/10.1007/s11187-021-00506-4).
* [GrubeStorrGrube2018] Grube, L. E., Storr, V. H. 2018. Embedded entrepreneurs and post-disaster community recovery. Entrepreneurship & Regional Development, 30(7-8), 800-821, doi:[https://doi.org/10.1080/08985626.2018.1457084](https://doi.org/10.1080/08985626.2018.1457084).
* [Hadjielias, Christofi, TardaHadjielias et al.2022] Hadjielias, E., Christofi, M., Tarda, S. 2022. Contextualizing small business resilience during the COVID-19 pandemic: evidence from small business owner-managers. Small Business Economics, 1-30, doi:[https://doi.org/10.1007/s11187-021-00588-0](https://doi.org/10.1007/s11187-021-00588-0).
* [HallJonesHallJonesJones1999] Hall, R. E. Jones, C. I. 1999. Why do some countries produce so much more output per worker than others? The Quarterly Journal of Economics, 114(1), 83-116, doi:[https://doi.org/10.1162/003355399555954](https://doi.org/10.1162/003355399555954).
* [HallegatteDumasHallegatte2009] Hallegatte, S., Dumas, P. 2009. Can natural disasters have positive consequences? Investigating the role of embodied technical change. Ecological Economics, 68(3), 777-786, doi:[https://doi.org/10.1016/j.ecolecon.2008.06.011](https://doi.org/10.1016/j.ecolecon.2008.06.011).
* [Huang, Kerstein, WangHuang et al.2018] Huang, H. H., Kerstein, J., Wang, C. 2018. The impact of climate risk on firm performance and financing choices: An international comparison. Journal of International Business Studies, 49(5), 633-656, doi:[https://doi.org/10.1057/s41267-017-0125-5](https://doi.org/10.1057/s41267-017-0125-5).
* [Hwang PowellHwang Powell2005] Hwang, H. Powell, W. W. 2005. Institutions and entrepreneurship. In Handbook of entrepreneurship research, pp. 201-232. Springer.
* [JohnsonOlshanskyOlshansky2017] Johnson, L. A. Olshansky, R. B. 2017. After great disasters: An in-depth analysis of how six countries managed community recovery: Lincoln Institute of Land Policy.
* [Kaufmann, Kraay, ZoidoKaufmann et al.1999] Kaufmann, D., Kraay, A., Zoido, P. 1999. Governance matters. World Bank policy research working paper(2196), doi:[https://doi.org/10.1596/1813-9450-2196](https://doi.org/10.1596/1813-9450-2196).
* [KeeferKnackKeeferKnack1997] Keefer, P. Knack, S. 1997. Why don't poor countries catch up? A cross-national test of an institutional explanation. Economic Inquiry, 35(3), 590-602, doi:[https://doi.org/10.1111/j.1465-7295.1997.tb02035.x](https://doi.org/10.1111/j.1465-7295.1997.tb02035.x).
* [KaufmannKaufmann et al.1999]Klomp, J., & Valckx, K. (2014). Natural disasters and economic growth: A meta-analysis. _Global Environmental Change, 26_, 183-195, doi:[https://doi.org/10.1016/j.gloenvcha.2014.02.006](https://doi.org/10.1016/j.gloenvcha.2014.02.006).
* Knight (1921) Knight, F. H. (1921). _Risk, uncertainty and profit_ (Vol. 31): Houghton Mifflin.
* Leeson & Sobel (2008) Leeson, P. T., & Sobel, R. S. (2008). Weathering corruption. _The Journal of Law and Economics, 51_(4), 667-681, doi:[https://doi.org/10.1086/590129](https://doi.org/10.1086/590129).
* Loayza et al. (2012) Loayza, N. V., Olaberria, E., Rigolini, J., & Christiaensen, L. (2012). Natural disasters and growth: Going beyond the averages. _World Development, 40_(7), 1317-1336, doi:[https://doi.org/10.1016/j.worlddev.2012.03.002](https://doi.org/10.1016/j.worlddev.2012.03.002).
* Meyer et al. (2017) Meyer, K. E., van Witteloostuijn, A., & Beugelsdijk, S. (2017). What's in a p? Reassessing best practices for conducting and reporting hypothesis-testing research. _Journal of International Business Studies, 48_(5), 535-551, doi:[https://doi.org/10.1057/s41267-017-0078-8](https://doi.org/10.1057/s41267-017-0078-8).
* Mickiewicz & Olarewaju (2020) Mickiewicz, T., & Olarewaju, T. (2020). New venture evolution of migrants under institutional voids: Lessons from Shonga Farms in Nigeria. _International Small Business Journal, 38_(5), 404-423, doi:[https://doi.org/10.1177/0266242619896266](https://doi.org/10.1177/0266242619896266).
* Monllor & Murphy (2017) Monllor, J., & Murphy, P. J. (2017). Natural disasters, entrepreneurship, and creation after destruction: A conceptual approach. _International Journal of Entrepreneurial Behavior & Research, 23_(4), 618-637, doi:[https://doi.org/10.1108/IJEBR-02-2016-0050](https://doi.org/10.1108/IJEBR-02-2016-0050).
* Nikolaev et al. (2018) Nikolaev, B. N., Boudreaux, C. J., & Palich, L. (2018). Cross-country determinants of early-stage necessity and opportunity-motivated entrepreneurship: accounting for model uncertainty. _Journal of Small Business Management, 56_, 243-280, doi:[https://doi.org/10.1111/jsbm.12400](https://doi.org/10.1111/jsbm.12400).
* Noy (2009) Noy, I. (2009). The macroeconomic consequences of disasters. _Journal of Development Economics, 88_(2), 221-231, doi:[https://doi.org/10.1016/j.jdeveco.2008.02.005](https://doi.org/10.1016/j.jdeveco.2008.02.005).
* Oh & Oetzel (2011) Oh, C. H., & Oetzel, J. (2011). Multinationals' response to major disasters: how does subsidiary investment vary in response to the type of disaster and the quality of country governance? _Strategic Management Journal, 32_(6), 658-681, doi:[https://doi.org/10.1002/smj.904](https://doi.org/10.1002/smj.904).
* Peng et al. (2008) Peng, M. W., Wang, D. Y., & Jiang, Y. (2008). An institution-based view of international business strategy: A focus on emerging economies. _Journal of International Business Studies, 39_(5), 920-936, doi:[https://doi.org/10.1057/palgrave.jibs.8400377](https://doi.org/10.1057/palgrave.jibs.8400377).
* Pinkse & Kolk (2012) Pinkse, J., & Kolk, A. (2012). Multinational enterprises and climate change: Exploring institutional failures and embeddedness. _Journal of International Business Studies, 43_(3), 332-341, doi:[https://doi.org/10.1057/ijbs.2011.56](https://doi.org/10.1057/ijbs.2011.56).
* Raschky (2008) Raschky, P. A. (2008). Institutions and the losses from natural disasters. _Natural hazards and earth system sciences, 8_(4), 627-634, doi:[https://doi.org/10.5194/nhess-8-627-2008](https://doi.org/10.5194/nhess-8-627-2008).
* Romer (1990) Romer, P. M. (1990). Endogenous technological change. _Journal of Political Economy, 98_(5, Part 2), S71-S102, doi:[https://doi.org/10.3386/w3210](https://doi.org/10.3386/w3210).
* Sadowski & Sutter (2005) Sadowski, N. C., & Sutter, D. (2005). Hurricane fatalities and hurricane damages: Are safer hurricanes more damaging? _Southern Economic Journal, 72_(2), 422-432, doi:[https://doi.org/10.1002/j.2325-8012.2005.tb00710.x](https://doi.org/10.1002/j.2325-8012.2005.tb00710.x).
* Schultz (1975) Schultz, T. W. (1975). The value of the ability to deal with disequilibria. _Journal of Economic Literature, 13_(3), 827-846.
* Skidmore & Toya (2002) Skidmore, M., & Toya, H. (2002). Do natural disasters promote long-run growth? _Economic Inquiry, 40_(4), 664-687, doi:[https://doi.org/10.1093/ei/40.4.664](https://doi.org/10.1093/ei/40.4.664).
* Skidmore & Toya (2008)* Sobel (2008) Sobel, R. S. (2008). Testing Baumol: Institutional quality and the productivity of entrepreneurship. _Journal of Business Venturing, 23_(6), 641-655, doi:[https://doi.org/10.1016/j.jbusvent.2008.01.004](https://doi.org/10.1016/j.jbusvent.2008.01.004).
* Sobel & Leeson (2006) Sobel, R. S., & Leeson, P. T. (2006). Government's response to Hurricane Katrina: A public choice analysis. _Public Choice, 127_(1), 55-73, doi:[https://doi.org/10.1007/s11127-006-7730-3](https://doi.org/10.1007/s11127-006-7730-3).
* Starbuck et al. (1978) Starbuck, W. H., Greve, A., & Hedberg, B. (1978). Respondonding to crises. _Journal of Business Administration, 9_(2), 111-137.
* Stenholm et al. (2013) Stenholm, P., Acs, Z. J., & Wuebker, R. (2013). Exploring country-level institutional arrangements on the rate and type of entrepreneurial activity. _Journal of Business Venturing, 28_(1), 176-193, doi:[https://doi.org/10.1016/j.jbusvent.2011.11.002](https://doi.org/10.1016/j.jbusvent.2011.11.002).
* Stephan et al. (2015) Stephan, U., Uhlaner, L. M., & Stride, C. (2015). Institutions and social entrepreneur: The role of institutional voids, institutional support, and institutional configurations. _Journal of International Business Studies, 46_(3), 308-331, doi:[https://doi.org/10.1057/jibs.2014.38](https://doi.org/10.1057/jibs.2014.38).
* Sutter (2011) Sutter, D. (2011). Culture, Economics, and Recovery from Disaster. _Studies in Emergent Order, 4_, 18-30.
* Toya & Skidmore (2007) Toya, H., & Skidmore, M. (2007). Economic development and the impacts of natural disasters. _Economics Letters, 94_(1), 20-25, doi:[https://doi.org/10.1016/j.econlet.2006.06.020](https://doi.org/10.1016/j.econlet.2006.06.020).
* Urbano et al. (2019) Urbano, D., Aparicio, S., & Audretsch, D. (2019). Twenty-five years of research on institutions, entrepreneurship, and economic growth: what has been learned? _Small Business Economics, 53_(1), 21-49, doi:[https://doi.org/10.1007/s11187-018-0038-0](https://doi.org/10.1007/s11187-018-0038-0).
* Van Der Vegt et al. (2015) Van Der Vegt, G. S., Essens, P., Wahlstrom, M., & George, G. (2015). Managing risk and resilience. _Academy of Management, 58_(4), 971-980, doi:[https://doi.org/10.5465/amj.2015.4004](https://doi.org/10.5465/amj.2015.4004).
* Webb et al. (2020) Webb, J. W., Khoury, T. A., & Hitt, M. A. (2020). The influence of formal and informal institutional voids on entrepreneurship. _Entrepreneurship Theory and Practice, 44_(3), 504-526, doi:[https://doi.org/10.1177/1042258719830310](https://doi.org/10.1177/1042258719830310).
* White (1980) White, H. (1980). A heteroskedasticity-consistent covariance matrix estimator and a direct test for heteroskedasticity. _Econometrica_, 817-838, doi:[https://doi.org/10.2307/1912934](https://doi.org/10.2307/1912934).
* Williams & Shepherd (2016) Williams, T. A., & Shepherd, D. A. (2016). Building resilience or providing sustenance: Different paths of emergent ventures in the aftermath of the Haiti earthquake. _Academy of Management Journal, 59_(6), 2069-2102, doi:[https://doi.org/10.5465/amj.2015.0682](https://doi.org/10.5465/amj.2015.0682).

[MISSING_PAGE_EMPTY:36]

Figure 1: The Dependent Variable, Start-up Rate, is normally distributed after a log-transformation

Figure 2: Effect of Disasters on Start-Up Rate is Moderated by Voice and Accountability and Political Stability [95% confidence intervals]

Figure 3: Effect of Disasters on Start-Up Rate is Moderated by Government Effectiveness and Regulatory Quality [95% confidence intervals]

Figure 4: Effect of Disasters on Start-Up Rate is Moderated by Rule of Law and Control of Corruption [95% confidence intervals]

Tuple 21:
Cleaned Title: know software development startup
Cleaned Transcription: material posted permission ieee permission ieee way imply ieee endorsement bths product service internal personal use material permitted however permission reprintrepublish material advertising promotional purpose creating new collective work resale redistribution must obtained ieee sending blank email message textpubspermissionsieeeorg choosing view document agree provision copyright law protecting know software development startup carmine giardino michael unterkalmsteiner nicolo paternoster tony gorschek pekka abrahamsson startup newly created company little operating history facing high volatility technology market u alone new business established month accounting job creation startup important factor economy however environment startup dynamic unpredictable even chaotic forcing entrepreneur act quickly fail fast learn faster find market niche acquire sustainable income startup survive first five year venture capital funded startup fail due high risk startup missed market window business reason however since engineering practice startup largely unknown extent inadequate engineering contributing factor high failure rate also largely speculation present detailed investigation collection known empirical software engineering source related startup engineering practice well analysis accurate reliable available evidence see first critical step area largely unknown namely world software engineering practice startup startup anyway past term startup associated different meaning looking recurrent theme see table complete list adopted researcher practitioner startup small company exploring new business opportunity working solve problem solution wellknown market highly volatile newly founded make company startup highuncertainty rapidlyevolvement two key characteristic startup retrieved study better differentiate established company
Original Title: What do we know about software development in startups?
Original Transcription: This material is posted here with permission of the IEEE. Such permission of the IEEE does not in any way imply IEEE endorsement of any of BTH's products or services Internal or personal use of this material is permitted. However, permission to reprint/republish this material for advertising or promotional purposes or for creating new collective works for resale or redistribution must be obtained from the IEEE by sending a blank email message to

\[\text{pubs-permissions@ieee.org}.\]

By choosing to view this document, you agree to all provisions of the copyright laws protecting it.

What do we know about software development in startups?

Carmine Giardino, Michael Unterkalmsteiner, Nicolo Paternoster, Tony Gorschek, Pekka Abrahamsson

Startups are newly created companies with little or no operating history facing a high volatility in technologies and markets. In the US alone, 476,000 new businesses are established each month [1], accounting for about 20% of job creation [2]. As such, startups are an important factor in the economy. However, the environment of startups is dynamic, unpredictable and even chaotic, forcing entrepreneurs to act quickly, fail fast and learn faster to find a market niche to acquire a sustainable income. 60% of the startups do not survive the first five years, and 75% of venture capital funded startups fail [3]. Most of this is due to the high risk of startups, missed market window, and other business reasons. However, since engineering practices of startups are largely unknown, to what extent inadequate engineering is a contributing factor to this high failure rate is also largely speculation.

We present a detailed investigation and collection of all known empirical software engineering sources related to startups and their engineering practices, as well as analysis of how accurate reliable this available evidence is [4]. We see this as a first critical step into an area largely unknown, namely the world of software engineering practices in startups.

## What is a startup, anyway?

In the past, the term "startup" has been associated with different meanings. Looking at the recurrent themes (see Table 1 for a complete list) adopted by researchers and practitioners, a startup is a small company exploring new business opportunities, working to solve a problem where the solution is not well-known and the market is highly volatile. Being newly founded does not in itself make a company a startup. High-uncertainty and rapidly-evolvement are the two key characteristics for startups retrieved by the studies, which better differentiate them from more established companies.

Tuple 22:
Cleaned Title: empirical analysis vm startup time public iaa cloud extended report
Cleaned Transcription: empirical analysis vm startup time public iaa cloud extended report jianwei haodagger ting jiangdagger wei wangddagger kee kimdagger daggeruniversity georgia department computer science jhao tingjiang inkeekimugaedu ddaggerthe university texas san antonio department computer science weiwangutsaedu author contributed equally abstract vm startup time essential factor designing elastic cloud application example cloud application autoscaling reduce overprovisioning vm instance precise estimation vm startup time turn likely guarantee application performance improve cost efficiency however vm startup time little studied available measurement result performed previously consider various configuration vms modern cloud application work perform comprehensive measurement analysis vm startup time two major cloud provider namely amazon web service aws google cloud platform gcp three month measurement collected data point provider applying set configuration including vm type four different data center location four vm image size two o type two purchase model eg spotpreemptible vms v ondemand vms extensive analysis found vm startup time vary significantly several important factor vm image size data center location vm type o type moreover comparing previous measurement result confirm cloud provider specifically aws made significant improvement vm startup time currently much quicker vm startup time past performance measurement analysis vm startup time iaa cloud computing introduction last decade cloud computing become primary computing infrastructure many application increasingly migrated onpremise environment cloud time cloud infrastructure continuously evolving cloud computing currently offer diverse resource model vms container orchestration cloud function support various application type service scenario vms traditional resource type cloud vms still widely used common hosting platform user application different resource model like container kubernetes serverlesscloud function various aspect performance implication vms iaa infrastructure service cloud amazon ec extensively studied measurement result widely adopted developing novel cloud application cloud infrastructure management system particular understanding vm startup time crucial design elastic resource management system cloud application autoscaling according previous study performed vm startup time could vary significantly due various factor vm image size timeofday vm purchase model ondemand spot etc measurement result previous work still useful current cloud research number mechanism proposed optimizing vm startup process cloud data center last decade therefore important see whether improvement vm startup time public cloud provider work aim provide uptodate information vm startup time research community cloud researcher practitioner facilitate design novel resource performance management approach cloud application end performed empirical analysis vm startup time measured two widelyused public cloud service namely aws amazon web service gcp google cloud platform measurement conducted three month extensive trial trial performed least consecutive day cover temporal impact timeofday dateofweek vm startup time total obtained data point provider exploiting different set factor change vm startup time data collected using widelyused vm type commonly hosted four service region located u europe asia four vm image size gb gb two different o type linux window two vm purchase model ondemand spotpreemptible also applied moreover measured two different type vm startup time cold startup warm startup time cold startup time mean vms startup time user creates new vm startup time equivalent vms creation provisioning time warm startup time startup time measured user restarts existing stopped vm instance paper report coldwarm vm startup time aws gcp diverse configuration realistic vm usecases extensive analysis found vms startup time could significantly changed due several factor o type vm image size vm type generation locationsregions table summarizes analysis important factor changing vm startup time identifying critical factor vm startup time compare analysis result previous study comparison confirms cloud providersspecifically aws made significant improvement vm startup time currently much quicker vm startup time moreover implication finding study help various research cloud resource application management particular autoscaling algorithm accurate vm startup time determine exact scaling point handling increased user demand cloud simulator generate reliable simulation result study worth noting paper extended version previous work published ieee international conference cloud computing ieee cloud version paper contains additional measurement analysis vm start time aws gcp included ieee cloud version result work following contribution performed thorough measurement study vm startup time two major cloud provider aws gcp widely used research industry three month measurement collected large number data point various vm configuration reflecting realistic usecases vms cloud report vm startup time aws gcp diverse configuration extensive analysis found several factor considerably change vm startup time found gcp us cachebased approach reduce vms startup time recently used vm image stored gcp data center next minute user benefit using cached vm image reduce vm startup time structure rest paper follows section ii describes experimental setup measuring vm startup time section iii report measurement result vm startup time aws gcp section iv provides comparison previous work section v summarizes related work finally section vi concludes paper ii measurement methodology section describes methodology measuring vm startup time two public cloud provider measurement setup considered diverse factor lead changing vm startup time following configuration used measurement collect vm startup time realistic scenario cloud provider measured vm startup time aws gcp two provider widely used industry academic research crucial see vm startup time difference exist provider used vms aws ec google compute engine iaa model provider measurement period measurement conducted three month set trial measurement trial least twoweeks duration check temporal impact vm startup time timeofday dayofweek data center location region availability zone table ii describes region availability zone two provider used measurement chose four region located u east west europe asia check correlation cloud data center location vm startup time moreover region multiple zone measured vm startup time zone listed table ii see vm startup time fluctuation different availability zone region instance type table iii show vm type aws vm type gcp used measurement check vm startup time difference various instance type categorized vm type five vm class tiny small medium large xlarge class classification based memory size vm type vm type class exactly almost equivalent vm type chosen cloud provider moreover selecting instance type measurement considered vms different generation cpu model example measured startup time tsmall tsmall instance small class aws see vm startup time difference equivalent vm instance different generation diversity cpu model used tamedium malarge amd cpu aws n intel nd amd e intel amd instance type gcp used measurement check vm startup time difference due different cpu model o type vm image size tested vm startup time two different operating system linux window used ubuntu lts linux vms window server window vms vm image size used four different size usercreated vm image gb gb gb gb vm image fully filled o binarydata file vm purchase model ondemand lowavailability vm model used measurement spot instance model aws preemptible instance model gcp used low availability model specifically interesting measure vm startup time two different vm purchase model spotpreemptible instance different provisioning process different level availability compared ondemand model measurement procedure measure vm startup time rely vm status information provided cloud provider vm status often inaccurate instead implemented deployed application collect vm startup time interacting cloud provider measurement application calculated vm startup time based first successful remote access target vm example suppose trequest time call cloud apis start vm taccess first time successfully access eg login vm via ssh rdp vms startup time calculated taccesstrequest measured cold startup vm provisioning time warm startup time startup time existing vm vms startup time vm measured sequentially measurement period measured cold startup time vms every hour hour measured warm startup time several minute example measurement application sent request creating vm provider via aws boto google cloud apis top hour eg cold vm startup time measured measurement application could successfully access vm measurement application stopped vm several minute eg application sent another request start vm measured warm vm startup time vm successful remote access vm finally terminated worth noting vm startup time generally mean cold vm startup time work found cold startup time varies significantly per diverse factor warm startup time fairly consistent provider iii measurement result analysis measurement collected data point provider data include warm cold startup time measured set different configuration section ii total measured vm startup time aws gcp different configuration number collected sample configuration range configuration ensured enough sample obtain accurate vm startup measurement result high confidence using method proposed prior work footnote calculated linux window time vm type time image size time region time ondemand preemptible o type different o type vms widelyrecognized factor impact vm startup time per previous work therefore important see factor still change vm startup time confirm impact o type vm startup time measured vm startup time using linux window vms four different vm image size gb gb table iv report average vm startup time linux window instance aws gcp cold startup time aws vms shorter startup time vms gcp particular gcp vms showed time linux vms time window vms slower startup time compared aws vms regarding warm startup time provider showed similar startup time warm startup time much shorter cold startup time shorter time warm startup case mainly vm image already stored physical machine warm startup process delay vm image transfer regarding o impact vm startup time confirmed o type still impacting vm startup time based measurement result cloud provider showed different vm startup time linux window vms example linux vms aws showed faster startup time window vms whereas gcp window vms faster startup time linux vms observation different o type bullet aws vms faster startup time vms gcp bullet aws startup time linux vms faster window vm gcp show opposite result vm image size vm image size another widely accepted factor regarding variability vm startup time measure vm startup time various vm image size gb gb aws gcp confirm vm image size still changing startup time fig report average startup time aws linux window vms four different vm image size result also show cold warm startup time vms unlike previous finding measurement result confirm aws vms almost constant startup time regardless image size observed constant pattern o system well warm cold startup time maximum startup time difference smallest gb largest gb image size linux vms result clearly different widely used assumption vm startup process take longer vm image size increase assume aws could leverage several optimization described section v provide constant startup time regarding improvement however result show average startup time also analyzed distribution vm startup time image size shown fig observed vm startup time multimodal distribution indicating fig aws vm startup time different vm image size fig startup time distribution gcp linux vms fig gcp vm startup time different vm image size fig startup time distribution aws linux vmsthat straggler vms slow startup time specifically straggler vms clearly observed aws vms cold startup time eg fig aa think slow vm startup time affected factor investigate later section fig report vm startup time different image size measured gcp gcp result showed gcp vms startup time positive correlation vm image size different aws result shown figure gcp vms cold startup time increased vm image size increased linux window vms showed pattern change vm startup time measurement result cold startup time confirm vm image size still impacting vm startup time gcp unlike cold startup time warm startup time gcp vms constant stable regardless vm image size however stable warm startup time expected cloud provider reuse existing vm image warm startup performed fig show distribution cold warm startup time gcp linux vms interesting observation distribution gcp measurement result bimodal distribution particular group vms faster vm startup time majority measured vms shown fig aa analysis revealed group vms faster startup time gcps caching mechanism described vm image cache period gcp one major contribution work found analyzed gcps vm image cache mechanism effectively reduces startup time possibly offer nearconstant vm startup time regardless image size based measurement found cachebased approach work similarly several vm startup time reduction mechanism proposed research community procedure explains vm image caching mechanism used gcp user creates vm data center zone region based specific vm image used certain period time cache period data center vm image transferred image repository gcp data center vm created based transferred vm image image stored data center step vm startup time follows pattern reported fig user creates another vm based vm image used step data center within cache period vm created using vm image stored data center case cold startup time vm creation time much faster step delay vm image transmission vm image longer used cache period vm image removed data center vm image caching beneficial user creates vm based previously used vm image data center zone within cache period user creates vm based image different data center zone region mechanism work even within cache period important know exact cache period storing vm image gcp table v report vm image cache period five gcp region result also include cache period zone five region shown table v gcp data center generally minute vm image cache period within period cold startup time vm prestored cached image much faster startup time without cache fig show difference vm cold startup time without cached vm image vms cached image showed much faster cold startup time compared uncached case cache mechanism vm reduce startup time linux vm window vm observation different vm image size bullet aws vms show nearconstant vm startup time regardless image size however straggler vms bullet gcp vm image size still impact vm startup time however startup time decrease gcps internal caching mechanism gcps data center keep recently created vm image next minute thus gcp provide nearconstant startup time recreating vms based image within cache period instance type also measured vm startup time variation different vm type listed table iii section ii used vm type aws vm type gcp fig gcp startup time difference cached image instance type include shared core burstable generalpurpose instance fig report average ile cold startup time variation instance type aws please note result reporting cold startup time different vm type linux o image size considered calculating result vm image size meaningfully impact startup time omit result window instance result window vms similar pattern result reported fig among aws instance instance previous generation burstable instance showed significantly longer startup time compared instance type instance second average second ile startup time particular tnano smallest instance type aws vcpu gb memory showed unstable longest cold startup time among aws instance instance type vm type tended similar cold startup time vm type instance family also observed different generation purpose instance type eg v v could difference vm startup time measured difference cold startup time older newer generation instance fig show comparison result well instance regarding comparison also report result including excluding solely comparing nano type tnano showed substantially slower startup time shown fig newer generation instance showed faster cold startup time older instance type aws example instance without nano type faster startup time compared instance specifically average startup time tnano faster tnano tnano took second average regarding generalpurpose instance time difference two instance family smaller tinstances result showed newgeneration instance faster cold startup time oldergeneration instance fig show cold startup time variation vm type gcp fig contains measurement result linux vms gb image size fig measurement result window vms gb image size omit result image size measurement image size showed similar result fig regarding vm type linux o fig sharecore fsmall glmicro n instance showed slower vm startup time n nd estandard instance word first previous generation vm type fgln longer startup time compared second current generation vm type nnde linux o gcp fig gcp cold startup time different vm type linux o gb image size fig aws cold startup time different vm type graph contains measurement result ondemand linux vms image size fig aws cold startup time comparison vms older newer vm type graph contains measurement result ondemand linux vms fig gcp cold startup time different vm type window o gb image size however measurement result window vms fig different result linux vms fig nd second generation instance showed fastest vm startup time first generation window vms eg sharedcore n instance shorter startup time second generation ne instance cold startup time difference first second generation vms gcp summarized fig general newer generation instance type faster startup time older generation instance type linux startup time newer generation vm type window slower startup time older generation vm type observation different instance type aws family show significantly longer startup time instance type specifically tnano slowest instance among vm type faster startup time old generation vm instance type eg gcp older generation fgn vms linux o show slower startup time newer generation vms eg ne window vms report opposite result region data center location subsection analyzed vm startup time variation different region fig show average ile cold vm startup time four different region u east u west eu asia provider please note result fig collected ondemand linux vms omit result window vms showed similar result linux vms shown fig four region aws relatively consistent stable vm cold startup time maximum difference four region second average however vm cold startup time average ile gcp varied considerably different region maximum startup time difference second average average startup time four region among four region useast use nva fastest region uswest usw oregon showed longest vm startup time analyzed vm startup time per zone fig report linux vm startup time difference zone belong four aws region although aws showed similar vm startup time four region previous analysis vm startup time fluctuating per choose different zone even within region among zone measured aws zone zrm uswest zrm b useast zrm apeast least longer startup time compared average startup time four region vms another zone zrm b uswest zrm zrm b euwest fig average ile vm cold startup time different region aws vm startup time four region use isuseast nva usw isuswest oregon eu euwest paris asia apsoutheast singapore b gcp vm startup time four region use isuseast nva usw uswest oregon eu europewest belgium asia asiasoutheast singapore fig aws average ile vm cold startup time different zone zrm zrm f zone zone f fig gcp cold startup time comparison ondemand vms older newer vm type fig gcp average ile vm cold startup time different zone zrm zrm f zone zone dlonger startup time moreover observed difference average startup time among different zone even within region uswest result thus imply minimize vm startup time aws user carefully choose zone creating vms fig show vm startup time variation linux vms different zone within four region gcp overall startup time variation similar startup time fluctuation reported fig b also observed significant startup time variation zone another belonging geographical region gcp example zd europewest longer vm startup time gcp average interestingly zc region rd fastest vm startup time shorter zone vm startup time difference europewest region second particular europewest asiasoutheast showed high fluctuation vm startup time among zone observed europewest asiasoutheast region could difference vm startup time consequently result also imply gcp user need carefully choose zone specific region starting vms minimizing vm startup time order improve resource elasticity observation different data center region bullet cloud provider different zone region significantly differ vms startup time potential factor addition previous analysis investigated potential factor change vm startup time subsection provide analysis vm purchase model temporal factor changing vm startup time vm purchase model public cloud provider typically offer three different way purchasing vms ondemand reserved lowavailability model particular lowavailability model spot instance aws preemptible vms gcp increasingly used cloud user due high costefficiency per previous study industry report aws spot instance tended longer cold startup time important see previous report still valid potential factor aws spot instance longer startup time bidding process determine vms price however study always used bidding price higher current price spot instance minimize delay due bidding process precisely measure startup time delay caused cloud infrastructure moreover measurement experienced failure vm startup provisioning aws spot gcp preemptible vms due limited capacity instance nevertheless report failure rate statistic startup process lowavailability vms scope work fig show startup time five different spot vm type startup time normalized startup time ondemand vms startup time spot instance eg tmicro type could considerably eg different ondemand vms startup time could observe measurement result support spot vms longer startup time ondemand vms interestingly observed spot vms shorter startup time ondemand vms ie tt instance uswest similar result reported table measured gcps preemptible vms maximum difference startup time preemptible ondemand vms le window vms asiasoutheast zonesregions le difference startup time two model also observed several case preemptible vms shorter cold startup time result lowavailability model spot preemptible vms longer slower startup time compared ondemand vms temporal factor cloud data center may different amount workload per timeofday dayofweek cloud application eg web may repeating diurnal workload pattern analyzed whether temporal factor could change vm startup time first examined vm startup time variation different day week omit visualized result fig aws normalized startup time spot instance startup time spot vms normalized startup time ondemand vms variation provider commonly showed vms shorter startup time saturday sunday longer startup time weekday example aws longer vm startup time weekday fig report vm startup time difference three vm type different timeofday result confirm vm startup time could varying time also observed smaller older generation vm type could substantial vm startup time change compared bigger newer generation vms shown fig instance specifically tnano aws showed dynamic change startup time fig show vm startup time change gcp vm type three different region different timeofday similar aws result startup time gcp vms varying timeofday startup time affected location factor eg geographical region shown fig estandard vms asiasoutheast europewest significant change startup time vms useast result reported fig consistent finding section iiic iiid also result indicate vm startup time provider affected temporal factor vm startup time fluctuation amplified factor different vm type aws geographical locationsregions gcp observation potential factor bullet spot preemptible vms low availability model longer slower startup time ondemand vms bullet temporal factor different time change vms startup time moreover vms startup time amplified factor like vm type locationsregions iv discussion comparison previous measurement result compare analysis result previous report see much improvement made cloud provider comparison use awss measurement result reported mao et al measurement aws gcp abrita et al please note result graph mao et al measurement section interpretation graph table original author report therefore result fig table viii may marginal difference original result iva vm startup time comparison different vm image size first compare vm startup time various vm image size fig show awss vm startup time measured mao et al work different vm size measurement aws clearly showed vm startup time positive correlation vm image size based result assume aws used external storage store vm image interintradata center network may increase vm startup time however aws appear pattern vms startup time aws offer nearconstant vm startup time various image size moreover image size used work much larger vm image size used eg g v g measured startup time much smaller previous measurement implying aws significantly improved data center infrastructure aws could dramatically reduce vm startup time iva vm startup time comparison different vm type next compare vm startup time different vm type fig show startup time difference mao et al measurement measurement due year gap could directly compare vm startup time using fig gcp vm startup time fluctuation vms estandard instance type different time day result measured linux vm gb fig comparison previous work mao et al vm startup time different vm image size fig aws vm startup time change three vm type tnano tsmall tamedium different time day result contain measurement result linux vms instance type instead tried compare startup time similar vm type shown fig except micro instance type newer instance used work show significant reduction startup time result also confirms newer generation instance often show faster startup time older generation instance one finding described section iiic fig report comparison vm startup time previous report abrita et al measurement aws work abrita et al commonly measured startup time three vm type tnano tmicro mlarge aws vm startup time shown fig considerably different previous comparison mao et al specifically abrita et al reported much faster vm startup time second measurement result even faster warm startup time three vm type believe difference abrita et al used different vm image size andor template used work early stage work observed similar startup time creating vms default o image without extra data image since detailed information regarding vm image used abrita et al unknown presume using different vm image may reason faster startup time reported abrita et al work fig b show startup time comparison gcp measurement result abrita et al compared startup time result fmicro gsmall nlstandard vm type vm type commonly measured result abrita et al showed much faster vm startup time measurement cold startup time abrita et al result similar warm startup time vm type tried perform investigation understand differencessimilarities lack description measurement methodology especially procedure measure coldwarm startup time therefore assume majority measurement abrita et al contains warm startup time result vib vm startup time comparison different region measurement vm startup time per different region also compared abrita et al benchmark result comparison startup time tmicro aws three region gcp fmicros startup time three region used table vii report comparison result provider vm startup time difference similar previous vm type comparison reported section iva tmicro aws showed faster vm startup time abrita et al report warm startup time work also assume vm image size difference use default vm image gcp fmicros startup time measured abrita et al also close warm startup time measurement thus hold conclusion described section iva vib spot instance startup time comparison spot vms startup time compared result reported mao et al table viii report comparison result shown table spot instance second startup time significant portion slow startup time mainly related bidding process determining spot price however aws released new spot pricing model slower bidding process replaced simplified mechanism aws user quickly move vm startup process fair comparison calculate vm startup time without bidding process subtracting bidding time whole spot vm startup time reported original author calculated result shown table viii please refer value parenthesis startup time spot bidding process second result similar ondemand vm startup time reported fig except tmicro slower second ondemand vms spot vms however measurement show spot instance second startup time quicker measurement indicating aws improves spot infrastructure significantly provides much faster startup time summary comparison compared measurement two relevant previous report vm startup time comparing result mao et al confirm aws made significant improvement vm startup time currently much quicker vm startup time ondemand spot instance however compared fig comparison previous work abrita et al vm startup time different vm type aws gcp note vm image size measured abrita et al specified fig comparison previous work mao et al vm startup time different vm type note vm image size measurement g result work contain vm image size abrita et al result could confirm improvement change vm startup time able reproduce result could difference vm configuration measurement methodology ie cold v warm startup time vm image size use case accurate knowledge vm startup time critical designing effective predictive autoscaling policy predictive autoscaling new vms provisioned advance handle increased workload increased workload arrives without accurate knowledge vm startup time newlyprovisioned vms may created early leading idle vms wasted resource without knowledge newly provisioned vms may also started late delayed provision make resource underprovisioning resulting low performance qualityofservice qos requirement violation accurate knowledge vm startup time also crucial reliable cloud simulation instead actual execution cloud cloud simulator typically use execution time profile vms simulation therefore accuracy simulation result depends accuracy profile furthermore reported paper vm startup time considerably longer thus ignored therefore accurate vm startup time also important factor considered cloud simulator reliable simulation result v related work large body work measured performance cloud infrastructure cpu io network application performance regarding vm startup time mao et al performed measurement study vm startup time aws ec azure rackspace author identified several factor could affect vm startup time abrita et al reported benchmarking result vm startup time three cloud provider however previous work measurement result limitation used current cloud research resource management first measurement mao et al performed year ago result correctly reflect current status vm startup time number mechanism proposed applied optimizing vm provisioning process cloud data center necessary measure updated vm startup time provide uptodate information research community second report abrita et al provides recent statistic vm startup time benchmarking result employed limited vm configuration unclear measurement methodology moreover analysis measurement study considered much broader set vm configuration configuration aws configuration gcp including instance type image size data center location conducted measurement study much extended period time three month example mao et al used vm type aws abrita et al considered vm type aws vm type gcp work employed vm type provider measurement result collected across zone four region provider able collect analyze data point vm startup time therefore report much comprehensive thorough analysis vm startup time diverse configuration realistic scenario vi conclusion work report analysis vm startup time aws gcp measured analyzed vm startup time diverse configuration include two different o type vm type four different vm image size gb gb four geographical region two u one europe one asia two purchase model ondemand v spotpreemptible collected data point provider three month measurement analyzed data point identified factor change vm startup time measurement result show vm startup time varying significantly due diverse factor o type vm image size vm instance type data center location caching mechanism cloud provider eg gcp compared measurement analysis result work prior measurement study comparing measurement confirmed cloud provider specifically aws made significant improvement vm startup time currently offer much quicker vm startup time compared previous measurement result acknowledgment author thank radhika bhavsar contribution earlier version work reference michael armbrust armando fox rean griffith anthony joseph randy h katz andy konwinski gunho lee david patterson ariel rabkin ion stoica matei zaharia view cloud computing communication acm amazon web service httpsawsamazoncomhttpsawsamazoncom google cloud platform httpscloudgooglecomhttpscloudgooglecom openstack httpswwwopenstackorghttpswwwopenstackorg docker httpswwwdockercomhttpswwwdockercom gvisor httpsgithubcomgooglegvisorhttpsgithubcomgooglegvisor benjamin hindman andy konwinski matei zaharia ali ghodsi anthony joseph randy h katz scott shenker ion stoica mesos platform finegrained resource sharing data center usenix symposium networked system design implementation nsdi boston april muhammad tirmazi adam barker nan deng md e haque zhijing gene qin steven hand mor harcholbalter john wilkes borg next generation european conference computer system eurosys heraklion greece april aws lambda httpsawsamazoncomlambdahttpsawsamazoncomlambda eric jonas oifan pu shivarian venkataraman ion stoica benjamin recht occupy cloud distributed computing acm symposium cloud computing socc santa clara ca usa september paul c castro vatche ishakian vinod muthusamy aleksander slominski rise serverless computing communication acm amazon elastic container service httpsawsamazoncomecshttpsawsamazoncomecs kubernetes httpskubernetesiohttpskubernetesio dong du tianyi yu yubin xia biyuyang zuang guanglu yan chenggang qin qixuan wu haibo chen catalyzer submillisecond startup serverless computing initializationless boeing acm international conference architectural support programming language operating system asplos lausanne switzerland march jorg schad jens dittrich jorgearmlofu quianruiz runtime measurement cloud observing analyzing reducing variance proc vldb endow alexandro isup nezhi yigitsbi dick h j epema performance variability production cloud service ieeeacm international symposium cluster cloud grid computing ccgrid newport beach ca usa may study performance variation predictability public iaa cloud acm trans internet technology sen glenna mann john saunders wei wang lori l pollock mary lou soffa statisticsbased performance testing methodology cloud application acm joint meeting european software engineering conference symposium foundation software engineering esecfse tallinin estonia august zach hill li ming mao arkaitz ruizalvarez marty humphrey early observation performance window azure acm international symposium high performance distributed computing hpdc chicago illinois usa june iman sadoghi jesus hernandez martin tonglin li kevin brandstatter ketan maheshwari tiago pais pitta de lacerda ruivo gabriele garzoglio steven timm yong zhao ioan raicu understanding performance potential cloud computing scientific application ieee transaction cloud computing roberto r exposito guillermo l taboada sabela ramos jorge gonzalezdominguez juan toutino ramon doolle analysis io performance amazon ec cluster compute high io platform journal grid computing valerio persico pietro marcheta alessio botta antonio pescape measuring network throughput cloud case amazon ec computer network jiawei wen lei lu giuliano casale evgenia smirni le micromanging vms amazon ec ieee international conference cloud computing cloud new york city ny usa june anshul gandhi justin chan analyzing network aws distributed cloud computing sigmetrics performance evaluation review ming mao marty humphrey performance study vm startup time cloud ieee international conference cloud computing cloud honolulu hi usa june gabriella carrozza luigi battaglia vittorio manetti antonio marotta roberto canonico stefano avallone evaluation vm provisioning time cloud platform missioncritical infrastructure ieeeacm international symposium cluster cloud grid computing ccgrid chicago il usa may benchcouncil international symposium bench seattle wa usa december ming mao marty humphrey autoscaling minimize cost meet application deadline cloud workflow international conference high performance computing networking storage analysis sc seattle wa usa november kee kim wei wang yanjun qi marty humphrey empirical evaluation workload forecasting technique predictive cloud resource scaling ieee international conference cloud computing cloud san francisco ca usa june kaveh razavi thilo kiclamann scalable virtual machine development using vm image cache international conference high performance computing networking storage analysis sc denver co usa november kaveh razavi ana ion thilo kiclamann squirrel scatter hoarding vm image content laas compute node international symposium highperformance parallel distributed computing hpdc vancouver bc canada june kaveh razavi gerrit van der kolk thilo kielmann prebaked muvms scalable instant vm startup iaa cloud ieee international conference distributed computing system icdcs columbus oh june jiwei xu wenbo zhang zhenyu zhang tao wang tao huang clusteringbased acceleration virtual machine image deduplication cloud environment journal system software filipe manco costin lupu florian schmidt jose mendes simon kuenzer sumit sati kenichi yasukata costin raiciu felipe hui vm lighter safer container acm symp operating system principle sosp shanghai china october yifan zhang kai niu weigang wu keqin li yu zhou speeding vm startup cooperative vm image caching ieee transaction cloud computing page thuylinh nguyen ramon nou adrien lebre yolo speeding vm docker boot time reducing io operation european conference parallel distributed processing europar gottingen germany august alexandru agache marc brooker alexandra iordache anthony liguori rolf neugebauer phil piwonka dianamaria popa freeracker lightweight virtualization serverless application usenix symposium networked system design implementation nsdi santa clara ca usa february alexandru isosup simon ostermann nezhi yigitsbi radu prodan thomas fahringer dick h j epema performance analysis cloud computing service manytasks scientific computing ieee transaction parallel distributed system kee kim jacob steele yanjun qi marty humphrey comprehensive elastic resource management ensure predictable performance scientific application public iaa cloud ieeeacm international conference utility cloud computing ucc london united kingdom december alexey ilushkin ahmed alieldin nikolas herbst andre bauer alessandro vittorio papadopoulos dick h j epema alexandru isosup experimental performance evaluation autoscalers complex workflow acm transaction modeling performance evaluation computing system kee kim wei wang yanjun qi marty humphrey cloudinsight utilizing council expert predict future cloud application workload ieee international conference cloud computing cloud san francisco ca usa july vinoth kumaran jayakumar jaewoo lee kee kim wei wang selfoptimized generic workload prediction framework cloud computing ieee international parallel distributed processing symposium ipdps virtual event may kee kim wei wang yanjun qi marty humphrey forecasting cloud application workload cloudinsight predictive resource management ieee transaction cloud computing page rodrigo n calheiros rajiv ranjan anton beloglazov cesar f de rose rajkumar buyya cloudsim toolkit modeling simulation cloud computing environment evaluation resource provisioning algorithm software practice experience spe alberto nunez jose luis vazquezpoletti agustin c caminero gabriel g castane jesus carretero ignacio martin llorente iccloud flexible scalable cloud infrastructure simulator journal grid computing dzmitry kliazovich pascal bouvy samee ullah khan greencloud packetlevel simulator energyaware cloud computing data center journal supercomputing kee kim wei wang marty humphrey pic public iaa cloud simulator ieee international conference cloud computing cloud new york city ny usa june alexander pucher emre gul rich wolski chandra krintz using trustworthy simulation engineer cloud scheduler ieee international conference cloud engineering ice tempe az usa march jianwei hao ting jiang wei wang kee kim empirical analysis vm startup time public iaa cloud ieee international conference cloud computing cloud virtual event september amazon ec spot instance httpsawsamazoncomecspothttpsawsamazoncomecspot preemptible vm instance httpscloudgooglecomcomputedocsinstancespreemptiblehttpscloudgooglecomcomputedocsinstancespreemptible michael smit bradley simmons marin litoiu distributed applicationlevel monitoring heterogeneous cloud using stream processing future generation computing system aws sdk python boto httpsawsamazoncomsdkforpythonhttpsawsamazoncomsdkforpython compute engine client library httpscloudgooglecomcomputedocsapilibrarygoogleapispythonclientlibraryhttpscloudgooglecomcomputedocsapilibrarygoogleapispythonclientlibrary aleksander maricq dmitry duplyakin ivo jimenez carlos maltzahn ryan stutsamen robert ricci ana klimovic taming performance variability usenix symposium operating system design implementation osdi carlsbad ca usa october pradipta de manish gupta manoj soni aditya thatte caching vm instance fast vm provisioning comparative evaluation european conference parallel processing europar rhodes island greece august google compute engine machine type httpscloudgooglecomcomputedocsmachinetypeshttpscloudgooglecomcomputedocsmachinetypes zillow saving money emr auto scaling spot instance httpswwwzillowcomtechsavemoneycmrautoscalnergspothttpswwwzillowcomtechsavemoneycmrautoscalnergspot thanhphuong pham sasko risto thomas fahringer performance behavior characterization amazon ec spot instance ieee international conference cloud computing cloud san francisco ca usa july cheng wang qianlin liang bhuvan urgaonkar empirical analysis amazon ec spot instance feature affecting costeffective resource procurement acm transaction modeling performance evaluation computing system amazon web service new amazon ec spot pricing model simplified purchasing without bidding fewer interruption httpsawsamazoncomblogscomputenewamazonecspotpricinghttpsawsamazoncomblogscomputenewamazonecspotpricing netflix technology blog server netflixs predictive auto scaling engine httpsnetflixtechnoblecomscryernetflixspredictiveautoscalingengineaffchttpsnetflixtechnoblecomscryernetflixspredictiveautoscalingengineaffc n roy dubey gokhale efficient autoscaling cloud using predictive model workload forecasting ieee international conference cloud computing nikolas roman herbst nikolaus huber samuel kounev erich amrehn selfadaptive workload classification forecasting proactive resource provisioning acmspec international conference performance engineering icpe christian sierp jorg domanschke anne koziolek sebastian krach jakub krzyuba ralf h reussen rapid testing iaa resource management algorithm via cloud middleware simulation acmspec international conference performance engineering icpe title impact startup cost grid operator power price equilibrium transcription impact startup cost grid operator power price equilibrium footnote thank oxfordman institute providing historical price used calibrate model elexon providing historical data balancing mechanism used determine physical characteristic power plant connected uk power grid miha troha mathematical institute oxford university andrew wile building radcliffe observatory quarter woodstock road oxford ox gg united kingdom trohamathsoxacuk author supported grant slovene human resource development scholarship fund oxfordman institute raphael hauser mathematical institute oxford university andrew wile building radcliffe observatory quarter woodstock road oxford ox gg united kingdom hausermathsoxacuk associate professor numerical mathematics tanaka fellow applied mathematics pembroke college oxford author supported grant ephx engineering physical science research council uk plant rampup rampdown constant market design together transmission line play vital role behavior electricity price first game theoretic model modeling electricity price proposed unique relation forward spot price given twostage market one producer one consumer want maximize meanvariance objective function model extended multistage setting convex risk measure extended work setting one producer consumer optimize meanvariance objective function contrast game theoretic model capacity rampup rampdown constraint power plant included modeling profit power plant difference power price fuel cost together emission obligation work also incorporates idea structural approach model consistent observable fuel emission price applied model calculate electricity price uk taking account entire power grid consisting hundred power plant numerical simulation show model tendency underestimate spot price peak hour overestimate offpeak hour argued may occur startup cost included model paper extend model presented include startup cost various methodology already proposed include startup cost see example rely price uplift approach first power price without startup cost calculated price uplifted reflect startup cost model startup cost included mathematically rigorous fashion without relying uplift heuristic show startup cost responsible introducing many spike spot electricity price reduce number spike include grid operator responsible managing grid reliable delivery electricity enhancing model second part paper paper organized follows section give detailed mathematical description model section present numerical result numerical result motivate u introduce grid operator section conclude paper section problem description section provide detailed description model use purpose modeling term structure electricity price model belongs class game theoretic equilibrium model market participant divided consumer producer set consumer denoted c cardinality cinfty similarly set producer denoted p cardinality pinfty producer owns portfolio power plant different characteristic capacity startup cost rampup rampdown constraint efficiency fuel type set fuel type denoted l set rpl denote power plant owned producer pin p run fuel lin l set rpl may empty since producer typically possible type power plant moreover allows u include non physical trader bank speculator electricity generation facility without physical demand electricity producer pin p rpl lin l see section useful introduce another player named hypothetical market agent besides producer consumer hypothetical market agent play role electricity market ensures term structure electricity price market clearing condition satisfied electricity forward contract interested delivery time tj jin jtprime power delivery time tj traded numerous forward contract time ti iin ij electricity price time ti delivery time tj denoted pilefttitjright since contract trading time later delivery time exist require tmaxijtj jin j number forward contract ie sumjin jij denoted n uncertainty modeled filtered probability space leftomegamathcalfmathbbfmathcalfttin imathbbpright icupjin jij sigmaalgebra mathcalft represents information available time exogenous variable appear model aggregate power demand dlefttjright delivery period jin j b price fuel forward contract gllefttitjright fuel lin l delivery period jin j trading period iin ij c price emission forward contract gemlefttitjright jin j iin ij electricity price exogenous variable assumed adapted filtration leftmathcalftrighttin finite second moment let vkinmathbbrnk nkinmathbbn kin k kk given vector convenience define vector concatenation operator leftrightkin kvkleftvtopvktoprighttop producer producer pin p participates electricity fuel emission market forward well spot contract available market electricity price fuel price emission price denoted pilefttitjright gllefttitjright lin l gemlefttitjright respectively producer may participate market buying selling forward spot contract number electricity forward contract producer pin p buy trading time ti iin ij delivery time tj jin j denoted vplefttitjright similarly number fuel emission forward contract producer pin p buy trading time ti iin ij delivery time tj jin j denoted fpllefttitjright lin l oplefttitjright respectively producer generally nonempty portfolio power plant actual production electricity power plant rin rpl delivery time tj jin j denoted widehatwplrlefttjright production variable section investigate production power plant closely power plant rin rpl pin p lin l maximum export limit minimum stable limit denoted overlinewmaxplrlefttjright overlinewminplrlefttjright respectively maximum export limit defines maximum production capacity power plant minimum stable limit defines minimum production power plant able maintain longer period time allow parameter time dependent account maintenance power plant stable production power plant must satisfy widehatwplrlefttjrightinleftrightcupleftoverlinew minplrlefttjrightoverlinewmaxplrlefttjrightright tag jin j allowed power plant production widehatwplrlefttjrightinleftoverlinewminplr lefttjrightright short period time ie rampup rampdown phase formulate constraint optimization framework introduce new decision variable wplrleftkrightlefttjright kinleftright following meaning wplrleftrightlefttjright jin j continuous variable power plant fully ramped time tj power plant producing time tj wplrleftrightlefttjrightinleftright power plant rampup rampdown phase optimization framework wplrleftrightlefttjright defined wplrleftrightlefttjrightinleftright wplrleftrightlefttjright jin j binary variable power plant fully ramped time tj otherwise optimization framework wplrleftrightlefttjright defined wplrleftrightlefttjrightleq wplrleftright lefttjright wplrleftrightlefttjrightinleftright wplrleftrightlefttjrightinmathbbz wplrleftrightlefttjright jin jbackslashleftright continuous variable denotes increase wplrleftrightlefttjright time tj time tj optimization framework wplrleftrightlefttjright defined wplrleftrightlefttjrightgeq wplrleftright lefttjrightwplrleftrightlefttjright wplrleftrightlefttjrightinleftright wplrlefttjright jin jsetminusleftright binary variable power plant rampup phase otherwise optimization framework wplrlefttjright defined wplrlefttjrightgeq wplrlefttjrightwpl rlefttjright wplrlefttjrightinleftright wplrlefttjrightinmathbbz wplrlefttjright jin jsetminusleftright binary variable power plant rampdown phase otherwise optimization framework wplrlefttjright defined wplrlefttjrightgeq wplrlefttjrightwplrlefttjright wplrlefttjrightinleftright wplrlefttjrightinmathbbz wplrlefttjright jin j continuous variable widehatwplrlefttjrightwplrlefttjright overlinewminplrlefttjrightwplrlefttjright leftoverlinewmaxplrlefttjrightoverlinewminplr lefttjrightright wplrlefttjrightleq wplrlefttjright wplrlefttjrightinleftright variable wplrlefttjright tell u whether power plant running time tj power plant running time tj wplrlefttjright also widehatwplrlefttjright hand power plant fully ramped time tj wplrlefttjright wplrlefttjrightinleftright thus widehatwplrlefttjrightinleftoverlinewminplrleft tjrightoverlinewmaxplrlefttjrightright maximum rampup maximum rampdown constraint producer pin p able arbitrarily choose decision variable constraint limit feasible set change production power plant one delivery period next limited rampup rampdown constraint jinlefttprimeright tprime denotes last delivery period lin l rin rpl constraint expressed triangleoverlinewminplrlefttjrightleqwidehatwplr lefttjrightwidehatwplrlefttjrightleqtriangle overlinewmaxplrlefttjright tag triangleoverlinewmaxplr triangleoverlinewminplr represent maximum rate ramping respectively ramping rate highly depend type power plant gas power plant increase production zero maximum minute action may take day week nuclear power plant using rewrite constraint jinlefttprimeright overlinewminplrlefttjright leq wplrlefttjrightoverlinewminplr lefttjrightwplrlefttjrightleftoverlinew maxplrlefttjrightoverlinewminplrlefttj rightright wplrlefttjrightoverlinewminplr lefttjrightwplrlefttjrightleftoverlinewmaxplrlefttjrightoverlinewminplrlefttjrightright leq triangleoverlinewmaxplrlefttjright tagadditionally power plant rampup phase increase production finish rampup phase fast possible requirement enforced wplrlefttjrightgeqminleftwplrlefttj rightfractriangleoverlinewmaxplrlefttjrightoverline wminplrlefttjrightright tag jintprime since constraint relevant rampup phase reformulate jintprime wplrlefttjrightgeqminleftwplrlefttj rightfractriangleoverlinewmaxplrlefttjrightoverline wminplrlefttjrightrightmleftwplr lefttjrightright tag mgeq fractriangleoverlinewmaxplrlefttjright overlinewminplrlefttjright available optimization solver able handle constraint include min max function thus apply well established approach handle logical constraint introduce new binary decision variable wplrlefttjright wplrlefttjrightinleftright tag wplrlefttjrightinmathbbz tag jin j make sure least one following constraint wplrlefttjrightgeq wplrlefttjright fractriangleoverlinewmaxplrlefttjrightoverlinew minplrlefttjrightmleftwplrlefttj rightrightmwplrlefttjright tag wplrlefttjrightgeq mleftwplrleftt jrightrightmleftwplrlefttjrightright tag mgeq enforced similarly power plant rampdown phase decrease production finish rampdown phase fast possible requirement enforced wplrlefttjrightleqmaxleftwplrlefttj rightfractriangleoverlinewminplrlefttjrightoverline wminplrlefttjrightrightmleftwplr lefttjrightright tag jintprime available optimization solver able handle constraint include min max function apply approach described introduce new binary decision variable wplrlefttjright wplrlefttjrightinleftright tag wplrlefttjrightinmathbbz tag jin j make sure least one following constraint wplrlefttjrightleq wplrlefttjright fractriangleoverlinewminplrlefttjrightoverlinewmin plrlefttjrightmleftwplrlefttjright rightmwplrlefttjright tag wplrlefttjrightleq mleftwplrlefttj rightrightmleftwplrlefttjrightright tag enforced inequality constraint bound number electricity contract producer allowed trade vtradeleq vplefttitjrightleq vtrade tag large vtrade trading infinite number contract would clearly lead bankruptcy one counterparties involved must thus prevented shown vtrade chosen large enough constraint impact optimal solution eliminated problem equality constraint also equality constraint connect power plant production electricity fuel emission trading jin j electricity sold forward spot market together must equal actually produced electricity ie sumiin ijvplefttitjrightsumlin lsumrin rpl widehatwplrlefttjright tag producer pin p make sure sufficient amount fuel lin l bought cover electricity production delivery period jin j constraint expressed sumrin rplwidehatwplrlefttjrightcplrsumiin jfpllefttitjright tag cplr efficiency power plant rin rpl carbon emission obligation constraint written sumjin jsumiin ijolefttitjrightsumjin jsuml lsumrin rplwidehatwplrlefttjrightgplr tag gplr denotes carbon emission intensity factor power plant rin rpl constraint ensures enough emission certificate bought cover electricity production whole planning horizon producer optimization problem notation decision variable greatly simplified concatenated electricity trading vector vplefttjrightleftrightiin ijvplefttitjright vpleftrightjin jvplefttjright fuel trading vector fplefttitjrightleftrightlin lfpllefttitj right fplefttjrightleftrightiin ijfplefttitjright fpleftrightjin jfplefttjright emission trading vector oplefttjrightleftrightiin ijoplefttitjright opleftrightjin joplefttjright electricity production vector wplrlefttjrightleftrightkinleftldotsrightwp lrleftkrightlefttjright wpllefttjrightleftrightrin rplwplrlefttjright wplefttjrightleftrightlin lwpllefttjright wpleftrightjin jwplefttjright finally vpleftvptopfptopoptopwptoprighttop similarly notation price greatly simplified concatenated electricity price vector pilefttjrightleftrightiin ijpilefttitjright pileftrightjin jevarepsilon tjpilefttjright hatrinmathbbr constant interest rate fuel price vector glefttitjrightleftrightlin lgllefttitjright glefttjrightleftrightiin ijglefttitjright gleftrightjin jevarepsilon tjglefttjright emission price vector gemlefttjrightleftrightiin ijgemlefttitjright gemleftrightjin jevarepsilon tjgemlefttjright startup cost vector widehatsplrleftsplrrighttop splleftrightrin rplwidehatsplr spleftrightlin lspl widehatspleftrightjin jevarepsilon tjsp splrgeq denotes startup cost power plant rin rpl finally pipleftpitopgtopgemtopleftwidehatspright toprighttop producer goal maximize expected profit subject risk budget work assume risk budget expressed meanvariance framework main argument thatsupports decision delta hedging widely used hedging strategy captured framework profit ppleftvppipright producer pin p calculated ppleftvppiprightsumjin jehattautjleftsumi ijpptitjleftvppiprightsumlin lsumrin r plsplrwplrlefttjrightright tag profit pptitjleftvppipright iin ij jin j calculated pptitjleftvppiprightpilefttitjrightvp lefttitjrightoplefttitjrightgemlefttitj rightsumlin lgllefttitjrightfpllefttitj right meanvariance optimization framework producer interested meanvariance utility psipleftvpright mathbbemathbbpleftppleftvppipright righttfraclambdapmathrmvarmathbbpleftppleftvppiprightright mathbbemathbbpleftpiprighttopvptfrac lambdapvptopqpvp lambdap risk preference parameter qpmathbbemathbbpleftleftpipmathbbemathbbp leftpiprightrightleftpipmathbbemathbbpleftpip rightrighttopright extended covariance matrix objective solve following optimization problem phipmaxvpquadpsipleftvpright pr subject standard approach solving optimization problem binary constraint consider continuous relaxation define continuous relaxation problem pr phipmaxvpquadpsipleftvpright widetildepr subject problem widetildepr problem problem pr except include integrality constraint consumer make assumption demand completely inelastic consumer cin c responsible satisfying proportion pcin total demand dlefttjright time tj jin j since pc proportion clearly sumcin cpc number electricity forward contract consumer cin c buy trading time ti iin ij delivery time tj jin j denoted vclefttitjright inequality constraint bound number electricity contract consumer allowed trade vtradeleq vplefttitjrightleq vtrade tag large vtrade trading infinite number contract would clearly lead bankruptcy one counterparties involved must thus prevented shown vtrade chosen large enough constraint impact optimal solution eliminated problem equality constraint consumer responsible satisfying electricity demand end user electricity demand expected satisfied tj ie sumiin ijvclefttitjrightpcdlefttjright tagat time calculating optimal decision consumer assume know future realization demand dlefttjright precisely knowledge future realization demand change player take recourse action recalculating optimal decision updated demand forecast consumer may assume able execute recourse action job grid operator ensure sufficient amount electricity available market consumer optimization problem similarly producer simplify notation introducing electricity trading vector vclefttjrightleftrightiin ijvclefttitjright vcleftrightjin jvclefttjright consumer would like maximize profit subject risk budget similar model introduced producer assume risk budget expressed meanvariance framework profit consumer cin c calculated pcleftvcpirightsumjin jehatrtjleftsumiin jpilefttitjrightvclefttitjrightscpcd lefttjrightright tag hatrinmathbbr denotes constant interest rate scinmathbbr denotes contractually fixed price consumer cin c receives selling electricity end user eg household business etc note contractually fixed price sc affect optimal objective value consumer cin c also optimal solution since primarily interested optimal solution simplify notation set sc correct optimal value always calculated via postprocessing optimal solution already known may needed risk management purpose note reality end user change electricity provider consequently proportion pc cin c one could model end user electricity market similar equilibrium model presented focus paper assume proportion pc constant period interest meanvariance optimization framework consumer interested meanvariance utility psicleftvcright mathbbemathbbpleftpcleftvcpirightright tfraclambdactextvarmathbbpleftpcleftvcpirightright mathbbemathbbpleftpirighttopvctfrac lambdacvctopqcvc lambdac risk preference qcmathbbemathbbpleftleftpimathbbemathbbpleft pirightrightleftpimathbbemathbbpleftpirightright topright covariance matrix objective solve following optimization problem phicmaxvcpsicleftvcright co subject matrix notation analysis problem greatly simplified compact notation introduced equality constraint producer pin p expressed apvp inequality constraint bpvpleq bp apinmathbbrjleftlrighttimesdim vp bpinmathbbrnptimesdim vp bpinmathbbrnp np denotes number inequality constraint producer pin p define feasible set widetildespleftvpapvpaptext bpvpleq bpright spleftvpapvpaptext bpvpleq bptext leftvprightiinleftrightforall iinmathcalirightwhere mathcali denotes set decision variable binarity constraint ie wplrklefttjright kin rin rpl jin j useful investigate inner structure matrix considering equality constraint see apleftbeginarrayccchatahatap hatahatapendarrayright tag hatainmathbbrjtimes nhatainmathbbrjl time nlhatapinmathbbrjtimesdim wphatap inmathbbrjltimesdim wp one see matrix hata hata independent producer pin p matrix hatap hatap depend producer pin p one investigate structure hata see hataleftbeginarrayccc ddots jendarrayright tag j jin j row vector one length ij similarly hataleftbeginarrayccchatacdots vdotsddotsvdotsvdots cdotshata cdotsnendarrayright tag number row block notation l first l row correspond last row corresponds profit producer pin p written ppleftvppiprightpiptopvp compact notation meanvariance utility producer pin p calculated psipleftvpmathbbemathbbpleftpirightright mathbbemathbbpleftpiptopvptfrac lambdapvptopleftpipmathbbemathbbpleftpip rightrightleftpipmathbbemathbbpleftpipright righttopvpright mathbbemathbbpleftpiprighttopvptfrac lambdapvptopqpvp qpmathbbemathbbpleftleftpipmathbbemathbbp leftpiprightrightleftpipmathbbemathbbpleftpip rightrighttopright tag inner structure matrix qp following qpleftbeginarrayccchatqhatq hatqtophatq endarrayright tag hatqinmathbbrntimes nhatqinmathbbrntimesdim b pdim opmathbbrntimes nlhatqinmathbbrnl time nl one see hatq hatq hatq depend producer pin p size larger matrix qp depends producer pin p different producer different number power plant producer pin p attempt solve following optimization problem phipleftmathbbemathbbpleftpirightrightmaxvpin pmathbbemathbbpleftpiprighttopvpfrac lambdapvptopqpvp following continuous relaxation phipleftmathbbemathbbpleftpirightrightmaxvpin pmathbbemathbbpleftpiprighttopvpfrac lambdapvptopqpvpthe equality constraint consumer cin c expressed acvcac inequality constraint bcvcleq bc achata bcinmathbbrntimes n acinmathbbrj bcinmathbbrn define feasible set scleftvcinmathbbrnacvcactext bcvcleq b cright profit consumer cin c written pcleftvcpirightpitopvc compact notation meanvariance utility consumer cin c calculated psicleftvcmathbbemathbbpleftpirightright mathbbemathbbpleftpitopvctfraclambda cvctopleftpimathbbemathbbpleftpirightrightleft pimathbbemathbbpleftpirightrighttopvcright mathbbemathbbpleftpirighttopvctfrac lambdacvctopqcvc qcmathbbemathbbpleftleftpimathbbemathbbpleft pirightrightleftpimathbbemathbbpleftpirightright topright tag moreover note qchatq cin c set sc wlog consumer cin c attempt solve following optimization problem phicleftmathbbemathbbpleftpirightrightmaxvcin cmathbbemathbbpleftpirighttopvcfraclambdac vctopqcvc hypothetical market agent given price vector electricity pi fuel g emission gem producer pin p consumer cin c calculate optimal electricity trading vector vp vc solving pr co respectively however player necessary able execute calculated optimal trading strategy may find counterparty trade reality contract consists buyer seller imposes additional constraint also called market clearing constraint match number short long electricity contract iin ij jin j follows sumcin cvclefttitjrightsumpin pvplefttitj right tag electricity market responsible satisfying constraint matching buyer seller matching done sharing price order book information among market participant current price long contract short contract mean current price low asks start submitted higher price converse occurs short contract long contract eventually electricity price number long short contract match found price constraint satisfied naturally without explicitly requiring player satisfy best interest ie maximizes meanvariance objective function question formulate equilibrium constraint optimization framework naive approach writing market clearing constraint ordinary constraint force player satisfy regardless price need mechanism model matching buyer seller performed electricity market purpose introduce hypothetical market agent allowed slowly change electricity price ensure satisfied let hypothetical market agent following profit function beginarrayrclpmleftpivrightsumjin jehatrtj leftsumiin ijpilefttitjrightleftsumcin cvc lefttitjrightsumpin pvplefttitjrightright right mathbbemathbbpleftpirighttopleftsumcin cvc sumpin pvprightendarray tagand expected profit psimleftmathbbemathbbpleftpirightvrightmathbbe mathbbpleftpmleftvpirightright tag vleftvptopvctoprighttop vpleftrightpin pvp vcleftrightcin cvc let hypothetical market agent attempt solve phimleftvrightmaxmathbbemathbbpleftpirightpsim leftmathbbemathbbpleftpirightvright tag kkt condition matrix notation read sumcin cvcsumpin pvp tag exactly note equivalence theoretical result applied caution algorithmic framework formulation clearly unstable since small mismatch market clearing constraint sends price pminfty thus stable formulation hypothetical market agent must found let u analyze hypothetical market agent following slightly altered optimization problem hma beginarrayllmaxmathbbemathbbpleftpirightpsim leftmathbbemathbbpleftpirightvright textstsumcin cvcsumpin pvp mumendarray mum denotes dual variable equality constraint hma trivial check optimality condition hma correspond formulation hma clearly stable market clearing constraint satisfied precisely equality constraint dual variable make sure optimal solution remains market clearing constraint removed calculation optimal solution formulation hma used definition hypothetical market agent rest work see affecting expected electricity price hypothetical agent change electricity price process immediately clear construct stochastic process stochastic process exists refer reader constructive proof existence given proof based doob decomposition theorem allow hypothetical market agent control integrable predictable term process keeping martingale term process intact argumentation define vpleftrightpin pvp vleftvptopvctoprighttop nash equilibrium binarity constraint producer significantly complicate analysis problem pr thus focus continuous relaxation widetildepr instead show various numerical result section section binarity constraint significant impact equilibrium electricity price using continuous relaxation widetildepr interested finding nash equilibrium defined definition nash equilibrium ne decision v mathbbemathbbpleftpiright constitute nash equilibrium every producer pin p vp strategy psipleftvpmathbbemathbbpleftpirightrightleqpsi pleftvpmathbbemathbbpleftpirightright vpinwidetildesp every consumer cin c vc strategy psicleftvcmathbbemathbbpleftpirightrightleqpsi cleftvcmathbbemathbbpleftpirightright vcin sc price vector mathbbemathbbpleftpiright maximizes objective function hypothetical market agent ie psimleftmathbbemathbbpleftpirightvrightleqpsim leftmathbbemathbbpleftpirightvright mathbbemathbbpleftpirightin sm definition clear whether ne problem exists whether unique problem thoroughly investigated roughly speaking shown demand end user covered available system power plant ne exists moreover power plant similar enough big gap efficiency power plant one show ne also unique hand power plant similar enough expected equilibrium price electricity contract might interval instead single point paper focus numerical calculation ne assumption existence solution paper assume following slightly stricter condition assumption pin p exists vector vp apvpap bpvpbp cin c exists vector vc acvcac bcvcbc vector vp vc chosen satisfied quadratic programming formulation traditional approach solving equilibrium optimization problem shadow price see example however approach valid inequality constraint present shadow price depend set active constraint thus one use approach active set known inequality constrainted optimization active set usually know advance thus different approach needed proposed formulation seen extension shadow price concept inequality constrained optimization problem naive approach solving inequality constrained equilibrium optimization problem would choose expected price vector mathbbemathbbpleftpiright calculate optimal solution producer pin p consumer cin c solving widehatpr mathrmco respectively price leftsumcin cvcsumpin pvpright close zero solution found mathbbemathbbpleftpiright equilibrium expected price vector otherwise adjust expected price vector repeat procedure see algorithm costly requires solve large optimization problem ie calculate optimal solution producer consumer multiple time section show much better naive approach using reformulation propose large optimization problem must solved necessary sufficient condition vk kin pcup c mathbbemathbbpleftpiright constitute ne following due fact assumption implies slater condition mathbbemathbbpleftpikrighttoplambdakq kvkbktopetakaktopmuk etaktopleftbkvkbkright bkvkbk leq tag akvkak etak geq sumcin cvcsumpin pvp last equation corresponds kkt condition hypothetical market agent interpret kkt condition one large optimization problem includes new definition hma hypothetical market agent see join decision variable one vector xleftvtopmathbbemathbbpleftpirighttoprighttop rewrite equality constraint axa aleftaptopapptopactopacc topunderbracenrighttop number ending zero equal n aleftbeginarraycccccccap ddotsvdots app ac ddotsvdots acc mpcdotsmppicdotsiendarrayright mpinmathbbrntimesmathbbrdim vp matrix defined mplefttextdiagleftunderbracenrightleftbeginarray ccccdots vdotsddotsvdots cdotsendarrayrightright inequality constraint bxleq b bleftbptopbpptopbctopbcc toprighttop bleftbeginarraycccccccbp ddotsvdots bpp bc ddotsvdots bccendarrayright objective function pitopxfracxtopqx pileftmathbbemathbbpleftpiprighttop mathbbemathbbpleftpipprighttopunderbrace cnrighttop pip pip element pi set zero qleftbeginarrayccccccclambdapqpmptop ddotsvdots lambdappqppmpptop lambdacqci ddotsvdots lambdaccqcci mpcdotsmppicdotsiendarrayright dual variable etaleftetaptopetapptopetactopetacctopright muleftmuptopmupptopmuctop mucctopmumtopright setting reformulate kkt condition follows piqxbtopetaatopmu etatopleftbxbright bxb leq axa eta geq mum tagsince additional constraint mum dual variable problem handled available quadratic programming solver reformulate problem dual form start formulating optimization problem kkt condition maxx pitopxtfracxtopqx tag textst axa bxleq b mum defining lagrangian mathcallleftxmuetarightleftbeginarrayrlfracx topqxpitopxleftaxarighttopmuleftbxbrighttopeta textif etageq inftytextotherwiseendarrayright one show qsucceq vector satisfy market clearing constraint proof see mathcallleftxmuetaright therefore smooth convex function unconstrained minimizer determined solving mathcaldxmathcallleftxmuetaright calculating mathcaldxmathcallleftxmuetarightqxpiatopmubtopeta inserting pi back lagrangian equivalent formulation obtained follows mathcallleftxmuetarightleftbeginarrayrlfracx topqxatopmubtopetatextif etageq text qxpiatopmubtopeta inftytextotherwiseendarrayright relating latter maximization optimization problem following formulation obtained maxxmueta tfracxtopqxmutopaetatopb tag textst qxatopmubtoplambdapi etageq mum problem equivalent problem solved using quadratic programming algorithm based discussion section see obtained considering problem overlinepr continuous relaxation problem pr estimate error caused continuous relaxation use following procedure calculate equilibrium electricity price mathbbemathbbpleftpiright solving problem using equilibrium electricity price mathbbemathbbpleftpiright previous step calculate optimal trading vector vp pin p producer optimal trading vector vc cin c consumer solving pr co respectively calculate error textmiqpsumcin cvcsumpin pvp order verify procedure apply following similar procedure calculate equilibrium electricity price mathbbemathbbpleftpiright solving problem using equilibrium electricity price mathbbemathbbpleftpiright previous step calculate optimal trading vector vp pin p producer optimal trading vector vc cin c consumer solving widehatpr co respectively calculate error textqpsumcin cvcsumpin pvp section section present miqp qp modeling entire uk power grid numerical result section discus numerical result apply model section model realistic uk power grid estimation parameter section investigate estimate various parameter power plant enter model described section uk power plant required submit available capacity well rampup rampdown constraint grid operator half hourly basis data publicly available elexon website challenging problem estimate efficiency cplr startup cost splr carbon emission intensity factor gplr power plant rin rpl purpose calibration assume producer risk neutral set lambdap pin p furthermore neglect rampup rampdown constraint since power plant treated separately avoid writing subscriptssuperscripts plr footnote httpwwwbmreportscomhttpwwwbmreportscom explore detail calibration process let u establish relationship prove useful later section see power plant produce time tj income selling electricity spot price greater cost purchasing required fuel emission certificate current spot price remember power plant cover startup cost thus power plant run fuel lin l produce electricity time tj pilefttjtjrightcgllefttjtjrightggemlefttjt jright tag must hold production take place immediately clear must hold spot contract available let u investigate hold also forward future electricity contract available market trading time ti iin ij rational producer could enter short electricity forward contract simultaneously long fuel emission forward contract pilefttitjrightcgllefttitjrightggemlefttitjright tag delivery time tj producer two option acquire delivery fuel emission certificate bought trading time ti produce electricity case observes following profit widehatplefttjrightpilefttitjrightcglleftt itjrightggemlefttitjright produce electricity instead close forward electricity fuel emission contract case observes following profit widehatplefttjright leftpilefttitjrightpilefttjtjright rightcleftgllefttitjrightgllefttjtjrightright gleftgemlefttitjrightgemlefttjtj rightright power plant rin rpl run tj widehatplefttjrightwidehatplefttjright tag reordering term easy see inequality equivalent inequality using reasoning conclude purpose determining stack enough focus spot electricity fuel emission contract taking account startup cost equation described section profit maximization problem power plant written maxwleftrightwleftrightwleftrightsumjin j widetildewlefttjrightoverlineplefttjrightwleft rightlefttjrights tag subject wleftrightlefttjrightgeq wleftrightlefttj rightwleftrightlefttjright forall jin jbackslashleftright tag wleftrightlefttjrightleq wleftrightleft tjright forall jin j wleftkrightlefttjrightinleftright forall jin jkinleftright wleftrightlefttjrightinmathbbz forall jin j tag widehatwlefttjrightwleftrightlefttjrightoverline wminlefttjrightwleftrightlefttjrightleft overlinewmaxlefttjrightoverlinewminlefttjright rightforall jin j tag barplefttjrightpilefttjtjrightcglefttjtj rightggemlefttjtjrightforall jin j tag note impose integrality constraint variable wleftrightlefttjrightjin j implied account neglected risk premium trading cost maintenance cost etc introduce additional constant include barplefttjrightpilefttjtjrightcglefttjtj rightggemlefttjtjrightmforall jin j tag interested know optimal solution problem depends parameter c g let widetildewlefttjcgmsright denote optimal production problem task find c g satisfy mincgmssumjin jleftwidetildewlefttjcgmsright tildewlefttjrightright tag tildewlefttjright denotes observed historical production power plant optimization problem bilevel optimization problem corresponds outer optimization problem corresponds inner optimization problem traditionally problem difficult solve highly nonconvex process finding optimal solution outer optimization problem requires many expensive evaluation inner integer programming optimization problem however show case difficult integer programming problem replaced tractable linear programming problem without affecting optimal solution use following proposition see optimal solution problem calculated linear programming relaxation proposition matrix constraint problem totally unimodular let u write matrix inequality constraint leftaaarightleftbeginarraycwleftright wleftright wleftrightendarrayrightleq tag block matrix first show matrix leftaaright totally unimodular note entry leftright moreover row contains exactly two nonzero entry one entry sufficient condition matrix leftaaright totally unimodular trivial see apleftbeginarraycci endarrayrightq permutation matrix p q appropriate size implies matrix leftaaaright totally unimodular bound constraint included using similar argument virtue proposition relax binarity constraint reformulate problem linear programming problem beginarrayrlmaxwleftrightwleftrightwleft rightsumjin jwidehatwlefttjrightoverlineplefttj rightwleftrightlefttjrights textstwleftrightlefttjrightgeq wleftrightleftt jrightwleftrightlefttjrightforall jin jbackslash leftright wleftrightlefttjrightleq wleftrightlefttj rightforall jin j wleftkrightlefttjrightinleftrightkinleft rightforall jin jendarray tag combination particle swarm algorithm gurobi used solve bilevel optimization problem practice particle swarm applied outer gurobi inner optimization problem power plant used training sample obtained period uk power grid section apply model entire system uk power plant focus coal gas oil power plant power plant adapt production cover change demand thus responsible setting price nuclear power plant modeled explicitly rampup rampdown constraint tight production almost constant time usually deviate maximum production maintenance reason renewable source interconnectors modeled explicitly require different treatment covered paper section define demand dlefttjright jin j dlefttjrightdactlefttjrightprenwlefttjrightp interlefttjright tag dactlefttjright denotes actual demand uk power system prenwlefttjright denotes production renewable source including wind solar biomass hydro pumped storage pinterlefttjright denotes inflow power uk power system interconnectors make model useful practice one model term exceeds scope paper goal calculate electricity spot price information available interested delivery period assume two type power contract available first month ahead contract traded cover delivery four day second type spot contract requires immediate delivery traded half hour separately use future price coal gas oil available since historical demand forecast available used realized demand instead standard practice literature use model practice one could use demand forecast available flexon webpage develop new approach since information ownership power plant assumed one producer owns power plant connected uk grid one consumer responsible satisfying demand end user reality market participant information ownership incorporated model set lambdak kin pcup c impact risk aversion producer consumer thoroughly investigated described previous section estimated parameter c g power plant training sample obtained period footnote httpwwwbmreportscomhttpwwwbmreportscom motivate inclusion startup cost first investigate simplified version model described section neglect startup cost figure show output model startup cost set zero figure left hand side depicts calculated energy mix coal gas power plant figure right hand side depicts actually observed energy mix figure contain also spot price calculated model actually observed spot price difference calculated observed production fuel depicted figure see model predicts energy mix closely moreover daily pattern electricity price predicted model similar actually observed one model correctly predicted electricity price higher peak hour peak hour furthermore calculated electricity price two daily peak occur almost time historically observed price graph also reveal problem model firstly see model underestimate spot price peak hour overestimate offpeak hour similar result also found secondly two spike observed price captured model motivated u extend model incorporate startup cost power plant purpose calibration applied approach described section calculated equilibrium price energy mix startup cost included depicted figure comparing figure figure see calculated equilibrium price capture daily variation actually observed price much closely correctly predicts spike also forecast many false positive figure show inclusion startup cost slightly improved error energy mix calculation interesting explore condition electricity grid time spike electricity price occur descriptive parameter standing reserve srlefttjright jin j defined srlefttjrightsumpin psumlin lsumrin rplleftwpl rleftrightlefttjrightwplrleftrightlefttj rightrightleftoverlinewmaxplrlefttjrightoverlinew minplrlefttjrightright tag quantifies much power plant currently running increase production figure comparison calculated historical electricity price energy mix startup cost excluded ie set zero figure difference calculated observed gas coal production new power plant must turned since power plant severe constraint startup time low standing reserve usually implies low stability electricity grid figure depicts calculated standing reserve relevant time period see price spike occur standing reserve close zero situation new power plant must turned quickly afterwards cover temporary extra demand thus startup cost spread short period time high electricity price required action profitable however reality time low standing reserve rare grid operator responsible providing reliable electricity delivery preventing time low standing reserve achieved incentivizing power plant start production even profitable cost action distributed among market participant include grid operator model discussed next section remaining part section evaluate error caused using continuous relaxation problem pr follow procedure described section miqp error depicted dashed line figure estimate effect numerical error also calculated qp error shown figure solid line see figure leftsumein cvesumpin pvprightinftyapprox mathrmmwh also reality production consumption match exactly mismatch reflected change power line frequency uk nominal power line frequency hz grid operator called national grid responsible keeping frequency within pm nominal power line frequency figure difference calculated observed gas coal production including startup cost figure comparison calculated historical electricity price energy mix startup cost included see figure largest error occur time demand high since overall demand electricity peak hour approximately mathrmgw conclude error within pm error bound model presented paper neglect loss electricity transmission distribution line according world bank transmission distribution loss uk account approximately maximum minimum total electricity production loss vary time change pm footnote see httpdataworldbankorgindicatoregelclosszscountriesgbdisplaygraphhttpdataworldbankorgindicatoregelclosszscountriesgbdisplaygraph due reason believe purpose modeling realistic power price enough consider continuous relaxation problem pr neglect binarity constraint grid operator section investigated include startup cost model calculated equilibrium price contained many spike reality prevented intervention grid operator time standing reserve low grid operator incentivizes additional power plant turn thus help making delivery electricity reliable section investigate incorporate action grid operator model quadratic programming formulation cost grid operator action help maintain high reliability delivery electricity distributed among market participant market participant collectively penalized situation standing reserve low figure error caused considering problem widehatpr instead problem pr figure standing reserve relevant time period include penalization model propose quadratic penalty function upsilonleftsrlefttjrightright defined upsilonleftsrlefttjrightrightalphaleftmaxleftbetasr lefttjrightrightright tag alpha beta used describe risk aversion grid operator parameter beta tell u level standing reserve grid operator start take action parameter alpha tell u much grid operator willing incentivize power plant start production one incorporate grid operator problem beginarrayllmaxxpitopxfracxtopqxsumjin j upsilonleftsrlefttjrightright textstaxa bxleq b mumendarray tag might immediately clear write penalty term quadratic programming framework follow approach widely used linear programming literature introduce decision variable zlefttjright following constraint beginarrayrclzlefttjrightgeq zlefttjrightgeqbetasrlefttjrightendarray tag hold jin j penalty function upsilonleftsrlefttjrightright written function zlefttjright upsilonleftzlefttjrightrightalpha zlefttjright tag fit quadratic programming framework one apply procedure described section find convenient dual formulation problem numerical result section investigate numerical result inclusion grid operator calculated equilibrium price energy mix depicted figure figure left hand side depicts calculated energy mix coal gas power plant figure right hand side depicts actually observed energy mix figure contain also spot price calculated model actually observed spot price set alpha beta determination optimal standing reserve challenging problem received lot attention literature see example exceeds scope paper comparing figure figure see calculated equilibrium electricity price figure follows daily variation much closely calculated equilibrium electricity price contain spike grid operator prevented managing standing reserve model assume player grid operator perfect demand forecast however reality usually case grid operator able predict demand perfectly corrective action often required large corrective action required time close delivery usually rather inefficient open cycle gas turbine power plant flexible enough cover demand cause spike electricity price modeling recursive action exceeds scope paper left future work figure show inclusion grid operator significant impact error energy mix figure show standing reserve inclusion grid operator standing reserve never reach zero since grid operator prevents requiring new power plant start production ensure stability electricity grid make spot price smoother significantly decrease number spike figure depicts miqp qp error inclusion grid operator comparing figure figure see inclusion grid operator small impact error remained within pm error bound conclusion paper proposed tractable quadratic programming formulation calculating equilibrium term structure electricity price startup cost power plant included model numerical simulation showed startup cost large impact electricity price startup cost included model calculated spot electricity price peak hour increased offpeak hour decreased moreover startup cost responsible introducing frequent high spike spot electricity price observed price spike occur time standing reserve low reality time low standing reserve rare intervention grid operator responsible providing reliable electricity delivery preventing time low standing reserve included grid operator model second part paper significantly decreased number spike moreover computed equilibrium electricity price matched historically observed price closely numerical simulation performed modeling realistic uk power grid consisting hundred power plant tractable approach estimate startup cost power plant historical production also proposed reference barlow diffusion model electricity price mathematical finance pp hendrik bessembinder michael l lemmon equilibrium pricing optimal hedging electricity forward market journal finance pp figure comparison calculated historical electricity price energy mix startup cost grid operator included figure difference calculated observed gas coal production including grid operator wolfgang behler risk premia electricity future dynamic equilibrium model risk management commodity market john wiley son ltd pp wolfgang behler jens mollermerbach valuation electricity future reducedform v dynamic equilibrium model mannheim finance working paper rene carmona michael coulon daniel schwarz electricity price modeling asset valuation multifuel structural approach mathematics financial economics pp le clewlow chris strickland multifactor model energy derivative research paper series quantitative finance research centre university technology sydney dec valuing energy option one factor model fitted forward price research paper series quantitative finance research centre university technology sydney apr gauthier de maere daertycke yves smerers liquidity risk power exchange generalized nash equilibrium model k de vos j drissen dynamic operating reserve strategy wind power integration renewable power generation iet pp e ela b kirby e lannoye milligan flynn b zavadil omalley evolution operating reserve determination wind power integration study power energy society general meeting ieee july pp isabel garcia claudia kloppelberg gernot muller estimation stable carma model application electricity spot price statistical modelling pp paul r gribik william w hogan susan l pope marketclearing electricity price energy uplift technical report harvard university cambridge dec inc gurobi optimization gurobi optimizer reference manual ben hambly sam howison ting kluge modelling spike pricing swing option electricity market quantitative finance pp figure error caused considering problem overlinepr instead problem pr figure standing reserve relevant time period scott harvey william w hogan market power market simulation technical report center business government harvard university cambridge july sam howison michael c coulon stochastic behaviour electricity bid stack fundamental driver power price journal energy market julio j lucia eduardo schwartz electricity price power derivative evidence nordic power exchange martinez methodology consideration startup cost marginal cost estimated production cost model electricity market eem th international conference european may pp thilo meyerbrands peter tankov multifactor jumpdiffusion model electricity price international journal theoretical applied finance ijtaf pp troin r hausen calculation power price equilibrium arxiv eprints existence uniqueness power price equilibrium arxiv eprints aismaelf vaz luisn vicente particle swarm pattern search method bound constrained global optimization journal global optimization pp binginging zhang pb luh e litvinov tongxin zheng feng zhao reducing uplift payment electricity market power system conference exposition psce ieeepes mar pp title varying importance extrinsic factor success startup fundraising competition earlystage network growthstage transcription varying importance extrinsic factor success startup fundraising competition earlystage network growthstage clement gastaud theophile carniel jeanmichel dalle agoranov paris france sorbonne universite paris france icnrs ecole polytechnique france jeanmicheldallesorbonneuniversitefr abstract address issue factor driving startup success raising fund using popular public startup database crunchbase explicitly take account two extrinsic characteristic startup competition company face using similarity measure derived wordvec algorithm well position investor investment network pioneering use graph neural network gnn recent deep learning technique enables handling graph whole show different stage fundraising early growthstage associated different success factor result suggest marked relevance startup competition early stage growthstage fundraising influenced network feature factor tend average global model could lead false impression startup success fundraising would mostly influenced intrinsic characteristic notably founder introduction literature overview case venture capital investment risk particularly high startup business model uncertain simple vision state affair startup usually sufficient determine whether succeed given considerable attention startup drawn past decade private investor public policy maker alike getting better understanding criterion driving startup success therefore become particularly relevant issue early literature topic highlighted several feature importance respect startup success failure besides earnings asset analysis including human capital founder psychology country culture using interview survey recently largescale public database appeared notably creation crunchbase used numerous recent academic study sometimes replaced supplemented similar datasets dealroom cbinsight owler context emerging field research started developing predictive model based largescale datasets predicting startup success failure predicting ma predicting crowdfunding success addition standard economic financial variable fund raised cash burn etc approach highlight importance feature influence founder online social medium presence else topic associated company description according study element driving investor decision would seem intrinsic potential investment target addressable market founder business model etc notably expense extrinsic context environmentrelated feature study started taking consideration element related environment startup operates particularly relevant availability information environment potential impact notably respect competition embeddedness startup given ecosystem sector specifically paper focused social network notably using distance feature investor company predict investment link prediction task recently different context predicting longterm success startup bonaventura et al made use network employee startup company interestingly result show crisis event increase unpredictability entrepreneurial ecosystem however none article look funding stage separately although earlystage growth latestage funding round mostly conducted different actor might therefore driven different dynamic sharchilev et al order predict future round simply includes stage previous funding round feature consider different model stage put differently wouldnt surprising factor interest investor choosing potential venture would differ different stage investment mixing stage factor critical certain round others could averaged disappear global model analyze funding stage separately paper addition accounting various intrinsic characteristic startup also explicitly ass relevance two key extrinsic feature explicitly account competition introducing dedicated metric although competition key element suitable affect influence startup success mostly neglected related work notable exception included two feature related competition model used metric directly retrieved crunchbase though crunchbase notoriously lacking regard point element since removed website crowdsourced database competitor also found owler focused large company would appropriate predict startup success extent knowledge different context predicting ma shi et al proposed framework evaluate competition large scale applying topic modeling technique startup description calculating business similarity measure representation following shi et al accordance suggestion progress direction using recent advance natural language processing technique compute company representation explicitly account network startup investor relation centrality investor also pioneering data use graph neural network gnn recent deep learning development enables handling graph whole machine learning prediction task instead simply using feature derived find predicting success startup raising fund indeed associated different feature early growth stage earlystage fundraising notably associated competition low intensity competition markedly increasing probability raising fund lower relevance network feature growthstage fundraising seems notably influenced network feature competition playing limited role characteristic competition network average global model giving false impression neither competition network would matter much compared characteristic founder notably whereas matter different stage startup fundraising material method data used exploit dataset startup crunchbase mainstream source data academic research startup retrieved date creation location sectoral tag describing economic sector technology andor market textual description notably information respect fund startup raised including date raised amount funding nature funding round identity investor well article mentioning company available crunchbase figure addition retrieved information available people giving u particular proxy regard experience startup founder overall dataset consists company investment round people news article data used prediction model however textual data potentially contains relevant information implies preprocessing particular encoding textual description startup vector enables similarity measurement startup use ass competition prediction task first noted definition success startup straightforward investor point view startup successful able make successful exit sell share profit usually ipo acquisition methodologically though acquisition always successful exit investor might able recover initial investment process furthermore since neither entry exit price generally disclosed extremely difficult discriminate successful unsuccessful exit addition already profitable startup might remain private long time qualify startup unsuccessful would misleading basically apart success crowdfunding ma main option suggested literature measure success predict future funding round ie given time determining startup raise fund next year parameter paper conduct two study parallel first semester study startup raised fund venture seed round try predict raise another round get acquired go public following two year remove study startup already acquired public end studied semester looking problem different time stamp allows u increase number sample also staying focused active startup second analysis focused different stage fundraiser instead taking startup raised semester select raised seed series series b time number sample reported table investor network propose position startup investor investor network extremely important determining success first stated vcs rely heavily network source startup startup thus better chance finding next investor existing one well connected second put forward faced great uncertainty quality young company third party rely prominence affiliate company make judgment quality young company endorsed prominent exchange partner perform better otherwise comparable venture lack prominent associate vc reputation also positively linked postipo performance order ass reputation investor use betweenness centrality relationship network done using crunchbase data build graph using coinvestments investor linked invested startup edge graph weighted weight proportional number portfolio company investor common prediction model startup use feature max mean sum centrality investor competition analysis assessing competition using startup description requires use measure similarity literature text embedding similarity skyrocketed last year rise natural language processing commonly used algorithm include bagofwords tfidf model used batista et al classify crunchbase startup category topic modeling approach lsi lda used shi et al recently using word embeddings wordvec glove fasttext among approach predictionbased wordembeddings found yield better result countbased counterpart thus use wordvec approach paper wordvec us neural network predict probable word around every given word compute lowdimensional vectorial representation word encoding context word used vectorial representation give u position wordspace word allowing u compute distance similarity measure word dimension
Original Title: An Empirical Analysis of VM Startup Times in Public IaaS Clouds: An
  Extended Report
Original Transcription: # An Empirical Analysis of VM Startup Times in Public IaaS Clouds: An Extended Report

Jianwei Hao\({}^{{\dagger}*}\), Ting Jiang\({}^{{\dagger}*}\), Wei Wang\({}^{{\ddagger}}\), and In Kee Kim\({}^{{\dagger}}\)

\({}^{{\dagger}}\)University of Georgia, Department of Computer Science, {jhao, ting.jiang1, inkee.kim}@uga.edu

\({}^{{\ddagger}}\)The University of Texas, San Antonio, Department of Computer Science, wei.wang@utsa.edu

* Both authors contributed equally.

###### Abstract

VM startup time is an essential factor in designing elastic cloud applications. For example, a cloud application with autoscaling can reduce under- and over-provisioning of VM instances with a precise estimation of VM startup time, and in turn, it is likely to guarantee the application's performance and improve the cost efficiency. However, VM startup time has been little studied, and available measurement results performed previously did not consider various configurations of VMs for modern cloud applications.

In this work, we perform comprehensive measurements and analysis of VM startup time from two major cloud providers, namely Amazon Web Services (AWS) and Google Cloud Platform (GCP). With three months of measurements, we collected more than 300,000 data points from each provider by applying a set of configurations, including 11+ VM types, four different data center locations, four VM image sizes, two OS types, and two purchase models (e.g., spot/preemptible VMs vs. on-demand VMs). With extensive analysis, we found that VM startup time can vary significantly because of several important factors, such as VM image sizes, data center locations, VM types, and OS types. Moreover, by comparing with previous measurement results, we confirm that cloud providers (specifically AWS) made significant improvements for the VM startup times and currently have much quicker VM startup times than in the past.

 Performance Measurement and Analysis; VM Startup Time; IaaS; Cloud Computing;

## I Introduction

For the last decade, cloud computing has become a primary computing infrastructure as many applications have been increasingly migrated from on-premise environments to clouds [1, 2, 3, 4]. At the same time, cloud infrastructure itself has been continuously evolving so that cloud computing currently offers diverse resource models, such as VMs, containers [5, 6] and orchestration [7, 8], and cloud functions [9, 10, 11], to support various application types and service scenarios. While VMs are the most traditional resource type in the clouds, VMs are still widely used as common hosting platforms for both user applications and different resource models, like containers [12], Kubernetes [13], and serverless/cloud functions [14].

Various aspects of performance implications in VMs and IaaS (Infrastructure as a Service) clouds, such as Amazon EC2, have been extensively studied [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]. The measurement results are widely adopted for developing novel cloud applications and cloud infrastructure management systems. In particular, understanding VM startup time [25, 26, 27] is crucial to design elastic resource management systems for cloud applications, such as autoscaling [28, 29]. According to a previous study [25] performed in 2012, VM startup time could vary significantly due to various factors, such as VM image sizes, time-of-day, VM purchase models (on-demand or spot), etc. While the measurement results from the previous work are still useful to current cloud research, a number of mechanisms have been proposed for optimizing VM startup processes in cloud data centers for the last decade [30, 31, 32, 33, 34, 35, 36, 37]. Therefore, it is important to see whether there is an improvement of VM startup time in public cloud providers.

This work aims to provide _up-to-date_ information about VM startup time to the research community so that cloud researchers and practitioners facilitate the design of novel resource and performance management approaches for cloud applications. To this end, we performed an empirical analysis of VM startup times, measured from two widely-used public cloud services, namely AWS (Amazon Web Services) [2] and GCP (Google Cloud Platform) [3]. The measurement was conducted for three months with extensive trials. Each trial was performed for at least 14 consecutive days to cover the temporal impact (time-of-day, date-of-week) [16, 18, 38] on VM startup time. In total, we obtained more than 300,000 data points from each provider by exploiting a different set of factors that can change the VM startup time. The data was collected by using 11+ widely-used VM types, which are commonly hosted in four service regions, located in the U.S., Europe, and Asia. Four VM image sizes (from 32GB to 256GB), two different OS types (Linux and Windows), and two VM purchase models (on-demand and spot/preemptible) were also applied. Moreover, we measured two different types of VM startup time; a _cold startup_ and _warm startup_ time. The cold startup time means the VM's startup time when a user creates a new VM so that this startup time is equivalent to the VM's creation (provisioning) time. The warm startup time is the startup time measured when a user (re)starts an existing (and stopped) VM instance.

This paper reports (cold/warm) VM startup times of AWS and GCP with diverse configurations for realistic VM use-cases. With extensive analysis, we found that VMs' startup time could be significantly changed due to several factors, such as OS types, VM image sizes, VM types (and generation), and locations/regions. Table I summarizes our analysis and important factors for changing VM startup times.

After identifying the critical factors for VM startup times, we compare our analysis results with the previous studies [25, 27]. The comparison confirms that cloud providers(specifically AWS) made significant improvements for the VM startup times and currently have much quicker VM startup times. Moreover, implications and findings from this study will help various research in cloud resource and application management. In particular, autoscaling algorithms [28, 29, 39, 40, 41, 42, 43] with the accurate VM startup time can determine the exact scaling point for handling increased user demands. And, cloud simulators [44, 45, 46, 47, 48] can generate more reliable simulation results with this study.

It is worth noting that this paper is an extended version of our previous work [49], which is published in the 2021 IEEE International Conference on Cloud Computing (IEEE CLOUD). This version of the paper contains additional measurements and analysis on VM start times in AWS and GCP, which are not included in the IEEE CLOUD 2021 version.

As a result, this work has the following contributions.

1. We performed a thorough measurement study on VM startup time of two major cloud providers; AWS and GCP, which are widely used in research and industry.

2. With three months of measurement, we collected a large number of data points with various VM configurations, reflecting the realistic use-cases of VMs in clouds.

3. We report VM startup times, in AWS and GCP, with diverse configurations. With extensive analysis, we found several factors that considerably change the VM startup times.

4. We found that GCP uses a cache-based approach to reduce VMs' startup time. Recently used VM images are stored in the GCP data center for the next 75 - 100 minutes, and users can benefit from using cached VM images to reduce VM startup times.

We structure the rest of the paper as follows. Section II describes the experimental setup for measuring VM startup time. Section III reports the measurement results of VM startup times from both AWS and GCP. Section IV provides a comparison with previous works. Section V summarizes related work. Finally, Section VI concludes this paper.

## II Measurement Methodology

This section describes the methodology for measuring VM startup time from two public cloud providers.

### _Measurement Setup_

We considered diverse factors that can lead to changing the VM startup time. The following configurations were used for this measurement to collect VM startup times with more realistic scenarios.

**Cloud Providers.** We measured VM startup time from AWS [2] and GCP [3]. Because these two providers are widely used in both industry and academic research, it is crucial to see if there VM startup time differences exist in both providers. We used VMs from AWS EC2 and Google Compute Engine, which are IaaS models of these providers.

**Measurement Period.** The measurement was conducted for three months in 2020 with a set of trials. Each measurement trial has at least two-weeks of duration to check there are temporal impacts on the VM startup time, such as time-of-day, day-of-week.

**Data Center Locations (Regions and Availability Zones).** Table II describes the regions and (availability) zones of two providers used for this measurement. We chose four regions, located in the U.S. (east and west), Europe, and Asia, to check any correlations between cloud data center locations and the VM startup times. Moreover, each region has multiple zones so that we measured VM startup time from all the zones listed in Table II to see if there are VM startup time fluctuations with different (availability) zones in the regions.

**Instance Types.** Table III shows 12 VM types from AWS and 11 VM types from GCP, used in the measurement to check the VM startup time differences in various instance types. We categorized these VM types into five VM classes: tiny, small, medium, large, and xlarge classes. This classification is based on the memory size of VM types. VM types in each class are not exactly the same, but almost equivalent VM types were chosen from both cloud providers. Moreover, when selecting instance types for the measurement, we considered VMs with different generations and CPU models. For example, we measured the startup time from both t2.small and t3.small instances (in the Small class) from AWS to see if there is the VM startup time difference from the equivalent VM instances with different generations. For the diversity of CPU models, we used t3a.medium and m5a.large with AMD CPUs from AWS. n2 (Intel), n2d (AMD), and e2 (Intel or AMD) instance types from GCP were used for the measurement to check the VM startup time differences due to different CPU models.

**OS Types and VM Image Sizes.** We tested the VM startup times with two different operating systems (Linux and Windows). We used Ubuntu 18.04 LTS for Linux VMs and Windows Server 2016 for Windows VMs. For the VM image sizes, we used four different sizes of user-created VM images, which are 32GB, 64GB, 128GB, and 256GB. The VM images were fully filled by OS and other binary/data files.

**VM Purchase Models.** Both on-demand and low-availability VM models were used for the measurement. The spot instance model [50] (from AWS) and the preemptible instance model [51] (from GCP) were used for the low availability models. Specifically, it is interesting to measure the VM startup time from two different VM purchase models because spot/preemptible instances can have different provisioning processes or a different level of availabilities compared to the on-demand models.

### _Measurement Procedure_

To measure the VM startup time, we did not rely on the VM status information provided by the cloud providers because the VM status is often inaccurate [25, 52]. Instead, we implemented and deployed applications that collect VM startup times by interacting with both cloud providers. The measurement applications calculated the VM startup time based on the very first successful remote access to the target VM. For example, suppose \(t_{request}\) is a time to call cloud APIs to start a VM, and \(t_{access}\) is the first time to successfully access (e.g., login) the VM via ssh or RDP. Then, a VM's startup time can be calculated by \(t_{access}-t_{request}\).

We measured both cold startup (VM provisioning time) and warm startup time (startup time of an existing VM) of VMs. Both startup times of a VM were measured sequentially. During the measurement period, we measured the cold startup time of VMs every hour on the hour, and then, measured the warm startup time after several minutes. For example, a measurement application sent a request for creating a VM to the providers (via AWS boto3 [53] or Google Cloud APIs [54]) at the top of the hour (e.g., 1 a.m.), and the **cold VM startup time** was measured when the measurement application could successfully access the VM. Then, the measurement application stopped the VM. After several minutes (e.g., at 1:10 a.m.), the application sent another request to start the VM and measured the **warm VM startup time** of the VM with successful remote access, and then, the VM was finally terminated. It is worth noting that the VM startup time generally means the cold VM startup time in this work because we found that the cold startup time varies more significantly as per diverse factors, and the warm startup time is fairly consistent in both providers.

## III Measurement Results and Analysis

Our measurement collected more than 300,000 data points from each provider. These data include both warm and cold startup times measured with a set of different configurations in Section II. In total, we measured VM startup time with 7681(for AWS) and 7042 (for GCP) different configurations, and the number of collected samples in each configuration has a range from 350 to 1500. For each configuration, we ensured there were enough samples to obtain accurate VM startup measurement results with high confidence using a method proposed by prior work [55].

Footnote 2: 704 is calculated by 2 (Linux or Windows) \(\times\) 11 (VM types) \(\times\) 4 (Image sizes) \(\times\) 4 (Regions) \(\times\) 2 (On-demand or Preemptible)

### _OS Types_

Different OS types for VMs are widely-recognized factors that can impact VM startup times as per the previous works [25, 30, 32]. Therefore, it is important to see if this factor still changes VM startup time. To confirm the impact of OS types on VM startup times, we measured the VM startup time using Linux and Windows VMs with four different VM image sizes (from 32GB to 256GB).

Table IV reports the average VM startup times of both Linux and Windows instances in AWS and GCP. For the cold startup times, AWS VMs had shorter startup times than the VMs in GCP. In particular, GCP VMs showed 2.22\(\times\), (Linux VMs) and 1.2\(\times\) (Windows VMs) slower startup times compared to the AWS VMs. Regarding the warm startup times, both providers showed similar startup times, and warm startup time is much shorter than cold startup time. The shorter time of the warm startup case is mainly because the VM images are already stored in the physical machine so that the warm startup process does not have any delays from VM image transfer.

Regarding OS impacts for VM startup times, we confirmed that OS types are still impacting the VM startup times based on the measurement result that both cloud providers showed different VM startup times between Linux and Windows VMs. For example, Linux VMs in AWS showed (40%) faster startup times than Windows VMs, whereas, in GCP, Windows VMs had (13%) faster startup times than Linux VMs.

**Observation#1: Different OS types**

\(\bullet\) AWS VMs have faster startup time VMs in GCP.

\(\bullet\) In AWS, the startup times of Linux VMs are 40% faster than Windows VM, but GCP shows the opposite results.

### _VM Image Sizes_

VM image size is another widely accepted factor regarding the variability in the VM startup times [25]. We measure VM startup times with various VM image sizes (from 32GB to 256GB) in AWS and GCP to confirm that VM image size is still changing startup times.

Fig. 1 reports average startup times of AWS Linux and Windows VMs with four different VM image sizes. The results also show both cold and warm startup times of the VMs. Unlike the previous findings, our measurement results confirm that AWS VMs had almost constant startup time regardless of their image sizes. We observed such constant patterns from both OS systems as well as both warm and cold startup times. The maximum startup time difference between the smallest (32GB) and the largest (256GB) image sizes is only 2% - 3% (Linux VMs). This result is clearly different from the widely used assumption that VM startup processes take longer as VM image size increases. We assume that AWS could leverage several optimizations (described in Section V) to provide constant startup time regarding this improvement.

However, the results only show the average startup times, so we also analyzed the distributions of VM startup times with the same image sizes. As shown in Fig. 2, we observed that the VM startup times had multi-modal distributions, indicating

Fig. 1: (AWS) VM startup times with different VM image sizes

Fig. 4: Startup time distribution of GCP Linux VMs

Fig. 3: (GCP) VM startup times with different VM image sizes

Fig. 2: Startup time distribution of AWS Linux VMsthat there were (straggler) VMs that have slow startup times. Specifically, such straggler VMs were clearly observed in AWS VM's cold startup times (e.g., Fig. (a)a). We think such slow VM startup times were affected by other factors that we investigate later in this section.

Fig. 3 reports VM startup times with different image sizes measured from GCP. The GCP results showed that GCP VMs' startup times had a positive correlation with the VM image sizes, which is different from the AWS results. As shown in the figure, the GCP VMs' cold startup time increased as the VM image size increased, and both Linux and Windows VMs showed the same patterns in the change of VM startup time. The measurement results with cold startup time confirm that the VM image sizes are still impacting the VM startup times in GCP. Unlike the cold startup times, the warm startup times of GCP VMs were constant and stable regardless of the VM image sizes. However, stable warm startup times are expected because cloud providers can reuse existing VM images when warm startups are performed.

Fig. 4 shows the distributions of both cold and warm startup times from GCP Linux VMs. An interesting observation from the distributions is that the GCP measurement results had bimodal distributions. In particular, a group of VMs had faster VM startup times than the majority of measured VMs (shown in Fig. (a)a). Our further analysis revealed that the group of VMs having faster startup times was because of GCP's caching mechanism, which is described below.

**VM Image Cache Period in GCP.** As one of the major contributions of this work, we found and analyzed GCP's _VM image cache mechanism_ that effectively reduces the startup time and possibly offers near-constant VM startup time (regardless of its image size). Based on our measurements, we found that the cache-based approach works similarly to several VM startup time reduction mechanisms proposed by the research community [30, 35, 56]. The below procedure explains the VM image caching mechanism used in GCP.

1. If a user creates a VM in a data center (a zone in a region) based on a specific VM image, which has not been used for a certain period of time (**cache period**) in the data center, the VM image is transferred from an image repository in GCP to the data center. And the VM is created based on the transferred VM image, and then, the image is stored in the data center. In this step, the VM startup time follows the pattern reported in Fig. 3.
2. If a user creates another VM based on the VM image (used in step 1) in the same data center _within the cache period_, the VM is created using the VM image stored in the data center. In this case, the cold startup time (VM creation time) is much faster than step 1 because there is no delay from the VM image transmission.
3. If the VM image is no longer used over the cache period, the VM image is removed from the data center.

The VM image caching is only beneficial when a user creates the VM based on a previously used VM image in the same data center (zone) within the cache period. If the user creates a VM, based on the same image, in the _different_ data center (zone) of the same region, then this mechanism does not work even within the cache period. So it is important to know the exact cache period of storing VM images in GCP. Table V reports the VM image cache period in the five GCP regions. These results also include the cache period in all zones in the five regions. As shown in Table V, GCP data centers generally have 70 - 100 minutes of VM image cache period. Within this period, the cold startup time of a VM with a pre-stored (cached) image is much faster than the startup time without cache.

Fig. 5 shows the difference in VM cold startup time with and without cached VM image. VMs with cached images showed much faster cold startup times compared to the uncached cases. With this cache mechanism, VM can reduce startup time by 60% (Linux VM) and 27% (Windows VM).

**Observation #2: Different VM image sizes**

\(\bullet\) AWS VMs show near-constant VM startup times regardless of their image sizes. (However, there are some straggler VMs.)

\(\bullet\) In GCP, VM image sizes still impact the VM startup times. However, the startup times can decrease with GCP's internal caching mechanism. GCP's data centers keep recently created VM images for the next 75-10 minutes; thus, GCP can provide near-constant startup times when recreating VMs (based on the same image) within the cache period.

### _Instance Types_

We also measured VM startup time variations of different VM types. As listed in Table III (in Section II), we used 12 VM types from AWS and 11 VM types from GCP. These

Fig. 5: (GCP) Startup time differences with cached images.

instance types include shared core (or burstable) and general-purpose instances. Fig. 6 reports the average and 90%ile cold startup time variations of 12 instance types in AWS. Please note that the results are only reporting the cold startup times of different VM types with Linux OS, and all image sizes are considered for calculating the results as the VM image sizes do not meaningfully impact the startup times. We omit the results from Windows instances, and the results with Windows VMs had a similar pattern to the results reported in Fig. 6. Among AWS instances, t2 instances (previous generation of burstable instances) showed significantly longer startup time compared to other instance types. t2 instances had 85.15 seconds of average and 158.22 seconds of 90%ile of startup time. In particular, t2.nano, the smallest instance type in AWS (with 1 vCPU and 0.5GB memory), showed the most unstable and longest cold startup time among 12 AWS instances. For other instance types (t3, m4, and m5), the VM types tended to have similar cold startup time with other VM types in the same instance family.

We also observed that different generations in the same purpose instance types (e.g., t2 vs. t3, m4 vs. m5) could have differences in VM startup time. We measured the differences in cold startup times between older and newer generation instances. Fig. 7 shows the comparison results between t2 and t3, as well as m4 and m5 instances. Regarding the comparison between t2 and t3, we also report the results with including, excluding, and solely comparing nano types because t2.nano showed substantially slower startup time. As shown in Fig. 7, the newer generation instances showed faster cold startup times than the older instance types in AWS. For example, t3 instances had 53% to 32% (without nano types) faster startup times compared to t2 instances. Specifically, the average startup time of t3.nano was 70% faster than that of t2.nano, and t2.nano only took 36.87 seconds on average. Regarding the general-purpose instances (m4 and m5), the time differences between two instance families are smaller than t-instances, and the results showed that m5 (newgeneration) instances had 12% faster cold startup time than m4 (older-generation) instances.

Fig. 8 and 9 show the cold startup time variations of 11 VM types in GCP. Fig. 8 contains the measurement results from Linux VMs with 64GB image size, and Fig. 9 has the measurement results from Windows VMs with 32GB image size. We omit the results with other image sizes because the measurements with other image sizes showed similar results with Fig. 8 and 9. Regarding VM types with Linux OS (Fig. 8), share-core (f1-small and gl-micro) and n13 instances showed slower (up to 42%) VM startup time than n2, n2d, and e2-standard instances4. In other words, the first (previous) generation VM types (f1/gl/n1) had longer startup time compared to the second (current) generation VM types (n2/n2d/e2) with Linux OS in GCP.

Fig. 8: (GCP) Cold startup times of different VM types with Linux OS (with 64GB image size).

Fig. 6: (AWS) Cold startup times of different VM types. This graph contains measurement results from on-demand Linux VMs (with all image sizes).

Fig. 7: (AWS) Cold startup time comparison of VMs between older and newer VM types. This graph only contains measurement results from on-demand Linux VMs.

Fig. 9: (GCP) Cold startup times of different VM types with Windows OS (with 32GB image size).

However, the measurement results from Windows VMs (Fig. 9) are different from the results with Linux VMs (Fig. 8). While the n2D (second generation) instances showed the fastest VM startup times, the first generation Windows VMs (e.g., shared-core and n1 instances) had shorter startup time than other second generation (n2/e2) instances. The cold startup time differences between the first and second generation VMs in GCP are summarized in Fig. 10. In general, the newer generation instance types are 9% - 36% faster in startup time than the older generation instance types with Linux, but, the startup times from the newer generation VM types with Windows can be slower (10% - 12%) than the startup times from the older generation VM types.

**Observation #3: Different instance types**

* In AWS, the t2 family shows significantly longer startup time than other instance types. Specifically, t2-nano is the slowest instance among 12 VM types.
* 70% faster startup time than old generation VM instance types (e.g., t2 and m4).
* In GCP, older generation (f1/g1/n1) VMs with Linux OS show slower startup times than newer generation VMs (e.g., n2/e2), but Windows VMs report the opposite results.

### _Regions and Data Center Locations_

In this subsection, we analyzed the VM startup time variations in different regions. Fig. 11 shows the average and 90%ile (cold) VM startup times in four different regions (U.S. east, U.S. west, EU, and Asia) from both providers. Please note that the results in Fig. 11 were collected from on-demand Linux VMs. We omit the results from Windows VMs because they showed similar results with the Linux VMs. As shown in Fig. 11(a), the four regions in AWS had relatively consistent and stable VM cold startup times. The maximum difference in the four regions was only 5.02 seconds on average. However, the VM (cold) startup times (both average and 90%ile) of GCP varied considerably with different regions. The maximum startup time difference was about 40 seconds on average, which is 32% of average startup times of all four regions. Among four regions us-east4 (US-E., N.Va) was the fastest region and us-west1 (US-W., Oregon) showed the longest VM startup times.

We further analyzed the VM startup times per zones, and Fig. 12 reports the Linux VM startup time differences in 14 zones that belong to four AWS regions. Although AWS showed similar VM startup times in four regions (in our previous analysis), the VM startup times were fluctuating as per we choose different zones even within the same region. Among 14 zones we measured in AWS, 3 zones (Z\({}_{\rm A}\) in us-west-2, Z\({}_{\rm B}\) in us-east-1, and Z\({}_{\rm A}\) in ap-east-1) had at least 20% longer startup time compared to the average startup time of all four regions. VMs in another 3 zones (Z\({}_{\rm B}\) in us-west-2, Z\({}_{\rm A}\) and Z\({}_{\rm B}\) in eu-west-3) had 11% to 17%

Fig. 11: Average and 90%ile VM cold startup times in different regions. (a) AWS VM startup times in four regions. US-E. isus-east-1 (N.Va), US-W. isus-west-2 (Oregon), EU: eu-west-3 (Paris), and Asia: ap-southeast-1 (Singapore). (b) GCP VM startup times in four regions. US-E. isus-east4 (N.Va), US-W.: us-west1 (Oregon), EU: europe-west1 (Belgium), and Asia: asia-southeast1 (Singapore).

Fig. 12: (AWS) Average and 90%ile VM cold startup times in 14 different zones. (Z\({}_{\rm A}\) – Z\({}_{\rm F}\): Zone A to Zone F)

Fig. 10: (GCP) Cold startup time comparison of (on-demand) VMs between older and newer VM types.

Fig. 13: (GCP) Average and 90%ile VM cold startup times in 12 different zones. (Z\({}_{\rm A}\) – Z\({}_{\rm F}\): Zone A to Zone D.)longer startup time. Moreover, it is observed that there was up to a 45% difference (average startup time) among different zones, even within the same region (us-west-2). These results thus imply that to minimize VM startup time, AWS users should carefully choose zones when creating VMs.

Fig. 13 shows the VM startup time variations of Linux VMs in 12 different zones within four regions in GCP. The overall startup time variations are similar to the startup time fluctuations reported in Fig. 11(b). And, we also observed there are significant startup time variations from a zone to another belonging to the same geographical region in GCP. For example, Zd in europe-west1 had 32% longer VM startup time than the GCP average. Interestingly, the Zc of the same region had 3rd fastest VM startup time (18% shorter) out of all 12 zones, and the VM startup time difference in the europe-west1 region can be up to 62 seconds. In particular, europe-west1 and asia-southeast1 showed high fluctuations of VM startup time among their zones. We observed that europe-west1 and asia-southeast1 regions could have 33% - 50% differences in the VM startup times. Consequently, these results also imply that GCP users need to carefully choose zones in a specific region when starting VMs for minimizing the VM startup time in order to improve resource elasticity.

**Observation #4: Different data center regions**

\(\bullet\) In both cloud providers, different zones in the same region can significantly differ in VMs' startup time.

### _Other Potential Factors_

In addition to previous analyses, we further investigated potential factors that can change the VM startup time. In this subsection, we provide our analysis of the VM purchase models and temporal factors for changing VM startup times.

**VM Purchase Models.** Public cloud providers typically offer three different ways of purchasing VMs, which are on-demand, reserved, and low-availability models. In particular, low-availability models, such as spot instances in AWS [50] and preemptible VMs in GCP [51], are being increasingly used by cloud users due to the high cost-efficiency. As per a previous study [25] and industry report [58], the AWS spot instances tended to have longer cold startup times, so it is important to see if the previous reports are still valid. A potential factor for AWS spot instances having longer startup time is the bidding process to determine the VMs' price. However, in this study, we always used the bidding prices higher than the current price of spot instances to minimize the delay due to the bidding process and precisely measure the startup time or delay only caused by the cloud infrastructure. Moreover, in this measurement, we experienced the failure of VM startup (or provisioning) in both AWS spot and GCP preemptible VMs due to the limited capacity of such instances. Nevertheless, we do not report the failure rate or statistics of the startup process of the low-availability VMs as it is out of the scope of this work.

Fig. 14 shows the startup times of the five different spot VM types, and the startup times are normalized to the startup time of on-demand VMs. While the startup time of spot instances (e.g., t2-micro type) could be considerably (e.g., 20%) different from the on-demand VMs' startup time, we could not observe any measurement results, which support that spot VMs had longer startup times than on-demand VMs. Interestingly, it is observed that spot VMs can have a shorter startup time than on-demand VMs. i.e., t2/t3 instances in us-west-1. Similar results (as reported in Table 4) were measured from GCP's preemptible VMs. The maximum difference in the startup time between preemptible and on-demand VMs was less than 6% (Windows VMs in asia-southeast1), and most zones/regions have less than 2% - 3% difference in the startup times between two models. Also, we have observed several cases that the preemptible VMs had shorter (cold) startup time. As a result, low-availability models (spot and preemptible VMs) no longer have slower startup time compared to on-demand VMs.

**Temporal Factors.** Cloud data centers may have a different amount of workloads as per "time-of-day" or "day-of-week" because cloud applications (e.g., web) may have repeating or diurnal workload patterns [29, 41]. So, we further analyzed whether such temporal factors could change the VM startup times. We first examined the VM startup time variations on different days of week. While we omit the visualized results

Fig. 14: (AWS) Normalized startup times of spot instances. The startup times of spot VMs are normalized to the startup times of on-demand VMs.

for this variation, both providers commonly showed that the VMs have shorter startup times on Saturdays and Sundays and longer startup times on weekdays. For example, AWS has a 14% longer VM startup times on weekdays.

Fig. 15 reports the VM startup time differences of three VM types at a different time-of-day, and the results confirm that the VM startup times could be varying over time. We also observed that smaller and older generation VM types could have more substantial VM startup time changes compared to bigger and newer generations VMs. As shown in Fig. 15, t2 instances (specifically t2.nano) in AWS showed more dynamic changes in their startup times. Fig. 16 shows the VM startup time changes in a GCP VM type in three different regions at different time-of-day. Similar to the AWS result, the startup times of GCP VMs were varying with time-of-day, but the startup times are more affected by location factors (e.g., geographical regions). As shown in Fig. 16, e2-standard-2 VMs in asia-southeast and europe-west1 had more significant changes in their startup times than VMs in us-east4. The results reported in Fig. 15 and 16 are consistent with our findings in Section III-C and III-D. Also, the results indicate that the VM startup times in both providers can be affected by temporal factors, and the VM startup time fluctuations can be amplified by other factors, such as different VM types (in AWS) and geographical locations/regions (in GCP).

**Observation #5: Other Potential Factors**

\(\bullet\) Spot or preemptible VMs (low availability models) no longer have slower startup time than on-demand VMs.

\(\bullet\) The temporal factors (different times) can change VMs' startup time. Moreover, VMs' startup time can be amplified by other factors like VM types and locations/regions.

## IV Discussion

### _Comparison with Previous Measurement Results_

We compare our analysis results with previous reports to see how much improvement has been made by cloud providers. For the comparison, we use AWS's measurement results reported by Mao et al. [25] in 2012 and measurements from both AWS and GCP by Abrita et al. [27] in 2018. Please note that the results and graphs for Mao et al.'s measurements in this section are our interpretations of graphs and tables in the original author's report [25]. Therefore, the results in Fig. 17 and 18, and Table VIII may have a marginal difference from the original results.

#### Iv-A1 VM Startup Time Comparison with Different VM Image Sizes

We first compare the VM startup times with various VM image sizes. Fig. 17 shows AWS's VM startup times measured by Mao et al. (2012) and by this work with different VM sizes. In the 2012 measurement, AWS clearly showed that the VM startup time has a positive correlation with the VM image sizes. Based on this result, we assume that AWS used external storage to store VM images, and inter/intra-data center networks may increase VM startup time. However, AWS in 2020 does not appear to have such a pattern in their VMs' startup time. AWS now can offer near-constant VM startup time with various image sizes. Moreover, the image sizes we used in this work are much larger than the VM image sizes used in 2012. e.g., up to 4G in 2012 vs. up to 256G in 2020. The measured startup time is much smaller than the previous measurement, implying that AWS significantly improved the data center infrastructures so that and AWS could dramatically reduce VM startup times.

#### Iv-A2 VM Startup Time Comparison with Different VM Types

Next, we compare the VM startup times with different VM types. Fig. 18 shows the startup time differences in Mao et al.'s measurements and our measurements. Due to the 9 years gap, we could not directly compare the VM startup time using the

Fig. 16: (GCP) VM startup time fluctuations of VMs (e2-standard-2 instance type) at different times of day. The results were measured with Linux VM with 32GB.

Fig. 17: Comparison with previous work (Mao et al. in 2012 [25]); VM startup times with different VM image sizes.

Fig. 15: (AWS) VM startup time changes of three VM types (t2.nano, t2.small, and t3a.medium) at different times of day. These results only contain the measurement results with Linux VMs.

same instance types. Instead, we tried to compare the startup time with similar VM types. As shown in Fig. 18, except for micro instance types, the newer instances used in this work show a significant reduction (\(53\%-67\%\)) in their startup times. This result also confirms that newer generation instances often show faster startup times than older generation instances, which is one of our findings described in Section III-C.

Fig. 19 reports the comparison of VM startup times between the previous report by Abrita et al. (2018) and this measurement. For AWS, our work and Abrita et al. commonly measured startup times of three VM types; t2.nano, t2.micro, and m4.large. The AWS VM startup times shown in Fig. 19(a) are considerably different from the previous comparison with Mao et al. Specifically, Abrita et al. reported much faster VM startup times (\(17-19\) seconds) than our measurements, and their results are even faster than warm startup times of these three VM types. We believe this difference can be because Abrita et al. used different VM image sizes and/or templates than those used in our work. In the early stage of this work, we observed similar startup times when creating VMs with default OS images (without extra data in the image). Since detailed information regarding VM images used in Abrita et al. is unknown, we presume that using different VM images _may_ be the reason for the faster startup time reported in Abrita et al.'s work.

Fig. 19(b) shows the startup time comparisons in GCP against the measurement results by Abrita et al. We compared the startup time results from f1-micro, g1-small, and nl-standard-1 VM types because these VM types were commonly measured. The results from Abrita et al. showed much faster VM startup times than our measurement of cold startup times, but Abrita et al's results are very similar to the warm startup times of these VM types. We tried to perform a further investigation to understand the differences/similarities, but [27] lacks the description of measurement methodology (especially for the procedure to measure cold/warm startup times). Therefore, we assume that the majority of the measurements by Abrita et al. contains the warm startup time results.

#### Vi-B3 VM Startup Time Comparison with Different Regions

Our measurements for VM startup times per different regions are also compared with Abrita et al.'s benchmark results. In this comparison, the startup times of t2.micro (AWS) in three regions and GCP f1-micro's startup times for three regions are used. Table VII reports the comparison results. For both providers, the VM startup times' differences are similar to the previous VM types comparisons reported in Section IV-A2. t2.micro of AWS showed faster VM startup times in Abrita et al.'s report than warm startup times from our work. We also assume that this can be because of the VM image size differences and the use of default VM images. In GCP, f1-micro's startup times measured by Abrita et al. are also very close to warm startup times from our measurements; thus, we hold the same conclusion described in Section IV-A2.

#### Vi-B4 Spot Instance Startup Time Comparison

The spot VMs' startup times are compared with the results reported by Mao et al., and Table VIII reports the comparison results. As shown in the table, the spot instances in \(2012\) had \(500-595\) seconds of startup times. A significant portion of such slow startup times was mainly related to the bidding process for determining the spot price [59, 60]. However, after AWS released a new spot pricing model in \(2018\)[61], such a slower bidding process has been replaced with a simplified mechanism so that AWS users can quickly move on to the VM startup process. For a fair comparison, we calculate VM startup time without a bidding process by subtracting bidding time from the whole spot VM startup time reported from the original author. The calculated results are shown in Table VIII (please refer to the values in the parentheses), and the startup times after the spot bidding process are from \(95\) to \(160\) seconds These results are similar to on-demand VM startup times reported in Fig. 18, except for t1.micro, which is \(58\%\) slower (about \(60\) seconds in on-demand VMs, \(95\)s in spot VMs). However, our measurements show that spot instances have \(41\) to \(53\) seconds of startup times, which are \(43\%-69\%\) quicker than the measurements in \(2012\), indicating that AWS improves spot infrastructure significantly and provides much faster startup times.

**Summary of Comparison.** We compared our measurements with the two most relevant previous reports for VM startup times. By comparing with the results by Mao et al., we confirm that AWS made significant improvements for the VM startup times and currently have much quicker VM startup times in both on-demand and spot instances. However, compared with

Fig. 19: Comparison with previous work (Abrita et al. [27]); VM startup times with different VM types in AWS and GCP. Note that the VM image size measured by Abrita et al. was not specified.

Fig. 18: Comparison with previous work (Mao et al. [25]); VM startup times with different VM types. Note that the VM image size in \(2012\) measurement was \(0.5\)G and the results from this work contain all VM image sizes.

Abrita et al.'s results, we could not confirm the improvements or changes in VM startup times because we were not able to reproduce their results. This could be because of differences in VM configurations and measurement methodologies. i.e., cold vs. warm startup times, VM image sizes.

### _Use Cases_

The accurate knowledge of VM startup time is critical for designing effective predictive auto-scaling policies [28, 29, 40, 41, 42, 43, 62, 63, 64]. In predictive auto-scaling, new VMs are provisioned in advance to handle the increased workloads before the increased workload arrives. Without accurate knowledge of the VM startup time, the newly-provisioned VMs may be created too early, leading to idle VMs and wasted resources. Without this knowledge, the newly provisioned VMs may also be started too late. The delayed provision makes resource under-provisioning, resulting in low performance and Quality-of-Service (QoS) requirement violations.

The accurate knowledge of VM startup time is also crucial for reliable cloud simulation. Instead of actual executions in the cloud, cloud simulators typically use execution time profiles of the VMs in their simulations [44, 45, 46, 47, 48, 65]. Therefore, the accuracy of the simulation results depends on the accuracy of these profiles. Furthermore, as reported in this paper, the VM startup time can be considerably longer and thus cannot be ignored. Therefore, accurate VM startup time is also an important factor to be considered by cloud simulators for reliable simulation results.

## V Related Work

There has been a large body of works that measured the performance of cloud infrastructures, such as CPU, IO, Network, and application performance [15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25]. Regarding the VM startup time, Mao et al. [25] performed a measurement study on VM startup times from AWS EC2, Azure, and Rackspace in 2012. The authors identified several factors that could affect the VM startup time. Abrita et al. [27] reported benchmarking results of VM startup times in three cloud providers. However, both previous works' measurement results have limitations to be used for the current cloud research and resource management. First, the measurement from Mao et al. was performed 9 years ago and the results do not correctly reflect the current status of VM startup times. This is because a number of mechanisms [30, 31, 32, 33, 34, 35, 36, 37] have been proposed and applied for optimizing VM provisioning processes in cloud data centers so that it is necessary to measure updated VM startup times to provide up-to-date information to the research community. Second, the report from Abrita et al. provides recent statistics in VM startup times, but the benchmarking results employed the limited VM configurations with unclear measurement methodologies. Moreover, our analysis and measurement study considered a much broader set of VM configurations (768 configurations in AWS, 704 configurations in GCP), including instance types, image sizes, and data center locations, and we conducted this measurement study for a much more extended period of time (three months). For example, Mao et al. used 6 VM types in AWS, and Abrita et al. only considered 5 VM types in AWS and 3 VM types in GCP, but our work employed more than 11 VM types from each provider. Our measurement results were collected across 12+ zones in four regions from both providers, and we were able to collect and analyze 300,000 data points for VM startup times. Therefore, we report a much more comprehensive and thorough analysis of VM startup times with diverse configurations and realistic scenarios.

## VI Conclusion

In this work, we report the analysis of VM startup times in AWS and GCP. We measured and analyzed VM startup times with diverse configurations, which include two different OS types, 11+ VM types, four different VM image sizes (from 32GB to 256GB), four geographical regions (two in the U.S., one in Europe, and one in Asia), and two purchase models (on-demand vs. spot/preemptible). We collected more than 300,000 data points from each provider with three months of measurements, analyzed these data points, and identified factors that change VM startup times. Our measurement results show that VM startup time can be varying significantly due to diverse factors such as OS types, VM image sizes, VM instance types, data center locations, and a caching mechanism in a cloud provider (e.g., GCP).

We then compared measurement and analysis results from this work against prior measurement studies. By comparing with the 2012 measurement [25], we confirmed that cloud providers (specifically AWS) made significant improvements for the VM startup times and currently offer much quicker VM startup times compared to the previous measurement results.

## Acknowledgment

The authors thank Radhika Bhavsar for contributions to earlier versions of this work.

## References

* [1] Michael Armbrust, Armando Fox, Rean Griffith, Anthony D. Joseph, Randy H. Katz, Andy Konwinski, Gunho Lee, David A. Patterson, Ariel Rabkin, Ion Stoica, and Matei Zaharia. A View of Cloud Computing. _Communications of ACM_, 53(4):50-58, 2010.
* [2] Amazon Web Services. [https://aws.amazon.com](https://aws.amazon.com), 2021.
* [3] Google Cloud Platform. [https://cloud.google.com](https://cloud.google.com), 2021.
* [4] OpenStack. [https://www.openstack.org/](https://www.openstack.org/), 2021.
* [5] Docker. [https://www.docker.com/](https://www.docker.com/), 2021.
* [6] gVisor. [https://github.com/google/gvisor](https://github.com/google/gvisor), 2021.
* [7] Benjamin Hindman, Andy Konwinski, Matei Zaharia, Ali Ghodsi, Anthony D. Joseph, Randy H. Katz, Scott Shenker, and Ion Stoica. Mesos: A Platform for Fine-Grained Resource Sharing in the Data Center. In _USENIX Symposium on Networked Systems Design and Implementation (NSDI)_, Boston, MA, April, 2011.
* [8] Muhammad Tirmazi, Adam Barker, Nan Deng, Md E. Haque, Zhijing Gene Qin, Steven Hand, Mor Harchol-Balter, and John Wilkes. Borg: the Next Generation. In _European Conference on Computer Systems (EuroSys)_, Heraklion, Greece, April, 2020.
* [9] AWS Lambda. [https://aws.amazon.com/lambda/](https://aws.amazon.com/lambda/), 2021.
* [10] Eric Jonas, Oifan Pu, Shivarian Venkataraman, Ion Stoica, and Benjamin Recht. Occupy the Cloud: Distributed Computing for the 99%. In _ACM Symposium on Cloud Computing (SoCC)_, Santa Clara, CA, USA, September, 2017.
* [11] Paul C. Castro, Vatche Ishakian, Vinod Muthusamy, and Aleksander Slominski. The rise of serverless computing. _Communications of ACM_, 62(12):44-54, 2019.
* [12] Amazon Elastic Container Service. [https://aws.amazon.com/ecs/](https://aws.amazon.com/ecs/), 2021.
* [13] Kubernetes. [https://kubernetes.io/](https://kubernetes.io/), 2021.
* [14] Dong Du, Tianyi Yu, Yubin Xia, Biyuyang Zuang, Guanglu Yan, Chenggang Qin, Qixuan Wu, and Haibo Chen. Catalyzer: Sub-millisecond Startup for Serverless Computing with Initialization-less Boeing. In _ACM International Conference on Architectural Support for Programming Languages and Operating Systems (ASPLOS)_, Lausanne, Switzerland, March, 2020.
* [15] Jorg Schad, Jens Dittrich, and Jorge-Armlofu Quian-Ruiz. Runtime Measurements in the Cloud: Observing, Analyzing, and Reducing Variance. _Proc. VLDB Endow._, 3(1):460-471, 2010.
* [16] Alexandro Isup, Nezhi Yigitsbi, and Dick H. J. Epema. On the Performance Variability of Production Cloud Services. In _IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)_, Newport Beach, CA, USA, May, 2011.
* A Study of Performance Variation and Predictability in Public IaaS Clouds. _ACM Trans. on Internet Technology_, 16(3):15:1-15:23, 2016.
* [18] Sen He, Glenna Manns, John Saunders, Wei Wang, Lori L. Pollock, and Mary Lou Soffa. A Statistics-based Performance Testing Methodology for Cloud Applications. In _ACM Joint Meeting on European Software Engineering Conference and Symposium on the Foundations of Software Engineering (ESECFSE)_, Tallinin, Estonia, August, 2019.
* [19] Zach Hill, He Li, Ming Mao, Arkaitz Ruiz-Alvarez, and Marty Humphrey. Early Observations on the Performance of Windows Azure. In _ACM International Symposium on High Performance Distributed Computing (HPDC)_, Chicago, Illinois, USA, June, 2010.
* [20] Iman Sadoghi, Jesus Hernandez Martin, Tonglin Li, Kevin Brandstatter, Ketan Maheshwari, Tiago Pais Pitta De Lacerda Ruivo, Gabriele Garzoglio, Steven Timm, Yong Zhao, and Ioan Raicu. Understanding the Performance and Potential of Cloud Computing for Scientific Applications. _IEEE Transactions on Cloud Computing_, 5(2):358-371, 2017.
* [21] Roberto R. Exposito, Guillermo L. Taboada, Sabela Ramos, Jorge Gonzalez-Dominguez, Juan Toutino, and Ramon Doolle. Analysis of I/O Performance on an Amazon EC Cluster Compute and High I/O Platform. _Journal of Grid Computing_, 11(4):613-631, 2013.
* [22] Valerio Persico, Pietro Marcheta, Alessio Botta, and Antonio Pescape. Measuring network throughput in the cloud: The case of Amazon EC2. _Computer Networks_, 93:408-422, 2015.
* [23] Jiawei Wen, Lei Lu, Giuliano Casale, and Evgenia Smirni. Less Can Be More: Micro-manging VMs in Amazon EC2. In _IEEE International Conference on Cloud Computing (CLOUD)_, New York City, NY, USA, June, 2015.
* [24] Anshul Gandhi and Justin Chan. Analyzing the Network for AWS Distributed Cloud Computing. _SIGMETRICS Performance Evaluation Review_, 43(3):12-15, 2015.
* [25] Ming Mao and Marty Humphrey. A Performance Study on the VM Startup Time in the Cloud. In _IEEE International Conference on Cloud Computing (CLOUD)_, Honolulu, HI, USA, June, 2012.
* [26] Gabriella Carrozza, Luigi Battaglia, Vittorio Manetti, Antonio Marotta, Roberto Canonico, and Stefano Avallone. On the Evaluation of VM Provisioning Time in Cloud Platforms for Mission-Critical Infrastructures. In _IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing (CCGrid)_, Chicago, IL, USA, May, 2014.
* BenchCouncil International Symposium (Bench)_, Seattle, WA, USA, December, 2018.
* [28] Ming Mao and Marty Humphrey. Auto-scaling to minimize cost and meet application deadlines in cloud workflows. In _International Conference on High Performance Computing Networking, Storage and Analysis (SC)_, Seattle, WA, USA, November, 2011.
* [29] In Kee Kim, Wei Wang, Yanjun Qi, and Marty Humphrey. Empirical Evaluation of Workload Forecasting Techniques for Predictive Cloud Resource Scaling. In _IEEE International Conference on Cloud Computing (CLOUD)_, San Francisco, CA, USA, June, 2016.
* [30] Kaveh Razavi and Thilo Kiclamann. Scalable Virtual Machine Development Using VM Image Caches. In _International Conference for High Performance Computing, Networking, Storage and Analysis (SC)_, Denver, CO, USA, November, 2013.
* [31] Kaveh Razavi, Ana Ion, and Thilo Kiclamann. Squirrel: scatter hoarding VM image contents on laas compute nodes. In _International Symposium on High-Performance Parallel and Distributed Computing (HPDC)_, Vancouver, BC, Canada, June, 014.
* [32] Kaveh Razavi, Gerrit Van Der Kolk, and Thilo Kielmann. Prebaked \(\mu\)VMs: Scalable, instant VM Startup for IaaS Clouds. In _IEEE International Conference on Distributed Computing Systems (ICDCS)_, Columbus, OH, June, 2015.
* [33] Jiwei Xu, Wenbo Zhang, Zhenyu Zhang, Tao Wang, and Tao Huang. Clustering-based acceleration for virtual machine image deduplication in the cloud environment. _Journal of Systems and Software_, 121:144-156, 2016.
* [34] Filipe Manco, Costin Lupu, Florian Schmidt, Jose Mendes, Simon Kuenzer, Sumit Sati, Kenichi Yasukata, Costin Raiciu, and Felipe Hui. My VM is lighter (and Safer) than your Container. In _ACM Symp. on Operating Systems Principles (SOSP)_, Shanghai, China, October, 2017.
* [35] Yifan Zhang, Kai Niu, Weigang Wu, Keqin Li, and Yu Zhou. Speeding Up VM Startup by Cooperative VM Image Caching. _IEEE Transactions on Cloud Computing_, pages 1-1, 2018.
* [36] Thuy-Linh Nguyen, Ramon Nou, and Adrien Lebre. YOLO: Speeding Up VM and Docker Boot Time by Reducing I/O Operations. In _European Conference on Parallel and Distributed Processing (EuroPar)_, Gottingen, Germany, August, 2019.
* [37] Alexandru Agache, Marc Brooker, Alexandra Iordache, Anthony Liguori, Rolf Neugebauer, Phil Piwonka, and Diana-Maria Popa. Freeracker: Lightweight Virtualization for Serverless Applications. In _USENIX Symposium on Networked Systems Design and Implementation (NSDI)_, Santa Clara, CA, USA, February, 2020.
* [38] Alexandru Isosup, Simon Ostermann, Nezhi Yigitsbi, Radu Prodan, Thomas Fahringer, and Dick H. J. Epema. Performance Analysis of Cloud Computing Services for Many-Tasks Scientific Computing. _IEEE Transactions on Parallel and Distributed Systems_, 22(6):931-945, 2011.
* [39] In Kee Kim, Jacob Steele, Yanjun Qi, and Marty Humphrey. Comprehensive Elastic Resource Management to Ensure Predictable Performance for Scientific Applications on Public IaaS Clouds. In _IEEE/ACM International Conference on Utility and Cloud Computing (UCC)_, London, United Kingdom, December, 2014.
* [40] Alexey Ilushkin, Ahmed Ali-Eldin, Nikolas Herbst, Andre Bauer, Alessandro Vittorio Papadopoulos, Dick H. J. Epema, and Alexandru Isosup. An Experimental Performance Evaluation of Autoscalers for Complex Workflows. _ACM Transactions on Modeling and Performance Evaluation of Computing Systems_, 3(2):8:1-8:32, 2018.

* [41] In Kee Kim, Wei Wang, Yanjun Qi, and Marty Humphrey. CloudInsight: Utilizing a Council of Experts to Predict Future Cloud Application Workloads. In _IEEE International Conference on Cloud Computing (CLOUD)_, San Francisco, CA, USA, July, 2018.
* [42] Vinoth Kumaran Jayakumar, Jaewoo Lee, In Kee Kim, and Wei Wang. A Self-Optimized Generic Workload Prediction Framework for Cloud Computing. In _IEEE International Parallel and Distributed Processing Symposium (IPDPS)_, Virtual Event, May, 2020.
* [43] In Kee Kim, Wei Wang, Yanjun Qi, and Marty Humphrey. Forecasting Cloud Application Workloads with CloudInsight for Predictive Resource Management. _IEEE Transactions on Cloud Computing_, pages 1-1, 2020.
* [44] Rodrigo N. Calheiros, Rajiv Ranjan, Anton Beloglazov, Cesar A. F. De Rose, and Rajkumar Buyya. CloudSim: a toolkit for modeling and simulation of cloud computing environments and evaluation of resource provisioning algorithms. _Software: Practice and Experience (SPE)_, 41(1):23-50, 2011.
* [45] Alberto Nunez, Jose Luis Vazquez-Poletti, Agustin C. Caminero, Gabriel G. Castane, Jesus Carretero, and Ignacio Martin Llorente. iC:Cloud: A Flexible and Scalable Cloud Infrastructure Simulator. _Journal of Grid Computing_, 10(1):185-209, 2012.
* [46] Dzmitry Kliazovich, Pascal Bouvy, and Samee Ullah Khan. GreenCloud: a packet-level simulator of energy-aware cloud computing data centers. _Journal of Supercomputing_, 62(3):1263-1283, 2012.
* [47] In Kee Kim, Wei Wang, and Marty Humphrey. PICS: A Public IaaS Cloud Simulator. In _IEEE International Conference on Cloud Computing (CLOUD)_, New York City, NY, USA, June, 2015.
* [48] Alexander Pucher, Emre Gul, Rich Wolski, and Chandra Krintz. Using Trustworthy Simulation to Engineer Cloud Schedulers. In _IEEE International Conference on Cloud Engineering (IC2E)_, Tempe, AZ, USA, March, 2015.
* [49] Jianwei Hao, Ting Jiang, Wei Wang, and In Kee Kim. An Empirical Analysis of VM Startup Times in Public IaaS Clouds. In _IEEE International Conference on Cloud Computing (CLOUD)_, Virtual Event, September, 2021.
* [50] Amazon EC2 Spot Instances. [https://aws.amazon.com/ec2/spot/](https://aws.amazon.com/ec2/spot/), 2021.
* [51] Preemptible VM Instances. [https://cloud.google.com/compute/docs/instances/preemptible](https://cloud.google.com/compute/docs/instances/preemptible), 2021.
* [52] Michael Smit, Bradley Simmons, and Marin Litoiu. Distributed, application-level monitoring for heterogeneous clouds using stream processing. _Future Generation Computing Systems_, 29(8):2103-2114, 2013.
* [53] AWS SDK for Python (Boto3). [https://aws.amazon.com/sdk-for-python/](https://aws.amazon.com/sdk-for-python/), 2021.
* [54] Compute Engine client libraries. [https://cloud.google.com/compute/docs/api/library/#google_apis_python_client_library](https://cloud.google.com/compute/docs/api/library/#google_apis_python_client_library), 2021.
* [55] Aleksander Maricq, Dmitry Duplyakin, Ivo Jimenez, Carlos Maltzahn, Ryan Stutsamen, Robert Ricci, and Ana Klimovic. Taming Performance Variability. In _USENIX Symposium on Operating Systems Design and Implementation (OSDI)_, Carlsbad, CA, USA, October, 2018.
* [56] Pradipta De, Manish Gupta, Manoj Soni, and Aditya Thatte. Caching VM Instances for Fast VM Provisioning: A Comparative Evaluation. In _European Conference on Parallel Processing (Euro-Par)_, Rhodes Island, Greece, August, 2012.
* [57] Google Compute Engine Machine types. [https://cloud.google.com/compute/docs/machine-types](https://cloud.google.com/compute/docs/machine-types), 2021.
* [58] Zillow. Saving Money with EMR Auto Scaling and Spot Instances. [https://www.zillow.com/tech/save-money-cmr-autoscalnerg-spot/](https://www.zillow.com/tech/save-money-cmr-autoscalnerg-spot/), 2017.
* [59] Thanh-Phuong Pham, Sasko Risto, and Thomas Fahringer. Performance and Behavior Characterization of Amazon EC2 Spot Instances. In _IEEE International Conference on Cloud Computing (CLOUD)_, San Francisco, CA, USA, July, 2018.
* [60] Cheng Wang, Qianlin Liang, and Bhuvan Urgaonkar. An Empirical Analysis of Amazon EC2 Spot Instance Features Affecting Cost-Effective Resource Procurement. _ACM Transactions on Modeling and Performance Evaluation of Computing Systems_, 3(2):6:1-6:24, 2018.
* [61] Amazon Web Services. New Amazon EC2 Spot pricing model: Simplified purchasing without bidding and fewer interruptions. [https://aws.amazon.com/blogs/compute/new-amazon-ec2-spot-pricing/](https://aws.amazon.com/blogs/compute/new-amazon-ec2-spot-pricing/), 2018.
* [62] Netflix Technology Blog. Server: Netflix's predictive auto scaling engine. [https://netflixtechnoble.com/scryer-netflixs-predictive-auto-scaling-engine-a3f8fc922270](https://netflixtechnoble.com/scryer-netflixs-predictive-auto-scaling-engine-a3f8fc922270), 2013.
* [63] N. Roy, A. Dubey, and A. Gokhale. Efficient Autoscaling in the Cloud Using Predictive Models for Workload Forecasting. In _IEEE International Conference on Cloud Computing_, 2011.
* [64] Nikolas Roman Herbst, Nikolaus Huber, Samuel Kounev, and Erich Amrehn. Self-adaptive workload classification and forecasting for proactive resource provisioning. In _ACM/SPEC International Conference on Performance Engineering (ICPE)_, 2013.
* [65] Christian Sierp, Jorg Domanschke, Anne Koziolek, Sebastian Krach, Jakub Krzyuba, and Ralf H. Reussen. Rapid Testing of IaaS Resource Management Algorithms via Cloud Middleware Simulation. In _ACM/SPEC International Conference on Performance Engineering (ICPE)_, 2018.

Title: The impact of startup costs and the grid operator on the power price
  equilibrium
Transcription: # The impact of startup costs and the grid operator on the power price equilibrium+
Footnote †: We thank the Oxford-Man Institute for providing historical prices used to calibrate our model, and ELEXON for providing historical data about the Balancing Mechanism used to determine physical characteristics of the power plants connected to the UK power grid.

Miha Troha

Mathematical Institute, Oxford University, Andrew Wiles Building, Radcliffe Observatory Quarter, Woodstock Road, Oxford OX2 6GG, United Kingdom, troha@maths.ox.ac.uk. This author was supported through grants from the Slovene human resources development and scholarship fund, and the Oxford-Man Institute.

Raphael Hauser

Mathematical Institute, Oxford University, Andrew Wiles Building, Radcliffe Observatory Quarter, Woodstock Road, Oxford OX2 6GG, United Kingdom, hauser@maths.ox.ac.uk. Associate Professor in Numerical Mathematics, and Tanaka Fellow in Applied Mathematics at Pembroke College, Oxford. This author was supported through grant EP/H02686X/1 from the Engineering and Physical Sciences Research Council of the UK.

plants such as ramp-up and ramp-down constants, and market design together with the transmission lines play a vital role in the behavior of electricity prices. The first game theoretic model for modeling the electricity prices was proposed in [2], where a unique relation between a forward and a spot price is given in a two-stage market with one producer and one consumer, who each want to maximize their mean-variance objective function. This model was extended to a multistage setting in [4] and [3], and to any convex risk measure in [8]. [21] further extended the work of [3] to a setting with more than one producer and consumer, who optimize their mean-variance objective functions. In contrast to other game theoretic models, capacity and ramp-up and ramp-down constraints of power plants are included. By modeling the profit of power plants as a difference between the power price and fuel costs together with emissions obligations, this work also incorporates ideas from the structural approach. As in [6] and [7], the model is consistent with observable fuel and emission prices. [20] applied this model to calculate the electricity prices in the UK by taking into account the entire power grid consisting of a few hundred power plants. Numerical simulations show that this model has a tendency to underestimate spot prices during the peak hours and to overestimate them during the off-peak hours. It is argued that this may occur because startup costs are not included in the model.

In this paper, we extend the model presented in [20] and include the startup costs. Various methodologies have already been proposed on how to include the startup costs (see [18], [12] and [23] for example). Most of them rely on a price uplift approach, where first the power price without startup costs is calculated. This price is then uplifted to reflect the startup costs. In our model, the startup costs are included in a mathematically rigorous fashion without relying on the uplift heuristic.

We show that startup costs are responsible for introducing many spikes in spot electricity prices. To reduce the number of spikes, we include the grid operator, who is responsible for managing the grid and for a reliable delivery of electricity, by enhancing our model in the second part of the paper.

This paper is organized as follows: In Section 2 we give a detailed mathematical description of the model, and in Section 3 we present the numerical results. Numerical results motivate us to introduce the grid operator in Section 4. We conclude the paper in Section 5.

## 2 Problem description

In this section we provide a detailed description of a model that we use for the purpose of modeling the term structure of electricity prices. The model belongs to a class of game theoretic equilibrium models. Market participants are divided into consumers and producers. A set of consumers is denoted by \(C\) and has cardinality \(0<|C|<\infty\). Similarly, a set of producers is denoted by \(P\) and has cardinality \(0<|P|<\infty\). Each producer owns a portfolio of power plants that can have different characteristics such as capacity, startup costs, ramp-up and ramp-down constraints, efficiency, and fuel type. The set of all fuel types is denoted by \(L\). Sets \(R^{p,l}\) denote all power plants owned by producer \(p\in P\) that run on fuel \(l\in L\). A set \(R^{p,l}\) may be empty since each producer typically does not own all possible types of power plants. Moreover, this allows us to include non physical traders such as banks or speculators, who do not own any electricity generation facilities and are without a physical demand for electricity, as producers \(p\in P\) with \(R^{p,l}=\{\}\) for all \(l\in L\).

As we will see in Section 2.4, it is useful to introduce another player named the hypothetical market agent besides producers and consumers. The hypothetical market agent plays the role of the electricity market and ensures that the term structure of the electricity price is such that the market clearing condition is satisfied for all electricity forward contracts.

We are interested in delivery times \(T_{j}\), \(j\in J=\{1,...,T^{\prime}\}\), where power for each delivery time \(T_{j}\) can be traded through numerous forward contracts at times \(t_{i}\), \(i\in I_{j}\). The electricity price at time \(t_{i}\) for delivery at time \(T_{j}\) is denoted by \(\Pi\left(t_{i},T_{j}\right)\). Since contracts with trading time later than delivery time do not exist, we require \(t_{\max\{I_{j}\}}=T_{j}\) for all \(j\in J\). The number of all forward contracts, i.e. \(\sum_{j\in J}|I_{j}|\), is denoted by \(N\). Uncertainty is modeled by a filtered probability space \(\left(\Omega,\mathcal{F},\mathbb{F}=\{\mathcal{F}_{t},t\in I\}\,,\mathbb{P}\right)\), where \(I=\cup_{j\in J}I_{j}\). The \(\sigma\)-algebra \(\mathcal{F}_{t}\) represents information available at time \(t\).

The exogenous variables that appear in our model are (a) aggregate power demand \(D\left(T_{j}\right)\) for each delivery period \(j\in J\), (b) prices of fuel forward contracts \(G_{l}\left(t_{i},T_{j}\right)\) for each fuel \(l\in L\), delivery period \(j\in J\), and trading period \(i\in I_{j}\), and (c) prices of emissions forward contracts \(G_{em}\left(t_{i},T_{j}\right)\), \(j\in J\), \(i\in I_{j}\). Electricity prices and all exogenous variables are assumed to be adapted to the filtration \(\left\{\mathcal{F}_{t}\right\}_{t\in I}\) and have finite second moments.

Let \(v_{k}\in\mathbb{R}^{n_{k}}\), \(n_{k}\in\mathbb{N}\), \(k\in K\), and \(K=\{1,...,|K|\}\) be given vectors. For convenience, we define a vector concatenation operator as

\[\left|\right|_{k\in K}v_{k}=\left[v_{1}^{\top},...,v_{|K|}^{\top}\right]^{\top}.\]

### Producers

Each producer \(p\in P\) participates in the electricity, fuel, and emission markets. Forward as well as spot contracts are available on all markets. Electricity prices, fuel prices, and emission prices are denoted by \(\Pi\left(t_{i},T_{j}\right)\), \(G_{l}\left(t_{i},T_{j}\right)\) where \(l\in L\), and \(G_{em}\left(t_{i},T_{j}\right)\), respectively.

A producer may participate in the market by buying and selling forward and spot contracts. The number of electricity forward contracts that producer \(p\in P\) buys at trading time \(t_{i}\), \(i\in I_{j}\) for delivery at time \(T_{j}\), \(j\in J\) is denoted by \(V_{p}\left(t_{i},T_{j}\right)\). Similarly, the number of fuel and emission forward contracts that producer \(p\in P\) buys at trading time \(t_{i}\), \(i\in I_{j}\) for delivery at time \(T_{j}\), \(j\in J\) is denoted by \(F_{p,l}\left(t_{i},T_{j}\right)\), \(l\in L\) and \(O_{p}\left(t_{i},T_{j}\right)\), respectively. Producers own a generally non-empty portfolio of power plants. The actual production of electricity from power plant \(r\in R^{p,l}\) at delivery time \(T_{j}\), \(j\in J\) is denoted by \(\widehat{W}_{p,l,r}\left(T_{j}\right)\).

#### 2.1.1 Production variables

In this section we investigate the production of power plants more closely. Each power plant \(r\in R^{p,l}\), \(p\in P\), \(l\in L\) has a maximum export limit and minimum stable limit denoted by \(\overline{W}_{max}^{p,l,r}\left(T_{j}\right)\) and \(\overline{W}_{min}^{p,l,r}\left(T_{j}\right)\), respectively. The maximum export limit defines the maximum production capacity of a power plant and the minimum stable limit defines the minimum production that a power plant is able to maintain for a longer period of time. We allow each of the parameters to be time dependent to account for the maintenance of power plants.

Stable production of each power plant must satisfy

\[\widehat{W}_{p,l,r}\left(T_{j}\right)\in\left\{0\right\}\cup\left[\overline{W }_{min}^{p,l,r}\left(T_{j}\right),\overline{W}_{max}^{p,l,r}\left(T_{j}\right)\right] \tag{1}\]

for each \(j\in J\). It is allowed for a power plant to have production \(\widehat{W}_{p,l,r}\left(T_{j}\right)\in\left(0,\overline{W}_{min}^{p,l,r} \left(T_{j}\right)\right)\) for a very short period of time (i.e. during a ramp-up and ramp-down phase). To formulate these constraints in an optimization framework, we introduce new decision variables \(W_{p,l,r}^{\left(k\right)}\left(T_{j}\right)\), \(k\in\left\{1,...,6\right\}\) with the following meaning:

* \(W_{p,l,r}^{\left(1\right)}\left(T_{j}\right)\), \(j\in J\) is a continuous variable that is \(1\) if the power plant is fully ramped up at time \(T_{j}\) and \(0\) if the power plant is not producing at all at time \(T_{j}\). If \(W_{p,l,r}^{\left(1\right)}\left(T_{j}\right)\in\left(0,1\right)\) then the power plant is in the ramp-up or ramp-down phase. In an optimization framework, \(W_{p,l,r}^{\left(1\right)}\left(T_{j}\right)\) is defined as \[W_{p,l,r}^{\left(1\right)}\left(T_{j}\right)\in\left[0,1\right].\] (2)
* \(W_{p,l,r}^{\left(2\right)}\left(T_{j}\right)\), \(j\in J\) is a binary variable that is \(1\) if the power plant is fully ramped up at time \(T_{j}\) and \(0\) otherwise. In an optimization framework, \(W_{p,l,r}^{\left(2\right)}\left(T_{j}\right)\) is defined as \[W_{p,l,r}^{\left(2\right)}\left(T_{j}\right)\leq W_{p,l,r}^{\left(1\right)} \left(T_{j}\right)\] (3) \[W_{p,l,r}^{\left(2\right)}\left(T_{j}\right)\in\left[0,1\right]\] and (4) \[W_{p,l,r}^{\left(2\right)}\left(T_{j}\right)\in\mathbb{Z}.\]
* \(W_{p,l,r}^{\left(3\right)}\left(T_{j}\right)\), \(j\in J\backslash\left\{1\right\}\) is a continuous variable that denotes the increase of \(W_{p,l,r}^{\left(1\right)}\left(T_{j}\right)\) from time \(T_{j-1}\) to time \(T_{j}\). In an optimization framework, \(W_{p,l,r}^{\left(3\right)}\left(T_{j}\right)\) is defined as \[W_{p,l,r}^{\left(3\right)}\left(T_{j}\right)\geq W_{p,l,r}^{\left(1\right)} \left(T_{j}\right)-W_{p,l,r}^{\left(1\right)}\left(T_{j-1}\right)\] and (6) \[W_{p,l,r}^{\left(3\right)}\left(T_{j}\right)\in\left[0,1\right].\]* \(W_{p,l,r}^{(4)}\left(T_{j}\right)\), \(j\in J\setminus\left\{1\right\}\) is a binary variable that is \(1\) if the power plant is in the ramp-up phase and \(0\) otherwise. In an optimization framework, \(W_{p,l,r}^{(4)}\left(T_{j}\right)\) is defined as (2.7) \[W_{p,l,r}^{(4)}\left(T_{j}\right)\geq W_{p,l,r}^{(1)}\left(T_{j}\right)-W_{p,l, r}^{(1)}\left(T_{j-1}\right)\] (2.7) \[W_{p,l,r}^{(4)}\left(T_{j}\right)\in\left[0,1\right]\] and (2.8) \[W_{p,l,r}^{(4)}\left(T_{j}\right)\in\mathbb{Z}.\]
* \(W_{p,l,r}^{(5)}\left(T_{j}\right)\), \(j\in J\setminus\left\{1\right\}\) is a binary variable that is \(1\) if the power plant is in the ramp-down phase and \(0\) otherwise. In an optimization framework, \(W_{p,l,r}^{(5)}\left(T_{j}\right)\) is defined as (2.9) \[W_{p,l,r}^{(5)}\left(T_{j}\right)\geq W_{p,l,r}^{(1)}\left(T_{j-1}\right)-W_{p,l,r}^{(1)}\left(T_{j}\right)\] (2.9) \[W_{p,l,r}^{(5)}\left(T_{j}\right)\in\left[0,1\right]\] and (2.10) \[W_{p,l,r}^{(5)}\left(T_{j}\right)\in\mathbb{Z}.\]
* \(W_{p,l,r}^{(6)}\left(T_{j}\right)\), \(j\in J\) is a continuous variable such that (2.11) \[\widehat{W}_{p,l,r}\left(T_{j}\right)=W_{p,l,r}^{(1)}\left(T_{j}\right) \overline{W}_{min}^{p,l,r}\left(T_{j}\right)+W_{p,l,r}^{(6)}\left(T_{j}\right) \left(\overline{W}_{max}^{p,l,r}\left(T_{j}\right)-\overline{W}_{min}^{p,l,r} \left(T_{j}\right)\right)\] where (2.12) \[W_{p,l,r}^{(6)}\left(T_{j}\right)\leq W_{p,l,r}^{(2)}\left(T_{j}\right)\] and (2.13) \[W_{p,l,r}^{(6)}\left(T_{j}\right)\in\left[0,1\right].\]

Variable \(W_{p,l,r}^{(1)}\left(T_{j}\right)\) tells us whether the power plant is running at time \(T_{j}\). If the power plant is not running at time \(T_{j}\), then by (2.3) and (2.12), \(W_{p,l,r}^{(6)}\left(T_{j}\right)=0\) and by (2.11) also \(\widehat{W}_{p,l,r}\left(T_{j}\right)=0\). On the other hand, if the power plant is fully ramped up time \(T_{j}\), then \(W_{p,l,r}^{(1)}\left(T_{j}\right)=1\) and \(W_{p,l,r}^{(6)}\left(T_{j}\right)\in\left[0,1\right]\), and thus \(\widehat{W}_{p,l,r}\left(T_{j}\right)\in\left[\overline{W}_{min}^{p,l,r}\left( T_{j}\right),\overline{W}_{max}^{p,l,r}\left(T_{j}\right)\right]\).

#### 2.1.2 Maximum ramp-up and maximum ramp-down constraints

Producer \(p\in P\) is not able to arbitrarily choose her decision variables because there are some constraints that limit her feasible set. The change in production of each power plant from one delivery period to next is limited by the ramp-up and ramp-down constraints. For each \(j\in\left\{1,...,T^{\prime}-1\right\}\), where \(T^{\prime}\) denotes the last delivery period, \(l\in L\) and \(r\in R^{p,l}\) these constraints can be expressed as

\[\triangle\overline{W}_{min}^{p,l,r}\left(T_{j}\right)\leq\widehat{W}_{p,l,r} \left(T_{j+1}\right)-\widehat{W}_{p,l,r}\left(T_{j}\right)\leq\triangle \overline{W}_{max}^{p,l,r}\left(T_{j}\right), \tag{2.14}\]

where \(\triangle\overline{W}_{max}^{p,l,r}\) and \(\triangle\overline{W}_{min}^{p,l,r}\) represent maximum rates for ramping up and down, respectively. The ramping rates highly depend on the type of the power plant. Some gas power plants can increase production from zero to the maximum in just a few minutes, while the same action may take days or weeks for a nuclear power plant.

Using (2.11), we can rewrite Constraint (2.14) for all \(j\in\left\{1,...,T^{\prime}-1\right\}\) as

\[\overline{W}_{min}^{p,l,r}\left(T_{j}\right) \leq W_{p,l,r}^{(1)}\left(T_{j+1}\right)\overline{W}_{min}^{p,l,r} \left(T_{j+1}\right)+W_{p,l,r}^{(6)}\left(T_{j+1}\right)\left(\overline{W}_{ max}^{p,l,r}\left(T_{j+1}\right)-\overline{W}_{min}^{p,l,r}\left(T_{j+1} \right)\right)\] \[-W_{p,l,r}^{(1)}\left(T_{j}\right)\overline{W}_{min}^{p,l,r} \left(T_{j}\right)-W_{p,l,r}^{(6)}\left(T_{j}\right)\left(\overline{W}_{max}^{p,l,r}\left(T_{j}\right)-\overline{W}_{min}^{p,l,r}\left(T_{j}\right)\right)\] \[\leq \triangle\overline{W}_{max}^{p,l,r}\left(T_{j}\right). \tag{2.15}\]Additionally, if the power plant is in a ramp-up phase, then it has to increase production and finish the ramp-up phase as fast as possible. Such a requirement can be enforced as

\[W_{p,l,r}^{(1)}\left(T_{j+1}\right)\geq\min\left\{W_{p,l,r}^{(1)}\left(T_{j} \right)+\frac{\triangle\overline{W}_{max}^{p,l,r}\left(T_{j}\right)}{\overline {W}_{min}^{p,l,r}\left(T_{j}\right)},1\right\} \tag{16}\]

where \(j\in\{1,...,T^{\prime}-1\}\). Since this constraint is relevant only during the ramp-up phase, we reformulate it for \(j\in\{1,...,T^{\prime}-1\}\) as

\[W_{p,l,r}^{(1)}\left(T_{j+1}\right)\geq\min\left\{W_{p,l,r}^{(1)}\left(T_{j} \right)+\frac{\triangle\overline{W}_{max}^{p,l,r}\left(T_{j}\right)}{\overline {W}_{min}^{p,l,r}\left(T_{j}\right)},1\right\}-M_{1}\left(1-W_{p,l,r}^{(4)} \left(T_{j}\right)\right), \tag{17}\]

where \(M_{1}\geq 1+\frac{\triangle\overline{W}_{max}^{p,l,r}\left(T_{j}\right)}{ \overline{W}_{min}^{p,l,r}\left(T_{j}\right)}\). Most of the available optimization solvers are not able to handle constraints that include min or max functions. Thus, we apply a well established approach to handle logical constraints, and introduce a new binary decision variable \(W_{p,l,r}^{(7)}\left(T_{j}\right)\) as

\[W_{p,l,r}^{(7)}\left(T_{j}\right)\in\left[0,1\right] \tag{18}\]

and

\[W_{p,l,r}^{(7)}\left(T_{j}\right)\in\mathbb{Z} \tag{19}\]

where \(j\in J\), that makes sure that at least one of the following constraints

\[W_{p,l,r}^{(1)}\left(T_{j+1}\right)\geq W_{p,l,r}^{(1)}\left(T_{j}\right)+ \frac{\triangle\overline{W}_{max}^{p,l,r}\left(T_{j}\right)}{\overline{W}_{ min}^{p,l,r}\left(T_{j}\right)}-M_{1}\left(1-W_{p,l,r}^{(4)}\left(T_{j} \right)\right)-M_{2}W_{p,l,r}^{(7)}\left(T_{j}\right) \tag{20}\]

and

\[W_{p,l,r}^{(1)}\left(T_{j+1}\right)\geq 1-M_{1}\left(1-W_{p,l,r}^{(4)}\left(T _{j}\right)\right)-M_{2}\left(1-W_{p,l,r}^{(7)}\left(T_{j}\right)\right), \tag{21}\]

where \(M_{2}\geq 1\), is enforced.

Similarly, if a power plant is in the ramp-down phase, then it has to decrease production and finish the ramp-down phase as fast as possible. Such requirement can be enforced as

\[W_{p,l,r}^{(1)}\left(T_{j+1}\right)\leq\max\left\{W_{p,l,r}^{(1)}\left(T_{j} \right)-\frac{\triangle\overline{W}_{min}^{p,l,r}\left(T_{j}\right)}{\overline {W}_{min}^{p,l,r}\left(T_{j}\right)},0\right\}+M_{1}\left(1-W_{p,l,r}^{(5)} \left(T_{j}\right)\right) \tag{22}\]

for \(j\in\{1,...,T^{\prime}-1\}\). Most of the available optimization solvers are not able to handle constraints that include min or max functions. We apply the approach described above and introduce a new binary decision variable \(W_{p,l,r}^{(8)}\left(T_{j}\right)\) as

\[W_{p,l,r}^{(8)}\left(T_{j}\right)\in\left[0,1\right] \tag{23}\]

and

\[W_{p,l,r}^{(8)}\left(T_{j}\right)\in\mathbb{Z} \tag{24}\]

where \(j\in J\), that makes sure that at least one of the following constraints

\[W_{p,l,r}^{(1)}\left(T_{j+1}\right)\leq W_{p,l,r}^{(1)}\left(T_{j}\right)- \frac{\triangle\overline{W}_{min}^{p,l,r}\left(T_{j}\right)}{\overline{W}_{min }^{p,l,r}\left(T_{j}\right)}+M_{1}\left(1-W_{p,l,r}^{(5)}\left(T_{j}\right) \right)+M_{2}W_{p,l,r}^{(8)}\left(T_{j}\right) \tag{25}\]

and

\[W_{p,l,r}^{(1)}\left(T_{j+1}\right)\leq M_{1}\left(1-W_{p,l,r}^{(5)}\left(T_{j }\right)\right)+M_{2}\left(1-W_{p,l,r}^{(8)}\left(T_{j}\right)\right) \tag{26}\]

is enforced.

#### 2.1.3 Other inequality constraints

We bound the the number of electricity contracts that each producer is allowed to trade as

\[-V_{trade}\leq V_{p}\left(t_{i},T_{j}\right)\leq V_{trade} \tag{27}\]

for some large \(V_{trade}>0\). Trading of an infinite number of contracts would clearly lead to a bankruptcy of one of the counterparties involved and must thus be prevented. In [21] it was shown, that if \(V_{trade}\) is chosen to be large enough, then Constraint (27) has no impact on the optimal solution and can be eliminated from the problem.

#### 2.1.4 Equality constraints

There are also equality constraints that connect power plant production with electricity, fuel, and emission trading. For each \(j\in J\) the electricity sold in the forward and spot market together must equal the actually produced electricity, i.e.

\[-\sum_{i\in I_{j}}V_{p}\left(t_{i},T_{j}\right)=\sum_{l\in L}\sum_{r\in R^{p,l} }\widehat{W}_{p,l,r}\left(T_{j}\right). \tag{28}\]

Each producer \(p\in P\) has to make sure that a sufficient amount of fuel \(l\in L\) has been bought to cover the electricity production for each delivery period \(j\in J\). Such constraint can be expressed as

\[\sum_{r\in R^{p,l}}\widehat{W}_{p,l,r}\left(T_{j}\right)c^{p,l,r}=\sum_{i\in I _{j}}F_{p,l}\left(t_{i},T_{j}\right) \tag{29}\]

where \(c^{p,l,r}>0\) is the efficiency of power plant \(r\in R^{p,l}\).

The carbon emission obligation constraint can be written as

\[\sum_{j\in J}\sum_{i\in I_{j}}O\left(t_{i},T_{j}\right)=\sum_{j\in J}\sum_{l \in L}\sum_{r\in R^{p,l}}\widehat{W}_{p,l,r}\left(T_{j}\right)g^{p,l,r}, \tag{30}\]

where \(g^{p,l,r}>0\) denotes the carbon emission intensity factor for power plant \(r\in R^{p,l}\). This constraint ensures that enough emission certificates have been bought to cover the electricity production over the whole planning horizon.

#### 2.1.5 Producers' optimization problem

The notation of the decision variables is greatly simplified if they are concatenated into

* electricity trading vectors \(V_{p}\left(T_{j}\right)=\left|\right|_{i\in I_{j}}V_{p}\left(t_{i},T_{j}\right)\) and \(V_{p}=\left|\right|_{j\in J}V_{p}\left(T_{j}\right)\),
* fuel trading vectors \(F_{p}\left(t_{i},T_{j}\right)=\left|\right|_{l\in L}F_{p,l}\left(t_{i},T_{j} \right)\), \(F_{p}\left(T_{j}\right)=\left|\right|_{i\in I_{j}}F_{p}\left(t_{i},T_{j}\right)\), and \(F_{p}=\left|\right|_{j\in J}F_{p}\left(T_{j}\right)\),
* emission trading vectors \(O_{p}\left(T_{j}\right)=\left|\right|_{i\in I_{j}}O_{p}\left(t_{i},T_{j}\right)\) and \(O_{p}=\left|\right|_{j\in J}O_{p}\left(T_{j}\right)\),
* electricity production vectors \(W_{p,l,r}\left(T_{j}\right)=\left|\right|_{k\in\left\{1,\ldots,8\right\}}W_{p, l,r}^{\left(k\right)}\left(T_{j}\right)\), \(W_{p,l}\left(T_{j}\right)=\left|\right|_{r\in R^{p,l}}W_{p,l,r}\left(T_{j}\right)\), \(W_{p}\left(T_{j}\right)=\left|\right|_{l\in L}W_{p,l}\left(T_{j}\right)\), and \(W_{p}=\left|\right|_{j\in J}W_{p}\left(T_{j}\right)\),

and finally \(v_{p}=\left[V_{p}^{\top},F_{p}^{\top},O_{p}^{\top},W_{p}^{\top}\right]^{\top}\).

Similarly, the notation of the prices is greatly simplified if they are concatenated into

* electricity price vectors \(\Pi\left(T_{j}\right)=\left|\right|_{i\in I_{j}}\Pi\left(t_{i},T_{j}\right)\), and \(\Pi=\left|\right|_{j\in J}e^{-\varepsilon T_{j}}\Pi\left(T_{j}\right)\), where \(\hat{r}\in\mathbb{R}\) is a constant interest rate,
* fuel price vectors \(G\left(t_{i},T_{j}\right)=\left|\right|_{l\in L}G_{l}\left(t_{i},T_{j}\right)\), \(G\left(T_{j}\right)=\left|\right|_{i\in I_{j}}G\left(t_{i},T_{j}\right)\), and \(G=\left|\right|_{j\in J}e^{-\varepsilon T_{j}}G\left(T_{j}\right)\),
* emission price vector \(G_{em}\left(T_{j}\right)=\left|\right|_{i\in I_{j}}G_{em}\left(t_{i},T_{j}\right)\), and \(G_{em}=\left|\right|_{j\in J}e^{-\varepsilon T_{j}}G_{em}\left(T_{j}\right)\),
* startup costs vector \(\widehat{s}^{p,l,r}=\left[0,0,s^{p,l,r},0,0,0,0,0\right]^{\top}\), \(s^{p,l}=\left|\right|_{r\in R^{p,l}}\widehat{s}^{p,l,r}\), \(s^{p}=\left|\right|_{l\in L}s^{p,l}\), and \(\widehat{s}^{p}=\left|\right|_{j\in J}e^{-\varepsilon T_{j}}s^{p}\), where \(s^{p,l,r}\geq 0\) denotes the startup costs of power plant \(r\in R^{p,l}\),

and finally

\[\pi_{p}=\left[\Pi^{\top},G^{\top},G_{em}^{\top},\left(\widehat{s}^{p}\right)^{ \top}\right]^{\top}.\]

Any producers' goal is to maximize their expected profit subject to a risk budget. In this work we assume that the risk budget is expressed in a mean-variance framework. The main argument thatsupports this decision is that delta hedging, which is the most widely used hedging strategy, can be captured in this framework.

The profit \(P_{p}\left(v_{p},\pi_{p}\right)\) of producer \(p\in P\) can be calculated as

\[P_{p}\left(v_{p},\pi_{p}\right)=\sum_{j\in J}e^{-\hat{\tau}T_{j}}\left(\sum_{i \in I_{j}}P_{p}^{t_{i},T_{j}}\left(v_{p},\pi_{p}\right)-\sum_{l\in L}\sum_{r\in R ^{p,l}}s^{p,l,r}W_{p,l,r}^{(3)}\left(T_{j}\right)\right), \tag{31}\]

where the profit \(P_{p}^{t_{i},T_{j}}\left(v_{p},\pi_{p}\right)\) for each \(i\in I_{j}\) and \(j\in J\) can be calculated as

\[P_{p}^{t_{i},T_{j}}\left(v_{p},\pi_{p}\right)=-\Pi\left(t_{i},T_{j}\right)V_{p }\left(t_{i},T_{j}\right)-O_{p}\left(t_{i},T_{j}\right)G_{em}\left(t_{i},T_{j }\right)-\sum_{l\in L}G_{l}\left(t_{i},T_{j}\right)F_{p,l}\left(t_{i},T_{j} \right).\]

Under a mean-variance optimization framework, producers are interested in the mean-variance utility

\[\Psi_{p}\left(v_{p}\right) = \mathbb{E}^{\mathbb{P}}\left[P_{p}\left(v_{p},\pi_{p}\right) \right]-\tfrac{\lambda_{p}}{2}\mathrm{Var}^{\mathbb{P}}\left[P_{p}\left(v_{p},\pi_{p}\right)\right]\] \[= -\mathbb{E}^{\mathbb{P}}\left[\pi_{p}\right]^{\top}v_{p}-\tfrac{1 }{2}\lambda_{p}v_{p}^{\top}Q_{p}v_{p},\]

where \(\lambda_{p}>0\) is their risk preference parameter and \(Q_{p}:=\mathbb{E}^{\mathbb{P}}\left[\left(\pi_{p}-\mathbb{E}^{\mathbb{P}} \left[\pi_{p}\right]\right)\left(\pi_{p}-\mathbb{E}^{\mathbb{P}}\left[\pi_{p} \right]\right)^{\top}\right]\) an "extended" covariance matrix. Their objective is to solve the following optimization problem

\[\Phi_{p}=\max_{v_{p}}\quad\Psi_{p}\left(v_{p}\right)\] (PR)

subject to (2), (3), (4), (5), (6), (7), (8), (9), (10), (12), (13), (15), (18), (19), (20), (21), (23), (24), (25), (26), (27), (28), (29), and (23).

A standard approach to solving optimization problem with binary constraints is to consider its continuous relaxation. We define a continuous relaxation of Problem (PR) as

\[\Phi_{p}=\max_{v_{p}}\quad\Psi_{p}\left(v_{p}\right)\] ( \[\widetilde{PR}\] )

subject to (2), (3), (5), (6), (7), (9), (2), (12), (13), (15), (18), (20), (21), (25), (26), (23), (27), (28), (29), and (23). Problem \(\widetilde{PR}\) is the same as problem Problem (PR) except that it does not include integrality constraints (4), (8), (10), (19) and (24).

### Consumers

We make the assumption that demand is completely inelastic and that each consumer \(c\in C\) is responsible for satisfying a proportion \(p_{c}\in[0,1]\) of the total demand \(D\left(T_{j}\right)\) at time \(T_{j}\), \(j\in J\). Since \(p_{c}\) is a proportion, we clearly have that \(\sum_{c\in C}p_{c}=1\).

A number of electricity forward contracts consumer \(c\in C\) buys at trading time \(t_{i}\), \(i\in I_{j}\) for delivery at time \(T_{j}\), \(j\in J\) is denoted by \(V_{c}\left(t_{i},T_{j}\right)\).

#### 2.2.1 Inequality constraints

We bound the the number of electricity contracts that each consumer is allowed to trade as

\[-V_{trade}\leq V_{p}\left(t_{i},T_{j}\right)\leq V_{trade} \tag{32}\]

for some large \(V_{trade}>0\). Trading of an infinite number of contracts would clearly lead to a bankruptcy of one of the counterparties involved and must thus be prevented. In [21] it was shown, that if \(V_{trade}\) is chosen large enough, then Constraint (32) has no impact on the optimal solution and can be eliminated from the problem.

#### 2.2.2 Equality constraints

Consumers are responsible for satisfying the electricity demand of end users. The electricity demand is expected to be satisfied for each \(T_{j}\), i.e.

\[\sum_{i\in I_{j}}V_{c}\left(t_{i},T_{j}\right)=p_{c}D\left(T_{j}\right). \tag{33}\]At the time of calculating the optimal decisions, consumers assume that they know the future realization of demand \(D\left(T_{j}\right)\) precisely. If the knowledge about the future realization of the demand changes, then players can take recourse actions by recalculating their optimal decisions with the updated demand forecast. Consumers may assume that they will be able to execute the recourse actions, because it is the job of the grid operator to ensure that a sufficient amount of electricity is available on the market.

#### 2.2.3 Consumers' optimization problem

Similarly as for producers, we can simplify the notation by introducing electricity trading vectors \(V_{c}\left(T_{j}\right)=\left|\right|_{i\in I_{j}}V_{c}\left(t_{i},T_{j}\right)\) and \(V_{c}=\left|\right|_{j\in J}V_{c}\left(T_{j}\right)\).

Consumers would like to maximize their profit subject to a risk budget. Similar to the model we introduced for producers, we assume that the risk budget can be expressed in a mean-variance framework. The profit of consumer \(c\in C\) can be calculated as

\[P_{c}\left(V_{c},\Pi\right)=\sum_{j\in J}e^{-\hat{r}T_{j}}\left(\sum_{i\in I_{ j}}-\Pi\left(t_{i},T_{j}\right)V_{c}\left(t_{i},T_{j}\right)+s_{c}p_{c}D \left(T_{j}\right)\right), \tag{34}\]

where \(\hat{r}\in\mathbb{R}\) denotes a constant interest rate and \(s_{c}\in\mathbb{R}\) denotes a contractually fixed price that consumer \(c\in C\) receives for selling the electricity further to end users (e.g. households, businesses etc.). Note that the contractually fixed price \(s_{c}\) only affects the optimal objective value of consumer \(c\in C\), but not also her optimal solution. Since we are primarily interested in optimal solutions, we simplify the notation and set \(s_{c}=0\). The correct optimal value can always be calculated via post-processing when an optimal solution is already known. This may be needed for risk management purposes. Note that in reality, end users can change their electricity providers and consequently the proportions \(p_{c}\), \(c\in C\). One could model the end user electricity market with a similar equilibrium model as presented here, but this is not the focus of this paper. Here we assume that proportions \(p_{c}\) are constant for the period of our interest.

Under a mean-variance optimization framework consumers are interested in the mean-variance utility

\[\Psi_{c}\left(V_{c}\right) = \mathbb{E}^{\mathbb{P}}\left[P_{c}\left(V_{c},\Pi\right)\right]- \tfrac{\lambda_{c}}{2}\text{Var}^{\mathbb{P}}\left[P_{c}\left(V_{c},\Pi\right)\right]\] \[= -\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{\top}V_{c}-\tfrac{ \lambda_{c}}{2}V_{c}^{\top}Q_{c}V_{c},\]

where \(\lambda_{c}>0\) is their risk preference and \(Q_{c}:=\mathbb{E}^{\mathbb{P}}\left[\left(\Pi-\mathbb{E}^{\mathbb{P}}\left[ \Pi\right]\right)\left(\Pi-\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\right)^{ \top}\right]\) a covariance matrix. Their objective is to solve the following optimization problem

\[\Phi_{c}=\max_{V_{c}}\,\Psi_{c}\left(V_{c}\right)\] (CO)

subject to (32) and (33).

### Matrix notation

The analysis of the problem is greatly simplified if a more compact notation is introduced.

Equality constraints of producer \(p\in P\) can be expressed as

\[A_{p}v_{p}=0\]

and inequality constraints as

\[B_{p}v_{p}\leq b_{p}\]

for some \(A_{p}\in\mathbb{R}^{|J|\left(|L|+1\right)+1\times\dim v_{p}}\), \(B_{p}\in\mathbb{R}^{n_{p}\times\dim v_{p}}\) and \(b_{p}\in\mathbb{R}^{n_{p}}\), where \(n_{p}\) denotes the number of the inequality constraints of producer \(p\in P\). Define feasible sets

\[\widetilde{S}_{p}:=\left\{v_{p}:A_{p}v_{p}=a_{p}\text{ and }B_{p}v_{p}\leq b_{p}\right\}\]

and

\[S_{p}:=\left\{v_{p}:A_{p}v_{p}=a_{p}\text{ and }B_{p}v_{p}\leq b_{p}\text{ and } \left[v_{p}\right]_{i}\in\left\{0,1\right\}\;\forall i\in\mathcal{I}\right\},\]where \(\mathcal{I}\) denotes a set of decisions variables with binarity constraints (i.e. \(W_{p,l,r}^{(k)}\left(T_{j}\right)\) for all \(k\in\{2,4,5,7,8\}\), \(r\in R^{p,l}\) and for all \(j\in J\)).

It is useful to investigate the inner structure of the matrices. By considering equality constraints (2.28), (2.29), and (2.30) we can see that

\[A_{p}=\left[\begin{array}{ccc}\hat{A}_{1}&0&\hat{A}_{3,p}\\ 0&\hat{A}_{2}&\hat{A}_{4,p}\end{array}\right] \tag{2.35}\]

where \(\hat{A}_{1}\in\mathbb{R}^{|J|\times N},\hat{A}_{2}\in\mathbb{R}^{(|J||L|+1) \times N(|L|+1)},\hat{A}_{3,p}\in\mathbb{R}^{|J|\times\dim W_{p}},\hat{A}_{4,p }\in\mathbb{R}^{(|J||L|+1)\times\dim W_{p}}\). One can see that matrices \(\hat{A}_{1}\) and \(\hat{A}_{2}\) are independent of producer \(p\in P\) and matrices \(\hat{A}_{3,p}\) and \(\hat{A}_{4,p}\) depend on producer \(p\in P\). One can further investigate the structure of \(\hat{A}_{1}\) and see

\[\hat{A}_{1}=\left[\begin{array}{ccc}1_{1}&&0\\ &\ddots&\\ 0&&1_{|J|}\end{array}\right], \tag{2.36}\]

where \(1_{j}\), \(j\in J\) is a row vector of ones of length \(|I_{j}|\). Similarly,

\[\hat{A}_{2}=\left[\begin{array}{ccc}\hat{A}_{1}&\cdots&0&0\\ \vdots&\ddots&\vdots&\vdots\\ 0&\cdots&\hat{A}_{1}&0\\ 0&\cdots&0&1_{N}\end{array}\right], \tag{2.37}\]

where the number of rows in the block notation above is \(|L|+1\). The first \(|L|\) rows correspond to (2.29) and the last row corresponds to (2.30).

The profit of producer \(p\in P\) can be written as

\[P_{p}\left(v_{p},\pi_{p}\right)=-\pi_{p}^{\top}v_{p}.\]

In a compact notation, the mean-variance utility of producer \(p\in P\) can be calculated as

\[\Psi_{p}\left(v_{p},\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\right) = \mathbb{E}^{\mathbb{P}}\left[-\pi_{p}^{\top}v_{p}-\tfrac{1}{2} \lambda_{p}v_{p}^{\top}\left(\pi_{p}-\mathbb{E}^{\mathbb{P}}\left[\pi_{p} \right]\right)\left(\pi_{p}-\mathbb{E}^{\mathbb{P}}\left[\pi_{p}\right] \right)^{\top}v_{p}\right]\] \[= -\mathbb{E}^{\mathbb{P}}\left[\pi_{p}\right]^{\top}v_{p}-\tfrac{ 1}{2}\lambda_{p}v_{p}^{\top}Q_{p}v_{p},\]

where

\[Q_{p}:=\mathbb{E}^{\mathbb{P}}\left[\left(\pi_{p}-\mathbb{E}^{\mathbb{P}} \left[\pi_{p}\right]\right)\left(\pi_{p}-\mathbb{E}^{\mathbb{P}}\left[\pi_{p} \right]\right)^{\top}\right]. \tag{2.38}\]

The inner structure of matrix \(Q_{p}\) is the following

\[Q_{p}=\left[\begin{array}{ccc}\hat{Q}_{1}&\hat{Q}_{2}&0\\ \hat{Q}_{2}^{\top}&\hat{Q}_{3}&0\\ 0&0&0\end{array}\right] \tag{2.39}\]

where \(\hat{Q}_{1}\in\mathbb{R}^{N\times N},\hat{Q}_{2}\in\mathbb{R}^{N\times(\dim B _{p}+\dim O_{p})}=\mathbb{R}^{N\times N(|L|+1)},\hat{Q}_{3}\in\mathbb{R}^{N(|L |+1)\times N(|L|+1)}\). One can see that \(\hat{Q}_{1}\), \(\hat{Q}_{2}\), and \(\hat{Q}_{3}\) do not depend on producer \(p\in P\). The size of the larger matrix \(Q_{p}\) depends on producer \(p\in P\), because different producers have different number of power plants.

Producer \(p\in P\) attempts to solve the following optimization problem

\[\Phi_{p}\left(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\right)=\max_{v_{p}\in S _{p}}-\mathbb{E}^{\mathbb{P}}\left[\pi_{p}\right]^{\top}v_{p}-\frac{1}{2} \lambda_{p}v_{p}^{\top}Q_{p}v_{p},\]

with the following continuous relaxation

\[\Phi_{p}\left(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\right)=\max_{v_{p}\in S _{p}}-\mathbb{E}^{\mathbb{P}}\left[\pi_{p}\right]^{\top}v_{p}-\frac{1}{2} \lambda_{p}v_{p}^{\top}Q_{p}v_{p}.\]The equality constraints of consumer \(c\in C\) can be expressed as

\[A_{c}V_{c}=a_{c}\]

and the inequality constraints as

\[B_{c}V_{c}\leq b_{c}\]

where \(A_{c}=\hat{A}_{1}\), \(B_{c}\in\mathbb{R}^{2N\times N}\), \(a_{c}\in\mathbb{R}^{|J|}\) and \(b_{c}\in\mathbb{R}^{2N}\). Define a feasible set

\[S_{c}:=\left\{V_{c}\in\mathbb{R}^{N}:A_{c}V_{c}=a_{c}\text{ and }B_{c}V_{c}\leq b _{c}\right\}.\]

The profit of consumer \(c\in C\) can be written as

\[P_{c}\left(V_{c},\Pi\right)=-\Pi^{\top}V_{c}.\]

In a compact notation, the mean-variance utility of a consumer \(c\in C\) can be calculated as

\[\Psi_{c}\left(V_{c},\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\right) = \mathbb{E}^{\mathbb{P}}\left[-\Pi^{\top}V_{c}-\tfrac{1}{2}\lambda _{c}V_{c}^{\top}\left(\Pi-\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\right)\left( \Pi-\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\right)^{\top}V_{c}\right]\] \[= -\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{\top}V_{c}-\tfrac{ \lambda_{c}}{2}V_{c}^{\top}Q_{c}V_{c},\]

where

\[Q_{c}:=\mathbb{E}^{\mathbb{P}}\left[\left(\Pi-\mathbb{E}^{\mathbb{P}}\left[ \Pi\right]\right)\left(\Pi-\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\right)^{ \top}\right]. \tag{2.40}\]

Moreover, note that \(Q_{c}=\hat{Q}_{1}\) for all \(c\in C\). We set \(s_{c}=0\), w.l.o.g. Consumer \(c\in C\) attempts to solve the following optimization problem

\[\Phi_{c}\left(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\right)=\max_{V_{c}\in S_ {c}}-\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{\top}V_{c}-\frac{\lambda_{c}}{2 }V_{c}^{\top}Q_{c}V_{c}.\]

### The hypothetical market agent

Given the price vectors of electricity \(\Pi\), fuel \(G\), and emissions \(G_{em}\), each producer \(p\in P\) and each consumer \(c\in C\) can calculate their optimal electricity trading vectors \(V_{p}\) and \(V_{c}\) by solving (PR) and (CO), respectively. However, the players are not necessary able to execute their calculated optimal trading strategies because they may not find the counterparty to trade with. In reality each contract consists of a buyer and a seller, which imposes an additional constraint (also called the market clearing constraint) that matches the number of short and long electricity contracts for each \(i\in I_{j}\) and \(j\in J\) as follows,

\[\sum_{c\in C}V_{c}\left(t_{i},T_{j}\right)+\sum_{p\in P}V_{p}\left(t_{i},T_{j} \right)=0. \tag{2.41}\]

The electricity market is responsible for satisfying this constraint by matching buyers with sellers. The matching is done through sharing of the price and order book information among all market participants. If at the current price there are more long contract than short contracts, it means that the current price is too low and asks will start to be submitted at higher prices. The converse occurs, if there are more short contracts than long contracts. Eventually, the electricity price at which the number of long and short contracts matches is found. At such a price the constraint (2.41) is satisfied "naturally" without explicitly requiring the players to satisfy it. They do so because it is in their best interest, i.e. it maximizes their mean-variance objective functions.

The question is how to formulate such an equilibrium constraint in an optimization framework. A naive approach of writing the market clearing constraint as an ordinary constraint forces the players to satisfy it regardless of the price. We need a mechanism that models the matching of buyers and sellers as it is performed by the electricity market. For this purpose, we introduce a hypothetical market agent who is allowed to slowly change electricity prices to ensure that (2.41) is satisfied.

Let the hypothetical market agent have the following profit function

\[\begin{array}{rcl}P_{M}\left(\Pi,V\right)&=&\sum_{j\in J}e^{-\hat{r}T_{j}} \left[\sum_{i\in I_{j}}\Pi\left(t_{i},T_{j}\right)\left(\sum_{c\in C}V_{c} \left(t_{i},T_{j}\right)+\sum_{p\in P}V_{p}\left(t_{i},T_{j}\right)\right) \right]\\ &=&\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{\top}\left(\sum_{c\in C}V_{c}+ \sum_{p\in P}V_{p}\right)\end{array} \tag{2.42}\]and the expected profit

\[\Psi_{M}\left(\mathbb{E}^{\mathbb{P}}\left[\Pi\right],V\right)=\mathbb{E}^{ \mathbb{P}}\left[P_{M}\left(V,\Pi\right)\right], \tag{43}\]

where \(V=\left[V_{P}^{\top},V_{C}^{\top}\right]^{\top}\), \(V_{P}=\left|\right|_{p\in P}V_{p}\), and \(V_{C}=\left|\right|_{c\in C}V_{c}\) and let the hypothetical market agent attempts to solve

\[\Phi_{M}\left(V\right)=\max_{\mathbb{E}^{\mathbb{P}}\left[\Pi\right]}\Psi_{M} \left(\mathbb{E}^{\mathbb{P}}\left[\Pi\right],V\right). \tag{44}\]

The KKT conditions for (44) in the matrix notation read

\[\sum_{c\in C}V_{c}+\sum_{p\in P}V_{p}=0, \tag{45}\]

which is exactly the same as (41). Note, that the equivalence of (41) and (44) is a theoretical result that has to be applied with caution in an algorithmic framework. Formulation (44) is clearly unstable since only a small mismatch in the market clearing constraint sends the prices to \(\pm\infty\). Thus, a stable formulation of the hypothetical market agent must be found. Let us now analyze the hypothetical market agent with the following, slightly altered, optimization problem

(HMA) \[\begin{array}{ll}\max_{\mathbb{E}^{\mathbb{P}}\left[\Pi\right]}&\Psi_{M} \left(\mathbb{E}^{\mathbb{P}}\left[\Pi\right],V\right)\\ \text{s.t.}&\sum_{c\in C}V_{c}+\sum_{p\in P}V_{p}=0\\ &\mu_{M}=0,\end{array}\]

where \(\mu_{M}\) denotes the dual variables of the equality constraint in (HMA). It is trivial to check that the optimality conditions for (HMA) correspond to (41). Formulation (HMA) is clearly stable, because the market clearing constraint is satisfied precisely. The equality constraint on the dual variables makes sure that the optimal solution remains the same if the market clearing constraint is removed after the calculation of the optimal solution. Formulation (HMA) is used as a definition of the hypothetical market agent in the rest of this work.

We can see that, by affecting the expected electricity price, the hypothetical agent changes the electricity price process. It is not immediately clear how to construct such a stochastic process or that such a stochastic process exists at all. We refer the reader to [21], where a constructive proof of the existence is given. The proof is based on the Doob decomposition theorem, where we allow the hypothetical market agent to control an integrable predictable term of the process, while keeping the martingale term of the process intact.

For the further argumentation we define \(v_{P}=\left|\right|_{p\in P}v_{p}\) and \(v=\left[v_{P}^{\top},V_{C}^{\top}\right]^{\top}\).

### Nash equilibrium

Binarity constraints (4), (8), (10), (19) and (24) of each producer significantly complicate the analysis of Problem (PR) and thus, we focus on the continuous relaxation (\(\widetilde{PR}\)) instead. We then show through various numerical results in Section 3 and Section 4.2, that binarity constraints (4), (8), (10), (19) and (24) do not have a significant impact on the equilibrium electricity price.

Using the continuous relaxation (\(\widetilde{PR}\)), we are interested in finding a Nash equilibrium defined as

**Definition 1**: _Nash Equilibrium (NE)_

_Decisions \(v^{*}\) and \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\) constitute a Nash equilibrium if_

1. _For every producer_ \(p\in P\)_,_ \(v_{p}^{*}\) _is a strategy such that_ (46) \[\Psi_{p}\left(v_{p},\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\right)\leq\Psi _{p}\left(v_{p}^{*},\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\right)\] _for all_ \(v_{p}\in\widetilde{S}_{p}\)_;_
2. _For every consumer_ \(c\in C\)_,_ \(V_{c}^{*}\) _is a strategy such that_ (47) \[\Psi_{c}\left(V_{c},\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\right)\leq\Psi _{c}\left(V_{c}^{*},\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\right)\] _for all_ \(V_{c}\in S_{c}\)_;_3. _Price vector_ \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\) _maximizes the objective function of the hypothetical market agent, i.e._ (48) \[\Psi_{M}\left(\mathbb{E}^{\mathbb{P}}\left[\Pi\right],v^{*}\right)\leq\Psi_{M} \left(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*},v^{*}\right)\] _for all_ \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\in S_{M}\)_._

From Definition (1), it is not clear whether a NE for our problem exists and whether it is unique. This problem was thoroughly investigated in [21]. Roughly speaking, it was shown that if the demand of the end users can be covered by the available system of power plants, then a NE exists. Moreover, if the power plants are similar enough (if there are no big gaps in the efficiency of the power plants), then one can show that the NE is also unique. On the other hand, if power plants are similar enough, then the expected equilibrium price of each electricity contract might be an interval instead of a single point.

In this paper we focus on the numerical calculation of the NE under the assumption of the existence of solution. For this paper, we assume the following, a slightly stricter, condition.

**Assumption 2.2**: _For all \(p\in P\), the exists vector \(v_{p}\) such that \(A_{p}v_{p}=a_{p}\) a.s. and \(B_{p}v_{p}<b_{p}\) a.s., for all \(c\in C\), there exists vector \(V_{c}\) such that \(A_{c}V_{c}=a_{c}\) a.s. and \(B_{c}V_{c}<b_{c}\) a.s., and the vectors \(V_{p}\) and \(V_{c}\) can be chosen so that (45) is satisfied._

### Quadratic programming formulation

The traditional approach to solving equilibrium optimization problems is through shadow prices (see [8] for example). However, this approach is only valid when no inequality constraints are present. Shadow prices depend on the set of active constraints and thus one can only use this approach when the active set is known. In inequality constrainted optimization, the active set is usually not know in advance and thus a different approach is needed. The proposed formulation below can be seen as an extension of the shadow price concept to inequality constrained optimization problems.

A naive approach for solving inequality constrained equilibrium optimization problem would be to choose an expected price vector \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\) and then calculate optimal solutions for each producer \(p\in P\) and each consumer \(c\in C\) by solving \((\widehat{PR})\) and \((\mathrm{CO})\), respectively. If at such price \(\left\|\sum_{c\in C}V_{c}+\sum_{p\in P}V_{p}\right\|\) is close to zero, then the solution is found and \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\) is an equilibrium expected price vector. Otherwise, we have to adjust the expected price vector and repeat the procedure. We can see that such an algorithm is costly, because it requires to solve a large optimization problem (i.e. to calculate the optimal solutions of each producer and each consumer) multiple times. In the section below, we show that we can do much better than the naive approach. Using the reformulation we propose, the large optimization problem must be solved only once.

Necessary and sufficient conditions for all \(v_{k}\), \(k\in P\cup C\) and \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]\) to constitute a NE are the following, due to the fact that Assumption 2.2 implies the Slater condition,

\[-\mathbb{E}^{\mathbb{P}}\left[\pi_{k}\right]^{\top}-\lambda_{k}Q_ {k}v_{k}-B_{k}^{\top}\eta_{k}-A_{k}^{\top}\mu_{k} = 0\] \[\eta_{k}^{\top}\left(B_{k}v_{k}-b_{k}\right) = 0\] \[B_{k}v_{k}-b_{k} \leq 0 \tag{49}\] \[A_{k}v_{k}-a_{k} = 0\] \[\eta_{k} \geq 0\] \[\sum_{c\in C}V_{c}+\sum_{p\in P}V_{p} = 0.\]

The last equation corresponds to the KKT conditions of the hypothetical market agent.

We can now interpret (49) as the KKT conditions of one large optimization problem that includes the new definition (HMA) of the hypothetical market agent. To see this, we join all decision variables into one vector \(x:=\left[v^{\top},\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{\top}\right]^{\top}\) and rewrite

* the equality constraints as \(Ax=a\) with \(a:=\left[a_{p_{1}}^{\top},...,a_{p_{P}}^{\top},a_{c_{1}}^{\top},...,a_{c_{C}}^{ \top},\underbrace{0,...,0}_{N}\right]^{\top}\) where the number of ending zeros is equal to \(N\), and \[A:=\left[\begin{array}{ccccccc}A_{p_{1}}&0&&&&0\\ 0&\ddots&0&&&\vdots\\ &0&A_{p_{P}}&0&&&0\\ &&0&A_{c_{1}}&0&&0\\ &&&0&\ddots&0&\vdots\\ &&&0&A_{c_{C}}&0\\ M_{p_{1}}&\cdots&M_{p_{P}}&I&\cdots&I&0\end{array}\right],\] where \(M_{p}\in\mathbb{R}^{N}\times\mathbb{R}^{\dim v_{p}}\) is a matrix defined as \[M_{p}=\left[\text{diag}\left(\underbrace{1,...,1}_{N}\right)\left|\begin{array} []{ccc}0&\cdots&0\\ \vdots&\ddots&\vdots\\ 0&\cdots&0\end{array}\right.\right],\]
* the inequality constraints as \(Bx\leq b\) with \(b:=\left[b_{p_{1}}^{\top},...,b_{p_{P}}^{\top},b_{c_{1}}^{\top},...,b_{c_{C}} ^{\top}\right]^{\top}\), and \[B:=\left[\begin{array}{ccccccc}B_{p_{1}}&0&&&&0\\ 0&\ddots&0&&&\vdots\\ &0&B_{pp}&0&&&0\\ &&0&B_{c_{1}}&0&&0\\ &&&0&\ddots&0&\vdots\\ &&&0&B_{c_{C}}&0\end{array}\right],\]
* the objective function as \(-\pi^{\top}x-\frac{1}{2}x^{\top}Qx\) with \(\pi:=\left[\mathbb{E}^{\mathbb{P}}\left[\pi_{0,p_{1}}\right]^{\top},..., \mathbb{E}^{\mathbb{P}}\left[\pi_{0,p_{P}}\right]^{\top},\underbrace{0,...,0} _{(|C|+1)N}\right]^{\top}\) where \(\pi_{0,p}\) is \(\pi_{p}\) with elements of \(\Pi\) set to zero, and (2.50) \[Q:=\left[\begin{array}{ccccccc}\lambda_{p_{1}}Q_{p_{1}}&0&&&&M_{p_{1}}^{\top }\\ 0&\ddots&0&&&&\vdots\\ &0&\lambda_{p_{P}}Q_{pp}&0&&&M_{p_{P}}^{\top}\\ &&0&\lambda_{c_{1}}Q_{c_{1}}&0&&I\\ &&&0&\ddots&0&\vdots\\ &&0&\lambda_{c_{C}}Q_{c_{C}}&I\\ M_{p_{1}}&\cdots&M_{p_{P}}&I&\cdots&I&0\end{array}\right],\]
* the dual variables as \(\eta:=\left[\eta_{p_{1}}^{\top},...,\eta_{p_{P}}^{\top},\eta_{c_{1}}^{\top},...,\eta_{c_{C}}^{\top}\right]\) and \(\mu:=\left[\mu_{p_{1}}^{\top},...,\mu_{p_{P}}^{\top},\mu_{c_{1}}^{\top},..., \mu_{c_{C}}^{\top},\mu_{M}^{\top}\right]\).

In this setting we can reformulate the KKT conditions (2.49) as follows,

\[-\pi-Qx-B^{\top}\eta-A^{\top}\mu = 0\] \[\eta^{\top}\left(Bx-b\right) = 0\] \[Bx-b \leq 0\] \[Ax-a = 0\] \[\eta \geq 0\] \[\mu_{M} = 0. \tag{2.51}\]Since the additional constraints \(\mu_{M}=0\) on the dual variables of Problem 2.51 cannot be handled by most of the available quadratic programming solvers, we have to reformulate the problem in a dual form. We start by formulating the optimization problem out of the KKT conditions (2.51) as

\[\max_{x} -\pi^{\top}x-\tfrac{1}{2}x^{\top}Qx \tag{2.52}\] \[\text{s.t.} Ax=a\] \[Bx\leq b\] \[\mu_{M}=0\]

and by defining the Lagrangian as

\[\mathcal{L}\left(x,\mu,\eta\right)=\left\{\begin{array}{rl}-\frac{1}{2}x^{ \top}Qx-\pi^{\top}x-\left(Ax-a\right)^{\top}\mu-\left(Bx-b\right)^{\top}\eta ;&\text{if }\eta\geq 0\\ &\\ -\infty;&\text{otherwise}.\end{array}\right.\]

One can show that, \(Q\succeq 0\) for all vectors that satisfy the market clearing constraint (2.41) (for the proof see [20]). \(\mathcal{L}\left(x,\mu,\eta\right)\) is therefore a smooth and convex function. The unconstrained minimizer can be determined by solving \(\mathcal{D}_{x}\mathcal{L}\left(x,\mu,\eta\right)=0\). Calculating

\[\mathcal{D}_{x}\mathcal{L}\left(x,\mu,\eta\right)=-Qx-\pi-A^{\top}\mu-B^{\top}\eta\]

and inserting \(\pi\) back to the Lagrangian, an equivalent formulation is obtained as follows,

\[\mathcal{L}\left(x,\mu,\eta\right)=\left\{\begin{array}{rl}\frac{1}{2}x^{ \top}Qx+a^{\top}\mu+b^{\top}\eta&\text{if }\eta\geq 0\text{ and }-Qx-\pi-A^{\top}\mu-B^{\top}\eta=0,\\ &\\ -\infty&\text{otherwise}\end{array}\right.\]

Relating the latter to a maximization optimization problem, the following formulation is obtained

\[\max_{x,\mu,\eta} -\tfrac{1}{2}x^{\top}Qx-\mu^{\top}a-\eta^{\top}b \tag{2.53}\] \[\text{s.t.} Qx+A^{\top}\mu+B^{\top}\lambda+\pi=0\] \[\eta\geq 0\] \[\mu_{M}=0.\]

Problem (2.53) is equivalent to Problem (2.52), but it can be solved using any quadratic programming algorithm.

Based on our discussion in Section 2.5, we can see that (2.53) was obtained by considering Problem (\(\overline{PR}\)), which is a continuous relaxation of Problem (PR). To estimate the error caused by the continuous relaxation, we use the following procedure:

1. We calculate the equilibrium electricity price \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\) by solving problem (2.53).
2. Using the equilibrium electricity price \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\) from the previous step, we calculate optimal trading vectors \(V_{p}^{*}\), \(p\in P\) for all producers and optimal trading vectors \(V_{c}^{*}\), \(c\in C\) for all consumers by solving (PR) and (CO), respectively.
3. We calculate the error as (2.54) \[\text{MIQP}:=\sum_{c\in C}V_{c}^{*}+\sum_{p\in P}V_{p}^{*}.\]

In order to verify the procedure above, we apply the following very similar procedure:

1. We calculate the equilibrium electricity price \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\) by solving problem (2.53).

2. Using the equilibrium electricity price \(\mathbb{E}^{\mathbb{P}}\left[\Pi\right]^{*}\) from the previous step, we calculate optimal trading vectors \(V_{p}^{*}\), \(p\in P\) for all producers and optimal trading vectors \(V_{c}^{*}\), \(c\in C\) for all consumers by solving (\(\widehat{PR}\)) and (CO), respectively.
3. We calculate the error as (55) \[\text{QP}:=\sum_{c\in C}V_{c}^{*}+\sum_{p\in P}V_{p}^{*}.\]

In Section 3 and Section 4.2, we present the MIQP and QP when modeling the entire UK power grid.

## 3 Numerical results

In this section we discuss the numerical results and apply our model from Section 2 to model the realistic UK power grid.

### Estimation of parameters

In this section we investigate how to estimate various parameters of power plants that enter our model described in Section 2.

In the UK all power plants are required to submit their available capacity as well as ramp-up and ramp-down constraints to the grid operator on a half hourly basis. This data is publicly available at the Elexon website1. A more challenging problem is to estimate of the efficiency \(c^{p,l,r}\), startup costs \(s^{p,l,r}\) and the carbon emission intensity factor \(g^{p,l,r}\) for each power plant \(r\in R^{p,l}\). For the purpose of the calibration, we assume that all producers are risk neutral and set \(\lambda_{p}=0\) for all \(p\in P\). Furthermore, we neglect the ramp-up and ramp-down constraints (15), (20), (21), (25), and (26). Since each power plant is treated separately, we avoid writing subscripts/superscripts \(p,l,r\).

Footnote 1: [http://www.bmreports.com/](http://www.bmreports.com/)

Before we explore the details of the calibration process, let us establish a few relationships that will prove useful later in this section. We can see that a power plant will produce at time \(T_{j}\) if the income from selling electricity at the spot price is greater than the costs of purchasing the required fuel and emission certificates at the current spot price (remember that a power plant has to cover the startup costs too). Thus, for a power plant that runs on fuel \(l\in L\) and produces electricity at time \(T_{j}\),

\[\Pi\left(T_{j},T_{j}\right)-cG_{l}\left(T_{j},T_{j}\right)-gG_{em}\left(T_{j},T _{j}\right)>0 \tag{1}\]

must hold for production to take place.

It is immediately clear why (1) must hold when only spot contracts are available. Let us investigate why (1) holds also if forward and future electricity contracts are available on the market. At any trading time \(t_{i}\), \(i\in I_{j}\), a rational producer could enter into a short electricity forward contract and simultaneously into a long fuel and emission forward contract if

\[\Pi\left(t_{i},T_{j}\right)-cG_{l}\left(t_{i},T_{j}\right)-gG_{em}\left(t_{i},T_{j}\right)>0. \tag{2}\]

At delivery time \(T_{j}\), this producer has two options:

* To acquire the delivery of the fuel and emission certificates bought at trading time \(t_{i}\) and produce electricity. In this case, she observes the following profit (3) \[\widehat{P_{1}}\left(T_{j}\right)=\Pi\left(t_{i},T_{j}\right)-cG_{l}\left(t_{ i},T_{j}\right)-gG_{em}\left(t_{i},T_{j}\right).\]
* To produce no electricity and instead close the forward electricity, fuel, and emission contracts. In this case, she observes the following profit (4) \[\widehat{P_{2}}\left(T_{j}\right) = \left[\Pi\left(t_{i},T_{j}\right)-\Pi\left(T_{j},T_{j}\right) \right]-c\left[G_{l}\left(t_{i},T_{j}\right)-G_{l}\left(T_{j},T_{j}\right)\right]\] \[-g\left[G_{em}\left(t_{i},T_{j}\right)-G_{em}\left(T_{j},T_{j} \right)\right].\]

Power plant \(r\in R^{p,l}\) will run at \(T_{j}\) if and only if

\[\widehat{P_{1}}\left(T_{j}\right)>\widehat{P_{2}}\left(T_{j}\right). \tag{5}\]

With some reordering of the terms, it is easy to see that inequality (5) is equivalent to inequality (1).

Using the reasoning above, we can conclude that, for the purpose of determining the stack, it is enough to focus only on spot electricity, fuel and emission contracts. By taking into account startup costs and equations described in Section 2.1, the profit maximization problem of each power plant can be written as

\[\max_{W^{\left(2\right)},W^{\left(4\right)},W^{\left(6\right)}}\sum_{j\in J} \widetilde{W}\left(T_{j}\right)\overline{P}\left(T_{j}\right)-W^{\left(4 \right)}\left(T_{j}\right)s \tag{3.6}\]

subject to

\[W^{\left(4\right)}\left(T_{j}\right)\geq W^{\left(2\right)}\left(T_{j} \right)-W^{\left(2\right)}\left(T_{j-1}\right), \forall j\in J\backslash\left\{1\right\} \tag{3.8}\] \[W^{\left(6\right)}\left(T_{j}\right)\leq W^{\left(2\right)}\left( T_{j}\right), \forall j\in J\] (3.9) \[W^{\left(k\right)}\left(T_{j}\right)\in\left[0,1\right], \forall j\in J,\;k\in\left\{2,4,6\right\}\] (3.10) \[W^{\left(2\right)}\left(T_{j}\right)\in\mathbb{Z}, \forall j\in J, \tag{3.7}\]

where

\[\widehat{W}\left(T_{j}\right)=W^{\left(2\right)}\left(T_{j}\right)\overline {W}_{min}\left(T_{j}\right)+W^{\left(6\right)}\left(T_{j}\right)\left( \overline{W}_{max}\left(T_{j}\right)-\overline{W}_{min}\left(T_{j}\right) \right),\;\forall j\in J \tag{3.11}\]

and

\[\bar{P}\left(T_{j}\right)=\Pi\left(T_{j},T_{j}\right)-cG\left(T_{j},T_{j} \right)-gG_{em}\left(T_{j},T_{j}\right),\;\forall j\in J. \tag{3.12}\]

Note that we do not have to impose the integrality constraints for variable \(W^{\left(4\right)}\left(T_{j}\right)\)\(j\in J\), because they are implied by (3.10) and (3.7). To account for the neglected risk premium, trading costs, maintenance costs etc. we introduce an additional constant \(m>0\) and include it in (3.12) as

\[\bar{P}\left(T_{j}\right)=\Pi\left(T_{j},T_{j}\right)-cG\left(T_{j},T_{j} \right)-gG_{em}\left(T_{j},T_{j}\right)-m,\;\forall j\in J. \tag{3.13}\]

We are interested to know how the optimal solution of Problem (3.6) depends on parameters \(c\), \(g\), \(m\), and \(s\). Let \(\widetilde{W}^{*}\left(T_{j};c,g,m,s\right)\) denote the optimal production of Problem (3.6). Our task is to find \(c\), \(g\), \(m\), and \(s\) that satisfy

\[\min_{c,g,m,s}\sum_{j\in J}\left(\widetilde{W}^{*}\left(T_{j};c,g,m,s\right)- \tilde{W}\left(T_{j}\right)\right)^{2} \tag{3.14}\]

where \(\tilde{W}\left(T_{j}\right)\) denotes observed historical production of a power plant. The optimization problem is a bi-level optimization problem where (3.14) corresponds to the outer optimization problem and (3.6) corresponds to the inner optimization problem. Traditionally, such problems have been very difficult to solve, because they are highly non-convex and the process of finding the optimal solution of the outer optimization problem requires many expensive evaluations of the inner integer programming optimization problem. However, we can show that in our case a difficult integer programming problem can be replaced by a tractable linear programming problem without affecting the optimal solution.

We can use the following proposition to see that optimal solution of Problem (3.6) can be calculated by a linear programming relaxation.

**Proposition 3.1**: _The matrix of constraints (3.7), (3.8), and (3.9) for Problem (3.6) is totally unimodular._

Let us write the matrix of inequality constraints (3.7) and (3.8) as

\[\left[A_{1}A_{2}A_{3}\right]\left[\begin{array}{c}W^{\left(2\right)}\\ W^{\left(6\right)}\\ W^{\left(4\right)}\end{array}\right]\leq 0 \tag{3.15}\]

for some block matrices \(A_{1}\), \(A_{2}\), and \(A_{3}\). We will first show that matrix \(\left[A_{1}A_{2}\right]\) is totally unimodular. Note that all entries are \(\left\{-1,0,1\right\}\). Moreover, each row contains exactly two non-zero entries. One of the entries is \(1\) and the other is \(-1\). These are sufficient conditions for matrix \(\left[A_{1}A_{2}\right]\) to be totally unimodular. It is trivial to see that \(A_{3}=P\left[\begin{array}{cc}I&0\\ 0&0\end{array}\right]Q\) for some permutation matrices \(P\) and \(Q\) of the appropriate size. This implies that matrix \(\left[A_{1}A_{2}A_{3}\right]\) is totally unimodular. The bound constraints (11) can be included by using a similar argument.

By the virtue of Proposition 1, we can relax the binarity constraints and reformulate Problem (10) as an linear programming problem as

\[\begin{array}{rl}\max_{W^{\left(2\right)},W^{\left(4\right)},W^{\left(6 \right)}}&\sum_{j\in J}\widehat{W}\left(T_{j}\right)\overline{P}\left(T_{j} \right)-W^{\left(4\right)}\left(T_{j}\right)s\\ \text{s.t.}&W^{\left(4\right)}\left(T_{j}\right)\geq W^{\left(2\right)}\left(T _{j}\right)-W^{\left(2\right)}\left(T_{j-1}\right),\;\forall j\in J\backslash \left\{1\right\}\\ &W^{\left(6\right)}\left(T_{j}\right)\leq W^{\left(2\right)}\left(T_{j} \right),\;\forall j\in J\\ &W^{\left(k\right)}\left(T_{j}\right)\in\left[0,1\right],\;k\in\left\{2,4,6 \right\},\;\forall j\in J.\end{array} \tag{12}\]

A combination of a particle swarm algorithm [22] and Gurobi [13] was used to solve the bi-level optimization problem (12) in practice. Particle swarm was applied to the outer and Gurobi to the inner optimization problem.

For each power plant we used over 5000 training samples obtained from the period between 1/1/2012 and 1/1/2013.

### UK power grid

In this section we apply our model to the entire system of the UK power plants. We focus on the coal, gas, and oil power plants, because these power plants adapt their production to cover the changes in demand and are thus responsible for setting the price. Nuclear power plants do not have to be modeled explicitly because their ramp-up and ramp-down constraints are so tight that their production is almost constant over time. They usually deviate from the maximum production only for maintenance reasons. Renewable sources and interconnectors are not modeled explicitly, because they require a different treatment not covered in this paper. In this section, we define demand \(D\left(T_{j}\right)\) for all \(j\in J\) as

\[D\left(T_{j}\right):=D_{act}\left(T_{j}\right)-P_{renw}\left(T_{j}\right)-P_{ inter}\left(T_{j}\right) \tag{13}\]

where \(D_{act}\left(T_{j}\right)\) denotes the actual demand in the UK power system, \(P_{renw}\left(T_{j}\right)\) denotes the production from all renewable sources including wind, solar, biomass, hydro and pumped storage, and \(P_{inter}\left(T_{j}\right)\) denotes the inflow of power into the UK power system through interconnectors. To make this model useful in practice one has to model each of these terms, but this exceeds the scope of this paper.

Our goal is to calculate the electricity spot price with the information available on 11/2/2013. We are interested in a delivery period from 4/4/2013 00:00:00 to 8/4/2013 00:00:00. We assume that there are two types of power contract available. The first is a month ahead contract traded on 15/3/2013 17:00:00 and covers the delivery over all four days. The second type is a spot contract that requires an immediate delivery and is traded for each half hour separately. We use future prices of coal, gas, and oil as available on 11/2/2013. Since the historical demand forecast is not available, we used the realized demand instead, which is a standard practice in the literature. To use this model in practice, one could use a demand forecast available at the Flexon webpage2 or develop a new approach. Since we do not have the information about the ownership of the power plants, we assumed that there is only one producer who owns all power plants connected to the UK grid and only one consumer that is responsible for satisfying the demand of the end users. In reality, market participants have more information about the ownership that can be incorporated into the model. We set \(\lambda_{k}=10^{-7}\) for all \(k\in P\cup C\). The impact of the risk aversion of producers and consumers is thoroughly investigated in [20]. As described in the previous section, we estimated parameters \(c\), \(g\), \(m\), and \(s\) for each power plant from 5000 training samples obtained in the period between 1/1/2012 and 1/1/2013.

Footnote 2: [http://www.bmreports.com/](http://www.bmreports.com/)

To motivate the inclusion of startup costs we first investigate a simplified version of our model described in Section 2 and neglect the startup costs. Figure 3 shows the output of our model, when all startup costs are set to zero. The figure on the left hand side depicts the calculated energy mix between coal and gas power plants, while the figure on the right hand side depicts the actually observed energy mix. Both figures contain also the spot price calculated by our model and the actually observed spot price. The difference between calculated and observed production for each fuel is depicted in Figure

### 3.2.

We can see that our model predicts the energy mix very closely. Moreover, the daily pattern of the electricity price predicted by our model is similar to the actually observed one. The model correctly predicted that the electricity price is higher during the peak hours than during the off peak hours. Furthermore, the calculated electricity price has two daily peaks that occur at almost the same time as in the historically observed price.

The graphs also reveal a few problems of our model. Firstly, we can see that our model underestimates spot prices during peak hours and overestimates them during the off-peak hours. A similar results was also found in [15]. Secondly, the two spikes in the observed price are not captured in our model. This motivated us to extend our model and incorporate the startup costs of the power plants. For the purpose of calibration, we applied the approach described in Section 3.1.

Calculated equilibrium prices and the energy mix with startup costs included are depicted in Figure 3.3. By comparing Figure 3.1 and Figure 3.3, we can see that the calculated equilibrium price captures the daily variations of the actually observed price much more closely. It correctly predicts some of the spikes, but also forecasts many false positives. Figure 3.4 shows that the inclusion of startup costs slightly improved the error in the energy mix calculation.

It is interesting to explore the conditions of the electricity grid at times when the spikes in the electricity price occur. A very descriptive parameter is standing reserve \(SR\left(T_{j}\right)\), \(j\in J\), defined as

\[SR\left(T_{j}\right)=\sum_{p\in P}\sum_{l\in L}\sum_{r\in R^{p,l}}\left[W_{p,l, r}^{\left(2\right)}\left(T_{j}\right)-W_{p,l,r}^{\left(6\right)}\left(T_{j} \right)\right]\left[\overline{W}_{max}^{p,l,r}\left(T_{j}\right)-\overline{W} _{min}^{p,l,r}\left(T_{j}\right)\right], \tag{3.18}\]

which quantifies by how much the power plants that are currently running can increase their production

Figure 3.1. Comparison of the calculated and historical electricity price and energy mix when startup costs are excluded (i.e. set to zero).

Figure 3.2. The difference between calculated and observed gas and coal production.

before a new power plant must be turned on. Since most of the power plants have severe constraints on startup times, low standing reserve usually implies low stability of the electricity grid.

Figure 5 depicts the calculated standing reserve over the relevant time period. We can see that all price spikes occur when standing reserve is close to zero. In such situations, a new power plant must be turned on (and off quickly afterwards) to cover the temporary extra demand. Thus, the startup costs are spread over a very short period of time, and a high electricity price is required for such an action to be profitable. However, in reality, the times of a low standing reserve are very rare. The grid operator is responsible for providing a reliable electricity delivery and preventing times with a low standing reserve. This is achieved by incentivizing some of the power plants to start production even when it is not profitable for them. The costs of such actions are distributed among all market participants. How to include the grid operator in our model is discussed in the next section.

In the remaining part of this section, we evaluate the error caused by using the continuous relaxation of Problem (PR). We follow the procedure described in Section 2.6. The MIQP error is depicted by a dashed line in Figure 6. To estimate the effect of numerical errors, we also calculated the QP error which is shown in Figure 6 as a solid line.

We can see from Figure 6 that \(\left\|\sum_{e\in C}V_{e}^{*}+\sum_{p\in P}V_{p}^{*}\right\|_{\infty}\approx 40 \mathrm{MWh}\). Also in reality, production and consumption do not match exactly. The mismatch is reflected through changes in the power line frequency. In the UK, the nominal power line frequency is 50 Hz. The grid operator, called National Grid, is responsible for keeping the frequency within \(\pm 1\%\)3 of the nominal power line frequency. We

Figure 4: The difference between calculated and observed gas and coal production after including startup costs.

Figure 3: Comparison of the calculated and historical electricity price and energy mix when startup costs are included.

can see from Figure 6 that the largest errors occur at times when demand is high. Since the overall demand for electricity during the peak hours is approximately \(40\,\mathrm{GW}\) we can conclude that the error is within \(\pm 1\%\) error bound.

The model presented in this paper neglects the losses of electricity in transmission and distribution lines. According to the World Bank4 the transmission and distribution losses in the UK account for approximately \(7.5\%\) (maximum \(8.5\%\) in 2004 and minimum \(7.0\%\) in 2010) of the total electricity production. The losses vary in time and can change for \(\pm 1\%\).

Footnote 4: See [http://data.worldbank.org/indicator/EG.ELC.LOSS.ZS/countries/GB?display=graph](http://data.worldbank.org/indicator/EG.ELC.LOSS.ZS/countries/GB?display=graph).

Due to the reasons above, we believe that for the purpose of modeling realistic power prices, it is enough to consider the continuous relaxation of Problem (PR) and neglect binarity constraints.

## 4 Grid operator

In Section 2, we investigated how to include startup costs in our model. The calculated equilibrium price contained many spikes, which are in reality prevented by intervention of the grid operator. In times, when the standing reserve is low, the grid operator incentivizes additional power plants to turn on and thus help making the delivery of electricity more reliable. In this section we investigate how to incorporate the actions of the grid operator into our model.

### Quadratic programming formulation

The costs of the grid operator's actions that help to maintain a high reliability of the delivery of electricity are distributed among all market participants. All market participants are collectively penalized in the situations when the standing reserve is low.

Figure 6: Error caused by considering Problem \(\widehat{PR}\) instead of Problem PR.

Figure 5: Standing reserve for the relevant time period.

To include the penalization in our model, we propose a quadratic penalty function \(\Upsilon\left(SR\left(T_{j}\right)\right)\) defined as

\[\Upsilon\left(SR\left(T_{j}\right)\right):=\alpha\left(\max\left\{0,\beta-SR \left(T_{j}\right)\right\}\right)^{2}, \tag{12}\]

where \(\alpha>0\) and \(\beta>0\) are used to describe a risk aversion of the grid operator. Parameter \(\beta\) tells us at what level of the standing reserve does the grid operator start to take action. Parameter \(\alpha\) tells us how much is the grid operator willing to incentivize the power plant to start production.

One can incorporate the grid operator into Problem (52) as

\[\begin{array}{ll}\max_{x}&-\pi^{\top}x-\frac{1}{2}x^{\top}Qx-\sum_{j\in J} \Upsilon\left(SR\left(T_{j}\right)\right)\\ \\ \text{s.t.}&Ax=a\\ &Bx\leq b\\ \\ \mu_{M}=0\end{array} \tag{13}\]

It might not be immediately clear, how to write the penalty term (12) in a quadratic programming framework. We can follow an approach that is widely used in the linear programming literature and introduce a decision variable \(z\left(T_{j}\right)\) with the following constraints

\[\begin{array}{rcl}z\left(T_{j}\right)&\geq&0\\ \\ z\left(T_{j}\right)&\geq&\beta-SR\left(T_{j}\right),\end{array} \tag{14}\]

which hold for each \(j\in J\). The penalty function \(\Upsilon\left(SR\left(T_{j}\right)\right)\) can be written as a function of \(z\left(T_{j}\right)\) as

\[\Upsilon\left(z\left(T_{j}\right)\right):=\alpha z\left(T_{j}\right)^{2}, \tag{15}\]

which fits into the quadratic programming framework.

One can apply the procedure described in Section 2.6 to find a more convenient dual formulation of Problem (13).

### Numerical results

In this section we investigate numerical results after inclusion of the grid operator. Calculated equilibrium prices and the energy mix and depicted in Figure 1. The figure on the left hand side depicts the calculated energy mix between coal and gas power plants, while the figure on the right hand side depicts the actually observed energy mix. Both figures contain also the spot price calculated by our model and the actually observed spot price. We set \(\alpha=0.01\) and \(\beta=1500\). Determination of the optimal standing reserve is a challenging problem, which has received a lot of attention in the literature (see [10] and [9] for example) and exceeds the scope this paper.

By comparing Figure 2 and Figure 1, we can see that the calculated equilibrium electricity price in Figure 1 follows the daily variations much more closely. The calculated equilibrium electricity price does not contain any spikes, because the grid operator prevented them by managing the standing reserve. In our model, we assume that the players (and the grid operator) have a perfect demand forecast. However, in reality this is usually not the case. The grid operator is not able to predict the demand perfectly, and corrective actions are often required. When large corrective action is required at times close to delivery, then only a few (usually rather inefficient Open Cycle Gas Turbine) power plants are flexible enough to cover the demand, which causes spikes in the electricity price. Modeling of recursive actions exceeds the scope of this paper and is left for future work.

Figure 2 shows that the inclusion of the grid operator did not have any significant impact on the error in the energy mix.

Figure 3 shows the standing reserve after inclusion of the grid operator. The standing reserve never reaches zero since the grid operator prevents this by requiring new power plants to start production to ensure stability of the electricity grid. This makes the spot price smoother and significantly decreases the number of spikes.

Figure 4 depicts the MIQP and QP errors after inclusion of the grid operator. By comparing Figure 5 and Figure 4, we can see that the inclusion of the grid operator has a small impact on the errors, which remained within \(\pm 1\%\) error bound.

## 5 Conclusions

In this paper we proposed a tractable quadratic programming formulation for calculating the equilibrium term structure of electricity prices when the startup costs of power plants are included in the model. Through numerical simulations we showed that startup costs have a large impact on electricity prices. When startup costs are included in the model, the calculated spot electricity price during peak hours increased and during off-peak hours decreased. Moreover, startup costs are responsible for introducing frequent high spikes in the spot electricity price.

We observed that price spikes occur at times when the standing reserve in low. In reality, the times of a low standing reserve are rare, because of the intervention of the grid operator, who is responsible for providing a reliable electricity delivery and preventing times with a low standing reserve. We included the grid operator in our model in the second part of the paper. This significantly decreased the number of spikes. Moreover, the computed equilibrium electricity prices matched the historically observed prices very closely.

Numerical simulations were performed by modeling the realistic UK power grid consisting of a few hundred power plants. A tractable approach to estimate startup costs of power plants from their historical production was also proposed.

## References

* [1]M. T. Barlow, _A diffusion model for electricity prices_, Mathematical Finance, 12 (2002), pp. 287-298.
* [2]Hendrik Bessembinder and Michael L. Lemmon, _Equilibrium pricing and optimal hedging in electricity forward markets_, Journal of Finance, 57 (2002), pp. 1347-1382.

Figure 1: Comparison of the calculated and historical electricity price and energy mix with startup costs and the grid operator included.

Figure 2: The difference between calculated and observed gas and coal production after including the grid operator.

* [3]Wolfgang Behler, _Risk premia of electricity futures: A dynamic equilibrium model_, in Risk Management in Commodity Markets, John Wiley & Sons, Ltd., 2009, pp. 61-80.
* [4]Wolfgang Behler and Jens Moller-Merbach, _Valuation of electricity futures: Reduced-form vs. dynamic equilibrium models_, Mannheim Finance Working Paper No. 2007-07, (2009).
* [5]Rene Carmona, Michael Coulon, and Daniel Schwarz, _Electricity price modeling and asset valuation: a multi-fuel structural approach_, Mathematics and Financial Economics, 7 (2013), pp. 167-202.
* [6]Les Clewlow and Chris Strickland, _A multi-factor model for energy derivatives_, Research Paper Series 28, Quantitative Finance Research Centre, University of Technology, Sydney, Dec. 1999.
* [7], _Valuing energy options in a one factor model fitted to forward prices_, Research Paper Series 10, Quantitative Finance Research Centre, University of Technology, Sydney, Apr. 1999.
* [8]Gauthier De Maere d'Aertycke and Yves Smerers, _Liquidity Risks on Power Exchanges: a Generalized Nash Equilibrium model_, 2012.
* [9]K. De Vos and J. Drissen, _Dynamic operating reserve strategies for wind power integration_, Renewable Power Generation, IET, 8 (2014), pp. 598-610.
* [10]E. Ela, B. Kirby, E. Lannoye, M. Milligan, D. Flynn, B. Zavadil, and M. O'Malley, _Evolution of operating reserve determination in wind power integration studies_, in Power and Energy Society General Meeting, 2010 IEEE, July 2010, pp. 1-8.
* [11]Isabel Garcia, Claudia Kloppelberg, and Gernot Muller, _Estimation of stable CARMA models with an application to electricity spot prices_, Statistical Modelling, 11 (2011), pp. 447-470.
* [12]Paul R. Gribik, William W. Hogan, and Susan L. Pope, _Market-clearing electricity prices and energy uplift_, technical report, Harvard University, Cambridge, MA, Dec. 2007.
* [13]Inc. Gurobi Optimization, _Gurobi Optimizer Reference Manual_, 2014.
* [14]Ben Hambly, Sam Howison, and Ting Kluge, _Modelling spikes and pricing swing options in electricity markets_, Quantitative Finance, 9 (2009), pp. 937-949.

Figure 4.4. Error caused by considering Problem \(\overline{PR}\) instead of Problem PR.

Figure 4.3. Standing reserve for the relevant time period.

* [15]Scott M. Harvey and William W. Hogan, _Market power and market simulations_, technical report, Center for Business and Government, Harvard University, Cambridge, MA, July 2002.
* [16]Sam Howison and Michael C. Coulon, _Stochastic behaviour of the electricity bid stack: From fundamental drivers to power prices_, The Journal of Energy Markets, 2 (2009).
* [17]Julio J. Lucia and Eduardo Schwartz, _Electricity prices and power derivatives: Evidence from the nordic power exchange_, (2000).
* [18]D. Martinez, _A methodology for the consideration of start-up costs into the marginal cost estimated with production cost models_, in Electricity Market, 2008. EEM 2008. 5th International Conference on European, May 2008, pp. 1-10.
* [19]Thilo Meyer-Brands and Peter Tankov, _Multi-factor jump-diffusion models of electricity prices_, International Journal of Theoretical and Applied Finance (IJTAF), 11 (2008), pp. 503-528.
* [20]M. Troin and R. Hausen, _Calculation of a power price equilibrium_, ArXiv e-prints, (2014).
* [21], _The existence and uniqueness of a power price equilibrium_, ArXiv e-prints, (2014).
* [22]A.IsmaelF. Vaz and LuisN. Vicente, _A particle swarm pattern search method for bound constrained global optimization_, Journal of Global Optimization, 39 (2007), pp. 197-219.
* [23]Binginging Zhang, P.B. Luh, E. Litvinov, Tongxin Zheng, and Feng Zhao, _On reducing uplift payment in electricity markets_, in Power Systems Conference and Exposition, 2009. PSCE '09. IEEE/PES, Mar. 2009, pp. 1-7.

Title: The varying importance of extrinsic factors in the success of startup
  fundraising: competition at early-stage and networks at growth-stage
Transcription: The varying importance of extrinsic factors in the success of startup fundraising: competition at early-stage and networks at growth-stage

Clement Gastaud1,2, Theophile Carniel1,2, Jean-Michel Dalle*,1,2,3

**1** Agoranov, Paris, France

**2** Sorbonne Universite, Paris, France

**3** i3-CNRS, Ecole Polytechnique, France

* jean-michel.dalle@sorbonne-universite.fr

## Abstract

We address the issue of the factors driving startup success in raising funds. Using the popular and public startup database Crunchbase, we explicitly take into account two extrinsic characteristics of startups: the competition that the companies face, using similarity measures derived from the Word2Vec algorithm, as well as the position of investors in the investment network, pioneering the use of Graph Neural Networks (GNN), a recent deep learning technique that enables the handling of graphs as such and as a whole. We show that the different stages of fundraising, early- and growth-stage, are associated with different success factors. Our results suggest a marked relevance of startup competition for early stage while growth-stage fundraising is influenced by network features. Both of these factors tend to average out in global models, which could lead to the false impression that startup success in fundraising would mostly if not only be influenced by its intrinsic characteristics, notably those of their founders.

## 1 Introduction and literature overview

In the case of venture capital investments, where the risks are particularly high and startups' business models uncertain, a simple vision of the state of affairs of the startup is usually not sufficient to determine whether it will succeed or not. Given the considerable attention that startups have drawn in the past decade from private investors and public policy makers alike, getting a better understanding of the criteria driving startup success has therefore become a particularly relevant issue.

The early literature on this topic highlighted several features of importance with respect to startup success and failure, besides earnings and assets analysis, and including human capital [1], founders' psychology [2] or countries' cultures [3], using interviews or surveys. More recently, large-scale public databases have appeared, notably with the creation of Crunchbase [4] in 2007 that has been used in numerous recent academic studies [5], sometimes replaced or supplemented by other similar datasets such as Dealroom [6], CBinsight [7] or Owler [8].

In this context, an emerging field of research has started developing predictive models based on these large-scale datasets: predicting startup success or failure [9, 10], predicting M&As [11, 12] or predicting crowdfunding success [13, 14]. In addition to standard economic and financial variables (funds raised, cash burn, etc.), these approaches highlight the importance of other features such as the influence of founders [9, 13], online and social media presence [10, 14] or else topics associated with the company's description [15, 16]. According to these studies, most elements driving investors' decisions would seem to be only intrinsic to the potential investment target: its addressable market, founders, business model, etc., most notably at the expense of extrinsic, context- and environment-related features [18]. Some studies [10, 17] have started taking into consideration elements related to the environment in which the startup operates, which is particularly relevant both because of the availability of information on these environments, and because of their potential impact, notably with respect to competition or to the embeddedness of startups in given ecosystems and sectors. More specifically, some papers [19, 20] have focused on social networks, notably using distance features between investors and companies to predict investments as a link prediction task. Most recently, and in the different context of predicting the long-term success of startups, Bonaventura et al. [22] have made use of the network of employees, in startups and other companies. Interestingly, their results show that crisis events increase unpredictability in entrepreneurial ecosystems.

However, none of these articles look at funding stages separately, although early-stage, growth and late-stage funding rounds are mostly conducted by different actors and might therefore be driven by different dynamics. Sharchilev et al. [10], in order to predict future rounds, simply includes the stages of previous funding rounds as a feature but does not consider different models for each stage. To put it differently, it wouldn't be surprising at all if factors of interest for investors when choosing potential ventures would differ at the different stages of investment. By mixing all stages, some factors critical for certain rounds and not for others could be averaged out and disappear from global models.

We analyze funding stages separately in this paper. In addition, while accounting for various intrinsic characteristics of startups, we also explicitly assess the relevance of two key extrinsic features:

* we explicitly account for competition by introducing dedicated metrics. Although competition is a key element suitable to affect and influence startup success, it has been mostly neglected in related works, with the notable exception of [10] who included two features related to competition in their model, but used metrics directly retrieved from Crunchbase though Crunchbase has notoriously been lacking in this regard, to the point that these elements have since been removed from the website. A crowdsourced database of competitors can also be found on Owler [8], but it is focused on large companies, which would not be appropriate to predict startup success. To the extent of our knowledge, and in the different context of predicting M&As, only Shi et al. [12] have proposed a framework to evaluate competition at a large scale by applying topic modeling techniques to startup descriptions and calculating a "business similarity" measure from this representation. Following Shi et al. [12] and in accordance with the suggestions of [17], we progress further in this direction by using the recent advances of natural language processing techniques to compute companies' representations.
* we explicitly account for the network of startup and investor relations not only through the centrality of investors but also by pioneering on such data the use of Graph Neural Networks (GNN), a recent deep learning development [38] that enables the handling of graphs as such, and as a whole, in machine learning prediction tasks, instead of simply using features derived from it.

We find that predicting the success of a startup when raising funds is indeed associated with different features at early and growth stages: early-stage fundraising being notably associated with competition, with a low intensity of competition markedly increasing the probability of raising funds, and with a lower relevance of network features, while growth-stage fundraising seems to be notably influenced by network features, competition playing only a limited role. Both characteristics - competition and networks - do average out in the global model, giving the (false) impression that neither competition nor networks would matter so much, compared to the characteristics of founders notably - whereas they do matter, but at different stages of startup fundraising.

Materials and methods

### Data used

We exploit a dataset of startups from Crunchbase [4], a mainstream source of data for academic research [5]. For each startup, we retrieved its date of creation, location, sectoral tags (describing its economic sector, technology and/or market), textual description and, most notably, all the information with respect to the funds that the startup has raised, including the date at which they were raised, the amount of funding, the nature of the funding round and the identity of the investors as well as all the articles mentioning this company available on Crunchbase (Figure 1). In addition, we retrieved all information available about people, giving us in particular proxies with regard to the experience of startup founders. Overall, our dataset consists in 618 366 companies, 221 299 investment rounds, 783 787 people and 6 363 831 news articles.

Most of the data can be used as is in a prediction model. However, textual data that potentially contains relevant information implies preprocessing. In particular, encoding textual descriptions of startups in a vector enables similarity measurements between startups that we will use to assess competition.

### Prediction task

It should first be noted that the definition of "success" for a startup is not straightforward. From an investor's point of view, a startup is successful if he or she is able to make a successful _exit_: that is, if he or she can sell his or her shares for a profit, usually through an IPO or an acquisition. Methodologically though, acquisitions are not always successful exits, as investors might not be able to recover their initial investments in this process. Furthermore, since neither entry nor exit prices are generally disclosed, it is extremely difficult to discriminate between successful and unsuccessful exits. In addition, already profitable startups might remain private for a long time: to qualify such startups as "unsuccessful" would be misleading. Basically, apart from success in crowdfunding [13, 14] or M&As [11, 12], the main option suggested in the literature to measure success is to predict future funding rounds [10]: i.e., at a given time, determining which startups will raise funds in the next \(t\) years, with \(t\) a parameter.

In this paper, we will conduct two studies in parallel. First, for each semester between 2010 and 2015, we will study all the startups that raised funds in venture and seed rounds and try to predict if they will raise another round, get acquired or go public in the following two years. We will remove from this study startups that were already acquired or public before the end of the studied semester. Looking at the problem at different time stamps allows us to increase the number of samples, while also staying focused on _active_ startups.

Second, we will do the same analysis but focused on different stage fundraiser. Instead of taking all the startups that raised in a semester, we will only select those that raised in seed, series A or series B during this time.

The number of samples is reported in table 1.

### Investor network

We propose that the position of a startup's investors in the investor's network is extremely important in determining its success. First, as stated in [21], VCs rely heavily on their network to source startups. A startup thus has better chances of finding its next investor if its existing ones are well connected. Second, [23, 24] put forward that "faced with great uncertainty about the quality of young companies, third parties rely on the prominence of the affiliates of those companies to make judgments about their quality and that young companies "endorsed" by prominent exchange partners will perform better than otherwise comparable ventures that lack prominent associates". VC reputation has also been positively linked to post-IPO performances [25].

In order to assess the reputation of an investor, we use its betweenness centrality in the relationship network, as it was done in [23, 25, 26]. Using Crunchbase data, we can build this graph using co-investments, investors being linked if they both invested in the same startup. Each edge of the graph is weighted, the weight being proportional to the number of portfolio companies that the investors have in common. In our prediction model, for each startup, we will use as features the max, mean and sum of the centralities of its investors.

### Competition analysis

Assessing competition using startup descriptions requires the use of a measure of their similarity. Literature on text embedding and similarity has skyrocketed in the last few years with the rise of Natural Language Processing. Some of the most commonly used algorithms include a bag-of-words and TF-IDF model (used in Batista et al. [27] to classify Crunchbase startups in categories), topic modeling approaches such as LSI or LDA [28] (used in Shi et al. [12]) or more recently using word embeddings such as word2vec [29], GloVe [30] or FastText [31]. Among these approaches, prediction-based word-embeddings have been found to yield better results than their count-based counterparts [32], and we will thus use a word2vec approach in this paper.

Word2vec uses a neural network to predict the most probable words around every given word. By doing so, we compute a (low-dimensional) vectorial representation of each word, encoding the "context" in which the word is used. This vectorial representation gives us the position in word-space of each word, allowing us to compute distance and similarity measures between words. The dimension

Tuple 23:
Cleaned Title: recommending investor new startup integrating network diffusion investor domain preference
Cleaned Transcription: recommending investor new startup integrating network diffusion investor domain preference shuqi xu qianming zhang linyuan li manuel sebastian mariani institute fundamental frontier science university electronic science technology china chengdu china complexlab big data research center university electronic science technology china chengdu china alibaba research center complexity science hangzhou normal university hangzhou china urpp social network universitat zurich zurich switzerland abstract past decade many startup sprung create huge demand financial support venture investor however due information asymmetry investor company financing process usually challenging timeconsuming especially startup yet obtained investment effective datadriven technique automatically match startup potentially relevant investor would highly desirable analyze valid investment event collected wwwitiuzicom consider coldstart problem recommending investor new startup address problem constructing different tripartite network representation data node represent investor company company domain first find investor strong domain preference investing motivates u introduce virtual link investor investment domain tripartite network construction analysis recommendation performance diffusionbased algorithm applied various network representation indicates prospective investor new startup effectively revealed integrating network diffusion process investor domain preference keywords diffusion model recommender system venture investment coldstart problem tripartite network footnote journal information science introduction rapid development internet brings information overload problem people usually receive much information given issue greatly impairs efficiency decisionmaking process automated informationfiltering tool ranking algorithm recommender system provide u effective solution problem particular recommender system exploit data user past preference predict possible future interest thus widely applied various online platform including ecommerce website online social network previous work shown capable recommender system largely increase economic benefit also customer loyalty several financial investment scenario including stock investment real estate investment crowdfunding project portfolio management recommender system received increasing attention le attention devoted design application recommendation system domain venture investment emerging investment type aim offering seed funding startup company extant study topic focused helping vc firm find investee company effective method support new startup search investor yet gained attention scholar startup earlystage funding constitute key support yet obtaining challenging finding suitable investor interested startup business scope usually requires longterm research especially difficult new startup due inexperience reason investorfiltering system aimed new startup extremely beneficial main goal fill gap designing validating recommendation system technique identify suitable investor new startup end analyze investment event collected wwwitjuzicom focus startup received previous investment past widelystudied recommendation technique based bipartite network applicable since new startup previous investor turn isolated node investorcompany bipartite network making unreachable diffusion process problem classified coldstart problem new actor enters system insufficient past information provide himher recommendation overcome coldstart problem resort tagging technique wwwitjuzicom platform startup required provide several tag define business scope found investor strong preference toward small number tag particular majority case investor tends invest startup feature favorite tag hence motivated finding key role played industry field investment decision making use tag key piece information generate recommendation leveraging startup tag information construct three different tripartite network representation investment system natural tripartite representation one investor connected startup invested startup connected selfreported tag refer representation tagcompanyinvestor tci representation representation natural directly based collected data company selfreported tag investorcompany investment event commonly used existing study online social network kind tripartite network considers connection already data recommendation made applying physical diffusion process probabilistic spreading heat transfer see detail section available network however find goal produce recommendation investor new startup natural tci representation suboptimal reason new startup direct connection investor implies tci representation relatively long network path needed diffusion process travel target startup prospective investor moreover empirical analysis indicates investor tend concentrate investment toward startup small number preferred tag property suggests problem investortag connection potentially informative investorcompany connection motivated observation introduce virtual link investor tag construct two new tripartite network representation companytaginvestor cti companyinvestortag cit network representation three tripartite network representation considered tci cti cit apply diffusionbased recommendation algorithm find diffusion algorithm based network virtual link ie companytaginvestor companyinvestortag network achieve substantially better recommendation accuracy compared based natural tagcompanyinvestor representation main focus diffusionbased technique motivated existing work indicate class technique wellsuited scenario input data binary without rating limited information target item user available time narrow focus class algorithm alternative technique existing study including neighborbased collaborative filtering matrix factorization based bayesian personalized ranking see section also included analysis proposed diffusionbased algorithm turn outperform existing algorithm based tripartite network representation main contribution paper twofold first brings networkbased recommendation technique problem finding relevant investor newcomer startup second address problem introduces virtual link investor tag build network representation possibility introduce link exploited previous study recommendation algorithm based tripartite network yet virtual link turn vital achieving good recommendation performance new representation achieves indeed improved performance recommendation technique based straightforward tci representation existing collaborative filtering matrix factorization algorithm finding reveal powerful method startup find first investor paper structured follows section review related work section describe dataset analyze tag preference investor propose construction three tripartite network representation section introduce recommendation algorithm employed tripartite network baseline algorithm evaluation metric section present result discus finally section concludes paper point several open research direction related work recommendation method collaborative filtering cf one widelyused family recommendation technique grouped memorybased cf modelbased cf online system user rate item memorybased cf approach use user past rating data compute similarity user item produce prediction target user based similar user similar item already collected modelbased cf method leverage historical data learn predictive model wellknown modelbased cf technique include bayesian network clustering model latent semantic model among others critical component cf method measurement similarity pair user item known vulnerable data sparsity coldstart problem another common class technique contentbased filtering utilizes description item profile user preference find item best match item previously selected user recommendation process includes representing item feature learning user profile filtering also hybrid approach combine collaborative contentbased method different variant recommender system act data rating positiveonly data eg clickthrough data browsing history investment history without rating interest several physicsrooted recommendation method context input data represented bipartite network eg useritem network tripartite network eg useritemtag network based actual link dataset recommendation obtained employing classical physic process diffusion like probs algorithm heat transfer like heat algorithm network refer review networkbased recommendation algorithm recommender system investment domain applying recommender system financial investment problem received growing attention generally considered challenging task strict expectation informationseeker field application recommender system financerelated domain include stock investment real estate investment crowdfunding project portfolio management among others venture investment relatively scientific publication topic recommendation stone et al used collaborative filtering recommend relevant investment opportunity venture capital vc firm reported class activity characterized extremely sparse data number invested company vc firm follows powerlaw distribution point existence active vc firm zhao et al proposed riskaware startup selection method ranking algorithm predict vc firm new investment existing study largely concentrated helping vc firm find investee company lack research effective method support new startup searching investor bringing networkbased recommendation technique problem recommending investor startup one main contribution paper coldstart problem coldstart problem insufficient past information hard infer user preference item potentially relevant user simple approach mitigate coldstart problem recommend popular object based historical data strategy provide uniform recommendation user diverse outcome obtained gathering rapidly additional information user preference achieved actively eliciting user make informative choice integrating information user activity using hybrid technique combine recommendation obtained different method alternative technique one leverage additional information construct network run standard diffusionbased algorithm following idea zhang et al proposed diffusionbased recommendation algorithm considers social tag bridge connecting user object indicated tag effectively build relation existing object new one thereby providing solid recommendation new object deng et al introduced social mass diffusion smd method based mass diffusion process combined network user social network useritem bipartite network showed smd generate personalized recommendation new user global ranking based popularity besides scholar introduced number strategy based matrix factorization algorithm gantner et al proposed method extension matrix factorization optimized bayesian personalized ranking leveraged mapping function compute adequate latent feature representation new entity attribute kula estimated feature embeddings factorizing collaborative interaction matrix approach new user item represented term combination metadata feature estimated training set fernandeztobias et al analyzed several solution new user problem collaborative filtering based user personality information using factor describe individual personality openness conscientiousness extraversion agreeableness neuroticism assessed selfdescriptive sentence adjective including personalitybased matrix factorization personalitybased active learning personalitybased crossdomain recommendation summarize key element address coldstart problem acquired information user preference obtained either directly asking auxiliary information actively collecting available studied platform requiring target provide detailed individual information practicable case therefore majority approach mitigate coldstart problem target user least limited historical activity whereas recommendation new user without prior activity must draw support implicit preference feature paper focus coldstart problem startup without prior activity leverage startup selfreported tag infer investor preference data network construction dataset description collected investment event wwwtijuzicom event data includes information one investor one investee company company tag event time temporal resolution one day note joint investment involve several investor appear multiple event removed data event investor information missing leaf u investment event ranging dec st apr th investor company tag involved event table show two example average investor invests company blue square figure represent distribution number company per investor hand average company investor red dot figure represent distribution number investor per company company one investor manifestation sparse nature investment data sparsity reasonable since investment event frequent online activity event watching movie making new friend online platform final investment decision usually timeconsuming tag company reported tag average figure b illustrates distribution number tag per company
Original Title: Recommending investors for new startups by integrating network diffusion
  and investors' domain preference
Original Transcription: Recommending investors for new startups by integrating network diffusion and investors' domain preference

Shuqi Xu

Qianming Zhang

Linyuan Li

Manuel Sebastian Mariani

Institute of Fundamental and Frontier Science, University of Electronic Science and Technology of China, Chengdu, China ComplexLab, Big Data Research Center, University of Electronic Science and Technology of China, Chengdu, China Alibaba Research Center for Complexity Sciences, Hangzhou Normal University, Hangzhou, China URPP Social Networks, Universitat Zurich, Zurich, Switzerland

###### Abstract

Over the past decade, many startups have sprung up, which create a huge demand for financial support from venture investors. However, due to the information asymmetry between investors and companies, the financing process is usually challenging and time-consuming, especially for the startups that have not yet obtained any investment. Because of this, effective data-driven techniques to automatically match startups with potentially relevant investors would be highly desirable. Here, we analyze \(34,469\) valid investment events collected from _www.itiuzi.com_ and consider the cold-start problem of recommending investors for new startups. We address this problem by constructing different tripartite network representations of the data where nodes represent investors, companies, and companies' domains. First, we find that investors have strong domain preferences when investing, which motivates us to introduce virtual links between investors and investment domains in the tripartite network construction. Our analysis of the recommendation performance of diffusion-based algorithms applied to various network representations indicates that prospective investors for new startups are effectively revealed by integrating network diffusion processes with investors' domain preference.

keywords: Diffusion model, Recommender systems, Venture investment, Cold-start problem, Tripartite network +
Footnote †: journal: Information Sciences

## 1 Introduction

The rapid development of the Internet brings the information overload problem: people usually receive too much information about a given issue, which greatly impairs the efficiency of their decision-making process [11]. Automated information-filtering tools such as ranking algorithms [23] and recommender systems [26] provide us with effective solutions to this problem. In particular, recommender systems can exploit data on users and their past preferences to predict their possible future interests, thus have been widely applied by various online platforms, including e-commerce websites [25] and online social networks [40]. Previous works [34] have shown that capable recommender systems can largely increase not only economic benefits but also customer loyalty.

In several financial investment scenarios, including stock investment [14], real estates investment [15], crowd-funding project [3], and portfolio management [30], recommender systems have received increasing attention [50]. Less attention has been devoted to the design and applications of recommendation systems in the domain of venture investment, an emerging investment type that aims at offering seed funding to startup companies. Extant studies on the topic [37; 48] have focused on helping VC firms to find investee companies, while effective methods to support new startups in their search for investors have not yet gained attention from scholars. For a startup, early-stage fundings constitute key support, yet obtaining them is challenging [32]. Finding a suitable investor who is interested in the startup's business scope usually requires long-term research, which is especially difficult for new startups due to their inexperience [8]. For this reason, an investor-filtering system aimed at new startups can be extremely beneficial.

Our main goal is to fill this gap by designing and validating recommendation system techniques to identify suitable investors for new startups. To this end, we analyze 34,469 investment events collected from www.itjuzi.com[1]. As we focus on startups that received no previous investments in the past, widely-studied recommendation techniques based on bipartite networks [49] are not applicable here since the new startups with no previous investors turn out to be isolated nodes in the investor-company bipartite network, making them unreachable by diffusion processes. Our problem can be classified as a _cold-start problem_[35]: When a new actor enters the system, there is insufficient past information to provide him/her with a recommendation [26].

To overcome the cold-start problem, we resort to tagging techniques [16].On the www.itjuzi.com platform, each startup is required to provide several tags that define its business scope. We found that the investors have a strong preference toward a small number of tags - in particular, in the majority of cases, an investor tends to invest in startups that feature her favorite tag. Hence, motivated by this finding and the key role played by the industry field in investment decision making [10; 28], we use tags as a key piece of information to generate recommendations.

By leveraging startups' tag information, we construct three different tripartite network representations of the investment system. The most natural tripartite representation is one where investors are connected to the startups they invested in, and startups are connected to their self-reported tags - we refer to this representation as the tag-company-investor (TCI) representation. This representation is natural because it is directly based on the collected data (companies' self-reported tags and investor-company investment events), and it is commonly used in the existing studies on online social networks [36; 46; 47]. This kind of tripartite networks only considers the connections that are already in the data, and the recommendation is made by applying physical diffusion processes such as probabilistic spreading [49] and heat transfer [45] (see details in Section 4.1) to the available network. However, we find that if our goal is to produce recommendation of investors for new startups, the natural TCI representation is suboptimal. The reason is that a new startup has not direct connections with investors, which implies that in the TCI representation, relatively long network paths are needed for a diffusion process to travel from a target startup to a prospective investor. Moreover, our empirical analysis indicates that investors tend to concentrate their investments toward startups with a small number of preferred tags. This property suggests that for our problem, investor-tag connections are potentially more informative than investor-company connections.

Motivated by these observations, we introduce virtual links between investors and tags, and construct two new tripartite network representations: the company-tag-investor (CTI) and the company-investor-tag (CIT) network representations. On each of the three tripartite network representations considered here (TCI, CTI, and CIT), we apply diffusion-based recommendation algorithms. We find that diffusion algorithms based on networks with virtual links (i.e., the company-tag-investor and company-investor-tag networks) achieve substantially better recommendation accuracy compared to those based on the natural tag-company-investor representation.

Our main focus on diffusion-based techniques is motivated by existing works [26; 44] that indicate that this class of techniques is well-suited to scenarios where the input data are binary (without ratings) and only limited information about the target items or users is available. At the same time, we do not narrow our focus to this class of algorithms, alternative techniques from existing studies, including neighbor-based collaborative filtering [33] and matrix factorization based on Bayesian personalized ranking [13] (see Section 4.2) are also included in the analysis. The proposed diffusion-based algorithms turn out to outperform these existing algorithms that are not based on a tripartite network representation.

The main contribution of this paper is twofold. First, it brings network-based recommendation techniques to the problem of finding relevant investors for newcomer startups. Second, to address the problem, it introduces virtual links between investors and tags to build the network representation. The possibility to introduce these links has not been exploited by previous studies on recommendation algorithms based on tripartite networks [36; 46; 47], yet the virtual links turn out to be vital to achieving a good recommendation performance. The new representation achieves indeed improved performance over recommendation techniques based on the straightforward TCI representation and existing collaborative filtering [33] and matrix factorization algorithms [13]. Our findings reveal a powerful method for startups to find their first investor.

The paper is structured as follows: In Section 2, we review related works. In Section 3, we describe the dataset, analyze the tag preference of investors, and propose the construction of three tripartite network representations. In Section 4, we introduce the recommendation algorithms employed in the tripartite networks, the baseline algorithms, and the evaluation metrics. In Section 5, we present our results and discuss them. Finally, Section 6 concludes the paper and points out several open research directions.

## 2 Related work

### Recommendation methods

Collaborative filtering (CF) is one of the most widely-used family of recommendation techniques. It can be further grouped into memory-based CF and model-based CF [39]. In online systems where users rate items, memory-based CF approaches use users' past rating data to compute the similarity between users or items and produce a prediction for the target user based on the similar users to her or similar items to those she already collected. Model-based CF methods leverage historical data to learn a predictive model. Well-known model-based CF techniques include Bayesian networks [29], clustering models [6], latent semantic models [19], among others. The most critical component of CF methods is the measurement of the similarity between pairs of users or items, which are known to be vulnerable against data sparsity and cold-start problem [2].

Another common class of techniques is content-based filtering, which utilizes the description of items and the profile of users' preference to find the items that best match the items previously selected by the user. The recommendation process includes representing the items' features, learning users' profile, and filtering. There are also hybrid approaches which combine collaborative with content-based methods or with different variants [4].

While most recommender systems act on data with ratings, positive-only data (e.g., click-through data, browsing history, investment history) without ratings are of interest to several physics-rooted recommendation methods. In this context, the input data are represented as a bipartite network (e.g., a user-item network [49]) or a tripartite network (e.g., a user-item-tag network [47]) based on the actual links in the dataset. The recommendation can be obtained by employing classical physics processes such as diffusion (like in the Probs algorithm [49]) and heat transfer (like in the Heats algorithm [45]) on the network. We refer to [44] for a review of network-based recommendation algorithms.

### Recommender systems in investment domains

Applying recommender systems to financial investment problems has received growing attention [50]. It is generally considered as a challenging task because of the strict expectations from the information-seeker [50]. Fields of application for recommender systems in finance-related domains include stock investment [14], real estate investment [15], crowdfunding projects [3], and portfolio management [30], among others. As for venture investment, there have been relatively few scientific publications on the topic of recommendation. Stone et al. [37] used collaborative filtering to recommend relevant investment opportunities to venture capital (VC) firms. They reported that this class of activities is characterized by extremely sparse data, and the number of invested companies for VC firms follows a power-law distribution, which points out the existence of very active VC firms. Zhao et al. [48] proposed 5 risk-aware startup selection methods and ranking algorithms to predict VC firms' new investments. Existing studies largely concentrated on helping VC firms to find investee companies, while there is a lack of research and effective methods to support new startups searching for investors. Bringing network-based recommendation techniques to the problem of recommending investors to startups is one of the main contributions of our paper.

### Cold-start problems

In cold-start problems, because of insufficient past information, it is hard to infer users' preferences or items' potentially relevant users. A simple approach to mitigate the cold-start problem is to recommend the most popular objects based on historical data. But this strategy can only provide a uniform recommendation to all users. More diverse outcomes can be obtained by gathering rapidly additional information on users' preferences. This can be achieved by actively eliciting the user to make more informative choices [31], by integrating information from other user activities [5], or by using hybrid techniques to combine recommendations obtained by different methods [24]. As an alternative to these techniques, one can leverage the additional information to construct a network and run a standard diffusion-based algorithm on it. Following this idea, Zhang et al. [46] proposed a diffusion-based recommendation algorithm which considers social tags as a bridge connecting users and objects. They indicated that tags can effectively build up relations between existing objects and new ones, thereby providing solid recommendations of new objects. Deng et al. [9] introduced the Social Mass Diffusion (SMD) method based on a mass diffusion process in the combined network of users' social network and user-item bipartite network. They showed that the SMD can generate more personalized recommendations for new users than the global ranking based on popularity.

Besides, scholars introduced a number of strategies based on matrix factorization algorithm. Gantner et al. [13] proposed a method by an extension of matrix factorization optimized for Bayesian Personalized Ranking. They leveraged the mapping functions to compute adequate latent feature representations for new entities from their attributes. Kula [22] estimated feature embeddings by factorizing the collaborative interaction matrix. In his approach, new users or items can be represented in terms of combinations of metadata features that have been estimated from the training set. Fernandez-Tobias et al. [12] analyzed several solutions to the new user problem in collaborative filtering based on users' personality information (using 5 factors to describe an individual's personality: openness, conscientiousness, extraversion, agreeableness and neuroticism, as assessed by self-descriptive sentences or adjectives), including personality-based matrix factorization, personality-based active learning, and personality-based cross-domain recommendation.

To summarize, the key element to address the cold-start problem is the acquired information about the users' preference obtained either by directly asking for auxiliary information or by actively collecting it when available in the studied platforms. But requiring the targets to provide detailed individual information is not practicable in most cases. Therefore, the majority of approaches can only mitigate the cold-start problem when a target user has at least a limited historical activity, whereas recommendations for new users without prior activity must draw support from implicit preferences or features. In this paper, we focus on the cold-start problem for startups without prior activity, and we leverage the startups' self-reported tags to infer investors' preferences.

## 3 Data and network construction

### Dataset description

We collected 45,943 investment events from _www.tijuzi.com_[1]. Each event in the data includes the information of one investor, one investee company, the company's tags, and the event time (with the temporal resolution of one day). We note that joint investments that involve several investors appear as multiple events. We removed from the data all the events where the investor information is missing, which leaves us with 34,469 investment events ranging from Dec. 1\({}^{st}\), 1999 to Apr. 28\({}^{th}\), 2017. There are 5,588 investors, 14,887 companies, and 1,080 tags involved in these events. Table 1 shows two examples.

On average, an investor invests in 6.2 companies - the blue squares in Figure 1 (a) represent the distribution of the number of companies per investor. On the other hand, on average, a company has 2.3 investors - the red dots in Figure 1 (a) represent the distribution of the number of investors per company. 52% of companies have only _one investor_, which is a manifestation of the sparse nature of investment data. Such a sparsity is reasonable since investment events are not as frequent as online activity events (such as watching movies or making new friends in online platforms) [48], and the final investment decision is usually time-consuming [8]. As for tags, each company reported 4.9 tags, on average - Figure 1 (b) illustrates the distribution of the number of tags per company.

Tuple 24:
Cleaned Title: agile software startup deal uncertainty covid pandemic
Cleaned Transcription: agile software startup deal uncertainty covid pandemic rafael da camara federal rural university pernambuco recife pernambuco department computer science diwin recife pe brazil marcelo marinho federal rural university pernambuco recife pernambuco department computer science diwin recife pe brazil suzana sampaio federal rural university pernambuco recife pernambuco department computer science diwin recife pe brazil saulo cadete diwin recife pe brazil abstract dissipation severe acute respiratory syndrome coronavirus sarscov already taken pandemic proportion affecting country couple week evolution disease economic impact highly uncertain brings challenge newly created software company software startup company create innovative software product service dynamic fastgrowing market agile software method aim enable startup responding uncertainty caused covid paper investigates impact covid real software startup context understand reacted uncertainty caused covid research methodology action research within diwin brazilian software startup applied study carried throughout six sprint quarantine practice employed mitigate threat simultaneously allowing team remain open opportunity challenge detailed paper share lesson learned could help agile software startup improve way work uncertain environment caused covid pandemic keywordsagile software development software startup uncertainty covid empirical software engineering introduction pandemic already reshaping way company work also software engineering generates change process method use collaboration tool etc effect likely seen coming year one immediate way covid impacted company social distancing company already adopted virtual team another typical day although others likely temporary impact project team productivity collaboration since agile method started applied software development software team manager demanded additional capability achieve better result business level example agile team look ability sense respond change coordinated way across company agility coexists uncertainty unavoidable team using agile method uncertainty need embraced embraced uncertainty manifested firstly probabilityto change direction team believe iterative nature process give possibility change direction needed based presented context empirical study startup allowed u illustrate research objective tangible way conducted study aim present action taken startup manage uncertainty emerged covid pandemic main research question underlying study software development startup utilizing agile approach uncertainty caused covids rather working remote office wellappointed home office people working extempore bedroom kitchen table sofa partner child sibling parent roommate pet distract paper focus distributed software development dsd working home unexpectedly unprecedented crisis remote way working dsd benefit working home apply aim paper present transformation agile colocated startup working home approach furthermore study also summarizes set lesson learned used startup paper organized follows section introduce background problem define research question section describes method used section present result discus implication limitation section present conclusion future direction background agile majority company according recent estimate adopting agile approach software development becoming agile often go along fundamental change facing lot uncertainty regardless industry company motivation dilemma always decision agile made easily actually becoming agile many company claim agile although often neglect agile two component consider technical cultural agility neglect cultural agility may lead dissatisfaction people involved due uncertainty software development activity uncertainty uncertainty risk unknown probability focus uncertainty rather risk suggested improve project management providing important different perspective including limited enhanced focus opportunity management following product development researcher rely uncertainty conceptualization encompasses impact anything matter defining lack certainty lead situation potential outcome causal force fully understood explicitly line marinho define uncertainty incomplete information bear potential positive negative consequence high impact project objective word uncertainty discrepancy information available information required yet available toward reaching goal marinho et al key element software development project identification potential uncertainty source ability respond change software lifecycle perspective classifies uncertainty source project technological market environmental sociohuman different approach important uncertainty inherently good bad whereas uncertainty affect decision cause project even entire company fail uncertainty also vital predecessor innovation uncertainty seen part startup process uncertainty uncomfortable match founder avoid integral part allows startup successful startup startup organization devised create new product service condition uncertainty seek rapid growth repeatable profitable scalable business model software startup main focus development innovative product service using software commercial value created although software startup share common characteristic type startup scarcity resource lack operational history often accompanied wave technological change often occur software industry new computing technology network ability accommodate frequent change essential startup context agile method considered suitable process model software startup allow adopt change enable development adapt business strategy frequent delivery iterative incremental approach used agile philosophy reduces waiting time idea conception production market however software startup always enormous pressure time market currently need address uncertainty quickly due new coronavirus novel covid january world health organization declared spread new type coronavirus sarscov public health emergency international interest virus first identified patient pneumonia city wuhan province hubei china december due rapid transmissibility gained prominence world scientific community software development community facing many uncertainty due work environment change caused pandemic according paul ralph et al home office ergonomics distraction caused people team member live absence fitness facility fear pandemic truly affect well productivity team member worldwide virus covid affecting everyone although company particularly affected virus small software development company startup found maturity deal uncertainty related change impacted thus given uncertainty arising covid agile startup study following research question agile software development startup approach uncertainty caused covids method several empirical evaluation approach identified including case study ethnography experiment survey action research among action research appears essential valid instrument evaluating impact uncertainty covid within agile software startup context action research empirical research methodology researcher trying figure realworld problem meanwhile studying experience solving problem action research process defined several learning cycle consisting predefined stage research undertakes three cycle action research conduct action research following protocol proposed baskerville et al action research main characteristic involvement practitioner subject coresearchers similarly action research team consisted two internal researcher two external researcher hereafter referred research team workshop meeting held academic theory professional practice discussed iteratively propose action address many uncertainty challenge come pandemic quickly support company research team focused weekly sprint application action research cycle every two sprint performed action research protocol httpsbitlywwvehttpsbitlywwve dataset available company context study conducted inside operation diwin diwin startup based brazil partner around world company headquarters located recife city northeast brazil startup built emerged experience group entrepreneur researcher tech expert year research development solution based artificial intelligence following maturity artificial intelligence technology market capacity demand absorb startup saw need provide digital transformation economic sector first step connect concept process automation robotic build platform capable adapting business process need company improving process artificial intelligence digitalizing step footnote wwwdiwincom project context project insurance onboarding platform automobile communicates legacy erp enterprise resource planning two webapplications work interface project cover process automobile insurance since quotation proposal creation effectuation policy emission process phase made webapplications endusers operation user communication webapplications erp made robotic process automation studied team formed one scrum master one product owner one technical leader six developer gave one id preserve identity shown table study present action impact team member employee company focus study given software development member diwin project team use combination agile principle practice event framework model scrum kanban development process result diagnosis problem description covid pandemic diwin used operation colocated office situated recife however covid propagation possibility disease high spread recife became evident therefore immediate change mindset necessity adapt process guideline even workplace became urgent suddenly situation changed overnight case covid started appear recife march th march th state government decreed suspension class private public school university ahead march th state government decreed suspension activity factory commercial service provision establishment considered nonessential however government decree research team started discus situation possible impact company project meantime discussion pandemic raised many uncertainty regarding project contract customer response pandemic team capacity work remotely home infrastructure needed provided supplier work possibility lockdown demanded team adapt agile practice colocated work home consequently manage uncertainty could arise biggest challenge maintain productivity team ii define tool needed manage remote work iii align expectation client iv continue delivering value cycle v maintain employee welfare vi provide necessary infrastructure employee vii coordinate development process due chaotic situation generated pandemic diwin keep quality software development process proposed first author technical leader studied project conduct action research present investigate evaluate practice tool could contribute overcome challenge help manage related uncertainty derived remote work research accepted scrum master fourth author two author invited lead diagnosis execution action research team member warned research agreed participate action research cycle taken march th may th
Original Title: How do Agile Software Startups deal with uncertainties by Covid-19
  pandemic?
Original Transcription: # How do Agile Software Startups deal with uncertainties by Covid-19 pandemic?

Rafael da Camara

1 Federal Rural University of Pernambuco, Recife, Pernambuco

Department of Computer Science

2Di2win, Recife, PE, Brazil

 Marcelo Marinho

1 Federal Rural University of Pernambuco, Recife, Pernambuco

Department of Computer Science

2Di2win, Recife, PE, Brazil

 Suzana Sampaio

1 Federal Rural University of Pernambuco, Recife, Pernambuco

Department of Computer Science

2Di2win, Recife, PE, Brazil

 and Saulo Cadete

2Di2win, Recife, PE, Brazil

###### Abstract

The dissipation of severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2) has already taken on pandemic proportions, affecting over 100 countries in a couple of weeks. The evolution of the disease and its economic impact is highly uncertain, which brings challenges for newly created software companies. Software startups are companies that create innovative software products and services in a dynamic and fast-growing market. Agile Software Methods aims to enable startups in responding to uncertainty caused by Covid-19. This paper investigates the impact of Covid-19 in a real software startup context to understand how they have reacted against uncertainties caused by Covid-19. As a research methodology, action research within Di2Win, a Brazilian software startup, has been applied. The study was carried out throughout six sprints, during the quarantine. Practices employed to mitigate threats while simultaneously allowing teams to remain open to opportunities and challenges are detailed. This paper shares lessons learned that could help agile software startups improve their way of work in an uncertain environment caused by the Covid-19 pandemic.

Keywords:Agile software development, Software startups, Uncertainties, Covid-19, Empirical software engineering

## 1 Introduction

The pandemic is already reshaping the way companies work, also in software engineering, and generates changes in processes, methods, use of collaboration tools, etc. Other effects are likely to be seen in the coming years.

One of the immediate ways through which COVID-19 has impacted most companies is the social distancing. For companies that had already adopted virtual teams, this is just another typical day. Although for others, it is likely to have a temporary impact on projects, team productivity and collaboration.

Since agile methods started to be applied to software development, software teams and managers have demanded additional capabilities to achieve better results at the business level [1]. For example, agile teams look for the ability to sense and respond to changes in a coordinated way across the company. Agility co-exists with uncertainty which is unavoidable in the teams using agile methods. Uncertainty needs to be embraced. Embraced uncertainty is manifested firstly as the probabilityto change directions. All the teams believe that the iterative nature of their process gives them more possibilities to change directions when needed [2].

Based on the presented context, an empirical study of a startup which allowed us to illustrate our research objectives in a very tangible way was conducted. In this study, we aim to present the actions taken in the startup to manage uncertainties that emerged from the Covid-19 pandemic. The main research question underlying our study is: How do software development startups utilizing agile approach uncertainties caused by Covid-19s?

Rather than working in a remote office or well-appointed home office, some people are working in extempore in bedrooms, at kitchen tables, and on sofas while partners, children, siblings, parents, roommates, and pets distract them [3]. This paper does not focus on Distributed Software Development (DSD) [4]. But "working from home", unexpectedly, during an unprecedented crisis (remote way of working). So, DSD benefits of working from home do not apply. The aim of this paper is to present a transformation of an agile co-located startup into a working from home approach. Furthermore, this study also summarizes a set of lessons learned that can be used by other startups.

This paper is organized as follows: in Section 2 we introduce the background of the problem, and define our research questions. Section 3 describes the method used. In Section 4 we present the results, and discuss their implications and limitations; Section 5 presents conclusions and future directions.

## 2 Background

### Agile

The majority of companies, over 90% according to a recent estimate [5] are adopting an agile approach for software development. Becoming agile often goes along with fundamental changes that are facing a lot of uncertainties [6]. Regardless the industry or the company's motivation the dilemma is always the same: while the decision of doing agile is made easily, actually becoming agile is not [7]. Many companies claim to be agile, although they often neglect that agile has two components to consider: technical and cultural agility [7]. The neglect of cultural agility may lead to the dissatisfaction of the people involved due to uncertainties in software development activities.

### Uncertainty

An _uncertainty_ is a risk with unknown probability. A focus on uncertainty rather than risk has been suggested to improve project management by "providing an important different perspective, including, but not limited to, an enhanced focus on opportunity management" [8].

Following product development researchers [9, 8, 6], we rely on the uncertainty conceptualization that encompasses the impact of "anything that matters", defining it as the lack of certainty that leads to a situation in which "potential outcomes and causal forces are not fully understood" [9]. Explicitly, in line with Marinho [6] we define uncertainty as incomplete information that bears the potential for positive or negative consequences of high impact on project objectives. In other words, uncertainty is the discrepancy between the information that is available and the information that is required (but not yet available) toward reaching a goal [6].

To Marinho et. al [10, 6], the key elements of any software development project are the identification of potential uncertainty sources and the ability to respond to changes during the software lifecycle. In this perspective, [6] classifies the uncertainty sources in a project as: technological, market, environmental and socio-human.

Different approaches are important because uncertainty is not inherently good or bad. Whereas uncertainty affects decisions that can cause projects and even entire companies to fail, uncertainty is also a vital predecessor of innovation [6]. Uncertainty can be seen in any part of the startup process. Uncertainty is not just an uncomfortable match that the founders cannot avoid; it is an integral part of what allows startups to be successful.

### Startups

Startups are organizations devised to create new products or services under conditions of uncertainty, which seek rapid growth and repeatable, profitable and scalable business models [11]. Software startups have as main focus the development of innovative products or services, using software, from which the commercial value is created. Although software startups share common characteristics with other types of startups, such as scarcity of resources and lack of operational history [12], they are often accompanied by the wave of technological changes that often occur in the software industry, such as new computing technologies and network [13].

As the ability to accommodate frequent changes is essential in the startup context, agile methods have been considered the most suitable process model for software startups, as they allow them to adopt changes and enable development to adapt to business strategies [13]. Frequent delivery with an iterative and incremental approach, used in agile philosophy, reduces waiting time, from idea conception to production and the market.

However, software startups are always under enormous pressure from time to market and currently need to address uncertainties quickly due to the new coronavirus.

### Novel Covid-19

On January 30, 2020, the World Health Organization (WHO) declared the spread of a new type of coronavirus, SARS-CoV-2 [14], as a public health emergency of international interest [15]. This virus was first identified in patients with pneumonia in the city of Wuhan, in the province of Hubei, China, in December 2019 [16] and, due to its rapid transmissibility, it gained prominence in the world scientific community [16].

The software development community is facing many uncertainties due to the work environment changes caused by the pandemic. According to Paul Ralph _et al.,_[17], the home office ergonomics, the distractions caused by people with whom the team members live, the absence of fitness facilities and the fear of pandemic can truly affect well being and productivity of the team members.

As a worldwide virus, Covid-19 is affecting everyone, although some companies are particularly affected by the virus. Small software development companies and Startups that do not have the founds or the maturity to deal with the uncertainties related to such change are the most impacted. Thus, given the uncertainties arising by Covid-19 in agile startups, this study has the following research question:

_How do agile software development Startups approach uncertainties caused by Covid-19s?_

## 3 Method

Several empirical evaluation approaches can be identified, including case studies, ethnographies, experiments, surveys, and action research [18]. Among these, action research appears to be an essential and valid instrument for evaluating the impact of uncertainties by Covid-19 within an Agile Software Startup context. Action research is an empirical research methodology through which researchers are trying to figure a real-world problem meanwhile studying the experience of solving the problem.

The action research process can be defined as several learning cycles consisting of predefined stages. This research undertakes three cycles of action research. We conduct action research following the protocol proposed by Baskerville et al. [18].

The action research's main characteristic is the involvement of the practitioners as both subjects and co-researchers. Similarly, our action research team consisted of two internal researchers and two external researchers (hereafter referred to as "research team"). Workshops and meetings were held at which academic theory and professional practice were discussed to iteratively propose actions to address the many uncertainties and challenges that come with the pandemic. To quickly support the company, the research team focused on weekly sprints with an application of an action research cycle every two sprints. We performed an action research protocol ([https://bit.ly/2W13WVe](https://bit.ly/2W13WVe)) and the dataset is available at [19].

### Company Context

Our study was conducted inside the operation of Di2Win 3. Di2win is a startup based in Brazil, but with partners around the world. The company headquarters is located in Recife, a city in the Northeast of Brazil. The startup was built in 2018 and it emerged from the experience of a group of entrepreneurs, researchers, and tech experts with more than 25 years of research and development of solutions based on artificial intelligence. Following the maturity of artificial intelligence technologies, and the market capacity to demand and absorb them, the startup saw the need to provide a digital transformation to all economic sectors. The first step was to connect concepts from process automation, and robotic to build a platform capable of adapting to business process needs of any company, improving the process with artificial intelligence, and digitalizing all its steps.

Footnote 3: www.di2win.com

### Project Context

The project is an insurance onboarding platform for automobiles that communicates with a legacy ERP (Enterprise Resource Planning) through two Web-applications that works as an interface. The project covers all the processes of automobile insurance, since the quotation, the proposal creation and effectuation, and policy emission. All the process phases are made over the web-applications by both the end-users and the operation users, and all the communication between the web-applications and the ERP is made over robotic process automation.

The studied team is formed by one scrum master, one product owner, one technical leader, and six developers. We gave each one an ID to preserve their identity as shown in Table 1. The study presents actions that impact all team members and the other employees of the company, but the focus of the study was given to the software development members.

All Di2win project teams use a combination of agile principles, practices, and events from frameworks and models such as Scrum [20] and Kanban [21] in their development process.

## 4 Results

### Diagnosis

#### 4.1.1 Problem Description

Before the Covid-19 pandemic, Di2win used to have most of its operation in a co-located office situated in Recife. However, with the Covid-19 propagation, the possibility of the disease high spread in Recife became evident. Therefore, an immediate change of mindset and the necessity to adapt processes, guidelines and even the workplace became urgent.

Suddenly, the situation changed overnight, the cases of Covid-19 started to appear in Recife on March 12th, 2020. On March 16th, 2020, the state government decreed the suspension of classes from private and public schools and Universities Further ahead, on March 20th, 2020, the state government decreed the suspension of the activities of factories, commercial, and service provision establishments considered non-essentials. However, before all these government decrees, the research team started to discuss the situation and possible impact on the company's projects. In the meantime, during the discussions, the pandemic raised many uncertainties regarding project contracts, customers' response to the pandemic, team's capacity to work remotely (from home), infrastructure that needed to be provided, and suppliers' work.

The possibility of a lockdown demanded the team to adapt the agile practices co-located to a work from home, and consequently manage the uncertainties that could arise from it. The biggest challenges were (i) to maintain the productivity of the teams, (ii) to define the tools needed to manage the remote work, (iii) to align expectations with the clients', (iv) to continue delivering value through cycles, (v) to maintain the employee welfare, (vi) to provide the necessary infrastructure for all employees, and (vii) to coordinate the development process.

Due to the chaotic situation generated by the pandemic and by the will of Di2win to keep the quality of its software development process, it was proposed by the first author (the technical leader from the studied project) to conduct an action research to present, investigate, and evaluate practices and tools that could contribute to overcome the challenges and to help manage the related uncertainties derived from remote work.

The research was accepted by the scrum master (the fourth author), and the two other authors were invited to lead in the diagnosis and execution of the action research. All team members were warned about the research and they agreed to participate. The action research cycles were taken between March 19Th and May 6Th, 2020.

Tuple 25:
Cleaned Title: impact social medium presence board member composition new venture success evidence vcbacked u startup
Cleaned Transcription: impact social medium presence board member composition new venture success evidence vcnocked u startup gloor p fronzetti colladon grippa f hadley b woerner accepted manuscript review process prior final layout copyediting please cite gloor p fronzetti colladon grippa f hadley b woerner impact social medium presence board member composition new venture success evidence vcbacked u startup technological forecasting social change httpsdoiorgjtechforehttpsdoiorgjtechfore work licensed creative common attributionnoncommercialnoderivatives international license view copy license visit httpcreativecommonsorglicensesbyncndhttpcreativecommonsorglicensesbyncnd send letter creative common po box mountain view ca usa impact social medium presence board member composition new venture success evidence vcbacked u startup gloor p fronzetti colladon grippa f hadley b woerner abstract purpose study examine impact board member composition board member social medium presence performance startup using multiple source compile unique dataset usbased technology startup find startup venture capitalist board whose board member active twitter attract additional funding year though generate additional sale contrast startup venture capitalist board whose board member twitter show increased ability translate asset sale consistent research result indicate startup potentially benefit working vcs opportunity access additional funding although presence necessarily translate sale growth operational efficiency use number control variable including board gender representation board member position interlocking directorate network keywords social medium startup venture capitalist business performance interlocking introduction venture capitalist played key role supporting launch growth new company especially hightech sector cavallo et al venture capital often considered essential growth new venture provides equity equitylinked investment facilitates financial intermediation offer managerial direction arena et al kortum lerner wonglimpiyarat venture capitalist considered one key driving force american entrepreneurial ecosystem diana ingram phillips according national venture capital association venture investor raised billion since continue deploy capital highgrowth startup stanfill et al several empirical study demonstrated correlation vc involvement startup success vcbacked firm seem experience faster growth faster timetomarket product higher productivity greater innovation higher efficiency patent likely successful exit bernstain et al chemmanur et al dutta folta spender et al however little systematic evidence corporate venture capital investment creates value investing firm term operational efficiency dushnitsky lenox paper extends work area social legitimacy signaling chaney marshall dowling pfeffer suggested stuart hoang hybels study endorsement stuart et al vcs provide legitimacy firm presence act signal public ipo research confirmed board member critical source advice providing strategic direction connection financial support fried et al garg eisenhardt relationship level venture capital involvement startup success systematically scrutinized still room providing empirical evidence relationship operational efficiency venture capital engagement previous study focused role vcs hold supporting new venture research required disentangle specific influence vc startup social medium presence presence board impact performance despite previous study exploring association vcs presence board positive negative financial outcome finding remain inconclusive presence venture capitalist board new venture influence success impact specific key performance indicator study explore impact board director vc presence promoting startup growth focus particular impact sale increase funding time asset turnover selection indicator based need account new venture ability demonstrate efficient use resource sound strategy high potential growth securing additional funding result provide additional empirical evidence specific board composition informal social network created member direct influence startup performance among thing find startup venture capitalist board whose board member twitter show increased ability translate asset sale paper organized follows first two section explore benefit challenge startup actively engage vcs board well impact vcs social medium presence performance new venture two section meant provide basis theoretical framework showing virtual physical presence actively engaged board member venture capitalist impact new venture success introducing supporting hypothesis focus describing sample startup founded whose funding data available crunchbase analysis followed discussion benefit challenge inviting venture capitalist participate activity new venture impact vcs board advocate positive influence vcs claim vcs serve three main role identify promote successful startup screening monitoring coaching lahr mina screening allows vcs choose high quality company invest vcs experienced selecting certain criterion predict success technical expertise founder commitment spender et al monitoring requires vcs track status portfolio company comparing investment market trend opportunity protect value investment adding credibility prestige company invest kaplan stromberg reuer devarakonda finally coaching vcs provide advice support portfolio company intent improving chance success end return investment may include connecting firm potential resource assisting recruitment providing experience advice mentoring hellmann hellmann puri example recent study alliance partner selection reuer devarakonda found effect vc information intermediation pronounced prospective collaborator earliest stage product development recent study empirically demonstrated interorganizational network social capital represent important measure economic performance growth startup pirolo presutti though still debated social capital configuration advantageous startup performance various stage life cycle borgatti cross hite empirical study found human capital working experience significant impact success young high tech firm demonstrated lasch colleague education level working experience small medium enterprise startup training launching business sector last employment automatically related success factor initial organizational setup venture longterm financing structure good predictor success sustainable growth study highlighted role patenting metric success new venture example helmers rogers studied high mediumtech startup uk found decision patent positively affect growth total asset kortum lerner examined impact venture capital technological innovation looking patenting pattern across industry threedecade period result suggest positive significant effect vc support industrial innovation similarly chen explored association venture capital support technology commercialization found moderate improvement effect performance marketing financial support vcs seem matter startup posse lower degree market scope higher degree technology breadth recent study empirically confirmed performance benefit wellmatched owner firm using extensive longitudinal dataset population u private firm seeking go public vc owner lungeanu zajac matching based vc partner professional expertise seems le dependent complementarity founder background related current lifecycle stage startup bengtsson hsu study shown venture capitalist deeply involved establishing policy monitoring managerial activity high tech firm extent influence moderated factor stage organizational life cycle size venture capitalist lead position venture capitalist perceived firm performance background entrepreneur relationship ceo board member garg eisenhardt gomezmejia et al social medium presence value venture capitalist add portfolio company go beyond providing consulting accounting financial operational resource associated brand vc firm provides great value early stage company definition startup brand launch connection made available vcs network one valuable contribution early stage venture teten et al gulati higgins found tie young biotechnology firm prominent venture capital firm valuable ipo success cold market tie prominent investment bank valuable ipo success hot market shown study taiwanese hightech new venture lin et al successful entrepreneur adjust entrepreneurial strategy according social capital resource available ecosystem organizational scholar suggested seedstage investor rely social relationship select venture fund decision based two mechanism information transfer social tie social obligation venkataraman shane cable examined effect venture finance decision direct indirect tie entrepreneur seedstage investor field study revealed entrepreneur reputation defined information individual past performance mediates effect social tie demonstrating investor leverage social tie gather private information study stressed importance human network formation business cluster myint et al highlighted importance miniclusters key individual investor academic serial entrepreneur success high technology cluster company cambridge uk particular found startup company thrive high relational social capital built upon tie individual worked together company past furthermore physically located close proximity help maximize structural relational social capital could argue social medium allows investor entrepreneur establish virtual connection extend ability physical proximity generate trust facilitate knowledge sharing myint et al sapienza demonstrated effective venture capitalist maintain frequent open communication minimizing conflict application social network approach study impact social capital new venture success new hochberg colleague found company supported betternetworked vcs significantly likely survive subsequent financing eventual exit study cambridge hightechnology cluster myint et al used family tree interlocking directorship approach demonstrate positive impact social capital new venture success interlocking directorate occurs individual affiliated one organization sits board director another organization sapinski carroll another recent study explored entrepreneur increase social capital digital age looked unique technical capability social network site impact entrepreneur bridging bonding social capital smith et al gloor colleague studied public member profile german business networking site xing explore benefit network position online business social network confer aspiring entrepreneur comparing individual network attribute virtual realworld network found positive effect virtual network size embeddedness startup success seems confirm online tie good realworld relationship underlie study looked impact social medium new venture role social medium capital market akula social medium represent important channel information investor evaluate startup quality social medium activity example jin colleague found startup social medium activity associated investment investor specifically access le information channel angel scholar area computermediated communication demonstrated social capital accumulated differently online versus offline study validated assumption online friendship network help entrepreneur initiate weak tie manage strong one ellison et al sigfusson chetty fewer study explored social capital growth online network help entrepreneur support venture specific impact social capital performance gloor et al many pointed importance human network physical proximity myint et al entrepreneur investor though empirical study needed understand proximity online social network affect startup growth batjargal westhead et al hypothesis development figure present research framework based assumption new venture likely benefit active engagement board member venture capitalist first hypothesis stem assumption advantage disadvantage involving venture capitalist board startup demonstrated stuart et al new venture endorsed prominent exchange partner likely perform better otherwise comparable venture lack prominent connection benefit prominent business relationship derives transfer status legitimacy presence vcs board might influence business operation different level provides managerial strategic support could help entrepreneur manage resource efficiently generate sale demonstrated previous study social legitimacy benefit leveraging interorganizational tie kuhn et al stuart et al presence vcs startup board help generate perception high quality measure quality difficult observe based signaling theory test first hypothesis using sale funding asset turnoveroperational efficiency proxy performance h higher number venture capitalist startup board positively related increased performance figure research framework besides deciding appropriate vc firm best match new venture entrepreneur often advised select right vc partner company based understanding industry operational experience startup area potential value bring managerial style organizational culture importantly venture capitalist make difference based ability willingness put entrepreneur contact right partner help get market build business startup rely connection made board member social medium likely access greater knowledge improve understanding industry finding relevant expertise board social tie impact operation decisionmaking process smith et al based social legitimacy signaling theory chaney marshall kibler et al kuhn et al expect board member presence social medium increase likelihood increased sale attracting additional funding demonstrated kibler et al social legitimacy linked regional legitimacy among entrepreneur signal connection local community therefore legitimacy vcs provide legitimacy new venture extended social legitimacy created board twitter quality new venture easily observed potential investor likely ass company based observable attribute perceived associated underlying quality stuart et al among observable attribute presence vcs social medium represents signal good quality would encourage investment additional support based research conducted weill colleague company savvy board outperformed others key metric including roa revenue growth market cap growth board member experience digital business seems new financial performance differentiator translates study ability manage social medium presence generate interest attract managerial financial resource key new venture succeed rationale provides support second hypothesis state board member savvy present social medium lead better performance operationalized higher sale funding better asset turnover h presence board member twitter positively related increased performance new venture data method chose twitter study online communication behavior venture capitalist sitting startup board twitter social medium platform extensively used startup investor broadly used business community et al li et al liu et al addition recent empirical study using twitter source data could improve study replicability example cha colleague cha et al analyzed large dataset twitter explored type degree influence within network suggesting topological measure indegree alone ie number follower user reveals little influence popularity user study applied network sentiment analysis predict stock market bollen et al zhang et al samplethe data used paper subset sample collected hadley et al study investigated informal network venture capitalist hadley collected dataset extracted sp capital iq database contained startup crunchbase funding data study gathered data subset composed startup onesource sale data founded restricted sample startup itsoftware domain headquarters united state chose focus software startup could get access large dataset considering new venture received largest percentage sector dollar invested new venture also helped u control industry effect sample included list board member startup specified whether individual venture capitalist since focus impact venture capitalist startup success limited study firm managing venture capital investment fund opposed private equity hedge fund dependent variable ass startup success differentiated total sale total amount funding startup received since founding collected data total amount funding using crunchbase wwwcrunchbasecom data startup sale onesource wwwonesourcecom calculated asset turnover ratio salestotal funding ass efficiency company deploying asset generating revenue higher asset turnover ratio efficient startup generating revenue asset base acknowledge startup funding sale asset turnover ratio absolute measure startup success yet combination reflect overall startup success meaningful way independent variable first independent variable included engagement venture capitalist board demonstrated positive impact firm performance eisenhardt schoonhoven klotz et al second independent variable presence board member twitter control variable included set variable might impact firm performance include gender representation size age startup board size independent sponsorbacked subindustry company belong startup centrality interlocking directorate network several scholar compared female representation boardroom time chen et al farrell hersch demonstrated female representation top management improves firm performance dezso ross post byron additional study suggest firm operating industry greater number female employee likely female representation board bear et al erhardt et al hillman et al also controlled startup size age studied decade connection survival firm performance lotti santarelli raz gloor example baum colleague discussed firm size affect firm performance study indicates positive influence establishing alliance survival configuring efficient network another variable might impact firm profitability board size empirical evidence found negative correlation board size profitability eisenhardt schoonhoven mak kusnadi recently stam et al found theimpact entrepreneur personal network performance mediated age small firm industry institutional context small firm operate specific network performance measure used since size board could also impact performance also included board size another control variable board large number member might experience low efficiency due increased coordination mechanism cost small size board could agile reap better opportunity faster slowmoving board time startup fewer board member might deprived important connection resource managerial support large board provide startup also controlled level support received startup based empirical evidence group firm firm backed others may higher growth draw technology organizational expertise firm zahra baum et al found independent venture corporate sponsored venture influenced technology strategy may affect development success given widely recognized benefit social network providing access critical resource financial legal service business partnership controlled network position startup based number board member share control impact realworld tie built formal network interlocking directorate based company node linked company due director sitting board company interlocking directorate represent good proxy realworld tie even indirect one benefit connected entrepreneur investor either strong weak tie widely recognized literature battilana casciaro specifically analyzed social position startup interlocking network mean standard centrality algorithm calculating measure betweenness degree centrality wasserman faust inparticular degree centrality count number direct connection node social network startup share board member higher score metric betweenness centrality hand measure many time social actor inbetween shortest network path interconnect node startup higher betweenness centrality exhibit connection span across different social group often act mediator brokerage power easier access business resource allen et al finally controlled industry group within information technology sector kile phillips differentiating among following category semiconductor internet software service data processing outsourced service home entertainment software application software electronic equipment instrument communication equipment consulting service electronic component semiconductor equipment technology hardware storage peripheral figure illustrates variable used study explain connection number board member performance well member social medium activity performance result table present descriptive statistic variable worth noting average percentage female board member rather low maximum number board member average average degree interlocking startup independent others sponsorbacked startup least one vc among board member least one board member twitter startup size ranged employee startup age anywhere le year year figure variable hypothesesin table table present multiple regression model used ass impact independent variable sale funding dependent variable logarithmically transformed
Original Title: The impact of social media presence and board member composition on new
  venture success: Evidences from VC-backed U.S. startups
Original Transcription: The impact of social media presence and board member composition on new venture success: Evidences from VCNocked U.S. startups

Gloor, P. A., Fronzetti Colladon, A., Grippa, F., Hadley, B. M., & Woerner, S.

This is the accepted manuscript after the review process, but prior to final layout and copyediting. **Please cite as:**

Gloor, P. A., Fronzetti Colladon, A., Grippa, F., Hadley, B. M., & Woerner, S. (2020). The impact of social media presence and board member composition on new venture success: Evidences from VC-backed U.S. startups. Technological Forecasting & Social Change, 157, 120098.

[https://doi.org/10.1016/j.techfore.2020.120098](https://doi.org/10.1016/j.techfore.2020.120098)

This work is licensed under the Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License. To view a copy of this license, visit [http://creativecommons.org/licenses/by-nc-nd/4.0/](http://creativecommons.org/licenses/by-nc-nd/4.0/) or send a letter to Creative Commons, PO Box 1866, Mountain View, CA 94042, USA.

**The impact of social media presence and board member composition on new venture success: Evidences from VC-backed U.S. startups**

Gloor, P., Fronzetti Colladon, A., Grippa, F., Hadley, B. M., & Woerner, S.

**Abstract**

The purpose of this study is to examine the impact of board member composition and board members' social media presence on the performance of startups. Using multiple sources, we compile a unique dataset of about 500 US-based technology startups. We find that startups with more venture capitalists on the board and whose board members are active on Twitter attract additional funding over the years, though they do not generate additional sales. By contrast, startups which have no venture capitalists on the board and whose board members are not on Twitter show an increased ability to translate assets into sales. Consistent with other research, our results indicate that startups potentially benefit from working with VCs because of the opportunity to access additional funding, although their presence does not necessarily translate into sales growth and operational efficiency. We use a number of control variables, including board gender representation and board members' position in the interlocking directorates' network.

**Keywords:** social media; startup; venture capitalist; business performance; interlocking.

Introduction

Venture capitalists have played a key role in supporting the launch and growth of new companies, especially in the high-tech sector (Cavallo et al., 2019). Venture capital is often considered essential to the growth of new ventures as it provides equity (or equity-linked) investments, facilitates further financial intermediation, and offers managerial direction (Arena et al., 2018; Kortum and Lerner, 2000; Wonglimpiyarat, 2016). Venture capitalists are considered one of the key driving forces in the American entrepreneurial ecosystem (Diana and Ingram, 2014; Phillips, 2018). According to the National Venture Capital Association, venture investors have raised more than $130 billion since 2014 and will continue to deploy capital to high-growth startups (Stanfill et al., 2017).

Several empirical studies have demonstrated the correlation between VC involvement and startup success: VC-backed firms seem to experience faster growth, faster time-to-market of their products, higher productivity, greater innovation, higher efficiency, have more patents, and are more likely to have a successful exit (Bernstain et al., 2016; Chemmanur et al., 2011; Dutta and Folta, 2016; Spender et al., 2017). However, there is little systematic evidence that corporate venture capital investment creates value to investing firms in terms of operational efficiency (Dushnitsky and Lenox, 2006).

This paper extends the work in the area of social legitimacy and signaling (Chaney and Marshall, 2013; Dowling and Pfeffer, 1975). As suggested by Stuart, Hoang and Hybels in their study on endorsements (Stuart et al., 1999), VCs provide legitimacy to the firm as their presence acts as a signal to the public during IPOs. While research has confirmed that board members can be a critical source of advice, providing strategic direction, connections and financial support (Fried et al., 1998; Garg and Eisenhardt, 2017), the relationship between the level of venture capital involvement and startup success has not been systematically scrutinized and there is still room for providing more empirical evidence for the relationship between operational efficiency and venture capital engagement.

While previous studies have focused on the role that VCs hold in supporting new ventures, more research is required to disentangle the specific influence of the VC themselves on the startup and how their social media presence and presence on the board impacts performance. Despite previous studies exploring the association between VCs' presence on the board and positive or negative financial outcomes, findings remain inconclusive. How does the presence of Venture Capitalists on the board of new ventures influence their success? Does it have an impact on specific key performance indicators? In this study, we explore the impact that board of directors and VC presence have in promoting startup growth as we focus in particular on the impact on sales, increase of funding over time and asset turnover. The selection of these indicators is based on the need to account for the new venture's ability to demonstrate efficient use of resources, a sound strategy and high potential for growth by securing additional funding.

Our results provide additional empirical evidence that the specific board composition and the informal social networks created by the members have a direct influence on startups' performance. Among other things, we find that startups which have no venture capitalists on the board and whose board members are not on Twitter show an increased ability to translate assets into sales.

This paper is organized as follows. The first two sections explore the benefits and challenges for startups to actively engage VCs on their board, as well as the impact of VCs' social media presence on the performance of new ventures. These two sections are meant to provide the basis for our theoretical framework, showing that both virtual and physical presence of actively engaged board members and venture capitalists have an impact on new venture success. After introducing and supporting our hypotheses, we focus on describing our sample of 499 startups founded between 2011 and 2016, whose funding data was available on Crunchbase. This analysis is followed by a discussion about the benefits and challenges of inviting venture capitalists to participate in the activities of new ventures.

## 2 Impact of VCs on the Board

Advocates for the positive influence of VCs claim that VCs serve three main roles to identify and promote successful startups: screening, monitoring and coaching (Lahr and Mina, 2016). Screening allows VCs to choose which high quality companies to invest in. VCs are experienced at selecting for certain criteria that predict success, such as technical expertise and founder commitment (Spender et al., 2017). Monitoring requires VCs to track the status of their portfolio companies, comparing investments with market trends and opportunities. They protect the value of their investments by adding credibility and prestige to those companies they invest in (Kaplan and Stromberg, 2003; Reuer and Devarakonda, 2017). Finally, through coaching, VCs provide advice and support to their portfolio companies with the intent of improving their chances of success and, at the end, the return on their investment. This may include connecting the firm with potential resources, assisting with recruitment, and providing experience, advice, and mentoring (Hellmann, 2000; Hellmann and Puri, 2002). For example, a recent study on alliance partner selection (Reuer and Devarakonda, 2017) found that the effects of VC information intermediation are more pronounced when prospective collaborators are at the earliest stages of product development.

Recent studies have empirically demonstrated that inter-organizational networks and social capital represent important measures of the economic performance and growth of a start-up (Pirolo and Presutti, 2010), though it is still debated which social capital configuration is most advantageous for the start-up's performance during various stages of its life cycle (Borgatti and Cross, 2003; Hite, 2005). Other empirical studies found that human capital and working experience have no significant impact on the success of young high tech firms. As demonstrated by Lasch and colleagues (2007), education level, working experience in small and medium enterprises, start-up training, or launching a business in the same sector as the last employment are not automatically related to success. Factors such as the initial organizational setup of the venture and a long-term financing structure are good predictors of success and sustainable growth. Other studies have highlighted the role of patenting as metric for success of a new venture. For example, Helmers and Rogers (2011) studied high- and medium-tech start-ups in UK and found that the decision to patent positively affects growth in total assets for the between 2001 and 2005.

Kortum and Lerner (2000) examined the impact of venture capital on technological innovation by looking at the patenting patterns across industries over a three-decade period. Their results suggest a positive and significant effect between VC support and industrial innovation. Similarly, Chen (2009) explored the association between venture capital support and technology commercialization and found a moderate improvement effect on the performance: marketing and financial support from VCs seem to matter only when startups possess a lower degree of market scope and a higher degree of technology breadth.

A recent study empirically confirmed the performance benefits of well-matched owners and firms using an extensive longitudinal dataset of the population of U.S. private firms seeking to go public from 1997 to 2004, and their VC owners (Lungeanu and Zajac, 2016). Matching based on VC partners' professional expertise seems to be less dependent on their complementarity with the founder's background and more related to the current lifecycle stage of the startup (Bengtsson and Hsu, 2010).

Other studies have shown that venture capitalists are deeply involved in establishing policies and monitoring managerial activities in high tech firms. The extent of influence is moderated by such factors as stage in the organizational life cycle, size of the venture capitalist, lead position of the venture capitalist, perceived firm performance, background of entrepreneur and relationship between CEO and board members (Garg and Eisenhardt, 2017; Gomez-Mejia et al., 1990).

## 3 Social Media Presence

The value that venture capitalists add to their portfolio companies goes beyond providing consulting, accounting, financial or operational resources. Being associated to the brand of the VC firm provides great value to early stage companies. By definition, startups have no brand at launch, and the connections made available through the VCs' networks is one of their most valuable contributions for an early stage venture (Teten et al., 2013). Gulati and Higgins (2003) found that ties between young biotechnology firms and prominent venture capital firms were valuable to IPO success during cold markets, while ties to prominent investment banks were valuable to IPO success during hot markets. As shown by a study on Taiwanese high-tech new ventures (Lin et al., 2006), successful entrepreneurs are those who can adjust their entrepreneurial strategies according to their social capital and the resources available in their ecosystem.

Organizational scholars have suggested that seed-stage investors rely on social relationships to select which ventures to fund, where their decision is based on two mechanisms: information transfer through social ties and social obligation (Venkataraman, 1997). Shane and Cable (2002) examined the effects on venture finance decisions of direct and indirect ties between entrepreneurs and seed-stage investors. Their field study revealed that entrepreneurs' reputation - defined as information about an individual's past performance - mediates the effects of social ties, demonstrating that investors leverage their social ties to gather private information.

Other studies have stressed the importance of human networks in the formation of business clusters. Myint et al (2005) have highlighted the importance of mini-clusters of key individuals (investors, academics and serial entrepreneurs) to the success of the high technology cluster companies in Cambridge, UK. In particular, they found that startup companies thrive when there is high relational social capital built upon ties of individuals who have worked together in other companies in the past. Furthermore, being physically located in close proximity helps maximize both structural and relational social capital. Here we could argue that social media allows investors and entrepreneurs to establish virtual connections that extend the ability of physical proximity to generate trust and facilitate knowledge sharing (Myint et al., 2005).

Sapienza (1992) demonstrated that the most effective venture capitalists are those who maintain frequent, open communications while minimizing conflicts. The application of a social network approach to study the impact of social capital on new venture success is not new. Hochberg and colleagues (2007) found that when companies are supported by better-networked VCs, they are significantly more likely to survive to subsequent financing and eventual exit.

In a study of the Cambridge high-technology cluster, Myint et al. (2005) used a family tree and interlocking directorships approach to demonstrate the positive impact of social capital on new venture success. An interlocking directorate occurs when an individual affiliated with one organization sits on the board of directors of another organization (Sapinski and Carroll, 2017).

Another recent study explored how entrepreneurs increase social capital in the digital age and looked at how unique technical capabilities of social network sites impact entrepreneurs' bridging and bonding social capital (Smith et al., 2017). Gloor and colleagues (2018) studied the public member profiles of the German business networking site XING to explore the benefits that network position in online business social networks confer to an aspiring entrepreneur. After comparing individual and network attributes in virtual and real-world networks, they found no positive effect of virtual network size and embeddedness on startup success, which seems to confirm that online ties are only as good as the real-world relationships that underlie them.

Only few studies have looked at the impact of social media on new ventures or the role of social media in the capital markets (Akula, 2015). Social media represent an important channel of information for investors to evaluate startup quality through their social media activities. For example, Jin and colleagues (2017) found that startup social media activity is associated with more investment from investors, specifically from those who have access to less information channels such as angels.

Scholars in the area of computer-mediated communications have demonstrated that social capital is accumulated differently online versus offline. While some studies validated the assumption that online friendship networks help entrepreneurs initiate weak ties or manage strong ones (Ellison et al., 2014; Sigfusson and Chetty, 2013), fewer studies have explored how social capital growth in the online networks can help entrepreneurs support their ventures, and what specific impact social capital has on their performance (Gloor et al., 2018). Many have pointed out the importance of human networks and physical proximity (Myint et al., 2005) of entrepreneurs and investors, though more empirical studies are needed to understand how proximity in online social networks affect start-up growth (Batjargal, 2007; Westhead et al., 2003).

## 4 Hypotheses Development

Figure 1 presents the research framework based on the assumption that new ventures are likely to benefit from an active engagement of board members and venture capitalists.

Our first hypothesis stems from the assumption that there are more advantages than disadvantages in involving venture capitalists on the board of a startup. As demonstrated by (Stuart et al., 1999) new ventures that are "endorsed" by prominent exchange partners are likely to perform better than otherwise comparable ventures that lack prominent connections. The benefit of having prominent business relationships derives from a transfer of status and legitimacy. The presence of VCs on the board might influence business operations at different levels, as it provides managerial and strategic support that could help entrepreneurs manage resources more efficiently and generate more sales. As demonstrated by previous studies on social legitimacy and the benefits of leveraging inter-organizational ties (Kuhn et al., 2016; Stuart et al., 1999), the presence of VCs on a startup's board helps generate a perception of high quality when other measures of quality are difficult to observe. Based on the signaling theory, we test the first hypothesis by using sales, funding and asset turnover/operational efficiency as proxy for performance.

_H1: A higher number of Venture Capitalists on startups' boards will be positively related to increased performance._

Figure 1: Research Framework

Besides deciding on the most appropriate VC firm that best matches their new venture, entrepreneurs are often advised to select the right VC partner from that company, based on their understanding of the industry, their operational experience in the startup area, the potential value they can bring and their managerial style and organizational culture. Most importantly, venture capitalists will make a difference based on their ability and willingness to put entrepreneurs in contact with the right partners to help them get into the markets as they build their business.

Startups who can rely on the connections made by their board members on social media are likely to access greater knowledge, improve their understanding of the industry, finding relevant expertise through their board's social ties that can impact their operations and decision-making processes (Smith et al., 2017). Based on the social legitimacy and signaling theory (Chaney and Marshall, 2013; Kibler et al., 2015; Kuhn et al., 2016), we expect that board members' presence on social media will increase the likelihood of increased sales, attracting additional funding. As demonstrated by Kibler et al. (2015) social legitimacy is linked to regional legitimacy among entrepreneurs as this signals a connection to the local community and therefore legitimacy. VCs provide legitimacy to the new ventures, which is further extended by the social legitimacy created when the board is on Twitter. Because the quality of new ventures cannot be easily observed, potential investors are likely to assess the company based on observable attributes that are perceived as associated with its underlying quality (Stuart et al., 1999). Among those "observable attributes" the presence of VCs on social media represents a signal of good quality that would encourage further investment and additional support.

Based on the research conducted by Weill and colleagues (2019), companies with IT savvy boards outperformed others on key metrics including ROA, revenue growth, and market cap growth. Having board members with experience in digital business seems to be the new financial performance differentiator. This translates in our study into the ability to manage social media presence to generate interest and attract managerial and financial resources that are key for new ventures to succeed. This rationale provides support for our second hypothesis in which we state that board members which are more IT savvy and more present on social media, will lead to better performance, operationalized as higher sales, more funding and better asset turnover.

_H2: Presence of board members on Twitter will be positively related to increased performance of the new ventures._

## 5 Data and Methods

We chose Twitter to study the online communication behavior of venture capitalists sitting on the startup boards, as Twitter is the social media platform most extensively used by startups and investors, and broadly used by the business community (He et al., 2016; Li et al., 2018; Liu et al., 2015). In addition, there are other recent empirical studies that are using Twitter as source of data, which could improve our study's replicability. For example, Cha and colleagues (Cha et al., 2010) analyzed a large dataset on Twitter and explored types and degrees of influence within the network, suggesting that topological measures such as indegree alone (i.e. the number of followers of a user) reveals very little about the influence and popularity of users. Other studies applied both network and sentiment analyses to predict the stock market (Bollen et al., 2011; Zhang et al., 2011).

**5.1. Sample**The data used for this paper is a sub-set of the sample collected by Hadley et al. (2018), in a study that investigated informal networks of venture capitalists. Hadley collected a dataset extracted from the S&P Capital IQ database, which contained 3199 startups, out of which 1514 had Crunchbase funding data. In our study, we gathered data on a sub-set composed of 499 startups that had OneSource sales data and that were founded between 2011 and 2016. We restricted the sample to startups in the IT/Software domain with headquarters in the United States. We chose to focus on software startups so that we could get access to a large dataset, considering that in 2015 IT new ventures received the largest percentage by sector of all dollars invested in new ventures. This also helped us control for industry effects. The sample included a list of the board members for each startup and specified whether each individual was a venture capitalist or not. Since our focus is on the impact of venture capitalists on startup success, we limited the study to only those firms managing a venture capital investment fund, as opposed to private equity or hedge funds.

### Dependent Variables

To assess the startup success we differentiated between the total sales and the total amount of funding that the startup had received since its founding. We collected data on the total amount of funding using Crunchbase (www.crunchbase.com) and data about the startup's sales from OneSource (www.onesource.com). We then calculated the Asset Turnover Ratio (Sales/Total Funding) to assess the efficiency with which a company is deploying its assets in generating revenue. The higher the asset turnover ratio the more efficient the startup is at generating revenue from its asset base. We acknowledge that startup funding, sales, and asset turnover ratio are not absolute measures of startup success, yet in combination they can reflect overall startup success in a meaningful way.

### Independent Variables

The first independent variable we included was the engagement of venture capitalists on the board, which has been demonstrated to have a positive impact on firm performance (Eisenhardt and Schoonhoven, 1990; Klotz et al., 2014). The second independent variable is the presence of board members on Twitter.

### Control Variables

We included a set of variables that might have an impact on firm performance, which include: gender representation, size and age of the startup, board size, being independent or sponsor-backed, the sub-industry companies belong to, and startups' centrality in the interlocking directorate network.

Several scholars have compared female representation in boardrooms over time (Chen et al., 2016; Farrell and Hersch, 2005) and demonstrated that female representation in top management improves firm performance (Dezso and Ross, 2012; Post and Byron, 2015). Additional studies suggest that firms operating in industries with greater numbers of female employees are more likely to have female representation on their boards (Bear et al., 2010; Erhardt et al., 2003; Hillman et al., 2007).

We also controlled for startup size and age which have been studied for decades in connection to survival and firm performance (Lotti and Santarelli, 2004; Raz and Gloor, 2007). For example, Baum and colleagues (2000) discussed how and why firm size affects firm performance in a study that indicates the positive influence of establishing alliances on survival, and configuring them into an efficient network.

Another variable that might impact firm profitability is board size. Empirical evidences found negative correlations between board size and profitability (Eisenhardt and Schoonhoven, 1990; Mak and Kusnadi, 2005). Recently, Stam et al. (2014) found that theimpact of entrepreneurs' personal networks on performance was mediated by the age of small firms, the industry and institutional contexts in which the small firms operate, and by the specific network or performance measures used. Since the size of the board could also impact performance, we also included board size as another control variable. Boards with a large number of members might experience low efficiency due to increased coordination mechanism costs, where small size boards could be more agile and reap better opportunities faster than slow-moving boards. At the same time, startups with fewer board members might be deprived of important connections, resources and managerial support that large boards provide to startups.

We also controlled for the level of support received by startups, based on empirical evidences that group firms or firms that are backed by others may have higher growth as they can draw on technology and organizational expertise from other firms (Zahra, 1996). Baum et al. (2000) found that independent ventures or corporate sponsored ventures are influenced by technology strategies that may affect their development and success.

Given the widely recognized benefits of social networks in providing access to critical resources such as financial or legal services, or to business partnerships, we controlled for the network position of startups based on the number of board members they share. To control for the impact of real-world ties, we built a formal network of interlocking directorates based on companies (the nodes) who were linked to other companies due to the same director sitting on the boards of both companies. Interlocking directorates represent a good proxy for real-world ties, even if indirect ones. The benefits of being connected with other entrepreneurs and investors, either through strong or weak ties, has been widely recognized in literature (Battilana and Casciaro, 2012). Specifically, we analyzed the social position of startups in the interlocking network by means of standard centrality algorithms, calculating the measures of betweenness and degree centrality (Wasserman and Faust, 1994). Inparticular, degree centrality counts the number of direct connections a node has in the social network, with startups that share more board members having higher scores of this metric. Betweenness centrality, on the other hand, measures how many times a social actor is in-between the shortest network paths that interconnect the other nodes. Startups with higher betweenness centrality exhibit connections that span across different social groups - they often act as mediators, have more brokerage power and easier access to business resources (Allen et al., 2016).

Finally, we controlled for the industry group within the Information Technology sector (Kile and Phillips, 2009), by differentiating among the following categories: Semiconductors, Internet Software and Services, Data Processing and Outsourced Services, Home Entertainment Software, Application Software, Electronic Equipment and Instruments, Communications Equipment, IT Consulting and Other Services, Electronic Components, Semiconductor Equipment, Technology Hardware, Storage and Peripherals.

Figure 2 illustrates the variables used in the study to explain the connections between number of board members and performance as well as members' social media activity and performance.

## 6 Results

Table 1 presents the descriptive statistics for our variables. It is worth noting that the average percentage of female board members is rather low (7.4%). The maximum number of board members is 10 (3.45 on average), and the average degree of interlocking is 4.86. Only 12% of startups was independent, all the others being sponsor-backed. 57.1% of the startups had at least one VC among their board members and 57.9% had at least one board member on Twitter. Startups' size ranged from 1 to 602 employees, while startups' age was anywhere between less than a year and 5 years.

Figure 2: Variables and HypothesesIn Table 2 and Table 3, we present the multiple regression models used to assess the impact of our independent variables on sales and funding (dependent variables were logarithmically transformed).

Tuple 26:
Cleaned Title: survey software engineering practice brazilian startup
Cleaned Transcription: survey software engineering practice brazilian startup renata souza institute computing federal university bahia ufba salvador brazil renatamss ivanmachadoufbabr federal institute bahia ifba santo antonio de jesus brazil renatasouzaifbaedubr orges cico norwegian university science technology ntnu trondheim norway orgescicontnuno ivan machado institute computing federal university bahia ufba salvador brazil renatamss ivanmachadoufbabr abstract today significant technological advancement allows earlystage software startup build launch innovative product quickly market however many die early year path due market condition ignorance customer need lack resource focus misuse wellestablished practice study motivation analyze software engineering practice startup practitioner perspective objective identify practice tool startup employ daily routine carried expert survey study software developer involved software startup different domain result show startup initial validation phase select practice tool adhoc basis based development team prior knowledge move growth phase recognize could adopted better practice beforehand support product scaling mature team result also indicated support tool selected based integration tool ability automate operational activity keywordssoftware startup empirical software engineering survey study introduction impressive number entrepreneur create novel startup around world every day later might become famous profitable facebook instagram spotify linkedin dropbox according sutton startup share many feature small mediumsized young company example usually immature limited resource undergo multiple influence use dynamic technology hunt market startup defined organization established search repeatable scalable business model also startup organization dedicated creating something new condition extreme uncertainty limited financial human resource face various challenge barrier die earlier year several critical challenge every startup phase affect strength company stability crucial prepare come obstacle become unbeatable learning others startup experience help find way succeed fail faster therefore necessary leverage startup practice understand reason choice consequence paper aim shed light developer perception software engineering practice tool employed software startup brazilian cohort carried expert survey study software developer involved software startup different domain sent online questionnaire professional working startup via email social network facebook twitter linkedin result show software startup guided customer participates creating initial prototype product deployment adopted practice tool speed development activity remainder paper structured follows section cover researchrelated background section introduces survey study methodology result discussion located section respectively section present implication research practice threat study validity discussed section finally section outline overall conclusion direction future work background startup startup company start early stage asset low investment potential achieve high scalability many company took advantage popularization technology personal use google netflix spotify start almost scratch could reach wide range customer ignored major competitor offering solution almost always service based technology internet startup concept definition although simple encompasses many variable primary way recognize startup refers business model characterized innovative idea generates value turn work money additionally could considered policy aimed developing competent selfmanaged team could quickly react scenario change promotion creativity collaboration focus agility continuous training reward solving complex problem action must always link longterm vision startup lifecycle blank defined startup lifecycle four stage customer perspective defining observing problem evaluating problem defining solution evaluating solution crowne identified startup lifecycle perspective product development three stage follows startup phase period product conception first scale stabilization begin first customer receives product growth startup delivers product new customer without creating overhead development team maturity company evolves mature organization similarly wang defines lifecycle software startup taking account product stage concept underdevelopment functional prototype functional product limited user functional product high growth potential mature product software startup software startup share characteristic type startup lack resource operating history hightechnology challenge cuttingedge tool innovationdriven development carmel first one refer term software package startup shorten term software startup sutton argues software startup challenged limited resource immaturity multiple influence hightechnology turbulent market hilmola state software startup productoriented develop cuttingedge software product coleman characterize software startup productdriven small development team often developerled develops software various process without methodology giardino unterkalmsteiner use term software startup refer organization focused creation hightech innovative product little operating history aiming grow business highlyscalable market aggressively large software company relied year traditional software development nowadays realize need innovate maintain position highly competitive market also look gain significant advantage adapt market technology focusing cost efficiency lead time reduction quality improvement find startup new way keep leading position fastmoving innovative market software startup become one critical driver economy innovation even though mostly inexperienced coleman oconnor investigated software product startup establish software development process study employed grounded theory approach aim characterized experience small software organization developing process support software development activity significant factor might influence building process background software development manager background founder management styleprocess tailoring market requirement hence software startup depend mainly person experience acting software development manager hold expertise knowhow meet company goal coleman oconnor also claimed startup productdriven developerled context agile method may lot offer related work giardino et al wang et al performed largescale survey response indepth multiplecase study investigate critical challenge software startup giardino et al observed challenge earlystage startup wang et al observed challenge faced software startup across lifecycle stage pantiuchina et al also conducted extensive survey software startup examined use five agile lean startup practice work observed software engineering practice adopted startup divergent lifecycle stage startup life cycle classification based response provided developer classification made characterization made concerning information team size number customer product maturity shown following section research methodology study motivation analyze software engineering practice startup software practitioner perspective chose survey research instrument reach significant number opinion goal designing study keep brief possible still gathering relevant information survey received response ask identification respondent company decided preserve information reason confidentiality attract participant research participant brazilian territory applied methodology recommended linaker et al research survey principle defined kitchenham pfleeger section encompasses planning detail execution procedure reporting desired achieved result first identified research object step target population sampling step next constructed survey instrument step figure overview research methodology tested step distributed participant step last action analyze collected data step report result figure show research step study utilized webbased questionnaire reach practitioner brazilian startup ecosystem due brazil geographical dimension identifying research object objective identify software engineering practice tool startup employ daily routine also aimed investigate whether difference practice tool depend startup lifecycle formulated following research question rq software startup use software engineering practice across different lifecycle stage aim leverage practice software startup adopt different stage lifecycle stage differs rq tool software startup use support software engineering practice across different lifecycle stage aim observe whether change tool adoption different stage lifecycle stage differs startup need either follow adapt existing software engineering practice otherwise would risk losing market capitalization effect study needed investigate practice tool support establish common understanding software startup make choice identifying target population sampling startupbase official database brazilian startup ecosystem supported brazilian startup association target audience software developer software startup population selected brazilian software startup chose software developer representative group considering respondent work startup different lifecycle stage observe perspective survey included question reveal participant job software development experience information organization worked size ecosystem location project domain characterize survey participant defined following criterion include participant survey study respondent must work brazilian software startup respondent must work software developer survey instrument questionnaire comprises closed question small number open question obtain information specified twelve topic divided two group first gather participation consent respondent characterization startup characterization product characterization second group covered practice considering software engineering discipline software requirement software architecture software design software construction software testing software maintenance management process next specify goal defined category research participation consent free prior informed consent respondent characterization gather information respondent profile startup characterization gather information startup established number customer revenue number employee business domain product characterization characterize product type public lifecycle revenue need pivot time team work software requirement reveal employed requirement engineering practice software architecture identify decision regarding system architecture software design identify decision regarding user interface design software construction leverage main programming language development platform startup use software testing leverage startup software testing practice software maintenance leverage employed maintenance technique project management leverage project management practice software process leverage software process practice used survey monkey prepare disseminate questionnaire supplementary material available footnote httpsptsurveymonkeycomrfkrphttpsptsurveymonkeycomrfkrp pilot testing asked professional researcher experience software engineering survey design review survey goal remove misunderstanding hence improve instrument change made included adding answer choice several question exchanging word improve understanding changing question applied questionnaire september questionnaire used end test contained following question questionnaire contain anything expected reach goal questionnaire contain undesirable unnecessary information context purpose research able understand question properly error inconsistency questionnaire data collection september sent survey invitation email facebook twitter linkedin invitation text contains main instruction questionnaire link also sent reminder closed survey november made brief introduction necessary information purpose study justification choice importance respondent participation participant also informed privacy policy study clear detailed manner data analysis assembling data collection online survey took following step data validation phase analyzed result verify answer met criterion consistency integrity participant characterization data assembling synthesis including data provided startup work well software product service company deliver data partitioning phase researcher analyze response group subgroup data partitioning count data obtained demographic question number customer number employee startup diversification software product service financial collection data interpretation phase quantitative analysis take place result section report result survey study fact worth mentioning survey application question mandatory analyzed response whose respondent answered question one hundred fiftyeight people answered questionnaire however response met quality criterion characterization respondent section describes demographic data investigated developer education level expertise role working time draw observed sample profile term professional experience software development year experience year year year year experience software developer classify related expertise junior midlevel senior finally respondent played many different role working startup played one role played one role product highlight startup product service startup characterized product softwareasaservice saas software product software hardware product startup developedonly product half two product startup developed businesstobusiness bb product businesstoconsumer bc product businesstobusinesstoconsumer bbc product claimed product bb bc finally know preferred answer startup also asked respondent provide u information startup founding date age number customer revenue number employee lifecycle phase startup employee employee employee employee startup different business domain customer customer customer customer regarding startup lifecycle startup early stage validation growth one size classification company revenue brazilian institute geography statistic ibge us organizes company follows microentrepreneur le equal brl k usd k microenterprise le equal brl k usd k small company greater brl k le equal brl usd k mediumsized company greater brl le equal brl usd large company greater brl footnote ibge brazilian agency responsible official collection statistical geographic cartographic geodetic environmental information brazil information available httpswwwibgegovbrenhomeenghtmlhttpswwwibgegovbrenhomeenghtml footnote currency conversion july th brl usd startup software engineering practice rq answer research question software startup use software engineering practice across different lifecycle stage examined occurrence software engineering practice reported software developer software process asked professional used employ formalized software engineering process stated commonly followed software development process process management software methodology regarding employed methodology could observe developer perceive agile method best characterized practice followed iterative approach regarding project planning activity commonly used main reported one estimated followed delivery planning scheduling resource allocation process planning requirement engineering every startup gathered data professional reported requirement engineering phase software development process nevertheless stated company formalized requirement engineering process requirement elicitation commonly employ prototyping quick meeting customer report participant stated typically involve customer elicitation task addition said used brainstorming technique participant said used prototyping among others design quality attribute asked participant software architecture concern response indicate two used architectural pattern modelviewcontrol clientserver participant mentioned used layered architecture ruledbased eventbased pattern noted architectural pattern piper filter reflection peertopeer broker batch term quality attribute qa participant identified usability relevant qa indicated performance relevant qa well additionally pointed securityintegrity legal aspect also relevant implementation regarding approach developingreusing source code startup software developer reported using framework speed productservice development delivery also claimed use architectural pattern design pattern reuse strategy claimed built product based serviceoriented system program library next configurable vertical application erp enterprise resource planning system program generator software product line packaging legacy system modeldriven engineering thirdparty component option presented survey participant none reported practice software testing regarding software testing practice answered performed automated test furthermore said use manual testing responded perform testing practice asked run test case developer run test conversely case developer performed test person implement source code furthermore claimed customer ran test also asked developer test level commonly performed stated startup performed unit testing performed component testing performed integration testing performed acceptance testing use perform testing activity deploy considering time deliver software released day stated released software version day week week two month come delivering software customer participant affirmed spend day week within week percent reported released month maintenance regarding code maintenance technique adopted startup stated use software maintenance technique among startup used technique said used code understanding maintain product service said used migration missingpagefail discussion survey result revealed software professional focus effort speeding construction software product based customer guideline concentrate mainly usability performance security project planning primarily based delivery validation customer become involved software development activity eliciting requirement prototype testing delivering product service although architectural style design pattern prevalent software architecture decision based software development team knowledge adhoc manner software development based agile practice regardless wellestablished software development process also development process mainly scheduledriven focused planning delivery customer come productivity found general interest employing framework thirdparty api project investigate difference software practice adopted software startup lifecycle stage observe startup adopt similar set practice tool three stage startup validation growth however looking frequency response notice value practice tool support seamless integration automated testing automated security verification faster delivery user enter growth stage startup realize choice made earlier stage affected software quality software development speed new challenge solve accumulated problem adopting good software development practice minimal documentation automated testing provide security meet growing need demand increasing customer base implication research practice section present relevant implication emerge analysis study research implication discovery made academic scientific community must transferred software startup software startup work innovative complex environment need recommendation best practice tool adopt stage lifecycle recommendation avoiding pitfall affect short long run direct clear precise way practice implication observing choose use software engineering identified startup culture culture see act permit correct answer every question difficulty incessantly focus customer pain solve focus finding right question resolved way opportunity construct answer solution fit better validated refined customer presence possibility making mistake path starting trying assertively build answer solution relevance threat validity construct validity pilot test respondent reported instrument filling time extensive survey respondent may adequately answered question preferring short answer detailed description grouped question specific section better target question answer reduce threat validity another threat respondent understanding question help ensure survey understandability asked professional researcher experience software engineering experience survey design review study ensure question clear complete internal validity another observed threat may selecting practitioner sample understand number response obtained may adequately represent entire population startup software professional characterizing threat internal validity however decided include professional startup work different domain mostly office several brazilian city believe set might represent external validity respondent survey may adequately represent startup software practitioner thus result could statistically relevant nevertheless believe response analyzed provide rich qualitative data source reveal valuable insight reliability threat indicates interpretation might influence research result two author paper carried analysis process working together mitigate threat discussed disagreement assignment reach consensus conclusion software startup born disruptive idea business model pivot find valuable scalable business model need find strategy scale enter growth phase decreeing continuity closure however significant challenge software startup commonly reach higher level growth scale among challenge improving software engineering practice demanding task software startup study analyzes brazilian software startup dealt software engineering practice software practitioner perspective surveyed response software developer working brazilian software startup study show startup initial validation phase choose software engineering practice adhoc basis primarily based development team knowledge move growth phase recognize could adopted better software development practice support product scale mature team developer decide use support tool integrate others automate operational activity future work direction consider extending study reach professional global region perform crossvalidation analysis verify whether result still valid considering different scenario acknowledgment research partially funded ines cnpq grant fapesb grant jcb reference bajwa pivoting software startup fundamental software startup pp springer cham blank whats startup first principle steve blank blank four step epiphany successful strategy product win john wiley son carmel e january timetocompletion software package startup proceeding xxvii hawaii international conf system science cavalcante b h leal g c l balancieri r de farias junior technical aspect software development startup systematic mapping xliv latin american computer conference clei pp chanin r pomppermaier l fraga k sale prikladnicki r may applying customer development software requirement startup development program ieeeacm st international workshop software engineering startup softstart pp coleman g oconnor r v investigation software development process formation software startup journal ent inf manag crowne august software product startup fail evolution software product development startup company ieee international engineering management conference vol pp cukier software startup ecosystem evolution maturity model doctoral dissertation universidade de sao paulo dash scaling innovativeness startup india sedme small enterprise development management extension journal edison h wang x abrahamsson p lean startup large software company care proceeding xp pp edison h smorsgard n wang x abrahamsson p lean internal startup software product innovation large company enablers inhibitor journal system software giardino c paternoster n unterkalmsteiner gorschek abrahamsson p software development startup company greenfield startup model ieee transaction software engineering giardino c bajwa wang x abrahamsson p key challenge earlystage software startup international conference agile software development springer pp cham giardino c unterkalmsteiner paternoster n gorschek abrahamsson p know software development startup ieee software giardino c wang x abrahamsson p june earlystage software startup fail behavioral framework international conference software business icsob springer pp cham hillmola p helo p ojala l value product development lead time software startup system dynamic review kitchenham b pfleeger l principle survey research part population sample acm sigsoft soft engineering note klotins e unterkalmsteiner gorschek june software engineering knowledge area startup company mapping study international conference software business pp springer cham klotins e using case survey method explore engineering practice software startup ieeeacm st international workshop software engineering startup softstart pp linaker j sulaman maiani de mello r host guideline conducting survey software engineering melegati j goldman kon f wang x model requirement engineering software startup j inf software technology nguyenduc weng x abrahamsson p preliminary study agility business production case earlystage hardware startup proceeding th acmieee international symposium empirical software engineering measurement pp pantiuchina j mondini khanna wang x abrahamsson p may software startup applying agile practice state practice large survey international conference agile software development pp springer cham pfleeger l kitchenham b principle survey research part turning lemon lemonade acm sigsoft soft eng note real e lean startup new york crown business souza r malta k de almeida e software engineering startup single embedded case study ieeeacm st softstart pp ieee souza r malta k silva r masiero p almeida e machado case study startup software engineering practice preliminary result proceeding xviii sbqs pp souza r cico machado supplementary material survey software engineering practice brazilian software startup online available httpsdoiorgzenodohttpsdoiorgzenodo proceeding xxiv iberoamerican conference software engineering sutton role process software startup ieee software unterkalmsteiner abrahamsson p wang x nguyenduc shah bajwa baltes guido h conboy k cullina e dennehy others software startupsa research agenda einformatica soft eng j wang x edison h bajwa giardino c abrahamsson p may key challenge software startup across life cycle stage international conference agile software development pp springer cham winkel wilcox j teckchandani minute mvp entrepreneurship education pedagogy title solving data sparsity problem predicting success startup machine learning method transcription solving data sparsity problem predicting success startup machine learning method dafei yin yindafeichuangxincom jing li lijingchuangxincom gaosheng wu wugaoshengchuangxincom sinovation venture dinghao tower block b haidian street haidian district beijing china abstract predicting success startup company great importance startup company investor difficult due lack available data appropriate general method data platform like crunchbase aggregating information startup company possible predict machine learning algorithm existing research suffers data sparsity problem earlystage startup company much data available public try leverage recent algorithm solve problem investigate several machine learning algorithm large dataset crunchbase result suggest lightgbm xgboost perform best achieve f score interpret prediction perspective feature contribution construct portfolio based model achieve high success rate finding substantial implication machine learning method help startup company investor keywords machine learning venture capital startup prediction portfolio construction data sparsity footnote journal introduction predicting future success startup company great importance startup company venture capital vc firm startup company predicting future development competitor help adjust development strategy capture opportunity effectively vc firm predicting future success startup company help balance profit risk latestage company evaluation future success mostly based financial operating information however earlystage company usually enough data publicly available prediction traditionally evaluation startup company relies heavily investor personal experience recent year machine learning developing rapidly achieve great success many area exists research applying machine learning algorithm predict future success startup company yankov et al mckenzie sansone arroyo et al kaiser kuhn method well suited dealing sparse data common datasets startup company development machine learning method recent algorithm like xgboost chen guestrin lightgbm ke et al potential solve data sparsity problem paper aim make following three contribution first try leverage recent progress machine learning handle data sparsity problem validate recently developed algorithm xgboost chen guestrin lightgbm ke et al soft decision tree frosst hinton outperform many traditional algorithm including logistic regression k nearest neighbor decision tree multilayer perceptron random forest second construct factor using data crunchbase data aggregation platform built track startup global scale define multiple time window enrich number data sample take factor like macroeconomy consideration time window definition practical vc practice third introduce interpretability machine learning model interpret prediction perspective contribution factor finding company age past funding experience important factor footnote httpwwwcrunchbasecomhttpwwwcrunchbasecom rest paper structured follows previous research theoretical background reviewed sec approach introduced sec experimental result discussed sec construction portfolio described sec sec summarizes main conclusion discus future research direction theoretical background problem predicting future success startup company existed long time schendel hofer chandler hank still exploring scholar arroyo et al kaiser kuhn common solution classification model based decisive factor earlier study prediction success startup company based regression analysis logistic regression lussier kaiser kuhn ordered probit model lussier pfeifer halabi lussier lussier halabi loglogistic hazard model holmes et al researcher also develop expert system ragothaman et al rulebased method yankov et al recent year emergence platform aggregating business information company development machine learning approach possible use machine learning method solve problem startup prediction yankov et al test several treebased rulebased bayesbased machine learning method based questionnaire gathered startup company bulgarian author suggest bestderived model treebased c quinlan mckenzie sansone compare performance human expert several machine learning method including least absolute shrinkage selection operator support vector machine boosted regression analyze firm business plan competition nigeria author suggests investor using combination man machine rather relying human judge machine learningchosen portfolio arroyo et al analyze performance several machine learning method dataset startup company retrieved crunchbase consider five machine learning algorithm support vector machine decision tree random forest extremely randomized tree gradient tree boosting result suggest gradient tree boosting performs better predicting next funding round random forest extremely randomized tree perform better predicting acquisition one common problem datasets startup company sparsity nature earlystage company usually much data available public current approach well suited problem machine learning developing rapidly recent year many new model emerged gradient boosting decision tree gbdt friedman highly effective widely used machine learning method due efficiency accuracy interpretability several effective implementation recently including xgboost chen guestrin lightgbm ke et al xgboost chen guestrin scalable endtoend tree boosting system widely used data science achieves excellent result xgboost proposes novel sparsityaware algorithm sparse data weighted quantile sketch algorithm approximate tree learning us secondorder approximation convex loss function optimize objective quickly lightgbm ke et al proposes novel gradientbased oneside sampling go exclusive feature bundling efb method go lightgbm obtain quite accurate estimation information gain much smaller data size efb method bundle mutually exclusive feature usinga greedy algorithm solving data sparsity problem treebased classifier usually preferred investmentrelated research mainly interpreted soft decision tree frosst hinton take knowledge acquired neural net express knowledge model relies hierarchical decision creating explicable model knowledge previous approach applying method predicting future success startup company leverage recent progress compare performance method predicting future success startup company approach define concept ofsuccess include raising new funding acquired going ipo make prediction closer reality vc investment restrict concept future success defined time window month problem statement formulate problem evaluating startup company binary classification problem company synthesis set variable mathbfxiinmathbbrm evaluate future success size feature selection feature discussed detail sec label yi assigned according whether company succeed defined time window yibegincasestextcompany succeed time window textcompany succeed time windowendcases tag data set denoted mathcaldmathbfxiyi n size dataset given labeled sample machine learning method learn conditional probability given mathbfx ie pymathbfx given new data sample label model output prediction haty place sample class success failure hatyifmathbfxibegincasespyimathbfxigeq th pyimathbfxithendcases tag th threshold manually selected experiment th fair comparison try construct portfolio according suggestion algorithm aim constructing portfolio select subset mathcalsccck company size k ci corresponds company maximize expected number success company subset mathcals maxmathcalskmathbfesum yimathbfxiiinmathcals tag assume success company independent mathcals consisted company k largest pyimathbfxi data preprocessing time window data sample extracted using daily csv export crunchbase october full dataset contains organization venture deal filter company date establishment missing company founded removed unique id assigned company distinguish duplication company name total organization remain preprocessing make prediction closer reality vc investment restrict concept future success defined time window expect company raise new funding acquired go ipo within time threshold prediction evaluation time window interpreted time interval investor evaluate return investment use multiple time window enrich number data sample take factor like macroeconomy consideration practice vc firm believe time segment two funding round usually around month table summarizes time startup company need raise next round funding validating half company achieve next round within month round define evaluation time window month time interval according label distribution shown table time t denotes start evaluation window time make prediction considered moment vc investor invest company time tf denotes end evaluation time window company acquired went ipo closed funding event t removed accumulated time window final data sample consists sample event footnote might survival bias since crunchbase founded company failed creation crunchbase may register dataset factor exploration crunchbase provides information company news founder funding round acquisition compile set factor grouped three category related growth company based information available dataset summarized table since use multiple time window
Original Title: A Survey on Software Engineering Practices in Brazilian Startups
Original Transcription: # A Survey on Software Engineering Practices in Brazilian Startups

Renata Souza

1Institute of Computing, Federal University of Bahia (UFBA), Salvador, Brazil 1{renatamss, ivan.machado}@ufba.br
2Federal Institute of Bahia (IFBA), Santo Antonio de Jesus, Brazil 2{renata.souza}@ifba.edu.br

Orges Cico

3Norwegian University of Science and Technology (NTNU), Trondheim, Norway 3{orges.cico}@ntnu.no

Ivan Machado

1Institute of Computing, Federal University of Bahia (UFBA), Salvador, Brazil 1{renatamss, ivan.machado}@ufba.br

###### Abstract

Today's significant technological advancement allows early-stage software startups to build and launch innovative products quickly on the market. However, many of them die in the early years of their path due to market conditions, ignorance of customer needs, lack of resources, or focus, such as the misuse of well-established practices. The study's motivation is to analyze software engineering practices in startups from a practitioner's perspective. Our objective was to identify practices and tools the startups employ in their daily routines. We carried out an expert survey study with 140 software developers involved in software startups from different domains. The results show that startups in the initial and validation phases select practices and tools on an ad-hoc basis and based on the development team's prior knowledge. When they move into the growth phase, they recognize that they could have adopted better practices beforehand to support product scaling with a more mature team. The results also indicated that support tools are selected based on their integration with other tools and their ability to automate operational activities.

Keywords:Software Startups Empirical software engineering Survey Study

## 1 Introduction

An impressive number of entrepreneurs create novel startups around the world every day. Later, they might become famous and profitable, such as _Facebook, Instagram, Spotify, Linked-in, and Dropbox_. According to Sutton [30], a startup shares many features with small and medium-sized young companies. For example, they are usually immature, have limited resources, undergo multiple influences, use dynamic technology, and hunt at the market. A startup can be defined as an organization established to search for a repeatable and scalable business model [2]. Also, a startup is an organization dedicated to creating something new under conditions of extreme uncertainty [26].

As they have limited financial and human resources, they face various challenges, and barriers [14, 19]. Most of them die in earlier years [26]. Several critical challenges in every startup phase affect the strength and company stability [23]. It is crucial to prepare for what is to come so that an obstacle does not become unbeatable. Learning from others startups' experiences helps them find a way to succeed or fail faster [5, 8]. Therefore, it is necessary to leverage startup practices to understand the reason for these choices and their consequences.

This paper aims to shed light on the developers' perceptions of software engineering practices and tools employed by software startups in a Brazilian cohort. We carried out an expert survey study with 140 software developers involved in software startups from different domains. We sent an online questionnaire to professionals working in startups via email and social networks (_Facebook, Twitter, and LinkedIn_). The results show that the software startups are guided by the customer, who participates from creating the initial prototype up to product deployment, and the adopted practices and tools that speed up development activities.

The remainder of this paper is structured as follows. Section 2 covers the research-related background. Section 3 introduces the survey study methodology. The results and the discussion are located in Sections 4 and 5, respectively. Section 6 presents the implications for research and practice. The threats to this study's validity are discussed in Section 7. Finally, Section 8 outlines overall conclusions and directions for future work.

## 2 Background

### Startups

Startups are companies that start from an early stage with very few assets, and low investment [3, 13, 15]. Some of them have the potential to achieve high scalability [31]. Many of these companies took advantage from the popularization of technologies for personal use, such as _Google, Netflix, and Spotify_. They start almost from scratch [16, 27, 28] and could reach a wide range of customers ignored by major competitors offering solutions (almost always services) based on technology and the Internet [6].

The startup concept definition, although simple, encompasses many variables. The primary way to recognize a startup refers to its business model characterized by an innovative idea that generates value and turns work into money [10]. Additionally, it could be considered a policy aimed at developing competent, self-managed teams that could quickly react to scenario changes. The promotion of creativity, collaboration, focus on agility, continuous training, rewards for solving complex problems, and all actions must always link to a long-term vision.

### Startup lifecycle

Blank [3] defined the startup lifecycle as having four stages from a customer's perspective: (1) defining or observing a problem; (2) evaluating the problem; (3)defining a solution; and (4) evaluating the solution. Crowne [8] identified the startup lifecycle from the perspective of product development as having three stages, as follows:

1. The _startup_ phase is the period between product conception and the first scale.
2. _Stabilization_ begins when the first customer receives the product.
3. _Growth_ is when the Startup delivers the product to new customers without creating any overhead in the development team.
4. _Maturity_ is when the company evolves into a mature organization.

Similarly, Wang [32] defines a lifecycle for software startups taking into account the product stages: concept, underdevelopment, functional prototype, functional product with limited users, functional product with high growth potential, and mature product.

### Software Startups

Software startups share some characteristics with other types of startups, such as lack of resources, operating history, high-technology challenges, cutting-edge tools, and innovation-driven development [31]. Carmel [4] was the first one to refer to the term _software package startup_ and the shorten term _software startup_ in 1994. Sutton [30] argues that software startups are challenged by limited resources, immaturity, multiple influences, high-technology, and turbulent markets. Hilmola [17] states that most of the software startups are product-oriented and develop cutting-edge software products. Coleman [7] characterize software startups as product-driven, with a small development team, often developer-led, that develops software through various processes and without a methodology. Giardino [13], and Unterkalmsteiner [31] use the term software startups to refer to those organizations focused on the creation of high-tech and innovative products, with little or no operating history, aiming to grow their business in highly-scalable markets aggressively.

Large software companies relied for years on traditional software development. Nowadays, they realize they need to innovate to maintain their position in a highly competitive market. Also, they look to gain a significant advantage to adapt to market and technologies by focusing on cost efficiency, lead time reduction, and quality improvement. They find in startups this new way to keep their leading positions in a fast-moving and innovative market [12]. Software startups have become one of the critical drivers of economy and innovation, even though they are mostly inexperienced [30].

Coleman and O'Connor [7] investigated how software product startups establish their software development process. The study employed a grounded theory approach with the aim to characterized the experiences of small software organizations in developing processes to support their software development activities and the significant factors that might influence building processes: background of software, development manager background of founder, management style,process tailoring, market requirements. Hence, software startups depend mainly on the person's experience acting as software development manager who holds both expertise and know-how to meet company goals. Coleman and O'Connor [7] also claimed that startups are product-driven and developer-led. In this context, agile methods may have a lot to offer.

### Related Work

Giardino et al. [14] and Wang et al. [32] performed a large-scale survey of 5389 responses and an in-depth multiple-case study to investigate the critical challenges of software startups. Giardino et al. [14] observed the challenges in an early-stage startup, while Wang et al. [32] observed challenges faced by software startups across lifecycle stages. Pantiuchina et al. [24] also conducted an extensive survey of 1526 software startups where they examined the use of five agile and lean startup practices. In this work, we observed the software engineering practices adopted by startups through the divergent lifecycle stages. The startup's life cycle classification was based on the responses provided by the developers. This classification was made through characterization made concerning the information of the team size, the number of customers, and product maturity, shown in the following sections.

## 3 Research Methodology

The study's motivation is to analyze software engineering practices in startups from a software practitioner's perspective. We chose a survey as our research instrument to reach a more significant number of opinions. Our goal in designing the study was to keep it as brief as possible while still gathering all relevant information. The survey received 140 responses. We did not ask for the identification of respondents or companies. We decided to preserve this information for reasons of confidentiality and attract more participants to our research. These participants were from all over the Brazilian territory. We applied the methodology recommended by Linaker et al. [21] and the research survey principles defined by Kitchenham and Pfleeger [25]. This section encompasses the planning details, execution procedures, and reporting of the desired and achieved results.

We first identified the research object (Step 1), then the target population and sampling (Step 2). Next, we constructed the survey instrument (Step 3),

Figure 1: Overview of the Research Methodology

tested it (Step 4), and distributed it to the participants (Step 5). The last action was to analyze the collected data (Step 6) and report the results. Figure 1 shows the research steps of this study. We utilized a web-based questionnaire to reach practitioners from Brazilian startup ecosystems due to Brazil's geographical dimensions.

### Identifying the Research Object

Our objective was to identify software engineering practices and tools the startups employ in their daily routines. We also aimed to investigate whether there is any difference in practices and tools that depend on the startup's lifecycle. We formulated the following research questions:

**RQ1: Do software startup use the same software engineering practices across different lifecycle stages?**: _We aim to leverage the practices software startups adopt through the different stages of their lifecycle and at what stage it differs._
**RQ2: What tools do software startups use to support software engineering practices across different lifecycle stages?**: _We aim to observe whether there is a change in the tool's adoption through the different stages of their lifecycle and at what stage it differs._

Startups need to either follow or adapt existing software engineering practices. Otherwise, they would risk losing their market capitalization. In this effect, further studies are needed to investigate both practices and tool support to establish a common understanding of how software startups make their choices.

### Identifying Target Population and Sampling

The StartupBase4 is an official database of the Brazilian startup ecosystem supported by the Brazilian Startup Association5. Our target audience was software developers from software startups, while the population selected was Brazilian software startups. We chose software developers because they are the most representative group considering the respondents work for startups at different lifecycle stages and observe the same perspective. The survey included questions to reveal the participants' jobs, software development experience, and information on the organizations they worked for, such as size (ecosystem location) and project domain, to characterize the survey participants. We defined the following criteria to include participants in this survey study: (1) the respondent must work for a Brazilian software startup, and (2) the respondent must work as a software developer.

### Survey Instrument

The questionnaire comprises closed questions with a small number of open questions to obtain further information. We specified twelve topics divided into two groups. The first was to gather the participation consent, respondents' characterization, startups' characterization, and product characterization. The second group covered the practices considering each software engineering discipline: software requirements, software architecture, software design, software construction, software testing, software maintenance, management, and processes. We next specify the goals defined for each category:

* **Research participation consent:** free, prior and informed consent;
* **Respondents' characterization:** gather information about the respondents' profiles;
* **Startups' characterization:** gather information about when the startup was established, the number of customers, the revenue, the number of employees, and the business domain;
* **Product characterization:** characterize the product by type, public, life-cycle, revenue, need to pivot, and time that the team works on it;
* **Software requirements:** reveal the employed requirements engineering practices;
* **Software architecture:** identify decisions regarding system architecture;
* **Software design:** identify the decisions regarding user interface design;
* **Software construction:** leverage the main programming languages and development platforms the startup use;
* **Software testing:** leverage the startups' software testing practices;
* **Software maintenance:** leverage the employed maintenance techniques;
* **Project management:** leverage the project management practices;
* **Software process:** leverage the software process practices.

We used Survey Monkey6 to prepare and disseminate the questionnaire. Supplementary material is available at [29].

Footnote 6: [https://pt.surveymonkey.com/r/32FK9RP](https://pt.surveymonkey.com/r/32FK9RP)

### Pilot Testing

We asked professionals and researchers with experience in software engineering and survey design to review the survey. The goal was to remove any misunderstanding and hence improve the instrument. The changes we made included: adding more answer choices to several questions, exchanging words to improve understanding, and changing some questions. We applied the questionnaire in September 2020. The questionnaire used at the end of the test contained the following questions:

1. Does the questionnaire contain anything expected to reach our goals?
2. Does the questionnaire contain any undesirable or unnecessary information to the context and purpose of the research?
3. Were you able to understand the questions properly?
4. Is there an error or inconsistency in the questionnaire?

### Data Collection

On September 2020, we sent the survey invitation by email, _Facebook_, _Twitter_, and _Linked-in_. The invitation text contains the main instructions and the questionnaire link. We also sent reminders. We closed the survey in November 2020. We made a brief introduction with necessary information about the purpose of the study, justification of choice, and the importance of the respondent's participation. Participants were also informed about the privacy policies of the study in a clear and detailed manner.

### Data Analysis

After assembling the data collection from the online survey, we took the following steps: _(1) data validation_ - this is the phase in which we analyzed the results to verify if the answers met the criteria of consistency and integrity; _(2) participants' characterization_ - data assembling and synthesis, including data they provided about the startups they work for as well as the software products or services their companies deliver; _(3) data partitioning_ - this is the phase in which the researchers analyze the responses and group them into subgroups (data partitioning counts on data obtained in the demographic questions, such as the number of customers, number of employees, the startups' diversification of software products or services, and the financial collection); and _(4) data interpretation_ - in this phase the quantitative analyses takes place [18].

## 4 Results

In this section, we report the results of our survey study. Some facts are worth mentioning from this survey application: all questions were mandatory, and we only analyzed responses whose respondents answered 100% of the questions. One hundred fifty-eight people answered the questionnaire. However, 140 responses met our quality criteria.

### Characterization

#### 4.1.1 Respondents.

This section describes demographic data. We investigated the developers' education levels, expertise, roles, and working time to draw the observed sample profile. In terms of their professional experience in software development, 12% had up to 1 year of experience, 31% had between 2 and 3 years, 19% had between 4 and 5 years, 15% had between 6 and 10 years, and 23% had more than 10 years of experience. Software developers classify themselves as related to their expertise; 27% junior, 31% mid-level, and 42% were senior. Finally, the respondents played many different roles while working in startups: 58% played more than one role against 42%, who played only one role.

**Product.** We highlight startups' products or services. 65% startups characterized their products as Software-as-a-Service (SaaS), 31% as a software product, and 4% as a software and hardware product. 50% of the startups developedonly 1 product, and the other half had two or more products. 50% startups developed a _Business-to-Business_ (B2B) product, 23% a _Business-to-Consumer_ (B2C) product, and 19% a _Business-to-Business-to-Consumer_ (B2B2C) product. 4% claimed their product was both B2B and B2C. Finally, 4% did not know or preferred not to answer.

**Startups.** We also asked the respondents to provide us with information about the startups, such as the founding date, age, number of customers, revenue, number of employees, and lifecycle phases. 39% of 26 startups have 1 to 5 employees; 17% have 6 to 10 employees; 30% have between 11 and 50 employees, and 13% has more than 100 employees. Startups are from 13 different business domains. 57% have between 1 and 10 customers; 22% have between 11 and 100 customers; 9% is between 101 to 100 customers, and 13% has more than 1,000 customers. Regarding the startup lifecycle, 52% of startups are in the early stage, 17% of them in Validation, and 30% in Growth.

One of the size classifications of companies by revenue that the Brazilian Institute of Geography and Statistics (IBGE)7 uses organizes companies as follows: micro-entrepreneur, less than or equal to BRL 81K (USD 15.4K8); micro-enterprise, less than or equal to BRL 360K (USD 68.44K); small company, greater than BRL 360K and less than or equal to BRL 4.8M (USD 912.56K); medium-sized company, greater than BRL 4.8M and less than or equal to BRL 300M (USD 570M); large company, greater than BRL 300M.

Footnote 7: IBGE is the Brazilian agency responsible for official collection of statistical, geographic, cartographic, geodetic and environmental information in Brazil. Further information available at [https://www.ibge.gov.br/en/home-eng.html](https://www.ibge.gov.br/en/home-eng.html).

Footnote 8: Currency conversion on July 9th, 2021: BRL 1 = USD 0.19

### Startup Software Engineering Practices (RQ1)

To answer the research question, _do software startup use the same software engineering practices across different lifecycle stages?_, we examined the occurrence of software engineering practices reported by software developers.

**Software Processes.** We asked the professionals if they used to employ any formalized software engineering process. Most of them stated they commonly followed software development processes (61.5%) and process management (50%).

**Software Methodologies.** Regarding the employed methodologies, we could observe that 96% of developers perceive the agile methods as the best characterized their practices, followed by the iterative approach (23%). Regarding the project planning activities they commonly used, the main reported ones were estimated at 70%, followed by delivery planning with 65%, scheduling with 54%, resource allocation with 46%, and process planning with 35%.

**Requirements Engineering.** In every startup, we gathered data from all professionals reported any requirements engineering phase in their software development process. Nevertheless, only 28% out of them stated their company had a formalized requirements engineering process. Requirements elicitation commonly employs prototyping in quick meetings with customers. In 80% of the reports, the participants stated they typically involve customers in such elicitation tasks. In addition, 73% said they used the brainstorming technique, 70% of the participants said they used prototyping, among others.

**Design and Quality Attributes.** We asked the participants about software architecture concerns. The responses indicate that the two most used architectural patterns are model-view-control (46%) and client-server (31%). The participants mentioned that they used the layered architecture (27%), ruled-based (15%), and event-based (11%) patterns. Other noted architectural patterns were piper and filter (8%), reflection (8%), peer-to-peer (4%), broker (4%), and batch (4%). In terms of quality attributes (QA), 73% of the participants identified usability as the most relevant QA. 65% indicated that performance is a relevant QA as well. Additionally, 61% pointed out that security/integrity and legal aspects are also relevant.

**Implementation.** Regarding approaches for developing/reusing source code, startups' software developers reported using frameworks (38%) to speed up product/service development and delivery. They also claimed to use architectural patterns (35%) and design patterns (35%) as reuse strategies. 27% claimed they built their products based on service-oriented systems (27%) and program libraries (23%). Next, configurable vertical applications (15%), ERP (Enterprise Resource Planning) systems (12%), program generators (12%), software product lines (8%), and packaging of legacy systems (8%). Model-driven engineering and third-party components were other options presented by the survey participants, but none reported such practices.

**Software testing.** Regarding software testing practices, 69% answered that they performed automated tests. Furthermore, 62% said they use manual testing. Only 8% responded that they did not perform any testing practices. When asked who runs the tests, in 69% of the cases, the developers run the tests themselves. Conversely, only in 15% of the cases was the developer who performed the test a person who did not implement the source code. Furthermore, 23% claimed that customers ran tests. We also asked the developers about the test level they commonly performed. 77% stated that their startups performed unit testing, 42% performed component testing, 58% performed integration testing, and 27% performed acceptance testing. 8% did not use to perform testing activities.

**Deploy**. When considering the time to deliver software, 19% released it between 1 to 2 days, 12% stated they released a software version between 3 to 7 days, 15% between 1 and 2 weeks, 19% between 3 and 4 weeks, and 16% at two months or more. When it comes to delivering the software to the customer, most participants affirmed that 15% spend between 1 to 2 days; 12% between 3 to 4 weeks, (38%) within 1 to 2 weeks; and 19% percent reported that they released between 2 to 3 months.

**Maintenance.** Regarding the code maintenance techniques adopted in the startups, 38% stated that they did not use any software maintenance techniques. Among the startups that used these techniques, 38% said they only used code understanding to maintain products or services, 27% said they used migration,

[MISSING_PAGE_FAIL:10]

## 5 Discussion

The survey results revealed that software professionals focus their efforts on speeding up the construction of the software product based on customer guidelines and concentrate mainly on usability, performance, and security. Project planning is primarily based on deliveries and validations with their customers, who become involved in software development activities, from eliciting requirements through prototypes to testing and delivering the product or service. Although architectural styles and design patterns are prevalent, software architecture decisions are based on the software development team's knowledge in an _ad-hoc_ manner. Software development is based on agile practices, regardless of other well-established software development processes. Also, the development process is mainly schedule-driven and focused on planning for delivery to the customer. When it comes to productivity, we found a general interest in employing frameworks and third-party API projects.

We investigate the differences between software practices adopted by software startups to their lifecycle stage. We observe that startups adopt a similar set of practices and tools in the three stages: startup, validation, and growth. However, looking at the frequency of responses, we notice that they value more practices and tools that support seamless integration, automated testing, automated security verification, and faster delivery to the user as they enter the growth stage. Startups realize that choices made in earlier stages have affected software quality and software development speed. And now, a new challenge is to solve the accumulated problems while adopting good software development practices, minimal documentation, and automated testing to provide security and meet the growing needs or demands of the increasing customer base.

## 6 Implications for Research and Practice

In this section, we present the relevant implications that emerge from the analysis of this study:

* **Research Implications.** The discoveries made by the academic and scientific community must be transferred to software startups. Software startups work in an innovative and complex environment and need recommendations on which best practices and tools to adopt at each stage of their lifecycle and recommendations on avoiding pitfalls that affect the short and long run in a direct, clear and precise way.
* **Practice Implications.** By observing how they choose and use software engineering, we identified a startup culture. The culture is how they see and act in which they permit themselves not to have the correct answers for every question and difficulty. They incessantly focus on the customer's pain and how to solve it but focus on finding the right question to be resolved. In this way, they have the opportunity to construct an answer or a solution that fits better that can be validated and refined with the customer's presence. There is the possibility of making mistakes on this path, starting over and trying again more assertively to build an answer or a solution with relevance.

## 7 Threats to Validity

_Construct Validity_: During the pilot test, some respondents reported that the instrument's filling time was extensive. As such, our survey respondents may not have adequately answered questions, preferring short answers to more detailed descriptions. We grouped the questions into specific sections to better target questions and answers to reduce threats to validity. Another threat was the respondents' understanding of the questions. To help ensure the survey's understandability, we asked professionals and researchers with experience in software engineering and experience in survey design to review the study to ensure the questions were clear and complete.

_Internal Validity_: Another observed threat may be selecting practitioners to the sample. We understand that the number of responses obtained may not adequately represent the entire population of startup software professionals, characterizing a threat to internal validity. However, as we decided to include only professionals from startups that work in different domains (and mostly have offices in several Brazilian cities), we believe this set might represent.

_External Validity_: The respondents of our survey may not adequately represent all startup software practitioners. Thus, our results could not be statistically relevant. Nevertheless, we believe that the 140 responses we analyzed provide a rich qualitative data source to reveal valuable insights.

_Reliability_: This threat indicates that the interpretation might influence the research results. Two authors of this paper carried out the analysis process by working together to mitigate such a threat. We discussed any disagreements in the assignment until we reach a consensus.

## 8 Conclusion

Software startups are born with disruptive ideas and business models. Some of them have to pivot until they find a valuable and scalable business model. They need to find a strategy to scale and enter a growth phase decreeing its continuity or closure. However, there are significant challenges software startups commonly to reach higher levels on the growth scale. Among the challenges, improving software engineering practices is a demanding task for software startups.

This study analyzes how Brazilian software startups have dealt with software engineering practices from a software practitioner's perspective. We surveyed 140 responses from software developers working in Brazilian software startups. Our study shows that startups in the initial and validation phases choose software engineering practices on an _ad-hoc_ basis and primarily based on the development team's knowledge. When they move into the growth phase, they recognize that they could have adopted better software development practices to support the product scale with a more mature team. The developers decide to use support tools that integrate with others and automate operational activities. Future work directions should consider extending this study to reach professionals from other global regions to perform a cross-validation analysis to verify whether the results are still valid when considering different scenarios.

#### Acknowledgments.

This research was partially funded by INES 2.0; CNPq grants 465614/2014-0 and 408356/2018-9 and FAPESB grant JCB0060/2016.

## References

* [1]
* [2] Bajwa, S. S. (2020). Pivoting in Software Startups. In Fundamentals of Software Startups (pp. 27-43). Springer, Cham.
* [3] Blank, S. (2010). What's A Startup? First Principles. Steve Blank.
* [4] Blank, S. (2020). The four steps to the epiphany: successful strategies for products that win. John Wiley and Sons.
* [5] Carmel, E. (1994, January). Time-to-completion in software package startups. In 1994 Proceedings of The XXVII Hawaii International Conf. on System Sciences.
* [6] Cavalcante, B. H., Leal, G. C. L., Balancieri, R., de Farias Junior, I. (2018). Technical Aspects of Software Development in Startups: A Systematic Mapping. 2018 XLIV Latin American Computer Conference (CLEI) (pp. 100-109).
* [7] Chanin, R., Pomppermaier, L., Fraga, K., Sales, A., Prikladnicki, R. (2017, May). Applying customer development for software requirements in a startup development program. In 2017 IEEE/ACM 1st International Workshop on software engineering for Startups (SoftStart) (pp. 2-5).
* [8] Coleman, G., O'Connor, R. V. (2008). An investigation into software development process formation in software start-ups. Journal of Ent. Inf. Manag.
* [9] Crowne, M. (2002, August). Why software product startups fail and what to do about it. Evolution of software product development in startup companies. In IEEE International Engineering Management Conference (Vol. 1, pp. 338-343).
* [10] Cukier, D. (2017). Software startup ecosystems evolution: a maturity model. Doctoral dissertation, Universidade de Sao Paulo.
* [11] Dash, A. (2019). Scaling the Innovativeness of Start-ups in India. SEDME (Small Enterprises Development, Management and Extension Journal), 46(3), 196-204.
* [12] Edison, H., Wang, X., Abrahamsson, P. (2015). Lean startup: why large software companies should care. In Proceedings of the XP2015 (pp.1-7).
* [13] Edison, H., Smorsgard, N. M., Wang, X., Abrahamsson, P. (2018). Lean internal startups for software product innovation in large companies: enablers and inhibitors. Journal of Systems and Software, 135, 69-87.
* [14] Giardino, C., Paternoster, N., Unterkalmsteiner, M., Gorschek, T., Abrahamsson, P. (2015). Software development in startup companies: the greenfield startup model. IEEE Transactions on software engineering, 42(6), 585-604.
* [15] Giardino, C., Bajwa, S. S., Wang, X., Abrahamsson, P. (2015). Key challenges in early-stage software startups. In International Conference on Agile Software Development. Springer (pp. 52-63), Cham.
* [16] Giardino, C., Unterkalmsteiner, M., Paternoster, N., Gorschek, T., Abrahamsson, P. (2014). What do we know about software development in startups?. IEEE software, 31(5), 28-32.
* [17] Giardino, C., Wang, X., Abrahamsson, P. (2014, June). Why early-stage software startups fail: a behavioral framework. In International conference of software business (ICSOB). Springer (pp. 27-41), Cham.
* [18] Hillmola, O. P., Helo, P., Ojala, L. (2003). The value of product development lead time in software startup. System Dynamics Review, 19(1), 75-82.
* [19] Kitchenham, B., Pfleeger, S. L. (2002). Principles of survey research: Part 5: populations and samples. ACM SIGSOFT Soft. engineering Notes, 27(5), 17-20.

* [19] Klotins, E., Unterkalmsteiner, M., Gorschek, T. (2015, June). software engineering knowledge areas in startup companies: a mapping study. In International Conference of Software Business (pp. 245-257). Springer, Cham.
* [20] Klotins, E. (2017). Using the case survey method to explore engineering practices in software start-ups. In 2017 IEEE/ACM 1st International Workshop on software engineering for Startups (SoftStart) (pp. 24-26).
* [21] Linaker, J., Sulaman, S. M., Maiani de Mello, R., Host, M. (2015). Guidelines for conducting surveys in software engineering.
* [22] Melegati, J., Goldman, A., Kon, F., Wang, X. (2019). A model of requirements engineering in software startups. J. Inf. and software technology, 109, 92-107.
* [23] Nguyen-Duc, A., Weng, X., Abrahamsson, P. (2018). A preliminary study of agility in business and production: cases of early-stage hardware startups. In Proceedings of the 12th ACM/IEEE International Symposium on Empirical software engineering and Measurement (pp. 1-4).
* [24] Pantiuchina, J., Mondini, M., Khanna, D., Wang, X., Abrahamsson, P. (2017, May). Are software startups applying agile practices? The state of the practice from a large survey. In International Conference on Agile Software Development (pp. 167-183). Springer, Cham.
* [25] Pfleeger, S. L., Kitchenham, B. A. (2001). Principles of survey research: part 1: turning lemons into lemonade. ACM SIGSOFT Soft. Eng. Notes, 26(6), 16-18.
* [26] Reis, E. (2011). The lean startup. New York: Crown Business, 27.
* [27] Souza, R., Malta, K., De Almeida, E. S. (2017). software engineering in startups: a single embedded case study. In 2017 IEEE/ACM 1st SoftStart (pp. 17-23). IEEE.
* [28] Souza, R., Malta, K., Silva, R., Masiero, P., Almeida, E., Machado, I. (2019). A Case Study about Startups' software engineering practices: A Preliminary Result. In Proceedings of the XVIII SBQS (pp. 198-203).
* [29] Souza, R., Cico, O., Machado, I. (2021). Supplementary Material to "A survey on the software engineering practices in Brazilian Software Startups". [Online] Available: [https://doi.org/10.5281/zenodo.5082313](https://doi.org/10.5281/zenodo.5082313) In Proceedings of the XXIV Ibero-American Conference on Software Engineering.
* [30] Sutton, S. M. (2000). The role of process in software start-up. IEEE software, 17(4), 33-39.
* [31] Unterkalmsteiner, M., Abrahamsson, P., Wang, X., Nguyen-Duc, A., Shah, S., Bajwa, S. S., and Baltes, Guido H., Conboy, K., Cullina, E., Dennehy, D., others (2016). Software startups-a research agenda. e-Informatica Soft. Eng. J, 10(1).
* [32] Wang, X., Edison, H., Bajwa, S. S., Giardino, C., Abrahamsson, P. (2016, May). Key challenges in software startups across life cycle stages. In International Conference on Agile Software Development (pp. 169-182). Springer, Cham.
* [33] Winkel, D., Wilcox, J., Teckchandani, A. (2019). The 60-Minute MVP. Entrepreneurship Education and Pedagogy,.

Title: Solving the Data Sparsity Problem in Predicting the Success of the
  Startups with Machine Learning Methods
Transcription: Solving the Data Sparsity Problem in Predicting the Success of the Startups with Machine Learning Methods

Dafei Yin

yindafei@chuangxin.com

Jing Li

lijing@chuangxin.com

Gaosheng Wu

wugaosheng@chuangxin.com Sinovation Ventures, Dinghao Tower Block B, No. 3 Haidian Street, Haidian District, 10080, Beijing, China

###### Abstract

Predicting the success of startup companies is of great importance for both startup companies and investors. It is difficult due to the lack of available data and appropriate general methods. With data platforms like Crunchbase aggregating the information of startup companies, it is possible to predict with machine learning algorithms. Existing research suffers from the data sparsity problem as most early-stage startup companies do not have much data available to the public. We try to leverage the recent algorithms to solve this problem. We investigate several machine learning algorithms with a large dataset from Crunchbase. The results suggest that LightGBM and XGBoost perform best and achieve 53.03% and 52.96% F1 scores. We interpret the predictions from the perspective of feature contribution. We construct portfolios based on the models and achieve high success rates. These findings have substantial implications on how machine learning methods can help startup companies and investors.

keywords: Machine learning, Venture capital, Startup prediction, Portfolio construction, Data Sparsity +
Footnote †: journal:

## 1 Introduction

Predicting the future success of startup companies is of great importance for both startup companies and venture capital (VC) firms. For startup companies, predicting the future development of themselves and their competitors can help them adjust their development strategies and capture opportunities effectively. For VC firms, predicting the future success of startup companies helps them balance their profit and risk.

For late-stage companies, the evaluation of future success is mostly based on financial and operating information. However, for early-stage companies, there is usually not enough data publicly available for prediction. Traditionally, the evaluation of startup companies relies heavily on investor's personal experience. In recent years, machine learning is developing rapidly and achieve great success in many areas. There exists some research applying machine learning algorithm to predict the future success of startup companies (Yankov et al., 2014; McKenzie and Sansone, 2017; Arroyo et al., 2019; Kaiser and Kuhn, 2020), but their methods are not well suited for dealing with sparse data, which is common in datasets of startup companies. With the development of machine learning methods, recent algorithms like XGBoost (Chen and Guestrin, 2016) and LightGBM (Ke et al., 2017) have the potential to solve this data sparsity problem.

In this paper, we aim to make the following three contributions. First, we try to leverage the recent progress of machine learning to handle this data sparsity problem. We validate that the recently developed algorithms, such as XGBoost (Chen and Guestrin, 2016), LightGBM (Ke et al., 2017), and soft Decision Tree (Frosst and Hinton, 2017), outperform many traditional algorithms including Logistic Regression, K Nearest Neighbor, Decision Tree, Multilayer Perceptron, and Random Forests. Second, we construct 19 factors using the data from Crunchbase 1, a data aggregation platform built to track startups on a global scale. We define multiple time windows to enrich the number of data samples and take factors like macroeconomy into consideration. This time window definition is more practical in VC practices. Third, we introduce interpretability into machine learning models. We interpret the predictions from the perspective of the contribution of each factor, finding that company age and past funding experience are the most important factors.

Footnote 1: [http://www.crunchbase.com](http://www.crunchbase.com)

The rest of the paper is structured as follows: The previous research and theoretical background are reviewed in Sec 2. Our approach is introduced in Sec 3. Experimental results are discussed in Sec 4. The construction of the portfolio is described in Sec 5. Sec 6 summarizes our main conclusion and discusses future research directions.

## 2 Theoretical background

The problem of predicting the future success of startup companies has existed for a long time (Schendel and Hofer, 1979; Chandler and Hanks, 1993) and is still exploring by scholars (Arroyo et al., 2019; Kaiser and Kuhn, 2020).

Common solutions are classification models based on decisive factors. Most earlier studies for the prediction of the success of startup companies are based on regression analysis such as logistic regression (Lussier, 1995; Kaiser and Kuhn, 2020), ordered probit model (Lussier and Pfeifer, 2001) (Halabi and Lussier, 2014) (Lussier and Halabi, 2010), and log-logistic hazard models (Holmes et al., 2010). Researchers also develop expert systems (Ragothaman et al., 2003) and rule-based methods (Yankov et al., 2014).

In recent years, with the emergence of platforms aggregating business information about companies and the development of machine learning approaches, it is possible to use machine learning methods to solve the problem of startup prediction. (Yankov et al., 2014) test several tree-based, rule-based, and Bayes-based machine learning methods based on questionnaires gathered from 142 startup companies in Bulgarian. The authors suggest that the best-derived model is the tree-based C4.5 (Quinlan, 1993). (McKenzie and Sansone, 2017) compare the performance of human experts and several machine learning methods, including Least Absolute Shrinkage and Selection Operator, Support Vector Machines, and Boosted Regression. They analyze 2,506 firms in a business plan competition in Nigeria. The author suggests that investors using the combination of man and machine rather than relying on human judges or machine learning-chosen portfolios. (Arroyo et al., 2019) analyze the performance of several machine learning methods in a dataset of over 120,000 startup companies retrieved from Crunch-base. They consider five machine learning algorithms: Support Vector Machines, Decision Tree, Random Forests, Extremely Randomized Trees, and Gradient Tree Boosting. The results suggest that the Gradient Tree Boosting performs better in predicting the next funding round, while Random Forests and Extremely Randomized Trees perform better in predicting acquisition. One common problem of the datasets with startup companies is their sparsity nature. For most early-stage companies, there is usually not very much data available to the public. Current approaches are not well suited for this problem.

Machine learning is developing rapidly in recent years, and many new models have emerged. Gradient Boosting Decision Tree (GBDT) (Friedman, 2001) is a highly effective and widely used machine learning method, due to its efficiency, accuracy, and interpretability. It has several effective implementations recently, including XGBoost (Chen and Guestrin, 2016) and LightGBM (Ke et al., 2017). XGBoost (Chen and Guestrin, 2016) is a scalable end-to-end tree boosting system, which is widely used in data science and achieves excellent results. XGBoost proposes a novel sparsity-aware algorithm for sparse data and a weighted quantile sketch algorithm for approximate tree learning. It uses the second-order approximation of the convex loss function that can optimize the objective quickly. LightGBM (Ke et al., 2017) proposes novel Gradient-based One-Side Sampling (GOSS) and Exclusive Feature Bundling (EFB) methods. With GOSS, LightGBM can obtain a quite accurate estimation of the information gain with much smaller data size. The EFB method bundles mutually exclusive features usinga greedy algorithm, solving the data sparsity problem. Tree-based classifiers are usually more preferred in investment-related research, mainly because they can be interpreted. Soft Decision Tree (Frosst and Hinton, 2017) takes the knowledge acquired by neural nets and expresses the knowledge in a model that relies on hierarchical decisions, creating a more explicable model. To our knowledge, there is no previous approach applying these methods in predicting the future success of startup companies. We leverage this recent progress and compare the performance of these methods in predicting the future success of startup companies

## 3 Our Approach

We define the concept of'success' to include raising new funding, being acquired, or going for an IPO. To make the prediction closer to the reality of VC investment, we further restrict the concept of future success to be in a defined time window (18 months).

### Problem Statement

We formulate the problem of evaluating startup companies as a binary classification problem. For each company \(i\), we synthesis a set of variables \(\mathbf{x_{i}}\in\mathbb{R}^{m}\) to evaluate its future success, \(m\) is the size of features. The selection of the features is discussed in detail in Sec 3.3. The label \(y_{i}\) is assigned according to whether the company will succeed in the defined time window:

\[y_{i}=\begin{cases}1,&\text{company i will succeed in the time window}.\\ 0,&\text{company i will not succeed in the time window}.\end{cases} \tag{1}\]

Our data set can be denoted as: \(\mathcal{D}=\{(\mathbf{x_{i}},y_{i})\}\), \(i=1,2,...,n\), \(n\) is the size of the dataset. Given the labeled sample, the machine learning methods learn the conditional probability of \(y\) given \(\mathbf{x}\), i.e. \(p(y|\mathbf{x})\). Given a new data sample with no label, this model then outputs a prediction \(\hat{y}\) that places the sample into the class of success or failure.

\[\hat{y}_{i}=f(\mathbf{x_{i}})=\begin{cases}1,&p(y_{i}=1|\mathbf{x_{i}})\geq th\\ 0,&p(y_{i}=1|\mathbf{x_{i}})<th\end{cases} \tag{2}\]

where \(th\) is a threshold manually selected. In our experiment, th is 0.5 for fair comparison.

We then try to construct portfolios according to the suggestion of these algorithms. The aim of constructing a portfolio is to select a subset \(\mathcal{S}=\{c_{1},c_{2},...,c_{k}\}\) of companies with size \(k\), each \(c_{i}\) corresponds to a company, such that we maximize the expected number of success companies in the subset \(\mathcal{S}\).

\[\max_{|\mathcal{S}|=k}\mathbf{E}(\sum y_{i}|\{\mathbf{x_{i}},i\in\mathcal{S}\}) \tag{3}\]

If we assume that the success of each company is independent, \(\mathcal{S}\) is consisted of the companies with the \(k\) largest \(p(y_{i}=1|\mathbf{x_{i}})\).

### Data Preprocessing and Time Window

Our data sample is extracted using the daily CSV export of Crunchbase on October 20, 2020. The full dataset contains 1,166,402 organizations and 351,236 venture deals. We filter out the companies that the date of establishment is missing. The companies founded before 1990 are removed. Unique ids are assigned to each company to distinguish from the duplication of company names. Total 776,273 organizations remain after this preprocessing.

To make the prediction closer to the reality of VC investment, we restrict the concept of future success to be in a defined time window. We expect that the company will raise new funding, be acquired, or go for an IPO within a time threshold after the prediction. These evaluation time windows can be interpreted as the time intervals for investors to evaluate the return of investments. We use multiple time windows to enrich the number of data samples and take more factors like macroeconomy into consideration.

In practice, most VC firms believe the time segment between two funding rounds is usually around 18 months. Table 1 summarizes the time startup companies need to raise next round funding, validating that more than half of the companies achieve their next round within 18 months in most of the rounds. So we define the evaluation time window of 18 months. The time intervals and the according label distribution are shown in Table 22. The time \(t_{s}\) denotes the start of the evaluation window, which is the time we make the prediction and can be considered as the moment VC investors invest in a company. The time \(t_{f}\) denotes the end of the evaluation time window. The companies that were acquired, went for an IPO, closed, or had no funding events before \(t_{s}\) are removed. Accumulated in all the time windows, the final data sample consists of 398,489 sample events.

Footnote 2: There might be survival bias since the Crunchbase was founded in 2007. The companies failed before the creation of Crunchbase may not register in the dataset.

### Factor Exploration

Crunchbase provides information about companies, news, founders, funding rounds, and acquisitions. We compile a set of 19 factors grouped in three categories related to the growth of companies based on the information available in the dataset, as summarized in Table 3. Since we use multiple time windows, all

Tuple 27:
Cleaned Title: impact covid lockdown measure chinese startup local government public finance challenge policy implication
Cleaned Transcription: impact covid lockdown measure chinese startup local government public finance challenge policy implication xin sun georgia institute technology advisor daniel dench georgia institute technology april content introduction hypothesis development data research design result conlusion abstract paper aim ass impact covid public finance chinese local government particular focus effect lockdown measure startup pandemic outbreak placed significant fiscal pressure local government containment measure led decline revenue increased expense related public health social welfare tandem startup faced substantial challenge including reduced funding profitability due negative impact lockdown measure entrepreneurship moreover pandemic generated short longterm economic shock affecting employment economic recovery address challenge policymakers must balance health concern economic development regard government consider implementing preferential policy focus startup ensure survival growth policy may include financial assistance tax incentive regulatory flexibility foster innovation entrepreneurship large covid pandemic profound impact public finance chinese local government startup ecosystem addressing challenge faced local government startup require comprehensive approach balance health economic consideration includes targeted policy support entrepreneurship innovation introduction impact lockdown startup china covid covid pandemic emerged late swept globe unprecedented speed impacting health livelihood million people worldwide primary focus pandemic public health effect also become increasingly apparent covid pose significant economic challenge country around world government worldwide impose stringent measure contain spread viruswhich led widespread disruption economic activity measure included restriction people movement closure nonessential business restriction international trade measure severely impacted global supply chain limiting allocation resource exacerbating preexisting global economic challenge lockdown measure implemented many country particularly severe impact production employment numerous industry particularly require physical interaction tourism transportation industry suffered significant revenue loss due travel restriction lower demand disruption industry also knockon effect broader economy leading increased level unemployment reducing overall economic growth china government successfully brought covid pandemic control april shifted focus towards preventing imported case asymptomatic infection however despite control pandemic crisis resulted several unavoidable outcome firstly exportoriented firm faced significant challenge due widespread nature pandemic causing obstacle supply chain disruption production led significant financial difficulty many firm secondly due unpredictable nature pandemic challenging determine would safe resume work production although government allowed factory resume operation instance illness resulted temporary shutdown leading discontinuity production bankruptcy many firm thirdly enterprise faced significant operational risk due supply chain capital chain disruption formidable challenge business pandemic sharp drop order cost pressure intensified risk fourthly pandemic led change consumer behavior significant shift demand towards contactless service essential good created emergent need responsive supply system presented challenge startup term funding profitability overall outcome illustrate multidimensional challenge presented covid pandemic significant implication business policymakers alike startup face significant challenge vulnerability competing market frequently encounter issue insufficient funding talent shortage difficulty developing business covid pandemic amplified issue endangering survival many startup pandemic caused widespread production disruption depressed domestic consumption inflexible expense related rent wage interest expense put immense strain startup fragile capital chain result substantial number startup faced bankruptcy pandemic profound implication startup ecosystem highlighting importance robust adaptable business model adequate resource startup survival paper aim examine impact covid pandemic number new startup china specifically use monthly provincelevel data measure number startup based number new registered enterprise province china research seek determine whether lockdown measure imposed pandemic significant effect establishment new startup china additionally aim provide empirical evidence development entrepreneurship china economic ramification covid extensively studied researcher widely agree pandemic significantly impacted global economy covid led reduced demand factory closure negative sale gap longlasting scar policymakers face difficult tradeoff preserving public health maintaining income employment also potentially limiting mobility lockdown policy resulted reduced income expenditure resident spending serving direct source income resident enterprise china rapid spread covid disrupted normal life potential longterm effect country economy intensification pandemic may significant implication china economic future covid resulted shortterm longterm economic shock short term china lockdown policy include isolation social distancing measure reduced domestic market demand led unemployment research focusing chinese agriculture found sector suffered due decrease global demand chinese agricultural product looking ahead long term demand shock induced lockdown policy france believed temporary economy potentially recovering towards baseline trajectory following decade recent time level entrepreneur developing country linked wealth poverty nation yet remains one least studied significant economic social phenomenon researcher studying entrepreneurship startup focused corporate social responsibility small mediumsized enterprise smes offer explanation lack responsible entrepreneurship among smes list obstacle entrepreneurship developing country regard pandemic period estimate suggest disruption caused covid may longlasting effect employment potential substantial loss lasting decade even slump startup activity temporary furthermore lockdown policy negative impact firm creation significant policy relevance introduction impact covid local government public finance chinathe rapid spread covid epidemic caused major economy suffer led stagnating global economic growth china economic social development also seriously impacted scale local fiscal expenditure china larger scale revenue leading widening fiscal balance year year since growth rate fiscal expenditure exceeded growth rate revenue aggravating contradiction revenue expenditure although local public budget expenditure increased yearonyear billion yuan according fiscal data released ministry finance end china economy experienced mixed result national public budget revenue reaching million yuan national public budget expenditure totaled million yuan increase meanwhile china local government debt balance rose trillion yuan trillion yuan yearonyear amount general debt account special local government debt account impact epidemic led faster growth rate health affair expense local government fiscal expenditure due decline local tax revenue caused sequestration fiscal revenue le robust sustainability debt decrease addition local government dependent land finance concession stateowned land use right becoming main source government fund revenue public finance foundation important guarantee nationbuilding governance reflects national economic situation comprehensively also lay foundation national government carry macrocontrol market economy fiscal revenue important indicator measure financial status local government abundance stability fiscal revenue determine ability local government provide public good service economic social activity financial relationship central local government essential understanding composition local government revenue expenditure centrallocal fiscal relation generally include three aspect first division revenue mainly refers government revenue mainly tax allocated central local government tax usually categorized according attribute tax reflect national sovereignty classified central government revenue custom duty import tax tax relatively stable tax base clear regional attribute classified local government revenue property tax municipal tax tax strong liquidity uneven distribution region classified central government revenue shared revenue central government usually higher share second division fiscal power expenditure responsibility based three principle first principle scope benefit mean certain expenditure affect area outside region certain externality borne higher level government second principle complexity information mean complex information acquisition processing likely cause information asymmetry responsibility local especially grassroots government third principle stimulating initiative mean division fiscal power fully reflect matching right responsibility conducive active performance duty incentive achieving overall maximization benefit third transfer payment system typically includes two type payment general transfer payment special transfer payment former unconditional grant latter must used designated purpose general transfer payment primarily used subsidize local affair whereas special transfer payment mainly employed centrally entrusted affair central local joint affair local affair requiring guidance encouragement additionally transfer payment model lie general special transfer payment classification transfer payment model central local joint affair involving basic livelihood like education health general local government revenue mainly come two source one hand income partyowned enterprise various tax revenue include business tax local enterprise income tax personal income tax urban land use tax land valueadded tax hand fiscal transfer subsidy central government fiscal expenditure primarily divided education medical social security expenditure reflecting government investment constructing basic livelihood protection total financial expenditure mainly consists capital expenditure science technology support cost industrial transportation business expense health business expense among others local government debt refers debt raised guaranteed local government debtor name government resulting obligation repay fund issued form revenueraising local government revenue included local government budget arranged dispatched local government essential mean local government raise fund cover fiscal deficit total outstanding local government debt percentage provincial revenue exceeded percent province poorer province ratio high percent adam liu et al since tax sharing reform local government revenue people republic china prc faced downward risk problem ziying fan et al outbreak covid local government china implemented nonpharmaceuticalinterventions isolating confirmed patient close contact closing public place like school limiting stopping market gathering restricting transportation issuing domestic international travel ban although containment measure extent epidemic varied across city local fiscal pressure increased rise fiscal revenue expenditure gap accounted almost half local fiscal revenue yue mei guo et al lockdown policy directly indirectly affected local government revenue capacity paper analyze impact different urban outbreak indicator local government finance hypothesis development hypothesis development impact lockdown startup drawing upon literature review identifying research gap study aim develop hypothesis ha hb hc test effect lockdown measure startup china covid pandemic primary objective investigate relationship stringency lockdown measure number newly registered startup specifically study aim test following hypothesis h significant negative relationship stringency lockdown measure number startup china covid pandemic hypothesis h posit imposition stringent lockdown measure government curb spread covid adverse effect entrepreneurial ecosystem restriction movement social interaction business operation may deterred potential entrepreneur initiating new business resulting decline number startup hypothesis development impact covid local government public financethe hypothesis h study covid pandemic negative impact public finance local government china hypothesis based assumption containment measure taken control spread virus directly indirectly affected revenuegenerating capacity local government leading decline fiscal revenue additionally increased need public health spending economic support measure pandemic expected resulted increase local government expenditure h covid pandemic negatively affected public finance local government china h covid pandemic positively affected public finance local government china test h h study employ twoway fixed effect regression model using data chinese city monthly basis model control potential confounding factor cpi local house price data research design sample selection impact lockdown startup study employ monthly provincelevel data encompassing province china comprises total observation number newly registered business adopted primary measure startup study whereby newly registered business refer registered administrative department industry commerce accordance national law regulation relevant provision monthly number newly registered business collected illustrates steady increase time data utilized study monthly provincial data sourced wind dataset determine stringency lockdown measure province study us data oxford covid government response tracker oxcgrt program comprises indicator encompassing school closure travel restriction vaccination policy average stringency index chosen indicator lockdown measure range higher value denoting stricter lockdown measure notably lockdown policy first implemented wuhan january gradually extended province included study country government declaring lifting covid lockdown december sample selection impact covid local government public finance section focus studying impact covid epidemic fiscal revenue fiscal expenditure government debt thirty city using monthly data epidemic intensity indicator measured monthly number confirmed patient relevant city macro indicator cpi local house price considered control variable data source include finance bureau city national health commission people republic china national bureau statistic china noted fiscal data january year excluded study fiscal data cumulative city publish data unify january february february release important point term indicator selection section us number diagnosed patient city measure local epidemic risk level additionally due difference price level different place fact land concession account large proportion local government finance section also us house price city explanatory variable section data monthly data local government public finance cpi gdp sourced wind dataset fiscal data local government typically collected monthly local government may missing data month january therefore ensure data consistency paper excludes january data analysis data number confirmed patient city sourced covid record program variable public expenditure sample mean standard deviation minimum value maximum value variable public revenue sample mean standard deviation minimum value maximum value variable cpi sample mean standard deviation minimum value maximum value number confirmed patient sample mean standard deviation minimum value maximum value research design impact lockdown startup study effect covid startup use differenceindifference identification strategy estimate following regression textstartupstextitalphabetatextstringencytextit textprovincetextibetatextprovincetextibeta texttimetexttvarepsilontextit
Original Title: Impact of COVID-19 Lockdown Measures on Chinese Startups and Local
  Government Public Finance: Challenges and Policy Implications
Original Transcription: **Impact of COVID-19 Lockdown Measures on Chinese Startups and Local Government Public Finance: Challenges and Policy Implications**

Xin Sun

Georgia Institute of Technology

Advisor:

Daniel Dench

Georgia Institute of Technology

April 2023_Contents_

_1. Introduction_................................................................................................ \(2\)

_2. Hypothesis development................................................................ \(9\)

_3. Data and Research Design_................................ _10_

_4. Results_................................................ _14_

_5. Conlusion................................................................ _21_

###### Abstract

This paper aims to assess the impact of COVID-19 on the public finance of Chinese local governments, with a particular focus on the effect of lockdown measures on startups during the pandemic. The outbreak has placed significant fiscal pressure on local governments, as containment measures have led to declines in revenue and increased expenses related to public health and social welfare. In tandem, startups have faced substantial challenges, including reduced funding and profitability, due to the negative impact of lockdown measures on entrepreneurship. Moreover, the pandemic has generated short- and long-term economic shocks, affecting both employment and economic recovery. To address these challenges, policymakers must balance health concerns with economic development. In this regard, the government should consider implementing more preferential policies that focus on startups to ensure their survival and growth. Such policies may include financial assistance, tax incentives, and regulatory flexibility to foster innovation and entrepreneurship. By and large, the COVID-19 pandemic has had a profound impact on both the public finance of Chinese local governments and the startup ecosystem. Addressing the challenges faced by local governments and startups will require a comprehensive approach that balances health and economic considerations and includes targeted policies to support entrepreneurship and innovation.

_1.1 Introduction of the impact of lockdown on startups in China during COVID-19_

The COVID-19 pandemic, which emerged in late 2019, has swept the globe with unprecedented speed, impacting the health and livelihoods of millions of people worldwide. While the primary focus has been on the pandemic's public health effects, it has also become increasingly apparent that COVID-19 poses significant economic challenges for countries around the world. Governments worldwide have had to impose stringent measures to contain the spread of the virus,which has led to widespread disruptions in economic activity. These measures have included restrictions on people's movements, the closure of non-essential businesses, and restrictions on international trade. Such measures have severely impacted global supply chains, limiting the allocation of resources and exacerbating pre-existing global economic challenges. The lockdown measures implemented by many countries have had a particularly severe impact on the production and employment of numerous industries, particularly those that require physical interaction, such as tourism and transportation. These industries have suffered significant revenue losses due to travel restrictions and lower demand. The disruptions to these industries have also had a knock-on effect on the broader economy, leading to increased levels of unemployment and reducing overall economic growth.

In China, the government successfully brought the COVID-19 pandemic under control by April 2020 and shifted its focus towards preventing imported cases and asymptomatic infections. However, despite the control of the pandemic, the crisis resulted in several unavoidable outcomes. Firstly, export-oriented firms faced significant challenges due to the widespread nature of the pandemic, causing obstacles in supply chains and disruptions in production. This led to significant financial difficulties for many firms. Secondly, due to the unpredictable nature of the pandemic, it was challenging to determine when it would be safe to resume work and production. Although the government allowed some factories to resume operations, any instance of illness resulted in temporary shutdowns, leading to discontinuity in production and bankruptcy for many firms. Thirdly, enterprises faced significant operational risks due to supply chain and capital chain disruptions, which were formidable challenges for businesses during the pandemic. The sharp drop in orders and cost pressures further intensified these risks. Fourthly, the pandemic led to changes in consumer behavior, with a significant shift in demand towards contactless services and essential goods. This created an emergent need for a responsive supply system, which presented challenges for startups in terms of funding and profitability. Overall, these outcomes illustrate the multidimensional challenges presented by the COVID-19 pandemic and have significant implications for businesses and policymakers alike.

Start-ups face significant challenges and vulnerabilities in competing in the market. They frequently encounter issues such as insufficient funding, talent shortages, and difficulties in developing their businesses. The COVID-19 pandemic has further amplified these issues, endangering the survival of many start-ups. The pandemic has caused widespread production disruptions, depressed domestic consumption, and inflexible expenses related to rents, wages, and interest expenses, all of which have put immense strain on start-ups' fragile capital chains. As a result, a substantial number of start-ups have faced bankruptcy. The pandemic has had profound implications for the start-up ecosystem, highlighting the importance of robust and adaptable business models and adequate resources for start-up survival.

This paper aims to examine the impact of the COVID-19 pandemic on the number of new startups in China. Specifically, we use monthly province-level data to measure the number of startups based on the number of new registered enterprises in all 31 provinces in China. Through this research, we seek to determine whether the lockdown measures imposed during the pandemic had a significant effect on the establishment of new startups in China. Additionally, we aim to provide empirical evidence on the development of entrepreneurship in China.

The economic ramifications of COVID-19 have been extensively studied by researchers, who widely agree that the pandemic has significantly impacted the global economy. COVID-19 has led to reduced demand, factory closures, negative sales gaps, and long-lasting scars. Policymakers face a difficult trade-off between preserving public health and maintaining income and employment, while also potentially limiting mobility. Lockdown policies have resulted in reduced income and expenditure for residents, with their spending serving as a direct source of income for other residents and enterprises. In China, the rapid spread of COVID-19 has disrupted normal life, with the potential for long-term effects on the country's economy. The intensification of the pandemic may have significant implications for China's economic future.

COVID-19 has resulted in both short-term and long-term economic shocks. In the short term, China's lockdown policies, which include isolation and social distancing measures, have reduced domestic market demand and led to unemployment. Research focusing on Chinese agriculture found that the sector suffered due to a decrease in global demand for Chinese agricultural products in 2020. Looking ahead to the long term, the demand shock induced by lockdown policies in France is believed to be temporary, with the economy potentially recovering towards its baseline trajectory over the following decade.

In recent times, the level of entrepreneur in developing countries has been linked to the wealth and poverty of these nations, yet it remains one of the least studied significant economic and social phenomena. Researchers studying entrepreneurship and startups have focused on corporate social responsibility of Small and Medium-Sized Enterprises (SMEs), which offers an explanation for the lack of responsible entrepreneurship among SMEs and lists obstacles to entrepreneurship in developing countries. With regards to the pandemic period, estimates suggest that the disruptions caused by COVID-19 may have long-lasting effects on employment, with the potential for substantial losses lasting over a decade even if the slump in startup activity is only temporary. Furthermore, lockdown policies have had a negative impact on firm creation, which has significant policy relevance.

_1.2 Introduction of the impact of COVID-19 on local government public finance in China_The rapid spread of the Covid-19 epidemic has caused major economies to suffer and led to stagnating global economic growth. China's economic and social development has also been seriously impacted. From 2011 to 2020, the scale of local fiscal expenditures in China has been larger than the scale of revenues, leading to a widening fiscal balance year by year. Since 2015, the growth rate of fiscal expenditure has exceeded the growth rate of revenue, aggravating the contradiction between revenue and expenditure. Although local public budget expenditure in 2020 increased by 3.36% year-on-year to 210.583 billion yuan.

According to fiscal data released by the Ministry of Finance by the end of 2022, China's economy experienced mixed results with national public budget revenue reaching 20,370,348 million yuan, up 0.6% from 2021. National public budget expenditures totaled 26,194,480 million yuan, an increase of 6.1%. Meanwhile, China's local government debt balance rose to 16.47 trillion yuan from 15.32 trillion yuan in 2021, up 7.51% year-on-year. Of this amount, general debt accounts for 62.70% and special local government debt accounts for 37.30%.

The impact of the epidemic in 2020 has led to a faster growth rate of health affairs expenses in each local government's fiscal expenditures. Due to the decline in local tax revenue caused by the sequestration, fiscal revenue is less robust, and the sustainability of the debt decreases. In addition, some local governments are dependent on land finance, with concessions of state-owned land use rights becoming the main source of government fund revenue.

Public finance is the foundation and important guarantee of nation-building and governance. It not only reflects the national economic situation comprehensively but also lays the foundation for the national government to carry out macro-control of the market economy. Fiscal revenue is an important indicator to measure the financial status of local governments. The abundance and stability of fiscal revenue determine the ability of local governments to provide public goods and services in economic and social activities. The financial relationship between central and local government is essential for understanding the composition of local government revenue and expenditure.

Central-local fiscal relations generally include three aspects: first, the division of revenue, which mainly refers to how government revenues, mainly from taxes, are allocated between the central and local governments. Taxes are usually categorized according to their attributes, with taxes that reflect national sovereignty being classified as central government revenue, such as customs duties and import taxes, while taxes with a relatively stable tax base and clear regional attributes are classified as local government revenue, such as property taxes and municipal taxes. Taxes with strong liquidity and uneven distribution between regions are classified as central government revenue or shared revenue, with the central government usually having a higher share.

Second, the division of fiscal powers and expenditure responsibilities is based on three principles. The first is the principle of scope of benefits, which means that if a certain expenditure affects areas outside the region and has certain externalities, it should be borne by a higher level of government. The second is the principle of complexity of information, which means that the more complex the information acquisition and processing is, and the more likely it is to cause information asymmetry, the more it should be the responsibility of local and especially grassroots governments. The third is the principle of stimulating initiative, which means that the division of fiscal powers should fully reflect the matching of rights and responsibilities, which is conducive to the active performance of duties and incentives and achieving overall maximization of benefits.

Third, the transfer payment system typically includes two types of payments: general transfer payments and special transfer payments. The former is an unconditional grant, while the latter must be used for designated purposes. General transfer payments are primarily used to subsidize local affairs, whereas special transfer payments are mainly employed for centrally entrusted affairs, central and local joint affairs, and local affairs requiring guidance and encouragement. Additionally, there are some transfer payment models that lie between general and special transfer payments, such as the classification transfer payment model for central and local joint affairs involving basic livelihoods, like education and health. In general, local government revenue mainly comes from two sources: on one hand, the income of party-owned enterprises and various tax revenues, which include business tax, local enterprise income tax, personal income tax, urban land use tax, and land value-added tax; on the other hand, there are fiscal transfer subsidies from the central government.

Fiscal expenditures are primarily divided into education, medical, and social security expenditures, reflecting the government's investment in constructing basic livelihood protection. Total financial expenditure mainly consists of capital expenditure, science and technology support costs, industrial transportation business expenses, and health business expenses, among others.

Local government debt refers to the debt raised or guaranteed by the local government as the debtor in the name of the government, and the resulting obligation to repay the funds. It is issued as a form of revenue-raising for local governments, and its revenue is included in local government budgets and arranged and dispatched by local governments. It is an essential means for local governments to raise funds to cover their fiscal deficits. By 2013, the total outstanding local government debt as a percentage of provincial revenue exceeded 100 percent for all provinces, and in some poorer provinces, the ratio was as high as 500 percent (Adam Y. Liu et al. 2022).

Since the Tax Sharing Reform in 1994, the local government revenue of the People's Republic of China (PRC) has faced downward risk problems (Ziying Fan et al. 2007). With the outbreak of Covid-19 in 2020, local governments in China have implemented non-pharmaceuticalinterventions, such as isolating confirmed patients and their close contacts, closing public places like schools, limiting or stopping market gatherings, restricting transportation, and issuing domestic and international travel bans. Although containment measures and the extent of the epidemic varied across cities, local fiscal pressure increased from 0.38 to 0.435, a rise of 14.53%, and the fiscal revenue and expenditure gap accounted for almost half of the local fiscal revenue (Yue Mei Guo et al. 2021). The lockdown policy directly or indirectly affected local government revenue capacity, and this paper will analyze the impact of different urban outbreak indicators on local government finances.

_2. Hypothesis Development_

_2.1 Hypothesis Development_ of _the Impact of Lockdown on Startups_

Drawing upon a literature review and identifying a research gap, this study aims to develop hypotheses H1a, H1b, and H1c to test the effect of lockdown measures on startups in China during the COVID-19 pandemic. The primary objective is to investigate the relationship between the stringency of lockdown measures and the number of newly registered startups. Specifically, this study aims to test the following hypotheses:

**H1: There is a significant negative relationship between the stringency of lockdown measures and the number of startups in China during the COVID-19 pandemic.**

Hypothesis 1 (H1) posits that the imposition of stringent lockdown measures by the government to curb the spread of COVID-19 has had an adverse effect on the entrepreneurial ecosystem. The restrictions on movement, social interactions, and business operations may have deterred potential entrepreneurs from initiating new businesses, resulting in a decline in the number of startups.

_2.2 Hypothesis Development of the Impact of COVID-19 on Local Government Public Finance_The hypothesis H2 of this study is that the Covid-19 pandemic has had a negative impact on the public finance of local governments in China. This hypothesis is based on the assumption that the containment measures taken to control the spread of the virus have directly or indirectly affected the revenue-generating capacity of local governments, leading to a decline in fiscal revenue. Additionally, the increased need for public health spending and economic support measures during the pandemic is expected to have resulted in an increase in local government expenditure.

**H2: The Covid-19 pandemic has negatively affected the public finance of local governments in China. H3: The Covid-19 pandemic has positively affected the public finance of local governments in China.**

To test H2 and H3, the study will employ a two-way fixed effects regression model, using data from 39 Chinese cities on a monthly basis. The model will control for potential confounding factors such as CPI and local house prices.

_3. Data and Research Design_

_3.1.1 Sample Selection of the Impact of Lockdown on Startups_

This study employs monthly province-level data from 2020 to 2022, encompassing all 31 provinces in China, and comprises a total of 1,116 observations.

The number of newly registered businesses is adopted as the primary measure of startups in this study, whereby newly registered businesses refer to those registered with the administrative department for industry and commerce in accordance with national laws, regulations, and relevant provisions. The monthly number of newly registered businesses collected illustrates a steady increase over time. All data utilized in this study are monthly provincial data, sourced from the Wind dataset.

To determine the stringency of lockdown measures in each province, this study uses data from the Oxford COVID-19 Government Response Tracker (OxCGRT) program, which comprises 23 indicators encompassing school closures, travel restrictions, and vaccination policy. The average stringency index is chosen as the indicator of lockdown measures, which ranges from 0 to 100, with higher values denoting stricter lockdown measures. Notably, the lockdown policy was first implemented in Wuhan in January 2020 and was gradually extended to all 31 provinces included in this study, with the country's government declaring the lifting of COVID-19 lockdown in December 2022.

_3.1.2 Sample Selection of the Impact of COVID-19 on Local Government Public Finance_

This section focuses on studying the impact of the Covid-19 epidemic on fiscal revenues, fiscal expenditures, and government debt of thirty cities, using monthly data. The epidemic intensity indicator is measured by the monthly number of confirmed patients in the relevant cities, while macro indicators such as CPI and local house prices are considered as control variables. The data sources include the Finance Bureau of each city, the National Health Commission of the People's Republic of China, and the National Bureau of Statistics of China.

It should be noted that fiscal data for January of each year are excluded from this study because fiscal data are cumulative, and some cities publish data to unify January and February as February releases (important point).

In terms of indicator selection, this section uses the number of diagnosed patients in cities to measure the local epidemic risk level. Additionally, due to differences in price levels in different places and the fact that land concessions account for a large proportion of local government finances, this section also uses the house prices of each city as an explanatory variable.

In this section, all the data are monthly. The data on local government public finance, CPI, and GDP are sourced from the Wind dataset. As fiscal data for local governments are typically collected monthly, some local governments may have missing data for the month of January. Therefore, to ensure data consistency, this paper excludes all January data from the analysis. The data on the number of confirmed patients in each city is sourced from the Covid-19 record program.

For the variable public expenditure, the sample mean is 973.45 with a standard deviation of 1272.13, a minimum value of 416, and a maximum value of 8430.9. For the variable public revenue, the sample mean is 792.01 with a standard deviation of 1150.81, a minimum value of 328.47, and a maximum value of 7771.8. For the variable CPI, the sample mean is 101.97 with a standard deviation of 1.11, a minimum value of 97.8, and a maximum value of 105.9. For the number of confirmed patients, the sample mean is389.4 with a standard deviation of3966, a minimum value of 0, and a maximum value of 50431.

#### 3.2.1 Research Design of the Impact of Lockdown on Startups

To study the effect of COVID-19 on startups, we use difference-in-difference as the identification strategy and estimate the following regression:

\[\text{Startups}_{\text{it}}=\alpha+\beta_{1}\text{Stringency}_{\text{it}}* \text{Province}_{\text{i}}+\beta_{2}\text{Province}_{\text{i}}+\beta_{3} \text{Time}_{\text{t}}+\varepsilon_{\text{it}},\]

Tuple 28:
Cleaned Title: hymap eliciting hypothesis earlystage software startup using cognitive mapping
Cleaned Transcription: hymap eliciting hypothesis earlystage software startup using cognitive mapping footnote document accepted manuscript following paper please cite j melegati e guerra x wang hymap eliciting hypothesis earlystage software startup using cognitive mapping information software technology vol p apr doi httpsdoiorgjinfsofhttpsdoiorgjinfsof jorge melegati jorgemelegatiunibzit eduardo guerra eduardoguerraunibzit xiaofeng wang xiaofengwangunibzit free university bozenbolzano piazza domenicani bolzano italy abstract context software startup develop innovative softwareintensive product given uncertainty associated innovative context experimentation approach based validating assumption software product data obtained diverse technique like ab test interview valuable company relying data rather opinion reduces chance developing unnecessary product feature improving likelihood success especially early development stage implementing unnecessary feature represents higher risk company survival nevertheless researcher argued lack clearly defined practice led limited adoption experimentation since first step approach define hypothesis testable statement software product feature based software development team create experiment eliciting hypothesis natural first step develop practice objective aim develop systematic technique identifying hypothesis earlystage software startup support experimentation company consequently improve software product method followed design science approach consisting artifact construction process divided three phase evaluation within three startup result developed hymap hypothesis elicitation technique based cognitive mapping consists process conducted facilitator using predefined question supported visual language depict cognitive map representing founder understanding product evaluation showed founder perceived artifact clear easy use useful leading hypothesis facilitating idea visualization conclusion theoretical perspective study provides better understanding guidance founder use develop startup practical point view technique identify hypothesis earlystage software startup keywords hypothesis engineering software startup experimentation hypothesis elicitation footnote work licensed creative common attributionnoncommercialnoderivatives international introduction good sense thing among men equally distributed phrase descartes begin discourse method changed science human history book philosopher introduces scientific method systematic way derive knowledge based experiment recently new trend strengthens idea systematically deriving knowledge rather relying personal intuition product software engineering experimentation approach process continuously validating product assumption transforming hypothesis prioritizing applying scientific method test hypothesis supporting refutingthem context practitioner employ several technique like iteration prototype gradual rollouts controlled experiment also problem solution interview recent position paper compared different model experimentation like hypex right observed model follow common step first software development team identify specify prioritize hypothesis based hypothesis design execute experiment finally analyze data collected confirm refute hypothesis drawing parallel requirement engineering activity employed requirementdriven approach call step identify specify prioritize hypothesis hypothesis engineering argued need systematic practice activity given confusion term assumption hypothesis especially among practitioner often use interchangeably fundamental differentiate throughout paper assumption refers personal teamwise generally implicit understanding taken truth without questioned proved meanwhile hypothesis explicit statement proved yet could tested experiment short assumption cognitive abstract idea could transformed hypothesis concrete element employed experimentation instance product owner belief user ecommerce website want save product bought later based assumption team develops functionality product owner instead want test assumption valid hypothesis statement could created user want save product bought later team could use hypothesis create experiment ass example showing user button providing new function gauge interest function without implementing feature paper target hypothesis engineering context software startup software startup organization looking sustainable business model innovative product service develop software core element although quickly identify several successful story like airbnb uber startup fail reason lack success various demanding market condition lack team commitment financial issue including inaccurate business development creation nonviable business model since defining characteristic software startup development innovative solution experimentation critical element context value experimentation corroborated idea lean startup wellknown methodology among practitioner place strong emphasis experimentation nevertheless startup still tend focus developing proposed solution instead focusing necessary learning process aspect essential especially earlystage startup developing wrong feature may represent total consumption limited financial human resource available company lead company ending one reason limited adoption experimentation lack clearly defined practice therefore essential step better implementation experimentation systematic way specify handle hypothesis study goal develop novel technique identify hypothesis earlystage software startup base product based hypothesis company could perform experiment progress precise information user market need therefore guide study proposed following research question rq hypothesis systematically defined earlystage software startup support experimentation achieve goal followed design science research dsr approach based hevner et al guideline consisting artifact construction evaluation artifact construction step composed three phase first phase goal understand assumption startup base product formed second third phase proposed assessed improved hymap technique elicit hypothesis based cognitive mapping systematically created set question evaluated practice using multiplecase study three software startup result indicate founder perceive technique clear easy use selfcontained useful leading hypothesis three type problem value product paper extends previous paper presented first two phase study study contributes practice providing novel hypothesis elicitation technique earlystage software startupsand theory describing founder create idea based previous experience step process relate different type hypothesis remaining paper organized follows section present background related work including justificatory knowledge support artifact effectiveness section present dsr method performed artifact development process evaluation section detail intermediate result artifact development process section describes final artifact section present evaluation section discus result finally section concludes paper background related work gregor hevner made distinction descriptive knowledge omega prescriptive knowledge lambda descriptive knowledge concern phenomenon including law theory describe natural artificial human phenomenon prescriptive knowledge focus humanbuilt artifact including construct model method according gregor hevner dsr important review descriptive prescriptive knowledge avoid lack novelty consequently potential lack contribution knowledge besides literature review include justificatory knowledge element used inform artifact construction explain effectiveness organized section fulfill requirement also present key concept study section present concept related software startup lifecycle section display process experimentation software engineering including hypothesis engineering section present available solution scientific practitionerproduced literature argue need study finally section present cognitive mapping use model business model software startup definition software startup consensus literature common aspect innovation uncertainty blank proposed definition generally adopted practice startup organization formed search repeatable scalable business model search viable business model novel softwareintensive product defining aspect software startup contrasting organization development team significant contributor uncertainty company face therefore paper use following definition software startup organization looking sustainable business model innovative product service develop software core element however company equal organizational perspective rather display different development stage based literature klotins et al proposed lifecycle model analyze startup progress composed four stage inception stabilization growth maturity first stage start idea end first product release next stage startup prepares scale regarding technical operational perspective growth stage startup aim reach desired market participation finally last stage progress established company summary early stage ie inception stabilization team focus finding relevant problem feasible solution later stage ie growth maturity focus marketing efficiency decided initially focus earlystage startup given two reason first lack testing assumption customer market represents higher risk startup survival since stage company generally many resource second later stage hypothesis obtained technique might already validated refuted product usage previous stage experimentation hypothesis engineering software engineering research experimentation least two meaning initially meant use scientific experiment guide research software engineering example seminal book wohlin et al describe several empirical strategy software engineering research recently term used describe process continuously validating product assumption transforming hypothesis prioritizing applying scientific method test hypothesis supporting refuting thisconcept encompasses several technique like iteration prototype gradual rollouts controlled experiment also problem solution interview adopted second connotation paper literature model describe experimentation general right hypex qcd model presented process cyclical approach consisted continuously executed step identify specify prioritize hypothesis design experiment execute analyze result update hypothesis accordingly nevertheless model describe hypothesis could systematically identified previous paper called step identifying specifying prioritizing hypothesis hypothesis engineering explore currently available practice hypothesis handling context software startup performed gray literature review practitionersproduced document identified document analyzed using thematic synthesis concluded practice could divided five activity elicitation prioritization specification analysis management available solution valuable piece prescriptive knowledge come practitioneroriented literature customer development lean startup latter huge success among practitioner consisted taking founder assumption hypothesis building experiment evaluate based result persevere pivot change another idea one criticism lean startup precisely lack operationalization instance bosch et al proposed earlystage software startup development model esssdm tackle problem consisted three part idea generation prioritized backlog funnel funnel comprises four step problem validation solution validation smallscale minimum viable product validation largescale minimum viable product validation funnel idea validated generate idea author suggested exploratory interview brainstorming following potential customer understand need exploration currently available practice handle hypothesis software startup identified several proposal elicit hypothesis classified similar proposal five category common category analyzed document consisted technique based canvas map best example assumption mapping technique recently proposed bland et al consists using series canvas including business model canvas bmc create hypothesis although bmc initially based ontology systematically developed assumption mapping neither derived evaluated scientifically second common category use predefined set question aspect consider instance customer problem solved product solve customer problem following category proposed technique suggested execution team session member could reach hypothesis based facilitation technique fourth category practice proposed describe individual technique founder could use reach hypothesis five why finally another suggestion use problem solution interview elicit hypothesis although several available practice hypothesis elicitation none systematically derived evaluated cognitive mapping business model concept plethora different definition used academic literature furnari described two theoretical perspective business model research activitybased perspective describes business model system activity firm use create capture value cognitive perspective considering cognitive instrument represent activity based cognitive perspective furnari proposed use cognitive map represent business model cognitive map visual representation causal aspect person belief system graph node represent concept individual use arrow causal link arrow generally labeled according type relationship positive one negative one neutral one cognitive map supported kelly personal construct theory state person look world pattern template called construct person creates try fit reality kelly also describes personasascientist idea scientist man seek predict thus control course event construct intended aid predictive effort brannback et al already discussed relationship cognitive mapping personal construct theory entrepreneur author argued entrepreneur need make sense hisher reality predict control find solve problem one essential aspect software startup founder influence product definition seppanen et al investigated competency initial team software startup observed strong influence founder action competency related business product creation nascent company based described far software startup business model strongly influenced founder perceive mentally model environment use model predict market future product behave research shown influence strong enough prevent use experimentation instance investigating limited adoption implementation experimentation software startup melegati et al identified inhibitor fact founder often overconfident idea deeming experiment evaluate unnecessary focusing developing solution giardino et al argued focus launching product one key challenge earlystage software startup face cognitive mapping could used materialize assumption regarding several aspect software product customer market technology startup founder base idea put position challenged eden point seeing idea form visualization people encouraged change mind technique used software engineering instance problem structuring requirement engineering decision model distributed software development agile method elicit cognitive map divided two group depending data obtained initially researcher used document source evidence perform content analysis develop map another way direct method researcher develop map situ interacting subject cognitive map elicited direct method employ two divergent approach pairwise judgment causal relationship capture visual form first form subject answer questionnaire combination concept evaluated based answer map built second form subject help facilitator build visual representation using paper pencil software solution pairwise approach better coverage expense difficult le engaging le representative freehand technique since startup context defined time resource constraint effective approach targeted company timeconsuming therefore visual approach suitable research method given research goal question aim solve realworld problem instead trying understand defined phenomenon unfolds goal develop artifact act world regard design science research dsr suitable method approach often used information system research shown several methodological guideline eg hevner et al peffers et al wieringa even special issue mi quarterly although use often explicitly mentioned software engineering research analysis awarded paper international conference software engineering engstrom et al showed study actually could classified dsr although explicitly using term recently though researcher explicitly used methodology tackle problem software engineering like gamification eg requirement eg research followed guideline proposed hevner et al according author dsr seek develop innovative artifact relying existing kernel theory applied tested modified extended experience creativity intuition problem solving capability researcher artifact could construct model method instantiation construct represent language used describe world model use represent realworld situation method define process guide solve problem finallyinstantiations demonstrate previous element could used scenario based classification artifact developed study method allowing earlystage software startup identify hypothesis guide experiment dsr study essential describe artifact development process evaluation study design artifact development process consisted three phase first two already described previous paper fig summarizes research method first phase understanding goal understanding team form assumption base product achieve goal performed multiplecase study two earlystage software startup result indicate requirement based team especially founder assumption market customer behavior second phase proposing used cognitive mapping make founder assumption explicit stage technique consisted using box arrow described cognitive mapping employment openended talk founder described understanding facilitator drew map assessed first version method two software startup result indicate approach could base comprehensive practice elicit hypothesis software startup however still lacked operationalization third phase improving improved technique defining specific notation different concept customer product feature creating list question guide cognitive map creation since startup complex phenomenon many variable founder background product market blurred boundary phenomenon context exists case study suitable choice evaluate technique company according yin one rationale research approach representative typical case therefore selected software startup mentioned founder one initial idea besides followed klotins et al lifecycle model selected startup inception stabilization phase guided development evaluation process according defined criterion utility quality effectiveness first fulfill utility criterion artifact aim value outside development environment therefore using artifact founder able create hypothesis real situation startup participated study utility associated perceived usefulness generally used explain adoption software development methodology eg technology general perceived usefulness refers degree developer expects following methodology improve individual job performance context experimentation software startup operationalize concept obtaining hypothesis build experiment regarding quality artifact evaluated several attribute completeness usability consistency study selected three attribute focus evaluation ease use clarity selfcontainedness since ultimate goal impact real startup consider method future adoption regard taking artifact innovation complexity factor influencing adoption therefore founder must perceive technique easy use concept process step clear selfcontained work independently applying facilitating providing detail proper use allowing anyone use rather depending figure research method including artifact construction process evaluation facilitator experience finally method description clear making comprehension straightforward finally artifact effective producing expected result case goal reveal hidden assumption founder product environment potential customer systemically elicit hypothesis would basis experiment following method aim satisfy seven guideline proposed hevner et al dsr design artifact dsr must produce viable artifact problem relevance goal develop solution relevant problem design evaluation utility quality efficacy artifact rigorously demonstrated research contribution dsr project provide clear verifiable contribution regarding design artifact design foundation andor design methodology research rigor dsr apply rigorous method construction evaluation artifact design search process dsr process inherently iterative search best optimal solution unfeasible goal feasible good design representing satisfactory solution communication research dsr solution presented effectively since target artifact method satisfy g argument importance experimentation earlystage software startup fulfills g following section describe design artifact g development process g evaluation g section discus research contribution g paper previous one communicate result g artifact design process section describes three phase artifact construction process understanding proposing improving detail including research method data collection analysis result obtained first phase understanding phase goal understand team form assumption base product selected two startup called b located italian technological park moment data collection startup b participated incubation process startup used space available data collection consisted semistructured interview followed predefined guide case interviewed founder case b also software developer interview question aimed understand interviewee background idea motivation build product changed throughout company history since goal understand assumption used create product came data analysis consisted explanation building causeeffect relationship sought looking explanation case case time data collection startup developing library added software development project company planned provide dashboard show live software runtime issue like exception detected inferred data collected within target system dashboard would also show solution similar problem found website focused programming issue stack overflow list freelance developer could solve problem case system would able fix issue automatically startup team consisted five people working parttime project spread across software development business plan marketing strategy founder worked software development consultant extended period participating thirdparty project observed tool could help work effectively besides believed technical level software developer decreasing therefore would make sense develop tool time data collection startup initial prototype consisted dashboard dummy data website presenting idea case b startup running website help hotel owner manager find best softwaresolutions business initial focus italian market aimed reach international market team consisted two founderspartners one developer founded company left partnership intern help administrative task performed interview founder original idea developer interviewed founder background online marketing worked company handled web marketing website staying twelve year large web agency last job worked director company technology business unit throughout work life extensive contact tourism sector especially hospitality industry founder told idea based need observed hotel owner many technological tool available run business software vendor reach customer founder inspiration american software review website compare different software solution particular market segment lack specific one hospitality sector therefore original idea list available software solution user review attract hotel owner website receive commission vendor interested customer visited website founder said original version gone online team started observing website usage data realized going expected team observed hotel owner able compare different software solution product rarely set feature sometimes hotel needed one software system fulfill requirement startup changed website ask hotel owner fill online form giving detail business based information provided system would match solution adapted business need interview developer clear influence idea limited thought good idea experience market trusted founder regarding business focused developing solution moment data collection startup customer base growing close breakeven looking expand market crosscase analysis common aspect case b based previous experience founder formed set belief explain specific market function customer behave based understanding founder predict potential customer would behave exposed product service instance startup b founder considered hotel owner wanted buy software solution able compare different alternative select best suited case based founder foresaw website list available software solution would useful hotel owner would able see solution select one would fit need fig summarizes process founder previous experience lead assumption customer market used forecast behavior customer new product idea process related founder innovation owner experience motivator startup product idea discussed literature startup b software ready website went online usage data showed result predicted hence founder update assumption customer change product accordingly new implicit theory emerged experiment result led company better result within market nevertheless reach stage startup figure process idea creation dashed line represent previous understanding background founder led idea adapted spent resource developing whole product could done earlier team analyzed customer rearrangement exposed implicit process model development software startup process founder assumption guide elicitation requirement data generated software usage may impose change set assumption founder us updated representation world elicit new requirement fig depicts process causal chain researchconstructed linear display action andor state suggests plausible interrelated sequence event second phase proposing based first phase result hypothesis elicitation approach make explicit founder underlying assumption customer market phase goal evaluate feasibility using cognitive mapping make assumption explicit adapted approach proposed furnari using whiteboard depict current status mapping founder help aimed create cognitive map representing founder belief startup business model work detailed step ask founder describe business model concerning value proposition customer extract concept causal relationship inspect concept see reality based underlying assumption check founder map represented way problem understood moment evaluated initial proposal two italian software startup c performed interview session following defined protocol present concept hypothesis lean startup related ask interviewee describe business product idea especially regarding customer segment value proposition ask hypothesis founder believed idea based using whiteboard interacting founder draw cognitive map map represented understanding market create list hypothesis based cognitive mapping compare initially created list ask feedback process founder describe result case case c case c earlystage software startup planning develop digital mentor software developer increase happiness satisfaction product would adapt developer need company interested improving developer productiveness would pay fee make solution available team asked hypothesis founder mentioned already worked others planning evaluate first hypothesis software development team could organize interview got invalidated changed initial idea current one following hypothesis interviewee called exploration understand software developer care soft skill asked hypothesis founder said waiting another round test fig display representation cognitive map derived case process founder stated main element increase developer productivity would making work fun gamification arrow figure imply seven hypothesis developer productivity improves company result developer satisfaction improves developer productivity making development work fun improves developer productivity developer satisfaction gamification could make developer work fun making development work fun would increase company satisfaction increasing company result improve satisfaction figure founder assumption updated shown although identified hypothesis straightforward may demand proper experiment considered validated founder acknowledged see correlation fun productivity exists major risk case case developing software solution improve perceived quality connection internet especially location quality level low small mountain village innovative approach solution would make network status transparent enabling user adapt need improve quality service request interviewee detail product included article beginning interview founder explained considered main hypothesis concerned size lowquality area internet provider willing quickly fix problem mentioned talking many potential customer regarding solution would like solution fig depicts cognitive map developed session arrow five implied hypothesis increasing network efficiency improve user satisfaction making network transparent decrease user satisfaction making network transparent increase user willingness react bad quality internet connection user willingness ability react increase user satisfaction making network transparent increase user willingness react confronted hypothesis founder mentioned already thought nevertheless using word process made explicit structured although result promising observed process cognitive map elicitation repeatable highly dependent interviewer experience besides interviewer felt lack guidance properly conducting step another aspect observed lack uniformity box content concept noun others action event based improved technique next phase regarding expected attribute defined section artifact useful easy use effective improve quality selfcontainedness clarity third phase improving based previous phase result need systematic approach evident achieve goal focused developing proper visual language build map systematic method elicit founder since artifact development design search process figure cognitive map created interview founder startup c number included identify hypothesis figure cognitive map created interview founder startup number included identify hypothesis performed series map elicitation session potential founder subject phase necessarily created startup idea opinion could potentially basis new solution session evaluated process improved artifact make language process precise session occurred online researcher shared screen drew cognitive map using software diagramsnet interviewee help result reached satisfactory level considered artifact design process completed footnote httpsappdiagramsnethttpsappdiagramsnet following approach performed three session first two brazilian entrepreneur third based italy session tried improve visual language map elicitation process based previous session result table describes improvement applied technique session respective result hymap hypothesis elicitation using cognitive map earlystage software startup hymap method developed study process conducted facilitator draw cognitive map extract hypothesis based visual language depict map visual language represent startup founder cognitive map depict cognitive map support elicitation process developed visual language adapting cognitive mapping symbol described section differentiate concept represented consisted following element circle represent customer segment ellipsis used denote proposed solution dottedline box portray software feature solidline box represent concept either physical abstract filled noun arrow connect box circle box represent relationship among three type relationship offering influence perception defined type shape connected offering arrow connect solution feature represent product offer functionality influence arrow similar conventional cognitive map mentioned section represent one concept influence intensity labeled one sign denote type respectively one concept increase decrease influence perception arrow connect customer problem represent customer perceive concept issue restriction number inbound outbound arrow box must represent acyclical graph pattern construction lead layer element map shown fig product layer represent product feature layer represent feature founder expect product problem layer one layer element represent aspect founder think product feature solve finally customer layer represent expected customer user product figure template hymap map eliciting startup founder cognitive map hypothesis first step reach hypothesis elicit founder cognitive map reach goal propose iterative approach based map current status founder analyze relationship arrow consider underlying concept facilitator help founder process following predefined set question drawing map according visual language clarifying question founder understand way founder focus business question facilitator previously used technique asks founder question handle drawing facilitator could also ask clarification detail clear beginning process initial map created based following question productsolution name customer targeted solution customer aspect actor expects improve using solution solution feature envisaged aspect previous step fulfill based question answer facilitator put respective shape map connect arrow arrow founder judge concept implicitly used explain relationship question useful step new concept emerges new box representing added along new relationship arrow process repeated iteratively founder comfortable new concept added useful question evaluate process saturated possible create simple experiment evaluate relationship additionally founder must evaluate new concept added related concept already present map throughout process founder constantly ass map created coherent understanding customer market refine map founder add remove substitute element cognitive map finished say relationship represents assumption founder targeted customer value proposition product based formulate hypothesis based create experiment experiment piece software also interview questionnaire technique arrow originating different layer shown
Original Title: HyMap: eliciting hypotheses in early-stage software startups using
  cognitive mapping
Original Transcription: # HyMap: eliciting hypotheses in early-stage software startups using cognitive mapping+
Footnote †: This document is the accepted manuscript of the following paper (please cite as this): J. Melegati, E. Guerra, X. Wang. “HyMap: eliciting hypotheses in early-stage software startups using cognitive mapping.” Information and Software Technology, vol. 144, p. 106807, Apr. 2022, doi: [https://doi.org/10.1016/j.infsof.2021.106807](https://doi.org/10.1016/j.infsof.2021.106807).

Jorge Melegati

jorge.melegati@unibz.it

Eduardo Guerra

eduardo.guerra@unibz.it

Xiaofeng Wang

xiaofeng.wang@unibz.it Free University of Bozen-Bolzano, Piazza Domenicani 3, Bolzano, Italy

###### Abstract

**Context:** Software startups develop innovative, software-intensive products. Given the uncertainty associated with such an innovative context, experimentation, an approach based on validating assumptions about the software product through data obtained from diverse techniques, like A/B tests or interviews, is valuable for these companies. Relying on data rather than opinions reduces the chance of developing unnecessary products or features, improving the likelihood of success, especially in early development stages, when implementing unnecessary features represents a higher risk for companies' survival. Nevertheless, researchers have argued that the lack of clearly defined practices led to limited adoption of experimentation. Since the first step of the approach is to define hypotheses, testable statements about the software product features, based on which software development teams will create experiments, eliciting hypotheses is a natural first step to develop practices. **Objective:** We aim to develop a systematic technique for identifying hypotheses in early-stage software startups to support experimentation in these companies and, consequently, improve their software products. **Methods:** We followed a Design Science approach consisting of an artifact construction process, divided in three phases, and an evaluation within three startups. **Results:** We developed the HyMap, a hypotheses elicitation technique based on cognitive mapping. It consists of a process conducted by a facilitator using pre-defined questions, supported by a visual language to depict a cognitive map representing the founder's understanding of the product. Our evaluation showed that founders perceived the artifacts as clear, easy to use, and useful leading to hypotheses and facilitating their idea's visualization. **Conclusion:** From a theoretical perspective, our study provides a better understanding of the guidance founders use to develop their startups and, from a practical point of view, a technique to identify hypotheses in early-stage software startups.

keywords: hypotheses engineering, software startups, experimentation, hypotheses elicitation +
Footnote †: This work is licensed under a Creative Commons “Attribution-NonCommercial-NoDerivatives 4.0 International”

## 1 Introduction

"Good sense is, of all things among men, the most equally distributed" [1]. With this phrase, Descartes begins his _Discourse on the method_ that changed science and human history. In that book, the philosopher introduces the scientific method, a systematic way to derive knowledge based on experiments. Recently, a new trend strengthens this idea of systematically deriving knowledge rather than relying on personal intuition about products in software engineering: experimentation [2, 3]. This approach is a process of continuously validating product assumptions, transforming them into hypotheses, prioritizing, and applying the scientific method to test these hypotheses, supporting or refutingthem [2]. In this context, practitioners can employ several techniques like iterations with prototypes, gradual rollouts, and controlled experiments [4] but also problem and solution interviews [2].

In a recent position paper [5], we compared different models of experimentation, like HYPEX [6] and RIGHT [7]. We observed that these models follow common steps. First, software development teams identify, specify, and prioritize hypotheses. Based on these hypotheses, they design and execute experiments and, finally, analyze the data collected to confirm or refute the hypotheses. Drawing a parallel to Requirements Engineering activities employed in a requirement-driven approach, we call the step to identify, specify, and prioritize hypotheses as Hypotheses Engineering and argued the need for more systematic practices for these activities.

Given the confusion between the terms "assumption" and "hypothesis," especially among practitioners that often use them interchangeably [8], it is fundamental to differentiate them. Throughout this paper, "assumption" refers to a personal or team-wise, generally implicit, understanding taken as truth without being questioned or proved. Meanwhile, a "hypothesis" is an explicit statement that has not been proved yet but could be tested through an experiment. In short, assumptions are cognitive and abstract ideas that could be transformed into hypotheses [2], concrete elements employed in experimentation. For instance, a product owner believes that the users of an e-commerce website want to save products to be bought later. Based on this assumption, the team develops the functionality. If the product owner instead wants to test if the assumption is valid, a hypothesis statement could be created: "the users want to save products to be bought later." The team, then, could use this hypothesis to create an experiment to assess it, for example, by showing some users a button providing a new function, to gauge their interest in that function, but without implementing the feature.

In this paper, we target hypotheses engineering in the context of software startups. Software startups are organizations looking for a sustainable business model for an innovative product or service they develop where software is a core element [9]. Although we can quickly identify several successful stories like Airbnb or Uber, most startups fail [10]. Reasons for the lack of success are various: demanding market conditions, lack of team commitment, financial issues [11], including an inaccurate business development [12], that is, the creation of a non-viable business model. Since a defining characteristic of software startups is the development of an innovative solution, experimentation is a critical element in this context [13]. The value of experimentation is corroborated by the ideas of Lean Startup [14; 15], the most well-known methodology among practitioners, which places a strong emphasis on experimentation.

Nevertheless, startups still tend to focus on developing their proposed solution instead of focusing on the necessary learning process [16; 17]. This aspect is essential, especially in early-stage startups for which developing wrong features may represent a total consumption of the limited financial and human resources available to the company and lead to the company ending. One of the reasons for this limited adoption of experimentation is the lack of clearly defined practices [2]. Therefore, an essential step for a better implementation of experimentation is a systematic way to specify and handle hypotheses [5]. In this study, our goal is to develop a novel technique to identify the hypotheses on which early-stage software startups base their products. Based on hypotheses, these companies could perform experiments and progress with more precise information about the user and market needs. Therefore, to guide this study, we proposed the following research question:

**RQ: How can hypotheses be systematically defined in early-stage software startups to support experimentation?**

To achieve our goal, we followed a Design Science Research (DSR) approach based on Hevner et al.'s guidelines [18] consisting of the artifact construction and evaluation. The artifact construction step is composed of three phases. The first phase's goal was to understand how the assumptions on which startups base their products are formed. In the second and third phases, we proposed, assessed, and improved HyMap, a technique to elicit hypotheses based on cognitive mapping systematically created through a set of questions. We evaluated the practice using a multiple-case study with three software startups. The results indicate that founders perceive the technique as clear, easy to use, self-contained, and useful leading to hypotheses of three types: problem, value, and product. This paper extends a previous paper [19] that presented the first two phases of this study. This study contributes both to practice, providing a novel hypotheses elicitation technique to early-stage software startups,and to theory, by describing how founders create their ideas based on their previous experience and how the steps in this process relate to different types of hypotheses.

The remaining of this paper is organized as follows: Section 2 presents the background and related work, including the justificatory knowledge [20; 21] to support the artifact's effectiveness. Section 3 presents the DSR method and how we performed the artifact development process and evaluation. Section 4 details the intermediate results of the artifact development process, Section 5 describes the final artifact, and Section 6 presents its evaluation. In Section 7, we discuss the results and, finally, Section 8 concludes the paper.

## 2 Background and Related Work

Gregor and Hevner [20] made a distinction between descriptive knowledge (\(\Omega\)) and prescriptive knowledge (\(\Lambda\)). While descriptive knowledge concerns the "what" about phenomena, including laws and theories to describe natural, artificial, or human phenomena, the prescriptive knowledge focuses on the "how" of human-built artifacts, including constructs, models, and methods. According to Gregor and Hevner, in DSR, it is important to review both descriptive and prescriptive knowledge to avoid the lack of novelty and, consequently, a potential lack of contribution to knowledge. Besides that, this literature review should include justificatory knowledge, that is, elements used to inform the artifact construction and explain its effectiveness [20; 21].

We organized this section to fulfill the above requirements but also to present key concepts for this study. Section 2.1 presents concepts related to software startups and their lifecycle, and Section 2.2 displays the process of experimentation in software engineering, including hypotheses engineering. In Section 2.3, we present available solutions from the scientific and practitioner-produced literature and argue the need for our study. Finally, Section 2.4 presents cognitive mapping and its use to model business models.

### Software startups

The definition of software startup is not a consensus in the literature [22; 23], but the most common aspects are innovation and uncertainty [23]. Blank [24] proposed a definition generally adopted in practice: a startup is an organization formed to search for a repeatable and scalable business model. This search for a viable business model for a novel software-intensive product is a defining aspect of software startups, contrasting these organizations to other development teams [25], and being a significant contributor to the uncertainty these companies face [16]. Therefore, in this paper, we use the following definition: software startups are organizations looking for a sustainable business model for an innovative product or service they develop where software is a core element.

However, these companies are not equal from an organizational perspective but, rather, display different development stages. Based in the literature, Klotins et al. [26] proposed a life-cycle model to analyze the startups' progress composed of four stages: inception, stabilization, growth, and maturity. The first stage starts with the idea and ends with the first product release. In the next stage, the startup prepares to scale regarding technical and operational perspectives. In the growth stage, the startup aims to reach the desired market participation, and, finally, in the last stage, it progresses into an established company. In summary, during the early stages, i.e., inception and stabilization, teams focus on "finding a relevant problem" and "a feasible solution." In the later stages, i.e., growth and maturity, the focus is on marketing and efficiency. We decided to initially focus on early-stage startups, given two reasons. First, the lack of testing assumptions about the customer and market represents a higher risk to the startup survival since, at this stage, the company generally does not have many resources. Second, in a later stage, the hypotheses obtained by the technique might have already been validated or refuted by the product usage in previous stages.

### Experimentation and Hypotheses Engineering

In software engineering research, experimentation has at least two meanings. Initially, it meant the use of scientific experiments to guide the research on software engineering. As an example, in a seminal book [27], Wohlin et al., describe several empirical strategies to software engineering research. Recently, the term is used to describe the process of continuously validating product assumptions, transforming them into hypotheses, prioritizing, and applying the scientific method to test these hypotheses, supporting or refuting them [2]. Thisconcept encompasses several techniques like iterations with prototypes, gradual rollouts, and controlled experiments [4] but also problem and solution interviews [2]. We adopted this second connotation in this paper.

In the literature, there are some models to describe experimentation in general, such as RIGHT [7], HYPEX[6], and QCD [28]. These models presented the process as cyclical approaches consisted of continuously executed steps [5]: identify, specify, and prioritize hypotheses; design an experiment; execute it; analyze results; and update hypotheses accordingly. Nevertheless, these models do not describe how hypotheses could be systematically identified.

In a previous paper [5], we called the step of identifying, specifying, and prioritizing hypotheses as Hypotheses Engineering. To explore currently available practices for hypotheses handling in the context of software startups, we performed a gray literature review [8] on practitioners-produced documents. We identified 95 documents, analyzed them using thematic synthesis, and concluded that these practices could be divided into five activities: elicitation, prioritization, specification, analysis, and management.

### Available solutions

Valuable pieces of prescriptive knowledge come from practitioner-oriented literature, such as the Customer Development [24] and the Lean Startup [29]. The latter had a huge success among practitioners and consisted of taking the founders' assumptions as hypotheses, building experiments to evaluate them, and based on the results, persevere or pivot, that is, change to another idea. One criticism against the Lean Startup is precisely its lack of operationalization. For instance, Bosch et al. [30] proposed the Early-Stage Software Startup Development Model (ESSSDM) to tackle this problem. It consisted of three parts: idea generation, a prioritized backlog, and a "funnel". This funnel comprises four steps: problem validation, solution validation, small-scale minimum viable product validation, and large-scale minimum viable product validation. Through this funnel, ideas are validated. To generate ideas, the authors suggested exploratory interviews, brainstorming, or following potential customers to understand their needs.

In our exploration of the currently available practices to handle hypotheses in software startups [8], we identified several proposals to elicit hypotheses. We classified similar proposals into five categories. The most common category in the analyzed documents consisted of techniques based on canvases or maps, from which the best example is Assumption Mapping. This technique, recently proposed by Bland et al. [31], consists of using a series of canvases, including the Business Model Canvas (BMC) [32], to create hypotheses. Although the BMC was initially based on an ontology systematically developed [33], Assumption Mapping has been neither derived nor evaluated scientifically.

The second most common category was the use of a pre-defined set of questions or aspects to consider. For instance, _which customer problems are to be solved? Can our product solve the customer problem_. Then, in the following category, proposed techniques suggested the execution of team sessions where members could reach hypotheses based on facilitation techniques. In the fourth category, practices proposed describe individual techniques the founder could use to reach hypotheses such as "the five whys". Finally, another suggestion is to use problem or solution interviews to elicit hypotheses. Although there are several available practices for hypotheses elicitation, none of them were systematically derived nor evaluated.

### Cognitive mapping

The business model concept has a plethora of different definitions used in academic literature [34]. Furnari [35] described two theoretical perspectives in business model research: an activity-based perspective that describes a business model as "a system of activities that firms use to create and capture value," and a cognitive perspective considering it as a cognitive instrument to represent those activities.

Based on the cognitive perspective, Furnari [35] proposed the use of cognitive maps to represent business models. Cognitive maps are visual representations of causal aspects of a person's belief system as a graph where nodes represent the concepts individuals use and arrows, causal links between them [35]. The arrows are generally labeled according to the type of relationship: '+' for a positive one, '-' for a negative one, and '/o/' for a neutral one. Cognitive maps are supported by Kelly's Personal Construct Theory [36] which states that a person looks at the world through patterns or templates, called constructs, that this person creates and, in which, tries to fit the reality [37]. Kelly also describes the person-as-a-scientist idea: "as a scientist, man seeks to predict, and thus control, the course of events" and these constructs "are intended to aid him in his predictive efforts" [37]. Brannback et al. [38] have already discussed the relationship between cognitive mapping and the personal construct theory with entrepreneur. The authors argued that "an entrepreneur needs to make sense of his/her reality to predict and control - to find and solve problems" [38].

One essential aspect of software startups is the founders' influence on the product definition. Seppanen et al. [39] investigated the competencies of initial teams in software startups. They observed a strong influence from founders on the actions and competencies related to the business and product creation in these nascent companies.

Based on what we have described so far, software startups' business models are strongly influenced by how their founders perceive, mentally model the environment and how they use these models to predict the market and how the future product will behave. Research has shown that this influence is strong enough to prevent the use of experimentation. For instance, while investigating the limited adoption and implementation of experimentation in software startups, Melegati et al. [40] identified as an inhibitor the fact that founders are often overconfident with the idea, deeming experiments to evaluate it as unnecessary and focusing on developing the solution. Giardino et al. [16] argued that this focus on launching the product is one of the key challenges early-stage software startups face.

Cognitive mapping could be used to materialize the assumptions regarding several aspects of the software product, such as customers, market, and technology, on which startup founders base their ideas and put them in a position to be challenged. As Eden [36] points out: "by seeing their own ideas in this form of visualization [people] are being encouraged to 'change their mind."' This technique has been used in Software Engineering, for instance, in problem structuring in requirements engineering [41] or a decision model for distributed software development with agile [42].

The methods to elicit cognitive maps can be divided into two groups depending on how data is obtained [43]. Initially, researchers used documents or other sources of evidence to perform content analysis to develop these maps. Another way is through direct methods where researchers develop the map _in situ_ by interacting with subjects from whom the cognitive map is elicited. These direct methods can employ two divergent approaches: pairwise judgments of causal relationships or capture through visual forms. In the first form, subjects answer questionnaires where all combinations of concepts are evaluated, and based on the answers, a map is built. In the second form, with the subject's help, a facilitator builds a visual representation using paper and pencil or software solutions. The pairwise approach has better coverage at the expense of being more difficult, less engaging, and less representative than the freehand technique [43]. Since the startup context is defined by time and resource constraints [23], an effective approach targeted to these companies should not be time-consuming. Therefore, a visual approach is more suitable.

## 3 Research method

Given our research goals and question, we aim to solve a real-world problem. Instead of trying to understand how a defined phenomenon unfolds, our goal is to develop an artifact to act on the world. In this regard, Design Science Research (DSR) is a suitable method. This approach is often used in Information Systems research as shown by the several methodological guidelines (e.g., Hevner et al. [18], Peffers et al. [44], and Wieringa [45]) and even a special issue in _MIS Quarterly_[46]. Although its use is often not explicitly mentioned in Software Engineering research, in an analysis of awarded papers in the _International Conference on Software Engineering_, Engstrom et al. [47] showed that most of these studies actually could be classified as DSR although not explicitly using the term. More recently, though, researchers have explicitly used the methodology to tackle problems in software engineering like gamification (e.g., [48]) and requirements (e.g., [49]).

In this research, we followed the guidelines proposed by Hevner et al. [18; 20]. According to the authors, DSR seeks to develop innovative artifacts relying on existing kernel theories "that are applied, tested, modified, and extended through the experience, creativity, intuition, and problem solving capabilities of the researcher" [18]. These artifacts could be constructs, models, methods, or instantiations. Constructs represent the language used to describe the world, and models use them to represent real-world situations. Methods define processes to guide how to solve problems and, finally,instantiations demonstrate how the previous elements could be used in a scenario. Based on this classification, the artifact developed in this study is a method allowing early-stage software startups to identify hypotheses to guide experiments.

In a DSR study, it is essential to describe the artifact development process and its evaluation [18]. For this study, the design artifact development process consisted of three phases where the first two were already described in a previous paper [19]. Fig. 1 summarizes the research method.

The first phase, Understanding, had the goal of understanding how teams form the assumptions on which they base their products. To achieve this goal, we performed a multiple-case study with two early-stage software startups. Our results indicate that requirements are based on the team's, especially the founder's, assumptions about the market, and customer behavior. In the second phase, Proposing, we used cognitive mapping to make founders' assumptions explicit. At this stage, the technique consisted of using boxes and the arrows as described in cognitive mapping and the employment of an open-ended talk where the founder described her understanding, and a facilitator drew the map. We assessed this first version of the method in two other software startups. Our results indicate that this approach could base a comprehensive practice to elicit hypotheses in software startups. However, it still lacked some operationalization. In the third phase, Improving, we improved the technique by defining specific notations for different concepts (customer, product, and features) and creating a list of questions to guide the cognitive map creation.

Since a startup is a complex phenomenon with many variables, such as founders' background, product, and market, and a blurred boundary between phenomenon and context exists, a case study is a suitable choice to evaluate a technique for these companies. According to Yin [50], one rationale for this research approach is the representative or typical case. Therefore, we selected software startups where, as mentioned before, the founder is the one who had the initial idea. Besides that, we followed Klotins et al.'s life-cycle model [26] and selected startups in the inception and stabilization phase.

We guided the development and evaluation processes according to defined criteria: utility, quality, and effectiveness. First, to fulfill the utility criteria, the artifact aims to have "value outside the development environment" [20]. Therefore, using the artifact, founders should be able to create hypotheses for real situations, that is, for startups other than those that participated in the study. Utility is associated with the perceived usefulness, which is generally used to explain the adoption of software development methodologies (e.g., [51; 52]) and technology in general [53]. Perceived usefulness "refers to the degree to which a developer expects that following a methodology will improve his or her individual job performance" [52]. In the context of experimentation in software startups, we can operationalize this concept by obtaining hypotheses to build experiments.

Regarding quality, artifacts can be evaluated from several attributes, such as completeness, usability, and consistency [18]. In this study, we selected three attributes to focus on this evaluation: ease of use, clarity, and self-containedness. Since our ultimate goal is to impact real startups, we should consider this method's future adoption. In this regard, taking the artifact as innovation, complexity is a factor influencing adoption [54]. Therefore, founders must perceive the technique as easy to use, and its concepts and the process steps as clear. It should be self-contained, that is, it should work independently to who is applying or facilitating it, providing all the details to proper use, allowing anyone to use it rather than depending on

Figure 1: The research method including the artifact construction process and its evaluation.

the facilitator's experience. Finally, the method description should be clear, making its comprehension straightforward.

Finally, the artifact should be effective; that is, producing the expected result. In our case, the goals are to reveal hidden assumptions, that founders had about the product's environment and potential customers, and to systemically elicit hypotheses that would be the basis for experiments.

Following this method, we aim to satisfy the seven guidelines for proposed by Hevner et al. [18] for DSR:

1. Design as an artifact: DSR must produce a viable artifact;
2. Problem relevance: the goal should be to develop a solution to relevant problems;
3. Design evaluation: the "utility, quality, and efficacy" of the artifact should be rigorously demonstrated;
4. Research contributions: the DSR project should provide "clear and verifiable contributions" regarding the "design artifact, design foundations, and/or design methodologies";
5. Research rigor: DSR should apply rigorous methods both in the construction and in the evaluation of the artifact;
6. Design as a search process: the DSR process is inherently iterative and the search for the best, optimal solution is unfeasible. The goal should be feasible, good designs representing satisfactory solutions.
7. Communication of research: DSR solutions should be presented effectively.

Since the target artifact is a method, we satisfy G1. Our argument about the importance of experimentation to early-stage software startups fulfills G2. In the following sections, we describe the design artifact (G5), its development process (G6), and evaluation (G3). In Section 7, we discuss the research contributions (G4). This paper and previous one [19] communicate our results (G7).

## 4 Artifact design process

This section describes the three phases of the artifact construction process, Understanding, Proposing, and Improving, in detail, including the research method, data collection, analysis, and results obtained.

### First phase - Understanding

This phase's goal was to understand how teams form the assumptions on which they base their products. We selected two startups called from now on as A and B, located in an Italian technological park. At the moment of data collection, startup B participated in the incubation process, while startup A only used the space available.

Data collection consisted of semi-structured interviews that followed a pre-defined guide. For both cases, we interviewed the founders and, for case B, also the software developer. The interview questions aimed to understand the interviewees' background, the idea, the motivation to build the product, and how they changed throughout the company history. Since the goal was to understand from where the assumptions used to create the product came, data analysis consisted of explanation building where cause-effect relationships are sought [55] looking for an explanation for the cases [50].

#### 4.1.1 Case A

At the time of data collection, the startup was developing a library to be added to software development projects. The company planned to provide a dashboard to show live software run-time issues, like exceptions, detected or inferred from data collected within the target system. The dashboard would also show solutions to similar problems found on websites focused on programming issues, such as Stack Overflow, and a list of freelance developers that could solve the problem. In some cases, the system would be able to fix some issues automatically. The startup team consisted of five people working part-time on the project spread across software development, business plan, and marketing strategy.

The founder had worked as a software development consultant for an extended period. While participating in third-party projects, he observed that such a tool could help him work more effectively. Besides that, he believed that the technical level of software developers was decreasing. Therefore, it would make sense to develop such a tool.

At the time of data collection, the startup had an initial prototype consisted of a dashboard with some dummy data and a website presenting the idea.

#### 4.1.2 Case B

The startup was running a website to help hotel owners and managers to find the best softwaresolutions for their businesses. Its initial focus was on the Italian market, but it aimed to reach international markets. The team consisted of two founders/partners, one developer who founded the company but left the partnership, and an intern to help with administrative tasks. We performed interviews with the founder who had the original idea and the developer.

The interviewed founder had a background in online marketing. He had worked in a company that handled web marketing and websites before staying twelve years in a large web agency. In his last job, he worked as the director of the company's technology business unit. Throughout his work life, he had extensive contact with the tourism sector, especially the hospitality industry.

The founder told having the idea based on the needs he observed from hotel owners, which have many technological tools available to run the business, and software vendors, that have to reach these customers. The founder's inspiration was American software review websites that compare different software solutions to particular market segments and the lack of a specific one for the hospitality sector. Therefore, the original idea was to list available software solutions with users' reviews, attract hotel owners to the website, and receive a commission from vendors for each interested customer that visited their websites.

The founder said that, after the original version had gone online, the team started observing the website usage data and realized it was not going as expected. The team observed that the hotel owners were not able to compare different software solutions because these products rarely have the same set of features, and, sometimes, hotels needed more than one software system to fulfill their requirements. Then, the startup changed the website to ask the hotel owner to fill an online form giving details about the business. Based on the information provided, the system would match the solutions adapted to the business needs.

In the interview with the developer, it was clear that his influence on the idea was limited. He thought that it was a good idea but did not have experience in the market. He trusted the founders regarding the business and focused on developing the solution.

At the moment of data collection, the startup had its customer base growing, and it was close to break-even. It was looking to expand to other markets.

#### 4.1.3 Cross-case analysis

A common aspect between cases A and B is that, based on their previous experience, the founders formed a set of beliefs to explain how a specific market functions and its customers behave. Based on this understanding, founders predict how potential customers would behave when exposed to their product or service. For instance, in startup B, the founder considered that hotel owners wanted to buy software solutions and that they were able to compare the different alternatives and select the best suited for their cases. Based on that, the founder foresaw that a website with a list of available software solutions would be useful to hotel owners. They would be able to see all the solutions and select the one that would fit their needs. Fig. 2 summarizes this process: the founder's previous experience leads to assumptions about the customers and the market, used to forecast the behavior of customers, and a new product idea. This process is related to the founder being the innovation owner and her experience being the motivator for the startup product idea, as discussed in the literature [39].

In startup B, after the software was ready and the website went online, usage data showed that the results were not as predicted. Hence, the founder had to update his assumptions about the customers and change the product accordingly. This new "implicit theory" has emerged from the experiment result and led the company to better results within the market. Nevertheless, to reach this stage, the startup

Figure 2: The process of idea creation. The dashed lines represent the previous understanding that the background of the founder led to the idea. Adapted from [19].

spent resources developing the whole product that could have done earlier if the team had analyzed the customers.

Such rearrangement exposed an implicit process model for development in software startups. In such a process, the founder's assumptions guide the elicitation of requirements, and the data generated by the software usage may impose changes on this set of assumptions. Then, the founder uses such an updated representation of the world to elicit new requirements. Fig. 3 depicts this process through a causal chain, "a research-constructed linear display of actions and/or states that suggests a plausible, interrelated sequence of events" [56].

### Second phase - Proposing

Based on the first phase results, a hypothesis elicitation approach should make explicit the founders' underlying assumptions about the customers and the market. In this phase, our goal was to evaluate the feasibility of using cognitive mapping to make these assumptions explicit. To do so, we adapted the approach proposed by Furnari [35]. Using a whiteboard to depict the current status of the mapping and, with the founder's help, we aimed to create a cognitive map representing how and why the founder believes the startup's business model works. The detailed steps were:

1. ask the founder to describe the business model concerning the value proposition and customers;
2. extract concepts and causal relationships;
3. inspect each concept to see if they were, in reality, not based on an underlying assumption.
4. check with the founder if the map represented the way the problem was understood at the moment.

We evaluated this initial proposal in two other Italian software startups, C and D. We performed interview sessions following the defined protocol below:

1. Present the concept of hypotheses and how Lean Startup is related to it.
2. Ask the interviewee to describe his business or product idea, especially regarding customer segments and value proposition.
3. Ask on which hypotheses the founder believed his idea is based.
4. Using a whiteboard and interacting with the founder, draw a cognitive map until the map represented the understanding of the market.
5. Create a list of hypotheses based on cognitive mapping and compare it with the initially created list.
6. Ask feedback on the process to the founder.

Below, we describe the results for each case.

#### 4.2.1 Case C

Case C was an early-stage software startup planning to develop a digital mentor for software developers to increase their happiness and satisfaction. The product would adapt itself to each developer's needs. Companies interested in improving their developers' productiveness would pay a fee to make the solution available to their teams.

When asked about hypotheses, the founder mentioned some they had already worked with and others they were planning to evaluate. The first hypothesis was that software development teams could not organize themselves. Through some interviews, it got invalidated, and they changed from the initial idea to the current one. The following hypothesis or, how the interviewee called, _"exploration"_ was to understand if software developers care about soft skills. When asked about other hypotheses, the founder said that she was waiting for another round of tests.

Fig. 4 displays a representation of the cognitive map derived for this case. Through this process, the founder stated that the main element to increase developers' productivity would be making their work more fun through gamification.

The arrows in the figure imply seven hypotheses: 1) developers productivity improves the company results; 2) developers satisfaction improves developers productivity; 3) making the development work more fun improves the developers' productivity and 4) the developers satisfaction; 5) gamification could make developers' work more fun; 6) making the development work more fun would increase the company satisfaction; 7) increasing the company results will improve its satisfaction.

Figure 3: The founder’s assumptions being updated as shown in [19].

Although some identified hypotheses are straightforward and may not demand a proper experiment to be considered validated, the founder acknowledged that the _"[they] have to see if the correlation between having fun and the productivity [exists], that is a major risk."_

#### 4.2.2 Case D

Case D was developing a software solution to improve the perceived quality of connection to the Internet, especially for locations where such quality level is low, such as small mountain villages. Through an innovative approach, the solution would make the network status transparent, enabling the user to adapt it to their needs and improve the quality of service. At the request of the interviewee, details of this product are not included in this article.

At the beginning of the interview, the founder explained that he considered that the main hypothesis concerned with the size of the low-quality area and if Internet providers were willing to quickly fix the problem. He mentioned talking to many potential customers regarding the solution, and most of them would like to have the solution. Fig. 5 depicts the cognitive map developed in the session.

From the arrows, there are five implied hypotheses: 1) increasing the network efficiency will improve user satisfaction, 2) making the network more transparent will not decrease user satisfaction, 3) making the network more transparent will increase the user's willingness to react [to the bad quality of Internet connection], 4) the users' willingness and ability to react will increase user satisfaction, and 5) making the network more transparent will increase the user's willingness to react.

When confronted with the hypotheses, the founder mentioned they had already thought about them before. Nevertheless, using his words, the process _"made them explicit and more structured."_

Although the results were promising, we observed that the process of cognitive map elicitation was not repeatable because it was highly dependent on the interviewer's experience. Besides that, the interviewer felt the lack of guidance on properly conducting this step. Another aspect that we observed was the lack of uniformity in the boxes' content: some were concepts or nouns, but others were actions, events. Based on that, we improved the technique in the next phase. Regarding the expected attributes defined in Section 3, the artifact was useful, easy to use, and effective, but we should improve its qualities: self-containedness and clarity.

### Third phase - Improving

Based on the previous phase results, the need for a more systematic approach was evident. To achieve this goal, we focused on developing a proper visual language to build the maps and a systematic method to elicit them from founders. Since the artifact development is a design search process [20], we

Figure 4: Cognitive map created during interview with the founder of startup C. Numbers were included here to identify the hypotheses.

Figure 5: Cognitive map created during interview with the founder of startup D. Numbers were included here to identify the hypotheses.

performed a series of map elicitation sessions with potential founders. The subjects in this phase not necessarily created a startup but had an idea that, in their opinion, could potentially be the basis of a new solution. After each session, we evaluated the process and improved the artifacts to make the language and process more precise. The sessions occurred online, and the researcher shared his screen where he drew the cognitive map using the software Diagrams.net1 with the interviewee's help. Once the results reached a satisfactory level, we considered the artifact design process completed.

Footnote 1: [https://app.diagrams.net/](https://app.diagrams.net/)

Following this approach, we performed three sessions. While the first two were Brazilian entrepreneurs, the third was based in Italy. In each session, we tried to improve the visual language and the map elicitation process based on the previous session results. Table 1 describes the improvements we applied to the technique in each session and the respective results.

## 5 HyMap: Hypotheses Elicitation using Cognitive Maps for Early-Stage Software Startups

HyMap, the method developed in this study, is a process, conducted by a facilitator, to draw a cognitive map and extract hypotheses from it based on a visual language to depict the map.

### A visual language to represent startup founder cognitive maps

To depict the cognitive map that supports the elicitation process, we developed a visual language adapting the cognitive mapping symbols described in Section 2.4 to differentiate the concepts represented. It consisted of the following elements:

* Circles represent customer segments.
* An ellipsis is used to denote the proposed solution.
* Dotted-line boxes portray the software features.
* Solid-line boxes represent concepts, either physical or abstract, and are filled with nouns.
* Arrows connect boxes or circles to boxes and represent relationships among them. There are three types of relationships: offering, influence, and perception, that are defined by the types of the shapes connected. Offering arrows connect the solution and its features to represent that the product offers those functionalities. Influence arrows are similar to those in conventional cognitive maps, as mentioned in Section 2.4, and represent that one concept influence the intensity of the other. They should be labeled with one sign: '+', '-', '/o/' to denote its type: respectively, if one concept increases the other, decreases, or does not influence. Perception arrows are those that connect the customers with their problems and represent that customers perceive those concepts as issues.

There are no restrictions on the number of inbound or outbound arrows from boxes, but they must represent an acyclical graph. Such a pattern for the construction leads to layers of elements in the map, as shown in Fig. 6. In the Product layer, we represent the product. In the Features layer, we represent the features the founders expect for the product. In the Problems layers, one or more layers of elements represent the aspects founders think the product features will solve. Finally, in the Customer layer, we represent the expected customers and users for the product.

Figure 6: A template for the HyMap map.

### Eliciting startup founder cognitive maps and hypotheses

The first step to reach hypotheses is to elicit the founder's cognitive map. To reach this goal, we propose an iterative approach where, based on the map's current status, the founder should analyze each of the relationships (arrows) and consider if there are underlying concepts. A facilitator helps the founder in this process by following a predefined set of questions, drawing the map according to the visual language, and clarifying the questions if the founder does not understand them. This way, the founder focuses on the business questions while the facilitator that had previously used the technique asks the founder questions and handles the drawing. The facilitator could also ask for clarifications when details are not clear. At the beginning of this process, an initial map should be created based on the following questions:

1. What is the product/solution name?
2. What are the customers targeted by the solution?
3. For each customer, what are the aspects the actor expects to improve using the solution?
4. Which are the solution features envisaged, and which aspects in the previous step do they fulfill?

Based on these questions' answers, the facilitator put the respective shapes on the map and connect them with arrows. Then, for each arrow, the founder should judge if there are concepts implicitly used to explain that relationship. Some questions useful in this step are _how?_ and _why?_. If a new concept emerges, a new box representing it is added along with new relationships (arrows). This process is repeated iteratively until the founder is comfortable that no new concepts should be added. A useful question to evaluate if this process is saturated is if it is possible to create a simple experiment to evaluate that relationship. Additionally, the founder must evaluate if the new concepts added are related to other concepts already present on the map. Throughout the process, the founder should constantly assess if the map being created is coherent to her understanding of the customer and market. To refine the map, the founder can add, remove, or substitute elements.

Once the cognitive map is finished, we can say that each relationship represents an assumption the founder has about its targeted customer, value proposition, and product. Based on them, she can formulate hypotheses based on which she can create experiments. These experiments can be pieces of software but also interviews, questionnaires, or other techniques.

Arrows originating in different layers, as shown

Tuple 29:
Cleaned Title: transient shear banding startup flow insight nonlinear simulation
Cleaned Transcription: transient shear banding startup flow insight nonlinear simulation shweta sharma department chemical engineering indian institute technology kanpur kanpur india yogesh joshi yogeshiitacin department chemical engineering indian institute technology kanpur kanpur india v shankar yshankariitacin department chemical engineering indian institute technology kanpur kanpur india november study dynamic shear startup johnsonsegalman nonstretching roliepoly model using nonlinear simulation signature transient steadystate shear banding quantified monitoring degree banding defined difference maximum minimum shear rate shear startup consider case startup zero shear rate shear rate monotonic nonmonotonic region constitutive curve johnsonsegalman model exhibit shear stress overshoot startup nonlinear simulation show transient shear banding absent regardless whether startup shear rate monotonic nonmonotonic region constitutive curve latter case clearly inhomogeneity en route banded state magnitude degree banding substantially large compared eventual banded state marked inhomogeneity velocity profile predicted nonstretching roliepoly model solvent solution viscosity ratio smaller occurrence appear correlation stress overshoot startup inhomogeneity also sensitive initial amplitude perturbation magnitude reynolds number also compare result obtained within realm linearized dynamic previous study sharma et al journal rheology present nonlinear result show nonlinearities stabilizing effect mitigate divergence perturbation predicted within linearized dynamic shear startup argue neglect inertia nonlinear simulation selfconsistent solvent solution viscosity ratio small inertial effect need included order obtain physically realistic result nonlinear simulation show transient evolution shear startup quite sensitive reynolds number solvent viscosity parameter much smaller unity nonstretching roliepoly model however result johnsonsegalman model robust solvent solution viscosity greater reveal transient shear banding shear startup introduction viscoelastic fluid undergoing shear extensional flow often susceptible instability various kind shear banding one example instability exhibited viscoelastic material shear banding best understood context planar couette flow viscoelastic fluid applied shear rate underlying nonmonotonic region constitutive curve situation linear velocity profile becomes unstable transforms band two distinct shear rate shear rate two band lie stable branch constitutive curve shear banding seen shear startup flow transitioning eventual steady state referred transient shear banding shear banding observed flow reached steady state referred steadystate shear banding transient shear banding principle occur scenario regardless whether steady state banded homogeneous steady state banded however transient shear banding must distinguished inevitable inhomogeneity ensue en route banded state measuring extent inhomogeneity recent study transient shear banding quantified measuring difference maximum minimum shear rate dubbed degree banding steady state homogeneous evolution degree banding time transiently increase attain peak decrease zero steady state banded presence transient shear banding ascertained degree banding show transient peak substantially high magnitude attaining eventual value steady state evolution second derivative velocity direction momentum diffusion also utilised literature find presence transient shear banding also width interface two band must much smaller width band hence transient flow inhomogeneity shear startup may always designated transient shear banding stability steady state shear startup flow first studied yerushalmi et al proposed model independent fluid universal criterion existence steady state shear banding shear startup flow manuscript author stated shown value steady shear rate flow curve exhibit zero negative slope flow unstable criterion validated many researcher literature using experiment various constitutive model nonmonotonic region shear stress decrease function shear rate fluid universal model independent criterion existence transient shear banding shear startup flow proposed literature moorcroft fielding according criterion shear startup flow shear stress show overshoot time duration shear stress show negative slope function time strain shear startup flow becomes unstable form band different shear rate transiently author utilised modal stability analysis method calculated transient eigenvalue also known frozen time analysis derive criterion previous study discussed detail restrictive nature criterion based assumption utilised obtain simplified criterion assumption shear startup high shear rate ii frozen time analysis used tool obtain signature transient shear banding iii hopf bifurcation absent iv one real part transient eigenvalue positive time moorcroft fielding examined shear startup nonstretching roliepoly giesekus model using frozen time analysis linearized evolution perturbation nonlinear simulation check validity criterion found result obtained using nonstretching roliepoly model validated criterion transient shear banding observed presence stress overshoot however giesekus model transient shear banding observed even presence stress overshoot author argued since transient shear banding elastic instability model show stress overshoot magnitude strain qualify show transient shear banding fielding subsequently analysed transient shear banding criterion shear startup flow noted criterion useful may universal transient shear banding criterion shear startup flow tested experimentally theoretically literature found consistent result universally applicable discussed section ii previous study transient steady state shear banding observed shear startup entangled polymeric solution literature researcher proposed flow concentration coupling underlying reason transient shear banding shear startup flow wormlike micellar system also explored literature startup shear rate steady state also banded using geometry quite high shear stress inhomogeneity best knowledge transient shear banding reported shear startup flow wormlike micellar solution yet wherein steady state homogeneous shear stress almost homogeneous plate since multiple factor governing shear banding entangled polymeric solution study focus understanding possibility transient shear banding wormlike micellar solution also focus shear startup viscoelastic constitutive model predict monotonic nonmonotonic constitutive curve coupling concentration roliepoly model fit experimental result wormlike micellar solution johnsonsegalman model earlier study analyzed transient shear banding criterion shear startup flow using johnsonsegalman nonstretching roliepoly giesekus model using frozen time analysis fundamental matrix method frozen time analysis eigenvalue calculated time instant shear startup treating flow quasi steady approach valid transient growth rate significantly higher rate change basestate evolution fundamental matrix method evolution linearized perturbation obtained along evolution base state method also provides maximum amplitude perturbation independent initial condition consequently render robust result compared frozen time analysis used method showed assumption made derive criterion transient shear banding restrictive showed link positive transient eigenvalue stress overshoot also reported transiently positive eigenvalue lead growth linearized perturbation johnsonsegalman model case shear startup nonstretching roliepoly model found agreement stress overshoot transiently positive eigenvalue growth perturbation reported earlier moorcroft fielding using giesekus model showed transiently positive eigenvalue necessary transient growth linearized perturbation transient eigenvalue positive steady state stable attributed contrasting observation johnsonsegalman nonstretching roliepoly model difference order magnitude ratio solvent solution viscosity johnsonsegalman model nonstretching roliepoly model high shear rate showed maximum transient eigenvalue diverges decreasing ratio solvent solution viscosity also argued transient growth rate becomes significantly high inertial effect longer ignored assumed base state evolution inertialess evolution perturbation presence inertia found transient eigenvalue diverge saturates constant eigenvalue growth linearized perturbation also reduced significantly presence inertia concluded may transient shear banding shear startup flow solved higher value solvent solution viscosity ratio solvent solution viscosity le inclusion inertia may regularise evolution eigenvalue perturbation however conclusion based approximate solution inertia considered evolution perturbation base state furthermore growth linearized perturbation also necessarily guarantee presence transient shear banding since nonlinear term ignored therefore interest examine whether transient shear banding observed considering nonlinear term also determine effect inertia transient dynamic shear startup flow whether inertia regularises effect low ratio solvent solution viscosity work study shear startup flow johnsonsegalman nonstretching roliepoly model using full nonlinear simulation imposing perturbation beginning shear startup discus model governing equation sec ii also discus issue realistic initial amplitude perturbation study transient shear banding sec ii explore effect initial amplitude perturbation transient dynamic shear startup flow presence absence inertia sec iii also study effect decreasing ratio solvent solution viscosity inclusion inertia sec iii discus salient conclusion study sec iv ii model governing equation use johnsonsegalman nonstretching roliepoly model analyse shear startup viscoelastic fluid consider incompressible viscoelastic fluid two parallel plate infinite x z direction confined ydirection gap h plate plate rest time time tgeq top plate move steady velocity u x direction variable manuscript include superscript dimensional without one dimensionless addition assume noslip boundary condition hold plate case continuity equation satisfied automatically simplified cauchy momentum equation written follows nablacdotundersetapproxsigmarhofracpartial upartial tagwhere rho density fluid usim velocity field undersetapproxsigma total stress tensor consider total stress equal sum viscoelastic stress newtonian solvent stress contribution undersetapproxsigmaundersetapproxsigmabaretas hatgamma tag undersetapproxsigma viscoelastic stress baretas viscosity solvent polymeric wormlike micellar solution hatgammafracnablaundersetsimunablaunderset simut shear rate tensor use johnsonsegalman roliepoly model viscoelastic stress undersetapproxsigma model augmented additional stress diffusion term unique stress selection nonmonotonic region flow curve model made dimensionless follows undersetapproxsigmadfracundersetapproxsigmabar etasbaretaptau tttau undersetsimuundersetsimuu expression baretap contribution polymer zero shear viscosity solution tau relaxation time solution case roliepoly model tautaud represents reptation time johnsonsegalman model taulambda longest relaxation time relevant dimensionless group weissenberg number widfractau uh represents nondimensional shear rate reynolds number redfracrho uhbaretasbaretap ratio solvent viscosity zero shear viscosity solution etasdfracbaretasbaretasbaretap dimensionless form cauchy momentum equation given redfracpartial upartial tdfracpartialsigmaxypartial yeta swidfracpartialupartial tag johnsonsegalman model johnsonsegalman hereafter j model developed introduce nonaffine motion upperconvected maxwell ucm model replacing upperconvected derivative gordonschowalter derivative degree nonaffine motion governed slip parameter xi xi j model constitutive equation yield ucm model xi reduces lower convective maxwell lcm model constitutive equation j model given following equation undersetapproxsigmalambdaundersetapproxsigmabox baretaphatgamma tag gordonschowalter derivative undersetapproxsigma undersetapproxsigmaleftdfracxirightunderset approxsigmaleftdfracxirightundersetapproxsigma tag lambda longest relaxation time polymeric solution baretap contribution polymer zero shear viscosity solution xi fixed throughout result shown manuscript upperconvected lowerconvected derivative oversettriangledownundersetapproxtriangledown oversettriangleundersetapproxtriangle respectively simplified nondimensional componentwise equation model simple shear flow fracpartialsigmaxypartial tleftleftfracxirightsigma xxleftfracxirightsigmayyleftetasrightrightdot gammawisigmaxydfracpartialsigmaxypartial tag fracpartialsigmaxxpartial tleftleftfracxiright sigmaxyrightdotgammawisigmaxxdfracpartialsigmaxx partial tag fracpartialsigmayypartial tleftxisigmaxyrightdotgamma wisigmayydfracpartialsigmayypartial tag roliepoly model roliepoly model single mode molecular model entangled polymer melt name derived rouse linear entangled polymer model model developed likhtman graham simplification doiedwards tube model model also account molecular process including reptation convective constraint release ccr chain stretch retraction contour length fluctuation constitutive equation model expressed follows leftoversetsigmaundersetapproxsigmaoverseti undersetapproxirighttaudoversetnablaundersetapprox sigmafractaudtaurleftsqrtfractrleft oversetsigmaundersetapproxsigmarightrightleft oversetsigmaundersetapproxsigmabetaleftoverset sigmaundersetapproxsigmaoversetiundersetapprox approxirightleftsqrtfractrleftoversetsigma undersetapproxsigmarightrightdeltaright tag beta determines effectiveness convective constraint release mechanism deltafrac following fix strength convective constraint release oversetiundersetapproxi identity tensor also taud determines contribution reptation relaxation mechanism taur show contribution chain stretching relaxation mechanism number entanglement represented zleftzfractaudtaurright consequently fix two relaxation time likhtman graham simplified model considering taurto trleftoversetsigmaundersetapproxsigmarightdelta delta taurto simplified model known nonstretching roliepoly model referred hereafter nrp model whose constitutive equation given leftoversetsigmaundersetapproxsigmaoverseti undersetapproxirighttaudoversetnablaundersetapprox sigmafractaudlefttrleftoversetnabla undersetsimsigmaoversetuundersetsimsigma cdotoversetsigmaundersetapproxsigmarightright leftoversetsigmaundersetapproxsigmabetaleft oversetsigmaundersetapproxsigmaoverseti undersetapproxsigmarightright tag componentwise equation nrp model nondimensional form simple shear flow followsfracpartialsigmaxypartial twidotgammaleftsigmayyfrac sigmaxybetarightsigmaxydfracpartialsigmaxy partial tag fracpartialsigmayypartial tfracwidotgammaleftbeta sigmaxysigmayysigmaxyleftbetarightrightleftsigma yyrightdfracpartialsigmayypartial tag result presented manuscript using nrp model obtained using beta solve shear startup flow shear rate nonmonotonic region constitutive curve beta used shear rate monotonic region constitutive curve carry full nonlinear simulation simple shear flow using j nrp model solve eq eq eq study impose perturbation initial condition undersetsimu undersetapproxsigma expressed follows undersetsimuundersetsimuasinnpi tag undersetapproxsigmaundersetapproxsigmaacosn pi tag amplitude sine cosine wave n fix wavelength stress component shear rate perturbation chosen cosine velocity perturbation written term sine thus noslip boundary condition get satisfied manuscript n eq fixed throughout manuscript yield unstable mode considered note magnitude shear rate initial condition j nrp model solved shear startup absence inertia possible specify initial amplitude shear rate governing cauchy momentum equation devoid acceleration inertialess limit limit initial value shear rate actually dictated initial value sigmaxy given cauchy momentum equation eq absence inertia dotgammatsigmaxytetaswi consequence etasll initial shear rate perturbation oetassigmaxyt ie much larger magnitude stress perturbation thus etasll impose stress perturbation shear rate perturbation become much larger unity note step change shear rate shear startup protocol however use sigmaxysim would yield high value shear rate unrealistic impose large ie gg shear rate perturbation initial condition nonlinear simulation since maximum imposed shear rate base state note initial condition use numerical simulation intended mimic inevitable spontaneous perturbation would present laboratory experiment thus order initial condition numerical simulation physically realistic one shear rate perturbation magnitude much larger basestate shear rate unity case order address issue especially limit small eta necessary prescribe initial shear stress perturbation amplitude manner initial shear rate perturbation ie imposed shear rate jump startup flow nonlinear simulation carried using comsol r inbuilt partial differential equation solver comsol utilizes finite element method domain discretized point also result verified mesh size time stepping transient evolution nrp model shear startup shear rate nonmonotonic region constitutive curve sensitive change number domain element order magnitude owing linearly unstable velocity profile however overall conclusion study remains result result j model nrp model domain element relative absolute tolerance kept respectively iii result discussion earlier work demonstrated stress overshoot shear startup guarantee positive eigenvalue within frozentime linear stability analysis result growth perturbation within accurate analysis linearized dynamic using fundamental matrix approach caveat frozen time analysis also mentioned ref former particular used signature transient instability literature result linearized dynamic suggestive time evolution perturbation infinitesimal ultimate answer question whether transient shear banding present must come fullynonlinear solution shear startup objective present study numerically solve partial differential equation mentioned sec ii determine relevance stress overshoot positive eigenvalue within frozentime stability analysis growth decay linearizedperturbations transient shear banding analyze shear startup j nrp model shear rate monotonic nonmonotonic region constitutive curve discussed sec shear banding identified quantified reliably peak second derivative velocity however work quantify steady state transient shear banding case calculate degree banding defined difference maximum minimum shear rate flow fluid parallel plate degree shear banding zero flow homogeneous otherwise inhomogeneous magnitude determines extent inhomogeneity flow also show corresponding velocity profile function time correlate degree banding noted preceding section specifically address question realistic amplitude initial imposed stress perturbation creepingflow assumption subsequent subsection sec iiiiii examine influence flatness constitutive curve solvent viscosity inertia effect initial amplitude perturbation first discus effect initial amplitude perturbation considering reneq computing transient dynamic varying magnitude examine extent validity result linearized dynamic strictly valid limit initial shear rate perturbation amplitude specified directly dictated magnitude initial stress perturbation sigmaxyt cauchy momentum equation eq however reneq initial shear rate perturbation specified directly mentioned preceding section following subsection also compare shear stress evolution different obtained using full nonlinear simulation comparison also show shear stress evolution forced homogeneous flow obtained solving j nrp model assumption linear velocity profile time stress diffusion iii j modelwe first study shear startup j model creepingflow limit shear rate monotonic region constitutive curve case fix eta missingpageempty banding deltadotgammamax increase linear manner similarly velocity profile plotted fig supplementary information show transient shear banding significant deviation linear velocity profile explored value next study effect initial amplitude perturbation shear startup flow j model case shear rate nonmonotonic region constitutive curve steady state shear banding observed solve j model wi eta initial amplitude perturbation figure b show shear stress degree banding function time shear stress increase show overshoot attaining steady state evolution deltadotgamma show linear increase attaining steady state shown fig b initial linear increase deltadotgamma time semilog plot clearly demonstrates exponential growth perturbation expected shear rate linearly unstable region constitutive curve figure b also show deltadotgammamax deltadotgammasteadystate slightly higher stress evolution overlap case except attaining final steadystate stress find time attaining steady state value degree banding deltadotgamma depends value higher value lower time required j model become unstable attain steady state shear banding result also demonstrate perturbationsbegin grow exponentially time ie tapprox consequently onset instability exemplified exponential growth early time correlation time stress show decrease overshoot also pronounced transient increase ie deltadotgamma greater deltadotgammasteadystate time range stress decay overshoot shown fig also observe oscillation variation deltadotgamma time however peak value deltadotgamma oscillation significantly higher value deltadotgamma steady state therefore oscillation treated signature transient shear banding result show creepingflow assumption shear rate monotonic region constitutive curve j model show transient shear banding even though linearized perturbation showed growth decay flow ii maximum value degree banding deltadotgammamax order varies linear manner iii time associated maximum degree banding depends shear rate nonmonotonic region constitutive curve also distinct transient shear banding observed increase degree banding begin almost beginning flow time much lesser time shear stress decrease overshoot nrp modelwe next study effect initial amplitude perturbation shear startup nrp model creepingflow assumption shear rate monotonic figure maximum degree banding deltadotgammamax plotted shear startup j model shear rate monotonic wietas b ratio maximum degree banding deltadotgammamax degree banding steady state deltadotgammasteadystate plotted shear rate nonmonotonic wietas region constitutive curve region constitutive curve wi eta beta mentioned sec ii absence inertia possible provide initial condition shear rate instead initial value shear rate fixed initial stress perturbation sigmaxyt via cauchy momentum equation eq dotgammatsigmaxytetas shear rate perturbation become much larger stress perturbation initial shear rate perturbation order base state shear rate eta similarly initial shear rate perturbation order base state shear rate figure effect amplitude perturbation shear startup nrp model wietasbeta corresponds shear rate monotonic region constitutive curve shear stress evolution plotted forced homogeneous flow b variation degree banding deltadotgammadotgammamaxdotgammamin time shown different value inset fig b show early time variation degree banding semilog plot c early time variation degree banding time eta semilog plot initial shear rate perturbation order base state shear rate find shear stress evolution overlap shown fig velocity profile shear startup flow show presence transient shear banding negative velocity profile shown fig corresponding evolution degree banding shown fig b evolution deltadotgamma function time show sharp increase finally decay zero inset fig b show early time behavior semilog plot fig c show evolution result show perturbation initially grow linearly followed growth stronger linear final decay zero result show growth perturbation exponential implies shear startup nrp transiently linearly unstable however exponential growth perturbation begin almost start flow may correlation time shear stress start decrease overshoot similarly value deltadotgammamax significantly larger input amplitude shown fig therefore treat intrinsic instability shear startup nrp model interestingly figure b show time peak deltadotgamma decrease increase value value deltadotgammamax also depends value increasing value value deltadotgammamax also increase linear manner shown fig decrease deltadotgammamax also clearly visible velocity profile evolution slight deviation linear velocity profile transient shear banding transient negative velocity profile fig b shear stress degree banding velocity profile obtained using wi eta beta fig b also appeared ref included result comparison purpose shear rate nonmonotonic region constitutive curve wi eta beta find shear stress evolution function time different value overlap also observed previous case initial shear rate perturbation shear stress perturbation previous case value eta wi case well value higher shear stress attains steady state lower value time shown fig evolution deltadotgamma time also confirms degree banding show rapid increase attain maximum value decrease constant value axis linear deltadotgamma versus time plotted semilog scale increase degree banding linear stronger linear attaining steady state shown fig b c result demonstrates exponential growth perturbation agreement criterion yerushalmi et al however time degree banding begin grow exponentially much lesser time shear stress start decrease overshoot literature time decrease stress stress overshoot often linked time steady state shear banding structure begin form however result show shear banding structure start form beginning flow may discernible experiment hence shear banding structure associated time decrease stress overshoot importantly evolution deltadotgamma time semilog plot nrp model show linear increase initially followed nonlinear increase case shear rate monotonic well nonmonotonic region constitutive curve fig b b finding clear linear stability analysis predicts exponential growth early time soon nonlinear effect take hence linearized dynamic loses relevance time stress overshoot decay caution regarding use linear stability analysis unsteady flow shear startup flow ass occurrence shear banding also pointed peterson transiently high value deltadotgamma show presence transient shear banding constant value deltadotgamma steady state show presence steady state shear banding figure b show value deltadotgammamax much higher deltadotgammasteadystate however deltadotgammamax depends value linear fashion noted previous case ie corresponding result shown fig b time maximum value degree banding depends value higher value lower time corresponding maximum value degree banding higher value deltadotgammamax shown fig b b observation also similar previous case shear startup flow solved shear rate monotonic region constitutive curve also transient negative velocity profile observed case transient negative velocity profile distinct transient shear banding part gradual development steady state shear banding observed shown fig contrast j model result nrp model showed creepingflow assumption transient shear banding presence stress overshoot regardless whether steadystate velocity profile homogeneous banded result agreement observation reported previous study fig b ref wherein showed lin earized perturbation grow rapidly attain maximum order continuous decrease eta however presence transient shear banding degree banding sensitive magnitude observed initial shear rate perturbation unrealistically high ie eta wi case nrp model effect amplitude perturbation transient shear banding agreement result obtained literature stretching roliepoly model ii time associated maximum value degree banding maximum value degree banding depends value figure effect amplitude perturbation shear startup nrp model wietasbeta corresponds shear rate nonmonotonic region constitutive curve shear stress evolution plotted forced homogeneous flow b variation degree banding deltagammagammamaxgammamin time shown different value inset fig b show early time variation degree banding semilog plot c early time variation degree banding time eta semilog plot figure maximum degree banding deltadotgammamax plotted shear startup nrp model shear rate monotonic wietasbeta b nonmonotonic wietasbeta region constitutive curve figure velocity profile evolution shear startup flow nrp model fluid wi eta beta corresponds shear rate monotonic region constitutive curve figure show result figure b show result figure c show result figure show result iii variation deltadotgammamax linear suggests importance nonlinearities dynamic fig b iv magnitude initial shear rate perturbation realistic may discernible transient shear banding v case increase degree banding exponential initially occurs time much lesser time associated stress overshoot contrasting result j nrp model ascribed following reason case j model magnitude initial shear rate perturbation unrealistically high value eta much smaller compared unity ii case nrp model initial shear rate perturbation becomes unrealistic low value eta stress perturbation therefore creepingflow assumption initial shear rate perturbation realistic may transient shear banding observed shear startup flow j nrp model iii reneq study shear startup j nrp model nonzero inertial effect consider comparing result model nonzero inertia initial shear rate perturbation specified directly term however value eta considered differs order magnitude two model effect initial amplitude perturbation model different discussed effect inertia transient shear banding discussed sec iii effect initial amplitude perturbation evolution stress degree banding time model plotted fig supplementary information j modelfor j model find shear startup shear rate monotonic nonmonotonic region constitutive curve result obtained different initial amplitude perturbation nonzero inertia similar figure show value deltadotgammamax order increase linear fashion reneq well similarly shear rate nonmonotonic region constitutive curve also variation deltadotgammamax reneq shown fig b nrp modelfor nrp model find variation deltadotgammamax proportional value contrast result j model reneq shown fig interestingly value deltadotgammamax proportional case result show variation deltadotgammamax affected nonlinearities dynamic shear startup nrp model variation deltadotgammamax proportional result discussed detail sec iii similarly shear rate nonmonotonic region constitutive curve presence inertia effect initial amplitude perturbation similar case except shown fig b value deltadotgammamax equal deltadotgammasteadystate deltadotgammamax slightly higher deltadotgammasteadystate variation deltadotgammamax depends linear manner also show presence transient shear banding sensitive initial amplitude perturbation even presence inertia effect initial amplitude perturbation case j model presence inertia similar noninertial case direct shear rate perturbation amplitude specified steady state homogeneous nonhomogeneous case interestingly result nrp model noninertial case qualitatively similar result obtained presence inertia attribute observation also smaller value eta used nrp model rationalized using cauchy momentum equation given fracpartial upartial tfracrefracpartialsigmaxypartial fracetaswirefracpartialupartial tag show first term rh eq becomes much larger magnitude compared second term however case j model order term rh eq order eta interestingly indeed observed literature increase order viscous dissipation stabilizing effect flow effect solvent viscosity flatness constitutive curve previous study fig ref showed decreasing eta lead flattening constitutive curve j nrp model result consistent result reported literature flatness constitutive curve also increased increasing number entanglement however study focus effect eta keeping number entanglement fixed discus effect decreasing solvent viscosity contribution increase flatness constitutive curve several result reported literature suggesting increasing flatness constitutive curve increase chance transient shear banding shear startup flow section focus effect solvent viscosity shear rate monotonic region constitutive curve previous study showed using j model significant change transiently maximum eigenvalue maximum value growth linearized perturbation decrease eta also noted order study effect flatness constitutive curve value eta lowered order constitutive curve monotonic course present study found even result nonlinear simulation significant effect decreasing solvent viscosity degree banding evolution data shown however nrp model showed significant change transiently maximum eigenvalue maximum value growth linearized perturbation decrease eta using nonlinear simulation next study effect eta degree banding nrp model eta eta study shear stress variation degree banding time eta variation deltadotgammamax nonlinear order shown fig b c variation deltadotgammamax linear order eta variation deltadotgammamax independent order shown fig fh also value deltadotgammamax much higher eta compared eta value effect inertia transient shear banding discussed sec iii effect decreasing eta deltadotgammamax also summarized fig deltadotgammamax diverges power law fashion exponent divergence deltadotgammamax appear follow power law divergence deltadotgammamax decrease eta also similar divergence transient growth rate eigenvalue decrease eta previous study linearized analysis also show corresponding velocity profile fig figure show velocity profile deviate linear profile show negative velocity transiently negative velocity implies top plate velocity velocity fluid plate time top plate velocity opposite direction result highlight unrealistic nature result obtained due low value eta even consistent unbounded growth linearized perturbation shown previous study discus physically realistic result obtained section iii nrp model decrease solvent viscosity lead divergence deltadotgammamax however trend observed j model consistent result obtained linearized analysis earlier study addition also found effect variation case nrp model eta attributed significantly high value transient growth rate therefore consideration result j nrp model find divergence deltadotgammamax due increase flatness constitutive curve rather due decrease eta effect inertia previous study analyzed evolution linearized perturbation shear startup base state also evolving accounted effect inertia inclusion inertial effect evolution linearized perturbation base state evolution inertialess found evolution linearized perturbation figure effect amplitude perturbation shear startup flow nrp model eta eta first row show result shear startup flow nrp model wietas beta second row show result shear startup flow nrp model wietas beta result obtained shear rate monotonic region constitutive curve figure e show shear stress evolution function time figure bd figure fh show degree banding function time shear startup flow transiently maximum eigenvalue diverges decrease eta however inclusion inertia evolution linearized perturbation transient maximum eigenvalue saturates finite value magnitude saturated eigenvalue decrease increase section discus result obtained considering effect inertia full non linear simulation perturbation evolving flow j modelwe first compare result obtained different shear startup j model shear rate monotonic nonmonotonic region constitutive curve figure show effect inertia evolution degree banding function time shear rate monotonic region constitutive curve fig show result shear rate nonmonotonic region constitutive curve already discussed evolution degree banding j model fig b b shown fig find inertia effect variation degree banding time degree banding evolution overlap initially due presence inertioelastic wave depicted corresponding velocity profile shown supplementary information result consistent previous study using linear analysis wherein showed magnitude transient maximum eigenvalue small due high value eta transient growth rate high inertial effect affect dynamic shear startup flow missingpageempty figure variation maximum degree banding shear startup flow function eta shear startup flow nrp model fluid wi beta result obtained figure effect inertia degree banding shear startup flow j model wi eta shear rate monotonic region constitutive curve figure effect inertia degree banding shear startup flow j model wi eta shear rate nonmonotonic region constitutive curve regeq similarly shear rate nonmonotonic region constitutive curve peak observed degree banding function time decrease increase value shown fig peak observed significant peak observed regeq significant peak observed regeq result consistent result obtained low eta earlier study fig ref wherein showed increase maximum value transient growth rate fixed eta decrease effect inclusion inertia initial exponential growth perturbation inertialess flow fig c c also shown inset fig b b inset fig b show slope linear increase degree banding decrease increase linear increase observed inset fig b show slope linear increase decrease increase decrease deltadotgammamax function eta shown fig summarises effect inertia shear startup flow nrp model seen increase deltadotgammamax decrease eta significant change deltadotgammamax function observed eta inset fig show degree banding evolution time nrp model eta show deltadotgamma independent order initially finally decaying zero constant value deltadotgammamax order regeq nrp model similar j model result figure effect inertia degree banding shear startup flow nrp model wi eta beta inset fig b show early time evolution degree banding semilog plot shear rate monotonic region constitutive curve sec ii raised question validity creepingflow assumption solving nrp model etasll perturbation imposed beginning flow two broad reason creepingflow assumption etasll might lead erroneous result numerical solution transient maximum eigenvalue transient growth rate diverges decrease eta suggesting transient growth perturbation nonlinear simulation also diverge however transient growth rate shear rate perturbation diverges creepingflow assumption hold true neglecting acceleration term cauchy momentum equation account multiplied implicitly assumed rell acceleration term must remain finite however perturbation growth diverges acceleration term also exhibit similar behavior product dudt longer neglected ii due creepingflow assumption initial shear rate perturbation specified directly order fracsigmavvetaswi result imposing unrealistic magnitude initial shear rate perturbation especially initial stress perturbation kept important note inclusion inertial effect solvent viscosity contribution low etasleq even direct imposition realistic shear rate perturbation perturbation may eventually reach high magnitude figure show beyond critical perturbation grow unbounded shear startup nrp model result show eta deltadotgammamax order reneq eta deltadotgammamax sensitive value creepingflow assumption also affected inclusion inertial effect eta change figure effect inertia degree banding shear startup flow nrp model wi eta beta inset fig b show early time evolution degree banding semilog plot shear rate nonmonotonic region constitutive curve affect deltadotgammamax affected inclusion inertial effect fact velocity profile transient evolution sensitive eta small suggests specific detail experimental condition likely play crucial role nature observed velocity profile recently rassolov mohammadigoushki experimentally obtained velocity profile evolution wormlike micellar solution shear startup flow found steady state banded velocity profile evolution steady state velocity fluid two plate attains negative velocity however magnitude negative velocity reported top plate velocity however negative velocity fluid plate obtained eta shear rate nonmonotonic region constitutive curve top plate velocity shown fig far greater magnitude compared top plate negative velocity observed experimentally rassolov mohammadigoushki interestingly observed literature negative velocity transient velocity profile shear startup shear rate monotonic region constitutive curve lesser shear rate nonmonotonic region constitutive curve therefore based result conjecture either transient negative velocity observed experiment shear startup performed shear rate monotonic region constitutive curve negative transient velocity profile much lesser top plate velocity predicted nrp model fig comparison experimental result highlight importance inertial effect shear startup nrp model help regularising result comparison linearized evolution fully nonlinear simulation previous study also examined growth linearized perturbation different time imposition perturbation tp j nrp model therein shown even j model perturbed steady state tp flow exhibit transient growth eventual decay perturbation within linearized dynamic hand nrp model found flow perturbed steady state tp linearized perturbation decay without showing transient growth study compare magnitude growth linearized perturbation maximum deviation velocity linear profile obtained nonlinear simulation j nrp model study effect tp linearized growth perturbation obtained using fundamental matrix method gt tp lie time range stress decreasing function time stress overshoot j nrp model fluid value gt time show maximum possible growth linearized perturbation independent initial condition use compare maximum possible linearized growth perturbation deviation linear velocity profile high amplitude perturbation imposed shear startup may practically realisable experiment evolution gt function ttp j nrp model different tp shown fig b figure data obtained using tp j model tp nrp model appeared previous study included data comparison purpose case j model find stress decrease time stress overshoot wietas shown figa tp gt show slightly higher increase finally decaying tp compared tp data overlap onto shown fig nonlinear simulation result missingpageempty missingpageempty monotonic region constitutive curve j model found maximum degree banding proportional initial amplitude perturbation even sixfold increase order magnitude suggesting intrinsic transient instability j model shear startup also studied shear startup j nrp model including inertial effect initial shear rate perturbation specified directly result j model showed linear dependence variation maximum degree banding initial amplitude perturbation even presence inertial effect however nrp model maximum degree banding showed linear dependence initial amplitude perturbation beyond threshold level fluid inertia critical magnitude increase decrease eta absence inertia also showed maximum degree banding diverges power law exponent decreasing eta divergence maximum degree banding decreasing eta inertial effect included comparison result obtained using fundamental matrix method linearized evolution perturbation nonlinear simulation showed nonlinear term mitigate divergence perturbation result obtained using different initial amplitude perturbation showed time associated maximum value degree banding maximum value degree banding depends initial amplitude perturbation basis two observation conclude occurrence transient shear banding governed linear instability governed following factor initial amplitude perturbation solvent solution viscosity ratio eta inertial effect characterized overall show result shear startup nrp model sensitive initial amplitude perturbation magnitude inertial effect etasll therefore transient shear banding shear startup j nrp model eta ii inertial effect included etasll high transient growth perturbation creepingflow assumption hold true iii realistic initial amplitude perturbation imposed etasll creepingflow assumption hold true importantly comparison linear nonlinear study showed growth perturbation indicated linearized dynamic may necessarily signify transient shear banding nonlinear simulation result j nrp model show ultimate answer whether transient shear banding obtained using nonlinear simulation acknowledgment acknowledge financial support science engineering research board government india data availability data support finding study available within article supplementary material additional data available corresponding author upon reasonable request supplementary information shear start wi eta using j model monotonic constitutive curve effect inertia initial amplitude perturbationfigure effect inertia amplitude perturbation shown shear startup flow j model shear startup flow wi eta corresponds shear rate monotonic region constitutive curve first row shear stress plotted value result obtained using different value shear stress forced homogeneous flow also plotted fig b c second row fig df degree banding deltahatgamma evolution shown function time different value figure effect inertia amplitude perturbation shown shear startup flow j model shear startup flow wi eta corresponds shear rate nonmonotonic region constitutive curve first row shear stress plotted value result obtained using different value shear stress forced homogeneous flow also plotted fig b c next three row fig dl velocity profile evolution shown function time different value figure effect inertia amplitude perturbation shown shear startup flow j model shear startup flow wi eta corresponds shear rate nonmonotonic region constitutive curve first row shear stress plotted value result obtained using different value shear stress forced homogeneous flow also plotted fig b c second row fig df degree banding deltahatgamma evolution shown function time different value shear start wi eta beta using nrp model monotonic constitutive curve effect inertia initial amplitude perturbation figure effect inertia amplitude perturbation shown shear startup flow nrp model shear startup flow wietas beta corresponds shear rate monotonic region constitutive curve first row shear stress plotted value result obtained using different value shear stress forced homogeneous flow also plotted fig b c next three row fig dl velocity profile evolution shown function time different value figure effect inertia amplitude perturbation shown shear startup flow nrp model shear startup flow wi eta beta corresponds shear rate monotonic region constitutive curve first row shear stress plotted value result obtained using different value shear stress forced homogeneous flow also plotted fig b c second row fig df degree banding deltadotgamma evolution shown function time different value shear start wi eta beta using nrp model nonmonotonic constitutive curve effect inertia initial amplitude perturbation figure effect inertia amplitude perturbation shown shear startup flow nrp model shear startup flow wi eta beta corresponds shear rate nonmonotonic region constitutive curve first row shear stress plotted value result obtained using different value shear stress forced homogeneous flow also plotted fig b c next three row fig dl velocity profile evolution shown function time different value reference denn denn extrusion instability wall slip annual review fluid mechanic joshi et al joshi k lele r mashelkar slipping fluid unified transient network model journal nonnewtonian fluid mechanic petrie denn c j petrie denn instability polymer processing aiche journal howells benbow e howells j benbow flow defect polymer melt trans plast inst joshi denn joshi denn planar contraction flow slip boundary condition journal nonnewtonian fluid mechanic joshi denn joshi denn rupture entangled polymeric liquid elongational flow withdissipation journal rheology shaqfeh e g shaqfeh purely elastic instability viscometric flow annual review fluid mechanic olmsted p olmsted perspective shear banding complex fluid rheologica acta divoux et al divoux fardin manneville lerouge shear banding complex fluid annual review fluid mechanic germann n germann shear banding semidilute entangled polymer solution current opinion colloid interface science varchanis et al varchanis j haward c c hopkins j tsamopoulos q shen evaluation constitutive model shearbanding wormlike micellar solution simple complex flow journal nonnewtonian fluid mechanic adam fielding olmsted j adam fielding p olmsted transient shear banding entangled polymer study using roliepoly model journal rheology moorcroft fielding r l moorcroft fielding shear banding timedependent flow polymer wormlike micelle journal rheology jain et al jain r singh l kushwaha v shankar joshi role inertia thixotropy startup flow aging soft material transient dynamic shear banding ratecontrolled flow field journal rheology kushwaha shankar joshi l kushwaha v shankar joshi dynamic shear banding stresscontrolled startup shear flow model aging soft material role inertia thixotropy rheologica acta yerushalmi katz shinnar j yerushalmi katz r shinnar stability steady shear flow viscoelastic fluid chemical engineering science helgeson et al e helgeson reichert hu n j wagner relating shear banding structure phase behavior wormlike micellar solution soft matter johnson jr segalman johnson jr segalman model viscoelastic fluid behavior allows nonaffine deformation journal nonnewtonian fluid mechanic doi edward edward doi f edward f edward theory polymer dynamic vol oxford university press cates cates reptation living polymer dynamic entangled polymer presence reversible chainscission reaction macromolecule vasquez et al p vasquez g h mckinley l p cook network scission model wormlike micellar solution model formulation visometric flow prediction journal nonnewtonian fluid mechanic giesekus h giesekus simple constitutive equation polymer fluid based concept deformationdependent tensorial mobility journal nonnewtonian fluid mechanic likhtman graham e likhtman r graham simple constitutive equation linear polymer melt derived molecular theory roliepoly equation journal nonnewtonian fluid mechanic ianniruberto marrucci g ianniruberto g marrucci shear banding doiedwards fluid journal rheology briole et al briole l casanellas fardin c py cardoso j browaeys lerouge shearbanding fluid timedependent shear flow part ii test moorcroftfielding criterion journal rheology rassolov mohammadigoushki p rassolov h mohammadigoushki role micellar entanglement kinetics shear banding flow formation journal rheology moorcroft fielding r l moorcroft fielding criterion shear banding timedependent flow complex fluid physical review letter sharma shankar joshi sharma v shankar joshi onset transient shear banding viscoelastic shear startup flow implication linearized dynamic journal rheology fielding fielding trigger signature shear banding steady timedependent flow journal rheology cao likhtman j cao e likhtman shear banding molecular dynamic polymer melt physical review letter mohagheghi khomami mohagheghi b khomami elucidating flowmicrostructure coupling entangled polymer melt part ii molecular mechanism shear banding journal rheology zhou et al l zhou p vasquez l p cook g h mckinley modeling inhomogeneous response formation shear band steady transient flow entangled liquid journal rheology zhou cook mckinley l zhou l p cook g h mckinley multiple shearbanding transition model wormlike micellar solution siam journal applied mathematics zhou et al l zhou g h mckinley l p cook wormlike micellar solution iii vcm model prediction steady transient shearing flow journal nonnewtonian fluid mechanic burroughs et al c burroughs zhang shetty c bates e helgeson l g leal flowconcentration coupling determines feature nonhomogeneous flow shear banding entangled polymer solution journal rheology benzi et al r benzi divoux c barentin manneville sbragaglia f toschi continuum modeling shear startup soft glassy material physical review e tapadia wang p tapadia sq wang direct visualization continuous simple shear nonnewtonian polymeric fluid physical review letter ravindranath et al ravindranath sq wang olechnowicz r p quirk banding simple steady shear entangled polymer solution macromolecule wang et al sq wang ravindranath p boukany homogeneous shear wall slip shear banding entangled polymeric liquid simpleshear rheometry roadmap nonlinear rheology macromolecule boukany wang p e boukany sq wang use particletracking velocimetry flow birefringence study nonlinear flow behavior entangled wormlike micellar solution wall slip bulk disentanglement chain scission macromolecule boukany wang p e boukany sq wang exploring transition wall slip bulk shearing banding wellentangled dna solution soft matter boukany wang p e boukany sq wang shear banding entangled dna solution depending level entanglement journal rheology hu et al hu l wilen philip lip constitutive relation entangled polymer monotonic journal rheology hu et al hu c palla lip comparison shear banding shear thinning entangled micellar solution journal rheology li et al li hu g b mckenna c j dimitriou g h mckinley r mick c venerus l archer flow field visualization entangled polybutadiene solution nonlinear viscoelastic flow condition journal rheology wang et al sq wang g liu cheng p e boukany wang x li letter editor sufficiently entangled polymer show shear strain localization high enough weissenberg number journal rheology peterson j peterson shear induced demixing polymer melt solution phd thesis university california santa barbara fielding olmsted fielding p olmsted kinetics shear banding instability startup flow physical review e fielding olmsted fielding p olmsted flow phase diagram concentrationcoupled shear banding european physical journal e fielding olmsted fielding p olmsted early stage kinetics unified model shearinduced demixing mechanical shear banding instability physical review letter cromer et al cromer c villet g h fredrickson l g leal shear banding polymer solution physic fluid cromer et al cromer g h fredrickson l g leal study shear banding polymer solution physic fluid peterson et al j peterson cromer g h fredrickson l gary leal shear banding prediction twofluid roliepoly model journal rheology rassolov mohammadigoushki p rassolov h mohammadigoushki effect elasticity flow ramp kinetics shear banding flow formation wormlike micellar fluid journal rheology rassolov et al p rassolov scigliani h mohammadigoushki kinetics shear banding flow formation linear branched wormlike micelle soft matter mohammadigoushki et al h mohammadigoushki dalili l zhou p cook transient evolution flow profile shear banding wormlike micellar solution experimental result comparison vcm model soft matter alam nott alam p r nott influence friction stability unbounded granular shear flow journal fluid mechanic schmid henningson p j schmid henningson optimal energy density growth hagenpoiseuille flow journal fluid mechanic schmid kytomaa p schmid h kytomaa transient asymptotic stability granular shear flow journal fluid mechanic strang borre g strang k borre linear algebra geodesy gps siam olmsted et al p olmsted radulescu cy lu johnsonsegalman model diffusion term cylindrical couette flow journal rheology lu et al cy lu p olmsted r ball effect nonlocal stress determination shear banding flow physical review letter bird et al r b bird r c armstrong hassager dynamic polymeric liquid nd ed fluid mechanic wiley new york gordon schowalter r gordon w schowalter anisotropic fluid theory different approach dumbbell theory dilute polymer solution transaction society rheology constitutive model nonaffine motion constitutive equation polymer melt solution butterworths series chemical engineering edited r g larson butterworthheinemann pp holroyd martin graham g holroyd j martin r graham analytic solution role poly model timedependent shear journal rheology tomar et al g tomar v shankar shukla sharma g biswas instability dynamic thin viscoelastic liquid film european physical journal e tanner r tanner note rayleigh problem viscoelastic fluid zeitschrift fur angewandte mathematik und physik zamp denn porteous denn k porteous elastic effect flow viscoelastic liquid chemical engineering journal title failure celebrated analysis major pivot software startup transcription title article failure celebrated analysis major pivot software startup author sohaib shahid bajwa xiaofeng wang anh nguyen duc pekka abrahamsson note author version work definite version published bajwa s wang x nguyen duc et al empir software eng copyright owner version accessed httpslinkspringercomarticleshttpslinkspringercomarticles interested academic software startup research get touch software startup research network ssrn information httpssoftwarestartupsorghttpssoftwarestartupsorgthis author version work definite version published bajwa s wang x nguyen duc et al empir software eng httpsdoiorgshttpsdoiorgs failure celebrated analysis major pivot software startup sohaib shahid bajwa free university bozen bolzano xiaofeng wang free university bozen bolzano anh nguyen duc norwegian university science technology pekka abrahamsson norwegian university science technology abstract context software startup project failure embraced actively considered crucial obtain validated learning lead pivot pivot strategic change business concept product different element business model better understanding needed different type pivot different factor lead failure trigger pivot software entrepreneurial team make better decision chaotic unpredictable environment due nascent nature topic existing research knowledge pivot software startup limited study aimed identifying major type pivot software startup make startup process highlighting factor fail software project trigger pivot achieve conducted case survey study based secondary data major pivot happened software startup pivot type triggering factor identified finding show customer need pivot common among pivot type together customer segment pivot common market related pivot major product related pivot zoomin technology pivot several new pivot type identified including market zoomin complete side project pivot study also demonstrates negative customer reaction flawed business model common factor trigger pivot software startup study extends research knowledge software startup pivot type pivot triggering factor meanwhile provides practical knowledge software startup utilize guide effective decision pivoting pivot software startup lean startup validated learning pivoting factor side project author version work definite version published bajwa s wang x nguyen duc et al empir software eng httpsdoiorgshttpsdoiorgs introduction startup human institution create innovative product service search sustainable business model extreme uncertainty blank ries software startup startup build softwareintensive productsservices similar established software company software development project reputation failure savolainen et al project software startup fail well consequence project failure software startup even severe established software company majority software startup focused one single project time one project failure could put software startup business giardino et al however interestingly failure treated positive attitude software startup extent company practice celebrating failed project supercell according anecdotal evidence kelly software startup embrace even celebrate failure since environment software startup extremely unpredictable even chaotic failure considered crucial way sometimes way obtain important learning validate key assumption make software product business eisenmann et al fact ultimate goal intermediate failure along way avoid final fatal failure put startup business intermediate failure focused study validated learning obtained failing fast failing often lead software startup making strategic change business concept product different element business model type change called pivot lean startup approach ries claimed pivot frequently occurring commonality among different successful startup ries pivot inevitable almost software startup survive grow eventually obtain sustainable business model startup get business model right immediately evidenced fact many successful software startup turn initially started instance flickr used online multiplayer role playing game rather photo managing sharing service nazar twitter initially developed podcast service microblogging service carlson importance pivot software startup deserves research attention however due nascent nature research software startup scarcity study pivot software startup comprehensive valid knowledge yet built trigger software startup pivot make certain pivot decision actually pivot study reported paper one first attempt fill knowledge gap objective study lay foundation future study software startup pivot providing basic understanding pivot software startup basic understanding includes factor trigger software startup pivot major type pivot software startup make failure happen end research question guided study phrased following rq factor trigger software startup pivot rq type pivot software startup undertake answer research question employed systematic research process collected online material secondary data analysed major pivot software startup reported material including wellknown company youtube flickr pinterest twitter online material allowed u quickly obtain useful data many significant pivot software startup possible based analysis pivot software startup extracted list factor triggered pivot identified set major type pivot conducted better structure triggering factor pivot type categorized different group respectively rest paper organized follows section background literature related work reviewed section describes research approach employed study research finding presented detail section discussed section paper summarized section also outline future research background related work software startup lean startup software startup challenging endeavour systematic mapping study paternoster et al reveals frequently reported contextual feature software startup general lack resource high reactiveness flexibility intense time pressure uncertain condition tackling dynamic fast growing market software startup dealing various difficulty constantly emerging different direction top challenge include developing technologically innovative software product require novel development tool technique defining minimum viable product capture evaluate riskiest assumption might fail business concept discovering appropriate business strategy deliver value giardino et al inspired lean principle toyota manufacturing production system womack et al ries present new approach entrepreneur innovation referred lean startup lean startup focus effort create value customer eliminate waste development phase however since customer often unknown could perceive value also unknown therefore entrepreneur get building discover customer day one blank instead emphasizing business plan lean startup advocate build product iteratively deliver market earlier feedback core activity lean startup based buildmeasurelearn bml loop startup turn idea product measure customer response learns done developing minimum viable product mvp learning referred validated learning hypothesis business model validated decision made whether pivot persevere therefore lean startup also referenced hypothesisdriven entrepreneurship eisenmann et al author version work definite version published bajwa s wang x nguyen duc et al empir software eng httpsdoiorgshttpsdoiorgs failure software startup software engineering literature software project failure defined term cost schedule overrun project cancellation lost opportunity organization embark difficult journey software development linberg software project failure lead business failure established company drastic context startup one failed project could put startup company business giardino et al eventual failure startup pass point return leading termination business software startup failure rate high nobel marmer et al essence lean startup methodology help startup make early cheap failure often possible learn intermediate failure order avoid final catastrophe ries intermediate failure occur course startup process one embraced actively lead pivoting therefore focus study related work also reviewed based perspective failure software startup learning type failure crucial however paucity study failure software startup one exception giardino et al two software startup failure documented reason identified one main reason changing direction needed word necessary pivot taken due time issue echoed study shepherd et al according moment failure always straightforward sometimes entrepreneur decide continue business even though situation hopeless however case entrepreneur pivot improve entrepreneurial learning experience study investigates factor trigger pivot software startup best knowledge author pivot software startup pivot often considered synonym change however introducing change making decision several definition pivot presented literature recent year pivot considered validating hypothesis related business model blank maurya even though compulsory pivot related business model according ries pivot special kind change designed test validate assumption product business model engine growth based definition study define pivot strategic decision lead significant change one element startup product entrepreneurial team business model engine growth element change time considered pivot starting completely new different business previous research pivot software startup limited paternoster et al bosch et al offer alternative pivot perseverere ie abandon idea presenting software development model early stage software startup however study primarily focused pivoting study van der van bosch describes pivot software startup made couple architecture decision compare pivot software architecture decision developing new product present similarity difference two type decision according study pivot software architecture decision consider risk triggering factor making decision focusesof pivot software architecture decision different study considers pivot example business decision consider product related pivot another study hirvikoski provides overview software startup pivoted historically example twitter google facebook study argues successful startup made multiple pivot journey however pivot example based empirical data study shed light startup pivot moreover lack rigorous scientific argumentation terho et al identify different pivot type product zoomout customer segment business architecture etc explain affect different part lean canvas model however lack information pivot identified categorized specific pivot category scarcity literature identify major pivot software startup made order ground research basis used pivot type reported ries awareness type subject systematic scientific validation ries present ten different type pivot happen startup zoomin pivot single feature product becomes whole product chatting feature online game becomes standalone messager app zoomout pivot opposite zoomin pivot whole product becomes single feature much larger product example photosharing app extended social medium platform photographer customer segment pivot shift one customer segment another eg training app orginally targetting professional atheletes later amateur product hypothesis partially confirmed solving right problem different customer initially anticipated customer need pivot result getting know customer extremely well sometimes one realizes problem trying solve important customer often discover related problem important solved platform pivot refers change application supporting platform vice versa eg shifting online shop platform host online shop business architecture pivot pivot startup switch business architecture eg going high margin low volume instead focusing mass market value capture pivot method capture value company creates commonly referred monetization revenue model startup capture value creates different way example value capture pivot online service changing freemium price model monthly subscription fee model engine growth pivot typical growth engine startup viral wordofmouth sticky attracting user stay productservice long possible paid growth model startup change growth strategy seek rapid profitable growth channel pivot recognition startup company identified way reach customer effective previous one eg selling productservice via post mail selling online shop technology pivot startup delivers solution using completely different technology eg app shifting io android platform addition pivot type hirvikoski proposes new one social pivot bwhere active change social factor person environment change direction companylambda similarly severe lack scientific argumentation example support new pivot type research approach study designed exploratory due nascent nature software startup research area limited number previous study pivot order quickly obtain useful data understand direction inquiry future primary research decided use secondary data software startup pivot example could find different website develop initial understanding phenomenon study secondary data mean research data either collected individual researcher conduct study purpose one currently considered often combination two vartanian several source secondary data eg census magazine newspaper blog report etc advantage using secondary data data collection process fast inexpensive vartanian used care diligence secondary data provide costeffective way gaining initial understanding research question secondary data analysis also considered starting point research method often helpful designing subsequent primary research provide baseline compare primary data analysis result boslaugh use secondary data quite common discipline psychology trzesniewski et al also becoming suitable approach software engineering research community eg wang et al overall research methodology employed study considered case survey method yin heald cruzes et al since bworks best study consist heterogeneous collection case studieslambda case collection software startup pivot example researcher main task bto aggregate characteristic necessarily conclusion caseslambda yin heald p case survey method enables researcher note various experience found case aggregate frequency occurrence experience therefore ensures analysis qualitative evidence reliable manner cruzes et al list case survey one method synthesis qualitative mixedmethods evidence applied software engineering research ensure data collection analysis process systematic reliable adopted systematic literature review guideline kitchenham adapted context developed secondary data search analysis protocol protocol help reduce researcher bias without using possible data collection analysis could driven researcher expectation kitchenham overall data collection analysis process employed study illustrated fig explained detail following text author version work definite version published bajwa s wang x nguyen duc et al empir software eng httpsdoiorgshttpsdoiorgs data collection step define refine search keywords first step data collection define search keywords used search secondary data based main objective research question brainstormed initial set search keywords search string structured using guideline given kitchenham ensure captured keywords related software startup consulted search string used systematic mapping study regarding software startup paternoster et al conducted several trial search observed fig data collection analysis process missingpagefail pivot example coming softwarebased startup webpage english exclusion criterion webpage contains duplicated content previously examined webpage webpage non textbased eg video audio image webpage slideshare quora linkedin personal company blog excluded slideshare synthetic content lack contextual information whereas webpage quora linkedin personal company blog excluded potential subjectivity content decide startup software startup pivot described real pivot used definition software startup defined beginning section pivot defined section guide inclusionexclusion step first two author conducted step separately evaluation result two researcher compared disagreed item discussed url discussed two researcher consensus achieved step resulted search result collection b contains url represents webpage identify case search result collection b read content webpage looked information software startup pivoted startup process considered mentioned software startup potential case analysis since step relatively objective straightforward mainly conducted first author case doubt second author consulted step resulted case collection contains case webpage reorganized according identified case apply quality assurance criterion case collection ensure sufficient adequate data case analysis evaluated quality data case case collection based following quality assurance criterion data case startup allow researcher reconstruct pivoting story startup term startup focused pivot made pivot researcher make excessive guessing order understand pivoting type factor triggering pivot case included answer first criterion positive answer second one negative first two author conducted step separately evaluation result two researcher compared disagreed item case discussed consensus achieved step resulted case collection b contains case used data analysis data regarding case contained webpage data one case may spread one webpage one webpage may contain data one case webpage represented url used analysis documented available permanent address httpsfigsharecomsfbbccahttpsfigsharecomsfbbcca data analysis step extract relevant data case collection b case software startup contained case collection b looking following information case background information name startup location company founding year andor first product release date business domain main businessproductservice pivot main businessproductservice pivot description explanation startup pivoted get background information first used url obtained systematic search information found checked startup homepage linkedin page still information found resorted wikipedia wikipedia used six case docker fab seesmic shopify site voylla one link discussed software startup eg two link discussing twitter example pivoting included link along description startup name step conducted first author alone mainly concerned data retrieval first second author discussed unclear case resolve uncertain aspect regarding background information case coding data identify pivot type triggering factor data extracted case analysed qualitatively identify pivot type factor triggered reported pivot relied explanation given case material identify triggering factor pivot way selected case ensured triggering factor led pivot described completely open coding process used allow emergence triggering factor meanwhile seed category pivot type described section used coding process facilitate identification type pivot software startup experienced table present example coding conducted analysis step conducted first second author separately coding result two researcher compared disagreed item pivot type pivot instance pivot triggering factor pivot instance discussed two researcher consensus achieved step resulted pivot type triggering factor author version work definite version published bajwa s wang x nguyen duc et al empir software eng httpsdoiorgshttpsdoiorgs group pivot type triggering factor provide better structure pivot type classified drawing upon four dimension claimed vital successful venture macmillan et al employed related study eg giardino et al product dimension startup developing technologically innovative solution sutton market dimension refers identifying essential need customer blank financial dimension related funding investment return investment also way startup evolves set company growth place market yu et al team dimension main driving force behind several entrepreneurial activity related product business development giardino et al triggering factor grouped external internal factor external factor beyond control startup whereas internal factor stem decision activity startup result description pivoted software startup software startup included case survey come world however majority based united state canada two case company located israel located united kingdom australia new zealand india two company could obtain information geographic location social network ecommerce finance business main business domain software startup come domain include digital government operating system health travel industry product developed startup marketdriven internetbased targeted customer either general twitter yelp youtube specific segment eg ignighter target indian user primarily twenty four case recent software startup either founded releasing first product past five year case launched product startup released product first time case product release date could obtain information table list software startup included study including company name time pivot reported webpage main business idea
Original Title: Transient shear banding during startup flow: Insights from nonlinear
  simulations
Original Transcription: # Transient shear banding during startup flow: Insights from nonlinear simulations

Shweta Sharma

Department of Chemical Engineering, Indian Institute of Technology Kanpur, Kanpur 208016, India

Yogesh M. Joshi

yogesh@iit.ac.in Department of Chemical Engineering, Indian Institute of Technology Kanpur, Kanpur 208016, India

V. Shankar

y.shankar@iit.ac.in Department of Chemical Engineering, Indian Institute of Technology Kanpur, Kanpur 208016, India

November 3, 2021We study the dynamics of shear startup of the Johnson-Segalman and non-stretching Rolie-Poly models using nonlinear simulations. Signatures of transient and steady-state shear banding are quantified by monitoring the 'degree of banding' defined as the difference between maximum and minimum shear rates during shear startup. We consider cases where the startup is from zero shear rate to shear rates in both the monotonic and nonmonotonic regions of the constitutive curve. For the Johnson-Segalman model, which exhibits a shear stress overshoot during startup, our nonlinear simulations show that transient shear banding is absent regardless of whether the start-up shear rate is in the monotonic or nonmonotonic regions of the constitutive curve. In the latter case, while there is clearly an inhomogeneity _en route_ to the banded state, the magnitude of the degree of banding is not substantially large compared to that of the eventual banded state. Marked inhomogeneity in the velocity profile is predicted for the non-stretching Rolie-Poly model only if the solvent to solution viscosity ratio is smaller than \(O(10^{-3})\), but its occurrence does not appear to have any correlation with the stress overshoot during startup. These inhomogeneities are also very sensitive to initial amplitude of perturbations and the magnitude of Reynolds number. We also compare the results obtained within the realm of linearized dynamics in our previous study (Sharma _et al._, Journal of Rheology 65, 1391 (2021)) with the present nonlinear results and show that nonlinearities have a stabilizing effect and mitigate the divergence of perturbations (as predicted within the linearized dynamics) during shear startup. We argue that the neglect of inertia in the nonlinear simulations is not self-consistent if the solvent to solution viscosity ratio is very small, and that inertial effects need to be included in order to obtain physically realistic results. Our nonlinear simulations show that the transient evolution during shear startup is quite sensitive to the Reynolds number when the solvent viscosity parameter is much smaller than unity for non-stretching Rolie-Poly model. However, the results of the Johnson-Segalman model are very robust for solvent to solution viscosity greater than \(O(10^{-3})\) and do not reveal any transient shear banding during shear startup.
Introduction

Viscoelastic fluids undergoing shear and extensional flows are often susceptible to instabilities of various kinds [1; 2; 3; 4; 5; 6; 7]. Shear banding is one such example of an instability exhibited by viscoelastic materials [8; 9; 10; 11]. Shear banding is best understood in the context of a planar Couette flow of a viscoelastic fluid with the applied shear rate in the underlying nonmonotonic region of the constitutive curve. In this situation, the linear velocity profile becomes unstable and transforms into bands of two distinct shear rates. The shear rates in the two bands lie in the stable branch of the constitutive curve.

Shear banding seen during shear startup, when the flow is transitioning to its eventual steady state, is referred to as transient shear banding. Shear banding observed after the flow has reached steady state is referred to as steady-state shear banding. Transient shear banding can, in principle, occur in both the scenarios, regardless of whether the steady state is banded or homogeneous. If the steady state is banded, however, transient shear banding must be distinguished from the inevitable inhomogeneities that will ensue _en route_ to the banded state by measuring the extent of the inhomogeneity. In recent studies, transient shear banding is quantified by measuring the difference between maximum and minimum shear rates, which has been dubbed as the 'degree of banding' [12; 13]. If the steady state is homogeneous, then the evolution of degree of banding with time will transiently increase to attain a peak and then decrease to zero. If the steady state is banded, then the presence of transient shear banding can be ascertained only if degree of banding shows a transient peak of substantially high magnitude, before attaining its eventual value at steady state. The evolution of second derivative of velocity in the direction of momentum diffusion has also been utilised in literature to find out the presence of transient shear banding [14; 15]. Also, the width of the interface between two bands must be much smaller than the width of the bands; hence, transient flow inhomogeneities during shear startup may not always be designated as transient shear banding.

The stability of steady state in a shear startup flow was first studied by Yerushalmi et. al. [16] who proposed a model independent or fluid universal criterion for existence of steady state shear banding in shear startup flow. In their manuscript, the authors stated that "It is shown that all values of the steady shear rate where the flow curve exhibits a zero or negative slope the flow is unstable." This criterion has been validated by many researchers in the literature using experiments and various constitutive models with a nonmonotonic region where shear stress decreases as a function of shear rate [17; 18; 19; 20; 21; 22; 23; 24; 25; 26].

A fluid universal or model independent criterion for existence of transient shear banding during shear startup flow has been proposed in literature by Moorcroft and Fielding [13; 27]. According to this criterion, in a shear startup flow, if shear stress shows an overshoot then the time duration in which shear stress shows a negative slope as a function of time or strain, the shear startup flow becomes unstable and should form bands of different shear rates transiently. The authors utilised the modal stability analysis method and calculated the transient eigenvalue, also known as 'frozen time' analysis, to derive the criterion. In our previous study [28], we discussed in detail the restrictive nature of the criterion based on the assumptions utilised to obtain the simplified criterion. These assumptions are (i) shear startup is at a high shear rate, (ii) frozen time analysis can be used as a tool to obtain the signature of transient shear banding, (iii) Hopf bifurcation is absent, and (iv) only one real part of transient eigenvalue is positive at any time.

Moorcroft and Fielding [13] examined the shear startup of non-stretching Rolie-Poly and Giesekus models using frozen time analysis, linearized evolution of perturbations and nonlinear simulations to check the validity of the criterion. They found that the results obtained using the non-stretching Rolie-Poly model validated the criterion and transient shear banding was observed in presence of stress overshoot, however, for the Giesekus model, transient shear banding was not observed even in presence of stress overshoot. The authors argued that since transient shear banding is an elastic instability, the models that can show stress overshoot at same magnitude of strain can qualify to show transient shear banding. Fielding [29] subsequently analysed the transient shear banding criterion for shear startup flow and and noted that while the criterion is useful, it may not be universal.

The transient shear banding criterion for shear startup flow [13] has been tested experimentally and theoretically in the literature and it has been found to be consistent with some results but not universally applicable [24; 25; 28; 30; 31; 32; 33; 34; 35; 36; 37; 38; 39; 40; 41; 42; 43; 44; 45; 46; 47] as discussed in Section II of our previous study [28]. Transient and steady state shear banding has been observed in shear startup of entangled polymeric solutions in literature and researchers have proposed flow concentration coupling to be the underlying reason [48; 49; 50; 51; 52; 53]. Transient shear banding in shear startup flow of wormlike micellar systems has also been explored in the literature but only when the startup shear rate is such that the steady state is also banded or using geometries that has quite high shear stress inhomogeneity [25; 26; 40; 54; 55; 56; 44]. To the best of our knowledge, transient shear banding has not been reported in shear startup flow of wormlike micellar solutions yet, wherein the steady state is homogeneous and shear stress is almost homogeneous between the plates. Since there can be multiple factors governing the shear banding in entangled polymeric solutions, in this study, we focus on understanding the possibility of transient shear banding in wormlike micellar solutions. We also focus on shear startup of viscoelastic constitutive models that can predict a monotonic and nonmonotonic constitutive curve and have no coupling with concentration (Rolie-Poly model) [20; 22; 23; 32] and can fit experimental results of wormlike micellar solutions (Johnson-Segalman model [18]).

In our earlier study [28], we had analyzed the transient shear banding criterion for shear startup flow using Johnson-Segalman, non-stretching Rolie-Poly, and Giesekus models using frozen time analysis and fundamental matrix method. In the frozen time analysis, the eigenvalue is calculated at each time instant during shear startup, treating the flow to be quasi steady. This approach is valid only if the transient growth rate is significantly higher than the rate of change of base-state evolution. In the fundamental matrix method [57; 58; 59; 60], the evolution of linearized perturbations can be obtained along with the evolution of base state. This method also provides maximum amplitude of perturbations that is independent of initial conditions and consequently renders more robust results as compared to frozen time analysis. We used these methods and showed that the assumptions made to derive the criterion for transient shear banding [13] are restrictive. We showed that there is no link between positive transient eigenvalue and stress overshoot. We also reported that the transiently positive eigenvalue does not lead to growth of linearized perturbations for the Johnson-Segalman model.

For some cases of shear startup of non-stretching Rolie-Poly model, we found agreement between stress overshoot, transiently positive eigenvalue and growth of perturbations as reported earlier by Moorcroft and Fielding [13]. Using the Giesekus model, we showed that a transiently positive eigenvalue is not necessary for transient growth of linearized perturbations as the transient eigenvalue is not positive if the steady state is stable. We attributed the contrasting observations of Johnson-Segalman and non-stretching Rolie-Poly models to the difference in orders of magnitude of ratio of solvent to solution viscosity which is \(0.115\) for the Johnson-Segalman model and \(10^{-5}\) for non-stretching Rolie-Poly models. For high shear rates, we showed that the maximum transient eigenvalue diverges on decreasing the ratio of solvent to solution viscosity. We also argued that if transient growth rate becomes significantly high then inertial effects can no longer be ignored. We assumed the base state evolution to be inertialess and the evolution of perturbations in presence of inertia and found that transient eigenvalue does not diverge and saturates to a constant eigenvalue. The growth of linearized perturbations also reduced significantly in the presence of inertia. We concluded that there may not be any transient shear banding if shear startup flow is solved for higher values of solvent to solution viscosity. If the ratio of solvent to solution viscosity is less than \(O(10^{-3})\), then inclusion of inertia may regularise the evolution of eigenvalue and perturbations. However, this conclusion is based on an approximate solution in which inertia is considered only during evolution of perturbations and not during base state. Furthermore, the growth of linearized perturbations also does not necessarily guarantee the presence of transient shear banding since the nonlinear terms are ignored. Therefore, it is of interest to examine whether transient shear banding is observed after considering nonlinear terms. We also determine the effect of inertia on transient dynamics of shear startup flow and whether inertia regularises the effect of low ratio of solvent to solution viscosity.

In this work, we study the shear startup flow of the Johnson-Segalman and non-stretching Rolie-Poly models using full nonlinear simulations by imposing perturbations at the beginning of the shear startup. We discuss both the models and governing equations in Sec. II. We also discuss the issue of realistic initial amplitude of perturbations to study transient shear banding in Sec. II. We explore the effect of initial amplitude of perturbation on transient dynamics of shear startup flow in presence and absence of inertia in Sec. III.1. We also study the effect of decreasing ratio of solvent to solution viscosity and inclusion of inertia in Sec. III.3. We discuss the salient conclusions of this study in Sec. IV.

## II Models and governing equations

We use the Johnson-Segalman and non-stretching Rolie-Poly models to analyse shear startup of viscoelastic fluids. We consider an incompressible viscoelastic fluid between two parallel plates that are infinite in the \(x^{*}\) and \(z^{*}\) directions and confined in the \(y\)-direction, with a gap \(H\) between the plates. Both plates are at rest for time \(t^{*}<0\), but for time \(t^{*}\geq 0\), the top plate moves at a steady velocity \(U\) in the \(x^{*}\) direction. The variables in this manuscript that include a superscript \(*\) are dimensional, while those without one are dimensionless. In addition, we assume that the no-slip boundary condition holds at both the plates. In this case, the continuity equation is satisfied automatically and the simplified Cauchy momentum equation can be written as follows:

\[\nabla\cdot\underset{\approx}{\Sigma^{*}}=\rho\frac{\partial u^{*}}{\partial t ^{*}}, \tag{1}\]where, \(\rho\) is the density of the fluid, \(u_{\sim}^{*}\) is the velocity field, and \(\underset{\approx}{\Sigma^{*}}\) is the total stress tensor. We consider the total stress to be equal to the sum of viscoelastic stress and Newtonian solvent stress contributions:

\[\underset{\approx}{\Sigma^{*}}=\underset{\approx}{\sigma^{*}}+2\bar{\eta}_{s} \hat{\gamma}^{*}, \tag{2}\]

where, \(\underset{\approx}{\sigma^{*}}\) is the viscoelastic stress, \(\bar{\eta}_{s}\) is the viscosity of solvent in a polymeric or wormlike micellar solution, and \(\hat{\gamma}^{*}=\frac{1}{2}(\nabla\underset{\sim}{u^{*}}+(\nabla\underset{ \sim}{u^{*}})^{T})\) is the shear rate tensor. We use the Johnson-Segalman [18] and the Rolie-Poly [23] models for the viscoelastic stress \((\underset{\approx}{\sigma^{*}})\). Both models are augmented by an additional stress diffusion term for unique stress selection in the non-monotonic region of the flow curve [61; 62]. The models are made dimensionless as follows: \(\underset{\approx}{\sigma}=\dfrac{\underset{\approx}{\sigma^{*}}}{((\bar{ \eta}_{s}+\bar{\eta}_{p})/\tau)}\), \(t=t^{*}/\tau\), \(\underset{\sim}{u}=\underset{\sim}{u^{*}}/U\). In the above expressions, \(\bar{\eta}_{p}\) is the contribution of polymer to the zero shear viscosity of the solution and \(\tau\) is the relaxation time of the solution. In the case of Rolie-Poly model, \(\tau=\tau_{D}\), which represents the reptation time, and for Johnson-Segalman model \(\tau=\lambda\) which is the longest relaxation time. The relevant dimensionless groups are the Weissenberg number, \(Wi=\dfrac{\tau U}{H}\) which represents non-dimensional shear rate, Reynolds number \(Re=\dfrac{\rho UH}{\bar{\eta}_{s}+\bar{\eta}_{p}}\), and the ratio of solvent viscosity to the zero shear viscosity of the solution, \(\eta_{s}=\dfrac{\bar{\eta}_{s}}{\bar{\eta}_{s}+\bar{\eta}_{p}}\). The dimensionless form of Cauchy momentum equation is given below:

\[Re\dfrac{\partial u}{\partial t}=\dfrac{\partial\sigma_{xy}}{\partial y}+\eta_ {s}Wi\dfrac{\partial^{2}u}{\partial y^{2}} \tag{3}\]

_Johnson-Segalman model_ - The Johnson-Segalman (hereafter JS) model [18] was developed to introduce non-affine motion in the upper-convected Maxwell (UCM) model by replacing the upper-convected derivative with the Gordon-Schowalter derivative [18; 63; 64]. The degree of non-affine motion is governed by the slip parameter \(\xi\). If \(\xi=0\), the JS model constitutive equations yields the UCM model and if \(\xi=2\), it reduces to the Lower Convective Maxwell (LCM) model [63]. The constitutive equation of the JS model is given by the following equation

\[\underset{\approx}{\sigma^{*}}+\lambda\underset{\approx}{\sigma^{\Box}}=2 \bar{\eta}_{p}\hat{\gamma}^{*} \tag{4}\]

and the Gordon-Schowalter derivative \(\underset{\approx}{\sigma}\)[63] is

\[\underset{\approx}{\sigma^{*}}=\left(1-\dfrac{\xi}{2}\right)\underset{ \approx}{\sigma^{*}}+\left(\dfrac{\xi}{2}\right)\underset{\approx}{\sigma^{*}} \tag{5}\]

where, \(\lambda\) is the longest relaxation time of the polymeric solution, \(\bar{\eta}_{p}\) is the contribution of polymer to the zero shear viscosity of the solution, and \(\xi\) is fixed as \(0.01\) throughout the results shown in this manuscript. The upper-convected and the lower-convected derivatives are \(\overset{\triangledown}{\underset{\approx}{\triangledown}}\) and \(\overset{\triangle}{\underset{\approx}{\triangle}}\), respectively [65]. The simplified non-dimensional component-wise equations of the model for simple shear flow are

\[\frac{\partial\sigma_{xy}}{\partial t}=\left(-\left(\frac{\xi}{2}\right)\sigma_{ xx}+\left(1-\frac{\xi}{2}\right)\sigma_{yy}+\left(1-\eta_{s}\right)\right)\dot{ \gamma}Wi-\sigma_{xy}+D\frac{\partial^{2}\sigma_{xy}}{\partial y^{2}} \tag{6}\]

\[\frac{\partial\sigma_{xx}}{\partial t}=2\left(\left(1-\frac{\xi}{2}\right) \sigma_{xy}\right)\dot{\gamma}Wi-\sigma_{xx}+D\frac{\partial^{2}\sigma_{xx}}{ \partial y^{2}} \tag{7}\]

\[\frac{\partial\sigma_{yy}}{\partial t}=-\left(\xi\sigma_{xy}\right)\dot{\gamma }Wi-\sigma_{yy}+D\frac{\partial^{2}\sigma_{yy}}{\partial y^{2}} \tag{8}\]

_Rolie-Poly model_ - The Rolie-Poly model is a single mode molecular model for entangled polymer melts with its name derived from ROuse LInear Entangled POLYmers model. This model was developed by Likhtman and Graham by simplification of the Doi-Edwards tube model [19 and 23]. This model also accounts for most of the molecular processes, including reptation, convective constraint release (CCR), chain stretch, retraction, and contour length fluctuations. The constitutive equation of the model can be expressed as follows

\[\left(\overset{\sigma^{*}}{\underset{\approx}{\sigma^{*}}}-\overset{I}{ \underset{\approx}{I}}\right)+\tau_{D}\overset{\nabla}{\underset{\approx}{ \sigma^{*}}}=-2\frac{\tau_{D}}{\tau_{R}}\left(1-\sqrt{\frac{3}{tr\left( \overset{\sigma^{*}}{\underset{\approx}{\sigma^{*}}}\right)}}\right)\left( \overset{\sigma^{*}}{\underset{\approx}{\sigma^{*}}}+\beta\left(\overset{ \sigma^{*}}{\underset{\approx}{\sigma^{*}}}-\overset{I}{\underset{\approx}{ \approx}{I}}\right)\left(\sqrt{\frac{3}{tr\left(\overset{\sigma^{*}}{ \underset{\approx}{\sigma^{*}}}\right)}}\right)^{-2\delta}\right) \tag{9}\]

where, \(\beta\) determines the effectiveness of the convective constraint release mechanism, \(\delta=\frac{1}{2}\) following [23 and 66] which fixes the strength of convective constraint release. Here, \(\overset{I}{\underset{\approx}{I}}\) is the identity tensor. Also, \(\tau_{D}\) determines the contribution of reptation to relaxation mechanism, \(\tau_{R}\) shows the contribution of chain stretching to relaxation mechanism. The number of entanglements is represented by \(Z\left(Z=\frac{\tau_{D}}{3\tau_{R}}\right)\), which consequently fixes the two relaxation times.

Likhtman and Graham [23] further simplified the model by considering \(\tau_{R}\to 0\) and \(tr\left(\overset{\sigma^{*}}{\underset{\approx}{\sigma^{*}}}\right)=3+\Delta\) (here \(\Delta=0\) because \(\tau_{R}\to 0\)). The simplified model is known as non-stretching Rolie-Poly model referred hereafter as the nRP model whose constitutive equation is given by:

\[\left(\overset{\sigma^{*}}{\underset{\approx}{\sigma^{*}}}-\overset{I}{ \underset{\approx}{I}}\right)+\tau_{D}\overset{\nabla}{\underset{\approx}{ \sigma^{*}}}=-\frac{2}{3}\tau_{D}\left(tr\left(\overset{\nabla^{*}}{ \underset{\sim}{\sigma^{*}}}\overset{u^{*}}{\underset{\sim}{\sigma^{*}}} \cdot\overset{\sigma^{*}}{\underset{\approx}{\sigma^{*}}}\right)\right) \left(\overset{\sigma^{*}}{\underset{\approx}{\sigma^{*}}}+\beta\left( \overset{\sigma^{*}}{\underset{\approx}{\sigma^{*}}}-\overset{I}{ \underset{\approx}{\sigma^{*}}}\right)\right) \tag{10}\]

The component-wise equations of the nRP model in nondimensional form for simple shear flow are as follows:\[\frac{\partial\sigma_{xy}}{\partial t}=Wi\dot{\gamma}\left(\sigma_{yy}-\frac{2}{3} \sigma_{xy}^{2}(1+\beta)\right)-\sigma_{xy}+D\frac{\partial^{2}\sigma_{xy}}{ \partial y^{2}} \tag{11}\]

\[\frac{\partial\sigma_{yy}}{\partial t}=\frac{2}{3}Wi\dot{\gamma}\left(\beta \sigma_{xy}-\sigma_{yy}\sigma_{xy}\left(1+\beta\right)\right)-\left(\sigma_{ yy}-1\right)+D\frac{\partial^{2}\sigma_{yy}}{\partial y^{2}} \tag{12}\]

The results presented in this manuscript using the nRP model are obtained using \(\beta=0.6\) to solve shear startup flow with shear rate in the nonmonotonic region of the constitutive curve and \(\beta=1\) is used for shear rate in monotonic region of the constitutive curve. We carry out full non-linear simulations for simple shear flow using JS and nRP model and solve Eqs. 1, Eqs. 6-8 and Eqs. 11-12. In this study, we impose a perturbation as initial condition for \(\underset{\sim}{u}\) and \(\underset{\approx}{\sigma}\) which is expressed as follows:

\[\underset{\sim}{u}=\underset{\sim}{u^{0}}+A\sin(n\pi y) \tag{13}\] \[\underset{\approx}{\sigma}=\underset{\approx}{\sigma^{0}}+A\cos(n \pi y) \tag{14}\]

where, \(A\) is the amplitude of sine or cosine wave and \(n\) fixes its wavelength. All stress components and shear rate perturbation are chosen as cosines, so that the velocity perturbation can be written in terms of sines, and thus the no-slip boundary condition gets satisfied at \(y=0\) and \(1\). In this manuscript, \(n\) (in Eqs. 13 and 14) is fixed as \(1\) throughout the manuscript, as it yields the most unstable mode and \(A\) is considered as \(10^{-1}\), \(10^{-4}\), and \(10^{-7}\).

### A note on the magnitude of shear rate initial condition

When the JS and nRP models are solved for shear startup in the absence of inertia, then it is not possible to specify the initial amplitude of shear rate because the governing Cauchy momentum equation is devoid of any acceleration in the inertialess limit. In this limit, the initial value of the shear rate is actually dictated by the initial value of \(\sigma_{xy}\) as given by the Cauchy momentum equation (Eq. 3) in the absence of inertia: \(\dot{\gamma}(t=0)=\sigma_{xy}(t=0)/(\eta_{s}Wi)\). As a consequence, for \(\eta_{s}\ll 1\), the initial shear rate perturbation is \(O(\eta_{s}^{-1})\sigma_{xy}(t=0)\), i.e., it is much larger than the magnitude of the stress perturbation. Thus, for \(\eta_{s}\ll 1\), if we impose an \(O(1)\) stress perturbation at \(t=0\), the shear rate perturbations become much larger than unity. Note that the step change in the shear rate, in the shear start-up protocol, is itself from \(0\) to \(1\). However, if we use a \(\sigma_{xy}\sim O(1)\) at \(t=0\), this would yield a very high value of the shear rate at \(t=0\). It is unrealistic to impose a large (i.e. \(\gg O(1))\) shear rate perturbation as an initial condition in the nonlinear simulations, since the maximum imposed shear rate in the base state itself is \(O(1)\). Note that the initial conditions that we use in our numerical simulations are intended to mimic inevitable (spontaneous) perturbations that would be present in any laboratory experiment. Thus, in order for the initial conditions in the numerical simulations to be physically realistic, one should not have the shear rate perturbation magnitudes to be much larger than the base-state shear rate itself, which is unity in our case. In order to address this issue, especially in the limit of small \(\eta_{s}\), it is necessary to prescribe the initial shear stress perturbation amplitudes in a manner that the initial shear rate perturbation is at most \(O(10^{-1})\) (i.e. 10% of the imposed shear rate jump in the startup flow).

The non-linear simulations are carried out using COMSOL 5.0(r). The inbuilt partial differential equation solver of COMSOL utilizes the finite element method. The domain (0,1) is discretized into 6452 points (also, the results have been verified for mesh size and time stepping). The transient evolution of nRP model for shear start-up to shear rate in the non-monotonic region of the constitutive curve is sensitive to the change in number of domain elements by an order of magnitude (owing to the linearly unstable velocity profile). However, the overall conclusion of the study remains same for all these results. The results from the JS model and the nRP model are same for 6000-10000 domain elements. The relative and absolute tolerance is kept at \(10^{-5}\) and \(10^{-6}\), respectively.

## III Results and Discussion

In our earlier work [28], we demonstrated that if there is a stress overshoot during shear startup, this does not guarantee a positive eigenvalue within the frozen-time linear stability analysis, nor does it result in the growth of perturbations within a more accurate analysis of linearized dynamics using the fundamental matrix approach. (Some of the caveats of the frozen time analysis has also been mentioned in Ref. [13].) The former, in particular, has been used as a signature of transient instability in the literature [12; 13]. While results from linearized dynamics are suggestive of the time evolution when the perturbations are infinitesimal, the ultimate answer to the question of whether transient shear banding is present or not, must come from fully-nonlinear solutions of shear startup, which is the objective of the present study. Here, we numerically solve the partial differential equations mentioned in Sec. II, and determine the relevance of stress overshoot, positive eigenvalue within a frozen-time stability analysis, and the growth and decay of linearizedperturbations on transient shear banding. We analyze the shear startup of JS and nRP models with the shear rates in both monotonic and nonmonotonic regions of the constitutive curves. As discussed in Sec. I, shear banding can be identified and quantified more reliably by peak in second derivative of velocity [14; 15]. However, in this work, to quantify steady state and transient shear banding in each case, we calculate the degree of banding which is defined as the difference between maximum and minimum shear rates of the flow of fluid between parallel plates [12; 13]. If the degree of shear banding is zero, then the flow is homogeneous otherwise it is inhomogeneous and its magnitude determines the extent of inhomogeneity in the flow. We also show the corresponding velocity profiles as a function of time to correlate them with degree of banding. As noted in the preceding section, we specifically address the question of realistic amplitudes of the initial imposed stress perturbation under the creeping-flow assumption. In the subsequent subsections (Sec. III.2-III.3), we examine the influence of flatness of constitutive curve (or solvent viscosity) and inertia.

### Effect of initial amplitude of perturbation

We first discuss the effect of initial amplitude of perturbation \((A)\) by considering both \(Re=0\) and \(Re\neq 0\). By computing the transient dynamics at varying magnitudes of \(A\), we examine the extent of validity of results of linearized dynamics, which are strictly valid in the limit \(A\ll 1\). For \(Re=0\), the initial shear rate perturbation amplitude cannot be specified directly and is dictated by the magnitude of the initial stress perturbation \(\sigma_{xy}(t=0)\) from the Cauchy momentum equation (Eq. 3). However, for \(Re\neq 0\), initial shear rate perturbation can be specified directly as mentioned in preceding section. In the following subsections, we also compare the shear stress evolution for different \(A\) which is obtained using full nonlinear simulations. For comparison, we also show shear stress evolution for forced homogeneous flow which is obtained by solving the JS and nRP models with the assumption of linear velocity profile at all times, \(Re=0\) and no stress diffusion.

#### iii.1.1 \(Re=0\)

JS modelWe first study shear startup of the JS model in the creeping-flow limit, and for shear rate in the monotonic region of the constitutive curve. In this case, we fix \(\eta_{s}=0.16\) and 

[MISSING_PAGE_EMPTY:12]

of banding \((\Delta\dot{\gamma}_{max})\) increases in a linear manner with \(A\). Similarly, the velocity profiles plotted in Fig. S1 of the supplementary information show no transient shear banding or any significant deviation from linear velocity profile for all the explored values of \(A\) at \(Re=0\).

We next study the effect of initial amplitude of perturbation in the shear startup flow of the JS model for the case when the shear rate is in the nonmonotonic region of the constitutive curve and steady state shear banding is observed. We solve the JS model at \(Wi=12\), \(\eta_{s}=0.05\), and \(A=10^{-1}\), \(10^{-4}\), and \(10^{-7}\) for initial amplitude of perturbations with \(Re=0\). Figures 2 (a) and (b) show the shear stress and the degree of banding as a function of time. The shear stress increases and shows an overshoot before attaining steady state. The evolution of \(\Delta\dot{\gamma}\) shows a linear increase before attaining steady state as shown in Fig. 2(b). The initial linear increase of \(\Delta\dot{\gamma}\) with time on a semi-log plot clearly demonstrates the exponential growth of perturbations, which is expected as shear rate is in the linearly unstable region of constitutive curve [16]. Figure 3(b) also shows that \(\Delta\dot{\gamma}_{max}\) is same as \(\Delta\dot{\gamma}_{steady-state}\) for \(A=10^{-4}\) and \(10^{-7}\), and slightly higher for \(A=10^{-1}\). The stress evolution overlap with each other in all these cases, except just before attaining a final steady-state stress. We find that the time of attaining steady state value of degree of banding \((\Delta\dot{\gamma})\) depends on the value of \(A\). Higher the value of \(A\), lower is the time required for the JS model to become unstable and attain steady state shear banding. These results also demonstrate that perturbationsbegin to grow exponentially at time \(t<1\) (i.e. \(t\approx 0.3\)). Consequently, the onset of instability (as exemplified by the exponential growth at early times) has no correlation with the time during which stress shows any decrease after its overshoot. Also, there is no pronounced transient increase (i.e., \(\Delta\dot{\gamma}\) is not greater than \(\Delta\dot{\gamma}_{steady-state}\)) during the time range in which there is a stress decay after overshoot as shown in Fig. 2. We also observe that for \(A=10^{-1}\), there are some oscillations in the variation of \(\Delta\dot{\gamma}\) with time. However, the peak values of \(\Delta\dot{\gamma}\) during these oscillations are not significantly higher than the value of \(\Delta\dot{\gamma}\) at steady state. Therefore, these oscillations cannot be treated as a signature of transient shear banding.

The above results show that under creeping-flow assumption and shear rate in the monotonic region of the constitutive curve, JS model shows (i) no transient shear banding even though the linearized perturbation showed growth and decay during the flow, (ii) the maximum value of degree of banding (\(\Delta\dot{\gamma}_{max}\)) is of the order of \(A\) and varies in a linear manner with \(A\), and (iii) the time associated with maximum degree of banding depends on \(A\). If the shear rate is in the nonmonotonic region of the constitutive curve, then also distinct transient shear banding is not observed and increase in degree of banding begins almost at beginning of the flow and this time is much lesser than the time at which shear stress decreases after its overshoot.

nRP modelWe next study the effect of initial amplitude of perturbation on the shear start-up of the nRP model under the creeping-flow assumption when the shear rate is in the monotonic

Figure 3: (a) The maximum of degree of banding (\(\Delta\dot{\gamma}_{max}\)) is plotted for shear startup of JS model if the shear rate is in the monotonic \((Wi=12,\eta_{s}=0.16)\) and (b) the ratio of maximum of degree of banding \((\Delta\dot{\gamma}_{max})\) with degree of banding at steady state \((\Delta\dot{\gamma}_{steady-state})\) is plotted if the shear rate is in the nonmonotonic \((Wi=12,\eta_{s}=0.05)\) region of the constitutive curve for \(A=10^{-1}\), \(10^{-4}\), \(10^{-7}\) and \(Re=0\), \(10^{-2}\), \(10^{-1}\).

region of the constitutive curve \((Wi=30\), \(\eta_{s}=10^{-4}\), and \(\beta=1\)). As mentioned in Sec. II, in the absence of inertia, it is not possible to provide initial conditions to the shear rate. Instead, the initial values of the shear rate are fixed by the initial stress perturbation \(\sigma_{xy}(t=0)\) via the Cauchy momentum equation (Eq. 3). Because \(\dot{\gamma}(t=0)=\sigma_{xy}(t=0)/\eta_{s}\), the shear rate perturbations become much larger than the stress perturbations. For \(A=10^{-1}\), initial shear rate perturbation is of the order of \(10^{2}\) (\(10^{4}\%\) of base state shear rate for \(\eta_{s}=10^{-4}\)). Similarly, for \(A=10^{-4}\), initial shear rate perturbation is of the order of \(10^{-1}\) (\(10\%\) of base state shear rate) and for \(A=10^{-7}\)

Figure 4: Effect of amplitude of perturbation \((A)\) for shear startup of the nRP model for \(Re=0\). Here, \(Wi=30,\eta_{s}=10^{-4},\beta=1\) which corresponds to a shear rate in the monotonic region of the constitutive curve. (a) Shear stress evolution is plotted for \(A=10^{-1}\), \(10^{-4}\), \(10^{-7}\) and for a forced homogeneous flow. (b) The variation of degree of banding \((\Delta\dot{\gamma}=\dot{\gamma}_{max}-\dot{\gamma}_{min})\) with time is shown for different values of \(A=10^{-1}\), \(10^{-4}\), and \(10^{-7}\) for \(Re=0\). The inset of Fig. (b) shows early time \((t=0-0.3)\) for variation of degree of banding on a semi-log plot. (c) The early time \((t=0-0.01)\) variation of degree of banding with time for \(\eta_{s}=10^{-4}\), \(A=10^{-4}\) and \(Re=0\) on a semi-log plot.

initial shear rate perturbation is of the order of \(10^{-4}\) (0.01% of the base state shear rate).

We find that shear stress evolution does not overlap each other for \(A=10^{-1}\), \(10^{-4}\), and \(10^{-7}\) at \(Re=0\) as shown in Fig. 4(a). The velocity profiles during shear startup flow for \(A=10^{-1}\) and \(Re=0\) show the presence of transient shear banding with a negative velocity profile as shown in Fig. 7(a). The corresponding evolution of degree of banding is shown in Fig. 4(b). The evolution of \(\Delta\dot{\gamma}\) as a function of time shows a sharp increase and then finally decays to zero for \(A=10^{-1}\), \(10^{-4}\), and \(10^{-7}\). The inset of Fig. 4(b) shows the early time behavior \((t=0-0.3)\) on a semi-log plot and Fig. 4(c) shows the evolution only for \(A=10^{-4}\) and \(t=0-0.01\). These results show that perturbations initially grow linearly followed by a growth which is stronger than linear before final decay to zero. This result shows that the growth of perturbation is exponential which implies that the shear startup of nRP is transiently (and linearly) unstable for \(Re=0\). However, the exponential growth of perturbation begins almost at the start of the flow and may not have any correlation with time at which shear stress starts to decrease after its overshoot. Similarly, the value of \(\Delta\dot{\gamma}_{max}\) is significantly larger than the input amplitude \(A\) as shown in Fig. 6(a). Therefore, we can treat this as an intrinsic instability of shear startup of the nRP model.

Interestingly, figure 4(b) shows that the time of peak of \(\Delta\dot{\gamma}\) decreases with increase in value of \(A\) and the value of \(\Delta\dot{\gamma}_{max}\) also depends on the value of \(A\). On increasing the value of \(A\), the value of \(\Delta\dot{\gamma}_{max}\) also increases but not in a linear manner as shown in Fig. 6(a). The decrease in \(\Delta\dot{\gamma}_{max}\) with \(A\) is also clearly visible in the velocity profile evolution for \(A=10^{-7}\) as there is only a slight deviation from the linear velocity profile and not any transient shear banding or transient negative velocity profile (Fig. 7(b)). The shear stress, degree of banding and velocity profile obtained using \(Wi=30\), \(\eta_{s}=10^{-4}\), \(\beta=1\), \(A=10^{-1}\), and \(Re=0\) in Figs. 4(a), 4(b) and 7(a) has also been appeared in Ref. [13]. We have included these results only for comparison purposes.

If the shear rate is in the nonmonotonic region of the constitutive curve \((Wi=30\), \(\eta_{s}=10^{-4}\), and \(\beta=0.6)\), we find that for \(Re=0\), shear stress evolution as a function of time for different values of \(A\) does not overlap as also observed in the previous case (the initial shear rate perturbation and shear stress perturbation is same as for previous case as the value of \(A\), \(\eta_{s}\), and \(Wi\) is same in this case as well). If the value of \(A\) is higher, shear stress attains steady state at lower values of time as shown in Fig. 5(a). The evolution of \(\Delta\dot{\gamma}\) with time also confirms that the degree of banding shows a rapid increase to attain a maximum value and then decreases to a constant value if \(y-\) axis is linear. If \(\Delta\dot{\gamma}\) versus time is plotted on a semi-log scale, then the increase in degree of banding is linear or stronger than linear before attaining a steady state as shown in Figs. 4(b) and 4(c). This result demonstrates the exponential growth of perturbations which is in agreement with criterion of Yerushalmi et. al. [16]. However, the time at which degree of banding begins to grow exponentially is much lesser than time at which shear stress starts to decrease after its overshoot. In the literature [25; 26; 30; 31; 32; 32], the time of decrease in stress after stress overshoot is often linked with time at which steady state shear banding structure begins to form. However, our results show that shear banding structures starts to form at the beginning of the flow, but may not be discernible in experiments, and hence the shear banding structures are not associated with the time of decrease in stress after its overshoot.

More importantly, the evolution of \(\Delta\dot{\gamma}\) with time on a semi-log plot for the nRP model shows a linear increase initially followed by a nonlinear increase in both cases of shear rate in the monotonic as well as nonmonotonic region of the constitutive curve (Figs. 4(b) and 5(b)). Because of these findings, it is clear that the linear stability analysis predicts only the exponential growth at very early times, and soon after nonlinear effects take over, and hence the linearized dynamics loses its relevance for times where there is a stress overshoot and decay. The caution regarding the use of linear stability analysis in unsteady flow (shear startup flow) to assess the occurrence of shear banding has also been pointed out by Peterson [47].

The transiently high value of \(\Delta\dot{\gamma}\) shows the presence of transient shear banding and the constant value of \(\Delta\dot{\gamma}\) at steady state show presence of steady state shear banding. Figure 6(b) shows that for \(Re=0\), the value of \(\Delta\dot{\gamma}_{max}\) is much higher than \(\Delta\dot{\gamma}_{steady-state}\), however, \(\Delta\dot{\gamma}_{max}\) depends on the value of \(A\) but not in a linear fashion. As noted in previous case (i.e., corresponding to results shown in Fig. 4(b)), the time of maximum value of degree of banding depends on the value of \(A\). Higher the value of \(A\), lower is the time corresponding to maximum value of degree of banding, and higher will be the value of \(\Delta\dot{\gamma}_{max}\) as shown in Figs. 5(b) and 6(b). This observation is also similar to the previous case in which shear startup flow is solved for shear rate in the monotonic region of the constitutive curve. Also, transient negative velocity profile is observed in the case of \(Re=0\) for \(A=10^{-1}\) and \(A=10^{-4}\) but no transient negative velocity profile (or a distinct transient shear banding, which is not a part of gradual development to steady state shear banding) has been observed for \(A=10^{-7}\) as shown in Fig. S7.

In contrast to the JS model results, the nRP model showed that under the creeping-flow assumption (i) there can be transient shear banding in presence of stress overshoot (regardless of whether the steady-state velocity profile is homogeneous or banded). This result is in agreement with the observation reported in our previous study (Fig. 5(b) of Ref. [28]) wherein we showed that the lin earized perturbations grow rapidly and attain a maximum of the order of \(10^{4}\) before continuous decrease for \(\eta_{s}=10^{-4}\). However, the presence of transient shear banding (degree of banding) is sensitive to the magnitude of \(A\), and is observed only if the initial shear rate perturbation is unrealistically high, i.e., \(A=0.1\) for \(\eta_{s}=10^{-4}\) and \(Wi=30\) in the case of the nRP model. The effect of amplitude of perturbation on transient shear banding is in agreement with the results obtained in literature for the stretching Rolie-Poly model [12]. (ii) The time associated with maximum value of degree of banding and the maximum value of the degree of banding depends on the value of \(A\).

Figure 5: Effect of amplitude of perturbation \((A)\) for shear startup of the nRP model for \(Re=0\). Here, \(Wi=30,\eta_{s}=10^{-4},\beta=0.6\) which corresponds to a shear rate in the nonmonotonic region of the constitutive curve. (a) Shear stress evolution is plotted for \(A=10^{-1}\), \(10^{-4}\), \(10^{-7}\) and for a forced homogeneous flow. (b) The variation of degree of banding \((\Delta\gamma=\gamma_{max}-\gamma_{min})\) with time is shown for different values of \(A=10^{-1}\), \(10^{-4}\), and \(10^{-7}\) for \(Re=0\). The inset of Fig. (b) shows early time \((t=0-0.13)\) for variation of degree of banding on a semi-log plot. (c) The early time \((t=0-0.01)\) variation of degree of banding with time for \(\eta_{s}=10^{-4}\), \(A=10^{-4}\) and \(Re=0\) on a semi-log plot.

Figure 6: The maximum of degree of banding \((\Delta\dot{\gamma}_{max})\) for \(A=10^{-1}\), \(10^{-4}\), \(10^{-7}\) and \(Re=0\), \(10^{-2}\), \(10^{-1}\) is plotted for shear startup of nRP model if the shear rate is the (a) monotonic \((Wi=30,\eta_{s}=10^{-4},\beta=1)\) and (b) nonmonotonic \((Wi=30,\eta_{s}=10^{-4},\beta=0.6)\) region of the constitutive curve.

Figure 7: Velocity profile evolution during the shear startup flow of the nRP model fluid at \(Wi=30\), \(\eta_{s}=10^{-4}\), and \(\beta=1\) which corresponds to a shear rate in the monotonic region of the constitutive curve. Figure (a) shows result for \(Re=0\) and \(A=10^{-1}\) and figure (b) shows result for \(A=10^{-7}\) and \(Re=0\). Figure (c) shows result for \(A=10^{-1}\) and \(Re=10^{-1}\) and figure (d) shows result for \(A=10^{-4}\) and \(Re=10^{-1}\).

(iii) The variation of \(\Delta\dot{\gamma}_{max}\) with \(A\) is not linear, and suggests the importance of nonlinearities in the dynamics (Fig. 6(b)). (iv) If the magnitude of the initial shear rate perturbation is realistic then there may not be any discernible transient shear banding. (v) In both cases, the increase in degree of banding is exponential initially and occurs at time, which is much lesser than time associated with stress overshoot.

The contrasting results of the JS and nRP models can be ascribed to the following reasons: (i) In the case of JS model, the magnitude of the initial shear rate perturbation is not unrealistically high because the value of \(\eta_{s}\) was not much smaller compared to unity. (ii) In the case of nRP model, the initial shear rate perturbation becomes unrealistic because of low value of \(\eta_{s}\) if the stress perturbations are \(O(1)\). Therefore, under the creeping-flow assumption, if the initial shear rate perturbation is realistic then there may be no transient shear banding observed in shear startup flow of JS and nRP models.

#### iii.2.2 \(Re\neq 0\)

We now study the shear startup of the JS and nRP models with non-zero inertial effects. We consider \(Re=10^{-2}\) and \(Re=10^{-1}\) for comparing results of both models. For nonzero inertia, the initial shear rate perturbation can be specified directly in terms of \(A\). However, as the value of \(\eta_{s}\) considered differs by orders of magnitude between the two models, the effect of initial amplitude of perturbation in both models is different as discussed below. The effect of inertia on transient shear banding is discussed in Sec. III.3. The effect of initial amplitude of perturbation on evolution of stress and degree of banding with time for both the models is plotted in Figs. S2, S4, S6 and S8 of the supplementary information.

JS modelFor the JS model, we find that during shear startup if the shear rate is in the monotonic or nonmonotonic region of the constitutive curve, then the results obtained for different initial amplitude of perturbations for non-zero inertia are similar to those for \(Re=0\). Figure 3(a) shows that the value of \(\Delta\dot{\gamma}_{max}\) is of the order of A and increases with A in a linear fashion for \(Re\neq~{}0\) as well as for \(Re=0\). Similarly, if the shear rate is in the nonmonotonic region of the constitutive curve, then also the variation of \(\Delta\dot{\gamma}_{max}\) with \(A\) is same for \(Re=0\) and \(Re\neq 0\) as shown in Fig. 3(b).

nRP modelFor the nRP model, we find that the variation of \(\Delta\dot{\gamma}_{max}\) with \(A\) is not proportional to the value of \(A\) which is in contrast to the results of JS model for \(Re\neq 0\) as shown in Fig. 6(a). Interestingly, for \(Re=10^{-1}\), \(A=10^{-1}\), and \(10^{-4}\), the value of \(\Delta\dot{\gamma}_{max}\) is proportional to \(A\) but it is not the case for \(A=10^{-7}\). This result shows that the variation of \(\Delta\dot{\gamma}_{max}\) with \(A\) is affected by the nonlinearities in the dynamics of shear startup of nRP model. For \(Re=1\) and \(Re=10\), the variation of \(\Delta\dot{\gamma}_{max}\) is proportional to \(A\). This result is discussed in detail in Sec. III.3.

Similarly, if the shear rate is in the nonmonotonic region of the constitutive curve, then in presence of inertia, the effect of initial amplitude of perturbation is similar to \(Re=0\) case except for \(Re=10^{-1}\) as shown in Fig. 6(b). For \(Re=10^{-1}\), the value of \(\Delta\dot{\gamma}_{max}\) is equal to \(\Delta\dot{\gamma}_{steady-state}\) for \(A=10^{-4}\) and \(10^{-7}\), and \(\Delta\dot{\gamma}_{max}\) is slightly higher than \(\Delta\dot{\gamma}_{steady-state}\) for \(A=10^{-1}\). For \(Re<10^{-1}\), the variation of \(\Delta\dot{\gamma}_{max}\) depends on \(A\) but not in a linear manner, which also shows that the presence of transient shear banding is sensitive to the initial amplitude of perturbation even in the presence of inertia.

The effect of initial amplitude of perturbation in the case of JS model in the presence of inertia is similar to the non-inertial case where a direct shear rate perturbation amplitude cannot be specified in both the steady state homogeneous and the nonhomogeneous case. Interestingly, the results of nRP model for non-inertial cases are qualitatively similar to results obtained in presence of inertia if \(Re<10^{-1}\). We attribute this observation also to smaller value of \(\eta_{s}\) used for the nRP model. This can be rationalized using the Cauchy momentum equation given by:

\[\frac{\partial u}{\partial t}=\frac{1}{Re}\frac{\partial\sigma_{xy}}{\partial y }+\frac{\eta_{s}Wi}{Re}\frac{\partial^{2}u}{\partial y^{2}} \tag{15}\]

which shows that if \(Re\) is \(O(10^{-5})\), then first term of R.H.S. of Eq. 15 becomes much larger in magnitude compared to second term. However in case of JS model, if \(Re\) is \(O(10^{-5})\), then the order of both terms of R.H.S. of Eq. 15 will be of the same order as \(\eta_{s}=0.16\). Interestingly, it has indeed been observed in the literature that increase in order of viscous dissipation has a stabilizing effect on flow [67].

### Effect of solvent viscosity or flatness of constitutive curve

In our previous study (Fig. 1 of Ref. [28]), we showed that decreasing \(\eta_{s}\) leads to more flattening of the constitutive curve for both JS and nRP models. This result is consistent with the results reported in the literature [12 and 13]. (The flatness of the constitutive curve can also be increased by increasing the number of entanglements [26]; however, in this study, we focus only on the effect of \(\eta_{s}\) by keeping the number of entanglements fixed.) We now discuss the effect of decreasing the solvent viscosity contribution or increase in flatness of constitutive curve. Several results have been reported in the literature [12; 13] suggesting that increasing the flatness of constitutive curve increases the chances of transient shear banding in shear startup flow. In this section, we focus on the effect of solvent viscosity only for shear rates in the monotonic region of the constitutive curve. In our previous study [28], we showed using the JS model that there is no significant change in the transiently maximum eigenvalue or the maximum value of growth of linearized perturbation with decrease in \(\eta_{s}\). We also noted that in order to study the effect of flatness of the constitutive curve, the value of \(\eta_{s}\) cannot be lowered below \(1/9\) in order for the constitutive curve to be monotonic. During the course of the present study, we found that even in the results from nonlinear simulations, there is no significant effect of decreasing the solvent viscosity (from 0.16 to 0.115) on degree of banding evolution (data not shown).

However, for the nRP model, we showed [28] that there is a significant change in the transiently maximum eigenvalue or the maximum value of growth of linearized perturbation with decrease in \(\eta_{s}\). Using nonlinear simulations, we next study the effect of \(\eta_{s}\) on the degree of banding of nRP model for \(\eta_{s}=10^{-3}\) and \(\eta_{s}=10^{-5}\). We study the shear stress and the variation of degree of banding with time for \(Re=0\), \(10^{-2}\), and \(10^{-1}\) with \(A=10^{-1}\), \(10^{-4}\), and \(10^{-7}\). For \(\eta_{s}=10^{-3}\), the variation of \(\Delta\dot{\gamma}_{max}\) with \(A\) is nonlinear, and it is not of the order of \(A\) for \(Re=0\) and \(Re=10^{-2}\) as shown in Figs. 8 (b), (c) and 9. For \(Re=10^{-1}\), the variation of \(\Delta\dot{\gamma}_{max}\) with \(A\) is linear and it is of the order of \(A\).

For \(\eta_{s}=10^{-5}\), the variation of \(\Delta\dot{\gamma}_{max}\) is independent of the order of \(A\) for \(Re=0\), \(10^{-2}\), and \(10^{-1}\) as shown in Figs. 8 (f)-(h) and 9. Also, the value of \(\Delta\dot{\gamma}_{max}\) is much higher for \(\eta_{s}=10^{-5}\) as compared to \(\eta_{s}=10^{-3}\) for each value of \(Re\). (The effect of inertia on transient shear banding is discussed in Sec. III.3). The effect of decreasing \(\eta_{s}\) on \(\Delta\dot{\gamma}_{max}\) is also summarized in Fig. 11. For \(A=10^{-1}\), \(\Delta\dot{\gamma}_{max}\) diverges in a power law fashion with exponent \(-1\). For \(A=10^{-4}\) and \(A=10^{-7}\), the divergence of \(\Delta\dot{\gamma}_{max}\) does not appear to follow a power law. The divergence of \(\Delta\dot{\gamma}_{max}\) with decrease in \(\eta_{s}\) is also similar to divergence of transient growth rate (or eigenvalue) with decrease in \(\eta_{s}\) in our previous study on linearized analysis [28]. We also show the corresponding velocity profiles in Fig. 10 for \(Re=0\), \(A=10^{-7}\) and \(Re=10^{-1}\), \(A=10^{-7}\). Figure 10 (a) shows that as the velocity profile deviates from the linear profile and shows negative velocity transiently with negative most velocity as -15! This implies that if the top plate velocity is 1, the velocity of fluid between the plates is 15 times the top plate velocity in the opposite direction. This result highlights the unrealistic nature of results obtained due to low value of \(\eta_{s}\) even with \(A=10^{-7}\) and is consistent with unbounded growth of linearized perturbations shown in our previous study [28]. We discuss how physically realistic results can be obtained below in Section III.

For the nRP model, decrease in solvent viscosity leads to divergence of \(\Delta\dot{\gamma}_{max}\). However, the same trend is not observed for the JS model, consistent with results obtained from the linearized analysis in our earlier study [28]. In addition, we also found that there is no effect of variation of \(A\) in case of nRP model for \(\eta_{s}=10^{-5}\), which can be attributed to the significantly high \((O(10^{3}))\) value of transient growth rate. Therefore, on consideration of results of the JS and nRP models, we find that the divergence of \(\Delta\dot{\gamma}_{max}\) is not due to increase in flatness of constitutive curve, but rather due to the decrease of \(\eta_{s}\).

### Effect of inertia

In our previous study [28], we had analyzed the evolution of linearized perturbations in shear startup while the base state is also evolving. We accounted for the effect of inertia by inclusion of inertial effects during the evolution of linearized perturbations, while the base state evolution was inertialess. We found out that if \(Re=0\) during the evolution of linearized perturbation, then the

Figure 8: Effect of amplitude of perturbation \((A)\) for \(Re=0\), \(10^{-2}\), and \(10^{-1}\) for shear startup flow of the nRP model for \(\eta_{s}=10^{-3}\) and \(\eta_{s}=10^{-5}\). First row shows results for shear startup flow of nRP model at \(Wi=30,\eta_{s}=10^{-3}\), and \(\beta=1\) while second row shows result for shear startup flow of nRP model at \(Wi=30,\eta_{s}=10^{-5}\), and \(\beta=1\) and both results are obtained for shear rate in the monotonic region of the constitutive curve. Figure (a) and (e) shows the shear stress evolution as a function of time and figure (b)-(d), figure (f)-(h) shows the degree of banding as a function of time during the shear startup flow.

transiently maximum eigenvalue diverges with decrease in \(\eta_{s}\). However, on inclusion of inertia during the evolution of linearized perturbations, the transient maximum of eigenvalue saturates to a finite value. The magnitude of saturated eigenvalue decreases with increase in \(Re\). In this section, we discuss the results obtained by considering the effect of inertia in full non linear simulations in which perturbations are evolving with the flow.

JS modelWe first compare the results obtained for different \(Re\) during shear startup of the JS model, with shear rates in monotonic and non-monotonic regions of the constitutive curve. Figure 12 shows the effect of inertia on the evolution of the degree of banding as a function of time for \(A=10^{-1}\), \(A=10^{-4}\), and \(A=10^{-7}\) if the shear rate is in the monotonic region of the constitutive curve and Fig. 13 shows the results when the shear rate is in the nonmonotonic region of the constitutive curve. We have already discussed the evolution of degree of banding for JS model in Figs. 1(b) and 2(b). As shown in Figs. 12 and 13, we find that inertia has no effect on the variation of degree of banding with time for \(A=10^{-1}\), \(10^{-4}\), and \(10^{-7}\). The degree of banding evolution does not overlap initially due to the presence of inertio-elastic waves [68; 69] (that are depicted in the corresponding velocity profiles shown in supplementary information). This result is consistent with our previous study using linear analysis wherein we showed that the magnitude of the transient maximum eigenvalue is small due to the high value of \(\eta_{s}\) and as the transient growth rate is not that high, the inertial effects do not affect the dynamics of the shear startup flow.

[MISSING_PAGE_EMPTY:25]

Figure 11: Variation of maximum of degree of banding during the shear startup flow as a function of \(\eta_{s}\) during shear startup flow of the nRP model fluid for \(Wi=30\), and \(\beta=1\). These results are obtained for \(Re=0\).

Figure 12: Effect of inertia on the degree of banding in shear startup flow of the JS model for \(A=10^{-1}\), \(10^{-4}\) and \(10^{-7}\), \(Wi=12\) and \(\eta_{s}=0.16\). The shear rate is in the monotonic region of the constitutive curve.

Figure 13: Effect of inertia on the degree of banding in shear startup flow of the JS model for \(A=10^{-1}\), \(10^{-4}\) and \(10^{-7}\), \(Wi=12\) and \(\eta_{s}=0.05\). The shear rate is in the nonmonotonic region of the constitutive curve.

\(Re\geq 10^{-2}\). Similarly, for shear rates in the nonmonotonic region of the constitutive curve, the peak observed in the degree of banding as a function of time decreases with increase in the value of \(Re\) for all \(A\) as shown in Fig. 15. For \(A=10^{-1}\), there is no peak observed for \(Re=10^{-1}\), and for \(A=10^{-4}\), no significant peak is observed for \(Re\geq 10^{-2}\), and for \(A=10^{-7}\), no significant peak is observed for \(Re\geq 10^{-3}\). This result is consistent with the results obtained for low \(\eta_{s}\) in our earlier study (Fig. 13 of Ref. [28]), wherein we showed that with increase in \(Re\), the maximum value of transient growth rate for a fixed \(\eta_{s}\) decreases. The effect of inclusion of inertia on initial exponential growth of perturbation during inertialess flow (Figs. 4(c) and 5(c)) is also shown for \(A=10^{-4}\) in inset of Figs. 14 (b) and 15 (b). The inset of Fig. 14 (b) shows that slope of linear increase of degree of banding decreases with increase in \(Re\). For \(Re=10^{-1}\), there is no linear increase observed. The inset of Fig. 15 (b) shows that the slope of linear increase decreases with increase in \(Re\) for \(A=10^{-4}\).

This decrease of \(\Delta\dot{\gamma}_{max}\) as a function of \(Re\) for \(A=10^{-1}\) and \(\eta_{s}=10^{-3}\), \(10^{-4}\), and \(10^{-5}\) is shown in Fig. 16, which summarises the effect of inertia in shear startup flow of the nRP model. It can be seen that with increase in \(Re\), \(\Delta\dot{\gamma}_{max}\) decreases for \(\eta_{s}=10^{-3}\), \(10^{-4}\), and \(10^{-5}\). The significant change in \(\Delta\dot{\gamma}_{max}\) as a function of \(Re\) can be observed for \(Re>10^{-2}\) for \(\eta_{s}=10^{-3}\), \(10^{-4}\), and \(10^{-5}\). The inset of Fig. 16 shows the degree of banding evolution with time for the nRP model for \(Re=1\) and \(Re=10\) and \(A=10^{-1}\) and \(A=10^{-4}\) with \(\eta_{s}=10^{-4}\). It shows that \(\Delta\dot{\gamma}\) is independent of \(Re\) and is of the order \(A\) initially before finally decaying down to zero. The constant value of \(\Delta\dot{\gamma}_{max}\) and of the order of \(A\) for \(Re\geq 1\) for the nRP model is similar to the JS model results.

Figure 14: Effect of inertia on the degree of banding in shear startup flow of the nRP model for \(A=10^{-1}\), \(10^{-4}\) and \(10^{-7}\), \(Wi=30\), \(\eta_{s}=10^{-4}\) and \(\beta=1\). The inset of Fig. (b) shows the early time evolution of degree of banding on a semi-log plot. The shear rate is in the monotonic region of the constitutive curve.

In Sec. II, we raised a question about the validity of the creeping-flow assumption in solving the nRP model for \(\eta_{s}\ll 1\) when a perturbation is imposed at the beginning of the flow. There are two broad reasons as to why the creeping-flow assumption for \(\eta_{s}\ll 1\) might lead to erroneous results in the numerical solution: (i) the transient maximum eigenvalue or transient growth rate diverges with decrease in \(\eta_{s}\) suggesting that transient growth of perturbations in nonlinear simulations can also diverge. However, if the transient growth rate of shear rate perturbation diverges, the creeping-flow assumption cannot hold true. This is because, while neglecting the acceleration term in the Cauchy momentum equation, on account of it being multiplied by \(Re\), it is implicitly assumed that for \(Re\ll 1\), the acceleration term must remain finite. However, when the perturbation growth diverges, the acceleration terms also exhibit a similar behavior, and the product of \(Re\) and \(du/dt\) can no longer be neglected. (ii) Due to the creeping-flow assumption, the initial shear rate perturbation cannot be specified directly and it is of the order of \(\frac{\sigma_{vv}}{\eta_{s}Wi}\) which results in imposing unrealistic magnitudes of initial shear rate perturbation, especially when the initial stress perturbations are kept \(O(1)\).

It is important to note that after inclusion of inertial effects, if the solvent viscosity contribution is very low such that \(\eta_{s}\leq O(10^{-4})\), then even with direct imposition of realistic shear rate perturbation, perturbations may eventually reach very high magnitudes. Figure 16 shows that beyond a critical \(Re\), the perturbations do not grow unbounded during shear startup of the nRP model.

The above results show that if \(\eta_{s}\) is \(O(10^{-3}-10^{-1})\), then \(\Delta\dot{\gamma}_{max}\) is of the order of \(A\) for \(Re=0\) and \(Re\neq 0\). If \(\eta_{s}\) is \(O(10^{-4})\), then \(\Delta\dot{\gamma}_{max}\) is very sensitive to the value of \(A\) under the creeping-flow assumption, and is also affected by inclusion of inertial effects. For \(\eta_{s}=10^{-5}\), the change

Figure 15: Effect of inertia on the degree of banding in shear startup flow of the nRP model for \(A=10^{-1}\), \(10^{-4}\) and \(10^{-7}\), \(Wi=30\), \(\eta_{s}=10^{-4}\) and \(\beta=0.6\). The inset of Fig. (b) shows the early time evolution of degree of banding on a semi-log plot. The shear rate is in the nonmonotonic region of the constitutive curve.

in \(A\) does not affect \(\Delta\dot{\gamma}_{max}\) and it is only affected by inclusion of inertial effects. The fact that the velocity profiles during transient evolution can be so sensitive to \(Re\), when \(\eta_{s}\) is very small, suggests that the specific details of the experimental conditions will likely play a crucial role in the nature of the observed velocity profiles.

Recently, Rassolov and Mohammadigoushki [26] experimentally obtained velocity profile evolution for wormlike micellar solution during shear startup flow and they found that steady state is banded. During the velocity profile evolution to steady state, the velocity of fluid between two plates attains a negative velocity, however, the magnitude of the negative most velocity reported is at most 25% of the top plate velocity. However, the negative most velocity of fluid between plates obtained for \(\eta_{s}=10^{-4}\) and shear rate in the nonmonotonic region of the constitutive curve can be at most 300% of the top plate velocity as shown in Fig. S7 which is far greater in magnitude as compared to 25% of top plate negative velocity observed experimentally by Rassolov and Mohammadigoushki [26]. Interestingly, it has been observed in literature [12; 13] that the negative most velocity in the transient velocity profile during shear startup, if shear rate is in monotonic region of constitutive curve, is lesser than that when the shear rate is in the nonmonotonic region of constitutive curve. Therefore, based on our results we conjecture that either transient negative velocity will not be observed during experiments if shear startup will be performed with shear rate in monotonic region of the constitutive curve or the negative most transient velocity profile will be much lesser than 100% or 1500% of the top plate velocity that has been predicted by nRP model in Figs. 7(a) and 10. The comparison with experimental results further highlights the importance of inertial effects during shear startup of nRP model which can help in regularising the results.

### Comparison of linearized evolution with fully nonlinear simulations

In our previous study [28], we had also examined the growth of linearized perturbations for different time of imposition of perturbations (\(t_{p}\)) for the JS and nRP models. Therein, it was shown that even if the JS model is perturbed at steady state (\(t_{p}=10\), 50, and 70), the flow exhibits a transient growth and eventual decay of perturbations within the linearized dynamics. On the other hand, for the nRP model, we found that if the flow is perturbed at steady state (\(t_{p}=1\) and 5), then the linearized perturbations decay without showing any transient growth. In this study, we compare the magnitude of growth of linearized perturbations with maximum deviation of velocity from a linear profile obtained from nonlinear simulations for the JS and nRP models for \(A=10^{-1}\). We study the effect of \(t_{p}\) on linearized growth of perturbations obtained using fundamental matrix method \((G(t))\) if \(t_{p}\) lies in the time range in which stress is decreasing as a function of time after stress overshoot for the JS and nRP model fluids. The value of \(G(t)\) at any time \(t\) shows the maximum possible growth of linearized perturbation independent of any initial condition. We use \(A=10^{-1}\) and \(Re=0\) so as to compare the maximum possible linearized growth of perturbation with deviation of linear velocity profile for a very high amplitude perturbation imposed in shear startup that may be practically realisable in an experiment. The evolution of \(G(t)\) as a function of \(t-t_{p}\) for the JS and nRP models for different \(t_{p}\) is shown in Figs. 17(a) and (b). In these figures, the data obtained using \(t_{p}=10\), and 20 for JS model and for \(t_{p}=1\), and 5 for the nRP model has appeared before in our previous study [28]. We have included this data only for comparison purposes.

In the case of JS model, we find that for \(t=1\), 2, and 3, the stress decreases with time after stress overshoot \((Wi=12,\eta_{s}=0.16\) as shown in Fig.1(a)). If \(t_{p}=1\), 2, and 3, then \(G(t)\) shows a slightly higher increase before finally decaying for \(t_{p}=1\) as compared to \(t_{p}=2\), 3, 10 and 20 for which data overlaps onto each other as shown in Fig. 17(a). The non-linear simulation results

[MISSING_PAGE_EMPTY:31]

[MISSING_PAGE_EMPTY:32]

monotonic region of the constitutive curve. For the JS model, we found that the maximum of degree of banding is proportional to the initial amplitude of perturbations, even for a six-fold increase in their order of magnitude, suggesting that there is no intrinsic transient instability in the JS model during shear startup. We also studied shear startup of both JS and nRP models by including inertial effects so that initial shear rate perturbation can be specified directly. The results of JS model again showed a linear dependence for the variation of maximum of degree of banding with initial amplitude of perturbation even in the presence of inertial effects. However, for the nRP model, the maximum of degree of banding showed linear dependence on initial amplitude of perturbation only beyond a threshold level of fluid inertia. This critical magnitude of \(Re\) increases with decrease in \(\eta_{s}\). In the absence of inertia, we also showed that maximum of degree of banding diverges with a power law exponent of \(-1\) on decreasing \(\eta_{s}\). There is no divergence of maximum of degree of banding on decreasing \(\eta_{s}\) when inertial effects are included.

The comparison of results obtained using the fundamental matrix method for linearized evolution of perturbations and those from nonlinear simulations showed that nonlinear terms mitigate the divergence of perturbations. The results obtained using different initial amplitude of perturbations showed that the time associated with maximum value of degree of banding and the maximum value of degree of banding depends on the initial amplitude of perturbation. On the basis of these two observations, we conclude that occurrence of transient shear banding, if any, is not governed by a linear instability, and is governed by the following factors: (1) the initial amplitude of perturbation, (2) the solvent to solution viscosity ratio \(\eta_{s}\), and (3) the inertial effects characterized by \(Re\). Overall, we show that the results of shear startup of nRP model is very sensitive to initial amplitude of perturbations and magnitude of inertial effects if \(\eta_{s}\ll 1\). Therefore, there will not be any transient shear banding in shear startup of JS and nRP model if (i) \(\eta_{s}>10^{-3}\) (ii) inertial effects are included if \(\eta_{s}\ll 1\), because of very high transient growth of perturbations, creeping-flow assumption cannot hold true, and (iii) realistic initial amplitude of perturbation is imposed if \(\eta_{s}\ll 1\) and creeping-flow assumption holds true. More importantly, the comparison of linear and nonlinear studies showed that growth of perturbations as indicated by linearized dynamics may not necessarily signify transient shear banding in the nonlinear simulations. The results of both JS and nRP models show that the ultimate answer of whether there will be any transient shear banding or not can be obtained only using nonlinear simulations.

## Acknowledgment

We acknowledge financial support from the Science and Engineering Research Board, Government of India.

## Data Availability

The data that supports the findings of this study are available within the article and its supplementary material. Additional data are available from the corresponding author upon reasonable request.

## Supplementary Information

Shear start up at \(Wi=12\), \(\eta_{s}=0.16\) using JS model (monotonic constitutive curve). Effect of inertia and initial amplitude of perturbationFigure S2: Effect of inertia \((Re)\) and amplitude of perturbation \((A)\) is shown for shear startup flow of JS model. Shear startup flow is at \(Wi=12\), \(\eta_{s}=0.16\) which corresponds to a shear rate in the monotonic region of the constitutive curve. In the first row, shear stress is plotted for \(Re=0\), \(10^{-2}\), \(10^{-1}\). For each value of \(Re\), the results are obtained using different values of \(A\) which are \(10^{-1}\), \(10^{-4}\), and \(10^{-7}\). Shear stress for a forced homogeneous flow is also plotted in Figs. (a), (b), and (c). In the second row (Figs. (d)-(f)), degree of banding (\((\Delta\hat{\gamma})\) evolution is shown as a function of time at different values of \(A\) for \(Re=0\), \(10^{-2}\), \(10^{-1}\).

Figure S3: Effect of inertia \((Re)\) and amplitude of perturbation \((A)\) is shown for shear startup flow of JS model. Shear startup flow is at \(Wi=12\), \(\eta_{s}=0.05\) which corresponds to a shear rate in the non-monotonic region of the constitutive curve. In the first row, shear stress is plotted for \(Re=0\), \(10^{-2}\), \(10^{-1}\). For each value of \(Re\), the results are obtained using different values of \(A\) which are \(10^{-1}\), \(10^{-4}\), and \(10^{-7}\). Shear stress for a forced homogeneous flow is also plotted in Figs. (a), (b), and (c). In the next three rows (Figs. (d)-(l)), velocity profile evolution is shown as a function of time at different values of \(Re\) and \(A\).

Figure S4: Effect of inertia \((Re)\) and amplitude of perturbation \((A)\) is shown for shear startup flow of JS model. Shear startup flow is at \(Wi=12\), \(\eta_{s}=0.05\) which corresponds to a shear rate in the non-monotonic region of the constitutive curve. In the first row, shear stress is plotted for \(Re=0\), \(10^{-2}\), \(10^{-1}\). For each value of \(Re\), the results are obtained using different values of \(A\) which are \(10^{-1}\), \(10^{-4}\), and \(10^{-7}\). Shear stress for a forced homogeneous flow is also plotted in Figs. (a), (b), and (c). In the second row (Figs. (d)-(f)), degree of banding (\(\Delta\hat{\gamma}\)) evolution is shown as a function of time at different values of \(A\) for for \(Re=0\), \(10^{-2}\), \(10^{-1}\).

Shear start up at \(Wi=30\), \(\eta_{s}=10^{-4}\), \(\beta=1\) using nRP model (monotonic constitutive curve).

Effect of inertia and initial amplitude of perturbation

Figure S5: Effect of inertia (\(Re\)) and amplitude of perturbation (\(A\)) is shown for shear startup flow of nRP model. Shear startup flow is at \(Wi=30,\,\eta_{s}=10^{-4}\), \(\beta=1\) which corresponds to a shear rate in the monotonic region of the constitutive curve. In the first row, shear stress is plotted for \(Re=0\), \(10^{-2}\), \(10^{-1}\). For each value of \(Re\), the results are obtained using different values of \(A\) which are \(10^{-1}\), \(10^{-4}\), and \(10^{-7}\). Shear stress for a forced homogeneous flow is also plotted in Figs. (a), (b), and (c). In the next three rows (Figs. (d)-(l)), velocity profile evolution is shown as a function of time at different values of \(Re\) and \(A\).

Figure S6: Effect of inertia \((Re)\) and amplitude of perturbation \((A)\) is shown for shear startup flow of nRP model. Shear startup flow is at \(Wi=30\), \(\eta_{s}=10^{-4}\), \(\beta=1\) which corresponds to a shear rate in the monotonic region of the constitutive curve. In the first row, shear stress is plotted for \(Re=0\), \(10^{-2}\), \(10^{-1}\). For each value of \(Re\), the results are obtained using different values of \(A\) which are \(10^{-1}\), \(10^{-4}\), and \(10^{-7}\). Shear stress for a forced homogeneous flow is also plotted in Figs. (a), (b), and (c). In the second row (Figs. (d)-(f)), degree of banding (\(\Delta\dot{\gamma}\) in) evolution is shown as a function of time at different values of \(A\) for \(Re=0\), \(10^{-2}\), \(10^{-1}\).

Shear start up at \(Wi=30\), \(\eta_{s}=10^{-4}\), \(\beta=0.6\) using nRP model (nonmonotonic constitutive curve). Effect of inertia and initial amplitude of perturbation

Figure S7: Effect of inertia \((Re)\) and amplitude of perturbation \((A)\) is shown for shear startup flow of nRP model. Shear startup flow is at \(Wi=30\), \(\eta_{s}=10^{-4}\), \(\beta=0.6\) which corresponds to a shear rate in the non-monotonic region of the constitutive curve. In the first row, shear stress is plotted for \(Re=0\), \(10^{-2}\), \(10^{-1}\). For each value of Re, the results are obtained using different values of \(A\) which are \(10^{-1}\), \(10^{-4}\), and \(10^{-7}\). Shear stress for a forced homogeneous flow is also plotted in Figs. (a), (b), and (c). In the next three rows (Figs. (d)-(l)), velocity profile evolution is shown as a function of time at different values of \(Re\) and \(A\).

## References

* Denn (2001)M. M. Denn, "Extrusion instabilities and wall slip," Annual Review of Fluid Mechanics **33**, 265-287 (2001).
* Joshi _et al._ (2000)Y. M. Joshi, A. K. Lele, and R. Mashelkar, "Slipping fluids: a unified transient network model," Journal of Non-Newtonian Fluid Mechanics **89**, 303-335 (2000).
* Petrie and Denn (1976)C. J. Petrie and M. M. Denn, "Instabilities in polymer processing," AIChE Journal **22**, 209-236 (1976).
* Howells and Benbow (1962)E. Howells and J. Benbow, "Flow defects in polymer melts," Trans. Plast. Inst **30**, 240-253 (1962).
* Joshi and Denn (2003)Y. M. Joshi and M. M. Denn, "Planar contraction flow with a slip boundary condition," Journal of Non-Newtonian Fluid Mechanics **114**, 185-195 (2003).
* Joshi and Denn (2004)Y. M. Joshi and M. M. Denn, "Rupture of entangled polymeric liquids in elongational flow withdissipation," Journal of Rheology **48**, 591-598 (2004).
* Shaqfeh (1996)E. S. G. Shaqfeh, "Purely elastic instabilities in viscometric flows," Annual Review of Fluid Mechanics **28**, 129-185 (1996).
* Olmsted (2008)P. D. Olmsted, "Perspectives on shear banding in complex fluids," Rheologica Acta **47**, 283-300 (2008).
* Divoux _et al._ (2016)T. Divoux, M. A. Fardin, S. Manneville, and S. Lerouge, "Shear banding of complex fluids," Annual Review of Fluid Mechanics **48**, 81-103 (2016).
* Germann (2019)N. Germann, "Shear banding in semidilute entangled polymer solutions," Current Opinion in Colloid & Interface Science **39**, 1-10 (2019).
* Varchanis _et al._ (2022)S. Varchanis, S. J. Haward, C. C. Hopkins, J. Tsamopoulos, and A. Q. Shen, "Evaluation of constitutive models for shear-banding wormlike micellar solutions in simple and complex flows," Journal of Non-Newtonian Fluid Mechanics **307**, 104855 (2022).
* Adams, Fielding, and Olmsted (2011)J. Adams, S. M. Fielding, and P. D. Olmsted, "Transient shear banding in entangled polymers: A study using the rolie-poly model," Journal of Rheology **55**, 1007-1032 (2011).
* Moorcroft and Fielding (2014)R. L. Moorcroft and S. M. Fielding, "Shear banding in time-dependent flows of polymers and wormlike micelles," Journal of Rheology **58**, 103-147 (2014).
* Jain _et al._ (2018)A. Jain, R. Singh, L. Kushwaha, V. Shankar, and Y. M. Joshi, "Role of inertia and thixotropy in start-up flows of aging soft materials: Transient dynamics and shear banding in a rate-controlled flow field," Journal of Rheology **62**, 1001-1016 (2018).
* Kushwaha, Shankar, and Joshi (2022)L. Kushwaha, V. Shankar, and Y. M. Joshi, "Dynamics and shear banding in stress-controlled start-up shear flow of a model aging soft materials: the role of inertia and thixotropy," Rheologica Acta **61**, 355-371 (2022).
* Yerushalmi, Katz, and Shinnar (1970)J. Yerushalmi, S. Katz, and R. Shinnar, "The stability of steady shear flows of some viscoelastic fluids," Chemical Engineering Science **25**, 1891-1902 (1970).
* Helgeson _et al._ (2009)M. E. Helgeson, M. D. Reichert, Y. T. Hu, and N. J. Wagner, "Relating shear banding, structure, and phase behavior in wormlike micellar solutions," Soft Matter **5**, 3858-3869 (2009).
* Johnson Jr and Segalman (1977)M. Johnson Jr and D. Segalman, "A model for viscoelastic fluid behavior which allows non-affine deformation," Journal of Non-Newtonian fluid mechanics **2**, 255-270 (1977).
* Doi, Edwards, and Edwards (1988)M. Doi, S. F. Edwards, and S. F. Edwards, _The theory of polymer dynamics,_ Vol. 73 (oxford university press, 1988).
* Cates (1987)M. Cates, "Reptation of living polymers: dynamics of entangled polymers in the presence of reversible chain-scission reactions," Macromolecules **20**, 2289-2296 (1987).

* Vasquez _et al._ (2007)P. A. Vasquez, G. H. McKinley, and L. P. Cook, "A network scission model for wormlike micellar solutions: I. model formulation and visometric flow predictions," Journal of Non-Newtonian Fluid Mechanics **144**, 122-139 (2007).
* Giesekus (1982)H. Giesekus, "A simple constitutive equation for polymer fluids based on the concept of deformation-dependent tensorial mobility," Journal of Non-Newtonian Fluid Mechanics **11**, 69-109 (1982).
* Likhtman and Graham (2003)A. E. Likhtman and R. S. Graham, "Simple constitutive equation for linear polymer melts derived from molecular theory: Rolie-poly equation," Journal of Non-Newtonian Fluid Mechanics **114**, 1-12 (2003).
* Ianniruberto and Marrucci (2017)G. Ianniruberto and G. Marrucci, "Shear banding in doi-edwards fluids," Journal of Rheology **61**, 93-106 (2017).
* Briole _et al._ (2021)A. Briole, L. Casanellas, M.-A. Fardin, C. Py, O. Cardoso, J. Browaeys, and S. Lerouge, "Shear-banding fluid (s) under time-dependent shear flows. part ii: A test of the moorcroft-fielding criteria," Journal of Rheology **65**, 1201-1217 (2021).
* Rassolov and Mohammadigoushki (2022)P. Rassolov and H. Mohammadigoushki, "Role of micellar entanglements on kinetics of shear banding flow formation," Journal of Rheology **67**, 169-181 (2022).
* Moorcroft and Fielding (2013)R. L. Moorcroft and S. M. Fielding, "Criteria for shear banding in time-dependent flows of complex fluids," Physical review letters **110**, 086001 (2013).
* Sharma, Shankar, and Joshi (2021)S. Sharma, V. Shankar, and Y. M. Joshi, "Onset of transient shear banding in viscoelastic shear start-up flows: Implications from linearized dynamics," Journal of Rheology **65**, 1391-1412 (2021).
* Fielding (2016)S. M. Fielding, "Triggers and signatures of shear banding in steady and time-dependent flows," Journal of Rheology **60**, 821-834 (2016).
* Cao and Likhtman (2012)J. Cao and A. E. Likhtman, "Shear banding in molecular dynamics of polymer melts," Physical Review Letters **108**, 028302 (2012).
* Mohagheghi and Khomami (2016)M. Mohagheghi and B. Khomami, "Elucidating the flow-microstructure coupling in entangled polymer melts. part ii: Molecular mechanism of shear banding," Journal of Rheology **60**, 861-872 (2016).
* Zhou _et al._ (2008)L. Zhou, P. A. Vasquez, L. P. Cook, and G. H. McKinley, "Modeling the inhomogeneous response and formation of shear bands in steady and transient flows of entangled liquids," Journal of rheology **52**, 591-623 (2008).
* Zhou, Cook, and McKinley (2016)L. Zhou, L. P. Cook, and G. H. McKinley, "Multiple shear-banding transitions for a model of wormlike micellar solutions," SIAM Journal on Applied Mathematics **72**, 1192-1212 (2012).
* Zhou _et al._ (2014)L. Zhou, G. H. McKinley, and L. P. Cook, "Wormlike micellar solutions: Iii. vcm model predictions in steady and transient shearing flows," Journal of Non-Newtonian Fluid Mechanics **211**, 70-83 (2014).
* Burroughs _et al._ (2023)M. C. Burroughs, Y. Zhang, A. Shetty, C. M. Bates, M. E. Helgeson, and L. G. Leal, "Flow-concentration coupling determines features of nonhomogeneous flow and shear banding in entangled polymer solutions," Journal of Rheology **67**, 219-239 (2023).
* Benzi _et al._ (2021)R. Benzi, T. Divoux, C. Barentin, S. Manneville, M. Sbragaglia, and F. Toschi, "Continuum modeling of shear startup in soft glassy materials," Physical Review E **104**, 034612 (2021).
* Tapadia and Wang (2006)P. Tapadia and S.-Q. Wang, "Direct visualization of continuous simple shear in non-newtonian polymeric fluids," Physical review letters **96**, 016001 (2006).
* Ravindranath _et al._ (2008)S. Ravindranath, S.-Q. Wang, M. Olechnowicz, and R. P. Quirk, "Banding in simple steady shear of entangled polymer solutions," Macromolecules **41**, 2663-2670 (2008).
* Wang _et al._ (2011)S.-Q. Wang, S. Ravindranath, and P. Boukany, "Homogeneous shear, wall slip, and shear banding of entangled polymeric liquids in simple-shear rheometry: A roadmap of nonlinear rheology," Macromolecules **44**, 183-190 (2011).
* Boukany and Wang (2008)P. E. Boukany and S.-Q. Wang, "Use of particle-tracking velocimetry and flow birefringence to study nonlinear flow behavior of entangled wormlike micellar solution: From wall slip, bulk disentanglement to chain scission," Macromolecules **41**, 1455-1464 (2008).
* Boukany and Wang (2009)P. E. Boukany and S.-Q. Wang, "Exploring the transition from wall slip to bulk shearing banding in well-entangled dna solutions," Soft Matter **5**, 780-789 (2009).
* Boukany and Wang (2009)P. E. Boukany and S.-Q. Wang, "Shear banding or not in entangled dna solutions depending on the level of entanglement," Journal of Rheology **53**, 73-83 (2009).
* Hu _et al._ (2007)Y. T. Hu, L. Wilen, A. Philips, and A. Lips, "Is the constitutive relation for entangled polymers monotonic?" Journal of Rheology **51**, 275-295 (2007).
* Hu _et al._ (2008)Y. T. Hu, C. Palla, and A. Lips, "Comparison between shear banding and shear thinning in entangled micellar solutions," Journal of Rheology **52**, 379-400 (2008).
* Li _et al._ (2013)Y. Li, M. Hu, G. B. McKenna, C. J. Dimitriou, G. H. McKinley, R. M. Mick, D. C. Venerus, and L. A. Archer, "Flow field visualization of entangled polybutadiene solutions under nonlinear viscoelastic flow conditions," Journal of Rheology **57**, 1411-1428 (2013).
* Wang _et al._ (2011)S.-Q. Wang, G. Liu, S. Cheng, P. E. Boukany, Y. Wang, and X. Li, "Letter to the editor: Sufficiently entangled polymers do show shear strain localization at high enough weissenberg numbers," Journal of Rheology **58**, 1059-1069 (2014).
* Peterson (2018)J. D. Peterson, _Shear Induced Demixing in Polymer Melts and Solutions_, Ph.D. thesis, University of California, Santa Barbara (2018).
* Fielding and Olmsted (2003)S. M. Fielding and P. D. Olmsted, "Kinetics of the shear banding instability in startup flows," Physical Review E **68**, 036313 (2003).
* Fielding and Olmsted (2003)S. M. Fielding and P. D. Olmsted, "Flow phase diagrams for concentration-coupled shear banding," The European Physical Journal E **11**, 65-83 (2003).
* Fielding and Olmsted (2003)S. M. Fielding and P. D. Olmsted, "Early stage kinetics in a unified model of shear-induced demixing and mechanical shear banding instabilities," Physical review letters **90**, 224501 (2003).
* Cromer _et al._ (2013)M. Cromer, M. C. Villet, G. H. Fredrickson, and L. G. Leal, "Shear banding in polymer solutions," Physics of Fluids **25**, 051703 (2013).
* Cromer _et al._ (2014)M. Cromer, G. H. Fredrickson, and L. G. Leal, "A study of shear banding in polymer solutions," Physics of Fluids **26**, 063101 (2014).
* Peterson _et al._ (2016)J. D. Peterson, M. Cromer, G. H. Fredrickson, and L. Gary Leal, "Shear banding predictions for the two-fluid rolie-poly model," Journal of Rheology **60**, 927-951 (2016).
* Rassolov and Mohammadigoushki (2020)P. Rassolov and H. Mohammadigoushki, "Effects of elasticity and flow ramp up on kinetics of shear banding flow formation in wormlike micellar fluids," Journal of Rheology **64**, 1161-1177 (2020).
* Rassolov _et al._ (2022)P. Rassolov, A. Scigliani, and H. Mohammadigoushki, "Kinetics of shear banding flow formation in linear and branched wormlike micelles," Soft Matter **18**, 6079-6093 (2022).
* Mohammadigoushki _et al._ (2019)H. Mohammadigoushki, A. Dalili, L. Zhou, and P. Cook, "Transient evolution of flow profiles in a shear banding wormlike micellar solution: Experimental results and a comparison with the vcm model," Soft matter **15**, 5483-5494 (2019).
* Alam and Nott (1997)M. Alam and P. R. Nott, "The influence of friction on the stability of unbounded granular shear flow," Journal of Fluid Mechanics **343**, 267-301 (1997).
* Schmid and Henningson (1994)P. J. Schmid and D. S. Henningson, "Optimal energy density growth in hagen-poiseuille flow," Journal of Fluid Mechanics **277**, 197-225 (1994).
* Schmid and Kytomaa (1994)P. Schmid and H. Kytomaa, "Transient and asymptotic stability of granular shear flow," Journal of Fluid Mechanics **264**, 255-275 (1994).
* Strang and Borre (1997)G. Strang and K. Borre, _Linear algebra, geodesy, and GPS_ (Siam, 1997).
* Olmsted _et al._ (2000)P. Olmsted, O. Radulescu, and C.-Y. Lu, "Johnson-segalman model with a diffusion term in cylindrical couette flow," Journal of Rheology **44**, 257-275 (2000).

* Lu _et al._ (2000)C.-Y. D. Lu, P. D. Olmsted, and R. Ball, "Effects of nonlocal stress on the determination of shear banding flow," Physical Review Letters **84**, 642 (2000).
* Bird _et al._ (1987)R. B. Bird, R. C. Armstrong, and O. Hassager, "Dynamics of polymeric liquids. 2nd ed. : Fluid mechanics," Wiley, New York **1** (1987).
* Gordon and Schowalter (1972)R. Gordon and W. Schowalter, "Anisotropic fluid theory: a different approach to the dumbbell theory of dilute polymer solutions," Transactions of the Society of Rheology **16**, 79-97 (1972).
* constitutive models with nonaffine motion," in _Constitutive Equations for Polymer Melts and Solutions_, Butterworths Series in Chemical Engineering, edited by R. G. Larson (Butterworth-Heinemann, 1988) pp. 129-155.
* Holroyd, Martin, and Graham (2017)G. A. Holroyd, S. J. Martin, and R. S. Graham, "Analytic solutions of the role poly model in time-dependent shear," Journal of Rheology **61**, 859-870 (2017).
* Tomar _et al._ (2006)G. Tomar, V. Shankar, S. Shukla, A. Sharma, and G. Biswas, "Instability and dynamics of thin viscoelastic liquid films," The European Physical Journal E **20**, 185-200 (2006).
* Tanner (1962)R. I. Tanner, "Note on the rayleigh problem for a visco-elastic fluid," Zeitschrift fur angewandte Mathematik und Physik ZAMP **13**, 573-580 (1962).
* Denn and Porteous (1971)M. Denn and K. Porteous, "Elastic effects in flow of viscoelastic liquids," The Chemical Engineering Journal **2**, 280-286 (1971).

Title: Failures to be celebrated: an analysis of major pivots of software
  startups
Transcription: Title of the article:

**Failures to be celebrated: an analysis of major pivots of software startups**

Authors:

**Sohaib Shahid Bajwa, Xiaofeng Wang, Anh Nguyen Duc and Pekka Abrahamsson**

Notes:

- This is the author's version of the work.

- The definite version was published in: Bajwa, S.S., Wang, X., Nguyen Duc, A., et al. Empir Software Eng (2017) 22: 2373.

- Copyright owner's version can be accessed at

[https://link.springer.com/article/10.1007/s10664-016-9458-0](https://link.springer.com/article/10.1007/s10664-016-9458-0)

Interested in academic Software Startup Research? Get in touch with the

Software Startup Research Network, SSRN for more information,

[https://softwarestartups.org/](https://softwarestartups.org/)This is the author's version of the work. The definite version was published in: Bajwa, S.S., Wang, X., Nguyen, Duc, A. et al. Empir Software Eng (2017) 22: 2373.[https://doi.org/10.1007/s10664-016-9458-0](https://doi.org/10.1007/s10664-016-9458-0)

## Failures to be celebrated: an analysis of major pivots of software startups

Sohaib Shahid Bajwa, Free University of Bozen Bolzano

Xiaofeng Wang, Free University of Bozen Bolzano

Anh Nguyen Duc, Norwegian University of Science and Technology

Pekka Abrahamsson, Norwegian University of Science and Technology

### Abstract

In the context of software startups, project failure is embraced actively and considered crucial to obtain validated learning that can lead to pivots. A pivot is the strategic change of a business concept, product or the different elements of a business model. A better understanding is needed on different types of pivots and different factors that lead to failures and trigger pivots, for software entrepreneurial teams to make better decisions under chaotic and unpredictable environment. Due to the nascent nature of the topic, the existing research and knowledge on the pivots of software startups are very limited. In this study, we aimed at identifying the major types of pivots that software startups make during their startup processes, and highlighting the factors that fail software projects and trigger pivots. To achieve this, we conducted a case survey study based on the secondary data of the major pivots happened in 49 software startups. 10 pivot types and 14 triggering factors were identified. The findings show that customer need pivot is the most common among all pivot types. Together with customer segment pivot, they are common market related pivots. The major product related pivots are zoom-in and technology pivots. Several new pivot types were identified, including market zoom-in, complete and side project pivots. Our study also demonstrates that negative customer reaction and flawed business model are the most common factors that trigger pivots in software startups. Our study extends the research knowledge on software startup pivot types and pivot triggering factors. Meanwhile it provides practical knowledge to software startups, which they can utilize to guide their effective decisions on pivoting.

Pivot Software startups Lean startup Validated learning Pivoting factor Side project This is the author's version of the work. The definite version was published in: Bajwa, S.S., Wang, X., Nguyen Duc, A. et al. Empir Software Eng (2017) 22: 2373.[https://doi.org/10.1007/s10664-016-9458-0](https://doi.org/10.1007/s10664-016-9458-0)

1 Introduction

Startups are human institutions that create innovative products or services and search for sustainable business models under extreme uncertainty (Blank, 2005; Ries, 2011). Software startups are startups that build software-intensive products/services. Similar to established software companies in which software development projects have a reputation for failure (Savolainen et al., 2011), projects in software startups do fail as well. The consequence of project failure for a software startup can be even more severe than that for an established software company. This is because a majority of software startups are focused on one single project at a time. One project failure could put a software startup out of business (Giardino et al., 2016).

However, interestingly, failure is treated with positive attitude in software startups, to the extent that a few companies have the practice of celebrating each failed project, such as Supercell, according to some anecdotal evidence (Kelly, 2013). Why do software startups embrace and even celebrate failures? Since the environments of software startups are extremely unpredictable and even chaotic, failures are considered a crucial way (sometimes the only way) for them to obtain important learning to validate key assumptions they make about their software products and business (Eisenmann et al., 2012). In fact, the ultimate goal of these intermediate failures along the way is to avoid the final fatal failures that put startups out of business. These intermediate failures are what we focused on in our study.

The validated learning obtained through failing fast and failing often leads software startups to making the strategic change of a business concept, product, or different elements of a business model. This type of change is called pivot in the Lean Startup approach (Ries, 2011). It is claimed that pivot is the most frequently occurring commonality among different successful startups (Ries, 2011). Pivot is inevitable for almost all software startups to survive, grow and eventually obtain sustainable business models. Only a few startups get their business models right immediately. It is evidenced by the fact that many successful software startups did not turn out to be what they had initially started with. For instance, Flickr used to be an online multiplayer role playing game rather than a photo managing and sharing service (Nazar, 2013), while Twitter was initially developed as a podcast service, not a microblogging service (Carlson, 2011).

The importance of pivot for software startups deserves research attention. However, due to the nascent nature of the research on software startups, there is a scarcity of studies on pivots in software startups. Comprehensive and valid knowledge is yet to be built on what trigger software startups to pivot, how and why they make certain pivot decisions, and how they actually pivot. The study reported in this paper is one of the first attempts to fill this knowledge gap. The objective of the study is to lay the foundations for future studies on software startup pivots by providing the basic understanding of pivots in software startups. The basic understanding includes the factors that trigger software startups to pivot, and the major types of pivots that software startups make when failures happen. To this end, the research questions that guided the study are phrased as following:

* RQ1: What are the factors that trigger software startups to pivot?
* RQ2: What are the types of pivots software startups undertake?

To answer the research questions, we employed a systematic research process. We collected online materials as secondary data and analysed the major pivots in 49 software startups reported in these materials, including the well-known companies such as YouTube, Flickr, Pinterest and Twitter. The online materials allowed us to quickly obtain useful data on as many significant pivots in software startups as possible. Based on the analysis of the pivots in these 49 software startups, we extracted a list of factors that triggered them to pivot, and identified a set of major types of pivots they conducted. To better structure the triggering factors and pivot types, we categorized them into different groups respectively.

The rest of this paper is organized as follows: in Section 2, the background literature and related work are reviewed. Section 3 describes the research approach employed in the study. The research findings are presented in detail in Section 4, and further discussed in Section 5. The paper is summarized in Section 6, which also outlines the future research.

## 2 Background and Related Work

### Software Startups and Lean Startup

Software startups are challenging endeavours. A systematic mapping study (Paternoster et al., 2014) reveals the most frequently reported contextual features of a software startup: general lack of resources, high reactiveness and flexibility, intense time pressure, uncertain conditions, and tackling dynamic and fast growing markets. Software startups are dealing with various difficulties constantly emerging from different directions. Some of the top challenges include developing technologically innovative software products that require novel development tools and techniques, defining minimum viable product to capture and evaluate the riskiest assumptions that might fail a business concept, and discovering an appropriate business strategy to deliver value (Giardino et al., 2015).

Inspired by the lean principles from Toyota manufacturing and production system (Womack et al., 1990), Ries (2011) presents a new approach of entrepreneur and innovation - referred to as Lean Startup. Lean Startup focuses on the efforts that create value to customers and eliminate waste during the development phase. However, since customers are often unknown, what they could perceive as value is also unknown. Therefore, entrepreneurs should "get out of the building" to discover customers from day one (Blank, 2013). Instead of emphasizing on a business plan, Lean Startup advocates to build the product iteratively and deliver to the market for earlier feedback. The core activity of any lean startup is based on the Build-Measure-Learn (BML) loops, through which a startup turns an idea into a product, measures customer response, and then learns. This can be done through developing minimum viable products (MVP). This learning is referred to as validated learning, where each hypothesis on a business model is validated, and then a decision is made on whether to pivot or persevere. Therefore, Lean Startup is also referenced as hypothesis-driven entrepreneurship (Eisenmann et al., 2012).

This is the author's version of the work. The definite version was published in: Bajwa, S.S., Wang, X., Nguyen Duc, A. et al. Empir Software Eng (2017) 22: 2373.[https://doi.org/10.1007/s10664-016-9458-0](https://doi.org/10.1007/s10664-016-9458-0)

### Failure in Software Startups

In Software Engineering literature, software project failures are defined in terms of cost and schedule over-runs, project cancellations, and lost opportunities for the organizations that embark on the difficult journey of software development (Linberg 1999). While software project failures can lead to business failures in established companies, it is not so drastic as in the context of startup where one failed project could put a startup company out of business (Giardino et al. 2016), the eventual failure of a startup when it passes a point of no return, leading to the termination of business. Software startup failure rate can be as high as 75 % to 90 % (Nobel 2011; Marmer et al. 2011).

The essence of Lean Startup methodology is to help startups make early and cheap failures as often as possible, and learn from these intermediate failures in order to avoid final catastrophes (Ries 2011). These intermediate failures that occur during the courses of startup processes are the ones that should be embraced actively and that can lead to pivoting, therefore the focus of our study. The related work is also reviewed based on this perspective on failure in software startups. Learning from this type of failures is crucial. However there is a paucity of studies on failures in software startups. One exception is Giardino et al. (2014), in which two software startup failures were documented and the reasons identified. One main reason is not changing directions when they were needed, or in other words, necessary pivots were not taken at due time. This issue is echoed in the study of Shepherd et al. (2009). According to them, the moment of failure is not always that straightforward. Sometimes entrepreneurs decide to continue the business even though the situation is hopeless. However, in some other cases, entrepreneurs do pivot and improve their entrepreneurial learning experience, but there is no study that investigates factors that trigger pivots in software startups, to the best knowledge of the authors.

### Pivots in Software Startups

Pivot is often considered the synonym of change. However, it is not about introducing just any change and making any decision. Several definitions of pivot are presented in literature in recent years. Pivot is considered as validating a hypothesis related to a business model (Blank 2005; Maurya 2012), even though it is not compulsory that a pivot can only be related to a business model. According to Ries (2011), a pivot is a special kind of change designed to test and validate the assumptions about a product, business model and the engine of growth. Based on these definitions, for this study we define a pivot as a strategic decision which leads to the significant change to one or more, but not all, elements of a startup: product, entrepreneurial team, business model or engine of growth. When all of these elements change at the same time, it is not considered a pivot but starting a completely new and different business.

Previous research on pivots in software startups is limited (Paternoster et al. 2014). Bosch et al. (2013) offer an alternative to pivot or perseverere i.e., to abandon the idea, by presenting a software development model for early stage software startups. However, the study is not primarily focused on pivoting. The study by Van der Van and Bosch (2013) describes pivots that software startups have made, and couples them with architecture decisions. It compares pivots and software architecture decisions in developing a new product, and presents the similarities and differences between these two types of decisions. According to the study, both pivots and software architecture decisions consider risk as a triggering factor in making a decision, while the focusesof pivots and software architecture decisions are different. This study considers a pivot an example of business decisions only, and does not consider product related pivots. Another study by Hirvikoski (2014) provides an overview of how software startups pivoted historically through the examples of Twitter, Google and Facebook. The study argues that most successful startups have made multiple pivots during their journey. However the pivot examples are not based on empirical data, and the study does not shed lights on why startups pivot. Moreover, it lacks rigorous scientific argumentation. Terho et al. (2015) identify different pivot types (product zoom-out, customer segment, business architecture etc.), and explain how they affect the different parts of the lean canvas model. However, there is a lack of information on how a pivot is identified and categorized under a specific pivot category.

There is a scarcity in the literature to identify major pivots that software startups have made. In order to ground our research on some basis, we used the pivot types reported in Ries (2011), with the awareness that these types are subject to systematic and scientific validation. Ries (2011) presents ten different types of pivots that can happen in startups:

* Zoom-in Pivot: A single feature of a product becomes the whole product, such as a chatting feature of an online game becomes a stand-alone messager app.
* Zoom-out Pivot: Opposite to zoom-in pivot, a whole product becomes a single feature of a much larger product. For example, a photo-sharing app is extended to an social media platform for photographers.
* Customer Segment Pivot: It is to shift from one customer segment to another, e.g. a training app orginally targetting at professional atheletes later on at amateurs, because a product hypothesis is partially confirmed, solving the right problem but for different customers than initially anticipated.
* Customer Need Pivot: As a result of getting to know customers extremely well, sometimes one realizes that the problem they are trying to solve is not important for the customers, but they often discover other related problems that are important for them and can be solved.
* Platform Pivot: It refers to change from an application to its supporting platform or vice versa, e.g., shifting from an online shop to a platform that hosts online shops.
* Business Architecture Pivot: In this pivot, a startup switches business architecture e.g. going for high margin, low volume instead of focusing on mass market.
* Value Capture Pivot: The methods that capture the value a company creates are commonly referred to as monetization or revenue models. A startup can capture value it creates through different ways. An example of value capture pivot can be an online service changing from freemium price model to monthly subscription fee model.
* Engine of Growth Pivot: Typical growth engines for startups are viral (through word-of-mouth), sticky (attracting users to stay with a product/service as long as possible) and paid growth models. A startup changes its growth strategy to seek rapid and more profitable growth.
* Channel Pivot: It is a recognition that a startup company has identified a way to reach their customers more effective than their previous one, e.g., from selling a product/service via post mails to selling on online shops.

* Technology Pivot: A startup delivers the same solution by using completely different technology, e.g. an app shifting from iOS to Android platform.

In addition to these pivot types, Hirvikoski (2014) proposes a new one - social pivot, Bwhere active changes in social factors, such as persons and environments, change the direction of a company.\({}^{\Lambda}\) Similarly, there is a severe lack of scientific argumentation and examples that support this new pivot type.

## 3 Research Approach

This study is designed to be exploratory due to the nascent nature of the software startup research area and the limited number of previous studies on pivots. In order to quickly obtain useful data and understand the directions of inquiry in future primary research, we decided to use secondary data on the software startup pivot examples that we could find on different websites, to develop an initial understanding of the phenomenon under the study.

Secondary data means that the research data is either collected by individuals other than the researchers who conduct the study, or for any other purposes than the one currently being considered, or often can be a combination of these two (Vartanian 2011). There can be several sources of secondary data e.g. census, magazines, newspapers, blogs, reports etc. The advantage of using secondary data is that data collection process can be fast, and inexpensive (Vartanian 2011). Used with care and diligence, secondary data can provide a cost-effective way of gaining an initial understanding of research questions. Secondary data analysis is also considered a starting point for other research methods, often helpful in designing subsequent primary research and can provide a baseline with which to compare the primary data analysis results (Boslaugh 2007). The use of secondary data is quite common in other disciplines, such as psychology (Trzesniewski et al. 2011), and it is also becoming a suitable approach in the software engineering research community (e.g. Wang et al. 2012).

The overall research methodology employed in this study can be considered the case survey method (Yin and Heald 1975; Cruzes et al. 2015), since it Bworks best when the studies consist of a heterogeneous collection of case studies\({}^{\Lambda}\) (in our case, a collection of software startup pivot examples), and the researchers' main task is Bto aggregate the characteristics, but not necessarily the conclusions, of these cases\({}^{\Lambda}\) (Yin and Heald 1975, p. 371). The case survey method enables the researchers to note the various experiences found in each case and then to aggregate the frequency of occurrence of these experiences, therefore ensures the analysis of qualitative evidence in a reliable manner. Cruzes et al. (2015) list case survey as one of the methods for the synthesis of qualitative and mixed-methods evidence that can be applied in Software Engineering research. To further ensure the data collection and analysis process is systematic and reliable, we adopted the systematic literature review guidelines by Kitchenham (2007) and adapted them to our context. We developed a secondary data search and analysis protocol. The protocol helps to reduce the researchers' bias, because without using it, it is possible that the data collection or analysis could be driven by researcher expectations (Kitchenham 2007).

The overall data collection and analysis process employed in the study is illustrated in Fig. 1 and explained in detail in the following text.

This is the author's version of the work. The definite version was published in: Bajwa, S.S., Wang, X., Nguyen Duc, A. et al. Empir Software Eng (2017) 22: 2373.[https://doi.org/10.1007/s10664-016-9458-0](https://doi.org/10.1007/s10664-016-9458-0)

### Data Collection Steps

1. Define and refine search keywords The first step of the data collection was to define the search keywords used to search the secondary data. Based on the main objectives and research questions, we brainstormed the initial set of search keywords. The search string was structured using the guidelines given by Kitchenham (2007). To ensure that we captured the keywords related to software startups, we consulted the search string used in a systematic mapping study regarding software startups (Paternoster et al., 2014). We conducted several trial searches, observed the

Fig. 1: The data collection and analysis process 

[MISSING_PAGE_FAIL:9]

* The pivot examples are coming from software-based startups
* The webpage is in English The exclusion criteria are:
* The webpage contains the duplicated content of a previously examined webpage
* The webpage is non text-based (e.g. videos, audios, or images)
* The webpage on Slideshare, Quora, LinkedIn, personal (or company) blogs We excluded Slideshare because of the synthetic content and lack of contextual information, whereas webpages from Quora, LinkedIn and personal (or company) blogs are excluded for the potential subjectivity in the content. To decide if a startup is software startup and if the pivot described is a real pivot, we used the definition of software startup (defined in the beginning of Section 1) and pivot (defined in Section 2.3) to guide the inclusion/exclusion step. The first two authors conducted this step separately. The evaluation results from the two researchers were compared and the disagreed items (5 %, 39 were discussed out of 783 URLs) were discussed between the two researchers until a consensus was achieved. This step resulted in the Search Results Collection B which contains 138 URLs and represents 138 webpages.
* Identify cases from Search Results Collection B We read through the content of the 138 webpages, and looked for the information about the software startups that pivoted during their startup processes. We considered each mentioned software startup a potential case for further analysis. Since this step was relatively objective and straightforward, it was mainly conducted by the first author. In the case of doubt, the second author was consulted. This step resulted in the Case Collection A that contains 101 cases. The 138 webpages were re-organized according to the identified cases.
* Apply quality assurance criteria to Case Collection A To ensure that we have sufficient and adequate data on the cases for further analysis, we evaluated the quality of data we had on the 101 cases in Case Collection A based on the following quality assurance criteria:
* Does the data about a case startup allow the researchers to re-construct the pivoting story of the startup in terms of what the startup was focused on before and after a pivot, and why it made the pivot?
* Do the researchers have to make excessive guessing in order to understand the pivoting type and the factors triggering those pivots? A case is included if the answer to the first criterion is positive and the answer to the second one is negative. The first two authors conducted this step separately. The evaluation results from the two researchers were compared and the disagreed items (36 out of 101 cases) were discussed until a consensus was achieved. This step resulted in Case Collection B which contains 49 cases that were used in the data analysis. The data regarding these cases are contained in 47 webpages. The data on one case may be spread in more than one webpage, and one webpage may contain data on more than one case. The 47 webpages (represented by their
URLs) used for analysis were documented and available at a permanent address at [https://figshare.com/s/152f52bb036cc6a67526](https://figshare.com/s/152f52bb036cc6a67526).

### Data Analysis Steps

* Extract the relevant data from Case Collection B For each case (software startup) contained in Case Collection B, we were looking for the following information on the case:
* Background information
* Name of the startup
* Location of the company
* Founding year and/or first product release date
* Business domain
* The main business/product/service before a pivot
* The main business/product/service after a pivot
* Description and explanation on how and why the startup pivoted To get the background information, we first used the URL obtained through our systematic search; if no information was found, we checked a startup's homepage or LinkedIn page; if still no information was found, we resorted to Wikipedia. Wikipedia is used in six cases (Docker, Fab, Seesmic, Shopify, Site59, Voylla). If there was more than one link that discussed the same software startup (e.g. two links discussing Twitter as an example of pivoting), we included all links along with the descriptions under the same startup name. This step was conducted by the first author alone as it was mainly concerned with data retrieval. The first and second authors discussed 3 unclear cases, to resolve uncertain aspects regarding the background information of these cases.
* Coding the data to identify pivot types and triggering factors The data extracted on each case was analysed qualitatively to identify the pivot types and the factors that triggered the reported pivots. We relied on the explanations given in the case material to identify the triggering factors of pivots. The way we selected the cases ensured that the triggering factors that led to pivots were described. A completely open coding process was used to allow the emergence of the triggering factors, meanwhile a seed category of pivot types as described in Section 2.3 was used in the coding process to facilitate the identification of the types of pivots these software startups have experienced. Table 1 presents an example of how coding was conducted: This analysis step was conducted by the first and second authors separately. The coding results from the two researchers were compared and the disagreed items (the pivot types of 12 pivot instances and the pivot triggering factors of 5 pivot instances) were discussed between the two researchers until a consensus was achieved. This step resulted in 10 pivot types and 14 triggering factors.

This is the author's version of the work. The definite version was published in: Bajwa, S.S., Wang, X., Nguyen Duc, A. et al. Empir Software Eng (2017) 22: 2373.[https://doi.org/10.1007/s10664-016-9458-0](https://doi.org/10.1007/s10664-016-9458-0)

Group pivot types and triggering factors

To provide a better structure of the pivot types, we classified them drawing upon the four dimensions that are claimed to be vital for successful ventures by MacMillan et al. (1987) and employed in other related studies (e.g. Giardino et al. 2014):

* Product dimension: startups are developing technologically innovative solutions (Sutton 2003).
* Market dimension: it refers to identifying the essential need of the customers (Blank 2005).
* Financial dimension: it is related to the funding, investments, and return on investments and also the way a startup evolves sets the company growth and its place in market (Yu et al. 2012).
* Team dimension: it is the main driving force behind several entrepreneurial activities related to product and business development (Giardino et al. 2014).

The triggering factors were grouped into external and internal factors. External factors are those that are beyond the control of a startup, whereas internal factors stem from the decisions or activities of a startup itself.

## 4 Results

### Description of the 49 Pivoted Software Startups

The 49 software startups included in our case survey come from all over the world, however the majority (37) are based in the United States, and 4 in Canada. Two case companies are located in Israel, while the other 4 are located in United Kingdom, Australia, New Zealand and India. For two companies we could not obtain the information on their geographic locations.

Social networks (30.61 %), e-commerce (24.44 %), and finance and business (12.24 %) are the main business domains these software startups come from. The other domains include digital government, operating system, health and travel industries. Most products developed by these startups are market-driven and Internet-based. The targeted customers are either general (such as Twitter, Yelp and YouTube) or from a specific segment (e.g., Ignighter targets at Indian users primarily).

Twenty four out of the 49 cases are recent software startups, either being founded or releasing their first products in the past five years (between 2010 and 2015), while 13 cases have launched their products during 2005-2009. 7 startups released their products first time during 1998 to 2004, while for 5 cases the product release dates we could not obtain information.

Table 2 lists the 49 software startups included in our study, including their company names (at the time their pivots were reported in the webpage), the main business ideas before and after

Tuple 30:
Cleaned Title: metric software startup multivocal literature review
Cleaned Transcription: metric software startup multivocal literature review kaikristian kemell xiaofeng wangx anh nguyenduc jason grendus tuure tuunanen pekka abrahamsson university jyvaskyla jyvaskyla finland kaikristianokemell pekkaabrahamsson tuuretuunanenjyufi free university bozenbolzano bozenbolzano italy xiaofengwangunibzit university southeast norway norway anguusnno venture oy singapore jgrendusgmailcom abstract metric used business make objective decision based data software startup particular characterized uncertain even chaotic nature context operate using data form metric help software startup make right decision amidst uncertainty limited resource however whereas conventional business metric software metric studied past metric specific context software startup widely covered within academic literature promote research area create starting point conducted multivocal literature review focusing practitioner literature order compile list metric used software startup said list intended serve basis research area metric based suggestion made practitioner empirically verified keywords software startup metric data multivocal literature review introduction importance data business greatly increased last decade acquiring storing using become easier cheaper wake technological progress development underlined following still relatively recent emergence big data discourse encouraged organization acquire store vast amount data even necessarily present use data often used various business support decisionmaking even though manager intuition often practice still important strategic decisionmaking purpose decisionmaking data used form metric metric quantifiable measurement phenomenon object present evrywhere everyday life measuring height weight measuring speed driving even qualitative data extent made quantifiable right approach simple yes question seen boolean term quantifying written statement technique likert scale survey user rate qualitative statement scale eg based much agree disagree employed much like larger software company software startup also employ various metric measure progress aid decisionmaking given software startup usually operate notable lack resource particularly tumultuous context software startup arguably benefit use metric making right decision amidst uncertainty make difference success failure however based past survey data software startup fact track metric use data gained tracking make decision specifically software startup felt early track metric remaining response track metric either resource believe would benefit tracked remarked data influence decisionmaking footnote largescale survey ultimately collected response conducted explore different aspect software startup however cleaning data filtering based whether particular question metric answered sim response remained survey extensive question mandatory thus response included answer question additionally number approximation even cleaning data duplicate dubious response eg name testcom doubt remaining response valid data data survey also used wang et al among others majority software startup end failure arguably proper use right metric something help alleviate situation part metric alert business approaching disaster give time react resulting decrease revenue really hit example tracking daily active user dau metric give near realtime data software number suddenly start dropping dramatically course day something likely wrong perhaps update deployed day initial drop started perhaps update dramatically affected stability software device operating system nonetheless situation hypothetical company tracking dau problem may become apparent dramatic drop revenue end month however metric typically quite contextdependent earlystage software startup still developing first product thus user yet tracking aforementioned dau serf purpose though metric extensively studied various context across discipline metric specifically relation software startup emerging area research eg classic business metric net present value certainly applicable software startup well understanding metric specifically useful software startup presently lacking end seek un derstand metric software startup currently use expected use based multivocal literature review focusing primarily practitioner literature literature review aim compile extensive list potential metric software startup creating fertile ground research metric context list intended propose potential metric offer little insight metric used thus formulate research problem paper follows rq metric could software startup use track progress business rest paper structured follows upcoming second section discus software startup metric area research relation extant research across discipline third section go methodology study detail fourth section present result implication limitation result discussed fifth final section also concludes paper software startup metric utilizing metric software startup combine various type metric utilize conventional business metric well business metric specifically aimed startup well softwarerelated metric including website metric across different life cycle stage eg proposed wang et al different metric important software startup example conventional financial metric relevant earlystage startup may still process acquiring first customer still calculatingly running deficit time relevant metric situation could simply measure amount remaining expendable capital software engineering se metric split process metric product metric process metric metric related process creating software maintaining operational life product metric related quality product product metric seen include usabilityrelated metric well process metric hand account various methodspecific practicespecific metric lean agile software development metric websiterelated metric also considered part se metric however website ultimately software term website metric specifically basic metric related system website performance site availability bandwidth become le relevant wake technological process particularly following popularization cloud technology virtually given website handle ordinary spike traffic load capacity allocated necessary indeed rather tracking systemrelated metric focus business point view shifted towards understanding way user interact assuring system per formance le relevant far easier achieve website stability modern computational power organization aim comprehensively track way user use website order better understand optimize accordingly generic metric purpose include tracking visit length per page tracking user click anything well tracking user enter website large amount data becoming increasingly cheap easy handle tool gathering analyzing data readily available eg google analytics tracking individual user fashion become widespread even among smaller organization including software startup way tracking user limited website software company equally interested understanding user software interact practice order improve software based data though software startup occasionally also concern directly studying usability user experience ux ux usability typically evaluated actively involving user participant study either directly observing use user selfreport experience form directly confronting user potential user order better understand need important certainly something software startup practitioner often choose well however involving user order better understand need something carried similar fashion regardless whether organization involved software startup larger organization thus consider scope literature review extant study area already reasonably applicable software startup context well say study ux usability testing point view software startup would worth carrying however business metric conventional business metric net present value studied economic discipline also applicable software startup however earlystage software startup may yet single customer even product thus revenue making many conventional financial metric le relevant especially earlier stage metric customer acquisition cost measure cost acquiring new customer mean eg advertising far useful startup similarly software startup aim explosive growth highly scalable business model thus also likely particularly interested metric related growth shorter period time extant research extensively studied business metric website metric software development related metric various context hand academic research specifically focused metric point view software startup currently scarce software startup extent similar larger software company operate within area software industry however software startup also differ larger mature software organization various way thus conventional business metric software metric specifically aimed software startup likely applicable software startup may important software startup whereas academic literature metric point view software startup currently scarce practitioner literature contains various account software startup metric order promote discussion encourage research area review practitioner literature area present practitioner view metric software startup utilize detail multivocal literature review discussed next methodology multivocal literature review primarily focusing practitioner account conducted collect data purpose formulating list preliminary result practitioner literature heterogeneous nature ranging book blog lacking common publication platform journal establishing fully systematic protocol reviewing challenging due vast amount available data nonetheless devised protocol order conduct review semisystematic fashion case refer semisystematic consisted multiple step second one conducted systematic fashion literature review consisted three step searching literature first reviewed popular book written highprofile practitioner expert eg eric ries steve blank relevant point view metric secondly conducted set google search order find le highprofile practitioner literature blog post various practitioner involved software startup using literature gathered first two step finally utilized snowballing technique discover literature discussed document already included review google search followed systematic protocol order gather higher quality data following query used search software startup metric startup metric startup metric list startup measure query first five page result screened inclusion result evaluated inclusion based following inclusion criterion document clearly intended advertisement tool eg firm writing blogpost recommend data analytics tool document present discus specific actionable metric opposed nonspecific group metric sale metric document textual document eg link video slideshow document standalone document written real name ie forum post written pseudonym document publicly available behind paywall registration document contains metric employed software startup eg ecommerce metric document duplicate result another search query chose limit inclusion metric specifically presented software startup metric choice made practitioner seldom speak softwarestartups practitioner literature startup typically assumed technology company either engineering software using software create value user thus practitioner seem think software startup redundant construct startup indeed focused software rather speaking software startup practitioner either simply speak startup focus specifically eg ecommerce startup hand se literature often refers software startup specifically new technologybased firm ntbf longstanding construct used refer startup business literature therefore chose include document speaking startup metric general metric also applicable software startup indeed document focused solely financial metric discus user software metric finally addition practitioner literature generalpurpose software engineering metric adapted extant academic literature example practitioner literature discussed monitoring operational efficiency time spent various task would occasionally adapt generic although nonetheless actionable metric specific employing existing research fashion sought compile extensive although mean comprehensive list metric software startup based primarily practitioner literature result discussed following section result generalpurpose software startup metric much practitioner literature reviewed paper consisted short n metric startup must measure type list five ten metric result considerable amount overlap hand point consensus among practitioner metric particularly interesting commonly cited metric user churn user retention metric user engagement metric metric measuring user activity financial metric focusing shortterm development cash burn userfocused financial metric user acquisition cost churn context used refer number user lost time period number total user important monetizing software however case freemium software software free revenue made ad insoftware purchase number active user becomes increasingly important business model common among software startup practitioner literature reflected relation metric addition closely measuring number user leaving activity user regularly cited important focus well simply measuring eg total user registered user considered insufficient instead software startup regularly urged focus measuring least monthly active user mau importantly daily active user dau activity metric suggested practitioner recency number day since login user ie aging cohort analysis well frequency logins user furthermore measuring churn software startup also encouraged measure user retention number user coming back use software opposed permanently leaving addition simply measuring often user used software software startup urged measure user engagement various metric exactly constitutes engagement change based software addition activity engagement suggested measured tracking exactly user using software example digital game one indicator user engagement could act actually completing task quest game opposed simply logging game verify user fact anything game financewise software startup recommended focus primarily user customerrelated metric alongside general financial metric user customer acquisition cost cac ie average cost acquiring new paying user user customer lifetime value ltv commonly cited financial metric past userfocused financial metric conventional financial metric revenue profit margin commonly discussed although emphasis placed especially metric indicating shortterm finance monthonmonth growth monthly recurring revenue similarly cash burn rate metric related eg monthly cash burn also commonly recommended software startup practitioner utilize tie fact software startup indeed typically lacking resource including capital largely reliant outside funding especially early life cycle past commonly cited metric discussed far uncovered wide variety metric intended software startup use intention study measured could measured chose include metric thought relevant enough listed practitioner literature end full list metric gathered literature review found entirety table table alphabetical order total metric included table metric listed derivative eg one could simply speak customer churn relation number lost customer however writer went detail churnrelated metric discussing monthly churn net churn gross churn separately case submetrics listed well hand metric also merged together prevalent metric example cancellation considered related user churn finally purpose making table easier read three reference included per metric given eg customer acquisition cost discussed different reference paper
Original Title: 100+ Metrics for Software Startups - A Multi-Vocal Literature Review
Original Transcription: **100+ Metrics for Software Startups -**

**A Multi-Vocal Literature Review**

 Kai-Kristian Kemell\({}^{1}\)[0000-0002-0225-4560], Xiaofeng Wang\({}^{2}\)[0000-0001-8424-419X],

Anh Nguyen-Duc\({}^{3}\)[0000-0002-7063-9200], Jason Grendus\({}^{4}\), Tuure Tuunanen\({}^{1}\)[0000-0001-7119-1412],

and Pekka Abrahamsson\({}^{1}\)[0000-0002-4360-2226]

\({}^{1}\) University of Jyvaskyla, 40014 Jyvaskyla, Finland

{kai-kristian.o.kemell, pekka.abrahamsson, tuure.tuunanen}jyu.fi

\({}^{2}\) Free University of Bozen-Bolzano, 39100 Bozen-Bolzano, Italy

xiaofeng.wang@unibz.it

\({}^{3}\) University of Southeast Norway, Norway

angu@usn.no

\({}^{4}\) 3D Ventures Oy, Singapore

jgrendus@gmail.com

**Abstract.** Metrics can be used by businesses to make more objective decisions based on data. Software startups in particular are characterized by the uncertain or even chaotic nature of the contexts in which they operate. Using data in the form of metrics can help software startups to make the right decisions amidst uncertainty and limited resources. However, whereas conventional business metrics and software metrics have been studied in the past, metrics in the specific context of software startup are not widely covered within academic literature. To promote research in this area and to create a starting point for it, we have conducted a multi-vocal literature review focusing on practitioner literature in order to compile a list of metrics used by software startups. Said list is intended to serve as a basis for further research in the area, as the metrics in it are based on suggestions made by practitioners and not empirically verified.

**Keywords:** Software Startup, Metric, Data, Multi-Vocal Literature Review

## 1 Introduction

The importance of data in business has greatly increased over the last few decades as acquiring, storing, and using it has become both easier and cheaper in the wake of technological progress. This development was further underlined following the still relatively recent emergence of the big data discourse [47], which encouraged organizations to acquire and store vast amounts of data even if they did not necessarily have any present use for it. Data is now often used by various businesses to support decision-making, even though manager intuition is often in practice still just as important in strategic decision-making [26].

For the purpose of decision-making, data can be used in the form of metrics. Metrics are quantifiable measurements of a phenomenon or object. They are present evrywhere in our everyday life from measuring height and weight to measuring speed while driving. Even qualitative data can to some extent be made quantifiable with the right approach: a simple yes or no question can be seen as a Boolean of 1 or 0. In terms of quantifying written statements, techniques such as the Likert scale survey, where users rate qualitative statements on a scale of e.g. 1 to 5 based on how much they agree or disagree with them, have been employed.

Much like larger software companies, software startups can also employ various metrics to measure progress and to aid in decision-making. Given that software startups usually operate under a notable lack of resources and in particularly tumultuous contexts [44], software startups can arguably benefit from the use of metrics. Making the right decisions amidst uncertainty can make all the difference between success and failure. However, based on past survey data1 from 4700 software startups, most of them in fact did not track metrics or did not use the data gained from tracking them to make decisions. More specifically, 41% of these 4700 software startups felt that it was too early for them to track metrics. Out of the remaining 59% of the responses, some 16% did not track metrics either because they did not have the resources to do or because they did not believe it would benefit them, and 14% tracked them but remarked that the data had no influence on their decision-making.

Footnote 1: This was a large-scale survey that ultimately collected 10000+ responses, conducted to explore different aspects of software startups. However, after cleaning the data and filtering it based on whether this particular question about metrics was answered, \(\sim\)4700 responses remained. As the survey was extensive, most questions were not mandatory, and thus not all responses included answers to all of the questions. Additionally, the numbers are approximations as even after cleaning the data of duplicate or dubious responses (e.g. “name: test.com”) no doubt not all of the remaining responses are valid data. Data from the same survey was also used by Wang et al. [48] among others.

The majority of software startups end in failure [44]. Arguably, the proper use of the right metrics is something that can help alleviate this situation in part. Metrics can alert a business of approaching disasters and give them time to react before the resulting decrease in revenue really hits them. For example, tracking Daily Active Users (DAU) is a metric that gives near real-time data of how a software is doing. If the number suddenly starts dropping dramatically over the course of a few days, something is likely wrong. Perhaps an update was deployed on the day the initial drop started, and perhaps that update dramatically affected the stability of the software on some devices or operating systems. Nonetheless, in a situation where this hypothetical company was not tracking their DAU, this problem may have only become apparent through a dramatic drop in revenue at the end of the month. However, metrics are typically quite context-dependent; for a very early-stage software startup that is still developing their first product and thus has no users yet, tracking the aforementioned DAU serves no purpose.

Though metrics have been extensively studied in various context across disciplines, metrics specifically in relation to software startups is an emerging area of research. While e.g. classic business metrics such as Net Present Value [38] are certainly applicable to software startups as well, our understanding of what metrics are specifically useful for software startups is presently lacking. To this end, we seek to un derstand what metrics software startups currently use, or are expected to use, based on a multi-vocal literature review focusing primarily on practitioner literature. Through the literature review, we aim to compile an extensive list of potential metrics for software startups, creating fertile ground for further research on metrics in this context. This list is intended to propose potential metrics but offers little insight in which of these metrics _should_ be used. Thus, we formulate the research problem of this paper as follows:

**RQ:** What metrics could software startups use to track progress of their business?

The rest of this paper is structured as follows. In the upcoming second section we discuss software startup metrics as an area of research in relation to extant research across disciplines. In the third section we go over the methodology of this study in detail, and in the fourth section we present our results. The implications and limitations of the results are discussed in the fifth and final section that also concludes this paper.

## 2 Software Startups and Metrics

In utilizing metrics, software startups combine various types of metrics. They can utilize conventional business metrics, as well as business metrics more specifically aimed at startups, as well as software-related metrics including website metrics. Across different life cycle stages (e.g. those proposed by Wang et al. [48]), different metrics can be important for software startups. For example, conventional financial metrics are not as relevant for early-stage startups that may still be in the process of acquiring their first customers or that are still calculatingly running a deficit for the time being. A more relevant metric in such a situation could be to simply measure the amount of remaining expendable capital.

Software Engineering (SE), metrics can be split into process metrics and product metrics [49]. Process metrics are metrics related to the process of creating the software, or maintaining it during its operational life, while product metrics are related to the qualities of the product. Product metrics can be seen to include usability-related metrics as well. Process metrics, on the other hand, account for various method-specific or practice-specific metrics such as lean or agile software development metrics [24]. Website-related metrics can also be considered to be a part of SE metrics, however, as websites are ultimately software [49].

In terms of website metrics specifically, basic metrics related to system (website) performance such as site availability or bandwidth [46] have become less relevant in the wake of technological process, particularly following the popularization of cloud technology. It is now virtually a given that a website can handle any ordinary spikes in traffic load with more capacity being allocated as necessary. Indeed, rather than tracking at system-related metrics, the focus from a business point of view has shifted towards understanding the way users interact with it [4]. While assuring system per formance is no less relevant than before, it is now far easier to achieve website stability with modern computational power.

Organizations aim to comprehensively track the way users use their website in order to better understand them and to optimize it accordingly [4]. Generic metrics for this purpose include tracking visit length per page, tracking what the users click (if anything at all), as well as tracking where the users enter the website from. With large amounts of data becoming increasingly cheap and easy to handle, and with tools for gathering and analyzing such data now being readily available (e.g. Google Analytics), tracking individual users in this fashion has become widespread even among smaller organizations, including software startups. This way of tracking users is not limited to websites. Software companies are equally interested in understanding how the users of their software interact with it in practice in order to improve the software based on the data.

Though software startups occasionally also concern themselves with directly studying usability and User Experience (UX), UX and usability are typically evaluated by actively involving users as participants for a study while either directly observing their use or having the users self-report their experiences through a form. Directly confronting users and potential users in order to better understand their needs can be important and is certainly something software startup practitioners often choose to do as well. However, involving users in order to better understand their needs is something that can be carried out in a similar fashion regardless of whether the organization involved is a software startup or a larger organization. We thus consider them to be out of scope for this literature review as the extant studies in the area are already reasonably applicable to the software startup context as well. This is not to say that further studies on UX and usability testing from the point of view of software startups would not be worth carrying out, however.

As for business metrics, conventional business metrics such as the Net Present Value studied in economic disciplines are also applicable to software startup. However, an early-stage software startup may not yet have a single customer or even a product and thus have no revenue, making many of the more conventional financial metrics less relevant to them especially in their earlier stages. Metrics such as Customer Acquisition Cost, which measures the cost of acquiring a new customer by means of e.g. advertising, can be far more useful for such startups. Similarly, software startups aim for explosive growth and highly scalable business models [44] and thus are also likely to be particularly interested in metrics related to growth over shorter periods of time.

Extant research has extensively studied business metrics, website metrics, and software development related metrics [24] in various contexts. On the other hand, academic research specifically focused on metrics from the point of view of software startups is currently scarce. Software startups are to some extent similar to larger software companies and operate within the same area of the software industry. However, software startups also differ from larger or more mature software organizations in various ways. Thus, while conventional business metrics or software metrics not specifically aimed at software startups are likely to be applicable to software startups, they may not be as important to software startups.

Whereas academic literature on metrics from the point of view of software startups is currently scarce, practitioner literature contains various accounts on software startup metrics. In order to promote discussion and to encourage research in the area, we will review some of the practitioner literature in the area and present the practitioners' views on what metrics software startups should utilize. The details of this multi-vocal literature review are discussed next.

## 3 Methodology

A multi-vocal literature review primarily focusing on practitioner accounts was conducted to collect data for the purpose of formulating a list of preliminary results. As practitioner literature is very heterogeneous in nature, ranging from books to blogs and lacking in common publication platforms such as journals, establishing a fully systematic protocol for reviewing it is challenging due to the vast amount of available data. We nonetheless devised a protocol in order to conduct the review in a semi-systematic fashion. In this case we refer to it as semi-systematic as it consisted of multiple steps, of which the second one was conducted in a systematic fashion.

The literature review consisted of three steps of searching for literature. First, we reviewed popular books written by high-profile practitioner experts (e.g. Eric Ries and Steve Blank) that were relevant from the point of view of metrics. Secondly, we conducted a set of Google searches in order to find less high-profile practitioner literature such as blog posts from various practitioners involved with software startups. Then, using the literature gathered during the first two steps, we finally utilized the snowballing technique to discover more literature discussed in the documents already included for the review.

For the Google searches, we followed a systematic protocol in order to gather higher quality data. The following queries were used for these searches: "software startup metrics", and "startup metrics", "startup metrics list", and "startup what to measure". For each query, the first five pages of results were screened for inclusion. The results were evaluated for inclusion based on the following inclusion criteria:

* The document is not clearly intended as an advertisement for a tool (e.g. a firm writing a blogpost to recommend their own data analytics tool)
* The document presents or discusses specific, actionable metrics (as opposed to non-specific groups of metrics such as sales metrics)
* The document is a textual document and not e.g. a link to a video or a slideshow
* The document is a stand-alone document written under a real name (i.e. not a forum post written under a pseudonym)
* The document is publicly available; not behind a pay-wall or registration
* The document contains metrics that can be employed by most software startups (e.g. not only e-commerce metrics)
* The document is not a duplicate result from another search query

We chose to not limit our inclusions to metrics specifically presented as _software_ startup metrics. This choice was made because practitioners seldom speak of softwarestartups. In practitioner literature, startups are typically assumed to be technology companies, or to either be engineering software or be using software to create value for their users. Thus, practitioners seem to think of software startup as a redundant construct when most startups indeed are focused on software. Rather than speaking of software startups, practitioners either simply speak of startups or focus more specifically on e.g. e-commerce startups. On the other hand, SE literature often refers to software startups specifically, and New Technology-Based Firm (NTBF)[2] is a long-standing construct used to refer to startups in business literature. We therefore chose to include documents speaking of startup metrics in general when those metrics were also applicable to software startups, and indeed most such documents not focused solely on financial metrics did discuss user and software metrics.

Finally, in addition to the practitioner literature some general-purpose software engineering metrics were adapted from extant academic literature. For example, some practitioner literature discussed monitoring operational efficiency and time spent on various tasks. We would occasionally adapt such generic, although nonetheless actionable, metrics to be more specific by employing existing research.

In this fashion, we sought to compile an extensive, although by no means comprehensive, list of metrics for software startups based primarily on practitioner literature. These results will be discussed in the following section.

## 4 Results: General-Purpose Software Startup Metrics

Much of the practitioner literature reviewed for this paper consisted of short "n metrics a startup must measure" type lists of five to ten metrics. As a result, there was a considerable amount of overlap. On the other hand, this points to there being some consensus among practitioners as to which metrics are particularly interesting. The most commonly cited metrics were: (1) user churn and user retention metrics, (2) user engagement metrics and metrics measuring user activity, (3) financial metrics focusing on short-term developments and cash burn, and (4) user-focused financial metrics such as User Acquisition Cost.

Churn, in this context, is used to refer to the number of users lost during a time period. The number of total users is important for monetizing any software. However, in the case of freemium software where the software itself is free and revenue is made through ads or in-software purchases, the number of _active_ users becomes increasingly important. Such business models are common among software startups and the practitioner literature reflected this in relation to metrics.

In addition to closely measuring the number of users leaving, the activity of the users was regularly cited as an important focus as well. Simply measuring e.g. total users or registered users was considered insufficient. Instead, software startups were regularly urged to focus on measuring at least their Monthly Active Users (MAU) and, more importantly, Daily Active Users (DAU). Other such activity metrics suggested by practitioners were recency, that is, the number of days since the login of a user (i.e. aging / cohort analysis), as well as frequency of logins of the users. Furthermore, while measuring churn, software startups were also encouraged to measure user retention, that is, the number of users coming back to use the software as opposed to permanently leaving.

In addition to simply measuring how often the users used the software, software startups were urged to measure user engagement through various metrics. What exactly constitutes engagement changes based on each software, but in addition to activity, engagement was suggested to be measured by tracking what exactly the users do while using the software. For example, in a digital game, one indicator of user engagement could be the act of actually completing a task (a "quest") in the game as opposed to simply logging into the game, which in and of itself does not verify that a user is in fact doing anything in the game.

Finance-wise, software startups were recommended to focus primarily on user and customer-related metrics alongside more general financial metrics. User or Customer Acquisition Cost (CAC), i.e. the average cost of acquiring a new (paying) user, and User or Customer Life-Time Value (LTV) were the most commonly cited financial metrics. Past the user-focused financial metrics, conventional financial metrics such as revenue and profit margin were commonly discussed, although emphasis was placed especially on metrics indicating more short-term finances such as Month-on-Month growth and Monthly Recurring Revenue. Similarly, (Cash) Burn Rate and metrics related to it (e.g. monthly cash burn) were also commonly recommended for software startup practitioners to utilize. This ties to the fact that software startups are indeed typically lacking in resources, including capital, and are largely reliant on outside funding especially early on in their life cycles [44].

Past these most commonly cited metrics discussed so far, we uncovered a wide variety of metrics intended for software startup use. As our intention was not to study what _should_ be measured but what _could_ be measured, we chose to include any metrics thought to be relevant enough to be listed in the practitioner literature. To this end, the full list of metrics gathered during the literature review can be found in its entirety in the table below (Table 1), in alphabetical order. A total of 118 metrics were included in the table.

Some of the metrics listed are derivative. E.g. one could simply speak of customer churn in relation to the number of lost customers. However, some writers went into detail about churn-related metrics by discussing monthly churn, net churn and gross churn separately. In these cases, the sub-metrics were listed as well. On the other hand, some metrics were also merged together under more prevalent metrics. For example, "cancellations" [5] was considered related to user churn. Finally, for the purpose of making the table easier to read, only up to three references were included per metric given that e.g. Customer Acquisition Cost was discussed in 18 different references of this paper.

Tuple 31:
Cleaned Title: green production factor survival innovative startup evidence italy
Cleaned Transcription: green production factor survival innovative startup evidence italy riccardo gianluigi serio maria michela dickson diego giuliani giuseppe espa faculty law university trento department economics management university trento abstract many study analyzed empirically determinant survival innovative startup company using data characteristic entrepreneur management focusing firm industryspecific variable however attempt made far ass role environmental sustainability production process based data describing characteristic italian innovative startup period article study difference survival green nongreen company show controlling confounding factor startup characterized green production process tend survive longer counterpart particular estimate green innovative startup twice likely survive nongreen one evidence may support idea environment sustainability help economic development keywords innovative startup newborn company survival probability kaplanmeier cox proportional hazard model introduction innovation always distinguishing activity humanity wheel invention world wide web constitutes indissoluble common thread inherent human nature innovation also crucial economic growth sustainability following growing pressure brought international competition duty company modern nation innovate important component engine innovation found startup company term startup appears first time forbes forbes indicate new type company embryonic phase life incumbent company since attention topic growing due occurrence positive association among new business initiative innovation rate economic growth see among others kirchhoff et al baptista et al bygrave et al colombelli et al startup may stimulate economy promoting innovation audretsch reynolds innovative one often report better performance vivarelli audretsch contribute positively generation new job development new sector ac audretsch shearman burrell general fuel overall improvement welfare system birch phillips kirchhoff rickne jacobsson despite contribution innovation economic development startup often struggle survive long time market higher difficulty face especially beginning business activity greatest problem newborn company deal concern socalled liability newness stinchcombe usually associated scarcity resource new entry access start develop business indeed balance sheet indicator consistent liquidity low leverage ratio ability make profit shown important predictor success failure startup especially preliminary stage life wiklund et al feature may affect positive result newborn business activity concern characteristic entrepreneur eg hisher previous work experience business world lazear dahl reichstein hisher ability cooperate eisenhardt schoonhoven result newborn company hence startup may experience high failure rate shapero giglierano especially reproduce existing product finaldi russo et al recently innovation increasingly dedicated problem using searching alternative energy source mitigate impact human activity earth according socalled green economy indeed pursuing sustainable development global issue finnegan et al garbasso crespi et al thus innovate meet need pursue sustainability innovative startup play crucial role iazzolino et al given reasonable expect form attention protection policy maker aimed promoting development new business initiative focused technological sustainable innovation study reported evidence seem validate assumption eg soderblom samuelsson goal policy maker intensify technology transfer market competition speed evolution industrial network hence increase production employment autio parhankangas ejermo xiao storey tether particular shown sustainabilityoriented technology offer opportunity restore competitiveness western saturated mature economy mazzanti zoboli costantini et al gilli et al indeed last year green economy one best response economic crisis surprisingly also startup interested green consciousness given possibility receive additional benefit adopting environmental ethic however true company devoted sustainable production recently gain increase growth necessarily go along probability survive market central topic startup although several contribution literature addressed issue identifying factor survival eg arbia et al development young innovative company eg giraudo et al study focused investigating link sustainable development neoentrepreneurial activity schick et al paper aim filling gap literature assessing whether risk market exit innovative startup face affected environmental sustainability production process particular exploiting data population italian innovative startup period mean cox proportionalhazard model verify green startup relatively higher survival performance compared nongreen one controlling structural factor influence firm survival paper structured follow section briefly describe current italian legislative framework innovative startup italian startup act section statistical framework presented section dataset italian innovative startup analysis conducted presented interesting insight brought light section concludes italian legislative framework innovative startup startup act end italian government decided intervene improve context birth growth newborn company socalled italian startup act law introduces definition new innovative company italian legal system namely innovative startup hereinafter isu requirement considered isu related nationality registered italy another eu country production branch italy age aged le year core business must centered research development production marketing innovative product high technological value company addition isus must satisfy least two three additional requirement expense rd innovation must least either annual cost turnover employ highly qualified personnel least one third phd holder student researcher least two third msc graduate owner depositary licensee registered patent owner registered software ministry economic development newborn company respecting requirement may registered special section innovative startup italian business register aim italian legislator clearly creation environment development new entrepreneurial idea highly innovative character possibility defined isus contemplated also company comply requirement period exceeding four year company born year entry force ii exceeding three year established iii two year registered italian business register company falling definition isus may enjoy substantial number concession going purely bureaucratic sphere tax financing governance grant example first cut many red tape rule exemption pay annual fee duty stamp example second tax incentive equity investor easier compensation vat credit extension term cover systematic loss flexible corporate managing tailormade labor law remuneration employee consultant stock option work equity included taxable income compulsory operationality test verify inactivity status facilitated speedup bankruptcy procedure many others finaldi russo et al ministry economic development italian regulation isus provides particular kind innovative startup defined high technological value company energy related field company intended green startup contrast nongreen startup shall establish green oriented activity regardless specific sector activity business literature empirical evidence show nowadays sustainability innovation go hand hand feed adopting greenapproach mean newborn company transform initial difficulty opportunity although italy lagging green transition last greenitaly report unioncamere fondazione symbola pointed entire nonagricultural entrepreneur invested period plan invest end green product technology order reduce environmental impact save energy curbing co emission therefore argue innovative startup belonging class properly considered green opposed nongreen one categorization help assessing whether greenness positively affect survival performance innovative startup empirical methodology survival analysis proper empirical methodology ass determinant survival time company time occurring entry company market exit market socalled survival duration analysis unlike traditional regression modelling approach logistic regression survival analysis specifically deal inevitable occurrence censoring presence truncated observation due fact actual survival time company longer observed followup time particular order study relationship company survival performance greenness production employ kaplanmeier curve cox proportional hazard regression model descriptive survival analysis kaplanmeier curve following approach kaplan meier possible estimate company survival probability nonparametrically using observed survival time censored uncensored company let consider k company cease operate time interval observation distinct point time tttcdotstk assuming exit company market occur independently one another probability surviving point time successive one multiplied together give cumulative survival probability word probability company still market tj say sbigtjbig calculated sbigtjbig followssbigtjbigsbigtjbigleftfracdjnjright nj number company still market tj dj represents number company exit market tj obviously since value st necessarily constant successive point time thus implying estimated probability step function varies point time exit kaplanmeier hereinafter km survival curve plot st may provide useful summary survival performance company addition comparison km curve different subgroup company group green nongreen startup allows identify presence factor affecting survival indeed possible test statistical significance difference survival curve different group logrank test peto et al test based computation group expected number company cease operate point time since previous one null hypothesis difference group ith group sum value across point time provides total expected number company exit say ei logrank test summarizes discrepancy observed number company exit group say oi ei mean following test statistic chisumigfracoivarepsilonivarepsiloni null hypothesis difference survival curve group chi test statistic follows chisquare distribution g degree freedom g number group survival regression modelling cox proportional hazard model regression method survival time data attempt model relationship one regressors socalled hazard function lambdait empirical context denotes instantaneous exit rate company surviving time consequently lambdaitmathrmdt give probability company exit market time given survived time unlike parametric survival regression model require specify functional form lambdait semiparametric cox proportionalhazards model cox require make distributional assumption model hazard function company varies according time k regressors xxxk follows lambdaitlambdatexpbetaxibetaxicdotsbeta kxki lambdat represents baseline hazard betabetabetak unknown parameter need estimated formulation need specify functional form lambdat since assumed common among company indeed ratio hazard two generic company l fraclambdaltlambdaltfraclambdatexpbetaxi cdotsbetakxkilambdatexpbetaxicdotsbetak xklexpbetaxixicdotsbetakxkixkl therefore depend neither lambdacdot although specified model make assumption data generating process however need hazard proportional holding proportionalhazards assumption verified grambschtherneau ph test grambsch therneau estimation model parameter associated significance test achieved using partial likelihood technique cox result data used perform analysis proposed present paper concern italian isus cover period corresponds period startup act order avoid spurious result isus agricultural sector excluded analysis subject different legislation business failure first five year time span grouped one category due small number unit year total number startup company end period equal table report total number percentage total innovative startup company distributed italian macroarea end time span half startup located northern italy northeast northwest located central italy quarter southern italy compared beginning period growth number startup hasinvolved northern southern area country central italy suffered considerable decrease regarding economic sector activity according nace classification isus belong service sector total startup company end reference period manufacturing sector total constitutes negligible share startup operating tourism trade form together little table first research question aim address concern verify green innovative startup company higher lower survival performance compared nongreen innovative startup order address question computed km survival curve implemented cox proportional hazard model using described dataset deal several missing value variable therefore number observation varies among different analysis panel figure show km curve isus italy period estimated survival probability year activity nearly indicating half considered company still market end observational period
Original Title: Green production as a factor of survival for innovative startups.
  Evidence from Italy
Original Transcription: **Green production as a factor of survival for innovative startups. Evidence from Italy**

Riccardo Gianluigi Serio\({}^{1}\), Maria Michela Dickson\({}^{2}\), Diego Giuliani\({}^{2}\) and Giuseppe Espa\({}^{2}\)

\({}^{1}\) - Faculty of Law, University of Trento

\({}^{2}\) - Department of Economics and Management, University of Trento

**Abstract**

Many studies have analyzed empirically the determinants of survival for innovative startup companies using data about the characteristics of entrepreneurs and management or focusing on firm- and industry-specific variables. However, no attempts have been made so far to assess the role of the environmental sustainability of the production process. Based on data describing the characteristics of the Italian innovative startups in the period 2009-2018, this article studies the differences in survival between green and non-green companies. We show that, while controlling for other confounding factors, startups characterized by a green production process tend to survive longer than their counterparts. In particular, we estimate that a green innovative startup is more than twice as likely to survive than a non-green one. This evidence may support the idea that environment sustainability can help economic development.

**Keywords**

Innovative startups; Newborn companies; Survival probability; Kaplan-Meier; Cox Proportional Hazard model.

## 1 Introduction

Innovation has always been a distinguishing activity of humanity. From the wheel to the invention of the world wide web, it constitutes an indissoluble common thread, inherent in human nature itself. Innovation is also crucial for economic growth and sustainability. Following the growing pressure brought about by international competition, it is now a duty for companies and modern nations to innovate. An important component of the engine of innovation is to be found in _startup_ companies. The term startup appears for the first time on Forbes in 1976 (Forbes, 1976) to indicate a new type of company and not an embryonic phase of the life of incumbent companies. Since then, the attention on the topic has been growing due to the occurrence of positive association among new business initiatives, innovation rate and economic growth (see, among others, Kirchhoff et al., 2007; Baptista et al., 2008; Bygrave et al., 2003; Colombelli et al., 2016)

Startups may stimulate economies by promoting innovation (Audretsch, 1995; Reynolds, 1997). The most innovative ones often report better performances (Vivarelli and Audretsch, 1998), contribute positively to the generation of new jobs and to the development of new sectors (Acs and Audretsch, 1987; Shearman and Burrell, 1988), and, more in general, fuel an overall improvement of the welfare system (Birch, 1979, 1987; Phillips and Kirchhoff, 1989; Rickne and Jacobsson, 1999).

Despite their contribution to innovation and economic development, startups often struggle to survive for a long time in the market, because of the higher difficulties they face, especially at the beginning of their business activity. The greatest problem that newborn companies deal with concern the so-called liability of newness (Stinchcombe, 1965), which is usually associated with the scarcity of resources that new entries have access to start and develop the business. Indeed, some balance sheet indicators, such as a consistent liquidity, very low leverage ratio and the ability to make profits, have been shown to be important predictors of success or failure of a startup, especially in the preliminary stages of its life (Wiklund et al., 2010). Other features that may affect the positive result of a newborn business activity concern the characteristics of the entrepreneur, e.g. his/her previous work experiences in the business world (Lazear, 2004; Dahl and Reichstein, 2007) or his/her ability to cooperate (Eisenhardt, Schoonhoven, 1990). As a result, newborn companies, and hence startups, may experience high failure rates (Shapero and Giglierano, 1982), especially those that reproduce existing products (Finaldi Russo et al., 2016).

Recently, innovation has been increasingly dedicated to problem of using and searching for alternative energy sources to mitigate the impact of human activities on Earth, according to the so-called _green economy_. Indeed, pursuing a sustainable development is more and more a global issue (Finnegan et al., 2018; Garbasso, 2014; Crespi et al., 2015).

Thus, when the will to innovate meets the need to pursue sustainability, innovative startups play a crucial role (Iazzolino et al., 2019). Given that, it is reasonable to expect some form of attention and protection by the policy maker aimed at promoting the development of new business initiatives focused on technological sustainable innovation. Some studies have reported evidences that seem to validate this assumption (e.g. Soderblom and Samuelsson, 2014). The goal of policy makers is to intensify technology transfer and market competition to speed up the evolution of the industrial network and hence to increase the production and the employment (Autio and Parhankangas, 1998; Ejermo and Xiao, 2014; Storey and Tether, 1998). In particular, it has been shown that sustainability-oriented technologies offer the opportunity to restore competitiveness in western saturated mature economies (Mazzanti and Zoboli, 2009; Costantini et al., 2013; Gilli et al. 2014). Indeed, in the last years, the green economy has been one of the best responses to the economic crisis. Not surprisingly, also startups have been interested by green consciousness, given the possibility to receive additional benefits if adopting environmental ethics.

However, while it is true that companies devoted to a sustainable production have recently gain an increase in growth, this not necessarily goes along with the probability to survive in the market, which should be a central topic for startups. Although several contributions in literature addressed the issue of identifying the factors of survival (e.g. Arbia et al., 2017) and development of young innovative companies (e.g. Giraudo et al., 2019), few studies have focused on investigating the link between sustainable development and neo-entrepreneurial activity (Schick, et al., 2002).

This paper aims at filling this gap in the literature by assessing whether and how the risk of market exit that innovative startups face is affected by the environmental sustainability of their production process. In particular, exploiting data about the population of Italian innovative startups in the period 2009-2018 and by means of the Cox proportional-hazard model, we verify that _green_ startups have a relatively higher survival performance compared to the _non-green_ ones, while controlling for other structural factors that influence firm survival.

The paper is structured as follow. Section 2 briefly describe the current Italian legislative framework of innovative startups, that is the Italian Startup Act. In Section 3, the statistical framework is presented. In Section 4 the dataset about Italian innovative startups on which the analyses are conducted is presented, and interesting insights are brought to light. Section 5 concludes.

**2. The Italian legislative framework of innovative startups: the "Startup Act"**

At the end of 2012 the Italian government decided to intervene to improve the context for the birth and growth of newborn companies through the so-called _Italian Startup Act_ (Law no. 221/2012), which introduces the definition of a new innovative company in the Italian legal system, namely the _innovative startup_ (hereinafter ISU). Requirements to be considered ISU are related to the nationality (being registered in Italy or in another EU country but with a production branch in Italy), age (aged less than 5 years) and core business (which must be centered on research, development, production, marketing of innovative products with high technological value) of the company. In addition, ISUs must satisfy at least two of three additional requirements, such as: expenses in R&D and innovation must be at least 15% of either its annual costs or its turnover; employs highly qualified personnel, such as at least one third of PhD holders and students, or researchers, or at least two third of M.Sc. graduates; be the owner, depositary or licensee of a registered patent, or the owner of a registered software (Ministry of Economic Development, 2019). Newborn companies respecting these requirements may be registered in the special section for innovative startups of the Italian Business Register. The aim of the Italian legislator was clearly the creation of an environment for the development of new entrepreneurial ideas with a highly innovative character. So that, the possibility to be defined ISUs was contemplated also for companies that comply with the requirements for a period **(i)** not exceeding four years, if the company was born up to 2 years before entry into force, **(ii)** not exceeding three years, if established between 2009 and 2010, and **(iii)** up to two years, if registered in the Italian Business Register between 2008 and 2009. Companies falling into definition of ISUs may enjoy a substantial number of concessions, going from the purely bureaucratic sphere to tax, financing and governance grants. Examples of the first are the cut of many red tape rules and exemption to pay annual fees and duty stamps, while examples of the second are tax incentives for equity investors, an easier compensation of VAT credits, the extension of terms to cover systematic losses, a flexible corporate managing, tailor-made labor laws, remuneration of employees and consultants through stock options and work for equity (not included in taxable income), not compulsory operationality tests to verify the inactivity status, facilitated and speed-up bankruptcy procedures, and many others (Finaldi Russo et al., 2016; Ministry of Economic Development, 2019).

The Italian regulation on ISUs provides a particular kind of innovative startup defined as "_high technological value companies in energy related fields"_. These companies are intended as _green_ startups (in contrast with _non-green_ startups), which shall establish green oriented activities, regardless of their specific sectors of activity. Business literature and empirical evidences show that nowadays sustainability and innovation go hand in hand and feed into themselves. Adopting a greenapproach means, for newborn companies, to transform initial difficulties into opportunities. Although Italy has been lagging in the green transition, the last GreenItaly report (Unioncamere and Fondazione Symbola, 2019) has pointed out that the 31.2% of the entire non-agricultural entrepreneur has invested in the period 2015-2018, or plan to invest by the end of 2019, in green products and technologies in order to reduce the environmental impact, save energy and curbing CO2 emissions. Therefore, we argue that the innovative startups belonging to this class can be properly considered as _green_ as opposed to the _non-green_ ones. This categorization can then help in assessing whether _greenness_ positively affects the survival performance of innovative startups.

## 3 Empirical methodology: survival analysis

The proper empirical methodology to assess the determinants of survival time of a company, that is the time occurring between the entry of a company into the market and its exit from the market, is the so-called survival (or duration) analysis. Unlike the more traditional regression modelling approaches, such as the logistic regression, survival analysis can specifically deal with the inevitable occurrence of censoring, that is the presence of truncated observations due to the fact that the actual survival time of a company can be longer than its observed follow-up time. In particular, in order to study the relationship between company survival performance and _greenness_ in production, we employ Kaplan-Meier curves and the Cox proportional hazards regression model.

### Descriptive survival analysis: the Kaplan-Meier curves

Following the approach by Kaplan and Meier (1958), it is possible to estimate the company survival probability non-parametrically using the observed survival times, both censored and uncensored, of each company.

Let consider that \(k\) companies cease to operate during the time interval under observation at distinct points in time \(t_{1}<t_{2}<t_{3}<\cdots<t_{k}\). Assuming that exit of companies from the market occur independently of one another, the probabilities of surviving from a point in time to the successive one can be multiplied together to give the cumulative survival probability. In other words, the probability that a company is still on the market at \(t_{j}\), say \(S\big{(}t_{j}\big{)}\), can be calculated from \(S\big{(}t_{j-1}\big{)}\) as follows:\[S\big{(}t_{j}\big{)}=S\big{(}t_{j-1}\big{)}\left(1-\frac{d_{j}}{n_{j}}\right),\]

where \(n_{j}\) is the number of companies still being on the market just before \(t_{j}\) and \(d_{j}\) represents the number of companies that exit from market at \(t_{j}\). Obviously, since \(t_{0}=0\), then \(S(0)=1\). The value of \(S(t)\) is necessarily constant between successive points in times thus implying that the estimated probability is a step function that varies only at the point in time of each exit. The Kaplan-Meier (hereinafter KM) survival curve is the plot of \(S(t)\) against \(t\) and may provide a useful summary of the survival performance of companies.

In addition, the comparison between the KM curves of different subgroups of companies, such as the groups of green and non-green startups, allows to identify the presence of factors affecting the survival. Indeed, it is possible to test the statistical significance of the difference between the survival curves of different groups through the log-rank test (Peto et al., 1977). This test is based on the computation, for each group, of the expected number of companies that cease to operate at each point in time, since the previous one, under the null hypothesis of no difference between groups. For each \(i\)-th group, the sum of these values across all points in time provides the total expected number of companies' exits, say \(E_{i}\). The log-rank test summarizes the discrepancies between the observed number of companies' exits in each group, say \(O_{i}\), and \(E_{i}\) by means of the following test statistic,

\[\chi^{2}=\sum_{i=1}^{g}\frac{(o_{i}-\varepsilon_{i})^{2}}{\varepsilon_{i}}.\]

Under the null hypothesis of no difference between the survival curves of the groups, the \(\chi^{2}\) test statistic follows a Chi-square distribution with \((g-1)\) degrees of freedom, where \(g\) is the number of groups.

_3.2 Survival regression modelling: the Cox proportional hazards model_

Regression methods for survival time data attempt to model the relationship between one or more regressors and the so-called hazard function \(\lambda_{i}(t)\), which in this empirical context denotes the instantaneous exit rate for company \(i\) surviving to time \(t\). Consequently, \(\lambda_{i}(t)\mathrm{d}t\) gives the probability of company \(i\) to exit from market at time \(t\), given that it survived until time \(t\). Unlike other parametric survival regression models, which require to specify a functional form for \(\lambda_{i}(t)\), the semi-parametric _Cox proportional-hazards model_ (Cox, 1972) does not require to make any distributional assumption.

Under this model, the hazard function for company \(i\) varies according to time \(t\) and \(k\) regressors (\(x_{1},x_{2},...,x_{k}\)) as follows:

\[\lambda_{i}(t)=\lambda_{0}(t)\exp(\beta_{1}x_{1i}+\beta_{2}x_{2i}+\cdots+\beta_ {k}x_{ki})\]

where \(\lambda_{0}(t)\) represents the baseline hazard and \(\beta_{1},\beta_{2},...,\beta_{k}\) are unknown parameters that need to be estimated. In this formulation there is no need to specify the functional form of \(\lambda_{0}(t)\) since it is assumed to be common among all companies. Indeed, the ratio between the hazards of any two generic companies \(i\) and \(l\) is

\[\frac{\lambda_{l}(t)}{\lambda_{l}(t)}=\frac{\lambda_{0}(t)\exp(\beta_{1}x_{1i }+\cdots+\beta_{k}x_{ki})}{\lambda_{0}(t)\exp(\beta_{1}x_{1i}+\cdots+\beta_{k} x_{kl})}=\exp[\beta_{1}(x_{1i}-x_{1i})+\cdots+\beta_{k}(x_{ki}-x_{kl})]\]

and, therefore, it does not depend on neither \(t\) nor \(\lambda_{0}(\cdot)\).

Although the specified model does not make any assumption about the data generating process, it however needs that the hazards are proportional. The holding of the proportional-hazards assumption can be verified with the Grambsch-Therneau P.H. test (Grambsch and Therneau, 1994). The estimation of the model parameters and the associated significance tests can be achieved using the partial likelihood technique (Cox, 1975).

## 4 Results

Data used to perform the analysis proposed in the present paper concern Italian ISUs and cover the period 2009-2018, which corresponds to the period of the Startup Act. In order to avoid spurious results, ISUs in agricultural sector have been excluded from the analyses because they are subject to a different legislation about business failure. The first five years of time span have been grouped in one category, due to the small number of units in each year. The total number of startup companies at the end of the period was equal to 9,453. Table 1 reports the total number and the percentage on the total of innovative startup companies, distributed by Italian macro-area. At the end of the time span, more than half of the startups (55.1%) are located in northern Italy (23.3% in North-East and 31.8% in North-West), while 20.5% are located in central Italy and only under a quarter (24.4%) in southern Italy. Compared to the beginning of the period, the growth in the number of startups hasinvolved both northern and southern areas of the country, with only central Italy to have suffered a considerable decrease.

Regarding the economic sector of activity (according to the NACE classification), most of ISUs belong to the service sector, which is the 76.3% of the total startup companies at the end of the reference period. The manufacturing sector, with its 18.4% on the total, constitutes a not negligible share, while startups operating in tourism and trade form together little more than 5% (Table 2).

The first research question that we aim to address concerns to verify if green innovative startup companies have a higher or lower survival performance compared to the non-green innovative startups. In order to address this question, we have computed the KM survival curves and implemented the Cox Proportional Hazard model. In using the described dataset, we had to deal with several missing values in some variables. Therefore, the number of observations varies among the different analyses.

Panel (a) of Figure 1 shows the KM curves for 9,453 ISUs in Italy in the 2009-2018 period. At the estimated survival probability after 8 years of activity for is nearly 57.5%, indicating that more than half of the considered companies is still in the market at the end of the observational period.

Tuple 32:
Cleaned Title: investor embrace gender diversity female ceo role gender startup fundraising
Cleaned Transcription: investor embrace gender diversity female ceo role gender startup fundraising christopher cassion santa clara university santa clara ca usa yuhang qian santa clara university santa clara ca usa constant bossou santa clara university santa clara ca usa margareta ackerman santa clara university santa clara ca usa footnote email mackermanscuedu abstract allocation venture capital one primary factor determining take product market startup succeed fail get participate shaping collective economy gender diversity contributes startup success funding allocated maleonly entrepreneurial team wake covid seeing notable decline funding female mixedgender team giving raise urgent need study correct longstanding gender bias startup funding allocation conduct indepth data analysis company crunchbase comparing funding allocation based gender composition founding team detailed finding across diverse industry geography presented construct machine learning model predict whether startup reach equity round revealing surprising finding ceo gender primary determining factor attaining funding policy implication pressing issue discussed keywordsgender bias venture capital diversity entrepreneur gender equality continues make stride across wide range industry stem medicine critical sphere bias persists compared male counterpart woman little access startup fund restricting engaging economy critical level according pitchbook female founder raised total venture capital funding invested mixed gender founding team received economic impact covid pandemic severe consequence female entrepreneur compared first quarter saw decline proportion deal made female mixedgender team funding allocated female team third quarter funding given femaleonly team dropped mixedgender team receiving urgent need understanding nature persistent bias uncovering effective solution systemic change united state startup founded woman yet number woman starting company primary issue far moreimportant problem lack access capital funding gap male female founder particularly high early stage venture analysis california massachusetts startup revealing femaleled venture le likely maleled one obtain vc funding generally wellknown venture community men easier time raising fund much remains unclear order ascertain effective solution necessary gain insight nature problem instance woman founding team increase decrease fundraising outcome role gender ceo play compared gender founder funding successfully raised gender impact amount raised much gender matter different geographic region across industry perform indepth data analysis company crunchbase analysis suggests presence bias woman across geography industry extends femaleonly also mixedgender team female ceo also construct machinelearning model decision tree random forest logistic regression gradient boosted tree multilayer perceptron mlp predict whether founding team reach priced funding round finding show ceo gender important founder characteristic predicting fundraising success beating critical feature including whether founder attended top university number prior exit discus implication finding utilization machine learning model venture capital allocation make recommendation systemic change footnote raising priced round major milestone offer startup mean succeed footnote startup role ceo often taken one founder nearly ubiquitous early stage background gender play key role across lifetime entrepreneurial journey woman le likely become entrepreneur men le likely get external funding new venture founded funding gap male female founder higher early stage venture later stage woman le likely get funded early stage le likely funded later stage strong signal growth available consequently womenowned business rely heavily internal funding ex personal finance rather funding others debt equity finance firm even though number womenowned firm increasing rapidly still left behind compared male counterpart receiving external founding previous work provides valuable insight role gender allocation venture capital fund however data used previous study tends geographically limited focusing individual country often u consisting several hundred instance manyquestions remain answered wide gender gap allocation venture capital funding across geographic region industry gender diversity help hinder fundraising outcome gender ceo play special role compared founder order gain broader understanding nature prevalence gender bias vc perform comprehensive analysis date impact gender startup funding across geography industry vertical utilizing statistical method machine learning technique careful account potential influence pipeline problem whereby fewer woman seeking engage entrepreneurship data analysis help inform policy recommendation hope support future research resolving gender bias startup funding allocation footnote pipeline problem often perceived primary cause gender gap startup funding allocation suggesting gap would eliminated woman interested men pursuing entrepreneurship devise apply analysis method shed light issue manner reduced pipeline problem methodology rely crunchbase data attain data set company along founder information consider four gender composition founding team consisting entirely male founder maleonly founding team consisting entirely female founder femaleonly team least one female least one male founder led male ceo mixed maleled team least one female least one male founder led female ceo mixed femaleled company gender leadership composition subsequently compared emphasis funding raised across variety industry geography construct machine learning model ascertain importance team gender composition leader gender funding outcome data collection data obtained crunchbase pride leading destination company insight earlystage startup fortune crunchbase provides two major type data information company data individual leadership position separately retrieved type data include nonoverlapping feature instance gender information available founder attribute absent company description footnote httpswwwcrunchbasecomhttpswwwcrunchbasecom final dataset integration company founder data first downloaded data company founder attribute interest analysis combined two company website attribute founder company dataset produce new dataset data point combined dataset contains attribute company aggregated attribute founder dataset dropped row missing value key attributed headquarter region total funding raised industry obtained final dataset entry company led multimember founding team worth noting company ranked higher crunchbase tend fewer missing value founder present founder dataset founder name present company dataset comma separated attribute whenever founder gender missing founder data set rely machinelearning model gender classification based name footnote utilized following namebased gender classifier httpsgithubcomclintvalgenderpredictorhttpsgithubcomclintvalgenderpredictor retrained model achieving accuracy another important aspect identifying leading startup define leader either ceo sole founder one person founding team order determine leadership inspect job title founder found crunchbase company primary organization set company male female led based gender identified founder femaleonly maleonly company respectively female male led reclassified industry attribute value reducing one hundred industry thirty combining closely related industry amongst twenty industry company selected picked first industry company provides primary industry company headquarter region used identify location attribute statistic delving extensive analysis share basic statistic data shown figure overall founder gender distribution company dataset consists femaleonly company maleonly company mixed femaleled company mixed maleled company see figure figure number company gender composition type analysis includes industry consisting least company see figure list industry omit location fewer company resulting three major geographic region consisted north america europe asiapacific since company located north america also include detailed analysis focusing company based top four u startup hub silicon valley bay area greater new york area greater los angeles area greater boston area lastly startup data founded year please see appendix additional information data set data analysis section analyse funding allocated founding team different gender composition result reported across diverse industry geographic region analysis industry begin analysis funding allocation industry across dominant industry identified data shown figure far maleonly company femaleonly mixedgender company across industry industry data commerce apps largest number company gaming agriculture farming administrative service fewest industry next biggest category maleled mixedgender group figure average funding gender composition founding team value ten million usd shown figure maleonly maleled mixedgender team receive great majority funding particular maleonly team receive significantly time funding femaleonly team statistic p maleonly team also get significantly time funding mixedgender femaleled team statistic p similarly mixedgender maleled team also receive significantly time funding mixedgender femaleled statistic p female team statistic p maleonly team receive funding industry industry significant difference amount raised maleonly team compared femaleonly team exception agriculture farming biotechnology difference significant hand difference maleonly maleled often insignificant significant difference found industry example data industry maleonly team get significantly funding mixed femaleled team statistic p female team statistic p insignificantly mixed maleled team statistic p similarly commerce maleonly team get significantly funding mixed femaleled team statistic p female team statistic p significantly mixed maleled team statistic figure number company gender composition type industry industry dominated maleonly team p industry study food one maleonly team raise largest amount total funding however difference maleonly mixed maleled team significant statistic p average funding industry pipeline problem fact fewer woman engage entrepreneur often perceived primary factor discrepancy funding allocation order gain insight nature issue beyond pipeline problem consider average funding allocated team successfully raised fund comparing amount raised gender founding team analysis help gain insight offering accessible demonstration potential gender gap lay audience shown figure maleonly founding team male led founding team lead average funding receiving highest amount average funding across industry industry mixedgender maleled figure total funding allocation founding team different gender composition across industry value hundred billion usd total funding across twenty one industry dominated company founded maleonly founder except food industry mixedgender maleled team raised funding group type team achieve highest average funding compared industry maleonly team raise average funding industry including food administrative service substantial gap average funding given mixed maleled led team maleonly mixed team raising greater amount funding twenty industry two industry energy education femaleled team receive average funding notably industry femaleonly team raise greatest amount average funding unlike total funding persistent gap average funding startup successfully raise fund explained low number woman entrepreneur comparing company led woman find industry femaleonly team receive average funding mixedgender femaleled startup analysis geography considering average funding allocation shown figure see raking average funding allocation across continent femaleonly team figure average funding allocation founding team different gender composition across industry value hundred million usd industry average funding highest mixedgender maleled team industry maleonly team industry receiving lowest average funding followed femaleled mixedgender team maleonly team finally mixedgender maleled team receiving highest amount average capital analyzing startup hub united state shown discover silicon valley new york maleonly team receive highest average funding narrowing beating mixedgender maleled team la boston follow global trend giving mixedgender maleled team highest amount average funding followed maleonly team silicon valley new york la femaleonly team receive least amount average funding followed mixed femaleled team however boston femaleonly team receive average funding mixedgender femaleled team summary company male ceo receive greater funding across continent u startup hub compared company female ceo mixedgender team perform well respect fundraising often better maleonly team led maleceos comparing total funding different gender composition team across continent see figure find mixedgender team receive great majority funding three continent considered europe appears exhibiting greatest preference maleonly team group receive significantly time funding femaleonly company statistic p european maleonly team raise significantly figure average funding allocation founding team different gender composition across dominant continent value hundred million usd continent consideration reveal raking maleled mixedgender team receiving highest average funding followed maleonly team femaleled mixedgender team finally femaleonly team receiving lowest amount average funding money mixed femaleled team statistic p comparing mixed gender team led men raise funding femaleled figure total funding major geographic region value hundred million usd maleonly founding team receive greater amount funding region considered femaleonly team femaleled team receive least founding figure average funding allocation founding team different gender composition across u startup hub value ten million usd u silicon valley bay area new york allocate highest average funding maleonly team whereas maleled mixedgender group greater los angeles area boston receive average funding group type group statistic p maleonly company europe raise nonsignificantly time total funding mixedgender team led men statistic p asiapacific maleonly company receive significantly time funding femaleonly company statistic p maleonly team raise insignificantly time mixedgender female led team statistic p comparing mixed gender team led men raise insignificantly time funding femaleled group statistic p finally male team raise time maleled mixedgender team statistically significant statistic p looking total funding different gender composition team across u startup hub see figure similar continental analysis male team receive great majority funding four major hub silicon valley exhibit greatest preference male founder maleonly company receiving significantly time funding femaleonly company statistic p significantly time mixedgender femaleled company statistic p los angeles area maleonly company significantly receive time funding femaleonly company statistic p comparing maleonly mixed femaleled company maleonly raised insignificantly time statistic p new york give maleonly company time funding femaleonly company figure total funding major u startup hub value hundred billion usd maleonly founding team receive greater amount funding region considered femaleonly femaleled team receive least statistic p time mixedgender femaleled company statistic p result significant finally analysis boston area show maleonly company receive time funding femaleonly company statistic p time mixedgender femaleled company statistic p however result significant predictive model venture capitalist primary aim identify startup become successful future machine learning model playing increasingly important role venture capital space see example predictive model used stage investment problem particularly challenging early stage startup prior availability qualitative data company performance prediction later stage startup benefit information factor revenue growth making prediction significantly accurate hand early stage investment often prerevenue precede product market fit rely primarily founder characteristic footnote many venture capital firm built custom model make public order maintain competitive advantage one primary risk utilization machine learning model ethical perspective perpetuation even amplification existing bias instance context credit market black hispanic borrower disproportionately le likely gain introduction machine learning much gender bias present startup data degree utilization machine learning model stand perpetuate even amplify gender bias venture capital explore direction creating several machine learning model based founder characteristic dominant characteristic available early stage investment analyze feature importance ascertain much prediction rely gender composition founding team gender ceo note exploration differs significantly prior work predictive modeling startup success since interested specifically importance gender attaining priced funding round contrast work field aim predict startup success incorporating information startup including quantitative success indicator total funding raised number employee feature selection order ascertain investor behaviour prior clear success indicator available focus exclusively founder characteristic however essential avoid including feature would heavily altered target variable instance social medium presence stand alter founder successfully raised funding similarly information regarding investment made founder heavily influenced entrepreneurial success also omitted training feature build model first extract set feature related founder aggregated dataset discussed methodology following feature selected male led boolean variable true ceo sole founder male false otherwise gender composition founding team maleonly femaleonly mixed maleled mixed femaleled total previously founded organization total number company previously founded member founding team average previously founded organization average number company previously founded founder previously founded organization boolean variable indicating true founder previously founded organization total number exit total number exit event founder participated average number exit average number exit event company founder exit boolean variable indicating true founder previously founded company exit event total number founder number founder company multiple founder boolean variable set true founding team consists two founder alma mater boolean variable indicating true founder went university false otherwise top school percentage founder went top school top school attended boolean variable set true founder went top school target feature goal experiment determine startup reached equity funding round based founder equity round startup sell share startup exchange large investment generally well million equity round important life cycle startup largely provide significant monetary influx company represents vote confidence venture capital community help subsequent round separate dataset two funding stage group preequity round postequity round define preequity round whose latest fundingstage angel round preseed seed round convertible note define postequity round whose latest funding stage series series b beyond corporate round using construct model predict whether founding team reached priced round model analysis using hyperparameter gridsearch obtain best model type constructed following model decision tree dt random forest logistic regression lr gradient boosted tree gbt multilayer perceptron mlp worldwide u data mlp highest accuracy worldwide data similar result found u data mlp giving highest accuracy figure figure summarize result worldwide u data respectively model performed comparably worldwide accuracy varying early stage prediction known highly challenging essential emphasize information company provided beyond founder feature order ascertain impact gender early stage investing unlikely much higher accuracy possible without incorporating feature beyond scope founder characteristic feature importance tree based model considering feature importance enables u ascertain significant genderrelated characteristic com
Original Title: Investors Embrace Gender Diversity, Not Female CEOs: The Role of Gender
  in Startup Fundraising
Original Transcription: # Investors Embrace Gender Diversity, Not Female CEOs: The Role of Gender in Startup Fundraising

Christopher Cassion

Santa Clara University, Santa Clara CA 95050, USA

1

Yuhang Qian

Santa Clara University, Santa Clara CA 95050, USA

1

Constant Bossou

Santa Clara University, Santa Clara CA 95050, USA

1

Margareta Ackerman

Santa Clara University, Santa Clara CA 95050, USA

1

Footnote 1: email: mackerman@scu.edu

###### Abstract

The allocation of venture capital is one of the primary factors determining who takes products to market, which startups succeed or fail, and as such who gets to participate in the shaping of our collective economy. While gender diversity contributes to startup success, most funding is allocated to male-only entrepreneurial teams. In the wake of COVID-19, 2020 is seeing a notable decline in funding to female and mixed-gender teams, giving raise to an urgent need to study and correct the longstanding gender bias in startup funding allocation.

We conduct an in-depth data analysis of over 48,000 companies on Crunchbase, comparing funding allocation based on the gender composition of founding teams. Detailed findings across diverse industries and geographies are presented. Further, we construct machine learning models to predict whether startups will reach an equity round, revealing the surprising finding that the CEO's gender is _the_ primary determining factor for attaining funding. Policy implications for this pressing issue are discussed.

Keywords:gender bias venture capital diversity entrepreneur. As gender equality continues to make strides across a wide range of industries from STEM to medicine, there is a critical sphere where bias persists: Compared to their male counterparts, women have little access to startup funds, restricting them from engaging in our economy at this critical level. According to Pitchbook, in 2019, female founders raised just 2.7% of the total venture capital funding invested and mixed gender founding teams received 12.9% [1].

The economic impact of the COVID-19 pandemic is having severe consequences for female entrepreneurs. Compared with 2019, the first quarter of 2020 saw a decline in the proportion of deals made with female and mixed-gender teams and funding allocated to female teams. In the third quarter of 2020, funding given to female-only teams dropped to 1.8% with mixed-gender teams receiving just 11.1% [1]. There is an urgent need for understanding the nature of this persistent bias and uncovering effective solutions for systemic change.

In the United States, only 10-15% of startups are founded by women [2]. Yet, the number of women starting companies is not the primary issue, the far moreimportant problem is their lack of access to capital [3]. The funding gap between male and female founders is particularly high at the early stage of a venture, with an analysis of California and Massachusetts startups revealing that female-led ventures are 63% less likely than male-led ones to obtain VC funding [4].

While it is generally well-known in the venture community that men have an easier time raising funds, much remains unclear. In order to ascertain effective solutions, it is necessary to gain insight into the nature of the problem. For instance, does having a woman on a founding team increase or decrease fundraising outcomes? What role does the gender of the CEO play compared to the gender of other founders? If funding is successfully raised, how does gender impact the amount raised? How much does gender matter in different geographic regions and across industries?

We perform an in-depth data analysis of over 48,000 companies on Crunchbase. Our analysis suggests the presence of bias against women across geographies and industries, which extends not only to female-only but also to mixed-gender teams with female CEOs. We also construct machine-learning models (Decision Tree, Random Forest, Logistic Regression, Gradient Boosted Trees, and Multi-layer Perceptron (MLP)) to predict whether a founding team will reach a priced funding round.1 Our findings show the CEO's2 gender to be the most important founder characteristic for predicting fundraising success, beating critical features including whether the founders attended top universities and the number of prior exits. We discuss the implications of these findings to the utilization of machine learning models in venture capital allocation, and make recommendations for systemic change.

Footnote 1: Raising a priced round is a major milestone that offers startups the means to succeed.

Footnote 2: In startups, the role of CEO is most often taken by one of the founders. This is nearly ubiquitous at early stages.

## 1 Background

Gender plays a key role across the lifetime of an entrepreneurial journey: Women are less likely to become entrepreneurs than men [5] and less likely to get external funding once a new venture is founded [6]. The funding gap between male and female founders is higher at the early stage of the venture than at later stages [7]. Women are 65% less likely to get funded at early stages and 35% less likely to be funded at later stages, when strong signals of growth are available [4].

Consequently, women-owned businesses rely heavily on internal funding (ex. personal finances) rather than funding from others, both debt and equity, to finance their firms [7]. Even though the number of women-owned firms is increasing rapidly [8], they are still left behind compared to their male counterparts in receiving external founding.

Previous work provides valuable insight into the role of gender in the allocation of Venture Capital funds. However, the data used in previous studies, such as those above, tends to be geographically limited (focusing on individual countries, often the US), or consisting of only several hundred instances. Manyquestions remain to be answered: How wide is the gender gap in the allocation of venture capital funding across geographic regions and industries? Does gender diversity help or hinder fundraising outcomes? Does the gender of the CEO play a special role compared to other founders?

In order gain a broader understanding into the nature and prevalence of gender bias in VC, we perform the most comprehensive analysis to date on the impact of gender on startup funding across geographies and industry verticals, utilizing both statistical methods and machine learning techniques. We are careful to account for the potential influence of the pipeline problem, whereby fewer women seeking to engage in entrepreneurship.3 The data analysis helps inform our policy recommendations, and we hope that it will support future research on resolving gender bias in startup funding allocation.

Footnote 3: The pipeline problem is often perceived as the primary cause of the gender gap in startup funding allocation, suggesting that the gap would be eliminated if women were as interested as men in pursuing entrepreneurship. We devise and apply analysis methods that shed light into these issues in a manner that cannot be reduced to the pipeline problem.

## 2 Methodology

We rely on Crunchbase data to attain a data set of over 48,000 companies along with founder information. We consider four gender compositions: founding teams consisting entirely of male founders (male-only), founding teams consisting entirely of female founders (female-only), teams with at least one female and at least one male founder led by a male CEO (mixed male-led), and teams with at least one female and at least one male founder led by a female CEO (mixed female-led). Companies with these gender and leadership compositions are subsequently compared, with emphasis on funding raised across a variety of industries and geographies. We then construct machine learning models to ascertain the importance of the team's gender composition and the leader's gender in funding outcomes.

### Data Collection

The data was obtained from Crunchbase, which prides itself for being "the leading destination for company insights from early-stage startups to the Fortune 1000."4 Crunchbase provides two majors types of data: Information on companies and data on individuals in leadership positions. We separately retrieved both types of data as they include some non-overlapping features. For instance, gender information is only available as a founder attribute and is absent from the company description.

Footnote 4: [https://www.crunchbase.com/](https://www.crunchbase.com/)

Our final dataset is an integration of the company and founder data. We first downloaded data of 224,000 companies and 175,000 founders with attributes of interest to our analysis. We then combined the two Company's Website attribute in both the founders and companies dataset to produce a new dataset of 63,462 data points. The combined dataset contains all the attributes of the companies and all the aggregated attributes of the founders dataset. We dropped all rows with missing values in the key attributed (headquarter region, total funding raised, and industry) and obtained a final dataset of 48,676 entries. 58.14% of the companies are led by multi-member founding teams. It is worth noting that companies ranked higher by Crunchbase tend to have fewer missing values.

While not all founders are present in the founders dataset, founders names are present in the company dataset as comma separated attributes. Whenever a founder's gender is missing from the founder data set, we rely on a machine-learning model for gender classification based on names.5

Footnote 5: We utilized the following name-based gender classifier: [https://github.com/clintval/gender-predictor](https://github.com/clintval/gender-predictor). We retrained the model, achieving an accuracy of 97.10%.

Another important aspect is identifying who is leading the startup. We define the leader as either the CEO, or the sole founder for one person founding teams. In order to determine leadership, we inspect the job titles of all of the founders found on Crunchbase that have the company as their primary organization. We set if the company is male or female led based on the gender of the identified founder. Female-only and male-only companies are respectively female and male led.

We reclassified the industries attribute values by reducing over one hundred industries down to thirty by combining closely related industries, from amongst which twenty industries with over 300 companies each were selected. We then picked the first industry that each company provides as its primary industry. The company's headquarter region was used to identify its location.

### Attribute Statistics

Before delving into extensive analysis, we share some basic statistics about the data. As shown in Figure 1, overall founder gender distribution of the 48,676 companies in our dataset consists of 7.13% female-only companies, 80.22% male-only companies, 3.26% mixed female-led companies, and 9.39% mixed male-led companies (see Figure 1)

Figure 1: **Number of companies of each gender composition type**

Our analysis includes 20 industries, each consisting of at least 300 companies (See Figure 3 for the list of industries). We omit locations with fewer than 1,500 companies, resulting in three major geographic regions, consisted of North America, Europe, and Asia-Pacific. Since 64.01% of companies are located in North America, we also include a detailed analysis focusing on companies based in the top four US startup hubs: Silicon Valley Bay Area, Greater New York Area, Greater Los Angeles Area, and Greater Boston Area. Lastly, 94.84% of the startups in our data were founded on or after the year 2000. Please see the Appendix for additional information about the data set.

## 3 Data Analysis

In this section, we analyse the funding allocated to founding teams with different gender compositions. Results are reported across diverse industries and geographic regions.

### Analysis by industry

We begin with an analysis of funding allocation by industry across the 20 most dominant industries identified in our data. As shown in Figure 3, there are far more male-only companies than female-only and mixed-gender companies across all industries. The industries Data, Commerce and Apps have the largest number of companies while Gaming, Agriculture and Farming and Administrative Services have the fewest. In all but 5 out the 20 industries, the next biggest category is male-led, mixed-gender groups.

Figure 2: **Average funding by gender composition of founding teams**. Values in tens of millions of USD.

As shown in Figure 4, male-only and male-led mixed-gender teams receive the great majority of funding. In particular, male-only teams receive significantly 31 times more funding than female-only teams (statistic=11.0715, \(P\)\(<\) 0.0001). Male-only teams also get significantly 47 times more funding than mixed-gender female-led teams (statistic=5.8197, \(P\)\(<\) 0.0001). Similarly, mixed-gender male-led teams also receive significantly 8.5 times more funding than mixed-gender female-led (statistic=3.5987, \(P\)\(<\) 0.0001) and female only teams (statistic=4.2129, \(P\)\(<\) 0.0001).

Male-only teams receive more funding in 19 of the 20 industries. In 18 of the 20 industries, there is a significant difference between the amount raised by male-only teams compared with female-only teams, the exceptions being agriculture & farming and biotechnology, where the difference is not significant. On the other hand, the difference between male-only and male-led is often insignificant, with a significant difference found in only 4 of the 20 industries.

For example, in the Data industry, male-only teams get significantly more funding than mixed female-led teams (statistic=6.0181, \(P\)\(<\) 0.0001), and female only teams (statistic=4.6942, \(P\)\(<\) 0.0001), and insignificantly more than mixed male-led teams (statistic=0.6319, \(P\)\(=\) 0.5276). Similarly, in Commerce, male-only teams get significantly more funding than mixed female-led teams (statistic=3.4581, \(P\)\(=\) 0.0005) and female only teams (statistic=3.7047, \(P\)\(=\) 0.0002) and significantly more than mixed male-led teams (statistic=2.6360,

Figure 3: **Number of companies for each gender composition type by industry.** All 20 industries are dominated by male-only teams.

\(P\)= 0.0084). Of the industries studies, Food is the only one where male-only teams did not raise the largest amount of total funding, however, the difference between male-only and mixed male-led teams was not significant (statistic=0.9567, \(P\)= 0.3427).

### Average funding by industry

The pipeline problem, the fact that fewer women engage in entrepreneur, is often perceived as the primary factor in the discrepancy in funding allocation. In order to gain insight into the nature of the issue beyond the pipeline problem, we consider the average funding allocated to teams that have successfully raised funds, comparing the amounts raised against the gender of the founding teams. This analysis helps gain insight while offering an accessible demonstration of a potential gender gap to lay audiences.

As shown on Figure 5, male-only founding teams and male led founding teams lead in average funding, receiving the highest amount of average funding across most industries (18 out 20). In 11 of the 20 industries, mixed-gender male-led

Figure 4: **Total funding allocation for founding teams with different gender composition across industries.** Values in in hundreds of billions of USD. Total funding across all twenty one industries are dominated by companies founded by male-only founders except in the Food industry where mixed-gender male-led teams raised more funding than any other group type.

team achieve the highest average funding, compared with 7 industries where male-only teams raise the most average funding. In industries including Food and Administrative Services there is a substantial gap between average funding given to mixed male-led led teams and male-only, with the mixed teams raising a greater amount of funding.

Of the twenty industries, there are only two industries (Energy and Education) where female-led teams receive more average funding. Notably, there are no industries where female-only teams raise the greatest amount of average funding. Unlike total funding, this persistent gap in average funding to startups that successfully raise funds cannot be explained by low numbers of women entrepreneurs.

Comparing companies led by women, we find that in 9 of the 20 industries female-only teams receive more average funding than mixed-gender female-led startups.

### Analysis by geography

Considering average funding allocation, shown in Figure 6, we see the same raking by average funding allocation across all continents, with female-only teams

Figure 5: **Average funding allocation for founding teams with different gender composition across industries.** Values in hundreds of millions of USD. Of the 20 industries, average funding is highest for mixed-gender male-led teams in 11 industries and for male-only teams in 7 industries.

receiving the lowest average funding, followed by female-led mixed-gender teams, then male-only teams, and finally mixed-gender male-led teams receiving the highest amount of average capital.

Analyzing startup hubs in the United States, shown in 7, we discover that in Silicon Valley and New York male-only teams receive the highest average funding, narrowing beating mixed-gender male-led teams. LA and Boston follow the global trend of giving mixed-gender male-led teams the highest amounts of average funding, followed by male-only teams. In Silicon Valley, New York, and LA, female-only teams receive the least amount of average funding, followed by mixed female-led teams. However, in Boston, female-only teams receive more average funding than mixed-gender female-led teams.

In summary, companies with male CEOs receive greater funding across all continents and US startup hubs compared with companies with female CEOs. Mixed-gender teams perform well with respect to fundraising, often better than male-only teams, when they are led by male-CEOs.

When comparing total funding for different gender composition teams across continents (see Figure 8), we find that mixed-gender teams receive the great majority of funding in the three continents considered. Europe appears to be exhibiting the greatest preference for male-only teams, where such groups receive significantly over 65.5 times more funding than female-only companies (statistic=6.5061, \(P<0.0001\)). European male-only teams raise significantly 92.9 more

Figure 6: **Average funding allocation to founding teams with different gender composition across dominant continents.** Values in hundreds of millions of USD. All continents under consideration reveal the same raking, with male-led mixed-gender teams receiving the highest average funding, followed by male-only teams, then female-led mixed-gender teams, and finally female-only teams receiving the lowest amount of average funding.

money than mixed female-led teams (statistic=7.6873, _P\(<0.0001\)_). Comparing mixed gender teams, those led by men raise 15.3 more funding than female-led

Figure 8: **Total funding by major geographic regions.** Values in hundreds of millions of USD. Male-only founding teams receive the greater amount of funding in all regions considered, while female-only teams and female-led teams receive the least founding.

Figure 7: **Average funding allocation to founding teams with different gender compositions across US startup hubs.** Values in tens of millions of USD. In the US, Silicon Valley Bay Area and New York allocate the highest average funding to male-only teams, whereas male-led mixed-gender groups in Greater Los Angeles Area and Boston receive more average funding than all other group types.

groups (statistic=2.0306, \(P\)= 0.0427). Male-only companies in Europe raise non-significantly 6 times more total funding than mixed-gender teams led by men (statistic=0.6232, \(P\)= 0.5327).

In Asia-Pacific, male-only companies receive significantly over 37 times more funding than female-only companies (statistic=5.1950, \(P\)\(<\) 0.0001). Male-only teams raise insignificantly over 43 times more than mixed-gender female led teams (statistic=1.0063, \(P\)= 0.3157). Comparing mixed gender teams, those led by men raise insignificantly 12 times more funding than female-led groups (statistic=1.8761, \(P\)= 0.0611). Finally, male only teams raise 3.5 time more than male-led mixed-gender teams, not statistically significant (statistic=1.6322, \(P\)= 0.1032).

When looking at total funding for different gender composition teams across US startup hubs (see Figure 9), similar to the continental analysis, male only teams receive the great majority of funding for the four major hubs. Silicon Valley exhibits some of the greatest preference for male founders, with male-only companies receiving significantly over 27 times more funding than female-only companies (statistic=2.9081, \(P\)\(<\) 0.0038) and significantly over 35 times more than mixed-gender female-led companies (statistic=2.7921, \(P\)\(<\) 0.0054).

In Los Angeles Area, male-only companies significantly receive over 23 times more funding than female-only companies (statistic=3.3092, \(P\)\(<\) 0.0010). Comparing male-only to mixed female-led companies, male-only raised insignificantly over 30 times more (statistic=1.0888, \(P\)= 0.2787). New York gives male-only companies over 21 times more funding than female-only companies

Figure 9: **Total funding by major US startup hubs.** Values in hundreds of billions of USD. Male-only founding teams receive the greater amount of funding in all regions considered, while female-only and female-led teams receive the least.

(statistic=6.8847, \(P\)\(<\) 0.0001) and over 37 times more than mixed-gender female-led companies (statistic=3.4533, \(P\)\(=\) 0.0006), both results being significant.

Finally, analysis of Boston area shows that male-only companies receive about 16 times more funding than female-only companies (statistic=1.8629, \(P\)\(<\) 0.0639) and about 41 times more than mixed-gender female-led companies (statistic=1.4243, \(P\)\(<\) 0.1599), however here the results were not significant.

## 4 Predictive Models

Venture capitalists' primary aim is to identify startups that will become successful in the future. As such, machine learning models have been playing an increasingly important role in the venture capital space (see, for example, [9], [10] and [11]).6 While predictive models can be used at any stage of investment, the problem is particularly challenging for early stage startups, prior to the availability of qualitative data on company performance. Prediction for later stage startups benefit from information on factors such as revenue and growth, making prediction significantly more accurate. On the other hand, early stage investments, which are often pre-revenue and precede product market fit, rely primarily on founder characteristics.

Footnote 6: Further, many venture capital firms built their own custom models which they do not make public in order to maintain a competitive advantage.

One of primary risks with the utilization of machine learning models from an ethical perspective is the perpetuation and even amplification of existing biases. For instance, in the context of credit markets, Black and Hispanic borrowers are disproportionately less likely to gain from the introduction of machine learning [12].

How much gender bias is present in startup data? To what degree does the utilization of machine learning models stands to perpetuate, or even amplify, gender bias in venture capital? We explore this direction by creating several machine learning models based on founder characteristics, the dominant characteristics available for early stage investments. We then analyze feature importance to ascertain how much the predictions rely on the gender composition of founding teams and the gender of the CEOs. Note that our exploration differs significantly from prior work in predictive modeling for startup success, since we are interested specifically in the importance of gender for attaining a priced funding round. By contrast, most work in the field aims to predict startup success by incorporating information about the startup itself, including quantitative success indicators such as total funding raised and number of employees.

### Feature Selection

In order to ascertain investor behaviour prior to having clear success indicators available, we focus exclusively on founder characteristics7. However, it is essential to avoid including features that would be heavily altered by the target variable. For instance, social media presence stands to alter for founders who successfully raised funding. Similarly, information regarding investments made by the founders is heavily influenced by their entrepreneurial success, and are as such also omitted.

#### 4.2.2 Training Features

To build the model, we first extract a set of features related to the founders from the aggregated dataset discussed in Methodology. The following features have been selected:

* **Male Led**: Boolean variable that is True if the CEO or sole founder is Male, False otherwise
* **Gender Composition**: If the founding team is male-only, female-only, mixed male-led, or mixed female-led
* **Total Previously Founded Organizations**: Total number of companies previously founded by members of the founding team
* **Average Previously Founded Organizations**: The average number of companies previously founded by the founders
* **Has Previously Founded Organizations**: Boolean variable indicating True if any of the founders previously founded an organization
* **Total Number of Exits**: Total number of exit events in which the founders participated
* **Average Number of Exits**: Average number of exit events for the company founders
* **Has Exits**: Boolean variable indicating True if any of the founders had previously founded a company that had an exit event
* **Total Number of Founders**: Number of founders of the company
* **Multiple Founders**: Boolean variable set to True if the founding team consists of two or more founders
* **Same Alma Mater**: Boolean variable indicating True if all of the founders went to the same university, False otherwise
* **% from Top School**: Percentage of founders that went to a top 100 school [13]
* **Top School Attended**: Boolean variable set to True if any of the founders went to a top 100 school[13]

#### 4.2.3 Target Feature

The goal of these experiments is to determine if a startup reached an equity funding round based on its founders. An equity round is when a startup sells shares of the startup in exchange for a large investment (generally well over a million). Equity rounds are important to the life cycle of startups largely because they provide a significant monetary influx into the company and represents a vote of confidence from the Venture Capital community, which helps with subsequent rounds.

We separate the dataset into two funding stage groups, pre-equity rounds and post-equity rounds. We define pre-equity rounds as those whose latest fundingstage is an Angel Round, Pre-Seed, Seed Round, or Convertible Note. We define post-equity rounds as those that whose latest funding stage is Series A, Series B or beyond, or Corporate Rounds. Using that, we construct models to predict whether a founding team has reached a priced round.

### Model Analysis

Using hyperparameter grid-search to obtain the best model of each type, we constructed the following models: (1) Decision Tree (DT), (2) Random Forest, (3) Logistic Regression (LR), (4) Gradient Boosted Trees (GBT), and (5) Multi-layer Perceptron (MLP), for each of the worldwide and US data. MLP had the highest accuracy on worldwide data, at 63.73%. Similar results were found for US data with MLP giving the highest accuracy of 63.61%. Figure 1 and Figure 4 summarize the results for worldwide and US data, respectively. All models performed comparably, with worldwide accuracies varying by only 0.86%.

Early stage predictions are known to be highly challenging. It is essential to emphasize that no information about the companies has been provided beyond founder features, in order to ascertain the impact of gender on early stage investing. It is unlikely that much higher accuracy is possible without incorporating features beyond the scope of founder characteristics.

#### 4.2.1 Feature importance in tree based models

Considering feature importance enables us to ascertain how significant are gender-related characteristics com

Tuple 33:
Cleaned Title: business model canvas pay attention software startup team
Cleaned Transcription: preprint article published th euromicro conference software engineering advanced application seaa final authenticated version available online httpsdoiorgseaahttpsdoiorgseaa article title business model canvas pay attention software startup team author kaikristian kemell atte elonen mari suoranta anh nguyenduc juan garbajosa rafael chanin jorge melegati usman rafiq abdullah aldaeej nana assyne afonso sale sami hyrynsalmi juhani riski henry edison pekka abrahamsson year please cite original version citing article k k kemell et al business model canvas pay attention software startup team th euromicro conference software engineering advanced application seaa portoroz slovenia pp doi seaa business model canvas pay attention software startup team kaikristian kemell atte elonen mari suoranta anh nguyenduc juan garbajosa rafael chanin jorge melegati usman rafiq abdullah aldaeej nana assyne afonso sale sami hyrynsalmi juhani risku henry edison pekka abrahamsson faculty information technology university jyvaskyla jyvaskyla finland school business economics university jyvaskyla jyvaskyla finland department business university southeast norway norway universidad politecnica de madrid madrid spain school technology pucrs porto alegre brazil faculty computer science free university bozenbolzano bolzano italy x department information system university maryland baltimore country baltimore united state department software engineering lut university lahti finland lero nui galway galway ireland abstract business model canvas bmc tool widely used describe startup business model despite various business aspect described bmc pay little emphasis teamrelated factor importance teamrelated factor software development acknowledged widely literature extensively studied importance team software startup also known literature among practitioner paper propose potential change bmc tool better reflect importance team especially software startup environment based literature review identify various component related team support empirical data mean qualitative case study five startup business model canvas software startup team success factor introduction business model play pivotal role earlystage startup guiding codevelopment software product customer business model canvas bmc prevalent visual modelling tool used capture business model organization consists nine nonoverlapping element knowledge represent business done allows company model current desired future business model using bmc organization identify necessary resource activity capturing business value although widely studied information system research bmc explored software engineering se moreover despite popularity field research empirically analyze bmcs effectiveness suitability software startup context scarce exception study ghezzi presented lean startup approach digital startup among approach bmc widely used practitioner recognized value outlining important aspect business idea team considered key aspect startup existing startup literature highlighted various antipatterns risk revolve around team lacking capability example notable problem earlystage startup however bmc team point focus considered simply one manyresources required deliver value proposition course reasonable argue human resource prominent certain business model however startup human capital important resource provide starting point including team strongly bmc related tool study software startup team paper conduct qualitative multiple case study software startup focusing team data case collected semistructured interview research question paper formulated follows rq team perspective incorporated business model canvas ii theoretical background section first discus bmc discus importance team software startup software development second subsection business model canvas osterwalder et al define business model something describes rationale organization creates delivers capture value business model commonly used business management clarify concept osterwalder et al developed ontology describe business model achieve goal author reviewed literature identified nine building block value proposition target customer distribution channel relationship value configuration core competency partner network cost structure revenue model based ontology osterwalder et al developed bmc tool communicate business model commonly used analyse describe design business model idea behind bmc create shared language would allow organization entrepreneur describe adjust business model create strategic option team potential gap software development traditionally carried team varying hierarchy level authority context team seldom communicate may lead inconsistency project level agile team differ significantly traditional software development team often seen selforganizing general core software development startup agile method often used conjunction lean startup method increase likelihood success though reason assume aforementioned success factor learning communication le important software startup type software organization key issue typically highlighted term team software startup lack capability based existing literature identify component related team considered affect success startup murozbullon et al link startup success team noting since startup seldom financial resource leverage resource bound team capability especially earlystage software startup right capability initial team pivotal would first component resource relation teamrelated resource murozbullon et al also discus heterogeneity note team heterogeneous capability likely generate positive outcome closely related resource importance personal network highlighted context startup well consider wayofworking third component aside specific method practice context se refers working culture example giardino et al underline importance reactiveness adjusting changing market situation emergence new technology searching business model term method hand software startup work largely either ad hoc using differing agile method practice effect success verified finally karhatsu et al linked team success selfguidance team autonomy ie selforganization team exhibited high degree selforganization likely achieve positive outcome thus identify least four possible component related team network human resource capability way working selforganizing empirical portion study discussed next seek validate list component see whether additional component arise data iii study design data study collected startup laboratory university jyvaskyla startup laboratory research unit teach study software startup also provides incubator service earlystage software startup specifically laboratory organizes coursebased earlystage software startup incubation five startup studied one startup ultimately educational ie team came consider idea unviable incubation one startup went become business time discontinued later three startup still exist form collected data using two source first conducted semistructured interview team member startup specifically interviewed startup team total respondent interview recorded record transcribed analysis done using transcript interview done either facetoface via skype english interview question split five category first respondent asked professional background background term entrepreneur startup entrepreneurship general secondly asked question related startup role business idea founded whether pivot thirdly respondent asked question focusing team many member team role included team fourthly respondent asked question related business model startup well area business model canvas key partner unique value proposition finally respondent asked question related success startup success refers receiving external funding plan continue startup term analysis emphasis placed difference similarity startup form cross case analysis thematic analysis inspired approach first utilized make sense data systematic manner iv result section split subsection according component described section iic presenting result highlight summarizing finding form primary empirical conclusion pecs discus following section interview citation presented asis spoken nonnative english speaker moreover noted analysis based individual citation alone cross comparison case component network multiple occasion respondent discussed importance personal network given especially earlystage startup operate scarce financial resource personal network leverage various purpose considered highly important even though operating within startup laboratory gave team contact leverage association one team also highlighted importance external network course top cake team member x team member x treasure provided u much contact boosted u think one reason successfulinterview network used startup respondent find required human resource ranging new team member advisor mentor perceived importance networking varied team recurring theme response respondent lack capability within team perceived lack capability within team largely directly associated limited personal network respondent gather data could used objectively validate success factor context team considered networking success factor vice versa team considered lack extensive personal network shortcoming affected chance succeed negatively pec professional network play vital role gathering necessary technical competence software startup early stage component resource discussing resource four five startup team cited team key resource respondent felt team primary selling point opposed product would say another team member experienced entrepreneur startup tend inexperienced person actual experience make startup somehow unique point investor well interview relation network theme discussed previous subsection human resource also considered key resource absence lacking capability issue discussed many respondent lacking time due responsibility another recurring topic interview many respondent student parttime fulltime balancing startup activity responsibility especially true revenue investor case team member either study work summarize team considered important resource startup even idea wanted sell felt important right people carry idea pec capability startup team crucial resource earlystage startup necessary team capability early stage startup include business development knowledge previous business experience key technical resource observation related pec network success factor earlystage startup however team member extensive personal network leverage even would hardly negative situation either arguably rather two pecs combined result observation grounded extant literature discus next section pec heterogeneous team capabilitywise success factor earlystage startup component way working startup established agreedupon way working scarcely followed existing method working way working startup considered iterative process varied task adjusted needed rather preplanned method startup team member clear role assigned case startup lacked resource term capability enough team member specializing different task simply worked whatever task required work case role team member changed based required time dont know specific role worked well team managed task prototype connection people anything dont know specific role would say asking respondent replying yeah like every time kind work came wouldnt like better better didnt really think like interview way working respondent startup worked ad hoc adjusting situation hand team follow clear methodology seemed work iteratively adjusting way working well idea based context pec earlystage startup work largely ad hoc available human type resource defines team way working rather founder will component selforganizing given startup respondent consisted small team member decisionmaking generally carried entire team everyone team would say nontaskspecific decision made felt like making decision together second cofounder interview selforganization always considered positive factor team startup selforganizing choice rather made decision one made earlystage startup arguably external pressure decisionmaking mostly come play external funding acquired pec earlystage software startup often forced selforganizing team usually member external funding v discussion overall finding served validate research framework devised based extant literature section iii importance team extent acknowledged extant literature finding highlight novelty finding stem argument focus software startup team first rather idea first also case context business model canvas pecs support notion network important software startup present extant literature team important resource startup pec reinforces idea described munozbullon et al heterogeneous team likely create positive outcome data support pec confirms notion paternoster et al argued software startup either use various agile method practice simply operate ad hoc especially earlystage software startup seem lean towards working ad hoc likely development team grows developer come board team also begin utilize tangible method practice though data help u ascertain assumption selforganization considered success factor agile team however stated pec startup team ultimately work agile manner making finding directly comparable existing literature indeed startup team study selforganizing conscious choice rather selforganizing primary limitation study stem qualitative case study method argued eisenhardt however suitable approach novel area research well gather indepth data general multiple case approach reduces threat validity stemming approach moreover finding ultimately served validate existing research part thus backed extant study vi conclusion paper studied software startup team point view businessmodel canvas done interviewing eight respondent five earlystage software startup goal study understand bmc could tailored better suit earlystage software startup one prominent user group tool existing literature anecdotal practitioner wisdom highlight importance team software startup tool place little emphasis team mostly filed key resource category tool never directly mentioned description category based finding suggest canvas least place emphasis team existing key resource category specifically component emphasize importance team capability carry idea startup alternatively team could even category bmc receive enough emphasis subcategory existing category given importance software startup regarding future study advocate study software startup team one avenue author intend pursue focus developing exploring role team business model suggesting canvas could improved cover aspect afterwards new canvas could evaluated empirically startup team might important resource software startup knowledgeintensive field study suggests team capability also interest venture capitalist therefore separate canvas modelling tool focus team specifically could interest communication different stakeholder interest startup acknowledgement project received funding european union horizon research innovation programme marie sklodowskacurie grant agreement financial support science foundation ireland grant rc reference j bosch h h olsson j bjork j llungblad early stage software startup development model framework operationalizing least principle software startup lean enterprise software system springer berlin heidelberg c cooper f j gimenogascon c woo initial human financial capital predictor new venture performance journal business venturing pp k eisenhardt building theory case study research academy management review pp c giardino n patemoster unterkalmsteiner gorschek p abrahamsson software development startup company greenfield startup model ieee transaction software engineering pp c giardino unterkalmsteiner n patemoster gorschek p abrahamsson know software development startup ieee software pp ghezzi digital startup adoption implementation lean startup approach effectuation bricolage opportunity creation practice technological forecasting social change vol august pp grazioit f fagerholm x wang p abrahamsson happens software developer unhappy journal system software pp r hoda j noble marshall using grounded theory study human aspect software engineering human aspect software engineering acm h karhatsu ikonen p kettunen f fagerholm p abrahamsson building block selforganizing software development team framework model empirical pilot study proceeding nd international conference software technology engieneering icste f keane k comrican j n sheehan comparing entrepreneur manager represent element business model canvas journal business venturing insight pp klang walnofer f hackin business model paradox systematic review exploration antecedent international journal management review pp e lumona examining business model softwareasaservice company phd dissertation university jynskyla finland f mufozbullon j sanchezbueno vossaz startup team contribution new firm creation role founding team experience entrepreneurship regional development pp osterwalder pigneur clark business model generation handbook visionary game changer challenger hoboken nj wiley osterwalder pigneur c l tucci clarifying business model origin present future concept communication association information system vol july n patemoster c giardino unterkalmsteiner gorschek p abrahamsson software development startup company systematic mapping study information software technology pp p seppanen p liuktunen k olivo little big team acquiring human capital software startup proceeding th international conference productfocused software process improvement profes innsbruck austria november december p seppanen yes cant building capable initial team software startup fundamental software startup pp springer cham j e tomayko hazzan human aspect software engineering firewall medium research agenda einformatica software engineering journal pp title using guild foster internal startup large organization case study transcription using guild foster internal startup large organization case study tor sporsem sintef digital trondheim norway anastasiia tkalich sintef digital trondheim norway nil brede sintef digital trondheim norway mae sintef digital trondheim norway marius mikalsen sintef digital trondheim norway nina rygh dnv hovik norway abstract software product innovation large organization fundamentally challenging restrained freedom flexibility conduct experiment response large agile company form internal startup initiate employment innovation inspired lean startup case study investigates community practice support five internal startup developing new software product within large organization observed six community practice meeting two workshop conducted ten semistructured interview course year finding show community practice called innovation guild allowed internal startup help collectively solving problem creating shared practice sharing knowledge study confirms benefit documented earlier research cop also hold true context software product innovation large organization henceforth suggest similar innovation guild described paper support large company innovation race new software product keywordssoftware product innovation community practice cop guild employeedriven innovation large organization lean startup maritime sector introduction software product innovation challenging large organization often lack freedom experiment established routine limit flexibility therefore need find strategy foster innovation one way establish parallel organizational structure like innovation guild support employee innovating parallel structure perform function regular organization illsuited perform well example parallel structure include quality circle community practice cop although study indicate parallel structure boost innovation role software product innovation wellexamined large organization currently trying lean startup approach give internal startup freedom create new software product experiment customer much like standalone startup innovation framework corporate startup design sprint google fedex day time atlasian increasingly gaining attention way giving guideline standardizing innovation process help organization track support software product innovation simultaneously framework like state practice tool internal startup leverage drive innovation however internal startup left explore practice dig needed knowledge shed light topic recognizing innovation large agile company may particularly challenging ask following research question large organization use cop support internal startup software product innovation answer report case study software product innovation dnv maritime cop based spotify call guild successfully applied facilitate innovation process inspired lean startup related work parallel organizational structure community practice cop commonly applied within softwareintensive company support employee problemsolving knowledge worker community practice group people share concern set problem passion topic deepen knowledge expertise area interacting ongoing basis cop take different function within organization evolve time organization cop provide arena problem solving drive strategic work share best practice onboard newcomer develop professional skill start new line business individual provide help overcoming challenge enabling contributing improve professional reputation provid professional identity essential opinion fun case dnv experimented cop support employeedriven innovation without sufficient support employeedriven innovation fail employee constantly need improve skill share knowledge coordinate across organization succeed empirical study cop software engineering far paasivaara lassenius summarized recently research use cop spotify known guild emerged study identified four archetype cop book club focus learning instead better working method discussed decision rarely made open source society focus membersowned component maintaining improving finding strategy support line focus onboarding providing answer technical issue facilitating solution discussion core expert guide lessexperienced employee standardizing committee align practice across organization creating artifact like toolset recommendation standard community practice wellresearched parallel structure however paasivaara lassenius argue researcher need study cop new context understand concept study answer call examine cop context software product innovation understand cop support organization parallel structure dnvs case need present additional literature innovation software product innovation defined creation introduction novel software product market lean startup popular approach software product innovation software developed validated continuous experiment customer minimize development cost increase customer satisfaction argued application lean startup principle eg buildmeasurelearn validated learning increase speed product development improves productmarket fit also face challenge large organization large company make use lean startup approach large organization foster internal startup encouraging new corporate effort environment enter new market explore new business strategy one suggested solution corporate startup offer guideline software product innovation existing organizational environment innovation framework like lean startup corporate startup based employee participation people pitch idea one highest potential prioritized case description research approach case maritime division dnv large worldwide provider businesstobusiness classification certification verification risk management training technical advisory service dnv set standard ship offshore structure vessel international water must comply known class rule rule comprise safety reliability environmental requirement dnv operating globally considers software product crucial offering value worldwide customer hence software product innovation part company strategy shift towards digital product service employee headquarters hamburg dnv maritime using agile method develop software since company established innovation program based stagegate innovation framework named corporate startup employee invited pitch idea new software product created internal startup develop internal startup participated cop called innovation guild support innovative work focal point study chose case study closely followed five internal startup june march collected data different way first conducted seven interview asking internal startup work attitude towards guild meeting two interviewed twice three interview manager support internal startup interview recorded transcribed page text second collected observation guild meeting workshop recording taking note third used documentation innovation framework strategic document status report email table summarize gathered data data analysis performed three step first textual data entered qualitative data analysis tool nvivo two researcher coded data inductively mean phenomenon concept rise textual data make themescategories subsequently compared category existing literature constructed code separately followed comparison discussion ending total code one example code guild meeting helped establishing contact others competence needed arranged code theme eg cross functional cooperation contribute positively internal startup include examplecode last quality check presented finding back informant comment duly noted cleared small misconception theme grouped according impact software product innovation issue addressed supported internal startup presented table result dnv created launched new product innovation framework mentioned previously facilitate software product innovation framework based stagegate model described corporate startup guided internal startup six stage table ideation customer insight maturity sustainin product idea suggested employee became idea owner responsible internal startup fulfill gate criterion proceed one stage another eg present evidence customer problem customer intent group business domain expert venture board evaluated whether idea owner evidence sufficient fulfill criterion progression operational line manager decided amount worktime idea owner could take original job work internal startup varying week week usually originally operative specialist idea owner unexperienced entrepreneur soon became evident internal startup faced common challenge could draw others knowledge overcome together innovation program manager decided form cop called innovation guild share knowledge find common solution startup shared problem besides
Original Title: Business Model Canvas Should Pay More Attention to the Software Startup
  Team
Original Transcription: This is a pre-print of an article published in 2020 46th Euromicro Conference on Software Engineering and Advanced Applications (SEAA). The final authenticated version is available online at: [https://doi.org/10.1109/SEAA51224.2020.00063](https://doi.org/10.1109/SEAA51224.2020.00063)

**Article Title:** Business Model Canvas Should Pay More Attention to the Software Startup Team

**Authors:** Kai-Kristian Kemell, Atte Elonen, Mari Suoranta, Anh Nguyen-Duc, Juan Garbajosa, Rafael Chanin, Jorge Melegati, Usman Rafiq, Abdullah Aldaeej, Nana Assyne, Afonso Sales, Sami Hyrynsalmi, Juhani Riski, Henry Edison, Pekka Abrahamsson

**Year:** 2020

**Please cite the original version when citing this article:** K. -K. Kemell et al., "Business Model Canvas Should Pay More Attention to the Software Startup Team," 2020 46th Euromicro Conference on Software Engineering and Advanced Applications (SEAA), Portoroz, Slovenia, 2020, pp. 342-345, doi: 10.1109/SEAA51224.2020.00063.

# Business Model Canvas Should Pay More Attention to the Software Startup Team

Kai-Kristian Kemell1, Atte Elonen1, Mari Suoranta2, Anh Nguyen-Duc3, Juan Garbajosa4, Rafael Chanin2,

Jorge Melegati2, Usman Rafiq2, Abdullah Aldaeej11, Nana Assyne1, Afonso Sales2,

Sami Hyrynsalmi2, Juhani Risku1, Henry Edison33, Pekka Abrahamsson1

1Faculty of Information Technology, University of Jyvaskyla, Jyvaskyla, Finland,

0000-0002-0225-4560, 0000-0002-0587-4431, 0000-0003-0469-6642, 0000-0002-4360-2226
2School of Business and Economics, University of

Jyvaskyla, Jyvaskyla, Finland, 0000-0002-3849-4902
3Department of Business and IT, University of Southeast Norway, Be, Norway, 0000-0002-7063-9200

4Universidad Politecnica de Madrid, Madrid, Spain, 0000-0003-0161-3485

5School of Technology, PUCRS, Porto Alegre, Brazil

0000-0002-6293-7419, 0000-0001-6962-3706

6Faculty of Computer Science, Free University of Bozen-Bolzano, Bolzano, Italy,

0000-0003-1303-4173, 0000-0003-3198-851X

1Department of Information Systems, University of Maryland Baltimore Country, Baltimore, United States

0000-0002-6405-1750
2Department of Software Engineering, LUT University, Lahti, Finland, 0000-0002-5073-3750

3Lero, NUI Galway, Galway, Ireland, 0000-0002-9494-8059

###### Abstract

Business Model Canvas (BMC) is a tool widely used to describe startup business models. Despite the various business aspects described, BMC pays a little emphasis on team-related factors. The importance of team-related factors in software development has been acknowledged widely in literature. While not as extensively studied, the importance of teams in software startups is also known in both literature and among practitioners. In this paper, we propose potential changes to BMC to have the tool better reflect the importance of the team, especially in a software startup environment. Based on a literature review, we identify various components related to the team, which we then further support with empirical data. We do so by means of a qualitative case study of five startups.

_Business Model Canvas, Software Startup, Team, Success Factor_

## I Introduction

Business Models play a pivotal role in early-stage startups, guiding the co-development of software products and customers. The Business Model Canvas (BMC) [14] is a prevalent visual modelling tool used to capture the business model of an organization. It consists of nine non-overlapping elements of knowledge which represent how business is done [10]. It allows a company to model its current or desired future business models. By using BMC, an organization can identify necessary resources and activities for capturing business value.

Although widely studied in information systems research [12], BMC has not been explored in Software Engineering (SE). Moreover, despite its popularity out on the field, research to empirically analyze BMC's effectiveness or suitability in software startup contexts is scarce. An exception is a study by Ghezzi, which presented Lean Startup Approaches in digital startups [6]. Among these approaches, BMC was the most widely used and practitioners recognized their value in outlining important aspects of business ideas.

The team is considered a key aspect of any startup. Existing startup literature has highlighted various anti-patterns and risks that revolve around the team. Lacking capabilities, for example, is a notable problem for any early-stage startup [17]. However, in BMC [14], the team is not a point of focus, being considered simply one of the manyresources required to deliver the value proposition. It is of course reasonable to argue that human resources are prominent in certain business models. However, for startups, human capital is the most important resource.

To provide a starting point for including the team more strongly in BMC and other related tools, we study software startup teams in this paper. We conduct a qualitative multiple case study of software startups, focusing on the teams. Data from the cases are collected with semi-structured interviews. The research question of the paper is formulated as follows:

**RQ:** How can the team perspective be incorporated into Business Model Canvas?

## II Theoretical Background

In this section, first, we discuss the BMC. Then, we discuss the importance of teams in software startups and in software development in the second subsection.

### _Business Model Canvas_

Osterwalder et al. [14] define business model as something that "describes the rationale of how an organization creates, delivers and captures value". Business models are a commonly used in both business and management [11]. To clarify the concept, Osterwalder et al. developed an ontology to describe business models [15]. To achieve this goal, the authors reviewed the literature and identified nine building blocks: value proposition, target customer, distribution channel, relationship, value configuration, core competency, partner network, cost structure, and revenue model.

Based on the ontology, Osterwalder et al. [14] developed the BMC as a tool to communicate business models. It is commonly used to analyse, describe and design business models. The idea behind BMC was to create a shared language that would allow organizations and entrepreneurs to describe and adjust business models to create strategic options.

### _Team: The Potential Gap_

Software development is traditionally carried out in teams of varying hierarchy and levels of authority. In this context, teams seldom communicate with each other, which may lead to inconsistency on a project level [19]. Agile teams differ significantly from traditional software development teams [7]. They are often seen as self-organizing, and in general, are at the core of software development [7].

In startups, agile methods are often used in conjunction with the Lean Startup method to increase likelihood of success [1]. Though there is no reason to assume that aforementioned success factors such as learning and communication are less important in software startups than other types of software organizations, a key issue typically highlighted in terms of teams in software startups is the lack of capabilities [18].

Based on existing literature, we can identify components related to the team that are considered to affect success in startups. Muroz-Bullon et al. [13] link startup success with the team, noting that since startups seldom have financial resources to leverage, most of their resources are bound to the team and its capabilities. Especially in early-stage software startups, having the right capabilities in the initial team is pivotal [18]. This would be the first component: resources.

In relation to team-related resources, Muroz-Bullon et al. [13] also discuss heterogeneity. They note that teams with more heterogeneous capabilities were more likely to generate positive outcomes. Closely related to resources, the importance of personal networks has been highlighted in the context of startups as well [3, 11].

We consider Way-of-Working to be the third component. Aside from specific methods or practices in the context of SE, this refers to working culture. For example, Giardino et al. [5] underline the importance of reactiveness in adjusting to changing market situations or the emergence of new technologies while searching for a business model. In terms of methods, on the other hand, software startups work largely either ad hoc or using differing agile methods and practices [16], but their effect on success has not been verified.

Finally, Karhatsu et al. [9] linked team success with self-guidance and team autonomy, i.e. self-organization. Teams that exhibited high degree of self-organization were more likely to achieve positive outcomes [9].

Thus, we identify at least four possible components related to the team: (1) networks, (2) human resources, or capabilities, (3) way of working, (4) self-organizing. In the empirical portion of the study, discussed next, we seek to validate this list of components, and to see whether any additional components arise from the data.

## III Study Design

Data for this study were collected from the Startup Laboratory of University of Jyvaskyla. The Startup Laboratory is a research unit that teaches and studies software startups, but also provides some incubator services for early-stage software startups. Specifically, the laboratory organizes course-based early-stage software startup incubation.

Five startups were studied. One of the startups was ultimately educational only, i.e. the team came to consider the idea unviable during the incubation. One of the startups went on to become a business for some time but was discontinued later. Three of the startups still exist in some form.

We collected data using two sources. First, we conducted semi-structured interviews with some of the team members of some of the startup. Specifically, we interviewed 5 startup teams and in total 8 respondents. All interviews were recorded, the records transcribed, and the analysis done using the transcripts. The interviews were done either Face-to-Face or via Skype, in English.

The interview questions were split into five categories. First, the respondents were asked about their professional background, and their background in terms of entrepreneur or startup entrepreneurship in general. Secondly, they were asked questions related to their startup and their role in it, such as its business idea, when it was founded, and whether there had been any pivots. Thirdly, the respondents were asked questions focusing on the team, such as how many members the team had, what their roles were, and why they were included into the team. Fourthly, the respondents were asked questions related to the business model of the startup, as well as areas of the business model canvas such as key partners and unique value proposition. Finally, the respondents were asked questions related to the success of the startup, where success refers to receiving external funding and their plans to continue with the startup.

In terms of analysis, emphasis was placed on differences and similarities of the startups in the form of a cross case analysis. A thematic analysis inspired approach was first utilized to make sense of the data in a systematic manner.

## IV Results

This section is split into subsections according to the components described in section II.C. In presenting our results, we highlight summarizing findings in the form of Primary Empirical Conclusions (PECs) which we will then discuss further in the following section. The interview citations are presented as-is, as spoken by non-native English speakers. Moreover, it should be noted that the analysis is not based on these individual citations alone but a cross comparison of the cases.

### _Component 1: Network_

On multiple occasions, the respondents discussed the importance of personal networks. Given that especially early-stage startups operate with scarce financial resources, having personal networks to leverage for various purposes was considered highly important. Even though operating within the Startup Laboratory gave the teams some contacts to leverage by association, all but one team also highlighted the importance of their own, external networks.

_"Then of course at the top of the cake we have team member X, and team member X is our treasure. He has provided us so much contacts and he has boosted us into what we are doing. And I think he is one of the reasons why we can be successful."_(Interview)

Networks were used by the startups of the respondents to find required human resources, ranging from new team members to advisors or mentors. While the perceived importance of networking varied by team, a recurring theme in the responses of the respondents was a lack of capabilities within the team. A perceived lack of capabilities within the team was largely directly associated with limited personal networks by the respondents themselves.

While we did not gather any data that could be used to objectively validate success factors in this context, the teams themselves considered networking to have been a success factor for them. Vice versa, some teams considered their lack of extensive personal networks to be a shortcoming that affected their chances to succeed negatively.

**PEC1:** Professional networks play a vital role for gathering necessary technical competence for software startups in their early stages.

### _Component 2: Resources_

In discussing resources, four out of five of the startup teams cited the team as their key resource. The respondents felt that their team was their primary selling point as opposed to their product itself.

_"I would say that [another team member] is an experienced entrepreneur, most startups tend to be inexperienced so having a person with actual experience does make the startup somehow unique. From the point of investors as well."_ (Interview)

In relation to the network theme discussed in the previous subsection, human resources were also considered key resources in their absence. Lacking capabilities were an issue discussed by many of the respondents.

Lacking time due to other responsibilities was another recurring topic in the interviews. As many of the respondents were students, part-time or full-time, they were balancing their startup activities with other responsibilities. This was especially true for those that had no revenue or investors. In those cases, the team members had to either study or work.

To summarize, the team was considered the most important resource the startups had. Even if the ideas were what they wanted to sell, they felt that it was important that they were the right people to carry out that idea.

**PEC2:** The capabilities of the startup team itself are the most crucial resources for an early-stage startup. The necessary team capabilities of an early stage startups include business development knowledge, previous business experience, and key technical resources.

This observation is related to the PEC1 that networks are a success factor for early-stage startups. However, not all team members have to have extensive personal networks to leverage, even if it would hardly be a negative situation either, arguably. Rather, these two PECs combined result in a further observation, which is grounded in extant literature, as we discuss in the next section:

**PEC3:** A heterogeneous team, capability-wise, is a success factor for early-stage startups.

### _Component 3: Way of Working_

While all the startups had established some agreed-upon way of working, they scarcely followed any existing methods for working. The ways of working in the startups were considered an iterative process that varied between tasks and was adjusted as needed, rather than a pre-planned method.

In some of the startups, the team members did not have clear roles assigned to them at all. This was the case in the startups that lacked the most resources in terms of capabilities. As they did not have enough team members specializing in different tasks, they simply worked on whatever tasks they had that required work. In these cases, the roles of the team members changed based on what was required at the time.

_"I don't know if we had any specific roles. We worked well as a team and just managed the tasks we had, prototypes or connections or people anything we had. I don't know. Did we have any specific roles? What would you say? [Asking other respondent]"_

_"[Replying] Yeah, we were not like that every time some kind of work came up, it wouldn't be like you are better at doing this and I am better in this, we didn't really think like that..."_ (Interview)

The ways of working of the respondents' startups worked ad hoc, adjusting to the situation at hand. The teams did not follow any clear methodologies and seemed to work iteratively, adjusting their way of working as well as their idea based on the context that they were in.

**PEC4:** Early-stage startups work largely ad hoc and the available human and other types of resources defines the team's way of working, rather than the founders' own wills.

### _Component 4: Self-Organizing_

Given that the startups of the respondents consisted of small teams of 1 to 5 members, decision-making was generally carried out between the entire team. Everyone on the team would have their say on any non-task-specific decision being made, should they have felt like doing so.

_"We have been making those decisions together with the second co-founder"_ (Interview)

Self-organization was not always considered a positive factor by the teams. Some startups were not self-organizing by choice, but rather, because they had to be. If they made no decisions themselves, no one made any. For an early-stage startup, arguably, external pressure in decision-making mostly comes into play once, or if, external funding is acquired.

**PEC5:** Early-stage software startups are often forced to be self-organizing, as the team usually only has a few members and no external funding.

## V Discussion

Overall, our findings served to validate the research framework devised based on extant literature in section III. While the importance of the team is to some extent acknowledged in extant literature [2][20], our findings further highlight this. The novelty of our findings stems from the argument that the focus on software startups should be on team first rather than idea first. This is also the case in the context of the Business Model Canvas.

PECs1 and 2 supports the notion that networks are important for software startups present in extant literature, and that the team is the most important resource of a startup [4][13]. PEC3 reinforces the idea described by Munoz-Bullon et al. [13] that the more heterogeneous the team is, the more likely it is to create positive outcomes. Our data supports it.

PEC4 confirms the notion of Paternoster et al. [16] who argued that software startups either use various agile methods and practices or simply operate ad hoc. Especially early-stage software startups seem to lean towards working ad hoc. It is likely that as the development team grows and more developers come on board, the team also begins to utilize some tangible methods or practices, though our data does not help us ascertain this assumption.

Self-organization is considered a success factor in agile teams [9]. However, as stated in PEC4, these startup teams ultimately did not work in an agile manner, making our findings not directly comparable to those in existing literature. Indeed, the startup teams in this study were not self-organizing by a conscious choice. Rather, they were self-organizing because they had to be.

The primary limitations of this study stem from the qualitative case study method. As argued by Eisenhardt [3], however, it is a suitable approach for novel areas of research, as well as to gather more in-depth data in general. The multiple case approach further reduces the threat to validity stemming from this approach. Moreover, our findings ultimately served to validate existing research for the most part, and thus are backed by extant studies.

## VI Conclusions

In this paper, we have studied software startup teams from the point of view of the BusinessModel Canvas. We have done so by interviewing eight respondents from five early-stage software startups. The goal of this study was to understand how BMC could be tailored to better suit early-stage software startups, which are one prominent user group of the tool. While existing literature and anecdotal practitioner wisdom highlight the importance of teams in software startups, the tool places little emphasis on the team, which is mostly filed under the 'key resources' category of the tool and never directly mentioned in the description of the category.

Based on our findings, we suggest that the canvas should at least place more emphasis on the team under the existing key resources category. Specifically, the component should emphasize the importance of having a team with the capabilities to carry out the idea of the startup. Alternatively, the team could even be a category of its own in BMC, as it does not receive enough emphasis being a subcategory of an existing category given its importance for software startups.

Regarding future studies, we advocate for more studies on software startup teams. One avenue that the authors themselves intend to pursue is to focus on developing and exploring the role of the team in business models by suggesting how the canvas could be improved to cover this aspect. Afterwards, the new canvas could be evaluated empirically by startups. The team might be the most important resource for a software startup in this knowledge-intensive field. As this study suggests, the team and its capabilities should also be of interest venture capitalists. Therefore, a separate canvas or modelling tool to focus on the team specifically could be of interest for communication between different stakeholders' interest in the startup.

## Acknowledgement

This project has received funding from the European Union's Horizon 2020 research and innovation programme under the Marie Sklodowska-Curie grant agreement No 754489 and with the financial support of the Science Foundation Ireland grant 13/RC/2094.

## References

* [1] J. Bosch, H. H. Olsson, J. Bjork, and J. Llungblad, "The Early Stage Software Startup Development Model: a Framework for Operationalizing Least Principles in Software Startups," In Lean Enterprise Software and Systems, 1-15. Springer, Berlin, Heidelberg 2013.
* [2] A. C. Cooper, F. J. Gimeno-Gascon, C. Y. Woo, "Initial Human and Financial Capital as Predictors of New Venture Performance," Journal of Business Venturing, 9(5), pp. 371-395, 1994.
* [3] K. M. Eisenhardt, "Building theories from case study research. Academy of Management Review," 14(4), pp. 532-550, 1989.
* [4] C. Giardino, N. Patemoster, M. Unterkalmsteiner, T. Gorschek, and P. Abrahamsson, "Software Development in Startup Companies: The Greenfield Startup Model," IEEE Transactions on Software Engineering, 42(6), pp. 585-604, 2016.
* [5] C. Giardino, M. Unterkalmsteiner, N. Patemoster, T. Gorschek, and P. Abrahamsson, "What Do We Know about Software Development in Startups?," IEEE Software, 31(5), pp. 28-32, 2014.
* [6] A. Ghezzi, "Digital startups and the adoption and implementation of Lean Startup Approaches: Effectuation," Bricolage and Opportunity Creation in practice," Technological Forecasting and Social Change, vol. 146, no. August, pp. 945-960, 2019.
* [7] D. Grazioit, F. Fagerholm, X. Wang, and P. Abrahamsson, "What happens when software developers are (un)happy," Journal of Systems and Software, 140, pp. 32-47, 2018.
* [8] R. Hoda, J. Noble, and S. Marshall, "Using Grounded Theory to Study the Human Aspects of Software Engineering," In Human Aspects of Software Engineering, 5, ACM, 2010.
* [9] H. Karhatsu, M. Ikonen, P. Kettunen, F. Fagerholm, and P. Abrahamsson, "Building Blocks for Self-Organizing Software Development Teams a Framework Model and Empirical Pilot Study," In Proceedings of the 2nd International Conference on Software Technology and En-gieneering (ICSTE), 2010.
* [10] S. F. Keane, K. T. Comrican, and J. N. Sheehan, "Comparing How Entrepreneurs and Managers Represent the Elements of the Business Model Canvas," Journal of Business Venturing Insights, 9, pp. 65-74, 2018
* [11] D. Klang, M. Walnofer, and F. Hackin, "The Business Model Paradox: A Systematic Review and Exploration of Antecedents," International Journal of Management Reviews, 16(4), pp. 454-478, 2014.
* [12] E. Lumona, "Examining Business Models of Software-as-a-Service Companies: PhD dissertation. University of Jynskyla, Finland. 2013.
* [13] F. Mufoz-Bullon, M. J. Sanchez-Bueno, and A. Vos-Saz, "Startup Team Contributions and New Firm Creation: the Role of Founding Team Experience," Entrepreneurship & Regional Development, 27(1-2), pp. 80-105, 2015.
* [14] A. Osterwalder, Y. Pigneur, and T. Clark, "Business Model Generation: A Handbook for Visionaries, Game Changers, and Challengers," Hoboken, NJ: Wiley, 2010.
* [15] A. Osterwalder, Y. Pigneur, and C. L. Tucci, "Clarifying Business Models: Origins, Present, and Future of the Concept," Communications of the Association for Information Systems, vol. 16, no. July, 2005.
* [16] N. Patemoster, C. Giardino, M. Unterkalmsteiner, T. Gorschek, and P. Abrahamsson, "Software development in startup companies: A systematic mapping study," Information and Software Technology, 56(10), pp. 1200-1218, 2014.
* [17] P. Seppanen, P., Liuktunen, K., and Olivo, M.: Little Big Team: Acquiring Human Capital in Software Startups. In Proceedings of the 18th International Conference on Product-Focused Software Process Improvement, PROFES 2017, Innsbruck, Austria, November 29-December 1, 280-296 (2017).
* [18] P. Seppanen, "Yes, We Can't Building a Capable Initial Team for a Software Startup," In Fundamentals of Software Startups, pp. 45-59. Springer, Cham, 2020.
* [19] J. E. Tomayko, and O. Hazzan, "Human Aspects of Software Engineering," Firewall Media, 2004.
* A Research Agenda," E-Informatica Software Engineering Journal, pp. 89-124, 2016.

Title: Using Guilds to Foster Internal Startups in Large Organizations: A case
  study
Transcription: # Using Guilds to Foster Internal Startups in Large Organizations: A case study

Tor Sporsem

1SINTEF Digital, 7034 Trondheim, Norway

1

Anastasiia Tkalich

1SINTEF Digital, 7034 Trondheim, Norway

1

Nils Brede

1SINTEF Digital, 7034 Trondheim, Norway

1

Mae

1SINTEF Digital, 7034 Trondheim, Norway

1

Marius Mikalsen

1SINTEF Digital, 7034 Trondheim, Norway

1

Nina Rygh

2DNV, 1361 Hovik, Norway

###### Abstract

Software product innovation in large organizations is fundamentally challenging because of restrained freedom and flexibility to conduct experiments. As a response, large agile companies form internal startups to initiate employment innovation, inspired by Lean startup. This case study investigates how communities of practice support five internal startups in developing new software products within a large organization. We observed six communities of practice meetings, two workshops and conducted ten semi-structured interviews over the course of a year. Our findings show that a community of practice, called the Innovation guild, allowed internal startups to help each other by collectively solving problems, creating shared practices, and sharing knowledge. This study confirms that benefits documented in earlier research into CoPs also hold true in the context of software product innovation in large organizations. Henceforth, we suggest that similar innovation guilds, as described in this paper, can support large companies in the innovation race for new software products.

Keywords:Software Product Innovation, Communities of Practice (CoP), Guilds, Employee-driven innovation, Large Organizations, Lean Startup, Maritime sector

## 1 Introduction

Software product innovation is challenging in large organizations because they often lack the freedom to experiment and have established routines that limit flexibility [4]. Therefore, they need to find strategies to foster innovation [10]. One way is to establish a parallel organizational structure - like an Innovation Guild - to support employees innovating. Parallel structures perform functions that the regular organization does not or is ill-suited to perform well [13]. Some examples of parallel structures include quality circles [8] and _Communities of Practices_ (CoP) [18]. Although some studies indicate that such parallel structures can boost innovation [16], their role in _software product innovation_ is not well-examined.

Large organizations are currently trying Lean startup approaches to give internal startups the freedom to create new software products and experiment with customers, much like a standalone startup [4]. Innovation frameworks such as _The corporate startup_[17], design sprints in Google [21], "FedEx Day" and "20% Time" in Atlasian[10] are increasingly gaining attention as a way of giving guidelines and standardizing innovation processes to help organizations track and support software product innovation. Simultaneously, frameworks like these do state which practices or tools internal startups should leverage to drive innovation. However, internal startups are left to explore such practices and dig up needed knowledge themselves.

To shed light on this topic and recognizing that innovation in large agile companies may be particularly challenging, we ask the following research question: _How does a large organization use CoP to support internal startups in software product innovation?_ To answer, we report on a case study of software product innovation at DNV Maritime, where a CoP - based on what Spotify call "Guilds" - was successfully applied to facilitate innovation processes inspired by Lean startup.

## 2 Related work

Parallel organizational structures, such as Communities of Practice (CoP), are commonly applied within software-intensive companies to support employees as problem-solving knowledge workers [13]. A community of practice is a _group of people who share a concern, a set of problems, or a passion about a topic, and who deepen their knowledge and expertise in this area by interacting on an ongoing basis_[18]. CoPs can take on different functions within an organization and evolve over time [11]. To an organization, a CoP can provide an arena for problem solving, drive strategic work, share best practice, onboard newcomers, develop professional skills, and start new lines of business [19]. To individuals, it can provide help in overcoming challenges, enabling contributing to your, improve professional reputation, provid a professional identity, and (most essential in our opinion) having fun.

In our case, DNV experimented with a CoP to support their employee-driven innovation. Without sufficient support, employee-driven innovation will fail [1]. Employees constantly need to improve their skills, share knowledge, and coordinate across the organization if they are to succeed.

Empirical studies of CoPs in software engineering are far between. Paasivaara and Lassenius [11] summarized some; [6; 7; 9]. Recently, research on the use of CoPs in Spotify (known as "guilds") have emerged [14]. This study identified four archetypes of CoPs:

* _Book clubs_ focus on "learning instead of doing", where better working methods are discussed, but decisions are rarely made.
* _Open source societies_ focus on members-owned components, maintaining them, improving, and finding strategies for them.
* _Support lines_ focus on onboarding, providing answers to technical issues, and facilitating solutions discussions. Core experts guide less-experienced employees.
* _Standardizing committees_ align practices across the organization by creating artifacts like toolset recommendations and standards.

Communities of practice are well-researched parallel structures. However, Paasivaara and Lassenius [11] argue that researchers need to study CoPs in new contexts to understand the concept further. In this study, we answer this call and examine CoPs in the context of software product innovation.

To understand how CoPs can support organizations as a parallel structure in DNV's case, we need to present some additional literature on innovation. _Software product innovation_ is defined as the creation and introduction of novel software products to the market.

_Lean startup_ is a popular approach to software product innovation where software is developed and validated through continuous experiments with customers to minimize development costs and increase customer satisfaction [12]. It is argued that the application of the Lean startup principles (e.g. _Build-Measure-Learn_ and _validated learning_) increases the speed of product development [5] and improves product-market fit [3], but also faces challenges in large organizations [15].

So, how does a large company make use of Lean startup approaches? Large organizations foster _internal startups_[4] by encouraging new corporate efforts in their own environment to enter new markets and explore new business strategies [3]. One suggested solution is _The corporate startup_[17] which offers guidelines for software product innovation in an existing organizational environment. Innovation frameworks like Lean startup and The corporate startup are based on employee participation. People pitch their ideas, and the ones with the highest potential are prioritized.

## 3 Case description and research approach

Our case is the Maritime division of DNV, a large worldwide provider of business-to-business classification, certification, verification, risk management, training, and technical advisory services. DNV sets standards for ships and offshore structures that vessels in international waters must comply with, known as Class Rules. These rules comprise safety, reliability, and environmental requirements. DNV is operating globally and considers software products crucial for offering value to its worldwide customers. Hence, software product innovation has been part of the company's strategy to shift towards digital products and services. With 3 700 employees and headquarters in Hamburg, DNV Maritime has been using agile methods to develop software since 2008.

In 2018, the company established an innovation program based on the stage-gate innovation framework named The corporate startup [17]. Employees were invited to pitch ideas for new software products and created internal startups to develop them. These internal startups participated in a CoP, called the Innovation Guild, to support their innovative work, which is the focal point of this study.

We chose a case study [20] because we closely followed five internal startups in the between June 2020 and March 2021. We collected data in 3 different ways. First, we conducted seven interviews, asking internal startups how they work and their attitude towards guild meetings (two of them were interviewed twice). Then we did three interviews with managers on how they support the internal startups. Interviews were recorded and transcribed into 61 pages of text. Second, we collected observations from guild meetings and workshops by recording them and taking notes. Third, we used documentation on the innovation framework, such as strategic documents, status reports, and emails. Table 1 summarize our gathered data

Data analysis was performed in three steps. First, textual data was entered into the qualitative data analysis tool NVivo. Two researchers coded the data inductively, which means that phenomenon and concepts rise from the textual data and make up themes/categories. Subsequently, we compared our categories with existing literature. We constructed codes separately followed by a comparison and discussion, ending up with a total of 150 codes. One example of a code: "Guild meetings helped me establishing contact to others with competence I needed." Further, we arranged the codes into 31 themes, e.g., "Cross functional cooperation contribute positively to internal startups" (which include the example-code above). As a last quality check, we presented our findings back to the informants. Comments were duly noted and cleared up small misconceptions.

The themes were grouped according to their impact on software product innovation. Which issue they addressed and how they supported internal startups is presented in table 3.

## 4 Results

DNV created and launched new products through the Innovation framework mentioned previously to facilitate software product innovation. The framework was based on a stage-gate model described in The corporate startup [17] and guided internal startups through six stages (Table 2) from ideation (_Customer insight_) to maturity (_Sustainin_). Each product idea was suggested by an employee who became an _idea owner_ and responsible for their own internal startup. They had to fulfill gate criteria to proceed from one stage to another (e.g., present evidence of the customer problem or customer intent). A group of business and domain experts (_Venture board_) evaluated whether the idea owners' evidence was sufficient to fulfill the criteria and progression. Operational line managers decided what amount of worktime idea owners could take out of their original job to work on the internal startups, varying from week to week - usually between 20-100 %.

Being originally operative specialists, the idea owners were unexperienced in entrepreneur. It soon became evident that all internal startups faced common challenges and could draw on each others' knowledge to overcome them. Together with the innovation program manager, they decided to form a CoP - called _Innovation guild_ - to share knowledge and find common solutions to the startups' shared problems. Besides,

Tuple 34:
Cleaned Title: pagurus eliminating cold startup serverless computing interaction container sharing
Cleaned Transcription: pagurus eliminating cold startup serverless computing interaction container sharing zijun li daggerquan chen daggerminyi guo department computer science engineering shanghai jiao tong university china daggershanghai institute advanced communication data science shanghai jiao tong university china lzjxxsjtueducn chenquan guomycssjtueducn abstract serverless computing provides finegrain resource sharing cloud tenant container function invocation action run individual container already started container user function new container created however long cold startup time container result long response latency action investigation show container user action share software package action requires new container borrow similar warm container action long cold startup eliminated based finding propose pagurus runtime container management system eliminating cold startup serverless computing pagurus comprised interaction container scheduler intraaction container scheduler action interaction container scheduler schedule shared container among action intraaction container scheduler deal management container lifecycle experimental result show pagurus effectively eliminates timeconsuming container cold startup action may start run m pagurus even warm container introduction adopting serverless computing cloud tenant submit function directly without renting virtual machine different specification cloud vendor schedule tenant function automatically high maintainability testability hyperscalers provide serverless computing service amazon lambda google cloud function microsoft azure function alibaba function compute serverless computing perfect internet service unstable query load since tenant charged query execution instead long term renting use terminology apache openwhisk eventdriven serverless computing platform action represents invocation user function whenever action received serverless computing run action using either newlylaunched container running warm container warm container keep serving query warm startup timeout recycled container different action rely various software package container shared warm container action new cold container need started long latency booting container well software environment code initialization restricts performance serverless computing action suffer long container cold startup time observe current serverless computing system may launch many container action instance may launch many container internet service diurnal load pattern low load le peak load peak load also observe idle container action even load action stable warm container idle wasting system resource used action container different action install different software package development microservice architecture action tend use popular common library package instance extracting likely dependency project package popular python package index pypi repository import popular package action tend use similar software package scenario action requires cold container startup able utilize idle container action cold startup turned warm startup endtoend latency greatly reduced three main challenge achieving purpose first challenge load action stable difficult determine whether action safely lend idle container action without affecting qualityofservice qos secondly existing serverless computing system support borrow operation container sharing allowed thirdly multiple renter lender coexist nontrivial design efficient container sharing strategy among action minimizes number cold startup tackle challenge propose pagurus container management system reduces container cold startup adaptive interaction container sharing pagurus container classified lender container executant container renter container executant container used owner action lender container lent action turn renter container pagurus proposes enhanced container component enables container sharing multiple action guarantee security user code action intraaction container scheduler adopted manage executant container renter container borrowed action lender container lent action whole serverless computing system adopts interaction container scheduler schedule container action handle proactive repacking based package similarity action workload main contribution paper follows container enhancement enables sharing enhance container design support runtime package repacking enables container sharing different action design similaritybased container repacking policy container different action install different software package analyze similarity action minimize number package installed container sharing design efficient interaction container sharing mechanism mechanism divide container three type based pagurus manages different way enables efficient interaction container sharing adaptive interaction container sharing pagurus greatly reduces possibility action suffers cold container startup pagurus also able integrated prior work reducing container cold startup time minimize overhead serverless computing case ii background related work background serverless computing container act lightweight virtualization creates multiple isolated userspace instance action serverless platform us container encapsulate execute query figure show way user action scheduled run serverless computing shown figure container must bootedrestoredinitializedinvoked host action action invoked first time alive container action serverless system encapsulates start new container initializes software environment load applicationspecific code run function step make cold startup may take several second container cold startup significantly increase endtoend latency user query especially processing single query often short hundred millisecond internet service deal problem researcher also proposed use criu checkpointrestore userspace technique restores container image checkpoint reduce cold startup time however still incurs long endtoend latency another approach called prewarm startup adopted openwhisk spawn stem cell container already initialized software environment advance though skip container startup user need perform applicationspecific code initialization preloaded library either make image size large cause long startup latency prewarm container container type action alive complete previous invocation new action query type directly executed running container warm startup warm startup eliminates container booting initialization warm container keep serving action achieve better endtoend latency however warm startup always possible warm container may recycled cold startup happens related work already lot prior work reducing container startup latency improve performance serverless computing sand separate different application via container allowing function one application run container different process xcontainer proposed new security paradigm isolating cloudnative container achieve higher throughput catalyzer adopts design utilizes technology criu ondemand recovery hendrickson also proposes openlambda deal long function startup latency locality consideration slacker sock share similar idea container launched generalizing zygote initialization reduce startup latency achieve function isolation unikernels achieve le latency better throughput via bypassing kernel unikernels serverless environment mcgrath proposed reuse container create container introducing queuing scheme worker collecting availability different queue existing work mainly focus seeking lightweight virtualization technology pursue lower overhead reduce container startup time one kind action work try make different action work collaboratively alleviate container cold startup problem furthermore pagurus combined different container technology achieve le cold startup latency iii motivation experimental setup investigation use apache openwhisk local cache representative serverless computing platform functionbench faasprofiler benchmark experiment setup based node cluster node connected gb ethernet switch node experimental cluster use one node perform computing one node generate query execution table show hardware software configuration node use representative serverless computing benchmark suite functionbench faasprofiler used benchmark workload shown table ii fig four possibility start action serverless computing system breakdown endtoend latency endtoend latency processing user query seriously affect user experience make investigation break endtoend latency benchmark serverless computing serverless computing system based container technology cold container startup happens idle container exist user query received scenario system creates new container serve query action cold container startup includes operation like initializing customized execution environment traditionally cold startup overhead includes container startup software environment function initialization applicationspecific code initialization operation may incur significant extra latency figure show percentage time spent cold container startup endtoend latency benchmark observed figure cold startup overhead increase endtoend latency benchmark general container cold startup time relatively stable best case cold container startup still take endtoend latency cdb worst case cold container startup take endtoend latency dd eliminate container cold startup endtoend latency application serverless computing greatly reduced end cloud vendor well recent work focused reducing container startup time discussed section ii even container cold startup time reduced m best case cold startup still take longer time case query directly get warm container m increasing usage highlevel language like python make cold startup even expensive latencysensitive application millisecondlevel latency target internet service m already result poor user experience existence redundant warm container important feature serverless computing elasticity current container startup strategy container started upon query waiting queue recycled soon query certain period eg second openwhisk therefore whenever running container fail catch query waiting queue new container must get started experience cold startup largescale serverless computing platform may coexist large number action different user action redundant warm container envision possible reuse redundant warm container eliminate cold startup end manually schedule container startup process reuse redundant warm container check number container launched qos metric endtoend latency figure report investigation result investigation prof assumption hold fig number container launched required b ensure ile latency target example benchmark vid fig distribution percentage time spent cold container startup action execution endtoend latency representative benchmark taking benchmark vid example figure figure b show number container launched ile endtoend latency query various load openwhisk manual scheduling respectively figure xaxis represents query workload querypersecond qps bar show number warm container corresponding left yaxis line show ile latency corresponding right yaxis observed figure ile latency benchmark show pattern cyclic variation little increase qps saturation point bring new container startup thanks lower overall latency achieved increasing qps result higher overall latency still headroom ile latency qos target possible use fewer container without violating qos requirement exactly manual scheduling shown figure b case bar black safely reduce least one container still achieving ile latency target prof application serverless computing platform warm idle container execution addition figure b also observe idle container usually appears minimum turning point latency represented blue circle figure minimum turning point usually come new container startup deal increasing query waiting queue also find common phenomenon based openwhisk besides vid benchmark also produce similar result hand easily anticipated even idle container case query workload drop suddenly widely witnessed proved real internet service diurnal load pattern definitely bring idle container potentially reuse challenge reusing container ensuring qos based analysis investigation opportunity leverage warm container action eliminate cold container startup action action may require different software package execution environment action container able used another container action container repacked used action repacking operation may take relatively long time extracting package benchmark suite functionbench also find benchmark import panda sklearn commom library like numpy even shared finding indicates different action tend share high proportion package others therefore possible build shared container image allowing several action run without installing extra package even case similarity library different action high use specific designed algorithm build connection however easy task build shared container image still several challenge action able share container container different action pack different software package container action reused action default container reuse brings extra time overhead allow action run action container reused container supposed install extra package inappropriate package installation brings large time overhead negates latency reduction elimination cold container startup security concern interaction container sharing container shared different action isolation weakened security privacy action must ensured interaction container reuse brings extra schedule complexity multiple action active concurrently efficient mechanism proposed manage container lend rent action iv design pagurus tackle challenge propose pagurus runtime container management system eliminating cold container startup interaction container sharing traditional serverless computing system design distributed deployment usually implemented two way one divide node master slave node load balancing realized central controller master node data slave node server node synchronized database shown figure however according previous study network bandwidth server node database usually bottleneck serverless computing masterslave design also unpractical therefore design pagurus using single node management node communicate maintain update local database file mean performance relevant computing power server node figure show design overview pagurus management shared container action interaction container scheduler introduced also responsible repacking container runtime necessary action intraaction container scheduler responsible coordinating three container pool ie executant container pool lender container pool renter container pool whenever container experience cold startup added executant container pool default keep intact provided recognized warm container query requesting container certain period container identified idle moved lender container pool possible crossaction reuse renter container pool reserve fig masterslave design serverless computing system container rent action lender container pool cold startup occur action pagurus allows first check whether possible reuse existing lender container another action avoid cold startup noticed lender action also get renter container whenever repacked others enable container sharing customize container structure pagurus four module ie code load action run lend rent code encryption shown figure code load action run current serverless computing platform responsible code loading database execution monitoring invoking action respectively lend rent code encryption specially introduced pagurus container sharing safety guarantee respectively lend rent essentially consists lend rent function lend help container transferred executant container lender container rent help renter inherit container property lender container addition code encryption module guarantee container security code reload container repacking container lifecycle management play critical role pagurus discus two issue following two section respectively special emphasis answering following question condition identify container executant container pool idle transfer lender container pool set renter candidate select appropriate renter container consideration runtime performance efficiency metric endtoend latency renter container guarantee security lender renter without exposing side code data v image repacking idle container identification idle container identification lender container generation two essential function intraaction container scheduler realize container sharing first important identify container action lent ie idle container serverless system query executed running container total capacity container exceeds one required ensure qos query period idle container arises known whether container judged idle depends query workload processing power desired qos therefore first describe query processing logic serverless computing producerconsumer problem analyze via queuing theory widely applied communication system computation storage system without loss generality query arrival process container described poisson process exponentially distributed interval averaged lambda query processing time follows exponential distribution average value mu independent task arrival query fairly allocated among container thus apply mmn model analyze processing process traffic density rhofraclambdanmu system stable state case derive stable distribution pik k query waiting queue pikbegincasesfracnpkpikkldotsn fracnnrhokpinknnldotsendcases tag pisumknfracnpkkfracnpnnrho brevity detailed analysis omitted derive average waiting time w stable state ie rho query waiting queue number query le number container ie pwpxn thus derive waiting time ie time spent waiting queue distribution pw pxnpxgeq nsumkninfty pik tag sumkninftyfracnnrhoknpifracpi nrho pwt sumkninftypwtxkpxk tag sumkninftypikinttfracnrhoknxk ngammaknenmu xdx inttpinsumkninftyfracnmu xrhokn knnrho enmu xdx fracpinrhoenmurhot summing obtain general waiting time distribution fwt fwt pwpwt tag fracpinrhoenmurhott let td represent qos target define rrealn rrealile latency action n container rreq rreqile latency requested action waiting time set maximum waiting time tdfracmu fwtrreqgeq represent whether qos requirement satisfied thus derive discriminant function determine whether idle container action exists leftbeginarraylrrealnrreqgeq hatfnrreqfracpinrhoenmurhotdfrac rhogeq endarrayright tag fig design pagurus criterion need satisfied identify idle container necessary rrealngeq rreq otherwise current qos action satisfied n container running serverless platform action suffers qos violation due cold startup upon qos satisfaction try evaluate whether possible remove one container executant container pool checking achievable qos removal hatfngeq n container already enough satisfy qos requirement idle container removed intraaction container scheduler meanwhile interaction container scheduler repack lender image thus intraaction container scheduler action apply criterion identify idle container possible reuse action send corresponding container information interaction container scheduler lender container image repacking discussed next subsection similaritybased repacking repacking refers adding extra dependent library maximize possibility reuse action different action usually ask container different library intuitively may add arbitrary library build lender container maximal reuse however result extremely large container leading high overhead fortunately notice different action also share library different degree motivates u design similaritybased container repacking pagurus interaction container scheduler analyzes software environment action repacks lender container image running intraaction container scheduler checking similarity lender action action filter action similar lender action apply collaborative filtering adopt nearest neighbor search nns calculate similarity two action cosinebased similarity wellknown similarity algorithm traditionally used user interest recommendation define actionl action require additional library actionnl action without additional library interaction container scheduler generates lender container image repacking similar image following step collect information action information library recorded including name version library action user dockerfile additional installed library recorded format lnlibversionlibversion case user declare version library interaction container scheduler take latest version default bring hazard library version contradiction example usera requires lib version userb requires lib version neither lease others container version contradiction create vector hold library action lender action scheduler first filter action common library lender action candidate action check whether library candidate action inconsistent lender action eg version contradiction case removed candidate action finally scheduler take union set library lender action rest candidate action form library vector distance calculation calculate cosine distance lender action candidate action similarity filter logic select top nl value similarity take corresponding action renter candidate action exist example actionnl selected lender action nl actionls without version contradiction added random renter besides number nnl actionnls also selected random renter therefore nl actionls nnl actionnls selected renter interaction container scheduler wrap renter additional library image lender action meanwhile renter code file also repacked code encryption module safety nl nnl hyperparameters obviously value affect repacking overhead time value set according case action get chance repacked lender container nlminfracnumactionlssizerenter poolnnlminfracnum actionnlsizerenter pool tag figure show repacking operation along timeline interaction container scheduler repacks lender container image based data collection image repacking time cost lender repacking hard measure due uncertainty library vector cardinality doubt higher cardinality ie library repacking indicates longer repacking time repacking phase lender action usually take le action according experiment repacking image committed different intraaction container scheduler creating lender container overhead depends number additional library installed library take relatively long time repack user resort submitting virtual environment custom container image avoid long installation time case fig timeline pagurus operation pagurus adopt traditional criu generate container instead repacking interaction container scheduler deal creating updating repacking image intraaction container scheduler responsible managing container pool eg starting executant container default image generating lender container repacked image unless repacked image updated container boot first time subsequent container use criu accelerate startup renter container check module designed make sure runtime library intraaction container scheduler consistent interaction container scheduler performing container repacking security guarantee pagurus lender container may shared several renter action natural inevitable concern security lender container meanwhile code file renter action need repacked shared container renter security ignored lender security guarantee pigurus explores stateless nature serverless computing clean user code cache lender container repacking lender image renter action get previous information action lender container renter security guarantee pigurus encrypts renter action code file module code encryption first repacking prevent code disclosure code encryption divided two part first protect privacy user file name pagurus adopts renaming strategy renaming code file uniformly mainpy adopted openwhisk environment folder user action encrypted zip file user password secondly lender container generated renter code file coexist container case renter folder need encrypted interaction container controller specified password protect renter privacy code security lender container noticed cleanup code decryption executed interaction container scheduler therefore neither side get information conclusion although pagurus weakens level isolation code security privacy required isolation still ensured satisfied using encryption secure data file cloud computing quite common practice acceptable action adopt encryption address security concern container sharing vi interaction container management section describe step creating lender container idle container using borrowed container run action generating lender container executant container action identified idle intraaction container scheduler generate lender container repacked image returned interaction container scheduler figure show detailed workflow generating lender container shown figure executant container action periodically feedback status intraaction container scheduler based status container intraaction container scheduler identifies redundant idle container idle container identified executant container intraaction container scheduler repacks idle container lender container step step detail idle container deleted executant container pool corresponding lender container added lender container pool information feedbacked intraaction container scheduler step scheduler aware change last step intraaction container scheduler informs interaction container scheduler change step way action able borrow container interaction container scheduler renting container action action act need container run free warm container intraaction container scheduler submits rent request interaction container scheduler exists lender container already prepared act action container changed renter container act put renter container pool act figure show detailed step renting container action among step crucial guarantee lender container delivery ensure information safety fig step actionb rent container actiona fig generating lender container idle executant container lender step interaction container scheduler deletes code data actionb well renter code file lender container deciphers code file actiona interaction container scheduler inform actionb actiona prepare container transferring step step actionas intraaction container scheduler receiving return container status schedule lender container renter container pool step actionbs lender container pool clear related status information step meanwhile management privilege lender container transferred actionbs intraaction container scheduler actionas intraaction container scheduler code cleaning actionb code decryption actiona executed parallel overhead cleaning le time cost code decryption overhead code cleaning hidden user based section via vib summarize state transition three different container figure action executed executant container default cold startup container managed executant container pool lender container transformed idle executant container identified intraaction container scheduler shared container regenerated repacked image renter container inherits action lender container make query get executed without container cold startup container keep running timeout recycle recycling container different pool serverless computing load action drop warm container action recycled save resource recycling done monitoring status container container receive new request time period openwhisk container recycled recycling done setting timeout period container container operate timeout period container recycled recycling policy able used pagurus directly three type container pagurus therefore design prioritybased recycle strategy pagurus strategy interaction container scheduler manages recycling container including executant container lender container renter container action pagurus recycles renter container container recycles lender container container design philosophy action need extra rent container container tend recycled figure show order recycling container load action drop specifically set different timeout period three type container renter container pool minimum timeout period fig executant container store information library action container recycle affect scheduling intraaction container scheduler timeout period executant container fig slightly larger timeout period lender container lender container repack additional library multiple action even executant renter container recycled also meet invocation action reason lender container maximum timeout period fig current implementation set timeout period renter container executant container lender container default vii evaluation pagurus section first evaluate performance pagurus reducing endtoend latency application warm container discus possibility pagurus eliminating cold startup effect pagurus supporting bursty load effect integrating orthogonal technique experimental setup experiment evaluate pagurus based node cluster described section iiia node experimental cluster serve interaction container scheduler repacking although use small scale cluster section section iv reveals situation large scale cloud serverless computing platform often manage container node independently container process context container supposed migrated node case fig configuration action running background fig recycling three type container fig state transition diagram three container use representative serverless computing benchmark suite functionbench faasprofiler evaluate pagurus table ii list used benchmark workload following experiment set maximum number container renter pool randomly run two benchmark background high load simulate realsystem situation better understand background configuration make schematic diagram shown figure real system longrunning service occasional query serverless computing platform service running background also uncertain total c combination experimental configuration pagurus randomly select two benchmark lender experimental configuration run benchmark time invoking benchmark every second way benchmark suffers cold container startup test following experiment collect endtoend latency test benchmark based experimental setup reducing endtoend latency show effectiveness pagurus reducing endtoend latency benchmark subsection experiment benchmark randomly select two benchmark lender background pagurus compare pagurus apache openwhisk restorebased method openwhisk creates new container benchmark corresponding container image startup new container restorebased method store checkpoint container memory restores checkpoint main memory needed figure show endtoend latency benchmark openwhisk restorebased method pagurus figure optimal report latency benchmark get warm container directly shown figure benchmark achieve shortest endtoend latency pagurus compared openwhisk restorebased method best case action get lender container pagurus reduces endtoend latency benchmark compared openwhisk restorebased method respectively compared optimal scenario pagurus introduces longer endtoend latency average pagurus greatly reduces endtoend latency schedule idle shared container speed action may suffer cold container startup action query hosted shared container container startup phase query skipped userspecific code initialization needed according measurement pagurus schedule lender container query le u completes container cleaning applicationspecific code initialization le m restorebased method also able reduce endtoend latency benchmark compared openwhisk mainly eliminates overhead creating new container image however consumes large memory space still result longer endtoend latency benchmark compared pagurus eliminating container cold startup possible renter container action action extra library software library pack determine probability skip cold startup probability eliminating cold startup important indicator reflects effectiveness pagurus experiment benchmark run c experimental setup setup select benchmark renter figure show percentage c setup benchmark skip cold container startup observe figure pagurus eliminates cold container startup dd fop lp mm cdb clou benchmark always rent container lender always find lender benchmark require additional library initialize software environment case container repacking algorithm able pack redundant idle container action renter container benchmark require extra library img vid km mr md possibility eliminating cold startup depends library similarity lender action renter action common popular additional library required action higher probability repacked lender action instance configuration pagurus eliminates cold container startup vid km img respectively benchmark mainly use shared pillow sklearn software package however mr md due unpopular package used lender action take lower priority pack lender container decision fig endtoend latency benchmark suffer cold startup openwhisk restorebased method pagurus fig probability eliminating cold startup pagurus lead relatively low probability eliminating cold startup mr md better understand problem figure show heat map benchmark similarity container repacking algorithm figure small square row vid column img represents possibility vid serf lender img rental small square row img column vid represents possibility vid serf renter img observed figure benchmark tend repack container mr md result explain reason pagurus show relatively low possibility eliminating cold container startup mr md alternative method resolve problem taking prior knowledge consideration another way increasing number renter lender choose noticed heat map figure asymmetric benchmark rely different software package assume action act relies software package liblib another action act relies software package lib case container act package act time container act half software package act possibility repacking container act act repacking container act act different renter container used multiple action benchmark always skip code container startup integrating work reducing cold startup time pagurus eliminates container cold startup integrated prior work proposed reduce container cold startup time subsection integrate pagurus restorebased method catalyzer respectively report performance benchmark still run experimental setup experimental setup launch benchmark time interval second figure show average container startup time benchmark time test observed figure restorepagurus reduces average container startup time benchmark average compared original restorebased method catalyzerpagurus reduces average container startup time average compared catalyzer pagurus able reduce average container startup time able totally skip container startup phase benchmark sometimes even appropriate lender container return pagurus slow container startup therefore pagurus integrated prior work reduce average cold startup time figure show cumulative distribution endtoend latency mm img restorebased method restorepagurus figure optimal show latency benchmark container warm integrating pagurus restorebased method endtoend latency test mm greatly reduced meanwhile query img show much shorter endtoend latency mm action query completely skip container startup thus overhead cold startup eliminated img action query eliminate cold startup overhead rest still experience container startup phase restorebased method pagurus observe large discontinuity figure b pagurus help query skip container startup phase reduce latency still suffer cold startup problem traditionally also integrate prewarm startup introduced section ii policy advanced container fig cumulative distribution benchmark cold startup endtoend latency pagurus restore fig average cold startup latency benchmark prewarm startup policy prewarm mean action get one prewarmed container prewarm mean action initialize one specific container created common cache fig benchmark similarity container repacking algorithm fig average cold startup latency pagurus integrated restorebased method catalyzer respectively startup technique figure observe pagurus still performs better preamarm method library specific prewarmed container may conflict user action case specific prewarmed container initialized making user action experience cold startup even though preamarm method show le endtoend latency pagurus due prewarmed container continuously running background additional gb memory resource required although comparatively high performance preamarm method unpractical extremely high resource usage supporting bursty load traditional serverless platform eg openwhisk fail support bursty workload without causing qos violation due long latency cold container startup pagurus able support smooth process bursty workload action interaction container sharing figure show supported bursty load benchmark without causing qos violation pagurus allows benchmark rent container observed figure benchmark pagurus able support time bursty load benchmark able rent renter container action mainly overhead renting container action much lower creating new container besides pagurus also reduces consumed memory space support bursty load benchmark compared openwhisk suppose bursty load openwhisk straightforward method maintaining warm container however container consume large main memory space contrary pagurus need launch additional container support bursty load figure show size main memory space saved pagurus shown figure observed figure pagurus gb gb memory saved case renter container gb gb memory case renter container compared openwhisk overhead pagurus table iii show overhead introduced pagurus shown table pagurus incurs five type overhead pagurus lender container store renter encrypted code file extra operation decrypt corresponding renter code file eliminating cold startup approach take kb space save information le m decrypt far le m database transmitting operation packing image introduced generation lender container extra packed image experience creating average mb space allocated storing preparation lender container done asynchronously result long endtoend latency container need boot image first time case container get accelerated startup checkpoint file take average kb space store besides repacked image checkpoint file recycled corresponding action invoked important part overhead cpu usage pagurus repacking container experiment show interaction container scheduler repacks container image action average cpu utilization node taking communication synchronization node account repacking phase consume cpu resource limit cpu usage repacking le server node repack container image action data collection minute conclude overhead incurred pagurus negligible viii conclusion paper present pagurusa container management system serverless eliminate container cold startup interaction container sharing implement design introducing three unique container pool lender container executant container renter container interaction container scheduler cooperated intraaction container scheduler action enable container scheduled different action reduce container cold startup evaluation result show pagurus significantly eliminate cold startup besides pagurus also integrated several container technology minimize container startup overhead serverless computing fig size reduced memory usage support bursty load pagurus compared openwhisk fig supported bursty load benchmark pagurus reference barroso jeffrey dean ur holzle web search planet google cluster architecture ieee micro pp cited s barroso tail scale communication acm pp cited s barroso tail scale communication acm pp cited s j dean l andre barroso tail scale communication acm pp cited s j dean l andre barroso tail scale communication acm pp cited s x dong j yu luo chen g xue li achieving secure efficient data collaboration cloud computing st ieeeacm international symposium quality service iwqos montreal canada june pp cited s du yu xia b zang g yan c qin q wu h chen catalyster submillisecond startup serverless computing initializationless booting proceeding twentyfifth international conference architectural support programming language operating system pp cited s n gautam analysis queue method application crc press cited s n gautam analysis queue method application crc press cited s hendrickson sturdevant e oakes harter v venkataramani c arpacidusseau r h arpacidusseau serverless computation openlambda login usenix mag cited s harter b salmon r liu c arpacidusseau r h arpacidusseau slacer fast distribution lazy docker container th usenix conference file storage technology fast santa clara ca usa february pp cited s hendrickson sturdevant e oakes harter v venkataramani c arpacidusseau r h arpacidusseau serverless computation openlambda login usenix mag cited s e jones j schleiersmith v sreekanti c tsai khandelwal q pu v shankar j carreira k krauth n yadowadkar et al cloud programming simplified berkeley view serverless computing arxiv preprint arxiv cited s j kim k lee functionbench suite workload serverless cloud function service cloud pp cited s r koller williams serverless end dominance linux cloud proceeding th workshop hot topic operating system hotos whistler bc canada may pp cited s madhavapeddy j scott unixernels rise virtual library operating system commun acm pp cited s f manco c lupu f schmidt j mendes kuener satti k yasukata c raiciu f h vm lighter safer container proceeding th symposium operating system principle shanghai china october pp cited s mcgrath p r brenner serverless computing design implementation performance th ieee international conference distributed computing system workshop icdcs workshop atlanta ga usa june pp cited s e oakes l yang zhou k hucker carazzaharter c arpacidusseau r h arpacidusseau sock serverlessoptimized container login usenix mag cited s q pu venkataraman stoica shuffling fast slow scalable analytics serverless infrastructure th usenix symposium networked system design implementation nsdi boston february pp cited s shahraud j balkid wentzlaff architectural implication functionasaservice computing proceeding nd annual ieeeacm international symposium microarchitecture micro columbus oh usa october pp cited s v shankar k krauth q pu e jones venkataraman stoica b recht j ragankelley numpyr serverless linear algebra corrabs cited s z shen z sun g sela e bagdasaryan c delimitrou r van renesse h weatherspoon xcontanures breaking barrier improve performance isolation cloudnative container iris bahar herlihy e witchel r lebeck ed proceeding twentyfourth international conference architectural support programming language operating system asplos providence ri usa april pp cited s w tai chang w huang security analysis data collaboration scheme hierarchical attributebased encryption cloud computing j network security pp cited s j thalheim p bhatotia p fonseca b kasicki cntr lightweight o container usenix annual technical conference usenix atc boston usa july pp cited s e tilevich h mossenbock editor proceeding th international conference managed language runtimes manlang linz austria september cited s r sarpangala venkatesh smejkal milojcicic gavrilovska fast inmemory cru docker container proceeding international symposium memory system memsys new york ny usa pp cited s vrable j j chen moore e vandekieff c snoeren g voelker savage scalability fidelity containment potemix virtual honeyfarm proceeding th acm symposium operating system principle sosp brighton uk october pp cited s k wang r ho p wu replayable execution optimized page sharing managed runtime environment proceeding fourteenth eurosys conference dresden germany march pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain serverless platform atc pp cited s l wang li zhang ristenpart swift pecking behind curtain title want invest predicting startup funding freely publicly available web information transcription missingpagefail ml framework investigated section order illustrate effectiveness proposed approach present set experiment also report analyze section result experiment finally section concludes paper related work explained section pace startup created impact economy new important relatively study investigated problem predicting trajectory startup work presented steintein et al perhaps one first attempt dive field using predictive model assessing success company work author explore prediction merger acquisition metric examine company categorized successful consider news pertaining company individual techcrunch input space defined paper includes companyspecific feature managerial financial feature combined topicdependent feature extracted via latent dirichlet allocation lda relatively similar work hunter et al hunter et al proposed construct portfolio startup least one startup achieves exit ie either get initial public offering ipo acquired another company data studied work principally taken three source crunchbase pitchbook linkedin starting brownian motion model author propose use greedy approach solve picking winner problem work differs two study firstly objective follow basically prediction funding event secondly importantly data use train model publicly available unlike linkedin data vc database come verified source ie startup datasets like techcrunch edited anyone footnote httpswwwcrunchhasecomhttpswwwcrunchhasecom footnote httpspitchbookcomhttpspitchbookcom footnote httpsangelcohttpsangelco past decade social medium particular twitter extensively used building ml model event detection sentiment analysis success prediction example twitterbased model hunter et al hunter et al hunter et al likewise context mentioned bauer et al twitter play crucial role survival failure new venture given fact tweet publicly available written company usually reliable source information used predict evolution startup one study investigates role social medium success company steintein et al therein shown social engagement startup like number tweet number follower significant correlation success receiving crowdfunding author argue since crowdfunding rather new fundraising technique traditional facetime approach investor practically exist activity startup social medium facebook twitter heavily boost odds receiving crowdfunds paper angelllist crowdfunding investment platform facebook twitter chosen data source angelllist used identify startup received crowdfunds select startup author picked startup snapshot k actively fundraising data cleaning startup positive kept perform prediction data highly imbalanced wide range technique hunter et al madsen et al madsen et al combined greedy feature selection algorithm used order train model better true positive rate tpr extensive analysis shown method presented steintein et al reach accuracy predicting crowdfunding event compared stein et al present study exploit social medium data also us series feature perform fundraising prediction shown section feature increase prediction performance significant manner footnote httpswwwcranchhasecomhttpswwwcranchhasecom recent study following line sharchilev et al sharchilev et al proposed method named webbased startup success prediction wbssp startup success prediction paper perhaps relevant study literature goal sharchilev et al predict within period time future startup already secured seed funding get round funding source data study mentioned crunchbase linkedin web construct model author define feature space decomposed four category general investor team mention web showed last category ie webbased mention boost prediction performance proposed pipeline order avoid overfitting learning algorithm designed grouping feature sparse dense feature feature passed set learning method fed boosting method catboost talaldi et al order obtain final prediction result eventually author discussed set research question particularly importance category feature effect treating sparse feature differently dense one present work differs sharchilev et al two important aspect first rely feature extracted freely publicly available information require costly manual development maintenance second rely simple machine learning model easily implemented reproduced overall feature rely simpler extract prediction model use easier develop result obtain least good one presented sharchilev et al data collection section describe detail process collecting data required solve prediction task first step process build list startup analysis along link website one use sufficiently large list startup available web case gathered k startup multiple source hub investor conference across world collected list startup website extract information following source startup website twitter api footnote httpsdevelopertwittercomhttpsdevelopertwittercom google search api footnote httpsdevelopersgooglecomhttpsdevelopersgooglecom countryspecific registration data company eg infogreffe containing information firm office location number employee footnote httpswwwinfogreffecomhttpswwwinfogreffecom footnote complete list found appendix distinguishing feature dataset geographical variety company previous work focus startup usa analyze startup across world slight focus europe figure illustrates distribution top country dataset feature data source collected one need extract proper set feature order define space prediction task done efficiently describe four category feature extracted along intuition behind web purpose startup success prediction general feature following feature considered core information startup country origin age number employee number office number people featured team page startup website importance feature task fundraising prediction quite obvious venture evolution different country varies age well number employee office characterize different stage startup evolution property fundraising process strongly depend stage venture country startup origin extracted address page company website use statistical method infer country likely country company employ regular expression extract phone number via country code simply look around phone number fixed window size find country country occurrence taken country origin case tie country selected infer age startup simply use creation date country give public access registry company one usually find creation date another heuristic use infer creation date date creation different medium company website social medium case different creation date identified two previously mentioned source older date taken creation date according observation context startup case good approximation creation date case return correct creation date case return creation date maximum two year shift number people featured team page startup website extracted follows usually team page follows repeating template containing information every person name role social medium link picture etc find extract repeating template use statistical method verify corresponds people name job function etc finally information number employee office extracted countryspecific database footnote httpsyandexruhttpsyandexru financial feature history startup previous funding round evidently important factor predicting future fundraising different fundraising round happen usually similar patent wrt previous round secured startup process detecting funding event startup described section work propose extract following feature summarize financial history startup total number previously secured funding round last fundraising amount mean maximal amount previously secured round time since last secured round google search result feature author shown highly useful set feature task startup success prediction extracted crawling observable web startup presence purpose extraction feature author analyze data yandex major russian search engine startup count number reference startup website webpage different domain data however easily accessible ordinary web user footnote httpscloudgooglecomfreedocsgcpfreetierhttpscloudgooglecomfreedocsgcpfreetier accordingly present study similar information using widely available tool extracted particular google search api startup search result date within year preceding start prediction period analyzed given startup name date range query google api made irrelevant result filtered order perform analysis domain frequency similar order exclude irrelevant result check whether snippet search result contains startup name since purpose work build model entirely free tool constrain amount query available google cloud platform free tier therefore obtain top result given startup name date range following statistic extracted form search result footnote httpscloudgooglecomfreedocsgcpfreetierhttpscloudgooglecomfreedocsgcpfreetier number relevant result assume result related startup snippet result contains startup name figure geographical distribution top country dataset total number result reported google number search result domain popular domain latter simply sort domain appearing result based number time contain name startup investigation take top domain intuition take domain likely talk startup result reduce amount noise feature space social network presence feature last two decade impact social network different social economic political process became remarkable given fact startup crucial reach potential audience via social medium category feature heavily impact prediction performance one note impact investigation done literature krishna et al highlighted importance social medium presence crowdfunding success startup use first set social medium feature binary indicate whether startup account several popular social medium facebook instagram linkedin youtube twitter blog startup website information extracted simple script search social network button website startup second set feature extracted social medium corresponds statistical information startup website number people give reference linkedin account team page startup number entry blog last year two feature indicate willingness startup appear social medium visible followed others important presence startup twitter since information twitter readily available contrary social medium like facebook linkein also extract feature describe activity startup particular social medium year precedes year funding event predicted aggregated monthly startup twitter account statistic last year including number posted tweet meanmax number like retweets user tweet modal language user tweet total number different user mention startup account tweet last year information hashtags used startup startup collect last tweet establish list frequently used hastags startup represented dimensional vector dimension correspond number time startup used hashtag last year table summarizes feature explained type feature categorical numerical well nature sparse dense also illustrated two rightmost column data labeling another challenge solving task predicting startup success open source labeling data commercial database often contain date funding event amount usually extracted manually human expert aim automatically detect startup fundraising news twitter purpose
Original Title: Pagurus: Eliminating Cold Startup in Serverless Computing with
  Inter-Action Container Sharing
Original Transcription: # Pagurus: Eliminating Cold Startup in Serverless Computing with Inter-Action Container Sharing

*Zijun Li, *\({}^{\dagger}\)Quan Chen, *\({}^{\dagger}\)Minyi Guo

_\({}^{*}\)Department of Computer Science and Engineering, Shanghai Jiao Tong University, China_

_\({}^{\dagger}\)Shanghai Institute for Advanced Communication and Data Science, Shanghai Jiao Tong University, China_

lzjxx1122@sjtu.edu.cn, {chen-quan, guo-my}@cs.sjtu.edu.cn

###### Abstract

Serverless computing provides fine-grain resource sharing between Cloud tenants through containers. Each function invocation (action) runs in an individual container. When there is not an already started container for a user function, a new container has to be created for it. However, the long cold startup time of a container results in the long response latency of the action. Our investigation shows that the containers for some user actions share most of the software packages. If an action that requires a new container can "borrow" a similar warm container from other actions, the long cold startup can be eliminated. Based on the above finding, we propose Pagurus, a runtime container management system for eliminating the cold startup in serverless computing. Pagurus is comprised of an inter-action container scheduler and an intra-action container scheduler for each action. The inter-action container scheduler schedules shared containers among actions. The intra-action container scheduler deals with the management of the container lifecycle. Our experimental results show that Pagurus effectively eliminates the time-consuming container cold startup. An action may start to run in 10ms with Pagurus, even if there is not warm container for it.

## I Introduction

Adopting serverless computing, Cloud tenants submit functions directly without renting virtual machines of different specifications, Cloud vendors schedule the tenants' functions automatically. For the high maintainability and testability, most hyperscalers now provide serverless computing services (such as Amazon Lambda [1], Google Cloud Function [2], Microsoft Azure Functions [3], and Alibaba Function Compute [4]). Serverless computing is perfect for the Internet services that have unstable query loads, since the tenants are charged for each query execution, instead of the long term renting.

We use the terminology in Apache OpenWhisk [5], an event-driven serverless computing platform. An _action_ represents the invocation of a user function. Whenever an action is received, serverless computing runs the action using either a newly-launched container or a running warm container. The warm containers keep serving queries (_warm startup_) until timeout to be recycled. While containers of different actions rely on various software packages, the containers are not shared. If there is not a warm container for an action, a new cold container needs to be started for it. The long latency of booting containers, as well as the software environment and code initialization, restricts the performance of serverless computing [6, 31, 33, 34, 43].

While some actions suffer from the long container cold startup time, we observe that current serverless computing systems may launch too many containers for some other actions. For instance, they may launch too many containers for Internet services with diurnal load patterns [17, 19] (the low load is less than 30% of the peak load) at the peak load. We also observe that there are idle containers for some actions, even if loads of these actions are stable. While these warm containers are idle and wasting the system resources, they are not used by any other action because the containers for different actions install different software packages.

With the development of micro-service architecture, the actions tend to use popular and common library package. For instance, by extracting likely dependencies in the projects on packages in the popular Python Package Index (PyPI) repository, 36% of imports are of 20 popular packages [32]. Actions tend to use similar software packages. In this scenario, if an action that requires cold container startup is able to utilize the idle containers of other actions, the cold startup is turned into a warm startup, its end-to-end latency can be greatly reduced.

There are three main challenges in achieving the above purpose. As for the first challenge, the loads of the actions are not stable [35]. It is difficult to determine whether an action can safely lend an idle container to other actions, without affecting its own Quality-of-Service (QoS). Secondly, existing serverless computing systems do not support the "borrow" operation. Container sharing is not allowed. Thirdly, multiple renters and lenders coexist. It is non-trivial to design an efficient container sharing strategy among actions that minimizes the number of the cold startup.

To tackle the above challenges, we propose **Pagurus**, a container management system that reduces container cold startup through adaptive inter-action container sharing. In Pagurus, the containers are classified into _lender containers_, _executant containers_ and _renter containers_. The executant containers can only be used by the owner action itself. The lender containers can be lent to other actions, and will turn into renter containers. Pagurus proposes an enhanced container component that enables the container sharing between multiple actions and guarantees the security of users' code. For each action, an _intra-action container scheduler_ is adopted to manage its executant containers, the renter containers borrowed from other actions, and the lender containers to be lent to other actions. The whole serverless computing system adopts an _inter-action container scheduler_ to schedule the containers between the actions and handles the proactive re-packing based on the package similarity of the actions and their workloads.

The main contributions of this paper are as follows.

* **The container enhancement that enables the sharing.** We enhance the container design to support the runtime package re-packing. It enables the container sharing between different actions.
* **The design of a similarity-based container re-packing policy.** While the containers for different actions install different software packages, we analyze the similarities of the actions, and minimize the number of packages installed for container sharing.
* **The design of an efficient inter-action container sharing mechanism.** This mechanism divides the containers into three types, based on which Pagurus manages them in different ways and enables efficient inter-action container sharing.

Through the adaptive inter-action container sharing, Pagurus greatly reduces the possibility that an action suffers from cold container startup. Pagurus is also able to be integrated with prior work on reducing the container cold startup time to minimize the overhead of serverless computing in all the cases.

## II Background and Related work

### _Background_

In serverless computing, container act as a lightweight virtualization that creates multiple isolated user-space instances for actions. The serverless platform uses containers to encapsulate and execute the queries.

Figure 1 shows the way that a user action is scheduled to run with serverless computing. As shown in the figure, a container must be booted/restored/initialized/invoked to host the action. If an action is invoked for the first time or there is no alive container for this action, the serverless system encapsulates it and starts up a new container, initializes software environment, loads application-specific code [13], and runs the function. All these steps make up a _cold startup_[26, 16], and may take several seconds. The container cold startup significantly increases the end-to-end latency of user queries [33, 6, 34, 43], especially the processing of a single query is often short (hundreds of milliseconds) for Internet services.

To deal with this problem, researchers also proposed to use CRIU (checkpoint-restore in user-space) [40, 41, 42, 7] technique that restores container images from checkpoints to reduce the cold startup time. However, it still incurs the long end-to-end latency [21]. Another approach called _prewarm startup_ adopted by OpenWhisk spawns stem cell containers that are already initialized with the software environment in advance. Though it skips the container startup and users only need to perform application-specific code initialization [24, 25, 8, 32], its pre-loaded libraries can either make the image size too large [39, 24], or cause long startup latency for the prewarm container [32, 18].

If a container for a type of action is alive (just complete the previous invocation), a new action query of the same type can be directly executed in the running container (_warm startup_). Warm startup eliminates the container booting and initialization, and these warm containers keep serving actions to achieve better end-to-end latency [31]. However, warm startups are not always possible because these warm containers may be recycled before cold startup happens [26, 16].

### _Related Work_

There are already lots of prior work on reducing the container startup latency to improve the performance of serverless computing [25, 21, 36, 15]. SAND [15] separates different applications from each other via containers, while allowing functions of one application to run in the same container by different processes. X-container [36] has been proposed as a new security paradigm for isolating cloud-native containers to achieve higher throughput. Catalyzer [21] adopts the design that utilizes the technology of CRIU with on-demand recovery. Hendrickson [25] also proposes OpenLambda to deal with the long function startup latency and locality consideration.

Slacker [24] and SOCK [32] share the similar idea that containers are launched by generalizing zygote initialization to reduce the startup latency. To achieve function isolation, Unikernels [28, 29] can achieve less latency and better throughput via bypassing the kernel with unikernels in serverless environments. McGrath [31] proposed to reuse containers and create containers by introducing a queuing scheme with workers collecting the availability in different queues.

Existing works mainly focus on seeking more lightweight virtualization technologies to pursue lower overhead, or to reduce the container startup time for one kind of action. Our work tries to make different actions work collaboratively to alleviate the container cold startup problem. Furthermore, Pagurus can be combined with different container technologies to achieve less cold startup latency.

## III Motivation

### _Experimental Setup_

In this investigation, we use Apache OpenWhisk [5] with local cache as the representative serverless computing platform, FunctionBench [27] and Faas-Profiler [34] as the benchmarks. The experiment setup is based on a 2-node cluster where the nodes are connected with a 25Gb/s Ethernet switch. In the 2-node experimental cluster, we use one node to perform the computing, and one node to generate the queries for execution. Table I shows the hardware and software configurations of each node. We use representative serverless computing benchmark suites FunctionBench [27] and Faas-profiler [34] and the used benchmark workloads are shown in Table II.

Fig. 1: Four possibilities to start an action in a serverless computing system.

### _Breakdown of the End-to-end Latency_

The end-to-end latency of processing a user's query seriously affects the user experience. We make an investigation and break down the end-to-end latencies of the benchmarks for serverless computing.

In a serverless computing system based on container technology, cold container startup happens when there are no idle containers exist, and a user query is received. In this scenario, the system creates a new container to serve the query. For an action, the cold container startup includes operations like initializing the customized execution environment. Traditionally, the cold startup overhead includes the container startup, the software environment of the function initialization, and application-specific code initialization. These operations may incur significant extra latency. Figure 2 shows the percentages of the time spent on the cold container startup in the end-to-end latencies of the benchmarks.

Observed from Figure 2, the cold startup overhead increases the end-to-end latencies of the benchmarks. In general, the container cold startup time is relatively stable. In the best case, the cold container startup still takes 48.2% of the end-to-end latency (_cdb_). While in the worst case, the cold container startup takes 93.8% of the end-to-end latency (_dd_).

If we can eliminate the container cold startup, the end-to-end latencies of the applications with serverless computing can be greatly reduced. To this end, Cloud vendors [1, 2, 3, 4, 12, 14], as well as recent works [16, 25, 30, 38] have focused more on reducing the container startup time as we discussed in Section II.

Even if the container cold startup time is reduced to about 40ms in the best case [21], the cold startup still takes longer time than the case that the query can directly get a warm container (\(<\)10ms) [5, 34]. The increasing usage of high-level language like Python, can make the cold startup even more expensive [15, 34]. For the latency-sensitive applications that have millisecond-level latency targets, such as Internet services, the 30ms already results in poor user experience.

### _Existence of Redundant Warm Containers_

An important feature of serverless computing is elasticity. By current container startup strategy, the containers are started up upon queries waiting in the queue, and will be recycled soon when there is no query for a certain period (e.g., 60 seconds in OpenWhisk). Therefore, whenever the running containers fail to catch up with the queries waiting in the queue, a new container must get started and experience cold startup. In a large-scale serverless computing platform, there may coexist a large number of actions from different users. If some actions have redundant warm containers, we envision that it is possible to reuse these redundant warm containers to eliminate the cold startup. To this end, we manually schedule the container startup process to reuse the redundant warm containers, and check the number of containers launched and the QoS in the metric of end-to-end latency. Figure 3 reports our investigation results. Our investigation proves that our assumption holds.

Fig. 3: The number of containers launched (a) and required (b) to ensure the 95%-ile latency target of an example benchmark _vid_.

Fig. 2: The distribution and percentages of time spent on the cold container startup and action execution in the end-to-end latencies of the representative benchmarks.

Taking the benchmark _vid_ as an example, Figure 3(a) and Figure 3(b) show the number of containers launched and the 95%-ile end-to-end latencies of the queries in various loads, for OpenWhisk and our manual scheduling, respectively. In the figure, the \(x\)-axis represents the query workload (Query-per-Second, QPS); the bars show the number of warm containers (corresponding to the left \(y\)-axis), and the line shows the 95%-ile latency (corresponding right \(y\)-axis).

Observed from Figure 3(a), the 95%-ile latency of the benchmark shows the pattern of cyclic variation. This is because a little increase in the QPS at the saturation point will bring in a new container startup, thanks to which, lower overall latency will be achieved. But further increasing the QPS will result in higher overall latency. While, there is still headroom between the 95%-ile latency and the QoS target, it is possible to use fewer containers without violating the QoS requirement. This is exactly what we do in the manual scheduling. As shown in Figure 3(b), in some cases (the bars in black), we can safely reduce at least one container while still achieving the 95%-ile latency target. It proves that some applications in the serverless computing platform do have some warm idle containers during execution. In addition, from Figure 3(b), we also observe that the idle container usually appears in a minimum turning point of the latency (represented by blue circle in the figure). It is because that the minimum turning point usually comes with a new container startup to deal with the increasing queries in the waiting queue. We also find that it is a common phenomenon based on Openwhisk. Besides \(vid\), the other benchmarks also produce the similar results. On the other hand, it can be easily anticipated that there will be even more idle containers in the case when the query workload drops suddenly. While, it has been widely witnessed and proved that real Internet services are with diurnal load pattern [17, 19]. Definitely, this will bring in more idle containers potentially for reuse.

### _Challenges in Reusing Containers and Ensuring QoS_

Based on the above analysis and investigation, there is an opportunity to leverage the warm containers of some actions to eliminate the cold container startup of other actions. While the actions may require different software packages and execution environment, an action's container is not able to be used by another container. An action's container has to be re-packed before it can be used by other actions. The re-packing operation may take a relatively long time.

By extracting the packages from the benchmark suite FunctionBench [27], we also find that 16.7% of the benchmarks import \(pandas\) and \(sklearn\), and some commom libraries like \(numpy\) are even shared by 22.2% of them. This finding indicates that, different actions tend to share a high proportion of packages with others. Therefore, it is possible to build a shared container image, allowing several actions to run without installing extra packages. Even if in some cases the similarity of libraries between different actions is not high, we can use specific designed algorithms to build some connection between them. However, it is not an easy task to build a shared container image as there are still several challenges, such as

* **Actions are not able to share containers.** While the containers of different actions pack different software packages, the containers of an action cannot be reused by other actions by default.
* **Container reuse brings extra time overhead.** To allow other actions to run in an action's container, the reused container is supposed to install extra packages. Inappropriate package installation brings large time overhead that negates the latency reduction from the elimination of the cold container startup.
* **Security concerns about inter-action container sharing.** When containers are shared between different actions, isolation is weakened. While, the security and privacy of the actions must be ensured.
* **Inter-action container reuse brings extra schedule complexity.** While multiple actions are active concurrently, an efficient mechanism has to be proposed to manage the container lend and rent between the actions.

## IV Design of Pagurus

To tackle the above challenges, we propose **Pagurus**, a runtime container management system for eliminating the cold container startup through inter-action container sharing.

For a traditional serverless computing system, the design of distributed deployment is usually implemented in two ways. One is to divide the nodes into master and slave nodes. Load balancing is realized by the central controller in the master node, and the data in the slave node (server node) is synchronized by the database, as shown in Figure 4. However, according to the previous studies, the network bandwidth between the server nodes and the database is usually the bottleneck of the serverless computing, and such master-slave design is also unpractical [25, 26, 32].

Therefore, we design Pagurus using the single node management, where all nodes communicate with each other to maintain and update local databases and files. By such means, the performance is only relevant to the computing power of the server node. Figure 5 shows the design overview of Pagurus. For the management of shared containers between actions, an _inter-action container scheduler_ is introduced. It is also responsible for the re-packing of the containers at runtime when necessary. For each action, there is an _intra-action container scheduler_ responsible for coordinating three container pools, i.e., an executant container pool, a lender container pool, and a renter container pool. Whenever a container experiences the cold startup, it is added to the executant container pool by default, and will keep intact provided that it is recognized as a warm container. When there is no query requesting the container for a certain period, the container will be identified as idle and moved to the lender container pool for possible cross-action reuse. The renter container pool reserves

Fig. 4: The Master-Slave design of a serverless computing system.

the containers rent from the other actions' lender container pool. Once a cold startup is about to occur on an action, Pagurus allows it to first check whether it is possible to reuse an existing lender container from another action to avoid cold startup. It should be noticed that the lender actions can also get renter containers whenever it is re-packed by others.

To enable the container sharing, we customize the container structure of Pagurus with four modules, i.e., _code load_, _action run_, _lend and rent_ and _code encryption_, as shown in Figure 5. _Code load_ and _action run_ are the same as current serverless computing platform, responsible for code loading from database and execution monitoring when invoking actions, respectively. _Lend and rent_ and _code encryption_ are specially introduced in Pagurus for container sharing and safety guarantee, respectively. _Lend and rent_ essentially consists of _lend_ and _rent_ functions. _Lend_ helps the container transferred from executant container to lender container. _Rent_ helps renter inherit containers and properties from lender container. In addition, _code encryption_ module guarantees the container security during code reload.

Container re-packing and container life-cycle management play critical roles in Pagurus. We will discuss the two issues in the following two sections, respectively, with special emphasis on answering the following questions:

* On what conditions, we can identify a container in the executant container pool as idle and transfer it to lender container pool?
* For a set of renter candidates, how to select the appropriate renter container in the consideration of runtime performance efficiency in the metric of end-to-end latency of renter containers?
* How to guarantee the security of lender and renter without exposing both sides' code and data?

## V Image Re-packing

### _Idle Container Identification_

Idle container identification and lender container generation are two essential functions in the intra-action container scheduler. To realize container sharing, it is first important to identify the containers of an action that can be lent, i.e., idle container. In the serverless system, the queries are executed by the running containers. If the total capacity of the containers exceeds the one required to ensure the QoS of the queries during a period, idle container arises. As we have known, whether a container can be judged as idle or not, depends on the query workload, the processing power, and the desired QoS. Therefore, we first describe the query processing logic of serverless computing into a producer-consumer problem, and analyze it via queuing theory, which has been widely applied in communication systems, computations and storage systems.

Without loss of generality, the query arrival process to a container can be described as Poisson process with exponentially distributed interval averaged as \(\lambda\). The query processing time follows an exponential distribution with average value \(\mu\), which is independent to the task arrival. The queries are fairly allocated among the containers. Thus, we can apply \(M/M/n\) model [22] to analyze the processing process.

When the traffic density \(\rho=\frac{\lambda}{n\mu}<1\), the system is in a stable state. In this case, we can derive the stable distribution \(\pi_{k}\) that there are \(k\) queries in the waiting queue as

\[\pi_{k}=\begin{cases}\frac{(np)^{k}\pi_{0}}{k!},k=1,2,\ldots,n-1\\ \frac{n^{n}\rho^{k}\pi_{0}}{n!},k=n,n+1,\ldots,\end{cases} \tag{1}\]

where \(\pi_{0}=[\sum_{k=0}^{n-1}\frac{(np)^{k}}{k!}+\frac{(np)^{n}}{n!(1-\rho)}]^{-1}\). For brevity, the detailed analysis is omitted. Then, we can further derive the average waiting time \(W\) under the stable state (i.e., \(\rho<1\)). No query will be in the waiting queue if the number of queries is less than the number of containers, i.e., \(P\{W=0\}=p\{X<n\}\). Thus, we can derive the waiting time (i.e., the time spent in the waiting queue) distribution as

\[P\{W\!=\!0\} =p\{X\!<\!n\}=1\!-\!p\{X\geq n\}\!=\!1\!-\!\sum_{k=n}^{\infty} \pi_{k} \tag{2}\] \[=1-\sum_{k=n}^{\infty}\frac{n^{n}\rho^{k}}{n!}\pi_{0}=1-\frac{\pi _{n}}{1-\rho},\]

and

\[P\{0\!<\!W\!<\!t\} =\sum_{k=n}^{\infty}P\{w\!<\!t|X\!=\!k\}P\{X\!=\!k\} \tag{3}\] \[=\sum_{k=n}^{\infty}\pi_{k}\int_{0}^{t}\frac{(n\rho)^{k-n+1}x^{k -n}}{\Gamma(k-n+1)}e^{-n\mu x}dx\] \[=\int_{0}^{t}\pi_{n}\sum_{k=n}^{\infty}\frac{(n\mu x\rho)^{k-n}}{ (k-n)!}n\rho e^{-n\mu x}dx\] \[=\frac{\pi_{n}}{1-\rho}[1-e^{-n\mu(1-\rho)t}].\]

Summing up (2) and (3), we obtain the general waiting time distribution \(F_{w}(t)\) as

\[F_{w}(t) =P\{W=0\}+P\{0<W<t\} \tag{4}\] \[=1-\frac{\pi_{n}}{1-\rho}e^{-n\mu(1-\rho)t},t>0.\]

Let \(T_{D}\) represent the QoS target and define \(r_{real}(n)\) as the \(r_{real}\)-ile latency of an action when there are \(n\) containers, and \(r_{req}\) as the \(r_{req}\)-ile latency requested by an action. So when the waiting time \(t\) is set as the maximum waiting time \(T_{D}-\frac{1}{\mu}\), \(F_{w}(t)-r_{req}\geq 0\) will represent whether the QoS requirement can be satisfied. Thus, we can derive the discriminant function to determine whether the idle container of an action exists as

\[\left\{\begin{array}{l}r_{real}(n)-r_{req}\geq 0\\ \hat{f}(n-1)=1-r_{req}-\frac{\pi_{n}}{1-\rho}e^{-(n-1)\mu(1-\rho)(T_{D}-\frac{1 }{\rho})}\geq 0.\end{array}\right. \tag{5}\]

Fig. 5: Design of Pagurus.

Both criteria in (5) need to be satisfied to identify an idle container. It is necessary that \(r_{real}(n)\geq r_{req}\), otherwise the current QoS of the action can not be satisfied when \(n\) containers running in serverless platform, and the action suffers QoS violation due to cold startup. Upon QoS satisfaction, we further try to evaluate whether it is possible to remove one container from the executant container pool by checking the achievable QoS after the removal. If \(\hat{f}(n-1)\geq 0\), \(n-1\) containers are already enough to satisfy the QoS requirement, and an idle container will be removed by its intra-action container scheduler. Meanwhile, the inter-action container scheduler will re-pack the lender image for it.

Thus, the intra-action container scheduler of an action can apply the criteria in (5) to identify the idle containers for possible reuse by the other actions, and send the corresponding container information to the inter-action container scheduler for lender container image re-packing, as will be discussed in the next subsection.

### _Similarity-based Re-packing_

Re-packing refers to adding extra dependent libraries to maximize the possibility of reuse by the other actions as different actions usually ask for containers with different libraries. Intuitively, we may add arbitrary more libraries to build a lender container for the maximal reuse. However, this will result in an extremely large container, leading to high overhead. Fortunately, we notice that different actions also share some libraries with different degrees. This motivates us to design a similarity-based container re-packing in Pagurus.

The inter-action container scheduler analyzes the software environment of each action, and re-packs the lender container image for each running intra-action container scheduler by checking the similarities between lender actions and other actions. To filter out actions similar to a lender action, we apply collaborative filtering and adopt Nearest Neighbor Search (NNS) to calculate the similarity between two actions. Cosine-based Similarity is a well-known similarity algorithm which is traditionally used in users' interests recommendation. We define the action-\(L\) as the actions that require additional libraries, and action-\(NL\) as actions without additional libraries. The inter-action container scheduler generates the lender containers images by re-packing the similar images in the following steps.

* **Collect information about all actions**. All the information about their libraries will be recorded, including the name and the version of libraries. For each action, by the user's \(Dockerfile\), additional installed libraries can be recorded in the format \(\{L_{n}\}=\{"lib_{1}":"version","lib_{2}":"version"\}\). In some cases when users do not declare the version of libraries, the interaction container scheduler will take the latest version as default. But it will bring in the hazard of libraries version contradiction. For example, if \(user_{A}\) requires \(lib_{1}\) with 1.0 version, while \(user_{B}\) requires \(lib_{1}\) with 2.0 version, neither can lease the other's containers because of the version contradictions.
* **Create a vector to hold the libraries of each action**. For each lender action, the scheduler first filters the actions with common libraries with the lender action as the candidate actions. It then checks whether the libraries in the candidate actions are inconsistent with that in lender action (e.g., version contradiction). In that case, it will be removed from the candidate actions. Finally, the scheduler takes the union set of the libraries both in the lender action and rest candidate actions to form a libraries vector for distance calculation.
* **Calculate the cosine distance between the lender action and the candidate actions as the similarity**. The filter logic is to select the top \(n_{L}\) values of all the similarities and then take the corresponding actions as renters. If no candidate actions exist (for example, action-\(NL\) is selected as lender action), \(n_{L}\) action-\(L\)s without version contradiction will be added in random to be the renters. Besides, a number \(n_{NL}\) of action-\(NL\)s will also be selected in random as renters.

Therefore, up to \(n_{L}\) action-\(L\)s and \(n_{NL}\) action-\(NL\)s will be selected as renters, and the inter-action container scheduler will wrap the renters' additional libraries into the image of the lender action. Meanwhile, the renters' code files will also be re-packed by \(code\ encryption\) module for safety. \(n_{L}\) and \(n_{NL}\) are hyper-parameters and obviously their values affect the re-packing overhead and time. Their values should be set according to (6), in which case all actions can get chances to be re-packed in lender containers.

\[n_{L}=\min\{\frac{num(action-Ls)}{size(renter\ pool)}\},n_{NL}=\min\{\frac{num( action-NL)}{size(renter\ pool)}\} \tag{6}\]

Figure 6 shows the re-packing operations along timeline. The inter-action container scheduler re-packs the lender containers images based on the data collection Image re-packing. The time cost in lender re-packing is hard to measure due to the uncertainty of the libraries vector cardinality. With no doubt that higher cardinality, i.e., more libraries for re-packing, indicates longer re-packing time. But the re-packing phase for each lender action usually takes less than 10s for most actions according to our experiments. After re-packing, the images are committed to different intra-action container schedulers for creating lender containers. The overhead depends on the number of additional libraries to be installed. If some libraries take a relatively long time to re-pack, users will resort to submitting a virtual environment [9] or custom container image [10] to avoid the long installation time. In this case,

Fig. 6: Timeline of Pagurus operations.

Pagurus will adopt traditional CRIU to generate the containers, instead of re-packing.

The inter-action container scheduler deals with creating and updating of the re-packing image, while the intra-action container scheduler is responsible for managing the container pools, e.g., starting an executant container from default image, generating the lender container from the re-packed image. Unless the re-packed image is updated, the container only boots from it for the first time, and any subsequent container will use CRIU to accelerate the startup. The _renter container check_ module is designed to make sure that the runtime and libraries in the intra-action container scheduler are consistent with that in the inter-action container scheduler when performing the container re-packing.

### _Security Guarantee_

In Pagurus, as a lender container may be shared by several renter actions, a natural and inevitable concern is on the security of lender container. Meanwhile, as the code files of renter actions need to be re-packed in the shared container, the renters' security cannot be ignored.

For lenders' security guarantee, Pigurus explores the stateless nature of serverless computing to clean up user code and cache of the lender container before re-packing a lender image. No renter action can get any previous information about the action with the lender container. For renters' security guarantee, Pigurus encrypts the renter action's code file by module \(code\ encryption\) first before re-packing to prevent code disclosure. The code encryption is divided into two parts. First, to protect the privacy of the users' files name, Pagurus adopts a renaming strategy by renaming code files uniformly such as \(\_main\_py\), as adopted by OpenWhisk [11]. Then, the environment folder for user actions will be encrypted into a ZIP file with the user password. Secondly, when a lender container is generated, all the renters' code files will coexist in this container. In this case, all the renters' folders need to be encrypted with inter-action container controller specified password to protect the renters' privacy and code security in the lender container. It should be noticed that the cleanup and code decryption are executed in inter-action container scheduler, and therefore neither side can get any information about each other.

In conclusion, although Pagurus weakens the level of isolation, the code security and privacy required by isolation are still ensured and satisfied. Using encryption to secure data and files in cloud computing is quite common in practice [20, 23, 37]. So it is acceptable for actions to adopt encryption to address the security concern in container sharing.

## VI Inter-action Container Management

In this section, we describe the steps of creating lender containers from idle containers, and using the borrowed container to run an action.

### _Generating a Lender Container_

If an executant container of an action is identified to be idle, its intra-action container scheduler will generate a _lender container_ from the re-packed image returned by the inter-action container scheduler. Figure 7 shows the detailed workflow of generating a lender container.

As shown in Figure 7, the executant containers of an action periodically feedback their status to the intra-action container scheduler. Based on the status of each container, the intra-action container scheduler identifies the redundant idle containers. Once an idle container is identified from the executant containers, the intra-action container scheduler re-packs the idle container to be a lender container (Step 2.1 and Step 2.2). In more detail, the idle container is deleted from the executant container pool, and the corresponding lender container is added to the lender container pool. This information is then feedbacked to the intra-action container scheduler (Step 3.1 and 3.2), so that the scheduler is aware of the change. In the last step, the intra-action container scheduler informs the inter-action container scheduler of the change (Step 4). In this way, other actions are able to borrow the container through the inter-action container scheduler.

### _Renting a Container from Other Actions_

When an action _ACT_ needs a container to run but there is no free warm container for it, its intra-action container scheduler submits a rent request to the inter-action container scheduler. If there exists such lender container that is already prepared for _ACT_ by other actions, the container is changed to be a _renter container_ of _ACT_, and is put in the _renter container pool_ of _ACT_. Figure 8 shows the detailed steps of renting a container from other actions.

Among these steps, it is crucial to guarantee the lender's container delivery and ensure the information safety of the

Fig. 8: The steps of Action_B rents a container from Action_A.

Fig. 7: Generating a lender container from an idle executant container.

lender. In Step 3, the inter-action container scheduler deletes the code and data of \(action_{B}\), as well as the other renters' code file in the lender container, and deciphers the code file of \(action_{A}\). Then inter-action container scheduler will inform \(action_{B}\) and \(action_{A}\) to prepare for container transferring (Step 3.1 and Step 3.2). Once \(action_{A}\)'s intra-action container scheduler receiving return container status, it will schedule this lender container to its renter container pool (Step 4.2) and \(action_{B}\)'s lender container pool will clear related status and information (Step 4.1). Meanwhile, the management privilege of the lender container is transferred from \(action_{B}\)'s intra-action container scheduler to \(action_{A}\)'s intra-action container scheduler.

The code cleaning of \(action_{B}\) and the code decryption of \(action_{A}\) are executed in parallel. While the overhead of cleaning is less than the time cost of code decryption, the overhead of code cleaning is hidden from users.

Based on Section VI-A and VI-B, we can summarize the state transitions for three different containers in Figure 9. The action is executed in the executant container by default, and all cold startup containers are managed in the executant container pool. Lender container is transformed from an idle executant container identified by its intra-action container scheduler to a shared container re-generated from the re-packed image. Renter container inherits from other actions' lender container to make queries get executed without container cold startup. All these containers will keep running until timeout to be recycle.

### _Recycling Containers in Different Pools_

In serverless computing, when the load of an action drops, some warm containers for the action are recycled to save resources. Recycling is done by monitoring the status of the containers. If a container does not receive new requests for a time period (60s in OpenWhisk), the container is recycled. The recycling is only done by setting a timeout period for each container. If a container does not operate in the timeout period, the container will be recycled. This recycling policy is not able to be used in Pagurus directly as there are three types of containers in Pagurus.

Therefore, we design a priority-based recycle strategy for Pagurus. In this strategy, the inter-action container scheduler manages the recycling of all its containers, including executant containers, lender containers, and renter containers. For an action, Pagurus recycles the renter containers before all the other containers, and recycles lender containers after all the containers. The design philosophy here is that an action does not need extra rent containers when its containers tend to be recycled. Figure 10 shows the order of recycling containers when the load of an action drops.

Specifically, we set different timeout periods for the three types of the containers. The renter container pool has the minimum timeout period (\(T1\) in Fig. 10). The executant container does not store information and libraries for other actions, the container recycle does not affect the scheduling of the intra-action container scheduler. The timeout period of executant containers (\(T2\) in Fig. 10) is slightly larger than the timeout period of the lender containers. Because the lender containers re-pack additional libraries for multiple actions, even if executant and renter containers are all recycled, it can also meet the invocation of the action. For the above reasons, the lender containers have the maximum timeout period (\(T3\) in Fig. 10).

In our current implementation, we set the timeout periods for the renter containers, executant containers, and lender containers to be 40s, 60s, and 120s by default.

## VII Evaluation of Pagurus

In this section, we first evaluate the performance of Pagurus in reducing the end-to-end latencies of applications when there is no warm containers for them. Then, we discuss the possibility of Pagurus in eliminating the cold startup, the effect of Pagurus in supporting bursty load, and its effect in integrating with the orthogonal techniques.

### _Experimental Setup_

In the experiment, we evaluate Pagurus based on a 2-node cluster described in Section III-A. In the 2-node experimental cluster, they serve for inter-action container scheduler re-packing. Although we only use a small scale cluster in this section, Section IV reveals the situation in large scale Clouds while serverless computing platforms often manage the containers on each node independently. While containers are in the process context, containers are not supposed to be migrated to other nodes in most cases.

Fig. 11: The configurations of actions running in the background.

Fig. 10: Recycling the three types of containers.

Fig. 9: The state transition diagram of three containers.

We use representative serverless computing benchmark suites FunctionBench [27] and Faas-profiler [34] to evaluate Pagurus. Table II lists the used benchmark workloads. In the following experiment, we set the maximum number of containers in the renter pool to be 2 and randomly run two benchmarks in the background with high loads to simulate the real-system situation. To better understand the background configuration, we make a schematic diagram, as shown in Figure 11. In a real system, there are some long-running services and some occasional queries on the same serverless computing platform, and the services running in the background are also uncertain. So there are total \(C_{11}^{2}=55\) combinations of experimental configurations for Pagurus when we randomly select two benchmarks to be the lender. In each experimental configuration, we run each benchmark for 100 times by invoking the benchmark once every 60 seconds. In this way, the benchmark suffers from the cold container startup in all the 100 tests. In the following experiment, we collect the end-to-end latencies of the 100 tests for each benchmark based on the above experimental setup.

### _Reducing End-to-end Latency_

We show the effectiveness of Pagurus in reducing the end-to-end latency of a benchmark in this subsection. In this experiment, for each benchmark, we randomly select two of the other 10 benchmarks to be the lenders in the background for Pagurus. We compare Pagurus with Apache OpenWhisk [5] and the restore-based method [7]. OpenWhisk creates a new container for a benchmark from the corresponding container image and startups the new container. Restore-based method stores the checkpoint of the container in the memory, and restores the checkpoint from the main memory when needed.

Figure 12 shows the end-to-end latencies of the benchmarks with OpenWhisk, Restore-based method, and Pagurus. In the figure, the "optimal" reports the latencies of the benchmarks when they get warm containers directly. As shown in the figure, all the benchmarks achieve the shortest end-to-end latencies with Pagurus compared with OpenWhisk and Restore-based method. In the best case where actions get lender containers, Pagurus reduces the end-to-end latencies of the benchmarks by 75.6% and 51.9% compared with OpenWhisk and the restore-based method respectively. When compared to the optimal scenario, Pagurus only introduces 0.48% longer end-to-end latency on average.

Pagurus greatly reduces the end-to-end latencies because it schedules the idle shared containers to speed up the actions that may suffer from cold container startups. If an action query is hosted in a shared container, the container startup phase for the query is skipped and only the user-specific code initialization is needed. According to our measurement, Pagurus schedules a lender container to a query in less than 15us, and completes the container cleaning and application-specific code initialization in less than 10ms.

The restore-based method is also able to reduce the end-to-end latencies of the benchmarks compared with OpenWhisk. This is mainly because it eliminates the overhead of creating the new container images. However, it consumes large memory space and still results in longer end-to-end latencies of the benchmarks compared with Pagurus.

### _Eliminating the Container Cold Startup_

It is possible that there is not a renter container for an action. For an action, the extra libraries (software libraries) it packs determine the probability that it will skip a cold startup. The probability of eliminating the cold startup is an important indicator that reflects the effectiveness of Pagurus.

In this experiment, for each benchmark, we run it in \(C_{10}^{2}=45\) experimental setups. For each setup, we select 2 out of the 10 benchmarks as the renters. Figure 13 shows the percentages of the \(C_{10}^{2}=45\) setups in which the benchmarks skip the cold container startup.

Observe from Figure 13, Pagurus eliminates all the cold container startup for _dd_, _fop_, _lp_, _mm_, _cdb_ and _clou_, because these benchmarks can always rent containers from the lenders. They can always find the lenders because these benchmarks do not require additional libraries to initialize the software environment. In this case, the container re-packing algorithm is able to pack the redundant idle containers of any actions to be its renter containers.

For the benchmarks that require extra libraries (_img_, _vid_, _kms_, _mr_, and _md_), the possibility of eliminating the cold startup depends on the libraries similarity of the lender actions and renter actions. The more common and popular the additional libraries required in the action, the higher the probability that it will be re-packed by the lender actions. For instance, in 77.3%, 59.1% and 57.6% of the configurations, Pagurus eliminates the cold container startup for _vid_, _kms_, and _img_ respectively. This is because these benchmarks mainly use the shared _Pillow_ and _sk-learn_ software packages. However, for _mr_ and _md_, due to the unpopular of packages they used, lender actions take lower priority to pack it in lender containers. The decision

Fig. 12: The end-to-end latencies of the benchmarks when they suffer from cold startup with OpenWhisk, Restore-based method, and Pagurus.

Fig. 13: The probability of eliminating cold startup with Pagurus.

leads to the relatively low probabilities (34.8% and 36.4%) of eliminating cold startup for _mr_ and _md_.

To better understand this problem, Figure 14 shows the heat map of the benchmark similarities in the container re-packing algorithm. In the figure, the very small square in row _vid_ and column _img_ represents the possibility that _vid_ serves as the lender for _img_ rental. The small square in the row _img_ and column _vid_ represents the possibility that _vid_ serves as the renter for _img_. Observed from the figure, all the benchmarks do not tend to re-pack containers for _mr_ and _md_. These results explain the reason that Pagurus shows a relatively low possibility in eliminating cold container startup for _mr_ and _md_. An alternative method to further resolve this problem is taking the prior knowledge into consideration. Another way is increasing the number of renters that each lender can choose.

It should be noticed that the heat map in Figure 14 is asymmetric, because the benchmarks rely on different software packages. Assume an action \(ACT_{1}\) relies on software packages \(lib_{1},lib_{2}\) and another action \(ACT_{2}\) relies on software packages \(lib_{1}\). In this case, the containers of \(ACT_{1}\) have all the packages for \(ACT_{2}\). At the same time, the containers of \(ACT_{2}\) only have half of the software packages for \(ACT_{1}\). The possibilities of re-packing the containers of \(ACT_{1}\) for \(ACT_{2}\), and re-packing the containers of \(ACT_{2}\) for \(ACT_{1}\) are different.

Renter containers can be used by multiple actions and not all the benchmarks can always skip the code container startup.

### _Integrating with Work on Reducing Cold Startup Time_

While Pagurus eliminates the container cold startup, it can be integrated with prior work proposed to reduce the container cold startup time. In this subsection, we integrate Pagurus with Restore-based method and Catalyzer [21] respectively, and report their performance. For each benchmark, we still run it in the 45 experimental setups. In each experimental setup, we launch the benchmark 100 times with an interval of 60 seconds. Figure 15 shows the average container startup time for each benchmark of the \(45\times 100=4,500\) tests.

Observed from Figure 15, _Restore+Pagurus_ reduces the average container startup time of the benchmarks by 43.4% on average compared with the original Restore-based method; _Catalyzer+Pagurus_ reduces the average container startup time by 12.2% on average compared with Catalyzer. Pagurus is able to further reduce the average container startup time, because it is able to totally skip the container startup phase for the benchmarks sometimes. Even if no appropriate lender container returns, Pagurus will not slow down the container startup. Therefore, Pagurus can be integrated with prior work to further reduce the average cold startup time.

Figure 16 shows the cumulative distribution of the end-to-end latencies of _mm_ and _img_ with _restore-based method_ and _Restore+Pagurus_. In the figure, "optimal" shows the latencies of the benchmarks when all the containers are warm. By integrating Pagurus with the restore-based method, the end-to-end latencies of all the 4,500 tests of _mm_ are greatly reduced. Meanwhile, 52.1% of the queries of _img_ show much shorter end-to-end latencies. In _mm_, action queries completely skip the container startup, thus overhead of cold startup is eliminated. While for _img_, about 52.1% of the action queries can eliminate cold startup overhead, the rest still have to experience the container startup phase with the restore-based method.

For Pagurus, we can observe a large discontinuity in Figure 16(b) as Pagurus helps most of the queries to skip the container startup phase to reduce the latency, and only a few of them still suffer from cold startup problem.

Traditionally, we can also integrate the prewarm startup (introduced in Section II) policy with these advanced container

Fig. 16: The cumulative distribution of the benchmarks’ cold startup end-to-end latencies in Pagurus and Restore.

Fig. 17: The average cold startup latencies of the benchmarks with prewarm startup policy. ’Prewarm for each’ means that each action can get one prewarmed container, and ’prewarm for all’ means all actions can initialize one specific container created from a common cache.

Fig. 14: The benchmark similarities in the container re-packing algorithm.

Fig. 15: The average cold startup latency when Pagurus is integrated with Restore-based method, and Catalyzer respectively.

startup techniques. From the Figure 17, we can observe that Pagurus still performs better than 'preamarm for all' method. It is because that the libraries in the specific prewarmed container may conflict with the user action. In this case, these specific prewarmed containers cannot be initialized, making user actions experience the cold startup. Even though the 'preamarm for each' method shows less end-to-end latency than Pagurus due to the prewarmed containers continuously running in the background, additional 2.75GB memory resources are required by it. So, although with comparatively high performance, 'preamarm for each' method is unpractical because of the extremely high resource usage.

### _Supporting Bursty Loads_

Traditional serverless platforms (e.g., OpenWhisk) fail to support bursty workload without causing QoS violation due to the long latency during the cold container startup. Pagurus is able to support the smooth process of the bursty workload of an action through the inter-action container sharing.

Figure 18 shows the supported bursty loads of the benchmarks without causing the QoS violation, when Pagurus allows the benchmark to rent 1 or 2 more containers. Observed from Figure 18, for all the benchmarks, Pagurus is able to support 3\(\times\) of the bursty loads if the benchmarks are able to rent 2 more renter containers from other actions. This is mainly because the overhead of renting containers from other actions is much lower than creating new containers.

Besides, Pagurus also reduces the consumed memory space to support the bursty loads of the benchmarks compared to OpenWhisk. To suppose the bursty load with OpenWhisk, a straightforward method is maintaining more warm containers. However, these containers consume large main memory space. On the contrary, with Pagurus, there is no need to launch additional containers to support the bursty loads. Figure 19 shows the size of the main memory space saved with Pagurus. As shown in the figure, Observed from the figure, in Pagurus, 0.25GB to 3GB of the memory is saved in the case of 1 renter container, and 0.5GB to 6.75GB of the memory in the case of 2 renter containers compared with OpenWhisk.

### _Overheads in Pagurus_

Table III shows the overheads introduced by Pagurus. As shown in the table, Pagurus incurs five types of overheads. In Pagurus, the lender container stores the renters' encrypted code files as an extra operation, and decrypt the corresponding renter's code file when eliminating cold startups. This approach only takes 4.3125KB of space to save information and less than 10ms to decrypt, which is far less than about 200ms of database transmitting. The operation of packing images is introduced in the generation of lender containers. The extra packed images experience creating by average 6.647s, and 485MB of space is allocated for storing. The preparation of lender containers is done asynchronously and does not result in the long end-to-end latency. Containers only need to boot from images for the first time. In other cases, containers get accelerated in startup by checkpoint files which takes average 332KB of space to store. Besides, the re-packed images and the checkpoint files will be recycled when the corresponding actions are not invoked.

The most important part of the overhead is the CPU usage when Pagurus re-packing containers. The experiment shows that when the inter-action container scheduler re-packs the container image for an action, the average CPU utilization on the node is only about 1.61%. After taking the communication and synchronization between nodes into account, the re-packing phase will consume about 2.4% of the CPU resource. If we limit the CPU usage of re-packing to less than 10% of the server, each node can re-pack container images for about 34 actions during the data collection in 1 minute. To conclude, the overhead incurred by Pagurus is negligible.

## VIII Conclusion

This paper presents Pagurus,a container management system for serverless to eliminate container cold startup by inter-action container sharing. We implement the design by introducing three unique container pools, _lender containers_, _executant containers_ and _renter containers_. The inter-action container scheduler cooperated with intra-action container schedulers in each action, enable containers scheduled between different actions to reduce container cold startup. The evaluation result shows that Pagurus can significantly eliminate the cold startup. Besides, Pagurus can also be integrated with several container technologies to minimize the container startup overhead of serverless computing.

Fig. 19: The size of the reduced memory usage to support the bursty loads with Pagurus compared with OpenWhisk.

Fig. 18: The supported bursty loads of the benchmarks with Pagurus.

## References

* [1]A. A. Barroso (2003) Jeffrey Dean, and Urs Holzle (2003) Web search for a planet: the google cluster architecture. IEEE micro (2), pp. 22-28. Cited by: SS1.
* [2]A. Barroso (2003) The tail at scale. Communications of the ACM56 (2), pp. 74-80. Cited by: SS1.
* [3]A. Barroso (2003) The tail at scale. Communications of the ACM56 (2), pp. 74-80. Cited by: SS1.
* [4]J. Dean and L. Andre Barroso (2013) The tail at scale. Communications of the ACM56 (2), pp. 74-80. Cited by: SS1.
* [5]J. Dean and L. Andre Barroso (2013) The tail at scale. Communications of the ACM56 (2), pp. 74-80. Cited by: SS1.
* [6]X. Dong, J. Yu, Y. Luo, Y. Chen, G. Xue, and M. Li (2002) Achieving secure and efficient data collaboration in cloud computing. In 21st IEEE/ACM International Symposium on Quality of Service, IWQoS 2013, Montreal, Canada, 3-4 June 2013, pp. 195-200. Cited by: SS1.
* [7]D. Du, T. Yu, Y. Xia, B. Zang, G. Yan, C. Qin, Q. Wu, and H. Chen (2020) Catalyster: sub-millisecond startup for serverless computing with initialization-less booting. In Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems, pp. 467-481. Cited by: SS1.
* [8]N. Gautam (2012) Analysis of queues: methods and applications. CRC Press. Cited by: SS1.
* [9]N. Gautam (2012) Analysis of queues: methods and applications. CRC Press. Cited by: SS1.
* [10]S. Hendrickson, S. Sturdevant, E. Oakes, T. Harter, V. Venkataramani, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dusseau (2016) Serverless computation with openLambda. login USENIX Mag.4 (14). Cited by: SS1.
* [11]T. Harter, B. Salmon, R. Liu, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dusseau (2016) SLACER: fast distribution with lazy docker containers. In 14th USENIX Conference on File and Storage Technologies, FAST 2016, Santa Clara, CA, USA, February 22-25, 2016, pp. 181-195. Cited by: SS1.
* [12]S. Hendrickson, S. Sturdevant, E. Oakes, T. Harter, V. Venkataramani, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dusseau (2016) Serverless computation with openLambda. login USENIX Mag.4 (14). Cited by: SS1.
* [13]E. Jones, J. Schleier-Smith, V. Sreekanti, C. Tsai, A. Khandelwal, Q. Pu, V. Shankar, J. Carreira, K. Krauth, N. Yadowadkar, et al. (2019) Cloud programming simplified: a berkeley view on serverless computing. arXiv preprint arXiv:1902.03383. Cited by: SS1.
* [14]J. Kim and K. Lee (2019) Functionbench: a suite of workloads for serverless cloud function service. In CLOUD, pp. 502-504. Cited by: SS1.
* [15]R. Koller and D. Williams (2017) Will serverless end the dominance of linux in the cloud?. In Proceedings of the 16th Workshop on Hot Topics in Operating Systems, HotOS 2017, Whistler, BC, Canada, May 8-10, 2017, pp. 169-173. Cited by: SS1.
* [16]A. Madhavapeddy and D. J. Scott (2014) Unixernels: the rise of the virtual library operating system. Commun. ACM57 (1), pp. 61-69. Cited by: SS1.
* [17]F. Manco, C. Lupu, F. Schmidt, J. Mendes, S. Kuener, S. Satti, K. Yasukata, C. Raiciu, and F. H. My (2017) VM is lighter (and safer) than your container. In Proceedings of the 26th Symposium on Operating Systems Principles, Shanghai, China, October 28-31, 2017, pp. 218-233. Cited by: SS1.
* [18]M. McGrath and P. R. Brenner (2017) Serverless computing: design, implementation, and performance. In 37th IEEE International Conference on Distributed Computing Systems Workshops, ICDCS Workshops 2017, Atlanta, GA, USA, June 5-8, 2017, pp. 405-410. Cited by: SS1.
* [19]E. Oakes, L. Yang, D. Zhou, K. Hucker, T. Carazza-Harter, A. C. Arpaci-Dusseau, and R. H. Arpaci-Dusseau (2018) SOCK: serverless-optimized containers. login USENIX Mag.43 (3). Cited by: SS1.
* [20]Q. Pu, S. Venkataraman, and I. Stoica (2019) Shuffling, fast and slow: scalable analytics on serverless infrastructure. In 16th USENIX Symposium on Networked Systems Design and Implementation, NSDI 2019, Boston, MA, February 26-28, 2019, pp. 193-206. Cited by: SS1.
* [21]M. Shahraud, J. Balkid, and D. Wentzlaff (2019) Architectural implications of function-as-a-service computing. In Proceedings of the 52nd Annual IEEE/ACM International Symposium on Microarchitecture, MICRO 2019, Columbus, OH, USA, October 12-16, 2019, pp. 1063-1075. Cited by: SS1.
* [22]V. Shankar, K. Krauth, Q. Pu, E. Jones, S. Venkataraman, I. Stoica, B. Recht, and J. Ragan-Kelley (2018) numpyR serverless linear algebra. CoRRabs/1810.09679. Cited by: SS1.
* [23]Z. Shen, Z. Sun, G. Sela, E. Bagdasaryan, C. Delimitrou, R. van Renesse, and H. Weatherspoon (2019) X-contanures: breaking down barriers to improve performance and isolation of cloud-native containers. In Iris Bahar, M. Herlihy, E. Witchel, and A. R. Lebeck (Eds.), Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems, ASPLOS 2019, Providence, RI, USA, April 13-17, 2019, pp. 121-135. Cited by: SS1.
* [24]W. Tai, Y. Chang, and W. Huang (2020) Security analyses of a data collaboration scheme with hierarchical attribute-based encryption in cloud computing. I. J. Network Security22 (2), pp. 212-217. Cited by: SS1.
* [25]J. Thalheim, P. Bhatotia, P. Fonseca, and B. Kasicki (2018) Cntr: lightweight OS containers. In 2018 USENIX Annual Technical Conference, USENIX ATC 2018, Boston, MA, USA, July 11-13, 2018, pp. 199-2112. Cited by: SS1.
* [26]E. Tilevich and H. Mossenbock (2018) editors. Proceedings of the 15th International Conference on Managed Languages & Runtimes, ManLang 2018, Linz, Austria, September 12-14, 2018. Cited by: SS1.
* [27]R. Sarpangala Venkatesh, T. Smejkal, D. S. Milojcicic, and A. Gavrilovska (2019) Fast in-memory cru for docker containers. In Proceedings of the International Symposium on Memory Systems, MEMSYS '19, New York, NY, USA, pp. 53-65. Cited by: SS1.
* [28]M. Vrable, J. Ma, J. Chen, D. Moore, E. Vandekieff, A. C. Snoeren, G. M. Voelker, and S. Savage (2005) Scalability, fidelity, and containment in the potemix virtual honeyfarm. In Proceedings of the 20th ACM Symposium on Operating Systems Principles 2005, SOSP 2005, Brighton, UK, October 23-26, 2005, pp. 148-162. Cited by: SS1.
* [29]K. Wang, R. Ho, and P. Wu (2019) Replayable execution optimized for page sharing for a managed runtime environment. In Proceedings of the Fourteenth EuroSys Conference 2019, Dresden, Germany, March 25-28, 2019, pp. 39:1-39:16. Cited by: SS1.
* [30]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [31]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [32]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [33]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [34]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [35]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [36]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [37]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [38]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [39]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [40]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [41]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [42]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [43]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of serverless platforms. In ATC, pp. 133-146. Cited by: SS1.
* [44]L. Wang, M. Li, Y. Zhang, T. Ristenpart, and M. Swift (2018) Pecking behind the curtains of

Title: Where Do You Want To Invest? Predicting Startup Funding From Freely,
  Publicly Available Web Information
Transcription: [MISSING_PAGE_FAIL:1]

ML frameworks we have investigated. Then in Section 5, in order to illustrate the effectiveness of the proposed approach, we present a set of experiments. We also report and analyze, in the same section, the results of experiments. Finally, Section 6 concludes the paper.

## 2. Related Work

As explained in Section 1, the pace at which startups are created and the impact that they have on economy is both new and important, and relatively few studies have investigated the problem of predicting the trajectories of startups. The work presented in (Steintein et al., 2017) is perhaps one of the first attempts to dive into the field of using predictive models for assessing the "success" of companies. In that work, the authors explore the prediction of Merger & Acquisition (M&A) as a metric to examine if a company should be categorized as successful or not. To do that, they consider news pertaining to companies and individuals on TechCrunch. The input space defined in this paper includes company-specific features, such as managerial and financial features, combined with topic-dependent features which have been extracted via Latent Dirichlet Allocation (LDA).

In a relatively similar work, Hunter et al. (Hunter et al., 2017) proposed to construct a portfolio of startups in which at least one startup achieves an exit, _i.e._ either gets Initial Public Offering (IPO) or is acquired by another company. The data studied in this work is principally taken from three sources: CrunchBase2, Pitchbook3 and LinkedIn. Starting from a Brownian motion model, the authors propose to use a greedy approach to solve the "picking winners" problem. Our work differs from these two studies in that, firstly, the objective that we follow is basically prediction of funding events. Secondly, and more importantly, the data we use to train our models is publicly available, unlike LinkedIn data or VC databases, and comes from verified sources, _i.e._ the startups themselves, while datasets like TechCrunch can be edited by anyone.

Footnote 2: [https://www.crunchhase.com/](https://www.crunchhase.com/)

Footnote 3: [https://pitchbook.com/](https://pitchbook.com/)

Footnote 4: [https://angel.co/](https://angel.co/)

Over the past decade, social media, in particular Twitter, have been extensively used in building ML models. Event detection, sentiment analysis and success prediction are only a few examples of Twitter-based models (Hunter et al., 2017; Hunter et al., 2017; Hunter et al., 2017). Likewise, in our context, as mentioned in (Bauer et al., 2017), Twitter can play a crucial role in survival or failure of new ventures. Given the fact that tweets are publicly available and, if written by the company itself, are usually reliable sources of information, they can be used to predict the evolution of startups.

One such study that investigates the role of social media on the success of companies is (Steintein et al., 2017). Therein, it is shown that the social engagement of a startup, like the number of tweets and the number of followers, has a significant correlation with its success in receiving crowdfunding. The authors further argue that, since crowdfunding is rather a new fundraising technique in which the traditional face-time approach with investors does not practically exist, the activity of a startup on social media such as Facebook and Twitter heavily boosts the odds of receiving crowdfunds. In that paper, AngellList4 (a crowdfunding investment platform), Facebook and Twitter were chosen as data sources, where AngellList has been used to identify the startups which received crowdfunds. To select startups, the authors picked 4001 startups, on a snapshot of 744K, which were actively fundraising, where, after data cleaning, only 271 startups, with 11 positives, were kept to perform prediction. The data being highly imbalanced, a wide range of techniques, such as (Hunter et al., 2017; Madsen et al., 2017; Madsen et al., 2017), combined with a greedy feature selection algorithm were used in order to train models with better true positive rates (TPR). Through an extensive analysis, it is shown that the method presented in (Steintein et al., 2017) can reach an accuracy of 84% in predicting crowdfunding events. Compared to (Stein et al., 2017), the present study not only exploits social media data, but also uses a series of other features to perform the fundraising prediction. As it will be shown in Section 5, these features increase the prediction performance in a significant manner.

Footnote 4: [https://www.cranchhase.com/](https://www.cranchhase.com/)

In a more recent study and following the same line, Sharchilev et al. (Sharchilev et al., 2017) proposed a method, named Web-Based Startup Success Prediction (WBSSP), for startup success prediction. This paper is perhaps the most relevant study to ours in the literature. The goal of (Sharchilev et al., 2017) is to predict, within a period of time in the future, if a startup which already secured seed funding will get further rounds of funding or not. Their source of data, as the studies mentioned above, is CrunchBase, LinkedIn and the web. To construct the model, the authors define a feature space which is further decomposed into four categories: general, investor, team and mentions on the web. They showed that the last category, _i.e._ web-based mentions, boost the prediction performance in their proposed pipeline. In order to avoid overfitting, the learning algorithm is designed by grouping the features into sparse and dense features. The features are then passed through a set of learning methods which are then fed into a boosting method (CatBoost (Talaldi et al., 2016)) in order to obtain the final prediction results. Eventually, the authors discussed a set of research questions, particularly the importance of each category of features and the effect of treating the sparse features differently than the dense ones.

The present work differs from (Sharchilev et al., 2017) in two important aspects: first, we rely on features that can be extracted from freely, publicly available information that does not require costly, manual development and maintenance, second, we rely on simple machine learning models that can be easily implemented and reproduced. Overall, the features we rely on are simpler to extract, the prediction models we use easier to develop and the results we obtain at least as good as the ones presented in (Sharchilev et al., 2017).

## 3. Data Collection

In this section, we describe in detail the process of collecting the data required to solve the prediction task. The first step in this process is to build a list of the startups for analysis, along with the links to their websites. To do that, one can use any sufficiently large list of startups available on the web. In our case, we gathered 22K startups from multiple sources, such as hubs, investors and conferences, across the world. Once having collected the list of the startups websites, we extract information from the following sources:

* Startup's own website,
* Twitter API5, Footnote 5: [https://developer.twitter.com](https://developer.twitter.com)
* Google search API6, Footnote 6: [https://developers.google.com/](https://developers.google.com/)* Country-specific registration data on companies (_e.g._ Infogr-effe 7) containing information about firms, such as the office locations and number of employees.8

Footnote 7: [https://www.infogreffe.com](https://www.infogreffe.com)

Footnote 8: The complete list can be found in the Appendix A.

Distinguishing feature of our dataset is its geographical variety of the companies. While most of the previous works focus on the startups from the USA[16, 41], we analyze the startups all across the world with a slight focus on Europe. Figure 1 illustrates the distribution of top-10 countries in our dataset.

### Features

Once the data from the above sources has been collected, one need to extract a proper set of features in order to define a space where the prediction task can be done efficiently. Below, we describe four categories of features that we extracted, along with the intuitions behind, from the web for the purpose of startup success prediction.

#### 3.1.1. General features

The following features are considered as the core information about startups:

* Country of origin,
* Age,
* Number of employees,
* Number of offices,
* Number of people featured on Team page of startup's website.

Importance of these features for the task of fundraising prediction is quite obvious: venture's evolution in different countries varies. Age as well as the number of employees and offices characterize different stages of startup evolution and the properties of fundraising process strongly depend on the stage of the venture.

The country of the startup's origin is extracted from the address pages on the company website. We use statistical methods to infer which country is the most likely the country of the company. To do that, we employ regular expressions to extract phone numbers (via country codes), then simply look around the phone number, in a fixed window size, to find the country. The country with the most occurrence is then taken as the country of origin and (in case of ties no country is selected).

To infer the age of the startup, we simply use its creation date. Most countries give public access to a registry of all companies, in which one can usually find the creation date. Another heuristic we use is to infer the creation date from the dates of the creation of different media from the company: website and the social media. In case of different creation dates identified by the two previously mentioned sources, the older date is taken as the creation date. According to our observations, in the context of startups, this is in most cases a very good approximation of creation date: in 28% of cases, it return the correct creation date and in 72% of cases, it returns a creation date with maximum of two years shift.

The number of people featured on Team page of startup's website is extracted as follows: usually the team page follows a repeating template containing information about every person (name, role, social media links, picture, etc). We find and extract this repeating template and then use statistical methods to verify that it corresponds to people names, job functions, etc. Finally, information about the number of employees and offices is extracted from the country-specific databases.9

Footnote 9: [https://yandex.ru](https://yandex.ru)

#### 3.1.2. Financial features

History of startup's previous funding rounds is evidently an important factor for predicting future fundraising as different fundraising rounds happen usually with similar patents w.r.t. the previous rounds secured by the startup. The process of detecting funding events for startups is described in Section 3.2. In this work, we propose to extract the following features to summarize the financial history of a startup:

* Total number of previously secured funding rounds,
* Last fundraising amount,
* Mean and maximal amount of previously secured rounds,
* Time since the last secured round.

#### 3.1.3. Google search results features

In [36], the authors have shown that a highly useful set of features for the task of the startup success prediction can be extracted from crawling of the observable web for the startup presence. For the purpose of extraction of these features, the authors analyze the data from Yandex10, a major Russian search engine. For each startup, they count the number of references to the startup's website on the webpages from different domains. This data, however, is not easily accessible by ordinary web users.

Footnote 10: [https://cloud.google.com/free/docs/gcp-free-tier](https://cloud.google.com/free/docs/gcp-free-tier)

Accordingly, in the present study, similar information using more widely available tools has been extracted, in particular Google search API. For each startup, search results with a date within a year preceding the start of _prediction period_ have been analyzed. Given a startup name and a date range, a query to Google API is made and irrelevant results were filtered in order to perform the analysis of domains frequencies similar to [36]. In order to exclude irrelevant results, we check whether the snippet of a search result contains the startup's name or not. Since the purpose of this work is to build models with entirely free tools, we constrain ourselves to the amount of queries available with the Google Cloud Platform Free Tier 11. Therefore, we obtain only top 10 results for a given startup name and a date range. The following statistics are then extracted form these search results:

Footnote 11: [https://cloud.google.com/free/docs/gcp-free-tier](https://cloud.google.com/free/docs/gcp-free-tier)

* Number of relevant results: we assume that result is related to startup only if a snippet of result contains the startup's name,

Figure 1. Geographical distribution of the top-10 countries in our dataset.

* Total number of results as reported by Google,
* Number of search results from each of 500 domains _popular_ domains.

For the latter, we simply sort all the domains appearing in the results based on the number of times they contain the name of startups under investigation. We then take the top 500 domains. The intuition is to take the domains which are more likely to talk about startups and, as a result, reduce the amount of noise in our feature space.

#### 3.1.4. Social networks presence features

Over the last two decades, the impact of social networks on different social, economic and political processes became remarkable. Given the fact that for a startup it is crucial to reach the potential audience via social media, this category of features can heavily impact the prediction performance. One can note such impacts in the investigations done in the literature such as (Krishna et al., 2016) which highlighted the importance of social media presence for a crowdfunding success of a startup. We use here, first, a set of social media features that are binary and indicate whether a startup has an account in several popular social media:

* Facebook,
* Instagram,
* Linkedin,
* YouTube,
* Twitter,
* Blog on the startup own website.

This information is extracted with a simple script that searches for social network buttons on a website of a startup. The second set of features extracted from social media corresponds to statistical information of a startup's website:

* Number of people that give reference to their Linkedin account on the team page of the startup,
* Number of entries in blog during the last year.

These two features indicate the willingness of the startup to appear in the social media and to be visible and followed by others.

Because of the important presence of startups on Twitter and since information from Twitter is readily available (contrary to other social media like Facebook and LinkeIn), we also extract features that describe the activity of each startup on this particular social media in the year the precedes the year for which funding events are predicted:

* Aggregated monthly startup's Twitter account statistics for the last year including: number of posted tweets, mean/max number of likes and retweets of user's tweets; modal language of user tweets,
* total number of different users that mention startup's account in their tweets during the last year,
* Information about _hashtags_ used by the startup: _a_) for all startups, we collect their last 2300 tweets from which we establish a list of the 500 most frequently used hastags; each startup is then represented as a 500-dimensional vector the dimensions of which correspond to the number of times the startup used the hashtag during the last year.

Table 1 summarizes the features explained above. The type of each feature (categorical or numerical) as well as its nature (sparse or dense) are also illustrated in the two rightmost columns.

### Data labeling

Another challenge in solving the task of predicting startup success from open sources is labeling the data. While commercial databases often contain dates of funding events where amounts are usually extracted manually by human experts, we aim to automatically detect startups fundraising from news and Twitter. For this purpose,

Tuple 35:
Cleaned Title: startphase control distributed system written erlangotp
Cleaned Transcription: startphase control distributed system written erlangotp peter burcsi eotvos lorand university faculty informatics department computer algebra email attila kovacs eotvos lorand university faculty informatics department computer algebra email antal tatrai eotvos lorand university faculty informatics department computer algebra email footnote email abstract paper present realization reliable fast startup distributed system written erlang traditional startup provided erlangotp library sequential parallelization usually requires unsafe adhoc solution proposed method call slight modification erlangotp stdlib applying system dependency graph make startup safe quick equally easy use newly developed legacy system key word phraseserlang parallel startup content introduction distributed system usually collection processor may share memory clock processor local memory processorsin system connected communication network communication take place via message form message include function invocation signal data packet computation based model message passing include actor model process algebra several aspect concurrent system written message passing language studied including garbage collection heap architecture memory management startup concurrency area fully covered yet investigation startup phase important system performance testing system frequently started stopped fast startup might beneficial critical distributed system often maintainability requirement availability also known five nine order comply five nine requirement course year total boot time could take minute practice due maintenance process every system planned time case fast reliable startup must startup time reason study startup phase product line requirement therefore code alter continuously change may influence code structure may affect execution order part although code often reloaded without stopping system change may influence startup challenge give generic solution support reliable robust fast startup even software andor hardware part system changed paper focus distributed programming language erlang erlang designed telecommunication company ericsson support faulttolerant system running soft realtime mode program erlang consist function stored module function executed concurrently lightweight process communicate asynchronous message passing creation deletion process require little memory computation time erlang open source development system distributed kernel erlang system set library provide building primitive larger system include routine io file management list handling practice erlang often used together library called open telecom platform otp otp consists development system platform building control system platform running telecommunication application set design principle behaviour together middleware application yield building block scalable robust real time system supervision restart configuration mechanism provided various mechanism like orb facilitate development corba based management system interface towards language include java interface interface allowing erlang program call c module etc interface complemented possibility defining idl interface code generated number erlangotp application library continuously increasing example snmp agent fault tolerant http server distributed relational database called mnesia etc one largest industrial application developed erlangotp axd carrierclass multiservice atm ip framerelay etc switching system ericsson robust flexible system used several place network developed year early announcement product see resulting long product line contains several thousand erlang module million line code startup erlang application performed traditional startup provided erlangotp library sequential designed start quickly possible special attention paid possibility parallelizing different operation performed startup order imposed due explicit dependency described application configuration file technically reason sequential startup process performing otp behaviour sends ack acknowledge signal parent whole initialization process finished mean process implicit precondition concurrent case maintaining precondition fundamental problem proposed solution enables concurrent startup provides erlangotp extension describing realizing precondition behaviour process hence startup fast remains reliable well use condition construct dependency graph manage order startup bear resemblance mechanism used apple macosx startupitems startupitem includes property list item providesrequiresuses item used systemstarter build soft dependency graph controlling order starting item exist mechanism erlangotp course startup time depend upon dependency among application degree startup activity parallelized startup time affected several factor probably significant disk io time latency time spent unnecessarily searching hardware element disk appropriate file load etc particular system measurement needed find time go startup paper focus particular system give instead general solution performing fast reliable startup erlangotp system mean dependency among application must given advance determined system designer paper structured follows completeness section contains basic description erlangotp feature concept section basic idea concurrent startup erlang application presented section deal detail proposed solution presenting prototype measurement performance prototype written section finally author write show conclusion section erlangotp section short description erlangotp concept given overview begin erlang language feature otp design principle startup mechanism discussed full description erlang many example author refer book online documentation code structure execution code written erlang structured follows function grouped together source file called module function used module exported module use must import alternatively use applymod fun arg builtin function modulenamefunctionname args form module together implement specific functionality form application application started stopped separately reused part system application provide program process structure usually directory structure well descriptor file application containing module name starting parameter many data belonging application release highest layer may contain several application complete system contains subset erlangotp application set userspecific application release describedby specific file called release resource file release resource file used generating bootscripts system creating package creating bootscript system able start first erlang kernel loaded specific genserver module applicationcontroller started module read application descriptor file sequentially creates process called applicationmaster application applicationmaster start corresponding application sends ack signal back start finished thus mentioned earlier erlangotp startup sequential central concept execution process erlang messageoriented executing erlang code mean creating strongly isolated process interact message passing process creation lightweight operation performed using spawn family function function create parallel process return immediately process id pid process created way say spawned erlang message sent form pidmsg received using receive design principle one useful feature otp predefined set design pattern called behaviour pattern designed provide easytouse application interface typical telecommunication application clientserver connection finite state machine order realize highly available faulttolerant system otp offer possibility structure process supervision tree supervision tree principal otp concept organize program execution tree process called supervision tree supervision tree node either worker leaf tree supervisor internal node worker erlang process perform functionality system supervisor start stop monitor child process supervisor node make decision error occurs supervision task generic specific part generic part responsible eg contact child specific part defines among thing restartingstrategy desirable worker uniform interface therefore otp defines several behaviour communication interface behaviour behaviour like every design pattern provide repeatable solution commonly occurring problem example large number simple server application share common part behaviour implement common part server code divided generic specific part generic part might contain main loop server waiting message specific part code contains server particular message arrives practice callback module implemented otp expects existence function eg handlecall module example several callback function implemented complete functionality application important one start stop let u summarize significant otp behaviour genserver genfsm genevent supervisor implement basic pattern genserver generic part server process genevent generic part event handling genfsm generic part finite state machine supervisor behaviour generic part supervisor node supervision tree callback module contains function initarg child working strategy node specified genserver behaviour also defines higher level function messaging synchronous call asynchronous cast message basic idea solution let u suppose erlang system plan make startup concurrent use spawn function instead builtin method supervisor childstarting spawned process run parallelly erlangotp supervisor monitoring mechanism one strongest erlangotp feature lost omitting ack mechanism builtin childstarting process would mean deep redesign reimplementation otp ack mechanism corresponds sequential childstarting also sequential start determines order process would vanish using naive way parallelization therefore alternative parallel ordering required avoid deadlock startup crash light previously mentioned property define guideline supervision tree structure well functionality must preserved startup must reliable fast faster sequential small modification permitted erlangotp stdlib dependency graph subsection consider dependence relation module introduce notion dynamic dependency graph order preserve supervisor tree structure define condition condition represent startup state module condition related module false module startup processed yet begin set true corresponding startup finished beginning startup condition false condition startup another module depends called precondition module process start precondition true represent relation dependency graph module corresponding condition vertex dependence module precondition directed edge graph behaviour module start instruction defined first user also first imply precondition first instruction module init function therefore verification precondition setting completed condition true insert immediately executing init function footnote remark sequential startup exist implicit precondition described hierarchy supervisor tree dependency graph widely used computer science example dependency graph applied startup mac osx operating system compiler optimization moreover dependency graph created erlang boot script generated given application however significant difference graph graph erlang software start different way different environment therefore module parameter execution dependency vary handled dynamically full performance order keep erlang robustness add one guideline dependency graph dynamic concurrent startup supervisor child also propose erlang trick enables starting process concurrent way set node start concurrently supervisor process mathsfs start child process mathsfw system start dummy wrapper node mathsfs instead dummy process mathsfs start simple function mathsfsmathsff call spawn function sends ack message back immediately parent mathsfs consequently next child mathsfw supervisor node mathsfs start far function mathsfsmathsff spawned function mathsff spawned function mathsff start process mathsfw attache dummy process mathsfs using supervisorstartchild function already started dummy process mathsfs run independently parallel part system ad figure inserting dummy supervisor node preserving supervisor restarting behaviour enabling fast parallel startup supervisor denoted square permanent process continuous border temporary process dashed border middle tree one see living process mathsfsmathsfw termination dummy function vantage method process w blocking precondition w waiting instead whole system figure show described supervision hierarchy start dummy supervisor node restart strategy set way crashing child result termination dummy supervisor thus connection w preserved following code fragment show concurrent startup supervisor child moduledummysuptree dummychildtreeid childspec spawndummysuptree childstarter treeid childspec ok self childstartertreeid childspec supervisorstartchildtreeid childspec ok startlinkchildspec supervisorstartlinkdummysuptree childspec initchildspec supflags oneforone ok supflags dummychildid dummysuptree dummychild self childspec temporary brutalkill worker dummysuptree genericserver solution prototype section give detail solution describing skeleton prototype discus implementation dependency graph erlang boot script supervisor init function stdlib module etc modified realization dependency graph dependency graph implemented module called releasegraph module implement export following function getconditions getpreconditions getconditiongroups getconditions function return list pair pair consists module name parameter condition name mod args conditionname note function tag mfa modulefunctionarguments triplet may omitted since always init function module function getconditions corresponds vertex dependency graph observe condition corresponds module together parameter rather module accordance dynamic dependency graph guideline general args parameter actual parameter value undefined latter case condition describes module startup arbitrary parameter getpreconditions function also give list element list following structure mod args conditionnames function corresponds edge dependency graph module init function called validity condition list must tested args parameter undefined meaning startup module parameter wait condition list become true third function facilitates management dependence relation huge system likely many condition condition organized group getconditiongroups function return list pair form conditiongroupname condition one use conditiongroupname instead condition defined list remark dependency graph necessarily connected module precondition module case definition corresponding condition superfluous module precondition consequently omitted return value getprecondition function let see example let two application app app given first server node controlled supervisor node another server second application wait complete startup ofthe first application possible implementation function might getconditions approotsup undefined condapprootsup genericserver appserver condappserver genericserver appserver condappserver genericserver appserver condappserver getconditiongroups groupappapp condappserver condappserver condappserver condapprootsup getpreconditions genericserver appserver groupappapp condition server startup controlled special server called conditionserver started erlang main system start store handle dependency graph user program also find load releasegraph module check validity data check mistypes existing condition name etc clearly error args field remains undiscovered args tag undefined dependency graph independent dynamic data case acyclic dependency graph assures deadlock free structure node precondition started concurrent way conditionserver performs following two task based dependency graph first set condition belonging ma true implemented setconditionma function second block caller process precondition satisfied implemented waitforconditionsma function function called generic part behaviour independently user program consequently conditionserver must implemented without genserver behaviour remark module dont precondition dont belong module precondition corresponding function call effect conditionserver module part erlang kernel module since erlang system startup several event handler server module started require access condition storage system modification supervisor behaviour startup concurrent system execution fork point must named case place supervisor node modified supervisor behaviour accepts extended child specification extension hold additional field sequential concurrent former case meaning child specification equivalent original one latter case supervisor node start child concurrently fork point remark modification supervisor behaviour clearly accepts original child specification following example show extended child specification appserver genericserver startlink appserver permanent worker genericserver concurrent generic part supervisor interprets concurrent child specification start dummy supervisor node proper parameter instead original child modification erlang system also necessary modify erlang behaviour callback init function called return successfully put modification genserver genevent genfsm supervisorbridge supervisor behaviour builtin utility create boot script start conditionserver automatically order start server new line inserted boot script second line following code segment show kernelprocessheartheartstart kernelprocessconditionserverconditionserverstart kernelprocesserrorloggererrorloggerstartlink implementation measurement fully implemented prototype described previous section implementation used otp extension extension based erlangotp rb version modification affected stdlibs v behaviour module namely genserver genfsm genevent supervisorbridge supervisor download prototype following url httpcompalginfeltehuprojectsstartuphttpcompalginfeltehuprojectsstartup described parallel reliable solution concurrent startup solution give welldefined interface handling dependency problem among concurrent starting module therefore preserve reliability mean reliability concurrent startup based dependency graph description user program following focus running time startup lack access large industrial application therefore created program measuring startup time several case simplicity dependence condition defined concurrent supervisor child starting performed measured program use modified erlangotp library making fast startup tested system genserver supervisor node genserver node perform timeconsuming resourceintensive computation init function measured system started sequentially concurrently time given second measurement performed five time figure show average measured value measurement performed smp machine amd dual core opteron ghz gb ram linux erlang otp rb three different system topology measured system deep process tree wide process tree random process tree deep process tree regular tree depth wide process tree regular tree depth random process tree generated using uniform distribution range number child node truncating tree level measured time needed system startup server supervisor started timer started erl shell called stopped last server supervisor started purpose created special application start server supervisor immediately performs illegal statement since node crash consequently erl terminates word measured time starting crashing erlang shell several way make system process tree concurrent tagged module start parallel speed startup depends number concurrent process deeper position fork point tree parallel thread created dummy supervisor therefore show running time function number concurrent thread function depth fork point figure show concurrent version surprisingly always faster sequential one case however concurrent startup two time faster sequential one figure startup speed sequential concurrent version second concurrent case put different number fork point different place process tree author created several concurrent case kind tree worst best case value represent slowest fastest concurrent startup time proper kind tree figure show startup speed function number fork point since processor dual core testbed surprising fold parallelism yield best result parallel process started one processor work processor performed whole startup case active process processor switch active process resulting serious overhead note however significant overhead measurement come time consuming part server init function figure show result depend depth fork point measured fall back performance node given level started parallel case system concurrent process deeper level one also observe version active process forking resistant depth case overhead come number dummy supervisor tree measurement suggests system forked close root possible figure startup speed second depending number running process set fork point level show depth fork point conclusion paper presented solution parallel startup erlang system gave general description solution measured startup time several case measurement show parallel startup much faster sequential hand solution provides welldefined mechanism controlling dependency relation among process resulting reliable system main advantage solution precise concise dependency handling preserving supervision tree structure dependency graph erlang module figure startup speed second depending depth fork point dependency graph dynamic le line modification stdlib disadvantage solution bad dependency graph could result deadlock system crash conclude solution highly capable parallelization erlang system startup case legacy system new development well acknowledgement author would thank lemon project httpslemoncseltehuhttpslemoncseltehu allowed u use project main computer measuring would also thank peter nagy ericsson telecommunication hungary answering question erlang otp research supported project tamopbkmr eotvos lorand university reference j armstrong making reliable distributed system presence software error phd thesis stockholm j armstrong r virding one pas realtime generational marksweep garbage collection proc iwmm international workshop memory management lecture note computer science j armstrong r virding c vikstrom williams concurrent programming erlang second edition prentice hall bell serviceoriented modelling service analysis design architecture wiley new generation atm switching system comput network open source erlang httpwwwerlangorghttpwwwerlangorg e johansson k sagonas j wilhelmsson heap architecture concurrent language using message passing proc ismm acm sigplan international symposium memory management pp k sagonas j wilhelmsson efficient memory management concurrent program use message passing sci comput programming horwitz rep use program dependence graph software engineering proc th international conference software engineering pp mac o x startup item httpdeveloperapplecomdocumentationmacosxhttpdeveloperapplecomdocumentationmacosx n lynch distributed algorithm first edition morgan kaufmann received august revised march title startup stanford university transcription missingpagefail academic startup spinoffs decade following startup academic spinoffs become extraordinary phenomenon great even wellknown analysis silicon valley startup show region home hightech firm firm created sharp decline thereafter university published analysis startup example mit stanford switzerland eth zurich epf lausanne analysis eesley claim active company trace root stanford company collectively formed independent nation estimated economy would world th largest extrapolating survey result company created estimated million job generate annual world revenue trillion report analyzes performance firm link stanford university information go section data end report course entrepreneurship technology company silicon valley particular stanford company hightech show figure also many firm service company product offering firm studied situation see appendix graphic overall hightech firm related information technology represent sample include firm selling hardware hw product semiconductor computer telecom equipment electronics well software sw including multimedia internet technology must mentioned internet service considered part software firm showing difficulty classifying firm domain activity figure stanford startup period foundation domain activitystatus firm firm eternal indeed life expectancy quite short zhang show half service nonservice firm died year creation third firm stopped activity surprisingly ratio increase time simplest explanation either bias database early year increase failure entrepreneurship fever accompanied internet development quarter acquired nonnegligible part gone public point total another third still private whereas tiny publicly quoted life expectancy firm private company figure show result overall average year cessation activity year acquired year going public public company time span represents year foundation ipo average hide however regular decrease stable value thereafter table appendix add information granular analysis field figure average time year exit figure status firm period foundation value creation value creation difficult analysis make private company company communicate number still exist little known disappear public company much easier analyze thanks document publish regular basis initial public offering ipo onwards inbetween relative value creation known company acquired disclosed value systematic analysis done public company well company gone public point transaction value also compiled publicly available public company public firm july following table describes feature former public company many firm going public addition existing public firm another gone acquired stopping activity becoming private next table compiles average value ipo month ipo value ipo sufficient describe value creation even value month also limited snapshot advantage giving usually accurate picture real value creation
Original Title: Start-phase control of distributed systems written in Erlang/OTP
Original Transcription: # Start-phase control of distributed systems written in Erlang/OTP

Peter Burcsi

Eotvos Lorand University

Faculty of Informatics

Department of Computer Algebra

email:

1

Attila Kovacs

Eotvos Lorand University

Faculty of Informatics

Department of Computer Algebra

email:

1

Antal Tatrai

Eotvos Lorand University

Faculty of Informatics

Department of Computer Algebra

email:

1

Footnote 1: email:

###### Abstract

This paper presents a realization for the _reliable_ and _fast_ startup of distributed systems written in Erlang. The traditional startup provided by the Erlang/OTP library is sequential, parallelization usually requires unsafe and ad-hoc solutions. The proposed method calls only for slight modifications in the Erlang/OTP stdlib by applying a system dependency graph. It makes the startup safe, quick, and it is equally easy to use in newly developed and legacy systems.

Key words and phrases:Erlang, parallel start-up

###### Contents

* 1 Introduction
* A distributed system is usually a collection of processors that may not share memory or a clock. Each processor has its own local memory. The processorsin the system are connected through a communication network. Communication takes place via messages [11]. Forms of messages include function invocation, signals, and data packets. Computation based models on message passing include the actor model and process algebras [4]. Several aspects of concurrent systems written in message passing languages have been studied including garbage collection [2], heap architectures [7], or memory management [8]. Startup concurrency is an area not fully covered yet.

Why is the investigation of the startup phase important?

* During system and performance testing, when the system is frequently started and stopped, fast startup might be beneficial.
* Critical distributed systems often have the maintainability requirement of 99.999 availability, also known as the "five nines". In order to comply with the "five nines" requirement over the course of a year, the total boot time could not take more than 5.25 minutes. In practice, due to the maintenance process, every system has a planned down time. In this case a fast and reliable startup is a must.
* The startup time is not the only reason to study the startup phase. In most product lines the requirements (and therefore the code) alter continuously. The changes may influence the code structure, which may affect the execution order of the parts. Although the code can often be reloaded without stopping the system, the changes may influence the startup. The challenge is to give a generic solution which supports reliable, robust and fast startup even when some software and/or hardware parts of the system had been changed.

In this paper we focus on the distributed programming language Erlang. Erlang was designed by the telecommunication company Ericsson to support fault-tolerant systems running in soft real-time mode. Programs in Erlang consist of functions stored in modules. Functions can be executed concurrently in lightweight processes, and communicate with each other through asynchronous message passing. The creation and deletion of processes require little memory and computation time. Erlang is an open source development system having a distributed kernel [6].

The Erlang system has a set of libraries that provide building primitives for larger systems. They include routines for I/O, file management, and list handling. In practice Erlang is most often used together with the library called the Open Telecom Platform (OTP). OTP consists of a development system platform for building, and a control system platform for running telecommunication applications. It has a set of design principles (behaviours), which together with middleware applications yield building blocks for scalable robust real time systems. Supervision, restart, and configuration mechanisms are provided. Various mechanisms, like an ORB, facilitate the development of CORBA based management systems. Interfaces towards other languages include a Java interface, an interface allowing Erlang programs to call C modules, etc. These interfaces are complemented with the possibility of defining IDL interfaces, through which code can be generated. The number of Erlang/OTP applications and libraries is continuously increasing. There are for example SNMP agents, a fault tolerant HTTP server, a distributed relational database called Mnesia, etc. One of the largest industrial applications developed in Erlang/OTP is the AXD 301 carrier-class multi-service (ATM, IP, Frame-relay, etc.) switching system of Ericsson. It is a robust and flexible system that can be used in several places of networks. It has been developed for more than 10 years (for an early announcement of the product, see [5]), resulting in a long product line. It contains several thousand Erlang modules and more than a million lines of code.

How is the startup of an Erlang application performed? The traditional startup provided by the Erlang/OTP library is sequential. It was not designed to start as quickly as possible, no special attention was paid to the possibility of parallelizing the different operations performed during startup. The only order imposed is due to the explicit dependencies described in the application configuration files. Technically, the reason of the sequential startup is that each process performing an OTP behaviour sends an ACK (acknowledge) signal to its parent only after the whole initialization process is finished. It means that each process has implicit preconditions. In the concurrent case, maintaining these preconditions is a fundamental problem. The proposed solution enables the concurrent startup and provides an Erlang/OTP extension for describing and realizing preconditions between behaviour processes. Hence the startup will not only be fast but remains reliable as well. The use of conditions to construct dependency graphs to manage the order of startup bears a resemblance to the mechanism used by Apple's MacOSX StartupItems. Each StartupItem includes a properties list of items that provides/requires/uses o-ther items, which are used by the SystemStarter to build a soft dependency graph controlling the order of starting items [10]. There does not exist any such mechanism in Erlang/OTP.

Of course, the startup times do not only depend upon the dependencies among the applications and the degree to which these startup activities can be parallelized. The startup times are affected by several other factors, probably the most significant being disk I/O times and latencies, the time spent unnecessarily searching for hardware elements, disks, appropriate files to load, etc. In a particular system measurements are needed to find where the time goes on for startup. In this paper we do not focus on a particular system, we give instead a general solution for performing fast and reliable startup in any Erlang/OTP systems. It means that dependencies among the applications must be given in advance. These can be determined by the system designers.

The paper is structured as follows. For completeness, Section 2 contains the basic description of Erlang/OTP features and concepts. In Section 3 the basic idea of the concurrent startup of Erlang applications is presented. Section 4 deals with the details of the proposed solution presenting a prototype. The measurements of the performance of our prototypes are written in Section 5 and finally the authors write a show conclusion in Section 6.

## 2 Erlang/OTP

In this section a short description of Erlang/OTP concepts is given. The overview begins with a few Erlang language features, then OTP design principles and the startup mechanism are discussed. For a full description of Erlang with many examples the authors refer to the books [1, 3] and to the on-line documentation [6].

### Code structure and execution

The code written in Erlang is structured as follows:

* _Functions_ are grouped together in source files called _modules_. Functions that are used by other modules are exported, modules that use them must import them. Or alternatively, have to use the apply(Mod, Fun, Arg) built-in function, or the module_name:function_name (args) form.
* Modules that together implement some specific functionality, form an _application_. Applications can be started and stopped separately, and can be reused as parts of other systems. Applications do not only provide program or process structure but usually a directory structure as well. There is a descriptor file for each application containing the module names, starting parameters and many other data belonging to the application.
* A _release,_ which is the highest layer, may contain several applications. It is a complete system which contains a subset of Erlang/OTP applications and a set of user-specific applications. A release is describedby a specific file, called release resource file. The release resource file can be used for generating boot_scripts for the system, and creating a _package_ from it. After creating a boot_script, the system is able to start. First, the Erlang kernel is loaded. Then, a specific gen_server module (application_controller) is started. This module reads the application descriptor files sequentially, and creates a process called application_master for each application. The application_master starts the corresponding application, and sends an ACK signal back when the start is finished. Thus, as it was mentioned earlier, the Erlang/OTP startup is sequential.

The central concept of the execution is the process. As Erlang is message-oriented, executing Erlang code means creating strongly isolated processes that can only interact through message passing. Process creation, which is a lightweight operation, can be performed using the spawn family of functions. These functions create a parallel process and return immediately with the process ID (Pid). When a process is created in this way, we say that it is spawned. Erlang messages are sent in the form Pid!Msg and are received using receive.

### Design principles

One of the most useful features in OTP is to have a pre-defined set of design patterns, called _behaviours_. These patterns were designed to provide an easy-to-use application interface for typical telecommunication applications such as client-server connections or finite state machines. In order to realize highly available and fault-tolerant systems, OTP offers a possibility to structure the processes into _supervision trees_.

#### 2.2.1 Supervision trees

A principal OTP concept is to organize program execution into trees of processes, called supervision trees. Supervision trees have nodes that are either _workers_ (leaves of the tree) or _supervisors_ (internal nodes). The workers are Erlang processes which perform the functionality of the system, while supervisors start, stop, and monitor their child processes. Supervisor nodes can make decisions on what to do if an error occurs. Supervision tasks have a generic and a specific part. The generic part is responsible e.g. for the contact with the children, while the specific part defines (among other things) the restartingstrategy. It is desirable that workers have a uniform interface, therefore OTP defines several behaviours with the same communication interface.

#### 2.2.2 Behaviours

Behaviours, like every design pattern, provide a repeatable solution to commonly occurring problems. For example, a large number of simple server applications share common parts. Behaviours implement these common parts. A server code is then divided into a generic and a specific part. The generic part might contain the main loop of the server that is waiting for messages, and the specific part of the code contains what the server should do if a particular message arrives. In practice, only a _callback module_ has to be implemented. OTP expects the existence of some functions (e.g. handle_call) in this module. As an example, several callback functions can be implemented for the complete functionality of an application, but the most important ones are: start/2, stop/1.

Let us summarize the most significant OTP behaviours: gen_server, gen_fsm, gen_event and supervisor. Each of them implements a basic pattern. The gen_server is the generic part of a server process, the gen_event is the generic part of event handling, the gen_fsm is the generic part of finite state machines. The supervisor behaviour is the generic part of the supervisor nodes of the supervision tree. Its callback module only contains the function init(Arg), in which the children and the working strategy of the node can be specified. The gen_server behaviour also defines higher level functions for messaging, such as the synchronous (_call_) or asynchronous (_cast_) messages.

## 3 The basic idea of the solution

Let us suppose that we have an Erlang system and we plan to make the startup concurrent. If we use the spawn function instead of the built-in methods of supervisor child-starting then the spawned processes run parallelly, but the Erlang/OTP supervisor monitoring mechanism - one of the strongest Erlang/OTP features - is lost. Omitting the ACK mechanism from the built-in child-starting process would mean a deep redesign and reimplementation of the OTP (the ACK mechanism corresponds to sequential child-starting). Also, sequential start determines an order between processes, which would vanish using a too naive way of parallelization. Therefore an alternative parallel ordering is required to avoid dead-locks and startup crashes.

In the light of the previously mentioned properties we define our guidelines:* The supervision tree structure, as well as other functionalities, must be preserved.
* The startup must be reliable and fast (faster than sequential).
* Only "small" modifications are permitted in the Erlang/OTP stdlib.

### The dependency graph

In this subsection we consider dependence relations between modules and introduce the notion of dynamic dependency graphs.

In order to preserve the supervisor tree structure, we define _conditions_. Conditions represent the startup state of modules. A condition related to a module is false while the module's startup is being processed (or has yet to begin) and set to true when the corresponding startup has been finished. At the beginning of the startup all conditions are false. Conditions that the startup of another module depends on are called the preconditions of that module. A process can only start if all its preconditions are true. We can represent these relations in a dependency graph. Modules (or corresponding conditions) are the vertices, dependence between modules (or preconditions) are the directed edges in this graph.

When a behaviour module starts instruction defined by the first user (which is also the first that can imply preconditions) is the first instruction of the module's init function. Therefore the verification of the preconditions and setting up the completed conditions to true have to insert immediately before and after executing the init function.1

Footnote 1: We remark that during the sequential startup there exist implicit preconditions which are described in the hierarchy of the supervisor trees.

Dependency graphs are widely used in computer science. For example, dependency graphs are applied in the startup of the Mac OSX operating system [10] or in compiler optimization [9]. Moreover, a dependency graph is created when the Erlang boot script is generated from a given application.

However, there is a significant difference between the graphs above and our graph. The same Erlang software start up in different ways in different environments, therefore module parameters, execution and dependencies can vary and should be handled dynamically for full performance. In order to keep Erlang's robustness, we add one more guideline to the above:

* The dependency graph should be dynamic.

### Concurrent startup of a supervisor's children

We also propose an Erlang trick that enables starting processes in a concurrent way. Here we can set which nodes should start concurrently. When a supervisor process \(\mathsf{s}\) starts a child process \(\mathsf{w}_{1}\), the system starts a _dummy_ (or _wrapper_) node \(\mathsf{s}_{1}\) instead. Then, the dummy process \(\mathsf{s}_{1}\) starts a simple function \(\mathsf{s}_{1,\mathsf{f}}\) (which just calls a spawn function) and sends an ACK message back immediately to its parent \(\mathsf{s}\). Consequently, the next child \(\mathsf{w}_{2}\) of the supervisor node \(\mathsf{s}\) can start. So far function \(\mathsf{s}_{1,\mathsf{f}}\) has spawned function \(\mathsf{f}\). The spawned function \(\mathsf{f}\) starts process \(\mathsf{w}_{1}\) and attaches it into the dummy process \(\mathsf{s}_{1}\) using the supervisor::start_child function2. The already started dummy process \(\mathsf{s}_{1}\) runs independently (parallel) from the other parts of the system. The ad

Figure 1: Inserting a _dummy_ supervisor node for (1) preserving the supervisor’s restarting behaviour, and (2) enabling fast parallel start-up. Supervisors are denoted by squares, permanent processes by continuous border, and temporary processes by dashed border. In the middle of the tree one can see the living processes \((\mathsf{s}_{2},\mathsf{w}_{2})\) after termination of the dummy functions.

vantage of this method is that if process \(w_{1}\) has a blocking precondition then only \(w_{1}\) is waiting instead of the whole system. Figure 1 shows the described supervision hierarchy after start. The dummy supervisor node's restart strategy can be set in such a way that a crashing child results in the termination of the dummy supervisor. Thus the connection between \(s\) and \(w_{1}\) is preserved.

The following code fragment shows the concurrent startup of a supervisor's children.

-module(dummy_sup_tree).

dummy_child({Tree_id, Child_spec}) ->  spawn(dummy_sup_tree, child_starter, [{Tree_id, Child_spec}]),  {ok, self()}.

child_starter({Tree_id, Child_spec}) ->  supervisor:start_child(Tree_id, Child_spec),  ok.

start_link({Child_spec}) ->  supervisor:start_link(dummy_sup_tree, [{Child_spec}]).

init([{Child_spec}]) ->  Sup_flags = {one_for_one, 0, 1},  {ok,  {Sup_flags,  [  {dummy_child_id, {dummy_sup_tree, dummy_child,  [{self(), Child_spec}]}, temporary, brutal_kill,  worker, [dummy_sup_tree, generic_server]}  ]  ]  }.

## 4 The solution's prototype

In this section we give the details of our solution by describing the skeleton of a prototype. We discuss the implementation of the dependency graph and how the Erlang boot script, the supervisors' init function, stdlib modules, etc, should be modified.

### Realization of the dependency graph

The dependency graph is implemented as a module called release_graph. This module implements and exports the following functions: get_conditions, get_preconditions and get_condition_groups.

The get_conditions function returns a list of pairs. Each pair consists of a module name (with parameters) and a condition name.

\(\{\) {Mod, Args}, condition_name \(\}\).

We note that the function tag of the MFA (Module-Function-Arguments triplet) may be omitted, since it is always the init function of the module. The function get_conditions corresponds to the vertices of the dependency graph. Observe that a condition corresponds to a module together with parameters rather than a module, in accordance with our dynamic dependency graph guideline. In general, the Args parameter can be an actual parameter value or undefined. In the latter case the condition describes the module's startup with arbitrary parameters.

The get_preconditions function also gives a list. The elements of the list have the following structure:

\(\{\) { Mod, Args }, [ condition_names ] \(\}\).

The function corresponds to the edges of the dependency graph. When a module's init function is called then the validity of the conditions in the list must be tested. Once again, the Args parameter can be undefined meaning that the startup of this module with any parameters has to wait until all conditions in the list become true.

The third function facilitates the management of dependence relations. Huge systems are likely to have many conditions and these conditions can be organized into groups. The get_condition_groups function returns a list of pairs of the form

\(\{\)condition_group_name, [ conditions ] \(\}\).

One can use the condition_group_name instead of the conditions defined in the list.

We remark that the dependency graph is not necessarily connected. Some modules are not preconditions of any other modules. In this case the definitions of the corresponding conditions are superfluous. Other modules do not have any preconditions, consequently they can be omitted from the return value of the get_precondition function.

Let's see an example. Let two applications app1 and app2 be given. The first has 3 server nodes that are controlled by a supervisor node. There is another server in the second application which has to wait for the complete startup ofthe first application. A possible implementation of the above functions might be:

... get_conditions() ->  [  {app1_rootsup, undefined }, cond_app1_rootsup },  {generic_server, [{app1_server1}]}, cond_app1_server1 },  {generic_server, [{app1_server2}]}, cond_app1_server2 },  {generic_server, [{app1_server3}]}, cond_app1_server3 }  ].

get_condition_groups() ->  [  { group_app1_app, [ cond_app1_server1,  cond_app1_server2,  cond_app1_server3,  cond_app1_rootsup ] }  ].

get_preconditions() ->  [  { generic_server, [{app2_server1}] }, [group_app1_app] }  ].

### The condition server

The startup is controlled by a special server, called condition_server, which is started during the Erlang main system start. It stores and handles the dependency graph of the user programs. It also finds and loads the release_graph module and checks the validity of the data in it (checks for mistypes, not existing condition names, etc.). Clearly, any error in the Args fields remains undiscovered. If the Args tags are all undefined then the dependency graph is independent from the dynamic data. In this case, an acyclic dependency graph assures dead-lock free structure if each node that has preconditions is started in a concurrent way.

The condition_server performs the following two tasks based on the dependency graph. (1) First, sets the conditions belonging to the {M,A}s to true. This is implemented in the set_condition({M,A}) function. (2) Second, it blocks the caller process until all its preconditions are satisfied. This is implemented in the wait_for_conditions({M,A}) function. These functions have to be called by the generic parts of the behaviours (independently of the users' programs). Consequently, the condition_server must be implemented without the gen_server behaviour.

We remark that for those modules which don't have any preconditions or don't belong to any other module's precondition, the corresponding function call has no effect.

The condition_server module has to be a part of the Erlang kernel modules, since during the Erlang system's startup several event handler and server modules are started, and they require access to the condition storage system.

### Modification of the supervisor behaviour

During the startup of a concurrent system, execution fork points must be named. In our case, these places are in the supervisor nodes. We modified the supervisor behaviour so that it accepts extended child specifications. The extension holds an additional field which can be sequential or concurrent. In the former case, the meaning of the child specification is equivalent with to original one. In the latter case, the supervisor node starts the child concurrently (fork point). We remark that the modification of the supervisor behaviour clearly accepts the original child specifications. The following example shows an extended child specification:

{app2_server1, {generic_server, start_link, [app2_server1]},  permanent, 10, worker, [generic_server], concurrent}.

If the generic part of supervisors interprets a concurrent child specification it starts a dummy supervisor node with the proper parameters instead of the original child.

### Further modifications of the Erlang system

It is also necessary to modify each Erlang behaviour before the callback init function is called, and after it returns successfully. We put these modifications into the gen_server, gen_event, gen_fsm, supervisor_bridge and supervisor behaviour.

The built-in utilities create boot scripts which do not start the condition_server automatically. In order to start the server, a new line has to be inserted into the boot script. The second line of the following code segment shows this:...  {kernelProcess,heart,{heart,start,[]}},  {kernelProcess,condition_server,{condition_server,start,[]}},  {kernelProcess,error_logger,{error_logger,start_link,[]}}, ...

## 5 Implementation and measurements

We fully implemented the prototype described in the previous sections. The implementation can be used as an OTP extension. This extension is based on Erlang/OTP R11B version and the modifications affected the stdlib's (v. 1.14.1) behaviour modules (namely: gen_server, gen_fsm, gen_event, supervisor_bridge, supervisor). You can download the prototype from the following url: [http://compalg.inf.elte.hu/projects/startup](http://compalg.inf.elte.hu/projects/startup).

Up to now, we described a parallel and reliable solution of the concurrent startup. Our solution gives a well-defined interface for handling the dependency problems among the concurrent starting modules. Therefore it preserves the reliability. It means that reliability of the concurrent startup is based on the dependency graph description of the users' programs. In the following we focus on the running time of the start-up.

We lack access to large industrial applications therefore we created programs for measuring the start-up time in several cases. For simplicity, no dependence conditions were defined, but concurrent supervisor child starting was performed. The measured programs use our modified Erlang/OTP libraries for making fast startup. The tested systems have some gen_server and some supervisor nodes. The gen_server nodes perform time-consuming, resource-intensive computations in their init functions. Each measured system has been started both sequentially and concurrently, the time is given in seconds. Each measurement has been performed five times and the figures show the average measured values. The measurements were performed on an SMP 4 machine with 2 AMD Dual Core Opteron, 2GHz, 16 GB RAM, Linux, Erlang 5.5, OTP R11B.

Three different system topologies were measured, a system with (1) deep process tree, (2) wide process tree, and (3) random process tree. The deep process tree was a 3-regular tree of depth 6, the wide process tree was a 10-regular tree of depth 2, and the random process tree was generated using uniform distribution from the range \([1,5]\) for the number of children of a node, then truncating the tree at level 5.

We measured the time that is needed for the system start-up as all servers and supervisors were started. The timer started when the erl shell was called and stopped when the last server or supervisor started. For this purpose we created a special application which starts just after all other servers or supervisors, and then immediately performs an illegal statement. Since this node crashes at once, consequently erl terminates. In other words, we measured the time between the starting and crashing of the Erlang shell.

There are several ways to make a system's process tree concurrent. We tagged the modules which have to start parallel. The speed of the startup depends on the number of the concurrent processes. The deeper the position of the fork point in the tree, the more parallel threads are created (more dummy supervisors). Therefore we show the running times as a function of the number of concurrent threads and as a function of the depth of fork points.

Figure 2 shows that the concurrent versions (not surprisingly) are always faster than the sequential ones. In some cases however, the concurrent start-up was two times faster than the sequential one.

Figure 2: Start-up speed of the sequential and concurrent versions (in seconds). In concurrent case we can put different number of fork points into different places in the process tree. The authors created several concurrent cases for each kind of trees. The worst and best case values represent the slowest and the fastest concurrent start-up time in the proper kind of trees.

Figure 3 shows the startup speed as a function of the number of fork points. Since there were 4 processors (2 dual core) in the testbed, it is not surprising that 4-fold parallelism yields the best results. When only 3 parallel processes were started, one processor did not work, and 3 processors performed the whole startup. In case of more than 4 active processes, the processors had to switch between the active processes resulting in a serious overhead. Note however, that the most significant overhead in our measurements comes from the time consuming part of the servers' init functions.

Figure 4 shows how the results depend on the depth of the fork points. We measured a fall back performance when all nodes in a given level were started parallel. In this case the system had more concurrent processes in the deeper levels. One can also observe that the version of 4 active process forking is the most resistant to the depth. In this case the only overhead comes from the number of dummy supervisor trees. The measurement suggests that the system should be forked as close to the root as possible.

Figure 3: Start-up speed (in seconds) depending on the number of running processes, which can be set by the fork points. The levels show the depth of the fork points.

## 6 Conclusions

In this paper we presented a solution for the parallel start-up of Erlang systems. We gave a general description of the solution and we measured the start-up time in several cases. Our measurements show that the parallel start-up can be much faster than the sequential. On the other hand our solution provides a well-defined mechanism for controlling the dependency relations among processes resulting reliable systems. The main advantages of our solution are:

* Precise and concise dependency handling.
* Preserving the supervision tree structures.
* The dependency graph is an Erlang module.

Figure 4: Start-up speed (in seconds) depending on the depth of the fork points.

* The dependency graph is dynamic.
* Less than 150 lines modification in the stdlib.

Disadvantage of our solution is that bad dependency graph could result deadlock or system crash. We conclude that our solution is highly capable for the parallelization of Erlang systems' startup in case of legacy systems and new developments as well.

## 7 Acknowledgements

The authors would thank to the Lemon project ([https://lemon.cs.elte.hu](https://lemon.cs.elte.hu)) that allowed us to use the project's main computer for measuring. We would also thank to Peter Nagy at Ericsson Telecommunications Hungary for answering our questions about Erlang and OTP.

The research was supported by the project TAMOP-4.2.1/B-09/1/KMR-2010-003 of Eotvos Lorand University.

## References

* [1] J. Armstrong, _Making reliable distributed systems in the presence of software errors_, PhD Thesis, Stockholm, 2003.
* [2] J. Armstrong, R. Virding, One pass real-time generational mark-sweep garbage collection, _Proc. IWMM'95: International Workshop on Memory Management,_ Lecture Notes in Computer Science, **986** (1995) 313-322.
* [3] J. Armstrong, R. Virding, C. Vikstrom, M. Williams _Concurrent Programming in Erlang,_ Second edition, Prentice Hall, 1996.
* [4] M. Bell, _Service-oriented modelling: service analysis, design, and architecture_, Wiley, 2008.
* a new generation ATM switching system, _Comput. Networks_, **31,** 6 (1999) 559-582.
* [6] Open Source Erlang, [http://www.erlang.org](http://www.erlang.org)
* [7]* [7] E. Johansson, K. Sagonas, J. Wilhelmsson, Heap architectures for concurrent languages using message passing, _Proc. ISMM'2002: ACM SIGPLAN International Symposium on Memory Management_, 2002, pp. 88-99.
* [8] K. Sagonas, J. Wilhelmsson, Efficient memory management for concurrent programs that use message passing, _Sci. Comput. Programming_, **62** (2006) 98-121.
* [9] S. Horwitz, T. Reps, The Use of Program Dependence Graphs in Software Engineering, _Proc. 14th International Conference on Software Engineering_, 1992, pp. 392-411.
* [10] Mac OS X Startup Items, [http://developer.apple.com/documentation/MacOSX/](http://developer.apple.com/documentation/MacOSX/)
* [11] N. A. Lynch, _Distributed Algorithms,_ First edition, Morgan Kaufmann, 1996

_Received: August 7, 2009 Revised March 5, 2010_

Title: Startups and Stanford University
Transcription: [MISSING_PAGE_FAIL:2]

## Academic Startups and Spinoffs

In the decades following the 50s and 60s, startups and academic spinoffs have become an extraordinary phenomenon. A great even if not well-known analysis of Silicon Valley startups [5] shows that the region was home to more than 22'000 high-tech firms in 2003 and more than 29'000 such firms had been created during the 90s (with a sharp decline thereafter). Most universities have published some analysis on their startups, for example at MIT [6], at Stanford [7] or in Switzerland at ETH Zurich [8], [9] and EPF Lausanne [10]. In his analysis [7], Eesley claims that "39'900 active companies can trace their roots to Stanford. If these companies collectively formed an independent nation, its estimated economy would be the world's 10th largest. Extrapolating from survey results, those companies have created an estimated 5.4 million jobs and generate annual world revenues of $2.7 trillion."

This report analyzes the performance of more than 5'000 firms which have a link to Stanford University. For more information, go to section "About the Data" at the end of the report. Of course entrepreneurship is not only about technology companies, but in Silicon Valley, and in particular at Stanford, most companies are high-tech as shows figure 1. Also many firms are service companies with no product offering. About 30% of the firms studied here are in that situation (see Appendix for more graphics). Overall high-tech firms related to information technologies represent more than 50% of the sample. They include firms selling hardware (HW) products such as semiconductors, computers, telecom equipment and electronics as well as software (SW) including multimedia and Internet technologies. It must be mentioned here that Internet services are considered as part of these software firms (showing the difficulty in classifying firms by domain of activities)

Figure 1: The Stanford startups by period of foundation and domains of activityStatus of Firms

Firms are not eternal and indeed their life expectancy is quite short. Zhang [5] shows that about half of both service and non-service firms had died 10 years after their creation. About a third of the firms had stopped their activities and surprisingly the ratio increases over time. The simplest explanations are either a bias in the database for early years or an increase in failure with the entrepreneurship fever which accompanied the Internet development. A quarter had been acquired (M&A) and a non-negligible part had gone public before at some point (6% in total). Another third was still private whereas a tiny 3% were publicly quoted.

So what is the life expectancy of these firms as private companies? Figure 3 shows the results. An overall average of 6.9 years before a cessation of activity, 7.8 years before being acquired and 7.3 years before going public. (For public companies, the time span represents years from foundation to IPO). These averages hide however a regular decrease until 1998 with more stable values thereafter. Table i in Appendix adds more information with a more granular analysis by fields.

Figure 3: Average time (in years) before exit

Figure 2: Status of firms with period of foundation

## Value Creation

Value creation is a difficult analysis to make for private companies. Most of these companies do not communicate about their numbers when they still exist and very little is known when they disappear. Public companies are much easier to analyze thanks to the documents they publish on a regular basis from their initial public offering (IPO) onwards. In-between some "relative" value creation is known when such companies are acquired with a disclosed value. A systematic analysis was done for public companies as well as for companies which had gone public at some point. The M&A transaction values were also compiled when publicly available.

### Public Companies

There were 148 public firms as of July 2017. The following table describes some of their features.

### Former Public Companies

There had been many more firms going public. In addition to the 148 existing public firms, another 333 had gone before being acquired (279), before stopping their activities (36) or becoming private again (18). The next table compiles the average value at the IPO and 12 months after the IPO.

Values at IPO are not sufficient to describe the value creation and even if the value after 12 months is also a limited snapshot, it has the advantage of giving usually a more accurate picture of the real value creation.

Tuple 36:
Cleaned Title: biotechnology startup different
Cleaned Transcription: biotechnology startup different herve lebret ecole polytechnique federale de lausanne vicepresidency innovation ch lausanne switzerland email hervelebretepflch phone orcid httpsorcidorghttpsorcidorg abstract domain technology startup biotechnology often considered specific unique technology content type founder manager amount venture capital raise time take reach exit well technology cluster belong seen unique feature based extensive research new database author claim biotechnology startup different might claimed amount venture capital raised time exit geography indeed similar even equity structure founder manager similarity difference still exist example experience founder revenue profit level exit keywords startup innovation venture capital technology biotechnology entrepreneurship jel classification number l l q introduction startup major phenomenon technology innovation last year dated beginning silicon valley among biotechnology startup recent important phenomenon beginning traced cetus corporation genentech founded also silicon valley today biotechnology become industry unique feature generally considered scientific content biotechnology firm higher counterpart given lengthy clinical trial associated growth development slower costly even riskier literature biotechnology startup rich academic well businessoriented standpoint general book quoted shimasaki binder hughes academic work numerous even article worth mentioned audretsch bradford brannback et al zahn patel zucker et al recent publication tzabbar margolis exemplifies unique feature role founder research launched since author built two database information related technology startup first one analyzes stanfordaffiliated corporation entrepreneur lebret focus field fundraising company background founder second one deal company filed go public lebret b focus equity structure company data set include large enough number biotechnology startup make possible revisit specific feature among hightech startup feature startup seems common knowledge biotechnology startup would different nature lengthy costly process invention commercialization would induce longer usual time exit startup well fund raising private investor venture capitalist result shown table stanfordrelated company relatively surprising result biotechnology company raise venture capital even higher percentage firm access theircapital take time exit time exit mean number year foundation either acquisition initial public offering ipo liquidation much higher ratio go public fewer acquired explanation may complex guess example one unique feature biotechnology company go public stock exchange much earlier others table illustrates term commercial development company revenue profit employment difference type exit ipo v value created exit correlated longer time span profitability table give list active venture capitalist stanfordrelated hightech company whereas biotech considered field specialized investor fund reality active fund biotech fact general fund one italic table however specialized fund biotech abingworth management asset management company mpm capital domain partner sofinova partner versant venture aberdare venture oxford bioscience partner among active one different field also dedicated fund andresseen horowitz founder fund benchmark capital kleiner perkins
Original Title: Are Biotechnology Startups Different?
Original Transcription: **Are Biotechnology Startups Different?**

Herve Lebret

Ecole Polytechnique Federale de Lausanne

Vice-Presidency for Innovation, CH-1015 Lausanne, Switzerland

Email: herve.lebret@epfl.ch - Phone: +41 21 693 70 54

Orcid : [https://orcid.org/0000-0002-2420-1216](https://orcid.org/0000-0002-2420-1216)

**Abstract**

In the domain of technology startups, biotechnology has often been considered as specific. Their unique technology content, the type of founders and managers they have, the amount of venture capital they raise, the time it takes them to reach an exit as well as the technology clusters they belong to are seen as such unique features. Based on extensive research from new databases, the author claims that the biotechnology startups are not as different as it might have been claimed: the amount of venture capital raised, the time to exit, their geography are indeed similar and even their equity structure to founders and managers have similarities. The differences still exist, for example the experience of the founders, the revenue and profit level at exit.

Keywords: startup, innovation, venture capital, technology, biotechnology, entrepreneurship

JEL classification numbers: L26, L65, M13, O32, Q55.

**Introduction**

Startups have been a major phenomenon of technology innovation in the last 60 years and can be dated to the beginnings of Silicon Valley in 1957. Among them, biotechnology startups have been a more recent and as important phenomenon. Their beginnings can be traced to Cetus Corporation and Genentech, both founded in the 70s, also in Silicon Valley. Today, biotechnology has become an industry in itself with some unique features. It is generally considered that the scientific content of biotechnology firms is higher than their counterparts and given the lengthy clinical trials associated with their growth, their development is slower, more costly and even riskier.

The literature on biotechnology startups is rich both from an academic as well as business-oriented standpoint. A few general books can be quoted (Shimasaki 2014, Binder 2008, Hughes 2011) and academic work is numerous even if again a few articles are worth being mentioned (Audretsch 2001; Bradford 2003; Brannback et al. 2009; Zahn and Patel 2005; Zucker et al. 1998). A recent publication by Tzabbar & Margolis (2017) exemplifies some unique features of the roles of founders.

Through research launched since 2010, the author has built two databases of information related to technology start-ups. The first one analyzes more than 5'600 Stanford-affiliated corporations and entrepreneurs (Lebret, 2017a) with a focus on fields, fundraising of the companies and background of the founders; the second one deals with more than 400 companies which had filed to go public (Lebret 2017b), with more focus on the equity structure of the companies. Both data sets include a large enough number of biotechnology startups which make it possible to revisit the specific features (if any) of these among high-tech startups.

**The features of the startups**

It seems to be common knowledge that biotechnology1 startups would be different because of the nature of their lengthy and costly process from invention to commercialization. This would induce a longer than usual time to exit for startups as well as more fund raising from (private) investors such as venture capitalists. Some of our results are shown in Table 1 for the Stanford-related companies. The relatively surprising results are: biotechnology companies do not raise more venture capital (even if a higher percentage of firms access theircapital), they do not take more time to exit (time to exit means the number of years from foundation to either an acquisition - M&A, an initial public offering - IPO or a liquidation); a much higher ratio of these goes public and fewer are acquired.

The explanations may be not very complex to guess as for example one unique feature of biotechnology companies is to go public on stock exchanges much earlier than others as Table 2 illustrates in terms of commercial development of the company (revenues, profits, employment). The difference in the type of exits (IPO vs. M&A) and value created at exits can be again correlated to the longer time span to profitability.

Table 3 gives the list of the most active venture capitalists in the Stanford-related high-tech companies. Whereas biotech has been considered as a field with its own specialized investor funds, the reality is that the most active funds in biotech are in fact general funds (the ones in italics in the table).

There are however specialized funds in biotech such as Abingworth Management, Asset Management Company, MPM Capital, Domain Partners, Sofinova Partners, Versant Ventures, Aberdare Ventures or Oxford Bioscience Partners among the most active ones (but this is not different from other fields such as IT which also has its dedicated funds such as Andresseen Horowitz, the Founders Fund or Benchmark Capital). Kleiner Perkins

Tuple 37:
Cleaned Title: critical business decision making technology startup perceptin case study
Cleaned Transcription: critical business decision making technology startup perceptin case study shaoshan liu perceptin shaoshanliuperceptinio abstract business decision made analysis judgment call susceptible analysis due time information constraint article present reallife case study critical business decision making perceptin autonomous driving technology startup early year perceptin perceptin make decision design computing system autonomous vehicle product providing detail perceptins decision process result decision hope provide insight beneficial entrepreneur engineering manager technology startup background perceptin established develop visual perception technology autonomous vehicle robot since inception perceptin successfully attracted million usd venture capital funding walden international matrix partner samsung venture perceptin international technology startup operation u japan europe asia perceptin consists researcher engineer business professional business professional responsible business development different market gather feedback company rd effort whereas engineer researcher responsible developing cutting edge autonomous driving technology past three year perceptin generated u patent international patent well numerous research paper perceptin decided develop low speed autonomous vehicle serve micromobility market micromobility rising transport mode wherein lightweight vehicle cover short trip massive transit ignore according u department transportation vehicle traffic attributed trip mile transportation need short trip disproportionally underserved current mass transit system due high cost affect society profoundly micromobility bridge transit service community need driving rise mobilityasaservice business analysis perceptins primary customer autonomous vehicle operator around globe perceptin partner autonomous vehicle operator provide micromobility service different market japan u europe perceptins ultimate goal provide affordable reliable autonomous driving technology allow perceptinsoperators generate profit subsequently grow business perceptin conducted pilot project globally understand micromobility market customer need well cost structure business one perceptins pilot project took place ztes industrial park shenzhen china zte leading chinese telecom company enormous campus shenzhen campus filled worker tremendous intracampus transportation need pilot project perceptins pod transferred ztes worker across campus perceptins pod pack four highdefinition camera four midrange radar set ultrasound sensor well gps sensor wheel odometry pilot project perceptin collected sufficient operation data customer feedback internal business analysis based internal business analysis perceptin provide lowspeed autonomous vehicle per unit perceptin could generate reasonable returnoninvestment roi perceptins customer autonomous vehicle operator thus perceptin set goal develop autonomous vehicle sold price tag five ten time lower commonly believed possible commercial autonomous vehicle however price tag also imposes strict challenging constraint design lowspeed autonomous vehicle detail break nonrecurring engineering nre cost research development recurring cost cost chassis cost drivebywire conversion meaning convert traditional vehicle one controlled computer cost sensor cost integration cost customer service finally cost computing system situation june based initial feedback zte case study perceptin conducted study autonomous driving computing system perceptin concluded computing bottleneck commercial deployment autonomous vehicle perceptin needed computing system reliable affordable highperformance energy efficient importantly needed solution cost effective short timetomarket perceptin faced several option optimization commercial offtheshelf mobile systemonchip soc computing system approach brings several benefit first since mobile socs reached economy scale would beneficial perceptin build technology stack affordable backwardcompatible computing system second perceptins vehicle target micromobility limited speed similar mobile robot mobile socs demonstrated however extensive study required fully understand mobile socs suitability autonomous driving may delay perceptins product launch six month procurement specialized autonomous driving computing system commercial computing platform specialized autonomous driving nxp mobileye nvidia mostly applicationspecific integrated circuit asic based chip provide high performance much higher cost instance firstgeneration nvidia px system cost besides cost issue computing system mostly accelerate perception function autonomous driving whereas perceptin require system optimizes endtoend performance development proprietary autonomous driving computing system developing proprietary computing system guarantee perceptin suitable system perceptins customer workload also mean perceptin need invest significant amount financial personnel resource project also investment guarantee success project huge risky bet startup like perceptin decision decision process started without quantitative evaluation method use judgement call evaluate different option summarized option table parameter evaluation include affordability backward compatibility suitability autonomous driving computing project risk parameter higher better affordability option clear winner backward compatibility option option deliver good result suitability option clear winner option unknown requires additional study risk option option low risk using table perceptin quickly ruled option due low score across parameter except suitability clear available data option worst choice among three internal debate began within perceptin whether move forward option option option seemed attractive unknown whether would suitable autonomous driving computing task suitable option would infeasible clear answer whether option would suitable sixmonth study would necessary option would extremely expensive option high risk even perceptin invested project would guaranteed success since unknown parameter option deterministic analysis could conducted perceptin management team use judgment call susceptible analysis decision process several round internal debate perceptin management team decided compare option option respective worst case scenario perceptin moved forward option worst case could happen six month wasted limited investment perceptin find option would suitable perceptin could still try option perceptin moved forward option worst case could happen half perceptins rd budget month wasted analysis perceptin decided take safest approach also approach everyone comfortable move forward option six month work try option result six month perceptin focused option unfortunately perceptin found mobile socs illsuited autonomous driving three reason
Original Title: Critical Business Decision Making for Technology Startups -- A PerceptIn
  Case Study
Original Transcription: Critical Business Decision Making for Technology Startups: A Perceptin Case Study

Shaoshan Liu

Perceptin

shaoshan.liu@perceptin.io

**Abstract**: _most business decisions are made with analysis, but some are judgment calls not susceptible to analysis due to time or information constraints. In this article, we present a real-life case study of critical business decision making of Perceptin, an autonomous driving technology startup: in early years of Perceptin, Perceptin had to make a decision on the design of computing systems for its autonomous vehicle products. By providing details on Perceptin's decision process and the results of the decision, we hope to provide some insights that can be beneficial to entrepreneurs and engineering managers in technology startups._

**Background**: Perceptin was established in 2016 to develop visual perception technologies for autonomous vehicles and robots. Since its inception, Perceptin has successfully attracted over 10 million USD of venture capital funding, from Walden International, Matrix Partners, and Samsung Ventures [1]. Perceptin is an international technology startup with operations in the U.S., Japan, Europe, and Asia. Perceptin consists of over 30 researchers and engineers and 10 business professionals. The business professionals are responsible for business development in different markets and gather feedbacks for the company's R&D efforts, whereas the engineers and researchers are responsible for developing cutting edge autonomous driving technologies. In the past three years, Perceptin has generated over 20 U.S. patents and over 100 international patents, as well as numerous research papers.

In 2017, Perceptin decided to develop low speed autonomous vehicles to serve the micromobility market, as micromobility is a rising transport mode wherein lightweight vehicles cover short trips that massive transit ignore [2]. According to US Department of Transportation, 60% of vehicle traffic is attributed to trips under 5 miles [3]. Transportation needs in short trips are disproportionally under-served by current mass transit systems due to high cost, which affects the society profoundly. Micromobility bridges transit services and communities' needs, driving the rise of Mobility-as-a-Service.

**Business Analysis**: Perceptin's primary customers are autonomous vehicle operators around the globe, and Perceptin partners with these autonomous vehicle operators to provide micromobility services in different markets, such as Japan, U.S., and Europe. Perceptin's ultimate goal is to provide affordable and reliable autonomous driving technologies that can allow Perceptin'soperators to generate profits, and subsequently grow the business. In 2017 and 2018, Perceptin conducted over 10 pilot projects globally to understand the micromobility market, the customer needs, as well as the cost structure of this business.

One of Perceptin's pilot projects took place in 2017 at ZTE's industrial park in Shenzhen China. ZTE is a leading Chinese telecom company with an enormous campus in Shenzhen, and the campus is filled with over 30,000 workers with tremendous intra-campus transportation needs. In this pilot project, Perceptin's pods transferred ZTE's workers across the campus. Each Perceptin's pod packs four high-definition cameras, four mid-range radar sets, and 10 ultrasound sensors, as well as GPS and sensors for wheel odometry [4]. From these pilot projects, Perceptin collected sufficient operation data and customer feedbacks for internal business analysis.

Based on internal business analysis, if Perceptin can provide low-speed autonomous vehicles under $70,000 per unit, Perceptin could generate a reasonable return-on-investment (ROI) for Perceptin's customers, the autonomous vehicle operators. Thus, in 2018 Perceptin set the goal to develop autonomous vehicles that can be sold at a price tag $70,000, which is five to ten times lower than what is commonly believed to be possible for commercial autonomous vehicles. However, the $70,000 price tag also imposes very strict and challenging constraints on the design of low-speed autonomous vehicles. In detail, we have to break down the $70,000 into Non-recurring engineering (NRE) cost such as research and development, recurring costs such as the cost of the chassis, the cost of drive-by-wire conversion (meaning to convert a traditional vehicle into one that can be controlled by computers), the cost of sensors, the cost of integration, the cost of customer service, and finally the cost of the computing system [5].

**Situation**: in June 2017, based on the initial feedbacks from the ZTE case study, Perceptin conducted a study on autonomous driving computing systems [6], Perceptin concluded that computing is the bottleneck for the commercial deployment of autonomous vehicles, and Perceptin needed a computing system that is reliable, affordable, high-performance, and energy efficient. Most importantly, we needed a solution that is cost effective and has a short time-to-market. Perceptin faced several options:

1. Optimization of commercial off-the-shelf mobile System-on-Chip (SoC) computing systems: This approach brings several benefits, first, since mobile SoCs have reached economies of scale, it would have been most beneficial for Perceptin to build its technology stack on affordable, backward-compatible computing systems. Second, Perceptin's vehicles target micromobility with limited speed, similar to mobile robots, for which mobile SoCs have been demonstrated before. However, an extensive study is required to fully understand mobile SoCs' suitability for autonomous driving, this may delay Perceptin's product launch by six months.
2. Procurement of specialized autonomous driving computing systems: there were commercial computing platforms specialized for autonomous driving, such as those from NXP, MobilEye, and Nvidia. They are mostly Application-Specific Integrated Circuit (ASIC) based chips that provide high performance at a much higher cost. For instance, the first-generation of Nvidia PX2 system costs over $10,000. Besides the cost issue, these computing systems mostly accelerate only the perception function in autonomous driving, whereas Perceptin require a system that optimizes the end-to-end performance.

3. Development of proprietary autonomous driving computing systems: developing a proprietary computing system guarantees that Perceptin have the most suitable system for Perceptin's customers and for its workloads, but also means that Perceptin need to invest a significant amount of financial and personnel resources on this project. Also, the investment does not guarantee the success of this project. It is a huge and risky bet for a startup like Perceptin.

**Decision**: then the decision process started, without quantitative evaluation methods, we had to use judgement calls to evaluate different options [10, 11]. We summarized these options in Table 1, the parameters of evaluation include _Affordability_, _Backward Compatibility_, _Suitability_ for autonomous driving computing, and project _Risk_. For all parameters, the higher the better. For _Affordability_, option 1 is the clear winner. For _Backward Compatibility_, both option 1 and option 3 deliver good results. For _Suitability_, option 3 is the clear winner, and option 1 is unknown and requires additional study. For _Risk_, both option 1 and option 2 have low risk.

Using table 1, Perceptin quickly ruled out option 2 due to its low score across all parameters except _Suitability_, it is clear from available data that option 2 was the worst choice among the three. Then internal debate began within Perceptin on whether to move forward with option 1 or option 3. Option 1 seemed very attractive, but it was unknown whether it would be suitable for autonomous driving computing tasks. If it was not suitable, then option 1 would be infeasible. To have a clear answer on whether option 1 would be suitable, a six-month study would be necessary. For option 3, it would be an extremely expensive option and with high risk. Even if Perceptin invested in this project, there would be no guaranteed success.

Since there is an unknown parameter in option 1, a deterministic analysis could not be conducted, and the Perceptin management team had to use judgment calls not susceptible to analysis in our decision process.

After several rounds of internal debate, the Perceptin management team decided to compare option 1 and option 3 in their respective worst case scenario. If Perceptin moved forward with option 1, the worst case that could happen was that six months wasted, but with limited investment. If Perceptin did find out that option 1 would not be suitable, Perceptin could still try option 3. If Perceptin moved forward with option 3, the worst case that could happen was that half of Perceptin's R&D budget and 12 months wasted. With this analysis, Perceptin decided to take the safest approach, also an approach that everyone was comfortable with: move forward with option 1 for six months, if that does not work, then try option 3.

**Results**: for six months, Perceptin focused on option 1 but unfortunately Perceptin found that mobile SoCs are ill-suited for autonomous driving for three reasons:

Tuple 38:
Cleaned Title: startup acquisition acquihires talent hoarding
Cleaned Transcription: startup acquisition acquihires talent hoarding jeanmichel benkert igor letina shuo liu benkert department economics university bern letina department economics university bern cepr liu guanghua school management peking university email jeanmichelbenkertunibech igorletinaunibech shuoliugsmpkueducn grateful florian ederer johannes johnen massimo motta armin schmutzler seminar participant university bayreuth copenhagen lausanne well joint humboldt university university toronto theory conference berlin ccer summer institute beijing swiss io day bern valuable feedback helpful comment shuo liu acknowledges financial support national natural science foundation china grant introduction historically competition authority concerned merger acquisition ma likely lead reduction effective competition since startup almost definition generally hold small nonexistent market share acquisition rarely challenged see eg bryan hovenkamp recently begun change competition authority starting scrutinize effect activity current also potential nascent competition context cunningham ederer shown pharmaceutical industry acquisition socalled killer acquisition aimed inhibiting development future competition backdrop competition authority believe may case carefully scrutinize startup acquisition footnote federal trade commission investigated whether large tech company making potentially anticompetitive acquisition nascent potential competitor ftc european commission also taken step indicating stricter enforcement see eg european commission increased attention competition authority deemed unnecessary critic arguing startup acquisition typically benign term impact competition even result killing startup product service one common argument eg barnett support view acquisition socalled acquihires name suggests acquihires essentially hiring instrument acquiring firm primarily interested hiring startup employee removing potential competitor consider case dropio startup offering easy file sharing dropio successful startup named winner cnets webware listed among best website time magazine acquiring dropio facebook promptly terminated announced ceo time sam lessin would assigned new role startup killed motivation different killer acquisition cunningham et al yet necessarily mean acquisition benign footnote see webware winner dropio cnet may best website dropio time august facebook acquires simple filesharing service dropio mashable october goal paper contribute discussion presenting simple yet general framework allowing study acquihires consider model two symmetric incumbent competing one market startup operating market seen orthogonal rule elimination potential competitor motivation acquisition incumbent attempt acquihire startup acquire integrate employee operation acquihire lead efficiency gain acquiring firm profit acquire increase competitor decrease following acquihire allow different degree efficiency gain modeling two distinct level match quality incumbent startup present three main result first show inefficient acquisition may occur even startup potential competitor incumbent context inefficiency manifested talent hoarding firm engaging acquihires even transaction lead lower aggregate profit startup acquirer afterward essentially find lowmatch firm increase expected profit acquiring startup potentially highmatch competitor learns existence acquihires generate inefficiency startup employee would productive either staying startup available moving highmatch competitor model thus suggests startup acquisition need benign even potential competition motif ruled second result examines effect acquihires consumer surplus whether acquihire decrease surplus depends whether loss surplus induced disappearance startup offset resulting efficiency gain particular highmatch acquisition increase consumer surplus lowmatch acquisition decrease competition authority identify match quality may face complex challenge regulating acquihires instance welfare effect banning acquihires may depend straightforwardly exante likelihood highmatch deal show prohibiting acquihires tends decrease consumer welfare probability either high low former case even though lowmatch firm strong incentive hoard talent potential negative impact rarely materializes latter case lowmatch firm endogenously choose engage expensive talent hoarding observed acquihires highmatch firm thus welfareenhancing probability highmatch sits intermediate range lowmatches remain tempted hoard talent rare banning acquihires largest scope enhancing expected consumer welfare final result show labormarket outcome acquihired employee may become volatile due firm talent hoarding obtain result expand baseline model adding second period moreover period economy may fall recession consequently firm may get hit potentially correlated adverse shock relative benchmark motive hoard talent show talent hoarding always lead hiring may also lead layoff unemployment acquihired employee adverse shock sufficiently likely sufficiently positively correlated finding lends support view talent hoarding major contributing factor substantial number layoff tech industry following increased pressure u economy footnote see tech talent war come back bite new york time november explore several extension baseline model online appendix extension include allowing acquiring firm differentiate startup talent technology incorporating asymmetry market power among potential acquirer expanding number firm introducing uncertainty order move accounting partial acquisition towards paper end discus extension greater detail arguing confirm robustness core finding also provide additional insight instance extension asymmetric firm highlight reasonable profit assumption dominant firm stronger incentive hoard talent observation resonates concern expressed many regulator regarding overhiring prevalent among tech giant related literatureour paper closely related literature studying economics startup acquisition much early literature examined various setting prospect acquisition impact incentive startup incumbent invest innovation eg gans stern mason weed norback persson phillips zhdanov rasmussen following cunningham et al demonstrated incumbent may acquire startup anticompetitive reason large literature studied effect restrictive merger policy would innovation overall welfare cabral katz letina schmutzler seibel motta peitz others examine acquisition steer direction innovation bryan hovenkamp callander matouschek dijk moragagonzalez motchenkova fumagalli motta tarantino consider impact financial constraint several paper consider dynamic incentive bryan hovenkamp cabral denicolo polo hollenbeck key insight incumbent pull far ahead technology space pace innovation go also possibility incumbent creates killzone disincentivizes entry either acquiring entrant copying product heavily investing innovation bao eeckhout kamepalli rajan zingales shelegia motta teh banerjee wang empirical side ederer pellegrino show startup increasingly favor acquisition ipo exit strategy finally several paper empirically study acquisition tech sector affeldt kesler eisfeld gautier lamesch gugler szucs wohak jin leccese wagman prado bauer paper differs literature considering startup potential competitor incumbent main channel acquisition create inefficiency thus fundamentally different examine firm engage acquhires instead directly poaching valuable employee question tackled barisaac johnson nocke show acquhire increase monopsony power acquirer removing relevant labormarket competitor turn lower wage making acquhiiringmore profitable direct hiring coyle polsky argue firm engage acquhires reputational reason acquirer want maintain good relationship vcs startup founder prefer reputation successful exit selby mayer add acquhiire method acquiring entire team paper also relates empirical literature directly study acquhires ouimet zarutskie ng stuart chen gao chen hshieh zhang show acquiring talent indeed important motivation acquisition however acquhired employee separate higher rate regularly hired employee ng stuart verginer parisi de jeude riccaboni may due preference working startup misalignment acquirer plan kim loh khashabi claussen kretschmer empirical finding consistent theoretical result talent hoarding model driven preemption effect firm acquiring talent partly prevent competitor becoming stronger course many paper identify preemption effect various setting patent race gilbert newbery ma international trade setting norback persson technology acquisition bryan hovenkamp preemptively acquiring labor different acquisition physical asset technology firm acquire property right labor setting implies solution preemption like licensing katz shapiro apply moreover additional issue like impact business cycle appear broadly related haegele find evidence talent hoarding manager within firm identify strategic motif talent hoarding across firm literature endogenous technological spillover caused worker changing job also broadly related possibility worker might move competitor influence whether multinational enterprise export produce locally fosfuri motta ronde much firm may invest innovation gersbach schmutzler ab also broadly related concept labor hoarding macroeconomics refers firm employing worker economic contraction necessary production firm avoid incurring hiring training cost contraction end economy recovers overview see biddle model predicts talent hoarding implies volatile hiring firing decision economic expansion contraction would dampen observed labor hoarding contraction interestingly exactly biddle pp report happening recently especially great recession practice talent hoarding become common model would provide potential explanation observation model two symmetric firm iin competing market second market entrepreneur e startup active status quo firm payoff given pif entrepreneur payoff pie model specify direct linkage two market eg consumer demand prefer consider orthogonal allows u rule conventional competition motif firm acquiring startup become clear later footnote many relevant application dominant firm market discus extension section formally develop online appendix b moreover also consider effect two firm online appendix b firm pursue acquihire whereby acquires integrates startup making bid p entrepreneur successful payoff consequence transaction depend match quality thetainhl acquirer startup match quality acquirer private information drawn iid firm according prthetahprthetallambdain specifically firm match thetai successfully pursues acquihire bid p payoff barpifthetaip firm payoff underlinepifthetai entrepreneur receives p assume acquihire lead relative efficiency gain competitor follows assumption assume barpifhpifpiebarpifl pifgequnderlinepiflunderlinepifh according assumption joint profit startup acquirer highest highmatch firm acquires startup second highest firm acquire startup lowest lowmatch firm acquires startup assumption ii say profit nonacquiring firm highest competitor pursue acquihire followed lowmatch competitor acquihire lowest highmatch competitor consumer point view three possible outcome first absent acquihire three firm active respective market case consumer surplus arising competition two symmetric firm csf startup cse second lowmatch acquihire result competition two asymmetric firm generating entire consumer surplus csl third highmatch acquihire also result similar competition generates entire consumer surplus csh whenever acquihire occurs consumer surplus generated startup cse lost make following assumption assumption let cshgeq cslgeq csf assumption capture idea one two firm becomes efficient pass efficiency consumer footnote possible assumption hold extending analysis case straightforward would come cost complex exposition finally timing follows outset nature draw private match type firm first stage firm opportunity attempt acquhire entrepreneur accept reject bid entrepreneur accepts bid game end otherwise move second stage stage firm opportunity attempt acquhire entrepreneur accept reject bid game end footnote online appendix b show emergence incentive hoard talent hinge firm knowledge order move fact firm get full surplus resulting acquhire however firm moving simultaneously eg entrepreneur auctioning startup talent hoarding proposition unlikely materialize firm high match value able outbid low matchvalue competitor exampleour reducedform model encompasses many standard oligopoly model specific application mind one could fix demand function derive precise result example consider cournot duopoly inverse demand function pqqabqbq constant marginal cost production c let highmatch acquiihire reduce acquirer marginal cost ch lowmatch acquiihire reduces cl hl assuming firm active highmatch acquiihire ach easy calculate firm profit various outcome piffracacb barpifhfracachb barpiflfracaclb underlinepifhfracachb underlinepiflfracaclb shown assumption satisfied interval pie value essentially free parameter ii always satisfied moreover standard calculation give u consumer surplus three possible outcome cshfracachb cslfracaclb csffracacb immediate assumption satisfied boxtalent hoarding define talent hoarding situation firm employ group worker although could efficiently engaged elsewhere model talent hoarding occurs whenever lowmatch firm acquires integrates startup employee startup would generate higher additional profit startup remained operational moreover firm competitor turn highmatch startup foregone efficiency would even greater proposition talent hoarding assumption firm behavior pbe uniquely specified namely firm highmatch startup acquiring lowmatch acquhire lambdageqlambdaaequivfracpiepifbarpiflpif underlinepifh tag proof suppose firm done acquhire follows assumption belief firm acquhire high type moving stage firm belief given prior highmatch firm always acquhire assumption lowmatch firm acquhire whenever barpiflpiegeqlambdaunderlinepifhlambdapif equivalently lambdalambdaaequivfracpiepifbarpiflpif underlinepifh note pie firm bid startup leaving entrepreneur indifferent accepting result proposition show talent hoarding may occur barpiflunderlinepifhpie lambdaa ii probability high match sufficiently high condition barpiflunderlinepifhpie guarantee gain lowmatch firm acquhire facing highmatch competitor bigger cost acquhire however since lowmatch firm make negative profit acquhire per se proceed facing highmatch competitor likely enough effectively lowmatch firm willing overpay making acquhire prevent potential emergence highly competitive firm lowmatch firm reap efficiency gain acquhire threat competitive firm motivating acquhire thus talent hoarding likely price acquisition pie low probability highmatch competitor lambda high footnote one may wonder lowmatch firm keep startup operational result might affected startup also valuable technology discus issue section formally analyze online appendix b b short argue operating startup subsidiary might le profitable integration due moral hazard issue also show startup also valuable technology firm incentive hoard technology still hoard talent discussion far focused exclusively firm turn implication talent hoarding consumer following acquuhire consumer surplus generated startup vanishes thus whether consumer benefit acquuhire hence appropriate response regulator depends change consumer surplus created competition firm following acquuhire assumption acquuhires always increase consumer surplus twofirm market cshcslcsf lead loss cse startup market cse low cshcslcsfcse lowmatch highmatch acquuhires increase consumer surplus policymakers always allow acquisition similarly cse high lowmatch highmatch acquuhires lower consumer surplus csfcsecshcsl policymakers prohibit acquisition footnote observe cse eg startup viable acquuhire always increase consumer surplus subtle case appears cse intermediate cshcsfcsecsl prohibiting highmatch acquuhire would decrease consumer surplus prohibiting lowmatch one would increase hence policymaker unable discern low highmatch acquuhires face tradeoff next result characterizes optimal policy case discussed define lambdacsequivfraccsfcsecslcshcsl tag value cutoff one defined relate crucial effect acquuhires consumer surplus proposition effect acquuhires consumer surplus csfcsecshcsl acquisition reduce consumer surplus cshcslcsfcse acquisition increase consumer surplus suppose cshcsfcsecsl acquhires reduce consumer surplus expectation lambdainlambdaalambdacs proof case ii straightforward demonstrate iii lambdalambdaa proposition highmatch firm engage acquuhire since cshcsfcseany acquiring case increase consumer surplus lambdageqlambdaa lowmatch highmatch firm engage acquhire expected consumer surplus lambda cshlambdacsl since expected consumer surplus acquhires prohibited csfcse acquhires reduce consumer surplus lambdageqlambdaa lambda cshlambdacslcsfcselongleftrightarrowlambdafrac csfcsecslcshcslequivlambdacs thus acquhires reduce consumer surplus lambdaaleqlambdalambdacs intuition proposition iii cshcsfcsecsl acquhires harmful talent hoarding ie low highmatch firm engage acquhire requiring lambdageqlambdaa probability high match sufficiently low requiring lambdalambdacs hence consumersurplus destroying acquhires occur intermediate lambda lambdainlambdaalambdacs figure illustrates proposition iii using cournot example pie two panel differ level consumer surplus generated startup set cse left panel cse right panel panel lambda grows lambdaa consumer surplus acquisition allowed increase solid line parameter firm endogenously engage highmatch acquhires benefit consumer lambdaa lowmatch firm start talent hoarding causing discontinuous drop consumer surplus visible panel however left panel lambdacslambdaa drop lambdaa sufficient lower consumer surplus level achieved acquisition prohibited dashdotted line right panel lambdaalambdacs lambdainlambdaalambdacs average consumer surplus lower acquhires allowed lambda increase beyond lambdacs highmatch acquhires become likely overall consumer surplus higher acquisition prohibited thus cshcsfcsecsl allowing acquhires lower consumer surplus intermediate value lambda finally dashed line represents consumer surplus could achieved regulator could differentiate lowmatch highmatch acquhires case allowing highmatch acquhires always increase consumer surplus course regulator imperfectly detect match type would lower expected consumer surplus dashed line finally regulator may interested effect talent hoarding total surplus sum firm profit consumer surplus follows directly discussion proposition talent hoarding reduces total surplus unambiguously transaction reduces consumer surplus otherwise impact depends structure one imposes reducedform model cournot example total surplus lowtype acquhire always lower hightype acquhire total surplus without acquhire hinge startup profit consumer surplus hiring separation unemployment next discus implication talent hoarding hiring separation unemployment acquuihred employee expand baseline model introducing second period allowing economic downturn two period first period expanded model identical baseline model section firm match type private information firm opportunity acquuhire firm period economy suffers downturn probability deltain downturn materializes event publicly observable firm may hit adverse shock see detail period entrepreneur option creating new startup leading outside option pie entrepreneur employed firm period firm must decide whether continue relationship cost pie lay entrepreneur might hired firm acquuhire period firm moving first period two footnote empirical evidence acquuhired employee leave acquirer likely join new startup kim ng stuart adverse shock come commonly known joint probability distribution downgrade firm though firm observes realization shock specifically firm hit shock siindn either downgraded high low match possible affected shock thus lowmatch firm hit downgrade stay lowmatch firm highmatch firm turn lowmatch firm firm affected shock match quality stay let ssindn profile shock hitting firm follows thedistribution prdd rgammagammagamma prdn rgammagamma prnd rgammagamma prnn rgammagammagamma gammain probability firm downgraded rin measure positive correlation firm shock particular r shock independent r perfectly positively correlated make comparative statement need benchmark relative compare hiring separation unemployment model talent hoarding consider case pifunderlinepifhunderlinepifl acquuhire firm affect firm j profit thus incentive hoard talent benchmark state formal result consider following intuition entrepreneur hired highmatch firm period firm affected economic downturn ie remains highmatch firm maintain entrepreneur employment therefore separation unemployment observed case contrast entrepreneur hired lowmatch firm period downgraded highmatch firm several period outcome arise talenthoarding motif may induce continued employment entrepreneur competitor believed high match value high enough probability thus would observe separation unemployment entrepreneur otherwise may observe layoff entrepreneur subsequently hired highmatch competitor hence observe separation entrepreneur become unemployed finally entrepreneur may laid hired competitor resulting separation unemployment note distinct period outcome turn affect behavior lowmatch firm period changing acquihire threshold solving game fully deriving probability period hiring well observing separation unemployment period obtain following result proved appendix footnote video game industry loh et al document skill employee need acquirer match well employee likely stay acquirer footnote term unemployment mean entrepreneur laid employed competitor since entrepreneur start business unemployment precise sense term occur proposition effect employment outcome presence talenthoarding motif always lead hiring benchmark additionally provided minleftfraclambda alambdafraclambdalambdarightr gamma talent hoarding also lead separation unemployment benchmark increase hiring follows immediately presence talent hoarding highmatch firm also lowmatch firm may pursue acquuhire increase separation unemployment subtle essentially either correlation firm adverse shock r marginal probability suffering downgrade gamma sufficiently high talent hoarding raise separation unemployment case r high firm shock informative firm shock due correlation hence allowing firm whenever draw negative shock forgo costly talent hoarding second period similarly gamma sufficiently high firm fairly confident whenever downturn occurs competitor downgraded prompting firm forgo talent hoarding gamma r sufficiently high firm often right laying entrepreneur firm indeed low match turn lead unemployment finally statement proposition strict whenever lambda sufficiently high talent hoarding take place discussion conclusion presented simple yet general reducedform model startup acquisition show acquihires may reflect firm desire hire talented employee may also rooted incentive engage inefficient talent hoarding thus potentially warranting regulator attention show acquihires may decrease consumer surplus increase job volatility acquihired employee thereby giving reason regulatory scrutiny deal baseline model relies several simplifying assumption discus main result analysis hold even relax assumption moreover extension baseline model reveal several additional insight formal analysis result found online appendix people technologyin baseline model startup value lie solely employee however startup also posse valuable technology posit key distinction people technology firm sell license acquired technology employee extend model share startup value also due technology acquirer trade startup technology employee competitor show lowmatch acquirer indeed incentive sell technology highmatch competitor price compensate decrease market profit due efficient competitor thus firm incentive hoard technology incentive hoard talent remains interestingly talent hoarding occurs strictly larger set parameter option resell technology effectively subsidizes talent hoarding dominant firminstead symmetric firm market could characterized dominant firm challenger show incentive hoard talent also emerge asymmetric model reasonable assumption impact acquisition profit dominant firm challenger dominant firm likely hoard talent multiple firmsnext examine market multiple firm may sequentially try acquihire startup focusing cournotoligopoly setting show limit number firm grows large talent hoarding take place intuitively profit risk competitor acquihire becomes smaller number competitor increase reducing incentive engage costly talent hoarding however effect increase number competitor incentive talent hoard necessarily monotonic reason nonmonotonicity increase number competitor addition decreasing profit risk also increase probability highmatch competitor acquire startup effect stronger small number firm clear indeed show parametric example may observe talent hoarding three firm two partial acquisitionsinstead integrating startup acquiring acquirer could allow continue operating independently market moreover instead buying startup outright firm could acquire partial stake context key question startup profit control right allocated first assume following investment entrepreneur receives dividend wage investor receives dividend share startup profit microfound payoff assume presence outside investor give rise agency problem capture reduced form thus allowing wide range agency model maintaining simple relatively tractable setup second considering control right primarily interested investor ability block entrepreneur ability push acquihire investor competitor assume entrepreneur always block acquihire could sell share refuse work acquiring firm entrepreneur would like acquihired investor want acquihire go entrepreneur spirit typical shareholder agreement try drag along investor force transaction assume investor probabilistic chance blocking attempt merely impose probability successfully blocking acquihire increasing investor stake startup find acquihire profitable buying startup letting operate independently implying talent hoarding persists extension withsufficiently strong blocking right investment may constitute viable cheaper alternative acquiring therefore investment cheaper acquhires possibility partial ownership may reduce frequency acquhires increasing frequency transaction taking place notably reduction overall profit lower case investment lowmatch acquhire therefore possibility investment likely lead inefficient market outcome albeit lower degree inefficiency close paper noting model give rise several hypothesis could tested empirically first model predicts positive relationship talent hoarding job volatility acquhired employee second acquhire dominant firm likely motivated talent hoarding third increasing market competitiveness curb talent hoarding always monotonically fourth strength blocking right implied shareholder agreement impact relative frequency acquhires investment proof proposition result reached three step solving benchmark game without talent hoarding talent hoarding comparing benchmarkabsent incentive hoard talent highmatch firm acquuhire thus layoff take place economy enters downturn period acquireer hit adverse shock following layoff observe unemployment competitor lowmatch firm highmatch firm got hit adverse shock finally hiring take place period unless firm lowmatch taken together probability observing layoff period ldeltalambdalambdalambdagammadeltalambdalambdagamma probability observing unemployment period udeltalambdalambdalambdargammagamma talent hoardingfirst note period incentive coincide period absent economic downturn ruling layoff unemployment following downturn three case arise period suppose firm acquuired period firm acquuhire period iff high match period highmatch firm acquuhire lowmatch firm received shock belief competitor high match probability lambdargamma acquuhire larger lambdaa analogously lowmatch firm receiving n shock acquuhire lambdagammargeqlambdaa suppose firm acquuhired period firm lowmatch acquuhire moving second thus firm acquuhire iff high match suppose acquuhire took place period firm low match commonly known leading acquuhires period either moving period firm acquuhire iff high match knowing firm low match since highmatch firm would always acquuhire lowmatch firm nothing yield lambdaleftunderlinepifhgammadeltagammadeltapif rightlambdapiflambdagammadeltaunderlinepifh pifpif payoff acquuhire depends parameter read piflpie lambdargammalambdaa barpiflpiedeltagammadeltagammalambdargamma pifunderlinepifhdeltagammapif lambdagammarlambdaalambdargamma barpiflpiedeltadeltalambdagammapif underlinepifhdeltapif lambdaalambdagammar case lowmatch firm always hoard talent period case hoard talent unless receives shock economic downturn case hoard talent long economy experience downturn thus comparing total payoff nothing acquuhire period acquuhire threshold period read respectively lambdaa lambdaacdotfracgammadelta lambdaa lambdaacdotfracdeltagammadeltagammar gammadeltagamma lambdaa lambdaa lambdaageqlambdaageqlambdaa comparisonto compare hiring separation unemployment need consider three case case lambdargammalambdaa lambdageqlambdaalambdaafracgammadelta hence lowmatch firm acquuhire period layoff unemployment observed le benchmark thus irrespective whether economy hit downturn entrepreneur always employed without separation case lambdagammarlambdaalambdargamma hence lambdalambdaa firm always acquuhire period period firm maintain employment entrepreneur unless receives shock hence probability layoff deltagamma larger benchmark layoff rate l moreover probability transition unemployment deltagammalambda pdn larger u iff fraclambdalambdargamma case lambdaalambdagammar lambdalambdaa firm acquuhire period firm maintain employment period unless hit downturn low match hence probability observing layoff deltagammalambdagammadeltalambdagamma larger l probability observing transition unemployment deltalambdalambdagammalambdapdnlambda larger u instead lambdalambdaa talent hoarding either stage equilibrium identical benchmark finally observe condition minleftfraclambdaalambdafraclambdalambdarightr gamma implies either case case ensures unemployment benchmark missingpageempty coyle j f g polsky acquihiring duke law journal cunningham et al c cunningham c f ederer killer acquisition journal political economy denicolo polo denicolo v polo acquisition innovation entrenchment monopoly available ssrn dijk et al dijk e j l moragagonzalez e motchenkova startup acquisition affect direction innovation cepr discussion paper dp ederer pellegrino ederer f b pellegrino great startup sellout rise oligopoly aea paper proceeding eisfeld eisfeld l entry acquisition software market working paper toulouse school economics european commission european commission commission guidance application referral mechanism set article merger regulation certain category case httpseceuropaeucompetitionconsultationsmergercontrolguidancearticlereferralspdfhttpseceuropaeucompetitionconsultationsmergercontrolguidancearticlereferralspdf fosfuri et al fosfuri motta ronde foreign direct investment spillover worker mobility journal international economics ftc ftc ftc examine past acquisition large technology company httpswwwftcgovnewseventsnewspressreleasesftcexaminepastacquisitionslargetechnologycompanieshttpswwwftcgovnewseventsnewspressreleasesftcexaminepastacquisitionslargetechnologycompanies last accessed fumagalli et al fumagalli c motta e tarantino shelving developing optimal policy merger potential competitor mimeo gans stern gans j stern incumbency rd incentive licensing gale creative destruction journal economics management strategy gautier lamesch gautier j lamesch merger digital economy information economics policy gersbach schmutzler agersbach h schmutzler endogenous spillover incentive innovate economic theory gautier lamesch b b endogenous technological spillover cause consequence journal economics management strategy gautier lamesch cgilbert r j newbery preemptive patenting persistence monopoly american economic review gugler et al gugler k f szucs u wohak startup acquisition venture capital innovation comparative study google apple facebook amazon microsoft tech rep vienna university economics business department economics haegele haegele talent hoarding organization available arxiv preprint arxiv hollenbeck hollenbeck b horizontal merger innovation concentrated industry quantitative marketing economics jin et al jin g z leccese l wagman top acquirer compare technology merger new evidence sp taxonomy international journal industrial organization jovanovic jovanovic b job matching theory turnover journal political economy kampalli et al kampalli k r g rajan l zingales kill zone available ssrn katz katz l big tech merger innovation competition market acquisition emerging competitor information economics policy katz shapiro katz l c shapiro rd rivalry licensing imitation american economic review kim kim j startup acquisition hiring strategy worker choice turnover available ssrn kim startup acquisition relocation employee entrepreneurship strategic management journal letina et al letina schmutzler r seibel killer acquisition beyond policy effect innovation strategy university zurich department economics working paper loh et al loh j p khashabi j claussen kretschmer disruption specialization employee exit vertical acquisition u video game industry available ssrn loh et al mason weed mason r h weed merger policy entry entrepreneurship european economic review motta peitz motta peitz big tech merger information economics policy ng stuart ng w e stuart acquired employee versus hired employee retained turned strategic management journal norback persson norback pj l persson privatization foreign competition journal international economics investment liberalization restrictive crossborder merger policy counterproductive journal international economics norback persson entrepreneurial innovation competition competition policy european economic review ouimet zarutskie ouimet p r zarutskie acquiring labor quarterly journal finance phillips zhdanov phillips g zhdanov rd incentive merger acquisition activity review financial study prado bauer prado j bauer big tech platform acquisition startup venture capital funding innovation information economics policy rasmussen rasmusen e entry buyout journal industrial economics selby mayer selby j k j mayer startup firm acquisition human resource strategy innovation acabire phenomenon working paper shelegia motta shelegia motta kill zone copying acquisition startup direction innovation cepr discussion paper dp teh et al teh c banerjee c wang acquisitioninduced kill zone monash university department economics discussion paper verginer et al verginer l f parisi j v l de jeude riccaboni impact acquisition inventor turnover biotechnology industry available arxiv preprint arxiv verginer et al online appendix publication online appendix cover extension discussed conclusion paper well robustness exercise concerning timing surplus sharing baseline model mentioned footnote people technology consider situation total value startup consists people work startup technology owned startup fundamental difference employee technology acquirer point view technology sold licensed people model implies acquirer resell startup technology competitor whenever sale increase joint profit suppose share value startup generated technology deltain share generated employee delta moreover simplicity assume acquiring technology employee generates delta delta impact acquiring entire startup would firm high match value startup probability lambda assume simplicity match value startup firm applies people technology identically match value firm private information beginning game timing game stage firm observes match quality startup make acquisition startup price p nothing startup accepts reject bid bid rejected game proceeds stage accepted firm sell startup technology price q firm stage like stage role firm reversed accommodate possibility selling startup technology slightly adapt notation main text suppose firm match theta acquisition price p absent sale startup technology profit read textfirm pifbarpifthetap textfirm pifunderlinepiftheta textstartuppwhich coincides profit baseline model although notation different technology part sold price q profit read footnote instance payoff acquiring firm match type theta main text barpiftheta read pifbarpiftheta textfirm pifdeltabarpifthetadelta underlinepifthetapq textfirm pifdeltaunderlinepiftheta deltabarpifthetaq textstartupp thus people joined firm startup increase firm profit decrease firm profit respectively conversely startup technology increase firm decrease firm profit respectively simplify model exposition explicitly model bargaining process two firm instead assume two firm meet bargaining table type revealed resulting surplus selling technology shared equally surplus resulting sale technology given pifdeltabarpifthetadeltaunderline pifthetappifdeltaunderlinepiftheta deltabarpifthetaleftpifbarpifthetap pifunderlinepifthetaright deltaleftbarpifthetaunderlinepif thetabarpifthetaunderlinepifthetaright case interested lowmatch firm sell technology highmatch firm surplus read deltaleftbarpifhunderlinepiflbarpifl underlinepifhright make two assumption profit first corresponds assumption baseline model main text extension notation second ensures surplus resulting technology sale lowmatch highmatch firm positive assumption b barpifhpiebarpifl underlinepifhunderlinepiflgeq assumption b barpifhunderlinepiflbarpiflunderlinepi fh finally break tie assume firm match type trade startup technology obtain following result proposition b assumption b b firm behavior pbe uniquely specified namely firm high match make acquisition sell technology low match make acquisition sell startup technology highmatch lowmatch firm lambdageqlambdaadeltaequivfracpiebarpiflunderline pifhfracdeltaleftbarpifhunderlinepifl barpiflunderlinepifhright nothing otherwiseproof suppose firm made acquisition follows assumption b firm make acquisition high match type irrespective belief moving stage firm belief given prior belief suppose highmatch firm acquired startup assumption b lowmatch firm would buy technology part startup tiebreaking assumption neither would highmatch firm assumption b highmatch firm acquires startup keep technology suppose lowmatch firm acquired startup tiebreaking assumption lowmatch firm would buy startup technology however assumption b technology part would sold highmatch firm anticipating threshold lowmatch firm acquire startup change relative model main text formally nothing yield piflambdaunderlinepifh making acquisition yield pifpielambdabarpifllambdaqdeltabarpif ldeltaunderlinepifh qfracdeltaleftbarpifhunderlinepiflbarpif lunderlinepifhright surplussplitting sale price thus acquisition take place whenever pifpielambdabarpifllambdaleftfracdeltaleft barpifhunderlinepiflbarpiflunderlinepi fhrightdeltabarpifldeltaunderlinepifh rightgeqpiflambdaunderlinepifh rearrange expression proposition one verify delta condition reduces condition main text delta increase threshold lambdaadelta decrease ie acquisition happens larger set parameter intuitively technology part startup sold highmatch firm expected cost hoarding talent fall lowmatch firm leading talent hoarding dominant firm consider situation instead two symmetric firm industry characterized dominant firm challenger firm firm different payoff denote barpidhbarpidlpidunderlinepidlunderline pidh dominant firm barpichbarpiclpicunderlinepiclunderline pich challenger maintain assumption firm assume ibarpifhpifpiebarpifl ii pifgequnderlinepiflunderlinepifh hold findc consider setting proposition firm either engage acquhires nothing corollary b acquhires dominant firm either dominant challenger firm move second engages aquihire high match type dominant firm move first engages acquihire high match type low match type probability challenger firm high match type lambdalambdadequivfracpiepidbarpidlpid underlinepidh b challenger firm move first engages acquihire high match type low match type probability dominant firm high type lambdalambdacequivfracpiepicbarpiclpic underlinepich b corollary follows directly proposition interesting question condition would dominant firm prone talent hoarding challenger firm ie lambdaclambdad following result give set simple sufficient condition proposition b following two inequality hold lambdaclambdad picunderlinepich pidunderlinepidh barpiclpic barpidlpid proof corollary b threshold value lambdadequivfracpiepidbarpidlpidunderline pidhquadtextandquad lambdacequivfracpiepicbarpiclpicunderline pich note condition stated proposition imply lambdadfracpiepidbarpidlpidunderlinepi dhfracpiepidbarpidlpicunderlinepic hfracpiepicbarpiclpicunderlinepich lambdac completing proof intuitively two inequality require dominant firm stand lose startup acquired challenger maybe dominant firm larger market share lose stand gain acquihiring startup larger market share might explanation improvement could offered consumer rapidly simple specification satisfies inequality equal proportional gainloss formally let profit function given beginarrayllllbarpidhhpidbarpidllpid underlinepidlellpidunderlinepidhhpid barpichhpicbarpicllpicunderlinepicl ellpicunderlinepichhpicendarray hl leqellhgeq implies acquihire either competitor proportionally equal effect dominant firm challenger firm long pidpic ie absent acquihire dominant firm higher profit challenger straightforward calculation show two inequality proposition b satisfied dominant firm prone acquihires challenger multiple firm often two firm competing given market extension thus allow ngeq firm competing market baseline firm may sequentially attempt acquihire startup firm match type thetainlh independent draw identical probability prthetahlambda absence acquihire firm make profit pifn firm match type theta make acquihire profit read barpifthetan firm underlinepifthetan firm jneq make thing concrete focus cournot oligopoly setting n firm following inverse demand function pqqnabcdotsuminqi b qi indicates quantity choice firm iinn ab assume demand intercept sufficiently large ensure interior solution let c denote constant marginal cost acquisition occur acquihire one firm assumed reduce marginal cost ctheta thetainhl satisfies hlgeq first establish increasing competition eliminates talent hoarding limit ntoinfty firm acquire startup efficient see thistake one n firm suppose match value startup theta clear piebarpifthetanpifn firm acquire startup whenever possible contrast footnote n firm necessarily necessarily thetaindependent necessarily thetaindependent piebarpifthetanpifn b acquihiring inefficient time necessary condition firm incentive acquihire barpifthetanunderlinepifhnpie b note lh b maximum difference firm profit acquiring acquiring startup cournot specification ntoinfty pifn underlinepifhn converge zero therefore condition b b hold simultaneously n sufficiently large implies whenever b hold firm match value theta conduct acquihire therefore talent hoarding problem occur equilibrium next argue impact competition talent hoarding nonmonotone note n talent hoarding arises equilibrium pieleqlambdaleftpifunderlinepifhrightbar piflpif b comparison suppose n firm anticipates firm acquire startup match value high firm inclined conduct acquihire even draw low match value following condition hold pieleqlambdalambdaleftpifunderlinepifh rightbarpiflpif b consider parametric example lambda b c h l piein one show assumption hold addition condition b violated condition b satisfied thus current example talent hoarding occur equilibrium two firm however three firm talent hoarding sure arise equilibrium partial acquisition section extends baseline model incorporate possibility partial investment firm may acquire minority stake startup without integrating need specify payoff resulting partial acquisition well right come partial ownership formally ability make partial acquisition mean firm additionally try acquire share sin startup continue operate standalone entity contrast model main text allow upfront deferred payment pd standard transaction main text would change anything presence partial ownership allows acquiring firm distinguish least partially investor get part upfront payment entrepreneur also receive deferred payment firm acquires share bid pd payoff read pifspiespd entrepreneur payoff spieswspd pie capture startup profit net potential wage paid entrepreneur function size external ownership profit accrue firm entrepreneur proportionate stake startup correspondingly w constitutes entrepreneur wage net effort cost different degree outside ownership particular piepiew entrepreneur owns entire startup thus obtains profit pay netofeffort wage payoff coincides initial payoff baseline model firm payoff unchanged pif firm acquires stake startup receives share profit dilution ownership give rise moral hazard entrepreneur side capture reduced form imposing following assumption assumption b assume piesws decreasing piewpieb assumption b capture moral hazard arising entrepreneur longer fully owns startup piesws decreasing reflects reduced effort entrepreneur result agency piewpiew capture firstbest value startup fully owned entrepreneur strictly higher secondbest value entrepreneur actually employee stake startup timing game follows first stage firm opportunity make bid entrepreneur acquire share sin startup make acquihire entrepreneur accepts bid acquihire game end otherwise move stage ownership structure startup depending whether entrepreneur accepted firm bid second stage firm make acquihire making pershare bid owner startup restrict attention bid pd pgeqpies owner expropriated entrepreneur accept bid game end entrepreneur accepts firm either also accept try block transaction succeeds probability q q weakly increasing function q q nature determineswhether potential blocking attempt succeeds game end benchmark first consider case ownership stake convey blocking right proposition b assumption b without blocking right ie q sin firm behavior pbe uniquely specified namely firm draw high match type make acquiring draw low type make acquiring lambdageqlambdaa nothing otherwise proof see proof proposition b contains special case result proposition b show partial ownership startup enough change firm behavior relative setting acquhires proposition indeed since investment profitable prevent highmatch firm making acquhire firm continue either nothing make acquhire depending probability highmatch firm materializing next result show ownership accompanied measure control startup make investment attractive firm proposition b assumption b blocking right firm behavior pbe uniquely specified namely firm draw high type make acquhire draw low type threshold value lambda nothing threshold investment depending model parameter may even higher threshold acquhire comparing threshold across proposition b b observe presence blocking right investment increase parameter space form talent hoarding occurs however possibility making investment instead acquhire may also mitigating effect relative setting acquhires talent hoarding mean investment create smaller inefficiency mean acquhires put differently allowing investment increase extensive margin talent hoarding partially decrease intensive margin proof solve game backward stage observe firm belief probability firm low type otherwise acquhire would taken place stage firm three action nothing making bid accepted entrepreneur firm making bid accepted entrepreneur understand observe payoff firm entrepreneur following firm investment size price pd read beginarrayrlmboxfirm pifspiespd mboxentrepreneurspieswspdendarray hence firm would try block bid pd resulting lower payoff entrepreneur would accept bid yielding lower payoff given constraint firm choose among three option nothing receive payoff pif ii make minimum bid firm entrepreneur accept yielding payoff barpifthetapieswspifunderlinepiftheta firm iii make bid entrepreneur accepts risking blocking attempt firm third option provides expected payoff firm qspifqsbarpifthetapiesws let u consider lowmatch firm first comparing nothing inducing entrepreneur accept obtain latter move better firm whenever barpiflpieswsgeqpif follows assumption b condition necessarily satisfied let hat threshold condition satisfied let compare nothing inducing shats obtain inducing better whenever barpiflpieswspifunderlinepiflgeq q spifqsbarpiflpiesws rearrangement rewritten qsbarpiflpifpieswsgeqpif underlinepifl b since righthand side b positive lefthand side negative shats condition never satisfied thus shats low type nothing let u compare firm inducing entrepreneur versus inducing accept sgeqhats inducing better whenever condition b hold since lefthand side b increasing define slinhats threshold condition satisfied overall lowmatch firm take following action shats nothing hatsleq sleq sl induces entrepreneur accept ssl induce entrepreneur firm accept offer next turn highmatch firm comparing payoff nothing inducing entrepreneur follows assumption firm always find former option inferior need compare payoff inducing versus entrepreneur particular inducing optimal whenever qsbarpifhpifpieswsgeqpifunderline pifh may satisfied threshold shin threshold high type induce entrepreneur note clear whether sh sl bigger stage observe firm belief firm type given prior firm acquire different stake turn may induce different response firm specially learned lowmatch firm may either nothing n induce entrepreneur e induce entrepreneur firm accept bid b highmatch firm may either e b follows let aa denote action profile low highmatch firm eg nb mean firm nothing low type induces accept type high let deltasequivpieswspiew following firm payoff resulting acquisition induces indicated firm behavior ne lambdaqsunderlinepifhlambdaqs pifdeltas nb pifdeltas eb lambdaqspiflambdaqs underlinepifldeltas bb pifdeltas ee qspifqslambdaunderlinepifh lambdaunderlinepifldeltas lambdaqsunderlinepifhlambdaqs pifdeltas illustrate calculate payoff consider case ne lowmatch firm nothing highmatch induces entrepreneur accept firm would try block acquuhire attempt firm observe lowest bid entrepreneur willing sell stake firm pdpiewspiesws considering case ne lowmatch firm would nothing yielding payoff pifspiespiewspiesws pifdeltas b highmatch firm would make bid firm try block succeeding probability q yielding following payoff firm qsleftpifdeltasrightqsleftunderlinepi fhdeltasright badding b b multiplying probability lambda lambda respectively obtain expression list finally complete list note acquuhire give payoff barpiflpiew firm nothing result lambdaunderlinepifhlambdapif footnote observe size firm investment across case list different investment size induce different behavior firm determine firm equilibrium strategy need distinguish three case three case based value threshold sh sl hat recall lowmatch firm nothing hat induce entrepreneur hat sl potentially induce sl highmatch firm induce entrepreneur sh may induce case shleqhatsleq sl note allows four type firm behavior following investment sleq sh ne lowmatch firm nothing highmatch induces entrepreneur shsleqhats nb namely lowmatch firm nothing highmatch induces hatssleq sl lowmatch firm induces entrepreneur highmatch induces eb ssl type firm induce end bb comparing payoff observe acquuhire dominates investment inducing bb eb investment inducing nb dominates acquuhire thus remaining action nothing inducing ne inducing nb nelambdaqsunderlinepifhlambdaq spifdeltas nbpifdeltas nlambdaunderlinepifhlambdapif investment necessary induce nb bigger one ne smaller hat pifpieswsgeqbarpifl note lambdato nothing dominates type investment lambdafracpiewpieswspifunderlinepi fh inducing nb dominates n depending parameter ne nb better investment low enough lambda inducing ne always better summary threshold value lambda nothing best larger lambda inducing ne better large lambda depending parameter inducing nb may best case hatsleq shleq sl note allows four type firm behavior following investment ne ee eb bb proceeding find threshold value lambda nothing best larger lambda inducing ne better large lambda depending parameter acquihire may best case hatsleq slleq sh note allows four type firm behavior following investment ne ee bb proceeding find threshold value lambda nothing best larger lambda inducing ne better large lambda depending parameter acquihire may best unknown order move consider variation baseline model order firm move privately drawn nature uniform probability hence firm necessarily moving first anymore specifically firm get interact startup directly observe whether firm already interacted startup still firm make bid acquihire startup entrepreneur accept reject exante probability firm private match type unchanged payoff following acquisition obtain following result proposition b assumption exists symmetric equilibrium firm acquihire startup price pie independently type lambdageqlambdaprimeaequivfracpieunderlinepifl barpiflunderlinepiflunderlinepifh b proof suppose firm j behaves suggested proposition entrepreneur accepts bid least pie consider incentive firm given assumption dominant strategy highmatch firm make bid pie acquihire whenever chance consider lowmatch firm given firm j would always acquihire firm know moving first hence nothing yield payoff lambdaunderlinepifhlambdaunderlinepifl acquihire yield barpiflpie hence acquihire optimal lambdageqlambdaprimea completing proof result show result proposition remains qualitatively unchanged firm order move particular talent hoarding continues arise long high type sufficiently likely surplus sharing modify baseline model allow arbitrary degree surplus sharing entrepreneur firm acquihire take place thus firm still move sequentially case acquihire entrepreneur receives share gammain surplus define surplus difference joint payoff arising acquihire joint payoff arising case acquihire proposition b talent hoarding happen following condition hold gammaleqfracbarpiflunderlinepifhpiebarpif hpifpie proof solve game backward consider highmatch firm surplus resulting acquihire given barpifhpifpie acquihire take place resulting payoff firm entrepreneur read pifgammabarpifhpifpie piegammabarpifhpifpie respectively consider lowmatch firm surplus read barpiflpifpie acquihire take place moving period consider highmatch firm surplus resulting acquihire read barpifhlambdaunderlinepifhlambda piflambdapielambdapiegammabarpifhpif pie barpifhpifpielambdagammalambda pifunderlinepifhgeq acquihire take place consider lowmatch firm surplus resulting acquihire read barpifhpifpielambdagammalambdapifunderline pifhbarpiflbarpifh expression positive implying acquihire profitable whenever lambdageqlambdaasequivfracpiepifbarpiflpif underlinepifhgammabarpifhpifpie pifunderlinepifhgammabarpifhpifpie lambdaasleq whenever condition stated proposition hold title ssthreshless start senderside tcp intelligence long fat network transcription sshreshless start senderside tcp intelligence long fat network xiao ludagger ke zhangdagger chuan heng fohddagger cheng peng fudagger dagger school computer engineering nanyang technological university singapore ddagger department electrical engineering university surrey uk abstract measurement show tcp flow internet shortlived flow stay operation tcp startup phase however many previous study indicate traditional tcp slow start algorithm perform well especially long fat network two obvious problem known impact slow start performance blind initial setting slow start threshold aggressive increase probing rate startup phase regardless buffer size along path current effort focusing tuning slow start threshold andor probing rate startup phase considered effective prompted investigation different approach paper present novel tcp startup method called thresholdless slow start ssthreshless start need slow start threshold operate instead ssthreshless start us backlog status bottleneck buffer adaptively adjust probing rate allows better seizing available bandwidth comparing traditional major modified startup method simulation result show ssthreshless start achieves significant performance improvement startup phase moreover ssthreshless start scale well wide range buffer size propagation delay network bandwidth besides show excellent friendliness operating simultaneously currently popular tcp newreno connection introduction tcp connectionoriented reliable inorder transport protocol carry application ranging bulk data transmission web browsing year tcp evolved original tcp tahoe currently widely used tcp newreno tcp us slow start startup phase probe capacity network path unknown characteristic tcp probing rate controlled congestion window cwnd tcp connection transmit cwnd amount unacknowledged packet tcp carry today internet traffic constitutes total number flow internet among tcp traffic shortlived tcp flow spend operational lifetime within slow start process cwnd ramp exponential manner measurement show tcp traffic short flow implies majority data transmission internet dominated tcp startup behavior slow start process cwnd set one four tcp packet initially value incremented one packet upon reception ack order probe test available bandwidth increment cwnd doubled round trip time rtt acks returned result value cwnd increased monotonically exponential rate every rtt network cope amount transmission tcp connection network congestion signaled triple duplicated acks seriously timeout detected tcp sender congestion signal detected tcp connection end slow start process congestion avoidance process take adjustment cwnd unlike slow start congestion avoidance maintains linear increment cwnd every rtt avoid congestion exponential increment cwnd slow start may significantly overshoot available bandwidth probing testing bandwidth availability overshooting cwnd may cause serious congestion packet loss require long time recover prevent overshooting slow start introduces parameter called slow start threshold ssthresh cwnd reach ssthresh overshooting likely tcp connection end slow start process let congestion avoidance process take turning growth cwnd conservative linear rate general current slow start process combine estimation bandwidth availability described ssthresh rate probing algorithm order achieve high bandwidth utilization depending accuracy bandwidth availability estimation corresponding rate probing algorithm designed achieve certain high level bandwidth utilization slow start process example extreme case bandwidth availability estimation highly accurate rate probing unnecessary tcp sender immediately operate optimal rate based estimation contrast inaccurate bandwidth availability estimation accompany prudent rate probing algorithm compensate inaccuracy estimation however slow start known extremely inefficient two obvious problem current slow start algorithm design lead inefficiency problem particularly severe long fat network lfns first obvious problem blind initial setting ssthresh due lack bandwidth availability estimation blind initial setting ssthresh prudent rate probing algorithm sought however current slow start process us exponential rate increment probing aggressive rate probing algorithm combination amplifies performance penalty problem precisely ssthresh set high compared bandwidthdelay product bdp represents capacity network pipe tcp connection may inject packet network causing congestion problem serious lfns cwnd doubled every rtt aggressive increase may easily cause burst loss consequent timeout overshooting network capacity conversely ssthresh set low tcp connection exit slow start enter congestion avoidance prematurely thus cwnd may take long time reach optimal operating point match capacity lfn case cause low link utilization call drawback blind ssthresh setting problem another problem current slow start related temporal queue buildup occurs slow start packet buildup buffer occurs tcp connection increase cwnd transmits packet within rtt round adequate buffer size critical hold buildup packet otherwise packet loss occur since slow start disregard backlog status bottleneck buffer packet loss may occur even cwnd reached available bandwidth significantly degrades performance problem significant buffer size bottleneck router much smaller bdp call drawback temporal queue buildup problem problem observed discussed current effort improving performance tcp slow start largely focus improving bandwidth estimation optimal sshtresh setting andor designing appropriate rate probing algorithm based reliability bandwidth availability estimation however due limited ability tcp sender observing network resource together fast changing network bandwidth availability accuracy bandwidth availability estimation largely uncertain giving basis design adequate rate probing algorithm optimizing slow start performance recognizing challenge finding optimal setting sshtresh probing algorithm paper take different approach bypass need ssthresh setting influence greatly performance solution called thresholdless slow start ssthreshless start pronounced sthreshless start senderside enhancement offer immediate benefit upon deployment key idea method make use backlog status bottleneck buffer monitored rtt refine cwnd ramping behavior adaptively adjust probing rate meet available network capacity sshreshless start proposes alternating exponential linear growth cwnd based backlog status tcp startup phase preliminary result reported shown encouraging performance gain tcp startup paper extensive simulation depth investigation conducted evaluate benefit rate alternation tcp startup performance briefly alternating two rate achieves benefit three aspect firstly eliminates need ssthresh decide congestion avoidance take end exponential growth cwnd without ssthresh blind ssthresh setting problem exist sshreshless start word network status detection translate ssthresh instead status used directly control rate probing algorithm aggressive prudent mode cwnd increased continuously alternating exponential linear rate congestion signal detected secondly sshreshless start monitor backlog status switch growth rate cwnd linear queue buildup observed prevents continuous queue buildup buffer hence avoids temporal queue buildup problem materialized packet lost event available bandwidth reached finally since cwnd increase monotonically sshreshless start packet loss inevitable due finite availability bandwidth however network congestion approach number backlogged packet bottleneck buffer increase signal sshreshless start turning linear growth rate cwnd preemptive switch linear growth rate cwnd network congestion approach allows fast recovery packet loss event eventually occurs implement tcp startup solution combine newreno newreno chosen several existing startup modification example hoe change limited slow start also refined based newreno also allows direct comparison existing modification comparing traditional slow start existing modification enhancement show significant improvement link utilization startup process various bdp buffer configuration besides enhancement also show good convergence behavior without adversely affecting coexisting tcp connection therefore throughput gain startup achieved using spared bandwidth effectively rather aggressively depriving bandwidth coexisting tcp connection remainder paper organized follows start demonstrating problem slow start simulation next section summarizing related work section iii describe sshreshless start section iv validate intensive simulation experiment section v finally conclude paper section vi ii problem traditional slow start illustrate inefficiency slow start lfn conduct simulation experiment using n fig show considered network topology used commonly purpose study fig tcp src represents tcp sender tcp dst represents tcp receiver router b two droptail bottleneck router side link bandwidth mbps oneway delay m two router bottleneck link mbps bandwidth m oneway delay convenience congestion window size measured number packet packet size byte ack set byte long give bdp value packet bottleneck router packet buffer size bdp tcp source run newreno traditional slow start simulation experiment conducted paper also use dumbbell topology varying buffer size oneway delay bandwidth traditional slow start tcp connection start initial ssthresh set arbitrary value ranging kb extremely high blind ssthresh setting problem severely degrade tcp startup performance especially lfn conduct simulation illustrate impact ssthresh setting performance slow start short transfer setup consider single tcp connection three case different ssthresh value one higher one equal one low bdp value precisely set ssthresh value packet simulation label nr s l nr s nr s respectively plot cwnd sequence number evolution three studied case fig seen result fig nr s l overestimate bdp quickly overshoot bdp produce burst loss router burst loss cause series timeout event tcp force cwnd exit exponential grow phase prematurely timeout restart ssthresh set much lower bdp case nr s see tcp fig network simulation topology connection exit slow start switch congestion avoidance phase prematurely case result low bandwidth utilization illustrated fig b whereas ssthresh set appropriately see best performance amount tcp connection rapidly grows bdp exit slow start maintain stable cwnd throughout simulation period overshooting bdp cwnd case nr s l clearly indicated great discrepancy sent received sequence number shown fig b record link utilization highest sequence number packet sent case table comparing throughput clear inadequate setting ssthresh affect greatly transmission capability short connection however even ssthresh set match bdp start found cwnd may still fail reach bdp also reported others literature illustrate effect test tcp connection whose initial ssthresh match bdp buffer size set time bdp cwnd buffer utilization evolution startup plotted fig seen cwnd reach packet bottleneck buffer hit maximum utilization small amount packet drop recorded since tcp sender take rtt period realize packet loss continues ramp cwnd doubling value packet resulting significant packet drop upon detection first triple duplicate acks tcp connection switch fast recovery cut ssthresh increment cwnd stall duplicate acks returned period since cwnd remains constant queue barely build buffer unable recover lost packet timeout event finally occurs around cwnd set ssthresh adjusted connection return slow start much lower ssthresh value point tcp connect seriously underestimated available bandwidth result significant underperformance cause problem attributed failure probing rate control temporal queue buildup occurs bottleneck buffer iii related work one critical problem traditional slow start performance inefficiency tcp sender lack ability estimate network condition properly improve tcp startup performance many approach attempted past achieve better estimation network bandwidth availability andor design rate probing mechanism le susceptible accuracy bandwidth availability estimation generally effort enhance startup performance categorized four different strategy fig comparison newreno different ssthresh settingdescribed rate probing refinement approach approach tcp connection us different rate probing mechanism traditional one achieve better utilization available network bandwidth proposed mechanism also use dynamic rate probing mechanism returned acks used indicate network status adjust rate probing mechanism bandwidth estimation approach approach tcp connection performs estimation network assist rate probing estimation may perform continuously historybased approach approach tcp connection us historical data network resource availability cached previous concurrent connection estimate current network status derive optimal parameter tcp connection start routerassisted approach approach tcp connection us direct feedback router indicate network resource adjusts sending rate accordingly rate probing refinement approach rate probing refinement approach seek modification cwnd ramping behavior increment probing rate le susceptible accuracy initial guess bandwidth availability estimation typical example approach limited slow start l us additional threshold prevent slow start algorithm increasing fast introduces new slow start threshold maxssthresh prevents probing rate growing excessively high precisely cwndleqmaxssthresh cwnd double rtt traditional slow start maxssthreshcwndleqssthresh cwnd increased fixed amount maxssthresh packet every rtt condition reduces growth rate cwnd turn reduces number drop fig ramping behavior newreno slow start ssthreshpkts buffer sizebdp startup however blind ssthresh setting problem remains unsolved approach scheme based similar strategy capstart smoothstart suffers shortcoming tcp vega demonstrated packet delay bottleneck router estimated observing rtt packet transmission provides better guidance tcp sender either refine rate probing strategy adjust slow start parameter ssthresh enhance slow start performance based observed packet delay tcp vega us different rate probing strategy namely double cwnd every rtt exit slow start phase estimation packet delay exceeds certain threshold method however often lead low bandwidth utilization due premature exiting slow start result temporary queue buildup buffer caused bursty tcp transmission enhancing usage rtt information delaybase slow start db us rtt information adjust maxssthresh indirectly prevents cwnd overshooting avoid premature exiting slow start phase however requires threshold rtt function setting appropriate threshold remains challenge bandwidth estimation approach bandwidth estimation approach aim solve arbitrary ssthresh setting problem setting estimated bdp value mitigate effect overshooting maintaining original rate probing strategy bandwidth estimation first introduced using packet pair bandwidth measurement technique packet pair measurement us interarrival time ack pair received source infer bottleneck bandwidth along path based technique hoe proposed set initial ssthresh product measured delay estimated bandwidth however attribute aggressive cwnd increase manner hoe change may suffer temporary queue overflow multiple loss bottleneck buffer large enough compared bdp many flow coexisting several improvement based packet pair bandwidth measurement proposed enhance hoe method nevertheless evidenced packet pair technique give reliable estimation bottleneck link capacity rather available bandwidth network path hence limited performance gain achieved beside packet pair technique packet train estimation measurement appears reliable estimation instantaneous available bandwidth path early slow start exit esse proposed us observation series ack returning time estimate instantaneous available bandwidth set initial ssthresh value paced start proposed us difference data packet train dispersion ack train dispersion interactively bandwidth estimation sstthresh setting tcp westwood us eligible rate estimation ere relies ack train receiver bandwidth estimation adaptive start proposes using ere assist slow start however research carried shown dispersion long packet train measure available bandwidth path rather tell another bandwidth metric known average dispersion rate adr value available bandwidth capacity path direct use dispersion long packet train available bandwidth measure may cause misleading estimation leading undesirable performance inspired finding hybrid slow start combine ack train estimation increase packet delay slow start algorithm performance enhancement summary estimation technique achieve certain performance gain compared slow start us arbitrary default ssthresh value performance gain limited due accuracy estimation caused various factor one obvious factor due additional manipulation ack reply modern tcp operation ack clustering compression delayed ack affecting accuracy bandwidth estimation factor tcp coarsegrained clock rerouting route asymmetry forward reverse path also pose challenge accuracy bandwidth estimation besides even accurate bandwidth estimation technique achieve approach using bandwidth estimation deal hence resolve temporal queue buildup problem historybased approach historybased approach make use history information cached previous concurrent connection improve slow start performance based assumption host subdomain would experience similar performance distant host usually scheme fall catalog intended restart transmission connection idle long time benefit certain application ie web browsing transaction tcp cache previous connection count history order save threeway handshake certain situation speed future connection establishment expanding available historical information tcp control block sharing congestion manager propose sharing slow start related information among recent concurrent tcp connection end node incremental enhancement falling within approach include tcp shared passive network discovery spand tcpspand adaptive tcp slow start summary historicalbased approach make use historical information help new tcp connection tune appropriate sending rate however usefulness historical information may vanish quickly due fast changing load condition network besides approach unable benefit tcp startup performance historical information exist example connection established new destination traditional slow start adopted instead routerassisted approach illustrated assistance router tcp rate control effective achieve high utilization network bandwidth measured directly router offer accurate bandwidth availability utilization role rate probing algorithm significantly reduced quickstart xcp typical example approach quickstart tcp sender advertises desired sending rate threeway handshake let network hop along path approve reject reduce requested sending rate way sender quickly tune appropriate rate without time consuming probing procedure comparatively xcp proposes finegrained feedback tcp sender decide sending rate summary routerassisted approach give potential significantly improve utilization network especially startup phase tcp connection require special operation router prevents immediate deployment thus attractiveness high iv enhancement shall introduce novel startup scheme called ssthreshless start goal address two aforementioned problem traditional slow start discussed section iii accuracy limitation bandwidth estimation historybased approach deployment drawback routerassisted approach argue rate probing refinement approach remains potential approach offer significant performance gain slow start immediate deployment however main challenge rate probing refinement approach ability quickly probe available bandwidth setting sending rate ensure high utilization based certain bandwidth availability estimation translated ssthresh setting recognizing challenge finding optimal setting ssthresh based certain bandwidth availability estimation adequate rate probing algorithm take difference bypass need ssthresh novel attempt design new startup scheme achieves efficient sending rate also cope well temporal queue buildup problem owing needle ssthresh call startup scheme thresholdless slow start ssthreshless start detail ssthreshless start following subsection backlogged packet detecting tcp vega known delaybased congestion control mechanism since us rtt packet transmission estimate backlog status buffer adjust congestion control strategy past research shown estimation term delayed packet due buffering bottleneck router lead accurate estimation network traffic load condition capitalizing effective estimation reuse estimation mechanism proposed ssthreshless start tcp vega throughput difference calculated diffexpectedactualleftfraccwndbaserttfraccwndrttright basertt minimum measured rtt rtt actual round trip time tagged packet denote delayed packet bottleneck buffer n rttbaserttnactual rearranging equation obtain nleftfraccwndbaserttfraccwndrttrighttimes basertt tag startup phase use calculate delayed packet bottleneck buffer provides information backlog status ssthreshless start ssthreshless start key idea ssthreshless start make use backlog status bottleneck buffer monitored rtt refine cwnd ramping behavior adaptively adjust probing rate meet available network capacity rather translating network status ssthresh network status directly used control rate probing algorithm propose twomode operation rate probing procedure namely linear increase mode adjustive increase mode mode intended operate situation queue buildup detected detected respectively recall estimated delayed packet number n certain number estimated delayed packet ngeqbeta used signal packet building event bottleneck router quantity beta design time protocol parameter ssthreshless start switch linear increase adjustive increase mode beta arbitrary set shall show slow start performance insensitive threshold based ssthreshless start measure n estimation backlog bottleneck router compare threshold beta estimated number backlog packet exceeds beta assume bottleneck router experiencing packet building backlog clear beta tcp sender said experienced one congestive event scheme tcp sender monitor congestive status record total number congestive event experienced rate probing purpose tcp connection begin binary exponential increase cwnd traditional slow start different traditional slow start tcp continuously monitor backlog packet monitored number backlog packet exceeds beta indicating occurring packet building ssthreshless start take control cwnd ssthreshless start operates either linear increase mode adjustive increase mode always start linear increase mode linear increase mode tcp connection increase cwnd one every rtt confines cwnd increment linear rate ssthreshless start activated estimated backlog packet exceeds beta first time thus starting ssthreshless start conservative increase manner help clear temporary buildup slowing transmission source buffer avoid buffer overflow multiple loss ssthreshless start remains mode long monitored number backlog packet exceeds beta monitored number backlog packet fall beta ssthreshless start switch adjustive increase mode cwnd increment rate turn aggressive aggressiveness increment also depends number encounter congestive event design congestive event tcp connection encounter milder increment cwnd cwnd increase monotonically either linear increase mode adjustive increase mode likelihood cwnd reaching available bandwidth also increase milder increment cwnd used prevent overshooting available bandwidth causing serious loss note different delaybased tcp startup scheme ie tcp vega db delaybased information used find threshold exiting startup phase ssthreshless start us backlog status dynamically switch cwnd ramping behavior exponentiallinear cycle adaptively seizing available bandwidth ssthreshless start exit packet loss occur pseudo code ssthreshless start given following ifthree dupacks receivedstartup phase exitsthen sstthreshcwnd congestioneventno congestivestatus congestive status last rtt switch congestion avoidance mode else ifngeqbeta congestivestatus cwndfraccwnd ack linear increase mode else ifcongestivestatus congestioneventno congestivestatus endif cwndmaxleftfraccwndfraccongestioneventnoright every ack adjustve increase mode endif endif algorithm sshreshless start pseudo code congestiveeventno indicates time congestive event occurred initial value set according design shown algorithm increment cwnd adjastive increase mode set fraccwnd every ack word every rtt cwnd increased value cwnd v performance evaluation section present numerical result sshreshless start compared tradition slow start variant given different network environment dissimilar parameter setting first evaluate parameter setting sshreshless start demonstrate ramping behavior throughput advantage variant finally also show fairness friendliness ssthreshless start parameter setting fig vary value switch beta ass sensitivity performance ssthreshless start surprisingly varying beta cause much difference performance present table ii numerical detail link utilization highest sequence number packet sent three different beta value small large seen table ii performance difference small indicates value beta mainly decisive factor performance make ssthreshless start tolerable inaccuracy tcp timer affect backlog estimation setting beta shown fig beta go large ramping behavior slightly aggressive extreme beta set infinity ssthreshless start behave like traditional slow start since congestive event never occur contrast beta set small value occurrence congestive event increase cwnd grows conservative rate based past experience conservative growth cwnd may significantly reduce burst loss thus suggest smaller beta setting fig ssthreshless start cwnd evolution different value beta recommend setting beta setting give conservative growth cwnd yet maintain high link utilization reported table ii ssthreshless start ramping behavior fig compare single flow ramping behavior sshreshless start slow start vega along monitored backlog bottleneck router buffer size set small value packet frac bdp ssthresh slow start set accurate value bdp case depending instantaneous backlog status sshreshless start switch exponential linear rate increase cwnd allows cwnd adaptively ramp bdp timely manner cwnd value reach eligible window size around maintains high link utilization ever since monitoring backlog status sshreshless start would switched linear rate occurrence packet loss end sshreshless start operation help congestion avoidance operation take sshreshless start cope loss comparison aggressive slow start increase cwnd bdp size around however temporary queue buildup occurs packet drop following fast recovery fails recover multiple loss since slow start remains exponential growth loss occurred cause timeout consequently sshtresh repeatedly adjusted downward eventually small value focus tcp connection enter congestion avoidance phase prematurely vega also enters congestion avoidance prematurely right backlog exceeds threshold conservative manages avoid multiple loss operates low throughput evaluation time shown fig neither slow start vega capable seizing eligible bdp majority available bandwidth left unused listed table iii sshreshless start capture high link utilization slow start vega utilize throughput comparison subsection compare newreno sshreshless start sl hoe change hc limited slow start l slow start small ssthresh packet s slow start large ssthresh packet s l tcp vega show sshreshless start significantly improves startup performance regard various buffer size oneway delay bandwidth focus startup performance evaluate performance first second addition use throughput ratio calculated throughput sshreshless start variant measure evaluate performance enhancement proposal fig fix bandwidth mbps delay m vary buffer size packet packet study impact buffer size performance case also evaluate slow start ssthresh setting accurate bdp size s show buffer robustness proposal evident high throughput achieved sshreshless start test case also seen buffer size small hoe change limited slow start even slow start ssthresh set accurate bdp suffer severe performance degradation startup algorithm fail obtain high throughput even help ample buffer size case small buffer size bdp shown table iv performance benefit sshreshless start significant gain time variant aforementioned one characteristic lfn long link delay thus ass performance long rtt bottleneck oneway delay m m bandwidth buffer size fixed mbps bdp respectively fig show throughput comparison scenario subtle change throughput newreno sshreshless start hoe change show fig comparison different tcp startup scheme bufferbdp first sability scale well long delay startup algorithm suffer performance degradation delay increase case largest tested oneway delay m listed table vc note throughput ssthreshless start achieves time traditional slow start fig newreno nr throughput versus buffer size first evaluate performance ssthreshless start respect another characteristic lfn high bandwidth vary bottleneck bandwidth mbps mbps besides fix bottleneck oneway delay m buffer size bdp fig report newreno throughput achievement different startup scheme scenario shown newreno ssthreshless start hoe change scale well wide range bandwidth scheme lack ability adapt network bandwidth effectively leading poor throughput achievement case largest tested bandwidth mbps listed table vd notably ssthreshless start outperforms traditional slow start time term throughput dynamic bandwidth considering available bandwidth may change several time startup phase tcp session dynamic environment ie connection may join leave link wellperformed startup scheme aware instantaneous available bandwidth adjust cwnd ramping strategy ass capability ssthreshless start network dynamic network load add burst udp crosstraffic set mbps starting first second stopping fifth second fig show comparison ssthreshless start slow start scenario first second cwnd ssthreshless start ramp usual initiating burst udp traffic ssthreshless start detects decrease available bandwidth quickly backlogged queue accordingly half cwnd growth rate time congestive event happens reaching available bandwidth cwnd turn linear increment right termination udp traffic flow ssthreshless start detects clearing bottleneck backlog alternate cwnd growth rate back exponential simulation show alternation exponential linear growth rate fig newreno nr throughput versus delay first cwnd cope well dynamic changing bandwidth availability hand due aggressive blind increase strategy slow start incurs loss upon presence udp flow following fast recovery fails recover multiple loss lead consequent timeout addition compare transmission capability link utilization highest sequence number packet sent recorded table amount data sshreshless start manages send almost two time larger slow start make sshreshless start greatly benefit short flow last several second dynamic environment friendliness slow start fig show coexistence multiple sshreshless start slow start connection consider five newreno connection connection newreno slow start ssthresh packet connection newreno sshreshless start connection start fig newreno nr throughput versus bottleneck bandwidth first second investigate effect ssthreshless start slow start startup time connection start th second estimate effect ssthreshless start existing tcp connection shown ssthreshless start utilizes network bandwidth left unused slow start connection beginning several round synchronized packet loss cwnd connection converges value connection join network adversely affect existing tcp connection able probing rate quickly reach state concurrent tcp connection finally five connection converge window size around packet size onefifth bdp connection utilizes share fairly demonstrating friendliness newreno ssthreshless start bandwidth sharing traditional slow start vi conclusion paper present novel senderside enhancement ssthreshless start improve tcp startup performance long fat network key idea make use backlog status bottleneck buffer monitored rtt refine cwnd ramping behavior dynamically adaptively adjusting probing rate reach available bandwidth alternating exponential linear growth rate fig comparison different tcp startup scheme udp crosstraffic mbps udp traffic start sec stop seccwnd based backlog status sshreshless start eliminates need slow start threshold sstthresh blind sstthresh setting problem vanishes use backlog status bottleneck buffer also allows sshreshless start cope various buffer size especially small buffer size cause performance degradation many tcp startup variant simulation result demonstrated compared traditional slow start many variant sshreshless start significantly improves link utilization startup phase meanwhile show good performance wide range buffer size propagation delay bandwidth bottleneck moreover sshreshless start show good convergence behavior without adversely affecting coexisting tcp connection therefore aware backlog status enhanced throughput startup phase achieved using bandwidth effectively fairly rather aggressively depriving bandwidth coexisting tcp connection reference x lu k zhang c p fu c h foh senderside tcp startup enhancement highspeed longdelay network proceeding wcnc sydney australia april v jacobson congestion avoidance control proceeding acm sigcomm stanford ca pp august floyd henderson newreno modification tcp fast recovery rfc april l brakmo w omalley et al tcp vega new technique congestion detection avoidance proceeding acm sigcomm london u k pp october feldmann j rexford r caceres efficient policy carrying web traffic flowswitched network ieeeacm transaction networking vol pp december h shimonishi sanadidi gerla improving efficiencyfriendliness tradeoff tcp wiredwireless combined network proceeding icc may c e palazzi residual capacity estimator tcp wiredwireless link proceeding wcc student forum ifip world compute congress toulouse france aug fig coexistence multiple sshreshless start slow start connection cwnd two newreno flow overlap b pancost cc chen sanadidi gerla buffer estimate filtering using dispersion delta proceeding pfldnet k kaneko j katto reno friendly tcp westwood based router buffer estimation proceeding joint icas icns floyd limited slow start tcp large congestion window rfc march lawrence sbrakmo larry lpeterson tcp vega end end congestion avoidance global internet ieee jsac journal selected area communication vol october haining wang care l williamson new tcp congestion control scheme smoothstart dynamic recovery proceeding ieee mascot montreal canada july h wang h xin d reef kg shin simple refinement slow start tcp congestion control proceeding iscc antibes france july leith r shorten g mccullagh j heffner l dunn f baker delaybased aimd congestion control proceeding pfldnet february dirceu cavendish kazumi kumazoe masato tsuru yuji oie mario gerla capstart adaptive tcp slow start high speed network first international conference evolving internet august allman floyd partridge c increasing tcp initial window rfc october keshav controltheoretic approach flow control proceeding acm sigcomm pp zurich switzerland september j c hoe improving startup behavior congestion control scheme tcp proceeding acm sigcomm pp october maron pdruschel tcp improving startup dynamic adaptive timer congestion control technical report tr department computer science rice university ren wang giowanni pau kenshin yamada mysanadidi mario gerla tcp startup performance large bandwidth delay network proceeding ieee infocom april ren wang kenshin yamada yahya sanadidi mario gerla tcp senderside intelligence handle evolution large leaky pipe ieee journal selected area communication vol february ccasetti mgerla smascolo mysanadidi rwang tcp westwood bandwidth estimation enhanced transport wireless link proceeding mobicom rome italy july sgiordano gprocissi frusso raffaello secchi use pipesize estimator improve tcp transient behavior proceeding ieee international conference communication volpp may c partridge rockwell allman r krishnan j sterbenz swifter start tcp bbn technical report france j lawasgrodek diepchi tran evaluation swift start tcp longdelay environment glenn research center cleveland ohio october ningning hu peter steenkiste estimating available bandwidth using packet pair probing cmucs school computer science carnegie mellon university pittsburgh pa september ningning hu peter steenkiste evaluation characterization available bandwidth probing technique ieee jsac special issue internet www measurement mapping modeling august manish jain constantinos dovrolis endtoend available bandwidth measurement methodology dynamic relation tcp throughput proceeding acm sigcomm pittsburgh pa august c dovrolis p ramanathan moore packet dispersion technique measure proceeding ieee infocom page april c dovrolis p ramanathan moore packetdispersion techniquesand capacityestimation methodology ieeeacm transaction networking vol pp sangtae ha injong rhee hybrid slow start highbandwidth longdistance network proceeding pfldnet march h balakrishnan seshan congestion manager rfc june jc mogul observing tcp dynamic real network proceeding acm sigcomm pp baltimore maryland august v paxson allman computing tcp retransmission timer rfc november j mo v anantharam rj la j walrand analysis comparison tcp reno vega proceeding globecom december sally floyd mark allman amit jain pasi sarolaht quickstart tcp ip rfc january katabi handley c rohrs congestion control high bandwidthdelay product network proceeding acm sigcomm august ariba f gouaisbaut labit feedback control router management tcpip network stability ieee transaction network service management vol december pp aggarwal savage anderson understanding performance tcp pacing proceeding ieee infocom march ningning hu peter steenkiste improving tcp startup performance using active measurement algorithmand evaluation proceeding ieee icnp pp november allman generation use tcp acknowledgment computer communication review oct allman glover l sanchez enhancing tcp satellite channel using standard mechanism rfc january concept rfc november rt braden ttcp tcp extension transaction functional specification rfc july yogesh bhumralkar jeng lung pravin varaiya network adaptive tcp slow start httppalealeeecsberkeleyeduhttppalealeeecsberkeleyedu varaiyacommhtml zhang l qiu keshav optimization tcp startup performance cornell c technical report february seshan stemm r h katz spand shared passive network performance discovery proceeding usits monterey ca december j touch tcp control block interdependence rfc april h balakrishnan seshan stemm rh katz tcp behavior busy internet server analysis improvement proceeding ieee infocom march c barakat e altman performance short tcp transfer networking performance communication network conference may h afifi elloumi g rubino dynamic delayed acknowledgment mechanism improve tcp performance asymmetric link proceeding iscc athens greece july l zhang shenker clark observation dynamic congestion control algorithm effect two way traffic proceeding acm sigcomm zurich switzerland pp september l zhang tcp timer dont work well proceeding acm sigcomm pp ioannis psaras vassilis tsaoussidis tcp timer still dont work well computer network httpwwwisiedunsnamnshttpwwwisiedunsnamns title simultaneous solution hubble tension observed bulk flow within h mpc transcription simultaneous solution hubble tension observed bulk flow within h mpc sergij mazurenko indranil banik pavel kroupa moritz haslbauer universitat bonn reginapacsweg bonn germany scottish university physic alliance university saint andrew north haugh saint andrew fife ky s uk ibstandrewsacuk indranil banik technikinstitut fur yankhane und kernphysik universitat bonn nussallee bonn germany astronomical institute faculty mathematics physic charles university v holesovickach cz praha czech republic email sergijmazurenkounibonnde sergij mazurenkoibstandrewsacuk indranil banik accepted xxx received yyy original form zzz abstract lambda cold dark matter lambdacdm standard cosmological model severe tension several cosmological observation foremost hubble tension exceeds sigma confidence galaxy number count show keenanbargercowie kbc supervoid significant underdensity mpc reconciled lambdacdm cosmology haslbauer et al previously showed high local hubble constant arises naturally due gravitationally driven outflow observed kbc supervoid main prediction model peculiar velocity typically much larger expected lambdacdm framework agrees recent discovery watkins et al galaxy cosmicflows catalogue significantly faster bulk flow expected lambdacdm model scale h mpc rising bulk flow curve unexpected standard cosmology causing sigma tension h mpc work determine semianalytic void model haslbauer et al predicts bulk flow scale find qualitative agreement observation especially vantage point chosen match observed bulk flow scale h mpc represents highly nontrivial success previously published model constrained bulk flow measurement shown solve hubble tension explain kbc void consistently peculiar velocity local group result suggest several cosmological tension simultaneously resolved structure grows efficiently lambdacdm paradigm scale ten hundred mpc keywords largescale structure universe cosmology theory gravitation galaxy kinematics dynamic galaxy statistic method data analysis introduction hubble tension one greatest currently debated unsolved problem cosmology wong et al migkas et al riess et al di valentino statistically significant discrepancy direct local measurement hubblelemaitre constant h prediction lambdacold dark matter lambdacdm efstathiou sutherland maddox ostriker steinhardt standard model cosmology parameter calibrated fit angular power spectrum anisotropy cosmic microwave background cmb local universe appears expanding faster prediction origin tension known high local determination h correct universe would younger lower cmbbased value correct however age oldest star argue interpretation cimatti moresco upper limit h consistent cmb measurement taken planck satellite planck collaboration vi atacama cosmology telescope aiola et al leaf open issue many local measurement show faster expansion rate eg figure di valentino reference therein recently argued hubble tension solved largely late time cosmic history jia hu wang vagnozzi expansion rate apparently diverging lambdacdm expectation rather recently gomezvalent et al another serious le widely known problem keenanbargercowie kbc void underdensity diameter gpc keenan barger cowie extended deep local underdensity indicated several observation optical maddox et al infrared huang et al busswell et al frith et al keenan et al whitbourn shank wong et al xray bohringer et al radio wavelength rubart schwarz rubart bacon schwarz nearinfrared measurement imply matter density half cosmic mean value distance mpc see figure keenan barger cowie figure kroupa using data millennium xxl simulation mxxl angulo et al haslbauer banik kroupa hereafter hbk showed kbc void sigma tension lambdacdm model despite accounting forredshift space distortion induced outflow void implies actual density contrast half reported keenan barger cowie deep extended void suggests cosmological model structure grows faster lambdacdm suggested outflow large local void solve hubble tension keenan et al shank et al ding et al camarena et al san martin rubio would natural solution local void creates hill potential causing galaxy flow away void purely kinematic perspective near uniformity cmb implies substantial underdensity today must consequence outflow using argument hbk estimated observed kbc void implies locally measured h exceed true background expansion rate see section local group lg situated within kbc void part bulk matter flow hubble tension naturally understood arising outflow induced kbc void problem lambdacdm unable form void relevant scale mpc universe almost homogeneous isotropic simultaneous solution kbc void hubble tension possible lambdacdm assume sigma density fluctuation early time see figure hbk moreover observation keenan et al trace majority galaxy luminosity function suggesting observed underdensity genuine underdensity total matter distribution see figure allowing redshift space distortion hbk found result keenan et al imply density within mpc approx cosmic mean evident galaxy number count greater distance much line finding wong et al hbk showed matter inhomogeneity comparable kbc void arise neutrino hot dark matter nuhdm cosmological framework angus katz et al wittenburg et al nuhdm model assumes milgromian dynamic mond milgrom mond postulate gravitational acceleration g isolated spherically symmetric system asymptotically related newtonian gravitational acceleration gn baryon alone according grightarrowbegincasesgntextif gngg sqrtagntextif gnll aendcases tag key new ingredient fundamental acceleration scale atimes value must deduced empirically like gravitational constant g standard gravity different study decade returned similar value abegeman broeils sander gentile famaey de blok mcgaugh lelli schombert mond gravitational field follows lagrangian ensuring usual symmetry conservation law respect linear angular momentum energy bekenstein milgrom milgrom least action principle lead generalized poisson equation nonlinear mass distribution mond highly successful galaxy scale famaey mcgaugh mcgaugh banik zhao nuhdm extends application cosmology postulating extra specie sterile neutrino rest energy ev crucial matching high velocity dispersion virialized galaxy cluster offset weak lensing xray peak bullet cluster high third peak angular power spectrum cmb review see section banik zhao background cosmology nuhdm lambdacdm skordis zlosnik though extra neutrino specie implies mild departure standard big bang nucleosynthesis see section hbk moreover model behave similarly early time redshift zgtrsim typical acceleration high thus standard gravity applies lower redshift significant difference arise largescale structure due lack cdm mond correction gravitational field angus diaferio angus et al katz et al wittenburg et al using semianalytic model nuhdm framework hbk evolved three initial void density profile maxwellboltzmann gaussian exponential large grid initial void size strength z initial condition constrained observation local universe z requirement density almost recover cosmic mean value distance mpc see figure table keenan barger cowie local void solution hubble tension implies quite large peculiar cmbframe velocity important constraint model observed peculiar velocity lg nurm lgpm km kogut et al peculiar velocity typically larger nuhdm katz et al wittenburg et al low value arises reasonable fraction observer gravitational field nearby distant structure sometimes partially cancel however consider larger region universe significant milgromian enhancement gravity implies much substantial bulk flow galaxy scale hundred mpc model viable rapid bulk flow need verified observationally test local void solution hubble tension proposed hbk extracting predicted bulk flow exact model without adjustment order compare priori bulk flow prediction recently published measurement using cosmicflows galaxy catalogue tully et al watkins et al present bulk flow galaxy scale h mpc happrox hubble constant unit km mpc velocity reported cmb frame bulk flow involves vector average line sight peculiar velocity distance section bulk flow expected decrease scale observed bulk flow curve opposite behaviour rise km beyond h mpc scale h mpc sigma tension lambdacdm model ptimes independent study recently reported excellent agreement bulk flow measurement watkins et al using dataset also found significant tension lambdacdm effective depth h mpc though conservative methodology prevented author going whitford howlett davis issue observationally unrelated hubble tension adopting different h would affect peculiar velocity spherically symmetric manner thus affecting inferred bulk flow curve shown figure watkins et al section compare result bottom right panel figure bulk flow predicted nuhdm model different void density profile possible vantage point previously shown provide best overall match several cosmological observablesmainly kbc void density profile high local h see hbk important note bulk flow measurement watkins et al available hbk earlier bulk flow measurement available used vhdm model parameter local void model way constrained fit observed bulk flow scale several hundred mpc primary objective study use bulk flow measurement watkins et al test priori prediction hbk hubble bubble model scale help ass whether hubble bulk flow tension faced lambdacdm model might common milgromian solution generally result help clarify whether velocity field local supervoid solution hubble tension might also match observed bulk flow scale h mpc structure paper follows section describe obtain predicted bulk flow manner reported observation present result section conclude section method starting point analysis peculiar velocity field semianalytic void model hbk shown figure maxwellboltzmann void density profile velocity field relevant model shown appendix combination spherically symmetric outflow void centre systemic motion whole void towards left reduces spherical symmetry axisymmetry refer peculiar velocity cmb frame total velocity mathbfvrm tot analogous equation hbk well suited comparison observation study bulk flow large scale heliocentric redshift typically corrected precisely known velocity sun frame cmb footnote r watkins private communication possible location local group position lg framework deduced finding point move velocity vrm totvrm lgpm rm kmskogut et al use notation vequivmathbfv vector mathbfv figure hbk show locus point solid black curve author suggested lg towards right hand side curve located away void centre however study lacked reliable way precisely determine lg ought simplify analysis considering two possible lg location call inner outer vantage point relative void centre bracket range possible lg distance void centre importantly vantage point place lg symmetry axis problem allowing u work axisymmetric code consider vantage point separately three considered void underdensity profile maxwellboltzmann gaussian exponential also consider uncertainty model prediction six case due uncertainty vrm lg slightly vary location lg mpc see appendix however le significant observational uncertainty bulk flow table show possible location lg three void density profile case inner vantage point lie within mpc void centre outer vantage point generally much distant maxwellboltzmann profile give outer vantage point reasonably close void centre distance drm mbr mpc observed peculiar velocity describe problem using cartesian coordinate centred observer two ax needed problem axisymmetric xaxis corresponds symmetry axis problem yaxis lie orthogonal direction distance point observer thus rsqrtxy observation distant galaxy tell u peculiar velocity along line sight applying consideration observable component peculiar velocity point vrm obsi leftfracxvxyvyrrighti tag vrm totequivvxvy velocity cmb frame found adding velocity relative void centre systemic velocity void whole towards x systemic void velocity given table c hbk adjustable analysis bulk flow velocity line sight peculiar velocity point typically thought scalar quantity help think vector mathbfvrm obsi pointing observer towards point bulk flow velocity cmb frame weighted average line sight peculiar velocity vector within spherical volume radius rrm bulk centred observer definition match equation watkins et al due simulated velocity field axisymmetric respect xaxis observer also lying axis bulk flow must along therefore consider xcomponent mathbfvrm obsi given vrm obsxi vrm obsileftfracxrrighti tag calculating bulk flow velocity matter taking suitably weighted average quantity discus point weight wipropto vir vi volume covered cell factor r necessary
Original Title: Startup Acquisitions: Acquihires and Talent Hoarding
Original Transcription: # Startup Acquisitions: Acquihires and Talent Hoarding

Jean-Michel Benkert, Igor Letina and Shuo Liu

Benkert: Department of Economics, University of Bern. Letina: Department of Economics, University of Bern and CEPR. Liu: Guanghua School of Management, Peking University. Email: jeanmichel.benkert@unibe.ch, igor.letina@unibe.ch, shuo.liu@gsm.pku.edu.cn. We are grateful to Florian Ederer, Johannes Johnen, Massimo Motta, Armin Schmutzler and to seminar participants at the Universities of Bayreuth, Copenhagen, and Lausanne as well as at the Joint Humboldt University + University of Toronto Theory Conference in Berlin, the CCER Summer Institute in Beijing and the Swiss IO Day 2023 in Bern for valuable feedback and helpful comments. Shuo Liu acknowledges financial support from the National Natural Science Foundation of China (Grants No. 72192844 and 72322006).

Introduction

Historically, competition authorities have been concerned with mergers and acquisitions (M&As) only when they were likely to lead to a reduction in effective competition. Since startups, almost by definition, generally hold small or nonexistent market shares, their acquisitions were rarely challenged (see e.g. Bryan and Hovenkamp, 2020). This has recently begun to change, as competition authorities are starting to scrutinize the effects of M&A activity not only on current but also on _potential_ (or _nascent_) competition. It is in this context that Cunningham, Ederer, and Ma (2021) have shown that in the pharmaceutical industry, 5.3%-7.4% of all acquisitions are so-called "killer acquisitions," aimed at inhibiting the development of future competition. Against this backdrop, competition authorities believe that there may be a case to carefully scrutinize startup acquisitions.1

Footnote 1: In 2020, the Federal Trade Commission investigated “whether large tech companies are making potentially anticompetitive acquisitions of nascent or potential competitors” (FTC, 2020). The European Commission has also taken steps indicating stricter enforcement (see e.g. European Commission, 2021).

This increased attention by competition authorities is deemed unnecessary by critics arguing that startup acquisitions are typically benign in terms of their impact on competition - even when they result in the "killing" of the startup's product or service. One common argument (e.g. Barnett, 2023) to support this view is that such acquisitions are so-called "acquihires." As the name suggests, acquihires are essentially a hiring instrument: the acquiring firm is primarily interested in hiring the startup's employees, not removing a potential competitor. Consider the case of Drop.io, a startup offering easy file sharing. In 2009, Drop.io was a successful startup, having been named a winner of CNET's Webware 100 and listed among the 50 best websites by Time magazine. After acquiring Drop.io in 2010, Facebook promptly terminated it and announced that its CEO at the time, Sam Lessin, would be assigned to a new role.2 While the startup was "killed," the motivation for doing so is different from the killer acquisitions of Cunningham et al. (2021). Yet, does that necessarily mean that the acquisition was benign?

Footnote 2: See “Webware 100 winner: Dropio,” _CNET_, May 2009, “50 Best Websites 2009 – Drop.io,” _Time_, August 2009, and “Facebook Acquires Simple File-sharing Service Drop.io,” _Mashable_, October 2010.

The goal of our paper is to contribute to this discussion, by presenting a simple yet general framework allowing the study of acquihires. We consider a model in which two symmetric incumbents are competing in one market, while a startup is operating in a market that can be seen as orthogonal. This rules out the elimination of potential competitors as the motivation for an acquisition. The incumbents can attempt an acquihire of the startup, that is, acquire it and integrate its employees into their own operations. An acquihire leads to an efficiency gain for the acquiring firm, so that profits of the acquire increase, while those of the competitor decrease following an acquihire. We allow for different degrees of efficiency gains by modeling two distinct levels of match quality between the incumbents and the startup.

We present three main results. First, we show that inefficient acquisitions may occur even if the startup is not a potential competitor to the incumbents. In our context, the inefficiency is manifested through _talent hoarding_: firms engaging in acquihires even when such transactions lead to lower aggregate profits for the startup and the acquirer afterward. Essentially, we find that a low-match firm can increase its expected profits by acquiring the startup before the (potentially high-match) competitor learns of its existence. Such acquihires generate an inefficiency because startup employees would be more productive by either staying with the startup or (if available) moving to the high-match competitor. Our model thus suggests that startup acquisitions need not be benign even when potential competition motives are ruled out.

Our second result examines the effect of acquihires on consumer surplus. Whether or not an acquihire decreases surplus depends on whether the loss of surplus induced by the disappearance of the startup is offset by the resulting efficiency gain. In particular, if high-match acquisitions increase consumer surplus while low-match acquisitions decrease it, competition authorities who cannot identify match qualities may face complex challenges in regulating acquihires. For instance, the welfare effects of banning acquihires may not depend straightforwardly on the ex-ante likelihood of a high-match deal. As we show, prohibiting acquihires tends to decrease consumer welfare when that probability is either very high or very low. In the former case, even though low-match firms have a strong incentive to hoard talent, the potential negative impact rarely materializes. In the latter case, low-match firms _endogenously_ choose not to engage in (expensive) talent hoarding, so that all observed acquihires are with high-match firms, and thus welfare-enhancing. It is when the probability of a high-match sits in an intermediate range - such that low-matches remain tempted to hoard talent and they are not rare - that banning acquihires has the largest scope for enhancing expected consumer welfare.

Our final result shows that the labor-market outcomes for acquihired employees may become more volatile due to firms' talent hoarding. To obtain this result, we expand our baseline model by adding a second period. Moreover, in between periods, the economy may fall into a recession and consequently, firms may get hit by potentially correlated adverse shocks. Relative to a benchmark with no motive to hoard talent, we show that talent hoarding always leads to more hiring and may also lead to more layoffs and unemployment for acquihired employees when the adverse shocks are sufficiently likely or sufficiently positively correlated. This finding lends support to the view that talent hoarding was a major contributing factor to the substantial number of layoffs in the tech industry following the increased pressure on the US economy in 2022.3

Footnote 3: See “Tech’s Talent Wars Have Come Back to Bite It,” _The New York Times_, November 2022.

We explore several extensions to our baseline model in the Online Appendix. These extensions include allowing the acquiring firm to differentiate between startup talent and technology, incorporating asymmetry in market power among potential acquirers, expanding the number of firms, introducing uncertainty in the order of moves, and accounting for partial acquisitions. Towards the paper's end, we will discuss these extensions in greater detail, arguing that they not only confirm the robustness of our core findings but also provide additional insights. For instance our extension with asymmetric firms highlights that, under reasonable profit assumptions, dominant firms have stronger incentives to hoard talent - an observation that resonates with concerns expressed by many regulators regarding the over-hiring prevalent among tech giants.

Related literature.Our paper is most closely related to the literature studying the economics of startup acquisitions. Much of the early literature has examined, in various settings, how the prospect of an acquisition impacts the incentives of startups and incumbents to invest in innovation (e.g., Gans and Stern, 2000; Mason and Weeds, 2013; Norback and Persson, 2012; Phillips and Zhdanov, 2013; Rasmussen, 1988). Following Cunningham et al. (2021), who demonstrated that incumbents may acquire startups for anti-competitive reasons, a large literature has studied the effects a more restrictive merger policy would have on innovation and overall welfare (Cabral, 2020, 2023; Katz, 2021; Letina, Schmutzler, and Seibel, 2023; Motta and Peitz, 2021). Others examine how acquisitions can steer the direction of innovation (Bryan and Hovenkamp, 2020; Callander and Matouschek, 2022; Dijk, Moraga-Gonzalez, and Motchenkova, 2021), while Fumagalli, Motta, and Tarantino (2023) consider the impact of financial constraints. Several papers consider dynamic incentives (Bryan and Hovenkamp, 2020; Cabral, 2018; Denicolo and Polo, 2021; Hollenbeck, 2020). A key insight is that if the incumbent pulls too far ahead in the technology space, the pace of innovation will go down. There is also the possibility that the incumbent creates a "kill-zone" which disincentivizes entry, either by acquiring entrants, copying their products, or heavily investing in innovation (Bao and Eeckhout, 2023; Kamepalli, Rajan, and Zingales, 2021; Shelegia and Motta, 2021; Teh, Banerjee, and Wang, 2022). On the empirical side, Ederer and Pellegrino (2023) show that startups increasingly favor acquisitions over IPOs as exit strategies. Finally, several papers empirically study acquisitions in the tech sector (Affeldt and Kesler, 2021, 2021; Eisfeld, 2022; Gautier and Lamesch, 2021; Gugler, Szucs, and Wohak, 2023; Jin, Leccese, and Wagman, 2023; Prado and Bauer, 2022). Our paper differs from this literature by considering startups that are not potential competitors of the incumbents. The main channel through which acquisitions create inefficiencies is thus fundamentally different.

We do not examine why firms engage in acquhires instead of directly poaching valuable employees. This question is tackled in Bar-Isaac, Johnson, and Nocke (2023), who show that an acquhire can increase the monopsony power of the acquirer by removing the most relevant labor-market competitor. This in turn lowers wages, making acquhiiringmore profitable than direct hiring. Coyle and Polsky (2013) argue that firms engage in acquhires for reputational reasons, as the acquirers want to maintain good relationships with VCs and the startup founders prefer the reputation of a successful "exit." Selby and Mayer (2013) add that acquhiire is a method of acquiring entire teams.

Our paper also relates to the empirical literature that directly studies acquhires. Ouimet and Zarutskie (2020), Ng and Stuart (2021) Chen, Gao, and Ma (2021) and Chen, Hshieh, and Zhang (2022) show that acquiring talent is indeed an important motivation for acquisitions. However, acquhired employees separate at a higher rate than regularly hired employees (Ng and Stuart, 2021; Verginer, Parisi, de Jeude, and Riccaboni, 2022), which may be due to a preference for working at startups or a misalignment with the acquirer's plans (Kim, 2020; Loh, Khashabi, Claussen, and Kretschmer, 2019). This empirical finding is consistent with our theoretical result.

Talent hoarding in our model is driven by the preemption effect, with firms acquiring talent partly to prevent competitors from becoming stronger. Of course, many papers identify the preemption effect in various settings, from patent races (Gilbert and Newbery, 1982), M&As in the international trade setting (Norback and Persson, 2004, 2007), to technology acquisitions (Bryan and Hovenkamp, 2020a). Preemptively acquiring labor is different from acquisitions of physical assets or technology, because firms do not acquire property rights over labor. In our setting, this implies that some solutions to preemption, like licensing (Katz and Shapiro, 1987), do not apply. Moreover, additional issues, like the impact of the business cycle, appear.

More broadly related is Haegele (2022), who finds evidence of talent hoarding by managers _within_ firms. We identify strategic motives for talent hoarding across firms. The literature on endogenous technological spillovers caused by workers changing jobs is also broadly related. The possibility that workers might move to the competitor influences whether multinational enterprises export or produce locally (Fosfuri, Motta, and Ronde, 2001) and how much firms may invest in innovation (Gersbach and Schmutzler, 2003a,b). Also broadly related is the concept of _labor hoarding_ from macroeconomics, which refers to firms employing more workers during economic contractions than is necessary for production. The firms do this to avoid incurring hiring and training costs after the contraction ends and the economy recovers (for an overview, see Biddle, 2014). Our model predicts that _talent hoarding_ implies more volatile hiring and firing decisions during economic expansions and contractions, which would dampen the observed _labor hoarding_ during contractions. Interestingly, this is exactly what Biddle (2014, pp. 209-210) reports has been happening recently, especially during the Great Recession. If the practice of _talent hoarding_ has become more common, then our model would provide a potential explanation for this observation.

Model

Two symmetric firms \(i\in\{1,2\}\) are competing in a market.4 There is a second market in which an entrepreneur \(E\)'s startup is active. In the status quo, the firms' payoffs are given by \(\Pi_{F}\) and the entrepreneur's payoff is \(\pi_{E}\). Our model does not specify any direct linkage between the two markets (e.g. through consumer demand), as we prefer to consider them as orthogonal to each other. This allows us to rule out conventional competition motives for the firms when acquiring the startup, as will become clear later.

Footnote 4: In many relevant applications there will be a dominant firm in the market. We discuss this extension in Section 5 and formally develop it in the Online Appendix B.2. Moreover, we also consider the effect of more than two firms in the Online Appendix B.3.

A firm can pursue an "acquihire," whereby it acquires and integrates the startup by making a bid \(p\) to the entrepreneur. If successful, the payoff consequences of the transaction depend on the match quality \(\theta\in\{H,L\}\) between the acquirer and the startup. This match quality is the acquirer's private information, and it is drawn i.i.d. for each firm according to \(\Pr(\theta=H)=1-\Pr(\theta=L)=\lambda\in(0,1)\). Specifically, if firm \(i\) with match \(\theta_{i}\) successfully pursues an acquihire at bid \(p\), its payoff is \(\bar{\Pi}_{F}^{\theta_{i}}-p\), while the other firm's payoff is \(\underline{\Pi}_{F}^{\theta_{i}}\) and the entrepreneur receives \(p\).

We assume that an acquihire leads to a relative efficiency gain over the competitor as follows.

**Assumption 1**: _We assume that_

* \(\bar{\Pi}_{F}^{H}>\Pi_{F}+\pi_{E}>\bar{\Pi}_{F}^{L}\)_;_
* \(\Pi_{F}\geq\underline{\Pi}_{F}^{L}>\underline{\Pi}_{F}^{H}\)_._

According to Assumption 1(i), the joint profits of the startup and the acquirer are highest when a high-match firm acquires the startup; second highest when the firm does not acquire the startup, and lowest when a low-match firm acquires the startup. Assumption 1(ii) says that the profits of the non-acquiring firm are highest when its competitor does not pursue an acquihire, followed by when a low-match competitor does an acquihire and lowest when a high-match competitor does so.

From the consumers' point of view, there are three possible outcomes. First, absent an acquihire all three firms are active in their respective markets. In this case, the consumer surplus arising from the competition between the two symmetric firms is \(CS_{F}\) and that from the startup is \(CS_{E}\). Second, a low-match acquihire results in competition between the two (now asymmetric) firms generating the entire consumer surplus (\(CS_{L}\)). Third, a high-match acquihire also results in a similar competition that generates the entire consumer surplus (\(CS_{H}\)). Whenever an acquihire occurs, the consumer surplus generated by the startup (\(CS_{E}\)) is lost. We make the following assumption.

**Assumption 2**: _Let \(CS_{H}\geq CS_{L}\geq CS_{F}\)._

The assumption captures the idea that as one of the two firms becomes more efficient, it passes off some of that efficiency to consumers.5

Footnote 5: While it is possible that this assumption does not hold, extending our analysis to those cases is straightforward, but would come at the cost of more complex exposition.

Finally, the timing is as follows. At the outset, nature draws the private match types of the firms. In the first stage, firm 1 has the opportunity to attempt an acquhire. The entrepreneur can accept or reject the bid. If the entrepreneur accepts the bid, the game ends. Otherwise, we move to the second stage. In this stage, firm 2 has the opportunity to attempt an acquhire. The entrepreneur can accept or reject the bid, after which the game ends.6

Footnote 6: In Online Appendix B.5 we show that the emergence of incentives to hoard talent does not hinge on firms’ knowledge of the order of moves nor on the fact that the firm gets the full surplus resulting from the acquhire. However, if firms were moving simultaneously, e.g., because the entrepreneur is auctioning off the startup, talent hoarding as in Proposition 1 is unlikely to materialize, as a firm with high match value should be able to outbid a low match-value competitor.

Example.Our reduced-form model encompasses many standard oligopoly models. With a specific application in mind, one could fix a demand function and derive more precise results. For example, consider a Cournot duopoly with (inverse) demand function \(P(q_{1},q_{2})=a-bq_{1}-bq_{2}\) and constant marginal cost of production \(c\). Let a high-match acquiihire reduce the acquirer's marginal cost to \(c-H>0\) while a low-match acquiihire reduces it to \(c-L\), with \(H>L\). Assuming that both firms are active after a high-match acquiihire (that is, \(a-c>H\)), it is easy to calculate the firms' profits after the various outcomes:

\[\Pi_{F}=\frac{(a-c)^{2}}{9b}, \bar{\Pi}_{F}^{H}=\frac{(a-c+2H)^{2}}{9b}, \bar{\Pi}_{F}^{L}=\frac{(a-c+2L)^{2}}{9b},\] \[\underline{\Pi}_{F}^{H}=\frac{(a-c-H)^{2}}{9b}, \underline{\Pi}_{F}^{L}=\frac{(a-c-L)^{2}}{9b}.\]

It can be shown that Assumption 1(i) is satisfied for an interval of \(\pi_{E}\) values (which is essentially a free parameter), while 1(ii) is always satisfied. Moreover, standard calculations give us consumer surplus for the three possible outcomes:

\[CS_{H}=\frac{(2a-2c+H)^{2}}{18b}, CS_{L}=\frac{(2a-2c+L)^{2}}{18b}, CS_{F}=\frac{(2a-2c)^{2}}{18b}.\]

It is immediate that Assumption 2 is satisfied. \(\Box\)Talent Hoarding

We define talent hoarding as a situation where a firm employs a group of workers although they could be more efficiently engaged elsewhere. In our model, talent hoarding occurs whenever a low-match firm acquires and integrates the startup because the employees of the startup would generate higher additional profits if the startup remained operational. Moreover, if the firm's competitor turns out to be a high-match with the startup, the foregone efficiency would be even greater.

**Proposition 1** (Talent hoarding): _Under Assumption 1, firm 1's behavior in any PBE is uniquely specified. Namely, if firm 1 is a high-match with the startup, it will do an acquiring; if it is a low-match it will do an acquhire if and only if_

\[\lambda\geq\lambda_{A}\equiv\frac{\pi_{E}+\Pi_{F}-\bar{\Pi}_{F}^{L}}{\Pi_{F}- \underline{\Pi}_{F}^{H}}. \tag{1}\]

Proof: Suppose firm 1 has not done an acquhire. It follows from Assumption 1 that, for any belief, firm 2 does an acquhire if and only if it has a high type. Moving to stage 1, firm 1's belief is given by the prior. A high-match firm 1 will always do an acquhire by Assumption 1. A low-match firm 1, will do an acquhire whenever \(\bar{\Pi}_{F}^{L}-\pi_{E}\geq\lambda\underline{\Pi}_{F}^{H}+(1-\lambda)\Pi_{F}\) or, equivalently,

\[\lambda>\lambda_{A}\equiv\frac{\pi_{E}+\Pi_{F}-\bar{\Pi}_{F}^{L}}{\Pi_{F}- \underline{\Pi}_{F}^{H}}.\]

Note that \(\pi_{E}\) is firm 1's bid for the startup, leaving the entrepreneur just indifferent between accepting or not.

The result in Proposition 1 shows that talent hoarding may occur when (i) we have \(\bar{\Pi}_{F}^{L}-\underline{\Pi}_{F}^{H}>\pi_{E}\) so that \(\lambda_{A}<1\), and (ii) the probability of a high match is sufficiently high. The condition \(\bar{\Pi}_{F}^{L}-\underline{\Pi}_{F}^{H}>\pi_{E}\) guarantees that the gain for a low-match firm from doing an acquhire when facing a high-match competitor is bigger than the cost of an acquhire. However, since a low-match firm makes a negative profit from the acquhire _per se_, it will only proceed when facing a high-match competitor is likely enough.7 Effectively, a low-match firm 1 is willing to overpay when making the acquhire to prevent the potential emergence of a highly competitive firm 2. While a low-match firm 1 does reap some efficiency gain from the acquhire, it is the threat of a more competitive firm 2 motivating the acquhire. Thus, talent hoarding is more likely if the price of the acquisition \(\pi_{E}\) is low and the probability of a high-match competitor \(\lambda\) is high.8

Footnote 8: One may wonder why the low-match firm does not keep the startup operational or how this result might be affected if the startup was _also_ valuable because of its technology. We discuss these issues in Section 5 and formally analyze them in the Online Appendices B.1 and B.4. In short, we argue that operating the startup as a subsidiary might be less profitable than integration due to moral hazard issues. We also show that when startups also own valuable technology the firms will have no incentive to hoard technology but will still hoard talent.

The discussion so far has focused exclusively on the firms. We now turn to the implications of talent hoarding for consumers. Following an acquuhire, the consumer surplus generated by the startup vanishes. Thus, whether consumers benefit from the acquuhire and hence what is the appropriate response of the regulators depends on the change in consumer surplus created by the competition between the firms following the acquuhire.

By Assumption 2, acquuhires always increase consumer surplus in the two-firm market (\(CS_{H}>CS_{L}>CS_{F}\)) but lead to the loss of \(CS_{E}\) in the startup market. If \(CS_{E}\) is very low, so that \(CS_{H}>CS_{L}>CS_{F}+CS_{E}\), then both the low-match and high-match acquuhires increase consumer surplus and the policymakers should always allow acquisitions.9 Similarly, if \(CS_{E}\) is very high so that both the low-match and high-match acquuhires lower consumer surplus (\(CS_{F}+CS_{E}>CS_{H}>CS_{L}\)), then the policymakers should prohibit all acquisitions.

Footnote 9: Observe that when \(CS_{E}=0\) (e.g., because the startup is not viable) an acquuhire always increases consumer surplus.

A more subtle case appears if \(CS_{E}\) is intermediate, so that \(CS_{H}>CS_{F}+CS_{E}>CS_{L}\). Now, prohibiting a high-match acquuhire would decrease consumer surplus while prohibiting a low-match one would increase it. Hence, a policymaker unable to discern low from high-match acquuhires faces a trade-off. Our next result characterizes the optimal policy in all the cases discussed. Define

\[\lambda_{CS}\equiv\frac{CS_{F}+CS_{E}-CS_{L}}{CS_{H}-CS_{L}}. \tag{2}\]

How the values of this cutoff and the one defined in (1) relate to each other will be crucial for the effect of acquuhires on consumer surplus.

**Proposition 2** (Effect of acquuhires on consumer surplus): __

1. _If_ \(CS_{F}+CS_{E}>CS_{H}>CS_{L}\)_, then all acquisitions reduce consumer surplus._
2. _If_ \(CS_{H}>CS_{L}>CS_{F}+CS_{E}\)_, then all acquisitions increase consumer surplus._
3. _Suppose that_ \(CS_{H}>CS_{F}+CS_{E}>CS_{L}\)_. Acquhires reduce consumer surplus in expectation if and only if_ \(\lambda\in[\lambda_{A},\lambda_{CS})\)_._

Proof: Cases (i) and (ii) are straightforward. We demonstrate (iii). When \(\lambda<\lambda_{A}\), by Proposition 1 only high-match firms engage in an acquuhire. Since \(CS_{H}>CS_{F}+CS_{E}\)any acquiring in this case increases consumer surplus. When \(\lambda\geq\lambda_{A}\), both low-match and high-match firm 1 engage in an acquhire and the expected consumer surplus is \(\lambda CS_{H}+(1-\lambda)CS_{L}.\) Since the expected consumer surplus when acquhires are prohibited is \(CS_{F}+CS_{E}\), acquhires reduce consumer surplus if and only if \(\lambda\geq\lambda_{A}\) and

\[\lambda CS_{H}+(1-\lambda)CS_{L}<CS_{F}+CS_{E}\Longleftrightarrow\lambda<\frac {CS_{F}+CS_{E}-CS_{L}}{CS_{H}-CS_{L}}\equiv\lambda_{CS}.\]

Thus, acquhires reduce consumer surplus if and only if \(\lambda_{A}\leq\lambda<\lambda_{CS}\).

The intuition for Proposition 2 (iii) is that when \(CS_{H}>CS_{F}+CS_{E}>CS_{L}\), acquhires are harmful only when there is talent hoarding (i.e., both low and high-match firms engage in an acquhire, requiring \(\lambda\geq\lambda_{A}\)) and the probability of a high match is sufficiently low (requiring \(\lambda<\lambda_{CS}\)). Hence, consumer-surplus destroying acquhires can occur only for intermediate \(\lambda\), that is when \(\lambda\in[\lambda_{A},\lambda_{CS})\).

Figure 1 illustrates Proposition 2(iii) using our Cournot example with \(\pi_{E}=0.9\). The two panels only differ in the level of consumer surplus generated by the startup. We set \(CS_{E}=0.4\) for the left panel and \(CS_{E}=0.5\) for the right panel. In both panels, as \(\lambda\) grows from 0 to \(\lambda_{A}\), the consumer surplus when acquisitions are allowed increases (the solid line). For these parameters, firms endogenously only engage in high-match acquhires, which benefit consumers. At \(\lambda_{A}\), low-match firms start talent hoarding, causing a discontinuous drop in consumer surplus visible on both panels. However, on the left panel \(\lambda_{CS}<\lambda_{A}\), so the drop at \(\lambda_{A}\) is not sufficient to lower the consumer surplus below the level achieved when acquisitions are prohibited (the dash-dotted line). On the right panel, \(\lambda_{A}<\lambda_{CS}\), so that for all \(\lambda\in[\lambda_{A},\lambda_{CS})\) the average consumer surplus is lower when acquhires are allowed than when they are not. As \(\lambda\) increases beyond \(\lambda_{CS}\), high-match acquhires become so likely that the overall consumer surplus is again higher than when acquisitions are prohibited. Thus, when \(CS_{H}>CS_{F}+CS_{E}>CS_{L}\), allowing acquhires only lowers consumer surplus for _intermediate_ values of \(\lambda\). Finally, the dashed line represents the consumer surplus that could be achieved if the regulators could differentiate between the low-match and high-match acquhires. In that case, allowing only high-match acquhires always increases consumer surplus. Of course, if the regulators can only imperfectly detect match types, that would lower the expected consumer surplus below the dashed line.

Finally, the regulator may be interested in the effect of talent hoarding on total surplus, that is, the sum of firms' profits and consumer surplus. It follows directly from our discussion of Propositions 1 and 2 that talent hoarding reduces total surplus unambiguously when the transaction reduces consumer surplus. Otherwise, the impact depends on the structure one imposes on our reduced-form model. In the Cournot example, total surplus with a low-type acquhire is always lower than with a high-type acquhire, while the total surplus without an acquhire hinges on the startup's profits and consumer surplus.

## 4 Hiring, Separation and Unemployment

We next discuss the implications of talent hoarding on the hiring, separation and unemployment of acquuihred employees. To do so, we expand our baseline model by introducing a second period and allowing for economic downturns between the two periods.

The first period of this expanded model is identical to the baseline model in Section 2: the firms' match types are private information and firm 1 has the opportunity to do an acquuhire before firm 2. Between the periods, the economy suffers a downturn with probability \(\delta\in(0,1)\). If a downturn materializes - an event that is publicly observable - the firms may be hit by adverse shocks (see details below). In period 2, the entrepreneur has the option of creating a new startup, once more leading to an outside option of \(\pi_{E}\) for her.10 If the entrepreneur was employed by a firm in period 1, that firm must decide whether to continue the relationship (at the cost \(\pi_{E}\)) or lay off the entrepreneur, who might then be hired by the other firm. If there was no acquuhire in period 1, it is again firm 1 moving first in period two.

Footnote 10: There is empirical evidence that acquuhired employees who leave the acquirer are likely to join a new startup (Kim, 2020, 2022; Ng and Stuart, 2021).

The adverse shocks come with a commonly known joint probability distribution over "downgrades" for firms, though each firm only observes the realization of its own shock. More specifically, firm \(i\) is hit by a shock \(S_{i}\in\{D,N\}\), where it is either downgraded from high to low match (if possible) or not affected by the shock. Thus, if a low-match firm is hit by a downgrade, it stays a low-match firm, while a high-match firm turns into a low-match firm. If a firm is not affected by the shock, its match quality stays the same. Let \((S_{1},S_{2})\in\{D,N\}^{2}\) be the profile of shocks hitting the firms, which follows thedistribution

\[\Pr(D,D) =r\gamma(1-\gamma)+\gamma^{2}, \Pr(D,N) =(1-r)\gamma(1-\gamma),\] \[\Pr(N,D) =(1-r)\gamma(1-\gamma), \Pr(N,N) =r\gamma(1-\gamma)+(1-\gamma)^{2},\]

where \(\gamma\in(0,1)\) is the probability that a firm will be downgraded and \(r\in[0,1]\) measures the positive correlation between the firms' shocks. In particular, for \(r=0\) the shocks are independent and for \(r=1\) they are perfectly positively correlated.

To make a comparative statement, we need a benchmark relative to which we can compare the hiring, separation, and unemployment in our model with talent hoarding. To do so, consider the case where \(\Pi_{F}=\underline{\Pi}_{F}^{H}=\underline{\Pi}_{F}^{L}\) so that an acquuhire by firm \(i\) does not affect firm \(j\)'s profits. Thus, there are no incentives to hoard talent in this benchmark.

Before we state the formal result, consider the following intuition. If the entrepreneur was hired by a high-match firm in period 1 and this firm is not affected by the economic downturn (i.e., remains high-match), the firm will maintain the entrepreneur's employment. Therefore, no separation or unemployment is observed in that case.11 In contrast, if the entrepreneur was hired by a low-match firm in period 1 or a downgraded high-match firm, several period-2 outcomes can arise. Talent-hoarding motives may induce the continued employment of the entrepreneur if the competitor is believed to have a high match value with a high enough probability. Thus, we would not observe any separation or unemployment of the entrepreneur. Otherwise, we may observe a layoff of the entrepreneur, who is subsequently hired by a high-match competitor. Hence, while we observe separation, the entrepreneur does not become unemployed. Finally, the entrepreneur may be laid off and not hired by the competitor, resulting in both separation and unemployment.12 Note that these distinct period-2 outcomes in turn affect the behavior of low-match firms in period 1, changing the "acquihire threshold." Solving the game fully and deriving the probabilities of period-1 hiring as well as observing separation and unemployment in period 2, we obtain the following result, proved in the appendix.

Footnote 11: In the video game industry, Loh et al. (2019) document that when the skills of the employees and the needs of the acquirer match well, the employees are more likely to stay with the acquirer.

Footnote 12: The term “unemployment” here means that the entrepreneur is laid off and then not employed by the competitor. Since the entrepreneur can start their own business, unemployment in the precise sense of the term does not occur.

**Proposition 3** (Effect on employment outcomes): _The presence of talent-hoarding motives always leads to more hiring than in the benchmark. Additionally, provided that \(\min\left\{\frac{\lambda A}{\lambda},\frac{1-\lambda}{\lambda}\right\}>(1-r)(1- \gamma)\), talent hoarding also leads to more separation and unemployment than in the benchmark._

The increase in hiring follows immediately, as in the presence of talent hoarding, not only high-match firms but also low-match firms may pursue an acquuhire. The increase in separation and unemployment is more subtle. Essentially, when either the correlation between firms' adverse shocks \(r\) or the (marginal) probability of suffering a downgrade \(\gamma\) is sufficiently high, talent hoarding raises separation and unemployment. In the case of \(r\) being high, this is because firm 1's shock is informative of firm 2's shock due to the correlation, hence allowing firm 1, whenever it draws a negative shock, to forgo the costly talent hoarding in the second period. Similarly, when \(\gamma\) is sufficiently high, firm 1 can be fairly confident that whenever a downturn occurs, the competitor will be downgraded, once more prompting the firm to forgo talent hoarding. Further, when \(\gamma\) or \(r\) are sufficiently high, firm 1 is often right in laying off the entrepreneur as firm 2 will indeed have a low match, which in turn leads to unemployment. Finally, all statements in the proposition are strict whenever \(\lambda\) is sufficiently high so that any talent hoarding at all takes place.

## 5 Discussion and Conclusion

We have presented a simple, yet general, reduced-form model of startup acquisitions. We show that acquihires may not only reflect firms' desire to hire talented employees but may also be rooted in an incentive to engage in inefficient talent hoarding, thus potentially warranting regulators' attention. Further, we show that acquihires may decrease consumer surplus and increase job volatility of acquihired employees, thereby giving further reasons for regulatory scrutiny of such deals.

Our baseline model relies on several simplifying assumptions. As we discuss below, the main results of our analysis hold even if we relax some of those assumptions. Moreover, the extensions of our baseline model reveal several additional insights. The formal analysis and results can be found in the Online Appendix.

People and technology.In our baseline model, the startup's value lies solely in its employees. However, some startups also possess valuable technology. We posit that the key distinction between people and technology is that firms can sell or license acquired technology but not employees.13 We extend the model so that some share of the startup's value is also due to its technology. An acquirer can trade the startup's technology (but not the employees) to its competitor. As we show, a low-match acquirer will indeed have an incentive to sell the technology to a high-match competitor, because the price will compensate her for any decrease in market profit due to a more efficient competitor. Thus firms will not have an incentive to hoard technology, while the incentive to hoard talent remains. Interestingly, talent hoarding now occurs for a strictly larger set of parameters, as the option to resell technology effectively subsidizes talent hoarding.

Dominant firm.Instead of symmetric firms, the market could be characterized by a dominant firm and a challenger. We show that the incentives to hoard talent also emerge in this asymmetric model. Further, under reasonable assumptions on the impact of acquisitions on the profits of the dominant firm and the challenger, the dominant firm is more likely to hoard talent.

Multiple firms.Next, we examine markets with multiple firms that may sequentially try to acquihire the startup. Focusing on the Cournot-Oligopoly setting, we show that in the limit, as the number of firms grows large, no talent hoarding takes place. Intuitively, the profit at risk from a competitor's acquihire becomes smaller as the number of competitors increases, reducing the incentives to engage in costly talent hoarding. However, the effect of the increase in the number of competitors on the incentives to talent hoard is not necessarily monotonic. The reason for the non-monotonicity is that an increase in the number of competitors, in addition to decreasing profit at risk, also increases the probability that a high-match competitor will acquire the startup. Which effect is stronger for a small number of firms is not clear. Indeed, we show in a parametric example that we may observe more talent hoarding when there are three firms than when there are two.

Partial acquisitions.Instead of integrating the startup after acquiring it, the acquirer could allow it to continue operating independently in its own market. Moreover, instead of buying the startup outright, a firm could acquire a partial stake in it. In this context, the key questions are how the startup's profits and control rights are allocated. First, we assume that following an investment the entrepreneur receives a dividend and a wage, while an investor only receives a dividend as their share of the startup's profits. To micro-found these payoffs, we assume that the presence of an outside investor gives rise to an agency problem, which we capture in reduced form, thus allowing for a wide range of agency models while maintaining a simple and (relatively) tractable setup. Second, considering control rights, we are primarily interested in the investor's ability to block and the entrepreneur's ability to push through an acquihire by the investor's competitor. We assume that the entrepreneur can always block an acquihire, as she could sell her shares but refuse to work for the acquiring firm. If the entrepreneur would like to be acquihired and the investor does not want the acquihire to go through, the entrepreneur can (in the spirit of typical shareholder agreements) try to "drag along" the investor and force the transaction. We assume that the investor has a probabilistic chance of blocking this attempt and merely impose that the probability of successfully blocking an acquihire is increasing in the investor's stake in the startup.

We find that an acquihire can be more profitable than buying a startup and letting it operate independently, implying talent hoarding persists in this extension. Withsufficiently strong blocking rights, an investment may constitute a viable and cheaper alternative to an acquiring. Therefore, as investments are cheaper than acquhires, the possibility of partial ownership may reduce the frequency of acquhires, while increasing the frequency of some transaction taking place. Notably, the reduction in overall profits is lower in the case of investments than of low-match acquhire. Therefore, the possibility of investments is more likely to lead to inefficient market outcomes, albeit at a lower degree of inefficiency.

We close the paper by noting that our model gives rise to several hypotheses that could be tested empirically. First, our model predicts a positive relationship between talent hoarding and job volatility of acquhired employees. Second, an acquhire by a dominant firm is more likely to be motivated by talent hoarding. Third, increasing market competitiveness can curb talent hoarding but not always monotonically. Fourth, the strength of blocking rights implied by shareholder agreements should have an impact on the relative frequency of acquhires and investments.

Proof of Proposition 3

The result is reached in three steps: solving the benchmark game without talent hoarding, with talent hoarding, and then comparing both.

Benchmark.Absent incentives to hoard talent, only high-match firms do an acquuhire. Thus, a layoff only takes place if the economy enters a downturn and the period-1 acquireer is hit by an adverse shock. Further, following a layoff, we observe unemployment only if the competitor was a low-match firm or if it was a high-match firm that got hit by an adverse shock. Finally, hiring takes place in period 1 unless both firms are low-match. Taken together, the probability of observing a layoff in period 2 is

\[l^{*}=\delta[\lambda+(1-\lambda)\lambda]\gamma=\delta(2\lambda-\lambda^{2})\gamma\] (A.1)

and the probability of observing unemployment in period 2 is

\[u^{*}=\delta(2\lambda-\lambda^{2}-\lambda^{2}(1-r)(1-\gamma))\gamma.\] (A.2)

Talent hoarding.First, note that period-2 incentives coincide with those in period 1 absent an economic downturn, ruling out layoffs and unemployment. Following a downturn, three cases arise in period 2:

* Suppose firm 1 acquuired in period 1. Then, firm 2 does an acquuhire in period 2 iff it has a high match. In period 2 a high-match firm 1 does an acquuhire. A low-match firm 1 that received a \(D\) shock, believes its competitor has a high match with probability \(\lambda(1-r)(1-\gamma)\) and will do an acquuhire if this is larger than \(\lambda_{A}\). Analogously, a low-match firm 1 receiving a \(N\) shock will do an acquuhire if \(\lambda(1-\gamma(1-r))\geq\lambda_{A}\).
* Suppose firm 2 acquuhired in period 1, so firm 1 is a low-match and will not do an acquuhire moving second. Thus, firm 2 does an acquuhire iff it has a high match.
* Suppose no acquuhire took place in period 1. Then, both firms have a low match and this is commonly known, leading to no acquuhires in period 2 either.

Moving to period 1, firm 2 does an acquuhire iff it has a high match, knowing that firm 1 has a low match, since a high-match firm 1 would always do an acquuhire. For a low-match firm 1, doing nothing yields

\[\lambda\left(\underline{\Pi}_{F}^{H}(2-\gamma\delta)+\gamma\delta\Pi_{F} \right)+(1-\lambda)2\Pi_{F}=\lambda(2-\gamma\delta)(\underline{\Pi}_{F}^{H}- \Pi_{F})+2\Pi_{F}.\]

The payoff of an acquuhire depends on parameters and reads:* \(2(\Pi_{F}^{L}-\pi_{E})\) if \(\lambda(1-r)(1-\gamma)>\lambda_{A}\);
* \((\bar{\Pi}_{F}^{L}-\pi_{E})(2-\delta\gamma)-\delta\gamma\lambda(1-r)(1-\gamma)( \Pi_{F}-\underline{\Pi}_{F}^{H})+\delta\gamma\Pi_{F}\) if \(\lambda(1-\gamma(1-r))>\lambda_{A}>\lambda(1-r)(1-\gamma)\);
* \((\bar{\Pi}_{F}^{L}-\pi_{E})(2-\delta)-\delta\lambda(1-\gamma)(\Pi_{F}- \underline{\Pi}_{F}^{H})+\delta\Pi_{F}\) if \(\lambda_{A}>\lambda(1-\gamma(1-r))\).

In case 1, a low-match firm will always hoard talent in period 2. In case 2, it will hoard talent unless it receives a \(D\) shock in an economic downturn. In case 3, it will hoard talent as long as the economy does not experience a downturn. Thus, comparing the total payoffs from doing nothing or an acquuhire in period 1, the acquuhire thresholds for period 1 read, respectively,

\[\lambda_{A}^{1} =\lambda_{A}\cdot\frac{2}{2-\gamma\delta},\] \[\lambda_{A}^{2} =\lambda_{A}\cdot\frac{2-\delta\gamma}{2-\delta\gamma-(1-r)(1- \gamma)\delta\gamma},\] \[\lambda_{A}^{3} =\lambda_{A},\]

so that \(\lambda_{A}^{1}\geq\lambda_{A}^{2}\geq\lambda_{A}^{3}\).

Comparison.To compare hiring, separation, and unemployment, we need to consider three cases.

_Case 1: \(\lambda(1-r)(1-\gamma)>\lambda_{A}\)._ Then, \(\lambda\geq\lambda_{A}^{1}=\lambda_{A}\frac{2}{2-\gamma\delta}\). Hence, a low-match firm will do an acquuhire in both periods so no layoffs or unemployment are observed, which is less than in the benchmark. Thus, irrespective of whether the economy hits a downturn, the entrepreneur is always employed without separation.

_Case 2: \(\lambda(1-\gamma(1-r))>\lambda_{A}>\lambda(1-r)(1-\gamma)\)._ Hence, \(\lambda>\lambda_{A}^{2}\) so firm 1 will always do an acquuhire in period 1. In period 2, firm 1 will maintain employment of the entrepreneur unless it receives shock \(D\). Hence, the probability of a layoff will be \(\delta\gamma\), which is larger than the benchmark layoff rate \(l^{*}\). Moreover, the probability of transition to unemployment will be \(\delta(\gamma-\lambda P(D,N))\), which is larger than \(u^{*}\) iff \(\frac{1-\lambda}{\lambda}>(1-r)(1-\gamma)\).

_Case 3: \(\lambda_{A}>\lambda(1-\gamma(1-r))\)._ If \(\lambda>\lambda_{A}^{3}\) then firm 1 will do an acquuhire in period 1. Firm 1 will maintain employment in period 2 unless it was hit by a downturn and has a low match. Hence, the probability of observing a layoff is \(\delta(\gamma+(1-\lambda)(1-\gamma))=\delta(1-\lambda(1-\gamma))\), which is larger than \(l^{*}\). The probability of observing a transition to unemployment is \(\delta([2\lambda-\lambda^{2}]\gamma-\lambda^{2}P(D,N)+(1-\lambda)^{2})\) which is larger than \(u^{*}\). If instead \(\lambda<\lambda_{A}^{3}\), then we have no talent hoarding in either stage and the equilibrium is identical to the benchmark.

Finally, observe that the condition \(\min\left\{\frac{\lambda_{A}}{\lambda},\frac{1-\lambda}{\lambda}\right\}>(1-r )(1-\gamma)\) implies that we are either in Case 2 or 3. Further, in Case 2, it ensures that we have more unemployment than in the benchmark.

[MISSING_PAGE_EMPTY:18]

Coyle, J. F. and G. D. Polsky (2013): "Acqui-Hiring," _Duke Law Journal_, 63, 281-346.
* Cunningham et al. (2021)C Cunningham, C., F. Ederer, and S. Ma (2021): "Killer acquisitions," _Journal of Political Economy_, 129, 649-702.
* Denicolo and Polo (2021)Denicolo, V. and M. Polo (2021): "Acquisitions, innovation and the entrenchment of monopoly," Available at SSRN 3988255.
* Dijk et al. (2021)Dijk, E., J. L. Moraga-Gonzalez, and E. Motchenkova (2021): "How do start-up acquisitions affect the direction of innovation?" _CEPR Discussion Paper No. DP16362_.
* Ederer and Pellegrino (2023)Ederer, F. and B. Pellegrino (2023): "The Great Start-up Sellout and the Rise of Oligopoly," _AEA Papers and Proceedings_, 113, 274-278.
* Eisfeld (2022)Eisfeld, L. (2022): "Entry and acquisitions in software markets," Working Paper, Toulouse School of Economics.
* European Commission (2021)European Commission (2021): "Commission Guidance on the application of the referral mechanism set out in Article 22 of the Merger Regulation to certain categories of cases," [https://ec.europa.eu/competition/consultations/2021_merger_control/guidance_article_22_referrals.pdf](https://ec.europa.eu/competition/consultations/2021_merger_control/guidance_article_22_referrals.pdf).
* Fosfuri et al. (2001)Fosfuri, A., M. Motta, and T. Ronde (2001): "Foreign direct investment and spillovers through workers' mobility," _Journal of international economics_, 53, 205-222.
* FTC (2020)FTC (2020): "FTC to Examine Past Acquisitions by Large Technology Companies," [https://www.ftc.gov/news-events/news/press-releases/2020/02/ftc-examine-past-acquisitions-large-technology-companies](https://www.ftc.gov/news-events/news/press-releases/2020/02/ftc-examine-past-acquisitions-large-technology-companies), last Accessed 26.01.2023.
* Fumagalli et al. (2023)Fumagalli, C., M. Motta, and E. Tarantino (2023): "Shelving or developing? Optimal policy for mergers with potential competitors," Mimeo.
* Gans and Stern (2000)Gans, J. S. and S. Stern (2000): "Incumbency and R&D incentives: Licensing the gale of creative destruction," _Journal of Economics & Management Strategy_, 9, 485-511.
* Gautier and Lamesch (2021)Gautier, A. and J. Lamesch (2021): "Mergers in the Digital Economy," _Information Economics and Policy_, 54, 100890.
* Gersbach and Schmutzler (2003a)Gersbach, H. and A. Schmutzler (2003a): "Endogenous spillovers and incentives to innovate," _Economic Theory_, 21, 59-79.
* Gautier and Lamesch (2003b) ------ (2003b): "Endogenous technological spillovers: causes and consequences," _Journal of Economics & Management Strategy_, 12, 179-205.
* Gautier and Lamesch (2003c)Gilbert, R. J. and D. M. Newbery (1982): "Preemptive patenting and the persistence of monopoly," _The American Economic Review_, 514-526.
* Gugler et al. (2023)Gugler, K., F. Szucs, and U. Wohak (2023): "Start-up Acquisitions, Venture Capital and Innovation: A Comparative Study of Google, Apple, Facebook, Amazon and Microsoft," Tech. rep., Vienna University of Economics and Business, Department of Economics.
* Haegele (2022)Haegele, I. (2022): "Talent hoarding in organizations," Available at arXiv preprint, arXiv:2206.15098.
* Hollenbeck (2020)Hollenbeck, B. (2020): "Horizontal mergers and innovation in concentrated industries," _Quantitative Marketing and Economics_, 18, 1-37.
* Jin et al. (2023)Jin, G. Z., M. Leccese, and L. Wagman (2023): "How Do Top Acquirers Compare in Technology Mergers? New Evidence from an SP Taxonomy," _International Journal of Industrial Organization_, 89, 102891.
* Jovanovic (1979)Jovanovic, B. (1979): "Job matching and the theory of turnover," _Journal of political economy_, 87, 972-990.
* Kampalli et al. (2021)Kampalli, S. K., R. G. Rajan, and L. Zingales (2021): "Kill Zone," _Available at SSRN 3555915_.
* Katz (2021)Katz, M. L. (2021): "Big Tech mergers: Innovation, competition for the market, and the acquisition of emerging competitors," _Information Economics and Policy_, 54, 100883.
* Katz and Shapiro (1987)Katz, M. L. and C. Shapiro (1987): "R&D rivalry with licensing or imitation," _The American Economic Review_, 402-420.
* Kim (2020)Kim, J. D. (2020): "Startup acquisitions as a hiring strategy: Worker choice and turnover," Available at SSRN 3252784.
* Kim (2022) ------ (2022): "Startup acquisitions, relocation, and employee entrepreneurship," _Strategic Management Journal_, 43, 2189-2216.
* Letina et al. (2023)Letina, I., A. Schmutzler, and R. Seibel (2023): "Killer acquisitions and beyond: policy effects on innovation strategies," University of Zurich, Department of Economics, Working Paper 358.
* Loh et al. (2019)Loh, J., P. Khashabi, J. Claussen, and T. Kretschmer (2019): "Disruption, specialization and employee exit: Vertical acquisitions in the US Video Game Industry," Available at SSRN 3354763.
* Loh et al. (2019)* Mason and Weeds (2013)Mason, R. and H. Weeds (2013): "Merger policy, entry, and entrepreneurship," _European Economic Review_, 57, 23-38.
* Motta and Peitz (2021)Motta, M. and M. Peitz (2021): "Big tech mergers," _Information Economics and Policy_, 54, 100868.
* Ng and Stuart (2021)Ng, W. and T. E. Stuart (2021): "Acquired employees versus hired employees: Retained or turned over?" _Strategic Management Journal_, 43, 1025-1045.
* Norback and Persson (2004)Norback, P.-J. and L. Persson (2004): "Privatization and foreign competition," _Journal of International Economics_, 62, 409-416.
* (2007): "Investment liberalization
- why a restrictive cross-border merger policy can be counterproductive," _Journal of International Economics_, 72, 366-380.
* Norback and Persson (2012) ------ (2012): "Entrepreneurial innovations, competition and competition policy," _European Economic Review_, 56, 488-506.
* Ouimet and Zarutskie (2020)Ouimet, P. and R. Zarutskie (2020): "Acquiring labor," _Quarterly Journal of Finance_, 10, 2050011.
* Phillips and Zhdanov (2013)Phillips, G. M. and A. Zhdanov (2013): "R&D and the Incentives from Merger and Acquisition Activity," _The Review of Financial Studies_, 26, 34-78.
* Prado and Bauer (2022)Prado, T. S. and J. M. Bauer (2022): "Big Tech platform acquisitions of start-ups and venture capital funding for innovation," _Information Economics and Policy_, 59, 100973.
* Rasmussen (1988)Rasmusen, E. (1988): "Entry for Buyout," _The Journal of Industrial Economics_, 36, 281-299.
* Selby and Mayer (2013)Selby, J. and K. J. Mayer (2013): "Startup firm acquisitions as a human resource strategy for innovation: The acabire phenomenon," Working Paper.
* Shelegia and Motta (2021)Shelegia, S. and M. Motta (2021): "The "kill zone": Copying, acquisition and start-ups' direction of innovation," CEPR Discussion Paper No. DP16151.
* Teh et al. (2022)Teh, C., D. Banerjee, and C. Wang (2022): "Acquisition-induced kill zone," Monash University, Department of Economics Discussion Paper No. 2022-24.
* Verginer et al. (2022)Verginer, L., F. Parisi, J. v. L. de Jeude, and M. Riccaboni (2022): "The Impact of Acquisitions on Inventors' Turnover in the Biotechnology Industry," Available at arXiv preprint arXiv:2203.12968.
* Verginer et al. (2021)Online Appendix: Not for Publication

The online appendix covers the extensions discussed in the conclusion of the paper, as well as the robustness exercises concerning the timing and surplus sharing in the baseline model mentioned in footnote 6.

### People and Technology

Consider a situation where the total value of the startup consists of the people who work for the startup and the technology owned by the startup. The fundamental difference between the employees and the technology, from the acquirer's point of view, is that technology can be sold (or licensed), while the people cannot. In our model, this implies that the acquirer can resell the startup's technology to the competitor, whenever such a sale increases joint profits. Suppose that the share of the value of the startup generated by the technology is \(\delta\in[0,1]\), while the share generated by employees is \((1-\delta)\). Moreover, for simplicity, assume that acquiring just the technology (or just the employees) generates \(\delta\) (or \(1-\delta\)) of the impact that acquiring the entire startup would have. Just as before, a firm can have a high match value with the startup with probability \(\lambda\), where we assume for simplicity that the match value of the startup to a firm applies to both the people and the technology identically. The match value of the firm is private information at the beginning of the game. The timing of the game in stage 1 is:

1. Firm 1 observes the match quality with the startup and makes an acquisition of the startup at price \(p\) or does nothing.
2. The startup accepts or rejects the bid.
3. If the bid is rejected, the game proceeds to stage 2. If accepted, firm 1 can sell the startup's technology at the price \(q\) to firm 2.

Stage 2 is like stage 1 but the roles of firms 1 and 2 are reversed. To accommodate the possibility of selling the startup's technology, we slightly adapt the notation from the main text. Suppose firm 1 with match \(\theta_{1}\) did an acquisition at price \(p\). Absent any sale of the startup's technology, profits read

\[\text{Firm }1:\Pi_{F}+\bar{\pi}_{F}^{\theta_{1}}-p\] \[\text{Firm }2:\Pi_{F}-\underline{\pi}_{F}^{\theta_{1}}\] \[\text{Startup}:p,\]which coincides with profits in the baseline model (although the notation is different).14 If the technology part is sold at price \(q\), the profits read

Footnote 14: For instance, the payoff of an acquiring firm with match type \(\theta_{1}\) in the main text is \(\bar{\Pi}_{F}^{\theta_{1}}\) while it now reads \(\Pi_{F}+\bar{\pi}_{F}^{\theta_{1}}\).

\[\text{Firm 1}:\Pi_{F}+(1-\delta)\bar{\pi}_{F}^{\theta_{1}}-\delta \underline{\pi}_{F}^{\theta_{2}}-p+q\] \[\text{Firm 2}:\Pi_{F}-(1-\delta)\underline{\pi}_{F}^{\theta_{1}}+ \delta\bar{\pi}_{F}^{-\theta_{2}}-q\] \[\text{Startup}:p.\]

Thus, the people who have joined firm 1 from the startup increase firm 1's profits and decrease firm 2's profits, respectively. Conversely, the startup's technology increases firm 2's and decreases firm 1's profits, respectively.

To simplify the model and the exposition, we do not explicitly model the bargaining process between the two firms. Instead, we assume that the two firms meet at the bargaining table, their types are revealed and the resulting surplus from selling the technology is shared equally. The surplus resulting from the sale of the technology is then given by

\[\Pi_{F}+(1-\delta)\bar{\pi}_{F}^{\theta_{1}}-\delta\underline{ \pi}_{F}^{\theta_{2}}-p+\Pi_{F}-(1-\delta)\underline{\pi}_{F}^{\theta_{1}}+ \delta\bar{\pi}_{F}^{\theta_{2}}-\left(\Pi_{F}+\bar{\pi}_{F}^{\theta_{1}}-p+ \Pi_{F}-\underline{\pi}_{F}^{\theta_{1}}\right)\] \[= \delta\left(\bar{\pi}_{F}^{\theta_{2}}+\underline{\pi}_{F}^{ \theta_{1}}-\bar{\pi}_{F}^{\theta_{1}}-\underline{\pi}_{F}^{\theta_{2}}\right).\]

The case we are interested in, is when a low-match firm 1 sells technology to a high-match firm 2. Then, the surplus reads \(\delta\left(\bar{\pi}_{F}^{H}+\underline{\pi}_{F}^{L}-\bar{\pi}_{F}^{L}- \underline{\pi}_{F}^{H}\right)\). We now make two assumptions on profits. The first corresponds to Assumption 1 in the baseline model in the main text (in this extension's notation). The second ensures that the surplus resulting from a technology sale from a low-match to a high-match firm is positive.

**Assumption B1**: \(\bar{\pi}_{F}^{H}>\pi_{E}>\bar{\pi}_{F}^{L}\) _and \(\underline{\pi}_{F}^{H}>\underline{\pi}_{F}^{L}\geq 0\)._
**Assumption B2**: \(\bar{\pi}_{F}^{H}+\underline{\pi}_{F}^{L}-\bar{\pi}_{F}^{L}-\underline{\pi}_ {F}^{H}>0\)_._

Finally, to break ties, we assume that firms of the same match type do not trade the startup's technology. We obtain the following result

**Proposition B1**: _Under Assumptions B1 and B2, firm 1's behavior in any PBE is uniquely specified. Namely, if firm 1 has a high match, it will make an acquisition and not sell the technology; if it has a low match, it will make an acquisition and sell the startup's technology to a high-match (but not a low-match) firm 2 if and only if_

\[\lambda\geq\lambda_{A}(\delta)\equiv\frac{\pi_{E}-\bar{\pi}_{F}^{L}}{\underline {\pi}_{F}^{H}+\frac{\delta}{2}\left(\bar{\pi}_{F}^{H}+\underline{\pi}_{F}^{L} -\bar{\pi}_{F}^{L}-\underline{\pi}_{F}^{H}\right)}\]

_and do nothing otherwise._Proof: Suppose firm 1 has not made the acquisition. It follows from Assumption B1 that firm 2 makes the acquisition if and only if it has a high match type, irrespective of its beliefs. Moving to stage 1, firm 1's beliefs are given by the prior belief. Suppose a high-match firm 1 acquired the startup. By Assumption B2 a low-match firm 2 would not buy the technology part of the startup and by our tie-breaking assumption neither would a high-match firm 2. Then, by Assumption B1 a high-match firm acquires the startup and keeps the technology. Suppose a low-match firm 1 acquired the startup. By our tie-breaking assumption, a low-match firm 2 would not buy the startup's technology. However, by Assumption B2, the technology part would be sold to a high-match firm 2. Anticipating this, the threshold for a low-match firm 1 to acquire the startup changes relative to the model in the main text. Formally, doing nothing yields

\[\Pi_{F}-\lambda\underline{\pi}_{F}^{H},\]

while making an acquisition yields

\[\Pi_{F}-\pi_{E}+(1-\lambda)\bar{\pi}_{F}^{L}+\lambda(q+(1-\delta)\bar{\pi}_{F} ^{L}-\delta\underline{\pi}_{F}^{H}),\]

where

\[q=\frac{\delta\left(\bar{\pi}_{F}^{H}+\underline{\pi}_{F}^{L}+\bar{\pi}_{F}^{ L}+\underline{\pi}_{F}^{H}\right)}{2},\]

is the surplus-splitting sale price. Thus, an acquisition takes place whenever

\[\Pi_{F}-\pi_{E}+(1-\lambda)\bar{\pi}_{F}^{L}+\lambda\left(\frac{\delta\left( \bar{\pi}_{F}^{H}+\underline{\pi}_{F}^{L}+\bar{\pi}_{F}^{L}+\underline{\pi}_{ F}^{H}\right)}{2}+(1-\delta)\bar{\pi}_{F}^{L}-\delta\underline{\pi}_{F}^{H} \right)\geq\Pi_{F}-\lambda\underline{\pi}_{F}^{H},\]

which we can rearrange to the expression in the Proposition.

One can verify that for \(\delta=0\) the above condition reduces to the condition (1) in the main text. As \(\delta\) increases, the threshold \(\lambda_{A}(\delta)\) decreases, i.e., the acquisition happens for a larger set of parameters. Intuitively, as the technology part of the startup can be sold to a high-match firm 2, the expected cost of hoarding the talent falls for the low-match firm 1, leading to more talent hoarding.

### Dominant Firm

Consider a situation where instead of two symmetric firms, the industry is characterized by a dominant firm and a challenger firm. The firms now have different payoffs, which we denote \((\bar{\Pi}_{D}^{H},\bar{\Pi}_{D}^{L},\Pi_{D},\underline{\Pi}_{D}^{L},\underline {\Pi}_{D}^{H})\) for the dominant firm and \((\bar{\Pi}_{C}^{H},\bar{\Pi}_{C}^{L},\Pi_{C},\underline{\Pi}_{C}^{L},\underline {\Pi}_{C}^{H})\) for the challenger. We maintain Assumption 1 for both firms, that is we assume that both (i)\(\bar{\Pi}_{F}^{H}>\Pi_{F}+\pi_{E}>\bar{\Pi}_{F}^{L}\) and (ii) \(\Pi_{F}\geq\underline{\Pi}_{F}^{L}>\underline{\Pi}_{F}^{H}\) hold for each \(F\in\{D,C\}\). We consider the setting as in Proposition 1, that is firms can either engage in acquhires or do nothing.

**Corollary B1** (Acquhires with a dominant firm):
1. _If either the dominant or the challenger firm moves second it engages in an aquihire if and only if it is the high match type._
2. _If the dominant firm moves first, it engages in an acquihire if it is the high match type or if it is the low match type and the probability that the challenger firm is the high match type is_ \[\lambda>\lambda_{D}\equiv\frac{\pi_{E}+\Pi_{D}-\bar{\Pi}_{D}^{L}}{\Pi_{D}- \underline{\Pi}_{D}^{H}}.\] (B.1)
3. _If the challenger firm moves first, it engages in an acquihire if it is the high match type or if it is the low match type and the probability that the dominant firm is the high type is_ \[\lambda>\lambda_{C}\equiv\frac{\pi_{E}+\Pi_{C}-\bar{\Pi}_{C}^{L}}{\Pi_{C}- \underline{\Pi}_{C}^{H}}.\] (B.2)

The corollary follows directly from Proposition 1. An interesting question is under which conditions would the dominant firm be more prone to talent hoarding than the challenger firm, i.e., when is \(\lambda_{C}>\lambda_{D}\)? The following result gives a set of simple sufficient conditions.

**Proposition B2**: _If the following two inequalities hold, then \(\lambda_{C}>\lambda_{D}\):_

\[\Pi_{C}-\underline{\Pi}_{C}^{H} <\Pi_{D}-\underline{\Pi}_{D}^{H},\] \[\bar{\Pi}_{C}^{L}-\Pi_{C} <\bar{\Pi}_{D}^{L}-\Pi_{D}.\]

Proof: From Corollary B1 we have the threshold values

\[\lambda_{D}\equiv\frac{\pi_{E}+\Pi_{D}-\bar{\Pi}_{D}^{L}}{\Pi_{D}-\underline{ \Pi}_{D}^{H}},\quad\text{and}\quad\ \lambda_{C}\equiv\frac{\pi_{E}+\Pi_{C}-\bar{\Pi}_{C}^{L}}{\Pi_{C}-\underline{ \Pi}_{C}^{H}}.\]

Note that the conditions stated in the proposition imply

\[\lambda_{D}=\frac{\pi_{E}+\Pi_{D}-\bar{\Pi}_{D}^{L}}{\Pi_{D}-\underline{\Pi}_ {D}^{H}}<\frac{\pi_{E}+\Pi_{D}-\bar{\Pi}_{D}^{L}}{\Pi_{C}-\underline{\Pi}_{C} ^{H}}<\frac{\pi_{E}+\Pi_{C}-\bar{\Pi}_{C}^{L}}{\Pi_{C}-\underline{\Pi}_{C}^{H }}=\lambda_{C},\]

completing the proof.

Intuitively, the two inequalities above require that the dominant firm both stands to lose more if a startup is acquired by the challenger (maybe because the dominant firm has a larger market share, so it has more to lose) and stands more to gain by acquihiring the startup itself (a larger market share might be an explanation again, as any improvement could be offered to more consumers more rapidly).

A simple specification that satisfies these inequalities is an "equal proportional gain/loss". Formally, let the profit functions be given by

\[\begin{array}{llll}\bar{\Pi}_{D}^{H}=H\Pi_{D},&\bar{\Pi}_{D}^{L}=L\Pi_{D},& \underline{\Pi}_{D}^{L}=\ell\Pi_{D},&\underline{\Pi}_{D}^{H}=h\Pi_{D},\\ \bar{\Pi}_{C}^{H}=H\Pi_{C},&\bar{\Pi}_{C}^{L}=L\Pi_{C},&\underline{\Pi}_{C}^{L }=\ell\Pi_{C},&\underline{\Pi}_{C}^{H}=h\Pi_{C},\end{array}\]

where \(H>L>1\) and \(1\leq\ell>h\geq 0\). This implies that an acquihire (either own or by the competitor) has a proportionally equal effect on both the dominant firm and the challenger firm. As long as \(\Pi_{D}>\Pi_{C}\) (i.e., absent any acquihire, the dominant firm has higher profits than the challenger), straightforward calculations show that the two inequalities of Proposition B2 are satisfied and the dominant firm is more prone to acquihires than the challenger.

### Multiple Firms

Often, more than two firms are competing in a given market. In this extension, we thus allow for \(n\geq 2\) firms competing in the same market. As in the baseline, firms may sequentially attempt to do an acquihire of the startup and each firm's match type \(\theta\in\{L,H\}\) is an independent draw with identical probability \(\Pr(\theta=H)=\lambda\). In the absence of an acquihire, each firm makes profits \(\Pi_{F}(n)\). If firm \(i\) with match type \(\theta\) makes an acquihire profits read \(\bar{\Pi}_{F}^{\theta}(n)\) for firm \(i\) and \(\underline{\Pi}_{F}^{\theta}(n)\) for firms \(j\neq i\).

To make things concrete, we focus on a Cournot oligopoly setting with \(n\) firms and the following inverse demand function:

\[P(q_{1},...,q_{n})=a-b\cdot\sum_{i=1}^{n}q_{i},\] (B.3)

where \(q_{i}\) indicates the quantity choice of firm \(i\in\{1,...,n\}\) and \(a,b>0\). We assume that the demand intercept \(a\) is sufficiently large to ensure an interior solution. Let \(c>0\) denote the constant marginal cost when no acquisitions occur. An acquihire by one firm is assumed to reduce its marginal cost to \(c-\theta>0\), where \(\theta\in\{H,L\}\) satisfies \(H>L\geq 0\).

We first establish that increasing competition eliminates talent hoarding in the limit: as \(n\to+\infty\), firms acquire startups if and only if it is efficient to do so.15 To see this,take any one of the \(n\) firms and suppose that its match value with the startup is \(\theta\). It is clear that if \(\pi_{E}<\bar{\Pi}_{F}^{\theta}(n)-\Pi_{F}(n)\), this firm will acquire the startup whenever possible. In contrast, if

Footnote 10: The \(n\) firms are not necessarily necessarily \(\theta\)-independent, but they are not necessarily \(\theta\)-independent.

\[\pi_{E}>\bar{\Pi}_{F}^{\theta}(n)-\Pi_{F}(n),\] (B.4)

acquihiring is inefficient. At the same time, a necessary condition for the firm to have incentives to do an acquihire is

\[\bar{\Pi}_{F}^{\theta}(n)-\underline{\Pi}_{F}^{H}(n)>\pi_{E}.\] (B.5)

Note that the LHS of (B.5) is the maximum difference in the firm's profits between acquiring and not acquiring the startup. In our Cournot specification, as \(n\to+\infty\), both \(\Pi_{F}(n)\) and \(\underline{\Pi}_{F}^{H}(n)\) converge to zero. Therefore, conditions (B.4) and (B.5) cannot hold simultaneously when \(n\) is sufficiently large. This implies that, whenever (B.4) holds, no firm with a match value \(\theta\) will conduct an acquihire, therefore the talent hoarding problem cannot occur in equilibrium.

Next, we argue that the impact of competition on talent hoarding can be non-monotone. Note that when \(n=2\), talent hoarding arises in equilibrium if and only if

\[\pi_{E}\leq\lambda\left(\Pi_{F}(2)-\underline{\Pi}_{F}^{H}(2)\right)+\bar{ \Pi}_{F}^{L}(2)-\Pi_{F}(2).\] (B.6)

In comparison, suppose that \(n=3\) and firm 1 anticipates that firms 2 and 3 will acquire the startup when their match values are high. Then, firm 1 will be inclined to conduct an acquihire even when it draws a low match value, if the following condition holds:

\[\pi_{E}\leq(2\lambda-\lambda^{2})\left(\Pi_{F}(3)-\underline{\Pi}_{F}^{H}(3) \right)+\bar{\Pi}_{F}^{L}(3)-\Pi_{F}(3).\] (B.7)

Now, consider a parametric example with \(\lambda=0.1\), \(a=10\), \(b=1\), \(c=3\), \(H=2\), \(L=0\), and \(\pi_{E}\in(0.534,0.54)\). One can show that Assumption 1 holds. In addition, condition (B.6) is violated but condition (B.7) is satisfied. Thus, in the current example, talent hoarding will not occur in equilibrium when there are two firms. However, with three firms, talent hoarding will for sure arise in equilibrium.

### Partial Acquisitions

This section extends the baseline model to incorporate the possibility of partial investments. That is, a firm may acquire a (minority) stake in the startup without integrating it. To do so, we need to specify the payoffs resulting from such partial acquisitions as well as the rights that come with partial ownership.

Formally, the ability to make partial acquisitions means that firms can additionally try to acquire a share \(s\in(0,1]\) of the startup and continue to operate it as a stand-alone entity. In contrast to the model in the main text, we allow for upfront and deferred payments \((p,d)\) as is standard in such transactions. In the main text, doing so would not change anything. In the presence of partial ownership, it allows the acquiring firm to distinguish at least partially between the investor (who only gets a part of the upfront payment) and the entrepreneur (who can also receive deferred payments). If a firm acquires a share \(s\) with bid \((p,d)\), its payoff reads \(\Pi_{F}+s\pi_{E}(s)-p-d\), while the entrepreneur's payoff is \((1-s)\pi_{E}(s)+w(s)+p+d\). Here, \(\pi_{E}(s)\) captures the startup's profit net of potential wages paid to the entrepreneur as a function of the size of the external ownership. These profits accrue to the firm and the entrepreneur proportionate to their stake in the startup. Correspondingly, \(w(s)\) constitutes the entrepreneur's wage (net of effort costs) for different degrees of outside ownership. In particular, \(\pi_{E}=\pi_{E}(0)+w(0)\). That is, when the entrepreneur owns the entire startup and thus obtains all of its profit and "pays herself" a net-of-effort wage, her payoff coincides with the initial payoff in the baseline model. The other firm's payoff is unchanged at \(\Pi_{F}\). When a firm acquires a stake in the startup it receives a share of profits, while the dilution of ownership gives rise to moral hazard on the entrepreneur's side, which we capture in reduced form, only imposing the following assumption.

**Assumption B3**: _We assume that \(\pi_{E}(s)+w(s)\) is decreasing in \(s\) with \(\pi_{E}(0)+w(0)>\pi_{E}(1)+b(1)\)._

Assumption B3 captures the moral hazard arising when the entrepreneur no longer fully owns the startup. \(\pi_{E}(s)+w(s)\) being decreasing reflects the reduced effort of the entrepreneur as a result of agency. \(\pi_{E}(0)+w(0)>\pi_{E}(1)+w(1)\) captures that the first-best value of a startup fully owned by the entrepreneur is strictly higher than the second-best value, when the entrepreneur is actually an employee and has no stake in the startup.

The timing of the game is as follows. In the first stage, firm 1 has the opportunity to make a bid to the entrepreneur to acquire a share \(s_{1}\in(0,1]\) of the startup or make an acquihire. If the entrepreneur accepts a bid for an acquihire, the game ends. Otherwise, we move to stage 2, the ownership structure of the startup depending on whether the entrepreneur accepted firm 1's bid. In the second stage, firm 2 can make an acquihire by making a (per-share) bid to the owner(s) of the startup, where we restrict attention to bids \((p,d)\) with \(p\geq\pi_{E}(s_{1})\), so that no owner can be expropriated. If the entrepreneur does not accept the bid, the game ends. If the entrepreneur accepts, firm 1 can either also accept or try to block the transaction and succeeds in doing so with probability \(q(s_{1})\), where \(q\) is a weakly increasing function with \(q(0)=0\) and \(q(1)=1\). Nature determineswhether a potential blocking attempt succeeds and the game ends.

As a benchmark, we first consider the case where ownership of a stake does not convey any blocking rights.

**Proposition B3**: _Under Assumptions 1 and B3 and without blocking rights, i.e., \(q(s)=0\) for all \(s\in[0,1]\), firm 1's behavior in any PBE is uniquely specified. Namely, if firm 1 draws a high match type, it will make an acquiring; if it draws a low type it will make an acquiring if and only if \(\lambda\geq\lambda_{A}\) and do nothing otherwise._

Proof: See the proof of Proposition B4, which contains this as a special case.

The result in Proposition B3 shows that partial ownership of the startup is not enough to change firm 1's behavior relative to the setting with only acquhires in Proposition 1. Indeed, since an investment is not profitable in itself and does not prevent a high-match firm 2 from making an acquhire, firm 1 will continue to either do nothing or make an acquhire, depending on the probability of a high-match firm 2 materializing. As the next result shows, it is ownership accompanied by some measure of control over the startup, which makes investments attractive to firm 1.

**Proposition B4**: _Under Assumptions 1 and B3 and with blocking rights, firm 1's behavior in any PBE is uniquely specified. Namely, if firm 1 draws a high type, it will make an acquhire. If it draws a low type, there is a threshold value for \(\lambda\) below which it does nothing. Above the threshold, it will do an investment and, depending on the model's parameters, there may be an even higher threshold above which it does an acquhire._

Comparing the thresholds across Propositions 1, B3 and B4, we can observe that the presence of blocking rights on investments increases the parameter space for which some form of talent hoarding occurs. However, the possibility of making investments instead of an acquhire may also have "mitigating" effects relative to a setting with only acquhires, as talent hoarding by means of investments create smaller inefficiencies than by means of acquhires. Put differently, allowing for investments increases the extensive margin of talent hoarding but partially decreases its intensive margin.

Proof: We solve the game backward.

**Stage 2** Observe that firm 2 believes with probability 1 that firm 1 is a low type, as otherwise, an acquhire would have taken place in stage 1. Firm 2 has three actions: doing nothing, making a bid that is accepted by both the entrepreneur and firm 1 and making a bid which is accepted only by the entrepreneur. To understand this, observe that the payoffs of firm 1 and the entrepreneur following a firm-1 investment of size \(s_{1}\) at price \((p_{1},d_{1})\) read \[\begin{array}{rl}\mbox{Firm 1}:&\Pi_{F}+s_{1}\pi_{E}(s_{1})-p_{1}-d_{1}\\ \mbox{Entrepreneur}:&(1-s_{1})\pi_{E}(s_{1})+w(s_{1})+p_{1}+d_{1}.\end{array}\]

Hence, firm 1 would try to block any bid \((p_{2},d_{2})\) resulting in a lower payoff than the above, while the entrepreneur would not accept any bid yielding a lower payoff than the above. Given these constraints, firm 2 will choose among three options: (i) do nothing and receive payoff \(\Pi_{F}\); (ii) make the minimum bid such that both firm 1 and the entrepreneur accept, yielding payoff \(\bar{\Pi}_{F}^{\theta}-\pi_{E}(s_{1})-w(s_{1})-\Pi_{F}+\underline{\Pi}_{F}^{\theta}\) for firm 2; or (iii) make a bid that only the entrepreneur accepts, risking a blocking attempt by firm 1. This third option provides an expected payoff for firm 2 of \(q(s_{1})\Pi_{F}+(1-q(s_{1}))(\bar{\Pi}_{F}^{\theta}-\pi_{E}(s_{1})-w(s_{1}))\).

Let us consider a low-match firm 2 first. Comparing doing nothing with inducing only the entrepreneur to accept, we obtain that the latter move is is better for firm 2 whenever

\[\bar{\Pi}_{F}^{L}-\pi_{E}(s_{1})-w(s_{1})\geq\Pi_{F}.\]

It follows from Assumptions 1 and B3 that this condition is not necessarily satisfied. Let \(\hat{s}\) be the threshold above which this condition is satisfied. Now let's compare doing nothing with inducing both for \(s_{1}<\hat{s}\). We obtain that inducing both is better whenever

\[\bar{\Pi}_{F}^{L}-\pi_{E}(s_{1})-w(s_{1})-\Pi_{F}+\underline{\Pi}_{F}^{L}\geq q (s_{1})\Pi_{F}+(1-q(s_{1}))(\bar{\Pi}_{F}^{L}-\pi_{E}(s_{1})-w(s_{1})),\]

which, after rearrangement, can be rewritten as

\[q(s_{1})(\bar{\Pi}_{F}^{L}-\Pi_{F}-\pi_{E}(s_{1})-w(s_{1}))\geq\Pi_{F}- \underline{\Pi}_{F}^{L}\] (B.8)

Since the right-hand side of (B.8) is positive and the left-hand side of it is negative for \(s_{1}<\hat{s}\), this condition is never satisfied. Thus, for \(s_{1}<\hat{s}\) the low type does nothing.

Now let us compare firm 2 inducing only the entrepreneur versus inducing both to accept when \(s_{1}\geq\hat{s}\). As above, inducing both is better whenever condition (B.8) holds. Since the left-hand side of (B.8) is increasing in \(s_{1}\), we define \(s^{L}\in[\hat{s},1]\) as the threshold above which the condition is satisfied. Overall, a low-match firm 2 will take the following actions: for \(s_{1}<\hat{s}\), do nothing; for \(\hat{s}\leq s_{1}\leq s_{L}\), induces only the entrepreneur to accept; and for \(s_{1}>s_{L}\), induce both the entrepreneur and firm 1 to accept the offer.

Next, we turn to the high-match firm 2. Comparing payoffs of doing nothing and inducing only the entrepreneur, it follows from Assumption 1 that the firm will always find the former option inferior. So we only need to compare the payoffs of inducing both versus only the entrepreneur. In particular, inducing both is optimal whenever

\[q(s_{1})(\bar{\Pi}_{F}^{H}-\Pi_{F}-\pi_{E}(s_{1})-w(s_{1}))\geq\Pi_{F}-\underline{ \Pi}_{F}^{H},\]

which may be satisfied for \(s_{1}\) above some threshold \(s^{H}\in[0,1]\). Below this threshold, the high type will induce only the entrepreneur. Note that it is not clear whether \(s^{H}\) or \(s^{L}\) are bigger.

###### Stage 1

Observe that firm 1's belief about firm 2's type is given by the prior. Firm 1 can acquire different stakes \(s_{1}\) which in turn may induce different responses from firm 2. Specially, we have learned that a low-match firm 2 may do either nothing (N), induce only the entrepreneur (E), or induce both the entrepreneur and firm 1 to accept a bid (B). As for a high-match firm 2, it may either do E or B. In what follows let \((A_{1},A_{2})\) denote the action profiles of the low- and high-match firm 2, e.g, \((N,B)\) means firm 2 does nothing when it is a low type, and it induces both to accept when its type is high. Let \(\Delta(s_{1})\equiv\pi_{E}(s_{1})+w(s_{1})-\pi_{E}(0)-w(0)\). The following are the firm-1 payoffs resulting from an acquisition of \(s_{1}\) which induces the indicated firm-2 behavior:

\[(N,E): \lambda(1-(q(s_{1})))\underline{\Pi}_{F}^{H}+(1-\lambda(1-q(s_{1 })))\Pi_{F}+\Delta(s_{1})\] \[(N,B): \Pi_{F}+\Delta(s_{1})\] \[(E,B): (1-(1-\lambda)(1-q(s_{1})))\Pi_{F}+(1-\lambda)(1-q(s_{1})) \underline{\Pi}_{F}^{L}+\Delta(s_{1})\] \[(B,B): \Pi_{F}+\Delta(s_{1})\] \[(E,E): q(s_{1})\Pi_{F}+(1-q(s_{1}))(\lambda\underline{\Pi}_{F}^{H}+(1- \lambda)\underline{\Pi}_{F}^{L})+\Delta(s_{1})\] \[(B,E): \lambda(1-(q(s_{1})))\underline{\Pi}_{F}^{H}+(1-\lambda(1-q(s_{1 })))\Pi_{F}+\Delta(s_{1})\]

To illustrate how to calculate these payoffs, consider the case \((N,E)\), where the low-match firm 2 does nothing and the high-match induces only the entrepreneur to accept (while firm 1 would try to block such an acquuhire attempt by firm 2). Observe that the lowest bid at which the entrepreneur is willing to sell a stake \(s_{1}\) to firm 1 is \(p_{1}+d_{1}=\pi_{E}(0)+w(0)-(1-s_{1})\pi_{E}(s_{1})-w(s_{1})\). As we are considering the case \((N,E)\), so that a low-match firm 2 would do nothing, yielding a payoff of

\[\Pi_{F}+s_{1}\pi_{E}(s_{1})-(\pi_{E}(0)+w(0)-(1-s_{1})\pi_{E}(s_{1})-w(s_{1})) =\Pi_{F}+\Delta(s_{1}).\] (B.9)

A high-match firm 2 would make a bid that firm 1 will try to block, succeeding with probability \(q(s_{1})\), yielding the following payoff to firm 1

\[q(s_{1})\left(\Pi_{F}+\Delta(s_{1})\right)+(1-q(s_{1}))\left(\underline{\Pi}_ {F}^{H}+\Delta(s_{1})\right).\] (B.10)Adding (B.9) and (B.10) up while multiplying them with the probabilities \(1-\lambda\) and \(\lambda\), respectively, we obtain the expression in the above list.16 Finally, to complete the list, note that an acquuhire gives a payoff \(\bar{\Pi}_{F}^{L}-\pi_{E}(0)-w(0)\) to firm 1 and doing nothing results in \(\lambda\underline{\Pi}_{F}^{H}+(1-\lambda)\Pi_{F}\).

Footnote 16: Observe that the size of firm 1’s investment \(s_{1}\) is not the same across cases in the above list, as different investment sizes induce the different behaviors of firm 2.

To determine firm 1's equilibrium strategy, we need to further distinguish between three cases three cases based on the values of the thresholds \(s^{H}\), \(s^{L}\), and \(\hat{s}\). Recall that a low-match firm 2 will do nothing below \(\hat{s}\), induce the entrepreneur between \(\hat{s}\) and \(s^{L}\) and potentially induce both above \(s^{L}\), while a high-match firm 2 will induce only the entrepreneur below \(s^{H}\) and may induce both above it.

_Case 1: \(s^{H}\leq\hat{s}\leq s^{L}\)._ Note that this allows only for four types of firm-2 behavior following an investment. If \(s_{1}\leq s^{H}\), then we have \((N,E)\), a low-match firm 2 does nothing and a high-match induces only the entrepreneur ; if \(s^{H}<s_{1}\leq\hat{s}\), then we have \((N,B)\), namely a low-match firm 2 does nothing and a high-match induces both; if \(\hat{s}<s_{1}\leq s^{L}\), then a low-match firm 2 induces the entrepreneur and a high-match induces both, so we have \((E,B)\); and if \(s_{1}>s^{L}\), both types of firm 2 induce both, so we end up with \((B,B)\). Comparing these payoffs, we observe that an acquuhire dominates investments inducing \((B,B)\) and \((E,B)\), while an investment inducing \((N,B)\) dominates an acquuhire. Thus, the remaining actions are doing nothing, inducing \((N,E)\) or inducing \((N,B)\).

\[(N,E):\lambda(1-(q(s_{1})))\underline{\Pi}_{F}^{H}+(1-\lambda(1-q( s_{1})))\Pi_{F}+\Delta(s_{1})\] \[(N,B):\Pi_{F}+\Delta(s_{1})\] \[(N):\lambda\underline{\Pi}_{F}^{H}+(1-\lambda)\Pi_{F},\]

where the investment necessary to induce \((N,B)\) is bigger than the one for \((N,E)\) but both are smaller than \(\hat{s}\) so that \(\Pi_{F}+\pi_{E}(s_{1})+w(s_{1})\geq\bar{\Pi}_{F}^{L}\). We note that:

* As \(\lambda\to 0\) doing nothing dominates both types of investment
* For \(\lambda>\frac{\pi_{E}(0)+w(0)-\pi_{E}(s_{1})-w(s_{1})}{\Pi_{F}-\underline{\Pi }_{F}^{H}}\) inducing \((N,B)\) dominates \((N)\)
* Depending on parameters, \((N,E)\) or \((N,B)\) is the better investment, but for low enough \(\lambda\) inducing \((N,E)\) is always better

In summary, there is a threshold value for \(\lambda\) below which doing nothing is best, then for larger \(\lambda\) inducing \((N,E)\) is better, and for very large \(\lambda\), depending on parameters, inducing \((N,B)\) may be best.

_Case 2: \(\hat{s}\leq s^{H}\leq s^{L}\)._ Note that this allows only for four types of firm-2 behavior following an investment: \((N,E)\), \((E,E)\), \((E,B)\) and \((B,B)\). Proceeding as above, we find that there is a threshold value for \(\lambda\) below which doing nothing is best, then for larger \(\lambda\) inducing \((N,E)\) is better, and for very large \(\lambda\), depending on parameters, doing an acquihire may be best.

_Case 3: \(\hat{s}\leq s^{L}\leq s^{H}\)._ Note that this allows only for four types of firm-2 behavior following an investment: \((N,E)\), \((E,E)\), \((B,E)\) and \((B,B)\). Proceeding as above, we find that there is a threshold value for \(\lambda\) below which doing nothing is best, then for larger \(\lambda\) inducing \((N,E)\) is better, and for very large \(\lambda\), depending on parameters, doing an acquihire may be best.

### Unknown Order of Moves

We consider a variation of our baseline model in which the order in which the firms move is privately drawn by nature with uniform probabilities. Hence, firm 1 is not necessarily moving first anymore. Specifically, when firm \(i\) gets to interact with the startup, it does not directly observe whether the other firm has already interacted with the startup. Still, firm \(i\) can make a bid to acquihire the startup, which the entrepreneur can accept or reject. Ex-ante probabilities of the firms' private match types are unchanged and the payoffs following an acquisition, too. We obtain the following result.

**Proposition B5**: _Under Assumption 1, there exists a symmetric equilibrium in which all firms acquihire the startup at price \(\pi_{E}\) independently of their type if_

\[\lambda\geq\lambda^{\prime}_{A}\equiv\frac{\pi_{E}+\underline{\Pi}_{F}^{L}- \bar{\Pi}_{F}^{L}}{\underline{\Pi}_{F}^{L}-\underline{\Pi}_{F}^{H}}.\] (B.11)

Proof: Suppose that firm \(j\) behaves as suggested in the proposition and that the entrepreneur accepts bids if and only if they are at least \(\pi_{E}\). We consider the incentives of firm \(i\). Given Assumption 1, it is a dominant strategy for a high-match firm \(i\) to make a bid \(\pi_{E}\) to do an acquihire whenever it has the chance to do so. Now, consider a low-match firm \(i\). Given that firm \(j\) would always do an acquihire, firm \(i\) knows that it is moving first. Hence, doing nothing yields a payoff of \(\lambda\underline{\Pi}_{F}^{H}+(1-\lambda)\underline{\Pi}_{F}^{L}\), while doing an acquihire yields \(\bar{\Pi}_{F}^{L}-\pi_{E}\). Hence, doing the acquihire is optimal if and only if \(\lambda\geq\lambda^{\prime}_{A}\), completing the proof.

The result shows that our result in Proposition 1 remains qualitatively unchanged when firms do not the order in which they move. In particular, talent hoarding continues to arise as long as high types are sufficiently likely.

### Surplus Sharing

We modify our baseline model to allow for arbitrary degrees of surplus sharing between the entrepreneur and the firm when an acquihire takes place. Thus, firms still move sequentially, but in case of an acquihire the entrepreneur receives a share \(\gamma\in[0,1]\) of the surplus. We define surplus here as the difference between the joint payoffs arising from an acquihire and the joint payoffs arising in the case of no acquihire.

**Proposition B6**: _Talent hoarding can happen if the following condition holds:_

\[\gamma\leq\frac{\bar{\Pi}_{F}^{L}-\underline{\Pi}_{F}^{H}-\pi_{E}}{\bar{\Pi}_{F }^{H}-\Pi_{F}-\pi_{E}}.\]

Proof: We solve the game backward. Consider a high-match firm 2. The surplus resulting from an acquihire is given by \(\bar{\Pi}_{F}^{H}-\Pi_{F}-\pi_{E}>0\) so that an acquihire takes place and the resulting payoffs for firm 2 and the entrepreneur read \(\Pi_{F}+(1-\gamma)(\bar{\Pi}_{F}^{H}-\Pi_{F}-\pi_{E})\) and \(\pi_{E}+\gamma(\bar{\Pi}_{F}^{H}-\Pi_{F}-\pi_{E})\), respectively. Consider a low-match firm 2. The surplus then reads \(\bar{\Pi}_{F}^{L}-\Pi_{F}-\pi_{E}<0\) so that no acquihire takes place.

Moving to period 1, consider a high-match firm 1. The surplus resulting from an acquihire reads

\[\bar{\Pi}_{F}^{H}-(\lambda\underline{\Pi}_{F}^{H}+(1-\lambda) \Pi_{F})-((1-\lambda)\pi_{E}+\lambda(\pi_{E}+\gamma(\bar{\Pi}_{F}^{H}-\Pi_{F}- \pi_{E})))\] \[=(\bar{\Pi}_{F}^{H}-\Pi_{F}-\pi_{E})(1-\lambda\gamma)+\lambda( \Pi_{F}-\underline{\Pi}_{F}^{H})\geq 0,\]

so that an acquihire takes place. Consider a low-match firm 1. The surplus resulting from an acquihire reads

\[(\bar{\Pi}_{F}^{H}-\Pi_{F}-\pi_{E})(1-\lambda\gamma)+\lambda(\Pi_{F}-\underline {\Pi}_{F}^{H})+\bar{\Pi}_{F}^{L}-\bar{\Pi}_{F}^{H}.\]

This expression is positive (implying that an acquihire is profitable) whenever

\[\lambda\geq\lambda_{A,S}\equiv\frac{\pi_{E}+\Pi_{F}-\bar{\Pi}_{F}^{L}}{\Pi_{F }-\underline{\Pi}_{F}^{H}-\gamma(\bar{\Pi}_{F}^{H}-\Pi_{F}-\pi_{E})},\]

for \(\Pi_{F}-\underline{\Pi}_{F}^{H}-\gamma(\bar{\Pi}_{F}^{H}-\Pi_{F}-\pi_{E})>0\). We have \(\lambda_{A,S}\leq 1\) whenever the condition stated in the proposition holds.

Title: SSthreshless Start: A Sender-Side TCP Intelligence for Long Fat Network
Transcription: # SShreshless Start: A Sender-Side TCP Intelligence for Long Fat Network

Xiao Lu\({}^{\dagger}\), Ke Zhang\({}^{\dagger}\), Chuan Heng Foh\({}^{\ddagger}\), and Cheng Peng Fu\({}^{\dagger}\)

\({}^{\dagger}\) School of Computer Engineering, Nanyang Technological University, Singapore

\({}^{\ddagger}\) Department of Electrical Engineering, University of Surrey, UK

###### Abstract

Measurement shows that \(85\%\) of TCP flows in the internet are short-lived flows that stay most of their operation in the TCP startup phase. However, many previous studies indicate that the traditional TCP Slow Start algorithm does not perform well, especially in long fat networks. Two obvious problems are known to impact the Slow Start performance, which are the blind initial setting of the Slow Start threshold and the aggressive increase of the probing rate during the startup phase regardless of the buffer sizes along the path. Current efforts focusing on tuning the Slow Start threshold and/or probing rate during the startup phase have not been considered very effective, which has prompted an investigation with a different approach.

In this paper, we present a novel TCP startup method, called _threshold-less slow start_ or SSthreshless Start, which does not need the Slow Start threshold to operate. Instead, SSthreshless Start uses the backlog status at bottleneck buffer to adaptively adjust probing rate which allows better seizing of the available bandwidth. Comparing to the traditional and other major modified startup methods, our simulation results show that SSthreshless Start achieves significant performance improvement during the startup phase. Moreover, SSthreshless Start scales well with a wide range of buffer size, propagation delay and network bandwidth. Besides, it shows excellent friendliness when operating simultaneously with the currently popular TCP NewReno connections.

## I Introduction

TCP is a connection-oriented, reliable and in-order transport protocol which carries applications ranging from bulk data transmission to web browsing. Over the years, TCP has evolved from original TCP Tahoe [2] to the currently most widely used TCP NewReno [3]. TCP uses Slow Start during startup phase to probe the capacity of a network path with unknown characteristics. The TCP probing rate is controlled by its congestion window, _cwnd_, where a TCP connection can transmit up to _cwnd_ amount of unacknowledged packets.

TCP carries 95% of today's Internet traffic and constitutes 80% of the total number of flows in the Internet [5]. Among those TCP traffic, short-lived TCP flows spend most of their operational lifetime within the Slow Start process when _cwnd_ ramps up in an exponential manner. Measurement in [49] shows that 85% of the TCP traffic are short flows. This implies that the majority of data transmission in the Internet is dominated by the TCP startup behavior.

In the Slow Start process, _cwnd_ is set between one and four TCP packets initially [16], and its value is incremented by one packet upon each reception of an ACK in order to probe and test the available bandwidth. With this increment, _cwnd_ is doubled for each round trip time (RTT) when all ACKs are returned. As a result, the value of _cwnd_ is increased monotonically with an exponential rate for every RTT until when the network cannot cope with the amount of transmission from the TCP connection. The network congestion is signaled by triple duplicated ACKs or more seriously a Timeout detected by the TCP sender. When this congestion signal is detected, the TCP connection ends the Slow Start process and the Congestion Avoidance process takes over the adjustment of _cwnd_. Unlike Slow Start, Congestion Avoidance maintains a linear increment of _cwnd_ every RTT to avoid congestion.

The exponential increment of \(cwnd\) in Slow Start may significantly overshoot the available bandwidth when probing and testing the bandwidth availability. This overshooting of \(cwnd\) may cause serious congestion and packet loss which require a long time to recover. To prevent this overshooting, Slow Start introduces a parameter called Slow Start threshold, _ssthresh_, where when _cwnd_ reaches _ssthresh_ where an overshooting is likely, the TCP connection ends the Slow Start process and lets the Congestion Avoidance process to take over turning the growth of _cwnd_ to a conservative linear rate.

In general, the current Slow Start process combines an estimation of the bandwidth availability described by \(ssthresh\) and a rate probing algorithm in order to achieve high bandwidth utilization. Depending on the accuracy of the bandwidth availability estimation, a corresponding rate probing algorithm can be designed to achieve a certain high level of bandwidth utilization during the Slow Start process. For example, in an extreme case where the bandwidth availability estimation is highly accurate, the rate probing is unnecessary as a TCP sender can immediately operate at the optimal rate based on the estimation. In contrast, an inaccurate bandwidth availability estimation should accompany with a prudent rate probing algorithm to compensate the inaccuracy of the estimation.

However, Slow Start is known to be extremely inefficient. Two obvious problems in the current Slow Start algorithm design leads to this inefficiency, and these problems are particularly severe in long fat networks (LFNs) [41, 42]. The first obvious problem is the blind initial setting of _ssthresh_ due to lack of bandwidth availability estimation. With the blind initial setting of _ssthresh_, a prudent rate probing algorithm should be sought. However, the current Slow Start process uses exponential rate increment probing which is an aggressive rate probing algorithm. This combination amplifies the performance penalty of the problem. Precisely, when _ssthresh_ is set too high compared to the bandwidth-delay product (BDP), which represents the capacity of a network pipe, a TCP connection may inject more packets into a network causing congestion. This problem is serious in LFNs, because _cwnd_ is doubled every RTT, and this aggressive increase may easily cause burst losses and consequent Timeout [2] by overshooting the network capacity. Conversely, when _ssthresh_ is set too low, a TCP connection will exit Slow Start and enter Congestion Avoidance prematurely. Thus, _cwnd_ may take a long time to reach an optimal operating point that matches the capacity of the LFN. Both cases cause low link utilization. Here, we call this drawback the blind _ssthresh_ setting problem.

Another problem in the current Slow Start is related to the temporal queue buildup occurs during Slow Start. Packets buildup in a buffer occurs when a TCP connection increases \(cwnd\) and transmits more packets within a RTT round. An adequate buffer size is critical to hold this buildup of packets, otherwise packet loss will occur. Since Slow Start disregards of the backlog status in the bottleneck buffer, packet losses may occur even before \(cwnd\) has reached the available bandwidth, which significantly degrades the performance. This problem is significant when the buffer size of the bottleneck router is much smaller than the BDP. Here, we call this drawback the temporal queue buildup problem. This problem has been observed and discussed in [21].

The current efforts in improving the performance of TCP Slow Start largely focus on improving bandwidth estimations [6, 8, 9, 22, 7] for optimal \(sshtresh\) setting and/or designing an appropriate rate probing algorithm based on the reliability of bandwidth availability estimation. However, due to the limited ability of a TCP sender in observing the network resource, together with the fast changing network bandwidth availability, the accuracy of bandwidth availability estimation is largely uncertain giving no basis for the design of an adequate rate probing algorithm for optimizing the Slow Start performance.

Recognizing the challenges in finding optimal settings for the \(sshtresh\) and the probing algorithm, in this paper, we take a different approach that bypasses the need for _ssthresh_ setting which influences greatly to the performance. Our solution, called _threshold-less slow start_ or SSthreshless Start (pronounced as s-thresh-less start), is a sender-side enhancement that offers immediate benefits upon deployment. The key idea of our method is that it makes use of backlog status at the bottleneck buffer, monitored by RTT to refine the _cwnd_ ramping up behavior and adaptively adjust probing rate to meet the available network capacity. SShreshless Start proposes alternating between an exponential and a linear growth of \(cwnd\) based on backlog status during the TCP startup phase. Our preliminary results reported in [1] have shown encouraging performance gain in TCP startup. In this paper, extensive simulation and in depth investigations are conducted to evaluate the benefit of rate alternation on TCP startup performance.

Briefly, The alternating of two rates achieves benefits in three aspects. Firstly, it eliminates the need of _ssthresh_ to decide when Congestion Avoidance should take over to end the exponential growth of \(cwnd\). Without _ssthresh_, the blind _ssthresh_ setting problem does not exist in SShreshless Start. In other words, the network status detection does not translate to _ssthresh_, instead, the status is used directly to control the rate probing algorithm between aggressive and prudent modes, where \(cwnd\) is increased continuously alternating between an exponential and a linear rates until a congestion signal is detected. Secondly, SShreshless Start monitors the backlog status and switches the growth rate of \(cwnd\) to linear when queue buildup is observed. This prevents continuous queue buildup in the buffer and hence avoids the temporal queue buildup problem from materialized into a packet lost event before the available bandwidth is reached. Finally, since \(cwnd\) increases monotonically during SShreshless Start, packet loss is inevitable due to the finite availability of the bandwidth. However, as network congestion approaches, the number of backlogged packets at the bottleneck buffer will have increases. This will signal SShreshless Start turning to linear growth rate for \(cwnd\). The preemptive switch to a linear growth rate for \(cwnd\) as network congestion approaches allows a fast recovery when a packet loss event eventually occurs.

We implement our TCP startup solution and combine it with NewReno. NewReno is chosen because several existing startup modifications, for example Hoe's Change [18] and Limited Slow Start [10], are also refined based on NewReno. This also allows a direct comparison to existing modifications. Comparing with traditional Slow Start and existing modifications, our enhancement shows significant improvement in link utilization during the startup process with various BDP and buffer configurations. Besides, our enhancement also shows good convergence behavior without adversely affecting coexisting TCP connections. Therefore, the throughput gain during startup is achieved by using the spared bandwidth effectively rather than aggressively depriving bandwidth from other co-existing TCP connections.

The remainder of the paper is organized as follows. We start by demonstrating the problems with Slow Start by simulations in the next section. After summarizing some related works in Section III, we describe the SShreshless Start in Section IV, validate it through intensive simulation experiments in Section V, and we finally conclude this paper in Section VI.

## II Problems with Traditional Slow Start

To illustrate the inefficiency of Slow Start in a LFN, we conduct simulation experiments using ns-2.34 [55]. Fig. 1 shows our considered network topology used commonly for this purpose of study. In Fig 1, TCP Src represents the TCP sender and TCP Dst represents the TCP receiver. Routers A and B are two droptail bottleneck routers. Side links are all with bandwidth of \(500\) Mbps, and one-way delay of \(0.1\) ms. Between the two routers there is a bottleneck link with \(40\) Mbps bandwidth and \(50\) ms one-way delay. For convenience, congestion window size is measured in number of packets, and the packet size is \(1000\) bytes while ACK is set to \(40\) bytes long. This gives the BDP value to be \(500\) packets. The bottleneck router is with \(250\) packets buffer size (BDP/2). TCP sources run NewReno with traditional Slow Start. All the other simulation experiments conducted in this paper also use this dumbbell topology with varying buffer size, one-way delay and bandwidth.

In traditional Slow Start [2], before a TCP connection starts, initial _ssthresh_ is set to an arbitrary value, ranging from 4 KB to extremely high. This blind _ssthresh_ setting problem severely degrade TCP startup performance, especially in LFN. We conduct an simulation to illustrate the impact of _ssthresh_ setting on the performance of Slow Start for short transfers.

In our setup, we consider a single TCP connection with three cases of different _ssthresh_ values where one is higher than, one is equal to and one is low than the BDP value. Precisely, we set the _ssthresh_ values to 5000, 500 and 32 packets in each simulation and label them as "NR with SS (L)", "NR with SS (A)", "NR with SS (S)", respectively. We plot the _cwnd_ and sequence number evolution of the three studied cases in Fig. 2.

As can been seen from the results in Fig. 2(a), "NR with SS (L)" that overestimates the BDP quickly overshoots the BDP and produces burst losses at the router. These burst losses cause a series of Timeout events in TCP that forces its _cwnd_ to exit exponential grow phase prematurely after Timeout restart. When _ssthresh_ is set much lower than the BDP in the case of "NR with SS (S)", we see that the TCP

Fig. 1: Network simulation topology.

connection exits Slow Start and switches to Congestion Avoidance phase prematurely. Both cases result in very low bandwidth utilization as illustrated in Fig. 2(b). Whereas if _ssthresh_ is set appropriately, we see the best performance amount all as the TCP connection rapidly grows to the BDP, exits the Slow Start and maintain stable _cwnd_ throughout the simulation period. The overshooting of BDP by _cwnd_ in the case of "NR with SS (L)" is clearly indicated by the great discrepancy between the sent and received sequence numbers as shown in Fig. 2(b).

We further record the link utilization and the highest sequence number of the packet being sent for each case in Table I. By comparing the throughput, it is clear that an inadequate setting of _ssthresh_ affects greatly the transmission capability of short connections.

However, even the _ssthresh_ is set to match the BDP at the start, we found that \(cwnd\) may still fail to reach the BDP as also reported by others in the literature [50]. To illustrate the effect, we test a TCP connection whose initial _ssthresh_ matches the BDP and the buffer size is set to only 0.2 times of the BDP. The \(cwnd\) and buffer utilization evolutions during the startup are plotted in Fig.3.

As can be seen, as \(cwnd\) reaches over 250 packets, the bottleneck buffer hits its maximum utilization and a small amount of packet drops is recorded. Since the TCP sender takes an RTT period to realize the packet loss, it continues to ramp up its \(cwnd\) by doubling the value to over 400 packets resulting significant packet drops.

Upon detection of the first triple duplicate ACKs, the TCP connection switches to Fast Recovery and cuts \(ssthresh\) to just below 250. The increment of \(cwnd\) stalls as only duplicate ACKs are returned. During this period, since \(cwnd\) remains constant, the queue barely builds up in the buffer. Being unable to recover all lost packets, a Timeout event finally occurs at around 1.3s where \(cwnd\) is set to 1 and \(ssthresh\) is adjusted to just above 100, and the connection returns to Slow Start at a much lower \(ssthresh\) value. At this point, the TCP connect has seriously underestimated the available bandwidth which results in significant underperformance. The cause of this problem is attributed to the failure of probing rate control when temporal queue buildup occurs in the bottleneck buffer.

## III Related Works

One critical problem of traditional Slow Start performance inefficiency is that TCP sender lacks the ability to estimate the network condition properly. To improve TCP startup performance, many approaches have been attempted in the past to achieve better estimation of network bandwidth availability and/or design a rate probing mechanism that is less susceptible to the accuracy of the bandwidth availability estimation. Generally, these efforts to enhance startup performance can be categorized into four different strategies

Fig. 2: Comparison of NewReno with different _ssthresh_ settingdescribed below.

* The rate probing refinement approach: In this approach, a TCP connection uses a different rate probing mechanism than the traditional one to achieve better utilization of available network bandwidth. Some proposed mechanisms also use dynamic rate probing mechanisms, where returned ACKs are used to indicate the network status and adjust the rate probing mechanisms.
* The bandwidth estimation approach: In this approach, a TCP connection performs an estimation of the network to assist rate probing. The estimation may perform continuously.
* The history-based approach: In this approach, a TCP connection uses historical data about the network resource availability cached by previous or concurrent connections to estimate the current network status and derive optimal parameters for the TCP connection to start.
* The router-assisted approach: In this approach, a TCP connection uses direct feedbacks from routers to indicate network resources and adjusts its sending rate accordingly.

### _The Rate Probing Refinement Approach_

The rate probing refinement approach seeks modification of the _cwnd_ ramping up behavior such that the increment of the probing rate is less susceptible to the accuracy of the initial guess of the bandwidth availability estimation. A typical example of this approach is the Limited Slow Start (LSS) [10] which uses an additional threshold to prevent the Slow Start algorithm from increasing too fast. It introduces a new Slow Start threshold, _max_ssthresh_, that prevents the probing rate from growing excessively high. Precisely, when _cwnd_\(\leq\)_max_ssthresh_, _cwnd_ doubles for each RTT as in the traditional Slow Start. When _max_ssthresh_\(<\)_cwnd_\(\leq\)_ssthresh_, _cwnd_ is increased by a fixed amount of \(max\_ssthresh/2\) packets for every RTT. This condition reduces the growth rate of _cwnd_ which in turns reduces the number of drops

Fig. 3: Ramping up behavior of NewReno with Slow Start (\(ssthresh\)=500pkts, Buffer Size=1/5BDP).

during the startup. However, the blind _ssthresh_ setting problem remains unsolved with this approach. Other schemes based on a similar strategy such as CapStart [15] and Smooth-Start [12, 13] suffers the same shortcoming.

In [11], TCP Vegas has demonstrated that the packet delay at the bottleneck router can be estimated by observing the RTT of each packet transmission. This provides a better guidance for a TCP sender to either refine its rate probing strategy or adjust Slow Start parameters such as _ssthresh_ to enhance its Slow Start performance. Based on the observed packet delay, TCP Vegas uses a different rate probing strategy, namely, it doubles _cwnd_ every other RTT, and exits the Slow Start phase when the estimation of packet delay exceeds a certain threshold. This method, however, often leads to low bandwidth utilization due to premature exiting of Slow Start as a result of temporary queue buildup in the buffer caused by bursty TCP transmission [21]. Enhancing the usage of RTT information, Delay-base Slow Start (DBSS) [14] uses RTT information to adjust _max_ssthresh_ which indirectly prevents _cwnd_ from overshooting and avoid premature exiting of the Slow Start phase. However, it requires a threshold on RTT to function and setting of an appropriate threshold remains a challenge.

### _The Bandwidth Estimation Approach_

The bandwidth estimation approach aims to solve arbitrary _ssthresh_ setting problem by setting it to some estimated BDP value to mitigate the effect of overshooting while maintaining the original rate probing strategy. Bandwidth estimation is first introduced in [17] by using packet pair bandwidth measurement technique. Packet pair measurement uses the inter-arrival time between the ACK pair received at the source to infer the bottleneck bandwidth along the path. Based on this technique, Hoe [18] proposed to set initial _ssthresh_ to the product of the measured delay and the estimated bandwidth. However, attribute to the aggressive _cwnd_ increase manner, Hoe's Change may suffer temporary queue overflow and multiple losses when the bottleneck buffer is not large enough compared to the BDP, or many flows are coexisting [21]. Several improvements based packet pair bandwidth measurement have been proposed to enhance Hoe's method [19, 24, 25, 26, 39]. Nevertheless, evidenced in [27, 28], the packet pairs technique gives a reliable estimation of the bottleneck link capacity rather than an available bandwidth on a network path. Hence, only limited performance gain can be achieved.

Beside the packet pairs technique, the packet trains estimation measurement appears to be more reliable for the estimation of the instantaneous available bandwidth of a path. Early Slow Start Exit (ESSE) proposed in [23] uses observation from a series of ACK returning times to estimate the instantaneous available bandwidth and set the initial _ssthresh_ value. Paced Start proposed in [40] further uses the difference between data packet train dispersion and ACK train dispersion to interactively for bandwidth estimation and _sstthresh_ setting. TCP Westwood uses Eligible Rate Estimation (ERE) [22] that relies on ACK train from receiver for bandwidth estimation. Adaptive Start [20] proposes using ERE to assist the Slow Start.

However, researches carried in [29, 30] have shown that the dispersion of long packet trains does not measure the available bandwidth in a path, rather, it tells another bandwidth metric known as Average Dispersion Rate (ADR), the value which is in between an available bandwidth and a capacity of the path. The direct use of the dispersion of long packet trains for available bandwidth measure may cause misleading estimation leading to undesirable performance. Inspired by these findings, Hybrid Slow Start [31] combines ACK train estimation and increase in packet delays in the the Slow Start algorithm for performance enhancement.

In summary, while these estimation techniques achieve a certain performance gain compared to Slow Start that uses arbitrary default _ssthresh_ value, the performance gain is limited due to their accuracy in the estimation caused by various factors. One obvious factor is due to the additional manipulation of ACK replies in modern TCP operations, such as ACK clustering and compression [33, 52], Delayed ACK [51] are affecting the accuracy of bandwidth estimation. Other factors such as TCP coarse-grained clocks [34], rerouting [35] and route asymmetry between forward and reverse path also pose challenges to the accuracy of bandwidth estimation. Besides, even an accurate bandwidth estimation technique is achieve, this approach of using bandwidth estimation do not deal with and hence cannot resolve the temporal queue buildup problem.

### _The History-Based Approach_

The history-based approach makes use of history information cached by previous or concurrent connections to improve Slow Start performance. It is based on the assumption that any hosts in the sub-domain would experience similar performance to distant hosts. Usually schemes fall into this catalog is intended for a restart transmission on connections that have been idle for a long time to benefit some certain applications (i.e., web browsing).

Transaction TCP [43, 44] caches previous connection count history in order to save the three-way handshake in certain situations to speed up future connection establishment. Expanding on the available historical information, TCP Control Block Sharing [48] and Congestion Manager [32] propose sharing of Slow Start related information among recent or concurrent TCP connections with the same end nodes.

Other incremental enhancements falling within this approach include TCP with Shared Passive Network Discovery (SPAND) or TCP/SPAND [47][46] and Adaptive TCP Slow Start [45].

In summary, the historical-based approach makes use of historical information to help a new TCP connection tune to a more appropriate sending rate. However, the usefulness of the historical information may vanish quickly due to the fast changing load conditions in the network. Besides, this approach is unable to benefit TCP startup performance when historical information does not exist. For example, when a connection is established to a new destination, traditional Slow Start is adopted instead.

### _The Router-Assisted Approach_

It is illustrated that assistance from routers for TCP rate control is effective to achieve high utilization of network bandwidth [38]. Measured directly at the routers, it offers accurate bandwidth availability utilization, and the role of rate probing algorithm can be significantly reduced. Quick-Start [36] and XCP [37] are some typical examples for this approach. In Quick-Start, a TCP sender advertises a desired sending rate during the three-way handshake to let the network (each hop along the path) approve, reject or reduce the requested sending rate. This way, a sender can quickly tune to an appropriate rate without the time consuming probing procedure. Comparatively, XCP proposes a more fine-grained feedback to TCP senders for them to decide their sending rates.

In summary, while the router-assisted approach gives potential to significantly improve the utilization of networks especially during the startup phase of a TCP connection, they require special operations in routers which prevents them from immediate deployment and thus their attractiveness is not high.

## IV The Enhancement

We shall introduce a novel startup scheme, called SSthreshless Start, with the goal to address the two aforementioned problems in the traditional Slow Start. As discussed in Section III, with the accuracy limitation in the bandwidth estimation and the history-based approaches, and the deployment drawback in the router-assisted approach, we argue that the rate probing refinement approach remains a potential approach that can offer significant performance gain in Slow Start with immediate deployment. However, the main challenge of the rate probing refinement approach is the ability to quickly probe available bandwidth for the setting of the sending rate to ensure high utilization based on a certain bandwidth availability estimation translated into _ssthresh_ setting. Recognizing the challenges in finding an optimal setting for _ssthresh_ based on a certain bandwidth availability estimation and an adequate rate probing algorithm, we take a difference that bypasses the need for _ssthresh_. With this novel attempt, we design a new startup scheme that not only achieves efficient sending rate, but also copes well with the temporal queue buildup problem. Owing to needless of _ssthresh_, we call our startup scheme _threshold-less slow start_ or SSthreshless Start. We detail SSthreshless Start in the following subsections.

### _Backlogged Packet Detecting_

TCP Vegas is known as a delay-based congestion control mechanism since it uses RTT for each packet transmission to estimate the backlog status of the buffer to adjust its congestion control strategy. Past research [4, 11] has shown that this estimation, in terms of the delayed packets due to buffering at the bottleneck router, leads to a more accurate estimation of network traffic load condition. Capitalizing on this effective estimation, we reuse this estimation mechanism in our proposed SSthreshless Start.

In TCP Vegas, the throughput difference is calculated by

\[Diff=(Expected-Actual)=\left(\frac{cwnd}{BaseRTT}-\frac{cwnd}{RTT}\right)\]

where _BaseRTT_ is the minimum of all measured RTT, and _RTT_ is the actual round trip time of a tagged packet. Denote the delayed packets at bottleneck buffer by \(N\), we have,

\[RTT=BaseRTT+N/Actual.\]

Rearranging the above equation, we obtain

\[N=\left(\frac{cwnd}{BaseRTT}-\frac{cwnd}{RTT}\right)\times BaseRTT. \tag{1}\]

During startup phase we can use (1) to calculate the delayed packets at bottleneck buffer. This provides the information of backlog status for our SSthreshless Start.

### _SSthreshless Start_

The key idea of SSthreshless Start is that it makes use of backlog status at the bottleneck buffer, monitored by RTT to refine the _cwnd_ ramping up behavior and adaptively adjust probing rate to meet the available network capacity. Rather than translating the network status into \(ssthresh\), the network status is directly used to control the rate probing algorithm.

We propose a two-mode operation in the rate probing procedure, namely, Linear Increase Mode and Adjustive Increase Mode, each mode is intended to operate in the situation when the queue buildup is detected or not detected, respectively. Recall that the estimated delayed packets number is \(N\), a certain number of estimated delayed packets, \(N\geq\beta\), can be used to signal a packet building up event at the bottleneck router. The quantity \(\beta\) is a design time protocol parameter for SSthreshless Start to switch between Linear Increase and Adjustive Increase modes. While \(\beta\) is arbitrary set, we shall show that the Slow Start performance is insensitive to this threshold.

Based on (1), SSthreshless Start measures \(N\), the estimation of backlog at the bottleneck router, and compares with the threshold \(\beta\). If the estimated number of backlog packets exceeds \(\beta\), we assume that the bottleneck router is experiencing packet building up. Once the backlog is clear below \(\beta\), the TCP sender is said to have experienced one congestive event. In our scheme, the TCP sender monitors the congestive status and records the total number of congestive event experienced for rate probing purpose.

Each TCP connection begins with the binary exponential increase of _cwnd_ as in the traditional Slow Start. Different from the traditional Slow Start, each TCP continuously monitors the backlog packets. When the monitored number of the backlog packets exceeds \(\beta\) indicating the occurring of packet building up, SSthreshless Start takes over the control of _cwnd_.

SSthreshless Start operates in either Linear Increase Mode or Adjustive Increase Mode, and it always starts in Linear Increase Mode. In Linear Increase Mode, the TCP connection increases its _cwnd_ by one for every RTT which confines the _cwnd_ increment to a linear rate. SSthreshless Start is activated when the estimated backlog packets exceeds \(\beta\) for the first time, thus starting SSthreshless Start in this conservative increase manner helps clear temporary buildup by slowing down the transmission from the source to the buffer to avoid buffer overflow and multiple losses. SSthreshless Start remains in this mode as long as the monitored number of backlog packets exceeds \(\beta\).

Once the monitored number of backlog packets falls below \(\beta\), SSthreshless Start switches to Adjustive Increase Mode where _cwnd_ increment rate turns aggressive again. The aggressiveness of the increment also depends on the number of encounters of congestive events. In our design, the more congestive events a TCP connection encounters, the milder is the increment of its _cwnd_. This is because as _cwnd_ increases monotonically in either Linear Increase Mode or Adjustive Increase Mode, the likelihood of _cwnd_ reaching the available bandwidth also increases, and a milder increment in _cwnd_ should be used to prevent it from overshooting the available bandwidth causing serious losses.

Note that, different from Delay-based TCP startup schemes (i.e., TCP Vegas and DBSS), where delay-based information is used the find the threshold of exiting startup phase, SSthreshless Start uses backlog status to dynamically switch _cwnd_ ramping up behavior in an exponential-linear cycles, adaptively seizing the available bandwidth. SSthreshless Start exits when packet losses occur. The pseudo code of SSthreshless Start is given in the following.

```
if(three DUPACKs are received)/*startup phase exits*/then _sstthresh=cwnd/2_; _Congestion_Event_No=0_; _Congestive_Status=0 // congestive status of last RTT_; _/*switch to Congestion Avoidance Mode*/ else if(\(N\geq\beta\)) then _Congestive_Status\(=1\)_; \(cwnd+=\frac{1}{cwnd}\); on each ACK _/*Linear Increase Mode*/ else if(Congestive_Status\(=1\)) then _Congestion_Event_No++_; _Congestive_Status\(=0\)_; endif \(cwnd+=\max\left(\frac{1}{cwnd},\frac{1}{2^{Congestion_Event\_No}}\right)\); for every ACK _/*Adjustve Increase Mode*/ endif endif
```

**Algorithm 1** SShreshless Start

In the above pseudo code, _Congestive_Event_No_ indicates the times of congestive events occurred with its initial value set to \(0\). According to our design shown in Algorithm 1, the increment of _cwnd_ in Adjastive Increase Mode is set between \(\frac{1}{cwnd}\) and 1 for every ACK. In other words, for every RTT, \(cwnd\) is increased by a value between 1 and \(cwnd\).

## V Performance evaluation

In this section, we present numerical results of SShreshless Start, compared with the tradition Slow Start and other variants, given different network environments with dissimilar parameter settings. We first evaluate the parameter setting of SShreshless Start, then demonstrate the ramping up behavior and throughput advantages over other variants. Finally, we also show the fairness and friendliness of our SSthreshless Start.

### _Parameter Setting_

In Fig. 4 we vary the value of switch, \(\beta\), to assess the its sensitivity to the performance of SSthreshless Start. Surprisingly, varying \(\beta\) does not cause much difference in the performance. We present in Table II the numerical details for the link utilization and highest sequence number of packets being sent for three different \(\beta\) values from small to large. As can be seen from Table II, the performance difference is very small. This indicates that the value of \(\beta\) is not a mainly decisive factor in the performance, which makes SSthreshless Start tolerable to the inaccuracy of TCP timers [53][54], which affects the backlog estimation, and the setting of \(\beta\).

As shown in Fig. 4, as \(\beta\) goes large, the ramping up behavior is slightly more aggressive. To an extreme when \(\beta\) is set to infinity, SSthreshless Start will behave like the traditional Slow Start since the congestive event can never occur. In contrast, when \(\beta\) is set to a small value, the occurrence of the congestive event increases and _cwnd_ grows in a more conservative rate. Based on the past experiences [12, 10], conservative growth in _cwnd_ may significantly reduce burst losses, we thus suggest a smaller \(\beta\) setting.

Fig. 4: SSthreshless Start _cwnd_ evolution under different values of \(\beta\).

We recommend the setting of \(\beta=3\) as this setting gives conservative growth in _cwnd_ yet maintain a high link utilization as reported in Table II.

### _SSthreshless Start Ramping up behavior_

Fig. 5 compares the single flow ramping up behaviors of SShreshless Start, Slow Start and Vegas, along with the monitored backlog at bottleneck router. The buffer size is set to a small value of 200 packets, or \(\frac{2}{5}\) of the BDP, and _ssthresh_ of Slow Start is set to accurate value of BDP in this case.

Depending on the instantaneous backlog status, SShreshless Start switches between exponential and linear rate to increase _cwnd_. It allows _cwnd_ to adaptively ramp up to the BDP in a timely manner. The _cwnd_ value reaches an eligible window size in around 2s, and maintains high link utilization ever since. By monitoring the backlog status, SShreshless Start would have switched to a linear rate just before the occurrence of a packet loss that ends the SShreshless Start operation, and this helps the Congestion Avoidance operation which takes over SShreshless Start to cope with the loss.

In comparison, the aggressive Slow Start increases its _cwnd_ to the BDP size in around 1s. However, the temporary queue buildup occurs with packet drops and following Fast Recovery [3] fails to recover the multiple losses since Slow Start remains in exponential growth when losses occurred, and this causes a Timeout. Consequently, the \(sshtresh\) is repeatedly adjusted downward to eventually a small value which focuses the TCP connection to enter Congestion Avoidance phase prematurely. For Vegas, it also enters Congestion Avoidance prematurely right after backlog exceeds its threshold. Being too conservative, it manages to avoid multiple losses but operates in a very low throughput. Over the evaluation time shown in Fig. 5, neither Slow Start nor Vegas is capable of seizing the eligible BDP where majority of available bandwidth is left unused. As listed in Table III, SShreshless Start captures as high as \(80\%\) of the link utilization, where Slow Start and Vegas utilize below \(30\%\).

### _Throughput Comparison_

In this subsection, we compare NewReno with SShreshless Start (SLS), Hoe's Change (HC), Limited Slow Start (LSS), Slow Start with small _ssthresh_, \(32\) packets (SS (S)), Slow Start with large _ssthresh_, 5000 packets, (SS (L)), and TCP Vegas. It shows that the SShreshless Start significantly improves startup performance with regards to various buffer size, one-way delay, and bandwidth. To focus on the startup performance, we only evaluate the performance in the first \(20\) seconds. In addition, we use Throughput Ratio, calculated as the throughput of SShreshless Start over other variants, as a measure to evaluate the performance enhancement of our proposal.

In Fig. 6, we fix the bandwidth to \(40\) Mbps, delay to \(50\) ms, and vary the buffer size from \(100\) packets to \(300\) packets to study impact of buffer sizes on the performance. In this case, we also evaluate the Slow Start with _ssthresh_ setting to the accurate BDP size, 500 (SS (A)), to show the buffer robustness of our proposal. It is evident that high throughput is achieved by our SShreshless Start in all the test cases. Also as can be seen, when the buffer size is small, Hoe's Change, Limited Slow Start and even Slow Start with _ssthresh_ set to accurate BDP suffer severe performance degradation. These startup algorithms fail to obtain a high throughput even with the help of ample buffer size. The case with a small buffer size, \(1/5\) BDP, is shown in Table IV. The performance benefit of SShreshless Start is significant, which gains up to 3 to 14 times over other variants.

As aforementioned, one of characteristic of LFN is long link delay. Thus, to assess performance with long RTT, we very the bottleneck one-way delay from \(10\) ms to \(100\) ms. The bandwidth and buffer size are fixed to \(40\) Mbps and BDP/2, respectively. Fig. 7 shows the throughput comparison under this scenario. The subtle changes in the throughput of NewReno with SShreshless Start and Hoe's Change shows their

Fig. 5: Comparison of different TCP startup schemes (Buffer=2/5BDP, first 10s)ability to scale well with long delay, while other startup algorithms suffer from performance degradation as delay increases. The case with largest tested one-way delay, 100 ms, is listed in Table V-C. Note that the throughput of SSthreshless Start achieves over 18 times that of the traditional Slow Start.

Fig. 6: NewReno (NR) throughput versus buffer size (first \(20\)s).

To evaluate the performance of SSthreshless Start with respect to another characteristic of LFN, high bandwidth, we vary the bottleneck bandwidth from \(10\) Mbps to \(150\) Mbps. Besides, we fix the bottleneck one-way delay to \(50\) ms and buffer size to BDP/2. Fig. 8 reports on NewReno throughput achievements with different startup schemes under this scenario. It is shown that, NewReno with SSthreshless Start and Hoe's Change scale well with a wide range of bandwidth. Other schemes lack the ability to adapt to network bandwidth effectively, leading to poor throughput achievements. The case with largest tested bandwidth, 150Mbps, is listed in Table V-D. Notably, SSthreshless Start outperforms the traditional Slow Start just over 35 times in terms of throughput.

### _Dynamic Bandwidth_

Considering that available bandwidth may change several times during the startup phase of a TCP session under a dynamic environment (i.e., other connections may join or leave the link), a well-performed startup scheme should be aware of the instantaneous available bandwidth to adjust the _cwnd_ ramping up strategy. To assess the capability of SSthreshless Start in the network with dynamic network load, we add a burst UDP cross-traffic set to 10 Mbps, starting at the first second and stopping at the fifth second. Fig. 9 shows the comparison of SSthreshless Start and Slow Start under this scenario.

During the first second, \(cwnd\) of SSthreshless Start ramps up just as usual. After initiating the burst of UDP traffic, SSthreshless Start detects the decrease of available bandwidth quickly through the backlogged queue, and accordingly, halves _cwnd_ growth rate each time when congestive event happens. After reaching the available bandwidth, _cwnd_ turns linear increment. Then, right after the termination of UDP traffic flow, SSthreshless Start detects the clearing up of bottleneck backlog and alternates _cwnd_ growth rate back to exponential again. This simulation shows that the alternation between exponential and linear growth rate

Fig. 7: NewReno (NR) throughput versus delay (first \(20\) s).

of _cwnd_ can cope well with dynamic changing bandwidth availability.

On the other hand, due to the aggressive and blind increase strategy, Slow Start incurs losses upon the presence of UDP flow. Following Fast Recovery fails to recover the multiple losses which leads to a consequent Timeout.

In addition, to compare the transmission capability, the Link Utilization and the highest sequence number of packets being sent are recorded in Table V-E. The amount of data SShreshless Start manages to send is almost two times larger than that of Slow Start. This makes SShreshless Start greatly benefit short flows, that lasts only for several seconds under a dynamic environment.

### _Friendliness to Slow Start_

Fig. 10 shows the coexistence of multiple SShreshless Start and Slow Start connections. We consider five NewReno connections, in which connections \(1\) and \(2\) are NewReno with Slow Start (_ssthresh_\(=\) 32 packets) and connections \(3\), \(4\), \(5\) are NewReno with SShreshless Start. Connections \(1\), \(2\), \(3\), \(4\) start at

Fig. 8: NewReno (NR) throughput versus bottleneck bandwidth (first \(20\) s).

second to investigate the effect of SSthreshless Start and Slow Start startup at the same time. Connection \(5\) starts at \(30\)th second to estimate the effect of SSthreshless Start on existing TCP connections. It is shown that SSthreshless Start utilizes network bandwidth left unused by Slow Start connections at the very beginning. After several rounds of synchronized packet losses, \(cwnd\) for each connection converges to a same value. When connection \(5\) joins the network, it does not adversely affect existing TCP connections. It is able to probing rate quickly to reach the state of other concurrent TCP connections. Finally, all five connections converge to the same window size, which is around \(100\) packet sizes or one-fifth of the BDP. Each connection utilizes its own share fairly, demonstrating the friendliness of NewReno with SSthreshless Start in bandwidth sharing with the traditional Slow Start.

## VI Conclusions

In this paper, we present a novel sender-side enhancement, SSthreshless Start, to improve TCP startup performance in long fat networks. The key idea is to make use of backlog status at the bottleneck buffer, monitored by RTT to refine the _cwnd_ ramping up behavior, dynamically and adaptively adjusting probing rate to reach the available bandwidth. By alternating between exponential and linear growth rates of

Fig. 9: Comparison of different TCP startup schemes under UDP cross-traffic (10Mbps UDP traffic starts at 1 sec and stops at 5sec)_cwnd_ based on the backlog status, SShreshless Start eliminates the need for the Slow Start threshold, _sstthresh_, and the blind _sstthresh_ setting problem vanishes. The use of backlog status at the bottleneck buffer also allows SShreshless Start to cope with various buffer sizes especially small buffer sizes that cause performance degradation in many TCP startup variants.

Simulation results demonstrated that, compared with traditional Slow Start and many other variants, SShreshless Start significantly improves link utilization during startup phase, meanwhile shows good performances to a wide range of buffer size, propagation delay and bandwidth of bottleneck. Moreover, SShreshless Start shows good convergence behavior without adversely affecting coexisting TCP connections. Therefore, being aware of backlog status, the enhanced throughput during startup phase is achieved by using the bandwidth effectively and fairly rather than aggressively depriving bandwidth from other co-existing TCP connections.

## References

* [1] X. Lu, K. Zhang, C. P. Fu, C. H. Foh, " A Sender-Side TCP Startup Enhancement in High-Speed and Long-Delay Network," in _Proceedings of WCNC_, Sydney, Australia, April 2010.
* [2] V. Jacobson, "Congestion Avoidance and Control," in _Proceedings of ACM SIGCOMM_, Stanford, CA, pp.314-329, August 1988.
* [3] S. Floyd, and T. henderson, "Newreno Modification to TCP's Fast Recovery," _RFC-2582_, April 1999.
* [4] L. S. Brakmo, S. W. O'Malley, et al., "TCP Vegas: New Techniques for Congestion Detection and Avoidance," in _Proceedings of ACM SIGCOMM_, London, U. K., pp.24-35, October 1994.
* [5] A. Feldmann, J. Rexford, and R. Caceres, "Efficient Policies for Carrying Web Traffic over Flow-switched Networks," _IEEE/ACM Transaction on Networking_ vol. 6, pp. 673-685, December 1998.
* [6] H. Shimonishi, M. Y. Sanadidi, and M. Gerla, "Improving Efficiency-Friendliness Tradeoffs of TCP in Wired-Wireless Combined Networks," in _Proceedings of ICC_, May 2005.
* [7] C. E. Palazzi, "Residual Capacity Estimator for TCP on Wired/Wireless Links", in _Proceedings of the WCC2004 Student Forum IFIP World Compute Congress_, Toulouse, France, Aug 2004.

Fig. 10: Co-existence of multiple SShreshless Start and Slow Start connections. (_cwnd_ of two NewReno flows overlap)* [8] B Pancost, CC Chen, MY Sanadidi, and M Gerla, "Buffer Estimate Filtering Using Dispersion Deltas," in _Proceedings of PFLDnet_, 2009.
* [9] K. Kaneko and J. Katto, "Reno Friendly TCP Westwood Based on Router Buffer Estimation," in _Proceeding of the Joint ICAS and ICNS_, 2005.
* [10] S. Floyd, "Limited Slow Start for TCP with Large Congestion Windows," _RFC-3742_, March 2004.
* [11] Lawrence S.Brakmo, and Larry L.Peterson, "TCP Vegas: End to End Congestion Avoidance on a Global Internet," _IEEE (JSAC) Journal of selected Areas in Communications_, VOL.13, NO.8, OCTOBER 1995.
* [12] Haining Wang and Care L. Williamson, "A New TCP Congestion Control Scheme: Smooth-Start and Dynamic Recovery," in _Proceedings of IEEE MASCOTS 98_, Montreal, Canada, July 1998.
* [13] H. Wang, H. Xin, D.S. Reeves, and K.G. Shin, "A Simple Refinement of Slow Start of TCP Congestion Control," in _proceedings of ISCC_, Antibes, France, July 2000.
* [14] D. Leith, R. Shorten, G. McCullagh, J. Heffner, L. Dunn, and F. Baker, "Delay-based AIMD Congestion Control," in _Proceedings of PFLDnet_, February 2007.
* [15] Dirceu Cavendish, Kazumi Kumazoe, Masato Tsuru, Yuji Oie, and Mario Gerla, "CapStart: An Adaptive TCP Slow Start for High Speed Networks," _First International Conference on Evolving Internet_, August 2009.
* [16] Allman, M., Floyd, S., and Partridge, C., "Increasing TCP's Initial Window," _RFC-3390_, October 2002.
* [17] S. Keshav, "A Control-theoretic Approach to Flow Control," in _Proceedings of ACM SIGCOMM_, pp. 3-15., Zurich, Switzerland, September 1991.
* [18] J. C. Hoe, "Improving the Startup Behavior of a Congestion Control Scheme for TCP," in _Proceedings of ACM SIGCOMM_, pp.270-280, October 1996.
* [19] M.Aron and P.Druschel, "TCP: Improving Startup Dynamics by Adaptive Timers and Congestion Control," Technical Report (TR98-318), Department of Computer Science, Rice University, 1998.
* [20] Ren Wang Giowanni Pau, Kenshin Yamada, M.Y.Sanadidi, and Mario Gerla, "TCP Startup Performance in Large Bandwidth Delay Networks," in _Proceedings of IEEE INFOCOM_, April 2004.
* [21] Ren Wang, Kenshin Yamada, M. Yahya Sanadidi, and Mario Gerla, "TCP with Sender-Side Intelligence to Handle Evolution, Large, Leaky Pipes," _IEEE Journal on Selected Areas in Communications_. Vol.23, No.2, February 2005.
* [22] C.Casetti, M.Gerla, S.Mascolo, M.Y.Sanadidi, and R.Wang, "TCP Westwood: Bandwidth Estimation for Enhanced Transport over Wireless Links," in _Proceedings of Mobicom 2001_, Rome, Italy, July 2001.
* [23] S.Giordano, G.Procissi, F.Russo, and Raffaello Secchi, "On the Use of Pipesize Estimators to Improve TCP Transient Behavior", in _Proceedings of the IEEE International Conference on Communications_, Vol.1,pp. 16-20, May 2005.
* [24] C. Partridge, D. Rockwell, M. Allman, R. Krishnan, and J. Sterbenz, "A Swifter Start For TCP," BBN Technical Report, No. 8339, 2002.
* [25] Frances J. Lawas-Grodek and Diepchi T. Tran, "Evaluation of Swift Start TCP in Long-Delay Environment," Glenn Research Center, Cleveland, Ohio, October 2004.
* [26] Ningning Hu and Peter Steenkiste, "Estimating Available Bandwidth Using Packet Pair Probing," CMU-CS-02-166 School of Computer Science Carnegie Mellon University, Pittsburgh, PA, September 2002.
* [27] Ningning Hu and Peter Steenkiste, "Evaluation and Characterization of Available Bandwidth Probing Techniques," _IEEE JSAC Special Issue in Internet and WWW Measurement, Mapping, and Modeling_, August 2003.
* [28] Manish Jain and Constantinos Dovrolis, "End-to-end Available Bandwidth: Measurement Methodology, Dynamics, and Relation with TCP Throughput," in _Proceedings of ACM SIGCOMM_, Pittsburgh, PA, August 2002.

* [29] C. Dovrolis, P. Ramanathan, and D. Moore, "What do Packet Dispersion Techniques Measure?," in _Proceedings of IEEE INFOCOM_, pages 905-914, April 2001.
* [30] C. Dovrolis, P. Ramanathan, and D. Moore, "Packet-dispersion Techniquesand a Capacity-estimation Methodology", _IEEE/ACM Transaction on Networking_, vol. 12, no. 6, pp. 963-977, 2004.
* [31] Sangtae Ha and Injong Rhee, "Hybrid Slow Start for High-bandwidth and Long-distance Networks," in _Proceedings of PFLDnet_, March 2008.
* [32] H. Balakrishnan and S. Seshan, "The Congestion Manager," _RFC-3124_, June 2001.
* [33] J.C. Mogul, "Observing TCP Dynamics in Real Networks," in _Proceedings of ACM SIGCOMM_, pp. 305-317, Baltimore, Maryland, August 1992.
* [34] V. Paxson and M. Allman, "Computing TCP's Retransmission Timer," _RFC-2988_, November 2000.
* [35] J. Mo, V. Anantharam, R.J. La, and J. Walrand, "Analysis and Comparison of TCP Reno and Vegas," in _Proceedings of GLOBECOM_, December 1999.
* [36] Sally Floyd, Mark Allman, Amit Jain, and Pasi Sarolaht, "Quick-Start for TCP and IP," _RFC-4782_, January 2007.
* [37] D. Katabi, M. Handley, and C. Rohrs, "Congestion Control for High Bandwidth-Delay Product Networks," in _Proceedings of ACM SIGCOMM_, August 2002.
* [38] Y. Ariba, F. Gouaisbaut, and Y. Labit, "Feedback control for router management and TCP/IP network stability," _IEEE Transactions On Network and Service Management_, vol. 6, no. 4, December 2009, pp. 255-266.
* [39] A. Aggarwal, S. Savage, and T. Anderson, "Understanding the Performance of TCP Pacing"", in _Proceedings of IEEE INFOCOM_, March 2000.
* [40] Ningning Hu and Peter Steenkiste, "Improving TCP Startup Performance Using Active Measurements: Algorithmand Evaluation," in _Proceedings of IEEE ICNP_, pp. 107-118, November 2003.
* [41] M. Allman, "On the Generation and Use of TCP Acknowledgment," _Computer Communication Review_, Oct 1998.
* [42] M. Allman, D. Glover, and L. Sanchez, "Enhancing TCP Over Satellite Channels Using Standard Mechanisms," _RFC-2488_, January 1999.
* Concepts," _RFC-1379_, November 1992.
* [44] R.T. Braden, "T/TCP TCP Extensions for Transactions Functional Specification," _RFC-1644_, July 1994.
* [45] Yogesh Bhumralkar, Jeng Lung, and Pravin Varaiya, "Network Adaptive TCP Slow Start," 2000. [http://paleale.eecs.berkeley.edu/](http://paleale.eecs.berkeley.edu/) varaiya/comm.html
* [46] Y. Zhang, L. Qiu, and S. Keshav, "Optimization TCP Start-up Performance," Cornell CS Technical Report, February 1999.
* [47] S. Seshan, M. Stemm, and R. H. Katz, "SPAND: Shared Passive Network Performance Discovery," in _Proceedings of USITS 97_, Monterey, CA, December 1997.
* [48] J. Touch, "TCP Control Block Interdependence," _RFC-2140_, April 1997.
* [49] H. Balakrishnan, S. Seshan, M. Stemm, and R.H. Katz, "TCP Behavior of a Busy Internet Server: Analysis and Improvements," in _Proceedings of IEEE INFOCOM 98_, March 1998.
* [50] C. Barakat and E. Altman, "Performance of Short TCP Transfers," _Networking 2000 (Performance of Communication Networks) conference_, May 2000.
* [51] H. Afifi, O. Elloumi, and G. Rubino, "A Dynamic Delayed Acknowledgment Mechanism to Improve TCP Performance for Asymmetric Links," in _Proceedings of ISCC_, Athens, Greece, July 1998.
* [52] L. Zhang, S. Shenker, and D. D. Clark, "Observations on the Dynamics of a Congestion Control Algorithm: The Effects of Two Way Traffic," in _Proceedings of ACM SIGCOMM_, Zurich, Switzerland, pp. 133-148, September 1991.
* [53] L. Zhang, "Why TCP Timers Don't Work Well," in _Proceedings of ACM SIGCOMM_, pp. 397-405, 1986.

* [54] Ioannis Psaras and Vassilis Tsaoussidis, "Why TCP Timers (Still) Don't Work Well," _Computer Networks_, 51(8):2033-2048, 2007.
* [55][http://www.isi.edu/nsnam/ns/](http://www.isi.edu/nsnam/ns/)

Title: A simultaneous solution to the Hubble tension and observed bulk flow
  within 250 ${h^{-1}}$ Mpc
Transcription: # A simultaneous solution to the Hubble tension and observed bulk flow within 250 \(h^{-1}\) Mpc

 Sergij Mazurenko\({}^{1}\), Indranil Banik\({}^{2}\), Pavel Kroupa\({}^{3,4}\) and Moritz Haslbauer\({}^{3}\)

\({}^{1}\)Universitat Bonn, Regina-Pacs-Weg 3, 53115 Bonn, Germany

\({}^{2}\)Scottish Universities Physics Alliance, University of Saint Andrews, North Haugh, Saint Andrews, Fife, KY16 9SS, UK

ib45@st-andrews.ac.uk (Indranil Banik)

\({}^{3}\)Technik-Institut fur Yankhane- und Kernphysik, Universitat Bonn, Nussallee 14-16, 53115 Bonn, Germany

\({}^{4}\)Astronomical Institute, Faculty of Mathematics and Physics, Charles University, V Holesovickach 2, CZ-180 00 Praha 8, Czech Republic

E-mail: sergij.mazurenko@uni-bonn.de (Sergij Mazurenko);ib45@st-andrews.ac.uk (Indranil Banik)

Accepted XXX. Received YYY; in original form ZZZ

###### Abstract

The \(\Lambda\) cold dark matter (\(\Lambda\)CDM) standard cosmological model is in severe tension with several cosmological observations. Foremost is the Hubble tension, which exceeds \(5\sigma\) confidence. Galaxy number counts show the Keenan-Barger-Cowie (KBC) supervoid, a significant underdensity out to 300 Mpc that cannot be reconciled with \(\Lambda\)CDM cosmology. Haslbauer et al. previously showed that a high local Hubble constant arises naturally due to gravitationally driven outflows from the observed KBC supervoid. The main prediction of this model is that peculiar velocities are typically much larger than expected in the \(\Lambda\)CDM framework. This agrees with the recent discovery by Watkins et al. that galaxies in the CosmicFlows-4 catalogue have significantly faster bulk flows than expected in the \(\Lambda\)CDM model on scales of \(100-250\)\(h^{-1}\) Mpc. The rising bulk flow curve is unexpected in standard cosmology, causing \(4.8\sigma\) tension at \(200\)\(h^{-1}\) Mpc. In this work, we determine what the semi-analytic void model of Haslbauer et al. predicts for the bulk flows on these scales. We find qualitative agreement with the observations, especially if our vantage point is chosen to match the observed bulk flow on a scale of \(50\)\(h^{-1}\) Mpc. This represents a highly non-trivial success of a previously published model that was not constrained by bulk flow measurements, but which was shown to solve the Hubble tension and explain the KBC void consistently with the peculiar velocity of the Local Group. Our results suggest that several cosmological tensions can be simultaneously resolved if structure grows more efficiently than in the \(\Lambda\)CDM paradigm on scales of tens to hundreds of Mpc.

keywords: large-scale structure of Universe - cosmology: theory - gravitation - galaxies: kinematics and dynamics - galaxies: statistics - methods: data analysis

## 1 Introduction

The Hubble tension is one of the greatest currently debated unsolved problems in cosmology (Wong et al., 2020; Migkas et al., 2021; Riess et al., 2022; Di Valentino, 2022). It is a statistically significant discrepancy between direct local measurements of the Hubble-Lemaitre constant \(H_{0}\) and the prediction of the Lambda-Cold Dark Matter (\(\Lambda\)CDM; Efstathiou, Sutherland & Maddox, 1990; Ostriker and Steinhardt, 1995) standard model of cosmology with parameters calibrated to fit the angular power spectrum of anisotropies in the cosmic microwave background (CMB). The local Universe appears to be expanding 10% faster than this prediction. While the origin of this tension is not known, if the high local determination of \(H_{0}\) is correct, then the universe would have to be about 10% younger than if the lower CMB-based value is correct. However, the ages of the oldest stars argue against this interpretation (Cimatti and Moresco, 2023). While their upper limit on \(H_{0}\) is consistent with CMB measurements taken by the Planck satellite (Planck Collaboration VI, 2020) and the Atacama Cosmology Telescope (Aiola et al., 2020), it leaves open the issue of why so many local measurements show a faster expansion rate (e.g. figure 1 of Di Valentino, 2021, and references therein). It has recently been argued that the Hubble tension should be solved largely at late times in cosmic history (Jia, Hu and Wang, 2023; Vagnozzi, 2023), with the expansion rate apparently diverging from \(\Lambda\)CDM expectations only rather recently (Gomez-Valent et al., 2023).

Another serious but less widely known problem is the Keenan-Barger-Cowie (KBC) void, an underdensity with a diameter of about a Gpc (Keenan, Barger and Cowie, 2013). Such an extended and deep local underdensity is indicated by several observations at optical (Maddox et al., 1990), infrared (Huang et al., 1997; Busswell et al., 2004; Frith et al., 2003, 2005, 2006; Keenan et al., 2013; Whitbourn and Shanks, 2014; Wong et al., 2022), X-ray (Bohringer et al., 2015, 2020), and radio wavelengths (Rubart and Schwarz, 2013; Rubart, Bacon and Schwarz, 2014). The near-infrared measurements imply that the matter density is only half the cosmic mean value out to a distance of 300 Mpc (see figure 11 of Keenan, Barger and Cowie, 2013 and figure 1 of Kroupa, 2015). Using data from the Millennium XXL simulation (MXXL; Angulo et al., 2012), Haslbauer, Banik and Kroupa (2020, hereafter HBK20) showed that the KBC void is in \(6.04\sigma\) tension with the \(\Lambda\)CDM model despite accounting forredshift space distortions induced by outflow from the void, which implies that the actual density contrast is about half that reported by Keenan, Barger & Cowie (2013). Such a deep and extended void suggests a cosmological model in which structure grows faster than in \(\Lambda\)CDM.

It has been suggested that outflows from a large local void can solve the Hubble tension (Keenan et al., 2016; Shanks et al., 2019; Ding et al., 2020; Camarena et al., 2022; San Martin & Rubio, 2023). This would be a natural solution because a local void creates a hill in the potential, causing galaxies to flow away from the void. From a purely kinematic perspective, the near uniformity of the CMB implies that a substantial underdensity today must be a consequence of outflows. Using this argument, HBK20 estimated that the observed KBC void implies that the locally measured \(H_{0}\) should exceed the true background expansion rate by 11% (see their section 1.1). The Local Group (LG) is situated within the KBC void and is a part of the bulk matter flow. While the Hubble tension can be naturally understood as arising from outflows induced by the KBC void, the problem for \(\Lambda\)CDM is that it is unable to form such a void because on the relevant scale of 300 Mpc, the universe should be almost homogeneous and isotropic. A simultaneous solution to the KBC void and Hubble tension is possible in \(\Lambda\)CDM, but only if we assume a 10\(\sigma\) density fluctuation at early times (see figure 1 of HBK20). Moreover, the observations of Keenan et al. (2013) trace the majority of the galaxy luminosity function, suggesting that the observed underdensity is a genuine underdensity in the total matter distribution (see their figure 9). Allowing for redshift space distortions, HBK20 found that the results of Keenan et al. (2013) imply that the density within 300 Mpc is \(\approx 20\%\) below the cosmic mean evident in galaxy number counts at greater distances. This is very much in line with the findings of Wong et al. (2022).

HBK20 showed that matter inhomogeneities comparable to the KBC void can arise in the neutrino Hot Dark Matter (\(\nu\)HDM) cosmological framework (Angus, 2009; Katz et al., 2013; Wittenburg et al., 2023). The \(\nu\)HDM model assumes Milgromian dynamics (MOND; Milgrom, 1983, 2014). MOND postulates that the gravitational acceleration \(g\) in an isolated spherically symmetric system is asymptotically related to the Newtonian gravitational acceleration \(g_{{}_{N}}\) of the baryons alone according to

\[g\rightarrow\begin{cases}g_{{}_{N}}\,,&\text{if }g_{{}_{N}}\gg a_{{}_{0}}\,,\\ \sqrt{a_{{}_{0}}g_{{}_{N}}}\,,&\text{if }g_{{}_{N}}\ll a_{{}_{0}}\,.\end{cases} \tag{1}\]

The key new ingredient is a fundamental acceleration scale \(a_{{}_{0}}=1.2\times 10^{-10}\) m s\({}^{-2}\). This value must be deduced empirically, just like the gravitational constant \(G\) in standard gravity. Different studies over the decades have returned very similar values for \(a_{{}_{0}}\)(Begeman, Broeils & Sanders, 1991; Gentile, Famaey & de Blok, 2011; McGaugh, Lelli & Schombert, 2016). The MOND gravitational field follows from a Lagrangian, ensuring the usual symmetries and conservation laws with respect to the linear and angular momentum and the energy (Bekenstein & Milgrom, 1984; Milgrom, 2010). The least action principle then leads to a generalized Poisson equation that is non-linear in the mass distribution.

MOND has been highly successful on galaxy scales (Famaey & McGaugh, 2012; McGaugh, 2020; Banik & Zhao, 2022). \(\nu\)HDM extends its application to cosmology by postulating an extra species of sterile neutrino with a rest energy of 11 eV, which is crucial to matching the high velocity dispersions of virialized galaxy clusters, the offset between the weak lensing and X-ray peaks in the Bullet Cluster, and the high third peak in the angular power spectrum of the CMB (for a review, see section 9.2 of Banik & Zhao, 2022). The background cosmology in \(\nu\)HDM is the same as in \(\Lambda\)CDM (Skordis & Zlosnik, 2019), though the extra neutrino species implies a mild departure from standard Big Bang nucleosynthesis (see section 3.1.2 of HBK20). Moreover, both models behave similarly at early times because when the redshift \(z\gtrsim 50\), the typical accelerations are high and thus standard gravity applies. At lower redshifts, significant differences arise in the large-scale structure due to the lack of CDM and the MOND corrections to the gravitational field (Angus & Diaferio, 2011; Angus et al., 2013; Katz et al., 2013; Wittenburg et al., 2023).

Using a semi-analytic model in the \(\nu\)HDM framework, HBK20 evolved three initial void density profiles (Maxwell-Boltzmann, Gaussian, and Exponential) for a large grid of initial void sizes and strengths at \(z=9\). The initial conditions were constrained by observations of the local Universe (\(z=0.01-0.15\)) and the requirement for the density to almost recover the cosmic mean value at distances of \(600-800\) Mpc (see figure 11 and table 1 of Keenan, Barger & Cowie, 2013). Any local void solution to the Hubble tension implies quite large peculiar (CMB-frame) velocities, so an important constraint on such models is the observed peculiar velocity of the LG (\(\nu_{\rm LG}=627\pm 22\) km s\({}^{-1}\); Kogut et al., 1993). While peculiar velocities are typically larger in \(\nu\)HDM (Katz et al., 2013; Wittenburg et al., 2023), such a low value arises for a reasonable fraction of observers because gravitational fields from nearby and more distant structures can sometimes partially cancel. However, if we consider a larger region of the universe, the significant Milgromian enhancement to gravity implies much more substantial bulk flows of galaxies on scales of hundreds of Mpc. If this model is to be viable, such rapid bulk flows need to be verified observationally.

We test the local void solution to the Hubble tension proposed in HBK20 by extracting the predicted bulk flow from the exact same model without any adjustments in order to compare its _a priori_ bulk flow predictions with recently published measurements. Using the CosmicFlows-4 galaxy catalogue (Tully et al., 2023), Watkins et al. (2023) present the bulk flow of galaxies on scales of \(100-250\)\(h^{-1}\) Mpc, where \(h\approx 0.7\) is the Hubble constant in units of 100 km s\({}^{-1}\) Mpc\({}^{-1}\), velocities are reported in the CMB frame, and the bulk flow involves a vector average of line of sight peculiar velocities out to some distance (Section 2.3). Bulk flows are expected to decrease with scale, but the observed bulk flow curve has the opposite behaviour and rises to \(>400\) km s\({}^{-1}\) beyond 160 \(h^{-1}\) Mpc. At a scale of \(200\)\(h^{-1}\) Mpc, it is in \(4.81\sigma\) tension with the \(\Lambda\)CDM model (\(P=1.49\times 10^{-6}\)).1 An independent study recently reported "excellent agreement with the bulk flow measurements of Watkins et al. (2023)" using the same dataset and also found significant tension with \(\Lambda\)CDM at an effective depth of \(173\)\(h^{-1}\) Mpc, though the more conservative methodology prevented the authors from going further out (Whitford, Howlett & Davis, 2023). This issue is observationally unrelated to the Hubble tension because adopting a different \(H_{0}\) would affect the peculiar velocities in a spherically symmetric manner, thus not affecting the inferred bulk flow curve shown in figure 7 of Watkins et al. (2023). In Section 3, we compare the results in the bottom right panel of this figure with the bulk flow predicted by the \(\nu\)HDM model for different void density profiles and possible vantage points that were previously shown to provide the best overall match to several other cosmological observables(mainly the KBC void density profile and the high local \(H_{0}\); see HBK20).

It is important to note that the bulk flow measurements of Watkins et al. (2023) were not available to HBK20. While earlier bulk flow measurements were available, these were not used - the \(v\)HDM model and the parameters of a local void in this model were in no way constrained to fit the observed bulk flow on scales of several hundred Mpc. The primary objective of this study is to use the bulk flow measurements of Watkins et al. (2023) to test the _a priori_ predictions of the HBK20 'Hubble bubble' model on the same scales. This will help to assess whether the Hubble and bulk flow tensions faced by the \(\Lambda\)CDM model might have a common Milgromian solution. More generally, our results will help to clarify whether the velocity field in a local supervoid solution to the Hubble tension might also match the observed bulk flow on scales of up to \(250~{}h^{-1}\) Mpc.

The structure of this paper is as follows: In Section 2, we describe how we obtain the predicted bulk flows in the same manner as the reported observations. We then present our results in Section 3 and conclude in Section 4.

## 2 Methods

The starting point for our analysis is the peculiar velocity field of the semi-analytic void model of HBK20, which is shown in their figure 8 for the Maxwell-Boltzmann void density profile (velocity fields of the relevant models are shown in our Appendix A). This is a combination of a spherically symmetric outflow from the void centre with a systemic motion of the whole void towards the left, which reduces the spherical symmetry to axisymmetry. We refer to the peculiar velocity in the CMB frame as the total velocity \(\mathbf{v}_{\rm tot}\) (analogous to equation 72 of HBK20). This is well suited for a comparison with observations because in studies of the bulk flow on large scales, heliocentric redshifts are typically corrected for the precisely known velocity of the Sun in the frame of the CMB.2

Footnote 2: R. Watkins, private communication.

### Possible locations for the Local Group

The position of the LG in this framework can be deduced by finding points which move with a velocity of \(v_{\rm tot}=v_{\rm LG}=627\pm 22~{}{\rm km~{}s^{-1}}\)(Kogut et al., 1993), where we use the notation that \(v\equiv|\mathbf{v}|\) for any vector \(\mathbf{v}\). Figure 8 of HBK20 shows the locus of such points with a solid black curve. Those authors suggested that the LG is towards the right hand side of this curve, which is located further away from the void centre. However, their study lacked any reliable way to precisely determine where the LG ought to be.

We simplify our analysis by only considering two possible LG locations, which we call the inner and outer vantage point (relative to the void centre). These bracket the range of possible LG distances from the void centre. Importantly, both vantage points place the LG on the symmetry axis of the problem, allowing us to work with an axisymmetric code. We consider both vantage points separately for all three considered void (under)density profiles (Maxwell-Boltzmann, Gaussian, and Exponential). We also consider uncertainties in the model predictions for each of these six cases due to the uncertainty in \(v_{\rm LG}\), which can slightly vary the location of the LG by a few Mpc (see Appendix A). This is however less significant than observational uncertainties in the bulk flow.

In Table 1, we show the possible locations of the LG for all three void density profiles. In all cases, the inner vantage point lies within 200 Mpc of the void centre. The outer vantage point is generally much more distant. Only the Maxwell-Boltzmann profile gives an outer vantage point reasonably close to the void centre, at a distance of \(d_{\rm MB,\,r}=262.27\) Mpc.

### Observed peculiar velocity

We describe the problem using Cartesian coordinates centred on the observer. Only two axes are needed because the problem is axisymmetric. The \(x\)-axis corresponds to the symmetry axis of the problem, while the \(y\)-axis lies in the orthogonal direction. The distance of any point from the observer is thus \(r=\sqrt{x^{2}+y^{2}}\).

Observations of distant galaxies can only tell us their peculiar velocity along the line of sight. Applying this consideration, the observable component of the peculiar velocity at point \(i\) is

\[v_{\rm obs,i} = \left(\frac{xv_{x}+yv_{y}}{r}\right)_{i}\, \tag{2}\]

where \(v_{\rm tot}\equiv(v_{x},v_{y})\) is the velocity in the CMB frame. This is found by adding the velocity relative to the void centre with the systemic velocity of the void as a whole, which is towards \(-x\). The systemic void velocity is given in tables 4 and C1 of HBK20 and is not adjustable in our analysis.

### Bulk flow velocity

While the line of sight peculiar velocity of point \(i\) is typically thought of as a scalar quantity, it will help to think of it as a vector \(\mathbf{v}_{\rm obs,i}\) pointing from the observer towards point \(i\). The bulk flow velocity in the CMB frame is the weighted average of these line of sight peculiar velocity vectors within a spherical volume of radius \(r_{\rm bulk}\) centred on the observer. This definition matches equation 26 of Watkins et al. (2023).

Due to the simulated velocity field being axisymmetric with respect to the \(x\)-axis and the observer also lying on this axis, the bulk flow must be along it. We therefore consider only the \(x\)-component of \(\mathbf{v}_{\rm obs,i}\), which is given by

\[v_{\rm obs,x,i} = v_{\rm obs,i}\left(\frac{x}{r}\right)_{i}. \tag{3}\]

Calculating the bulk flow velocity is then just a matter of taking a suitably weighted average of this quantity, which we discuss below.

Each point has a weight \(w_{i}\propto V_{i}/r^{2}\), where \(V_{i}\) is the volume covered by cell \(i\). The factor of \(1/r^{2}\) is necessary because we are

Tuple 39:
Cleaned Title: accurate halo mass function simplest excursion set theory
Cleaned Transcription: accurate halo mass function simplest excursion set theory sten delosthe observatory carnegie institution science santa barbara street pasadena ca usa max planck institute astrophysics karlschwarzschildstr garching germany email mdeloscarnegiescienceedu accepted xxx received yyy original form zzz abstract excursion set theory powerful widely used tool describing distribution dark matter halo normally applied simplifying approximation use numerical sampling method study mass function predicted theory without approximation spherical tophat window constant delta threshold theory accurately predicts mass function mass definition unconditional conditional simulation range matterdominated cosmology lambdacdm present epoch prediction lie mrm mrm c mass function contrast window function nonconstant threshold based ellipsoidal collapse predicts uniformly halo work indicates new way simply accurately evaluate halo mass function clustering bias assembly history range cosmology provide simple fitting function accurately represents prediction theory wide range parameter keywords method statistical galaxy halo cosmology theory dark matter largescale structure universe introduction theory excursion set powerful tool understanding dark matter halo distribution connects cosmological initial condition originally used predict halo mass function bond et al excursion set also employed study aspect halo distribution merger rate lacey cole spatial clustering mo white review see zentner basic idea excursion set approach particle density environment initial condition directly predicts halo membership later time density contrast field deltamathbfxleftrhomathbfxbarrhorightbarrho averaged mass scale exceeds present threshold deltarm c particle initially mathbfx part halo least mass preset later time mass satisfying condition comprise excursion set associated threshold deltarm cadler mass particle host halo taken largest mass excursion set footnote also known extended pressschechter theory particular consider density contrast field deltammathbfxt extrapolated time using linearorder cosmological perturbation theory averaged mass scale fixed position mathbfx time deltam regarded executing random walk decreasing starting deltainfty particle host mass deltam first cross threshold deltarm c make calculation firstcrossing distribution analytically tractable random walk ordinarily approximated markovian ie step uncorrelated step threshold deltarm c taken spherical collapse threshold deltarm c lead halo mass function press schechter approximation firstcrossing distribution correlated step also studied peacock heaven maggiore riotto paranjape et al musso sheth farahi benson musso sheth nikakhtar et al common refinement approach employ nonconstant threshold deltarm c motivated bond myers model ellipsoidal collapse sheth et al considered threshold depends threedimensional shape tidal deformation tensor tijpartialipartialjphi phi solution nablaphidelta ellipsoidal collapse delayed tidal force threshold deltarm c becomes higher tij significantly aspherical random walk six independent component tijmathbfm chiueh lee sheth tormen sandvik et al tested firstcrossing distribution result therefrom simplify problem however sheth et al exploited typical asphericity tijmathbfm depends approximate massdependent moving threshold deltarm cm since smaller associated ellipsoidal tide deltarm c taken decreasing function compared constant threshold halo mass function resulting moving threshold sheth et al yield better match result numerical simulation assuming uncorrelated step refinement ellipsoidal collapse threshold also explored angrick bartelmann ludlow et al borzyszkowski et al work relax approximation considering full dimensional tijmathbfm accounting fully correlation step several choice averaging window function use direct numerical sampling done quite efficiently eg nikakhtar et al generate halo mass function range cosmology compare mass function standard analytical prediction simulation result specifically consider scalefree concordance lambdacdm cosmological simulation diemer kravtsov test unconditional conditional mass function find standard choice window function spherical tophat real space ellipsoidal collapse threshold predicts halo every mass contrast constant deltarm c threshold yield halo mass function closely match scalefree simulation mass definition predicted conditional mass function related halo clustering bias assembly history also generally accurate lambdacdm threshold yield prediction lie mrm mrm c mass function common choice window function match simulation result closely either constant ellipsoidalcollapsemotivated threshold mass function predicted excursion set theory tophat window constant threshold nearly independent linear power spectrum considered function rms density variance sigma exhibit significant variation extreme spectral index feature power spectrum article organized follows section describes approach numerically sampling trajectory deltam tijm sec use sampled trajectory generate halo mass function compare outcome different threshold window function sec compare excursion set mass function derived cosmological simulation considering unconditional conditional mass function sec explore degree excursion set mass function adhere universal form expressed term sigma provide fitting function present conclusion sec appendix test well mass function calculate numerically converged appendix b detail extent predicted conditional mass function stick universal form numerical sampling excursion section describes numerically sample trajectory delta tij function averaging scale spherical collapse simplicity begin restricting consideration density contrast deltamathbfx function comoving position mathbfx let deltamathbfkintmathrmdmathbfxmathrmemathrmimathbfkcdot mathbfxdeltamathbfx fourier transform density contrast averaged radius r window function w given convolution deltarmathbfxintfracmathrmdmathbfkpimathrme mathrmimathbfkcdotmathbfxdeltamathbfkwkr tag whence follows definition power spectrum pk leftlangledeltarmathbfxdeltarprimemathbfx rightrangle intfracmathrmdmathbfkpipkwkrwkr prime tag intinftyfracmathrmdkkmathcalpkwkrwkr prime tag mathcalpkequivkpipk dimensionless power spectrum general wx function ranging xll xgg discretize windowing radius r sequence rrrn langledeltarnmathbfxdeltarnmathbfxrangle ntimes n covariance matrix vector deltarnequivdeltaa discretization trajectory delta random vector deltaa distributed according nvariate gaussian distribution mean covariance langledeltaadeltabrangle given accordance eq many way sample random deltaa distribution eg nikakhtar et al follow delos et al diagonalizing langledeltaadeltabranglesumcnaaclambdacabc tag orthogonal matrix lambdaa eigenvalue langledeltadeltarangle randomly sampled trajectory given deltaasumbnaabwb tag wb sampled univariate gaussian distribution mean variance lambdab upper panel fig show example density trajectory sampled three choice spherical window function wx tophat window function wxxsin xxcos x cut sharply real space gaussian window function wxmathrmex smooth real fourier space sharp kspace window function wx x otherwise express trajectory term windowing mass scale mpropto r consider two power spectrum pkpropto kn n left n right windowing mass scale expressed mass scale associated windowing radius r sigmar sigmarintinftyfracmathrmdkkmathcalpkwkr tag variance deltarmathbfx density field averaged radius r note depends window function result expressed unit normalization power spectrum pk irrelevant normalization windowing mass scale also irrelevant figure show example trajectory delta illustrating typical behaviour different window function sharp kspace window step delta varied uncorrelated lead extremely noisy trajectory contrast realspace tophat window blue lead much le noisy trajectory gaussian window orange smooth interesting note impact gaussian windowing intermediate tophat sharpk window despite mathematical sense gaussian window intermediate two ellipsoidal collapse extend treatment consider trajectory tidal tensor tij term fouriertransformed density contrast tij explicit expression tijmathbfxintfracmathrmdmathbfkpimathrmemathrm imathbfkcdotmathbfxdeltamathbfkfrackikjk tag since symmetric time matrix six independent component three taken eigenvalue lambdageqlambdageqlambda describe strength tidal deformation along principal ax remaining three degree freedom orient ax note deltalambdalambdalambda following standard terminology ellipsoidal collapse eg bond myers define ellipticity eequivlambdalambdadelta prolateness pequivlambdalambdalambdadelta thus delta e p parametrize eigenvalue tidal tensor averaged radius r window function w straightforwardly trijmathbfxintfracmathrmdmathbfkpi mathrmeimathbfkcdotmathbfxdeltamathbfkfrackikjkwkr tag follows leftlangle trijmathbfxtrprimeklmathbfxrightrangle intfracmathrmdmathbfkpipkfrackikjk kklkwkrwkrprime tag fracdeltaijdeltakldeltaikdeltajldeltail deltajkleftdeltarmathbfxdeltarprimemathbfxright tag deltaij kronecker delta equal ij otherwise equation result carrying angular integral eq discretize windowing radius rrrn langle traijmathbfxtrbklmathbfxrangle ntimes n covariance matrix since independent component diagonalizing covariance matrix sample random trajectory deltaavarepsilonapa using method sec trajectory fig generated using approach lower panel show ellipticity e prolateness p function averaging mass scale conditional trajectory also occasion sample trajectory deltar conditioned taking particular value deltarbardelta windowed chosen scale barr given discretization scheme rrn conditional distribution deltaaequivdeltara gaussian mean langledeltaaranglebigdeltarbardelta fraclangledeltaradeltabarrranglesigmabarrdelta tag covariance langledeltadeltaadeltadeltabranglebigdeltarbar deltalangledeltaadeltabranglefraclangledeltara deltabarrranglelangledeltarbdeltabarrrangle sigmabarr tag see eq deltadeltaaequivdeltaalangledeltaarangledeltar bardelta result follow classic theorem conditional gaussian distribution eg appendix bardeen et al similarly sec diagonalize langledeltadeltaadeltadeltabranglebigdeltarbar deltasumcnaaclambdacabc tag figure example trajectory tidal tensor tij function averaging mass scale fixed position time decompose tij density contrast delta upper panel ellipticity e middle panel prolateness p lower panel expressed unit e consider single trajectory three averaging window function different colour two different scalefree power spectrum lefthand versus righthand panel mass expressed unit mass scale rms variance delta sigma upper axis unity delta plot e p trajectory sharp kspace window green extremely noisy reflects lack correlation step deltaa n varied tophat blue gaussian orange window trajectory much smoother circle mark first crossing spherical collapse threshold deltac trajectory square mark first crossing ellipticity prolatenessdependent ellipsoidal collapse threshold deltacfmathrmccep orthogonal matrix lambdaa eigenvalue leftlangledeltadeltadeltadeltarightrangledeltasdelta random trajectory given deltaaleftlangledeltaarightranglebigdeltasdelta sumbnaabwb tag wb sampled gaussian distribution mean variance lambdab mass function excursion set theory excursion set approach particle deemed belong halo mass largest mass scale linearly evolved density contrast delta averaged around particle location exceeds threshold deltarm c halo mass location first crossing threshold trajectory delta viewed random walk decreasing averaging scale circle upper panel fig mark first crossing spherical collapse threshold deltarm c adopted also consider ellipsoidal collapse threshold deltarm cfrm ccep frm cc solution frm cclefteppfrm ccright tag approximated sheth et al note frm ccgeq square fig mark trajectory first crossing ellipsoidal collapse threshold respect horizontal axis circle square indicate mass particle host halo determined spherical ellipsoidal collapse respectively discretize window radius rrrn sigmarn see eq choice ensures probability negligible trajectory would already exceed collapse threshold deltarm c maximum radius rn important case first crossing would missed consider power spectrum pkpropto kn n n n n lower limit r discretization taken sigmar range first case last sample onedimensional trajectory delta alone use n logarithmically spaced averaging radius sample sixdimensional trajectory tij reduce number n spacing successive windowing mass scale mpropto r listed table power spectrum footnote discus later appendix impact choice n using numpy matrix operation harris et al author personal computer sample trajectory delta per second n trajectory tij per second n including decomposition deltaeandp see also nikakhtar et al potentially faster approach power spectrum sample trajectory delta alone trajectory tij trajectory find largest windowing scale delta exceeds threshold spherical ellipsoidal collapse attempt interpolate precise scale crossing occurred first crossing set mass halo hosting particle associated trajectory question since sampling trajectory associated arbitrary point initial density field sample arbitrary dark matter particle therefore distribution firstcrossing mass precisely differential fraction rm dfrm dm mass resides halo mass generally present halo mass function rm dfrm dlog differential mass fraction per logarithmic interval halo mass note commonly discussed differential halo number density related fracrm dnrm dlog mfractildepmfracrm dfrm log tag great convenience considering scalefree cosmology pkpropto kn change time equivalent change mass scale mean improve statistical precision calculation particularly largemass end stacking distribution firstcrossing mass evaluated different time assume scaleindependent growth valid dark matterdominated universe adopt growth factor ranging sigmarnsigmar separated factor sigmarsim sigmarn rms variance minimum maximum window scale respectively described thus smallest earliest time halo expected within resolution limit implied choice window scale uniformly scaling previously sampled trajectory delta growth factor equivalently scaling threshold obtain firstcrossing mass distribution time growth factor characteristic mass scale md earlier time defined mass associated window radius r dsigmar see eq unit md underlying firstcrossing mass distribution different must exactly count firstcrossing mass mmd logarithmic bin width deltalog mass bin stack count growth factor bin lie fully lower upper mass limit mmd mnmd mi mass associated window radius ri since md grows distribution lower earlier time tend improve count firstcrossing mass high mmd one disadvantage procedure uncertainty count mass bin estimated straightforwardly count contributed different correlated therefore attempt estimate uncertainty rm dfrm dlog solid curve fig show rm dfrm dlog result calculation spherical collapse blue ellipsoidal collapse orange threshold consider three different window function w different column two power spectrum pkpropto kn n n different row comparison also show dashed line standard analytic prediction leftfracrm dfrm dlog mrightrm scsqrtfracpifrac deltarm csigmamexpleftfracdeltarm csigmam rightleftfracrm dlogsigmamrm dlog mright tag press schechter bond et al spherical collapse
Original Title: Accurate halo mass functions from the simplest excursion set theory
Original Transcription: # Accurate halo mass functions from the simplest excursion set theory

 M. Sten DelosThe Observatories of the Carnegie Institution for Science, 813 Santa Barbara Street, Pasadena, CA 91101, USA Max Planck Institute for Astrophysics, Karl-Schwarzschild-Str. 1, 85748 Garching, Germany

E-mail: mdelos@carnegiescience.edu

Accepted XXX. Received YYY; in original form ZZZ

###### Abstract

Excursion set theory is a powerful and widely used tool for describing the distribution of dark matter haloes, but it is normally applied with simplifying approximations. We use numerical sampling methods to study the mass functions predicted by the theory without approximations. With a spherical top-hat window and a constant \(\delta=1.5\) threshold, the theory accurately predicts mass functions with the \(M_{200}\) mass definition, both unconditional and conditional, in simulations of a range of matter-dominated cosmologies. For \(\Lambda\)CDM at the present epoch, predictions lie between the \(M_{200\rm m}\) and \(M_{200\rm c}\) mass functions. In contrast, with the same window function, a nonconstant threshold based on ellipsoidal collapse predicts uniformly too few haloes. This work indicates a new way to simply and accurately evaluate halo mass functions, clustering bias, and assembly histories for a range of cosmologies. We provide a simple fitting function that accurately represents the predictions of the theory for a wide range of parameters.

keywords: methods: statistical - galaxies: haloes - cosmology: theory - dark matter - large-scale structure of Universe

## 1 Introduction

The theory of excursion sets1 is a powerful tool for understanding dark matter haloes and how their distribution connects to the cosmological initial conditions. Originally used to predict halo mass functions (Bond et al., 1991), excursion sets are also employed to study other aspects of the halo distribution, such as their merger rates (Lacey and Cole, 1993) and spatial clustering (Mo and White, 1996) (for a review, see Zentner, 2007). The basic idea of the excursion set approach is that a particle's density environment in the initial conditions directly predicts its halo membership at later times. If the density contrast field \(\delta(\mathbf{x})=\left[\rho(\mathbf{x})-\bar{\rho}\right]/\bar{\rho}\) averaged on the mass scale \(M\) exceeds a present threshold \(\delta_{\rm c}\), then the particle initially at \(\mathbf{x}\) is part of a halo of at least mass \(M\) at a preset later time. The masses \(M\) satisfying this condition comprise the _excursion set_ associated with the threshold \(\delta_{\rm c}\)(Adler, 2000). The mass of the particle's host halo is taken to be the largest mass in the excursion set.

Footnote 1: Also known as extended Press-Schechter theory.

In particular, consider the density contrast field \(\delta^{(M)}(\mathbf{x},t)\) extrapolated to the time \(t\) using linear-order cosmological perturbation theory and averaged on the mass scale \(M\). At fixed position \(\mathbf{x}\) and time \(t\), \(\delta^{(M)}\) can be regarded as executing a random walk in decreasing \(M\), starting from \(\delta^{(\infty)}=0\). Then the particle's host mass is the \(M\) for which \(\delta^{(M)}\) first crosses the threshold \(\delta_{\rm c}\). To make calculations of the first-crossing distribution analytically tractable, the random walk is ordinarily approximated to be Markovian, i.e., each step is uncorrelated with other steps. If the threshold \(\delta_{\rm c}\) is taken to be the spherical collapse threshold, \(\delta_{\rm c}=1.686\), this leads to the halo mass function of Press and Schechter (1974). Approximations to the first-crossing distribution with correlated steps have also been studied (Peacock and Heavens, 1990; Maggiore and Riotto, 2010; Paranjape et al., 2012; Musso and Sheth, 2012; Farahi and Benson, 2013; Musso and Sheth, 2014; Nikakhtar et al., 2018).

A common refinement of this approach is to employ a non-constant threshold \(\delta_{\rm c}\). Motivated by the Bond and Myers (1996) model of ellipsoidal collapse, Sheth et al. (2001) considered a threshold that depends on the three-dimensional shape of the tidal deformation tensor \(T_{ij}=-\partial_{i}\partial_{j}\phi\), where \(\phi\) is a solution to \(\nabla^{2}\phi=-\delta\). Ellipsoidal collapse is delayed by tidal forces, so the threshold \(\delta_{\rm c}\) becomes higher if \(T_{ij}\) is significantly aspherical. The random walk is now in the six independent components of \(T_{ij}^{(\mathbf{M})}\), and Chiueh and Lee (2001), Sheth and Tormen (2002), and Sandvik et al. (2007) tested the first-crossing distributions that result therefrom. To simplify the problem, however, Sheth et al. (2001) exploited how the typical asphericity of \(T_{ij}^{(\mathbf{M})}\) depends on \(M\) to approximate a mass-dependent "moving" threshold, \(\delta_{\rm c}(M)\). Since smaller \(M\) is associated with more ellipsoidal tides, \(\delta_{\rm c}\) is taken to be a decreasing function of \(M\). Compared to a constant threshold, halo mass functions resulting from the moving threshold of Sheth et al. (2001) yield a better match to the results of numerical simulations, assuming uncorrelated steps. Further refinements to the ellipsoidal collapse threshold have also been explored (Angrick and Bartelmann, 2010; Ludlow et al., 2014; Borzyszkowski et al., 2014).

In this work, we relax these approximations by considering the full 6-dimensional \(T_{ij}^{(\mathbf{M})}\) and accounting fully for correlations between steps, under several choices of averaging window function. We use direct numerical sampling, which can be done quite efficiently (e.g. Nikakhtar et al., 2018), to generate halo mass functions for a range of cosmologies. We compare these mass functions both to the standard analytical predictions and to simulation results. Specifically, we consider both the scale-free and the concordance \(\Lambda\)CDM cosmological simulations of Diemer and Kravtsov (2015). We test both unconditional and conditional mass functions.

We find that for the standard choice of window function - the spherical top-hat in real space - the ellipsoidal collapse threshold predicts too few haloes of every mass. In contrast, a constant \(\delta_{\rm c}=1.5\) threshold yields halo mass functions that closely match those of the scale-free simulations with the \(M_{200}\) mass definition. The predicted conditional mass functions related to halo clustering bias and assembly history are also generally accurate. For \(\Lambda\)CDM, the same threshold yields predictions that lie between \(M_{200\rm m}\) and \(M_{200\rm c}\) mass functions. Other common choices of window function cannot match the simulation results as closely with either constant or ellipsoidal-collapse-motivated thresholds. Mass functions predicted by excursion set theory with the top-hat window and a constant threshold are nearly independent of the linear power spectrum, when they are considered as a function of the rms density variance \(\sigma\), but they can exhibit significant variations for extreme spectral indices or when there are features in the power spectrum.

This article is organized as follows. Section 2 describes our approach for numerically sampling the trajectories \(\delta^{(M)}\) and \(T_{ij}^{(M)}\). In Sec. 3, we use those sampled trajectories to generate halo mass functions, and we compare the outcomes for different thresholds and window functions. In Sec. 4, we compare the excursion set mass functions to those derived from cosmological simulations, considering both unconditional and conditional mass functions. In Sec. 5, we explore the degree to which excursion set mass functions adhere to a universal form when they are expressed in terms of \(\sigma\), and we provide a fitting function. We present conclusions in Sec. 6. Appendix A tests how well the mass functions that we calculate are numerically converged, while Appendix B details the extent to which the predicted conditional mass functions stick to the same universal form.

## 2 Numerical sampling of excursions

This section describes how we numerically sample the trajectories of \(\delta\) or \(T_{ij}\) as a function of the averaging scale.

### Spherical collapse

For simplicity, we begin by restricting our consideration to the density contrast \(\delta(\mathbf{x})\), which is a function of comoving position \(\mathbf{x}\). Let \(\delta(\mathbf{k})=\int\mathrm{d}^{3}\mathbf{x}\,\mathrm{e}^{-\mathrm{i}\mathbf{k}\cdot \mathbf{x}}\delta(\mathbf{x})\) be its Fourier transform. The density contrast averaged on radius \(r\) with the window function \(W\) is given by the convolution

\[\delta^{(r)}(\mathbf{x})=\int\frac{\mathrm{d}^{3}\mathbf{k}}{(2\pi)^{3}}\mathrm{e}^{ \mathrm{i}\mathbf{k}\cdot\mathbf{x}}\delta(\mathbf{k})W(kr), \tag{1}\]

whence it follows from the definition of the power spectrum \(P(k)\) that

\[\left\langle\delta^{(r)}(\mathbf{x})\delta^{(r^{\prime})}(\mathbf{x}) \right\rangle =\int\frac{\mathrm{d}^{3}\mathbf{k}}{(2\pi)^{3}}P(k)W(kr)W(kr^{ \prime}) \tag{2}\] \[=\int_{0}^{\infty}\frac{\mathrm{d}k}{k}\mathcal{P}(k)W(kr)W(kr^{ \prime}). \tag{3}\]

Here \(\mathcal{P}(k)\equiv[k^{3}/(2\pi^{2})]P(k)\) is the dimensionless power spectrum. In general, \(W(x)\) is a function ranging from 1 for \(x\ll 1\) to 0 for \(x\gg 1\).

If we discretize the windowing radii \(r\) into a sequence \(r_{1}<r_{2}<...<r_{N}\), then \(\langle\delta^{(r_{n})}(\mathbf{x})\delta^{(r_{n})}(\mathbf{x})\rangle\) is the \(N\times N\) covariance matrix of the vector of \(\delta^{(r_{n})}\equiv\delta_{a}\). Under this discretization, a trajectory in \(\delta\) is just a random vector \(\delta_{a}\) distributed according to a \(N\)-variate Gaussian distribution with mean 0 and covariance \(\langle\delta_{a}\delta_{b}\rangle\) given in accordance with Eq. (3). There are many ways to sample random \(\delta_{a}\) from such a distribution (e.g. Nikakhtar et al., 2018); we follow Delos et al. (2019) in diagonalizing

\[\langle\delta_{a}\delta_{b}\rangle=\sum_{c=1}^{N}A_{ac}\lambda_{c}A_{bc}, \tag{4}\]

where \(A\) is an orthogonal matrix and \(\lambda_{a}\) are the eigenvalues of \(\langle\delta\delta\rangle\). A randomly sampled trajectory is then given by

\[\delta_{a}=\sum_{b=1}^{N}A_{ab}w_{b}, \tag{5}\]

where each \(w_{b}\) is sampled from the univariate Gaussian distribution of mean 0 and variance \(\lambda_{b}\).

The upper panels of Fig. 1 show examples of density trajectories sampled for three choices of spherical window function \(W(x)\):

1. the top-hat window function, \(W(x)=(3/x^{3})(\sin x-x\cos x)\), which cuts off sharply in real space;
2. the Gaussian window function, \(W(x)=\mathrm{e}^{-x^{2}/2}\), which is smooth in both real and Fourier space; and
3. the sharp \(k\)-space window function, \(W(x)=1\) if \(x<1\) and 0 otherwise.

We express these trajectories in terms of the windowing mass scale \(M\propto r^{3}\). We consider two power spectra: \(P(k)\propto k^{n}\) with \(n=-1\) (left) and \(n=-2.5\) (right). The windowing mass scales are expressed in this of \(M_{*}\), the mass scale associated with the windowing radius \(r_{*}\) such that \(\sigma(r_{*})=1\). Here

\[\sigma^{2}(r)=\int_{0}^{\infty}\frac{\mathrm{d}k}{k}\mathcal{P}(k)W^{2}(kr) \tag{6}\]

is the variance of \(\delta^{(r)}(\mathbf{x})\), the density field averaged on the radius \(r\). Note that \(M_{*}\) depends on the window function. When results are expressed in these units, the normalization of the power spectrum \(P(k)\) is irrelevant, and the normalization of the windowing mass scale \(M\) is also irrelevant.

Figure 1 shows example trajectories in \(\delta\), illustrating typical behaviour with the different window functions. For the sharp \(k\)-space window, steps in \(\delta\) as \(M\) is varied are uncorrelated, which leads to an extremely noisy trajectory. In contrast, the (real-space) top-hat window (blue) leads to much less noisy trajectories, and those with the Gaussian window (orange) are smooth. It is interesting to note how the impact of Gaussian windowing is not intermediate between top-hat and sharp-\(k\) windows, despite the mathematical sense in which the Gaussian window is intermediate between the other two.

### Ellipsoidal collapse

We now extend the above treatment to consider trajectories in the tidal tensor \(T_{ij}\). In terms of the Fourier-transformed density contrast, \(T_{ij}\) has the explicit expression

\[T_{ij}(\mathbf{x})=\int\frac{\mathrm{d}^{3}\mathbf{k}}{(2\pi)^{3}}\mathrm{e}^{\mathrm{ i}\mathbf{k}\cdot\mathbf{x}}\delta(\mathbf{k})\frac{k_{i}k_{j}}{k^{2}}. \tag{7}\]

Since it is a symmetric \(3\times 3\) matrix, it has six independent components. Three of them can be taken to be the eigenvalues \(\lambda_{1}\geq\lambda_{2}\geq\lambda_{3}\), which describe the strength of tidal deformation along principal axes, while the remaining three degrees of freedom orient those axes. Note that \(\delta=\lambda_{1}+\lambda_{2}+\lambda_{3}\). Following standard terminology for ellipsoidal collapse (e.g. Bond and Myers, 1996), we define the ellipticity \(e\equiv(\lambda_{1}-\lambda_{3})/(2\delta)\) and prolateness \(p\equiv(\lambda_{1}+\lambda_{3}-2\lambda_{2})/(2\delta)\); thus \(\delta\), \(e\), and \(p\) parametrize the eigenvalues of \(T\).

The tidal tensor averaged on the radius \(r\) with a window function \(W\) is straightforwardly

\[T^{(r)}_{ij}(\mathbf{x})=\int\frac{\mathrm{d}^{3}\mathbf{k}}{(2\pi)^{3}} \mathrm{e}^{i\mathbf{k}\cdot\mathbf{x}}\delta(\mathbf{k})\frac{k_{i}k_{j}}{k^{2}}W(kr), \tag{8}\]

from which it follows that

\[\left\langle T^{(r)}_{ij}(\mathbf{x})T^{(r^{\prime})}_{kl}(\mathbf{x})\right\rangle =\int\frac{\mathrm{d}^{3}\mathbf{k}}{(2\pi)^{3}}P(k)\frac{k_{i}k_{j}k_ {k}k_{l}}{k^{4}}W(kr)W(kr^{\prime}) \tag{9}\] \[=\frac{\delta_{ij}\delta_{kl}+\delta_{ik}\delta_{jl}+\delta_{il} \delta_{jk}}{15}\left(\delta^{(r)}(\mathbf{x})\delta^{(r^{\prime})}(\mathbf{x})\right), \tag{10}\]

where \(\delta_{ij}\) is the Kronecker delta (equal to \(1\) if \(i=j\) and \(0\) otherwise). Equation (10) results from carrying out the angular integrals in Eq. (9). If we discretize the windowing radii \(r_{1}<r_{2}<...<r_{N}\) again, then \(\langle T^{(r_{a})}_{ij}(\mathbf{x})T^{(r_{b})}_{kl}(\mathbf{x})\rangle\) is a \(6N\times 6N\) covariance matrix, since \(T\) has \(6\) independent components. By diagonalizing this covariance matrix, we can sample random trajectories \(\delta_{a},\varepsilon_{a},\)\(p_{a}\) using the same methods as in Sec. 2.1. The trajectories in Fig. 1 were generated using this approach, and the lower panels show the ellipticity \(e\) and prolateness \(p\) as a function of the averaging mass scale \(M\).

### Conditional trajectories

We will also have occasion to sample trajectories in \(\delta^{(r)}\) conditioned on it taking a particular value \(\delta^{(r)}=\bar{\delta}\) when windowed on a chosen scale \(\bar{r}\). Given the discretization scheme \(r_{1}<...<r_{N}\) again, the conditional distribution of the \(\delta_{a}\equiv\delta^{(r_{a})}\) is Gaussian with mean

\[\langle\delta_{a}\rangle\Big{|}_{\delta^{(r)}=\bar{\delta}}= \frac{\langle\delta^{(r_{a})}\delta^{(\bar{r})}\rangle}{\sigma^{2}(\bar{r})}\delta \tag{11}\]

and covariance

\[\langle\Delta\delta_{a}\Delta\delta_{b}\rangle\Big{|}_{\delta^{(r)}=\bar{ \delta}}=\langle\delta_{a}\delta_{b}\rangle-\frac{\langle\delta^{(r_{a})} \delta^{(\bar{r})}\rangle\langle\delta^{(r_{b})}\delta^{(\bar{r})}\rangle}{ \sigma^{2}(\bar{r})} \tag{12}\]

(see Eqs. 3 and 6). Here \(\Delta\delta_{a}\equiv\delta_{a}-\langle\delta_{a}\rangle\,|_{\delta^{(r)}= \bar{\delta}}\). These results follow from a classic theorem on conditional Gaussian distributions (e.g. Appendix D of Bardeen et al., 1986). Similarly to Sec. 2.1, we can diagonalize

\[\langle\Delta\delta_{a}\Delta\delta_{b}\rangle\Big{|}_{\delta^{(r)}=\bar{ \delta}}=\sum_{c=1}^{N}A_{ac}\lambda_{c}A_{bc}, \tag{13}\]

Figure 1: Example trajectories of the tidal tensor \(T_{ij}\) as a function of averaging mass scale \(M\) at a fixed position and time. We decompose \(T_{ij}\) into the density contrast \(\delta\) (upper panels), the ellipticity \(e\) (middle panels), and the prolateness \(p\) (lower panels, expressed in units of \(e\)). We consider a single trajectory for each of three averaging window functions (different colours) and two different scale-free power spectra (left-hand versus right-hand panels). The mass \(M\) is expressed in units of the mass scale \(M\), on which the rms variance in \(\delta\) (\(\sigma\), upper axis) is unity. Where \(\delta<0\), we do not plot \(e\) and \(p\). The trajectories with the sharp \(k\)-space window (green) are extremely noisy, which reflects a lack of correlation between steps in \(\delta_{a}\) as \(N\) is varied. For the top-hat (blue) and Gaussian (orange) windows, the trajectories are much smoother. The circles mark first crossing of the spherical collapse threshold \(\delta_{c}=1.686\) for each trajectory, while the squares mark first crossing of the ellipticity- and prolateness-dependent ellipsoidal collapse threshold \(\delta_{c}=1.686f_{\mathrm{cc}}(e,p)\).

where \(A\) is an orthogonal matrix and \(\lambda_{a}\) are the eigenvalues of \(\left\langle\Delta\delta\Delta\delta\right\rangle|_{\delta^{(s)}=\delta}\). A random trajectory is now given by

\[\delta_{a}=\left\langle\delta_{a}\right\rangle\Big{|}_{\delta^{(s)}=\delta}+ \sum_{b=1}^{N}A_{ab}w_{b}, \tag{14}\]

where each \(w_{b}\) is sampled from the Gaussian distribution of mean 0 and variance \(\lambda_{b}\).

## 3 Mass functions from excursion set theory

In the excursion set approach, a particle is deemed to belong to a halo of mass \(M\) if that is the largest mass scale for which the (linearly evolved) density contrast \(\delta\) averaged around that particle's location exceeds some threshold \(\delta_{\rm c}\). That is, the halo mass is the location of first crossing of the threshold, if the trajectory in \(\delta\) is viewed as a random walk in decreasing averaging scale \(M\). The circles in the upper panels of Fig. 1 mark these first crossings if the spherical collapse threshold \(\delta_{\rm c}=1.686\) is adopted. We also consider the ellipsoidal collapse threshold \(\delta_{\rm c}=1.686f_{\rm cc}(e,p)\), where \(f_{\rm cc}\) is the solution to

\[f_{\rm cc}=1+0.47\left[5(e^{2}-p|p|)f_{\rm cc}^{2}\right]^{0.615}, \tag{15}\]

as approximated by Sheth et al. (2001). Note that \(f_{\rm cc}\geq 1\). The squares in Fig. 1 mark each trajectory's first crossing of the ellipsoidal collapse threshold. With respect to the horizontal axis, the circles and squares indicate the mass of the particle's host halo, as determined by spherical and ellipsoidal collapse, respectively.

We discretize the window radii \(r_{1}<r_{2}<...<r_{N}\) such that \(\sigma(r_{N})=0.28\) (see Eq. 6). This choice ensures that the probability is negligible that a trajectory would already exceed the collapse threshold \(\delta_{\rm c}\) at or above the maximum radius \(r_{N}\), which is important because in that case the first crossing would be missed. We consider power spectra \(P(k)\propto k^{n}\) with \(n=-1\), \(n=-1.5\), \(n=-2\), and \(n=-2.5\); the lower limit \(r_{1}\) of the discretization is taken such that \(\sigma(r_{1})\) ranges from about 400 in the first case to about 30 in the last. When we sample one-dimensional trajectories in \(\delta\) alone, we use \(N=3200\) logarithmically spaced averaging radii, while to sample six-dimensional trajectories in \(T_{ij}\), we reduce this number to \(N=800\).2 The spacing between successive windowing mass scales \(M\propto r^{3}\) is listed in Table 1 for each power spectrum.

Footnote 2: We discuss later (and in Appendix A) the impact of the choice of \(N\). Using numpy matrix operations (Harris et al., 2020), the author’s personal computer samples about 400 trajectories in \(\delta\) per second for \(N=3200\) or about 150 trajectories in \(T_{ij}\) per second for \(N=800\) (including the decomposition into \(\delta,e,\,and\,p\)). See also Nikakhtar et al. (2018) for a potentially faster approach.

For each power spectrum, we sample \(10^{5}\) trajectories in \(\delta\) alone and \(10^{5}\) trajectories in \(T_{ij}\). For each trajectory, we find the largest windowing scale for which \(\delta\) exceeds the threshold for spherical or ellipsoidal collapse, and then we attempt to interpolate the precise scale at which the crossing occurred. The first crossing sets the mass \(M\) of the halo hosting the particle associated with the trajectory in question. Since we are sampling trajectories associated with arbitrary points in the initial density field, our sample is of arbitrary dark matter particles. Therefore, the distribution of first-crossing masses is precisely the differential fraction \({\rm d}f/{\rm d}M\) of all mass that resides in haloes of mass \(M\). We will generally present halo mass functions as \({\rm d}f/{\rm d}\log M\), the differential mass fraction per logarithmic interval in halo mass, but note that the more commonly discussed differential halo number density is related by

\[\frac{{\rm d}n}{{\rm d}\log M}=\frac{\tilde{p}}{M}\frac{{\rm d}f}{{\rm d} \log M}. \tag{16}\]

A great convenience of considering scale-free cosmologies, with \(P(k)\propto k^{n}\), is that a change in time is equivalent to a change in mass scale. This means that we can improve the statistical precision of this calculation - particularly at the large-mass end - by stacking the distributions of first-crossing masses evaluated at different times. We assume scale-independent growth (valid for a dark matter-dominated universe) and adopt growth factors \(D\) ranging from \(\sigma(r_{N})/\sigma(r_{1})\) to 1 separated by factors of 1.03, where \(\sigma(r_{1})\sim O(100)\) and \(\sigma(r_{N})=0.28\) are the rms variance at the minimum and maximum window scales, respectively, as described above. Thus, at the smallest \(D\) (earliest time), no haloes are expected within the resolution limit implied by the choice of window scales. By uniformly scaling each previously sampled trajectory in \(\delta\) by the growth factor \(D\) (or equivalently scaling the thresholds by \(1/D\)), we obtain the first-crossing mass distribution at the time when the growth factor was \(D\). The characteristic mass scale \(M_{*}(D)\) at this earlier time is defined to be the mass associated with the window radius \(r_{*}\) such that \(D\sigma(r_{*})=1\) (see Eq. 6). In units of \(M_{*}(D)\), the underlying first-crossing mass distributions at different \(D\) must be all exactly the same.

We count first-crossing masses \(M/M_{*}(D)\) in logarithmic bins of width \(\Delta\log M=0.33\). For each mass bin, we stack the counts from all growth factors \(D\) for which the bin lies fully between the lower and upper mass limits, \(M_{1}/M_{*}(D)\) and \(M_{N}/M_{*}(D)\), where \(M_{i}\) is the mass associated with the window radius \(r_{i}\). Since \(M_{*}(D)\) grows with \(D\), the distributions at lower \(D\) (earlier times) tend to improve the count of first-crossing masses at high \(M/M_{*}(D)\). One disadvantage of this procedure is that the uncertainty of the count in each mass bin cannot be estimated straightforwardly, because the counts contributed by different \(D\) are correlated. Therefore, we do not attempt to estimate the uncertainty in \({\rm d}f/{\rm d}\log M\).

The solid curves in Fig. 2 show the \({\rm d}f/{\rm d}\log M\) that result from this calculation, for both the spherical collapse (blue) and ellipsoidal collapse (orange) thresholds. We consider three different window functions \(W\) (different columns) and the two power spectra \(P(k)\propto k^{n}\) with \(n=-1\) and \(n=-2.5\) (different rows). For comparison, we also show as dashed lines the standard analytic predictions,

\[\left.\frac{{\rm d}f}{{\rm d}\log M}\right|_{\rm sc}=\sqrt{\frac{2}{\pi}}\frac {\delta_{\rm c}}{\sigma_{M}}\,\exp\left(-\frac{\delta_{\rm c}^{2}}{2\sigma_{M} ^{2}}\right)\left|\frac{{\rm d}\log\sigma_{M}}{{\rm d}\log M}\right| \tag{17}\]

(Press & Schechter, 1974; Bond et al., 1991) for the spherical collapse

Tuple 40:
Cleaned Title: filament formation due diffusive instability dusty protoplanetary disk
Cleaned Transcription: filament formation due diffusive instability dusty protoplanetary disk department astronomy yale university new ct usa minkai lin linlin institute astronomy astrophysics academia sinica taipei taiwan physic division national center theoretical science taipei taiwan institute astronomy astrophysics academia sinica taipei taiwan physic division national center theoretical science taipei taiwan institute astronomy astrophysics academia sinica taipei taiwan physic division national center theoretical science taipei taiwan institute astronomy astrophysics academia sinica taipei taiwan physic division national center theoretical science taipei taiwan abstract report finding new local diffusion instability protoplanetary disk operate dust fluid subject mass diffusion shear viscosity dustgas drag provided diffusivity viscosity decrease sufficiently rapidly increasing dust surface mass density devise vertically averaged axisymmetric hydrodynamic model describe dense midplane dust layer protoplanetary disk gas modeled passive component imposing effective diffusiondependent pressure mass diffusivity viscosity onto otherwise collisionless dust fluid via turbulence excited gas alone dust gas combination particular argue condition met dustgas mixture generates smallscale turbulence streaming instability supported recent measurement dust mass diffusion slope simulation hypothesize newly discovered instability may origin filamentary feature almost ubiquitously found simulation streaming instability addition model allows growing oscillatory mode operate similar fashion axisymmetric viscous overstability dense planetary ring however remains speculative required condition mode met protoplanetary disk konstantin gerbig marius lehmann introduction protoplanetary disk birthplace planet one key stage within coreaccretion scenario planet formation involves conversion small dust particle kmsized planetesimal formation planetesimal associated multitude challenge specifically coagulational growth thought inhibited around meter size radial drift fragmentation small solid birnstiel et al blum last two decade attention therefore directed towards gravitational contraction sufficiently massive disk region particle filament local overdensities since required dusttogas ratio supersolar one must invoke additional process effectively concentrate dust particle includes secular gravitational instability ward youdin takahashi inutsuka tominaga et al particle trap pressure maximum onishi sekiya shibaike alibert xu bai turbulent concentration chamber hartlep cuzzi dustgas drag instability johansen et al schafer et al gerbig et al gerbig li prominent socalled streaming instability youdin goodman jacquet et al squire hopkins linear phase streaming instability utilizes relative equilibrium velocity dust gas classical picture induced background gas pressure gradient drive exponentiallygrowing mode youdin goodman streaming instability saturates dynamic timescales quasisteadystate characterized turbulent particle density velocity fluctuation johansen youdin eventually system selforganizes azimuthally elongated filament drift inwards merge see eg yang johansen li et al li youdin threestep evolution readily observed shearingbox simulation vertically stratified unstratified protoplanetary disk drag dust feedback included formation planetesimal within streaming instability framework requires additional component dust selfgravity albeit priori obvious thought occur streaming instability nonlinear phase either emergence overdense filament nonlinear phase investigated numerically numerous occasion specifically schreiber klahr found twodimensional simulation dust diffusivities tend decrease dusttogas ratio behavior also seen threedimensional stratified simulation gerbig li typically attributed particle carrying much collective inertia effectively diffused away residual gas turbulence conversely backreaction particle inertia onto gas may lead decrease diffusion increasing dusttogas ratio alternative picture view particle diffusion similar gas pressure model aim discus thoroughly paper region high diffusion expels particle towards region low diffusion either way implication particle diffusion decreasing increasing dust density hitherto investigated analytically context stability dusty protoplanetary disk previous model chen lin umurhan et al diffusion depend stopping time gas viscosity taken constant paper perform instability analysis sheet particle subject dustgas drag force mass momentum diffusion diffusion coefficient allowed vary particle density existence dependence established hydrodynamic simulation schreiber klahr gerbig li treatment bear thus similarity hydrodynamic study viscous instability lin bodenheimer ward salo schmidt viscous overstability schmit tscharnuter schmidt et al latter ogilvie lehmann et al planetary ring paper structured follows outline hydrodynamical model specifically focusing diffusion term physical relevance well perform linear perturbation analysis sect next discus arising nonoscillatory overstable mode sect respectively discus contextualize result sect lastly sect concludes paper summary finding hydrodynamic model diffusion viscosity particleladen protoplanetary disk dust diffusion long identified immense importance dust dynamic consequently planetesimal formation see eg cuzzi et al deem worth explicitly defining work relevant property term putting context previous study related particle diffusion recent comprehensive discussion turbulent diffusion protoplanetary disk refer binkert generally speaking diffusion act minimize free energy work describe dust fluid subject diffusion mass driven gradient dust concentration momentum driven pressure gradient shear stress typical condition dust particle protoplanetary disk collisional therefore experience collisional pressure force instead dynamic influenced coupling gas namely via stopping time trm appears drag term momentum equation ie mathbffrm dproptomathbfvmathbfutrm mathbfv mathbfu particle gas velocity respectively gas turbulence fully characterized gas velocity mathbfu additional diffusion term would needed modeling dust diffusion protoplanetary disk indeed numerical simulation typically employ explicit diffusivity viscosity instead compute diffusive effect indirectly via dustgas interaction reflected mathbfueg yang et al riols et al treatment often practical analytical progress employ diffusion subgrid model describe diffusion viscosity due particle coupling gas using explicit term hydrodynamical equation governing equation specifically work consider isothermal infinitesimally thin axisymmetric particle disk absence selfgravity embedded gas enters system diffusion viscosity drag polar coordinate rphi system governed set vertically averaged fluid equation fracpartialsigmapartial tfracrfracpartialr sigma vrpartial rfracrfracpartialpartial rleftrd fracpartialsigmapartial rright tag fracpartial vrpartial tleftvrfracdsigma fracpartialsigmapartial rrightfracpartial vrpartial r fracvphiromegarfracvrurtrm fracsigmafracpartialcphisigmapartial r fracsigma rfracpartialpartial rleftrvrdfracpartial sigmapartial rrightfr fracpartial vphipartial tleftvrfracdsigma fracpartialsigmapartial rrightfracpartial vphipartial r fracvphirleftvrfracdsigmafracpartialsigma partial rright fracvphiuphitrm sfphi eq describe dynamical evolution surface mass density sigma radial velocity vr azimuthal velocity vphi respectively omegasqrtgmr keplerian angular frequency stellar mass gravitational constant g continuity equation take form advectiondiffusion equation mass diffusivity dust momentum equation incorporate advection vr diffusion flux lead modified gradient advection term left hand side momentum equation well modified curvaturerelated advection term right hand side eq addition fifth term right hand side eq incorporates vradvection momentum carried diffusion flux refer tominaga et al discussion additional advection term associated diffusion flux implication full dustgas mixture considered note allow total gas dust angular momentum conserved provide rigorous justification set hydrodynamical equation appendix using meanfield theory based reynolds averaging application set plausible closure relation given context field sigmamathbfv interpreted mean field separated scale underlying small fluctuation characterize turbulence eq includes vertically averaged effective dust pressure prm dsigma crm velocity dispersion crm dust fluid since dust assumed collisionless effective velocity dispersion assumed generated solely particle coupling turbulence crm dpropto specifically follow klahr schreiber gerbig li write crm dfracdcrm strm scrm sdapproxfracd trm tag follows balance diffusion sedimentation latter approximation requires dll trm scrm case numerical simulation eg schreiber klahr gerbig li discus pressure model appendix b finally include explicit momentum diffusion term modeled navierstokes stress term fr fphi calculated via mathbfffracsigmanablacdot tag viscous stress tensor component tijnusigmaleftfracpartial vipartial xjfracpartial v jpartial xifracdeltaijnablacdotmathbfvright tag nu effective vertically averaged kinematic shear viscosity particle fluid inclusion shear stress term differentiates eq eq dust momentum equation used tominaga et al model also distinguishes work concerning dusty protoplanetary disk scale planetesimal formation consider diffusivity viscosity nu consequently via eq also velocity dispersion crm dust pressure depend surface mass density sigma specifically assert power law dependency form proptoleftfracsigmasigmarightbetarm diff tag nu proptoleftfracsigmasigmarightbetarm visc tag betarm diff betarm visc dimensionless exponent also introduce corresponding dimensional slope betad fracpartialdsigmapartialsigmadbetarm diff tag betanu fracpartialnusigmapartialsigmanubetarm visc tag high dusttogas ratio betarm found negative schreiber klahr gerbig li aware numerical constraint betanu within context turbulent diffusion dusty protoplanetary disk model applicability equation applied combined inertia disk dominated particle fluid dusttogas volume mass density ratio rhorm prhorm ggtrsim case presence gas reduced perturbation evoke drag mass diffusion momentum diffusion aka viscosity analytic model agnostic source diffusion viscosity paper specifically apply particle layer midplane protoplanetary disk subject nonlinear streaming instability given context model restricted radial length scale exceeding characteristic scale underlying turbulence case characteristic scale streaming instability taurm ssim order lrm sisimeta reg youdin goodman squire hopkins gerbig et al etasim characterizes radial pressure gradient disk thus scale equilibrium relative velocity dust gas smaller stopping time restriction relaxed characteristic scale linear streaming instability decrease eg lin youdin appendix also note vertical direction restriction formally always satisfied model vertically unstratified implying vanishing vertical wavenumber mode whether mode supported actual vertically stratified dust layer requires stratified analysis thus subject future work point fluid description particle protoplanetary disk applied strictly valid trm somega since decoupled grain dynamical evolution stress tensor general ignored see eg garaud et al jacquet et al must modeled using kinetic approach work instead assume external turbulence able establish simple newtonian stressstrain relation particle fluid characterized shear viscosity nu isotropic velocity dispersion crm discussed sect appendix extent similar effect mutual particle collision planetary ring indeed frequent enough known establish newtonian stressstrain relation particle flow eg stewart et al shu stewart however streaming instability turbulence main application model expected occur large stopping time withdraws physical justification assumption least given context addition mutual collision ignored model may principle become relevant velocity dispersion crm dpropto trm becomes sufficiently small despite limitation also present discus result assuming larger particle trm somega retain concrete connection viscous instability overstability planetary ring also large grain protoplanetary disk experience momentum mass diffusion mean see discussion sect model may still provide useful insight despite lacking stress tensor evolution contained kinetic approach linearized equation dispersion relation adopt local corotating cartesian reference frame distance r star xyrrrphiomega vxvrvyvphiromega perturb system around background state sigmasigmasigmaprimevxvxprimevyqomega xvy prime sigmarm const linearize perturbed quantity following appendix b klahr schreiber neglect perturbed gas velocity mathbfuprime linearized drag term proptomathbfvprimetrm justified mean field quantity derived appendix timeaveraged one turbulent correlation time assumption conveniently decouples dust gas equation allows u isolate effect dust densitydependent turbulence alone keplerian shear q eq thus become fracsigmafracpartialsigmaprimepartial fracpartial vxprimepartial x fracsigmafracpartialpartial xleftdfrac partialsigmaprimepartial xright tag fracpartial vxprimepartial tomega vyprime fracvxprimetrm fracsigmatrm sfracpartialdsigmapartial sigmafracpartialsigmaprimepartial xnufracfracpartial vxprimepartial x fracpartial vyprimepartial tfracomega vx prime fracvyprimetrm sfracomegafracdsigma fracpartialsigmaprimepartial x nufracpartialvyprimepartial xfrac omegasigmafracpartialnusigmapartialsigmafracpartial sigmaprimepartial x set linearized equation novel includes navierstokes viscosity particle fluid relates particle pressure diffusion stopping time via eq produce second term rh radial momentum equation take account dependence diffusion viscosity particle surface mass density motivated simulation schreiber klahr gerbig li consequence radial azimuthal momentum equation respectively contain slope diffusion viscosity respect particle surface mass density depending slope term act stabilizing destabilizing perturbation equilibrium state defined discus mass diffusion term continuity equation term proptopartialpartial x assuming nu term describing advection background shear diffusion flux second term rh eq always stabilizing note diffusion flux term term four angular momentum conserving term eq added tominaga et al survives linearization notably behaves like fourth term right hand side eq containing viscosity gradient rest paper diffusion flux reference term specifically unless stated otherwise lastly drag term stabilizing effect analysis include radial azimuthal drag term contrast klahr schreiber drop azimuthal drag term proceed introducing axisymmetric mode form fprimerelefthatfeikxntright tag complex frequency n radial wavenumber k take k without loss generality mode grow decay ren ren respectively imn corresponds oscillation frequency sign set wave travel direction get nfrachatsigmasigma ikhatvxdkfrachatsigmasigma tag nhatvxomegahatvy frachatvxtrm sfraciktrm sbetadfrac hatsigmasigmafracnu khatvx nhatvyfracomegahatvx frachatvytrm sfracikdomegafrachat sigmasigma nu khatvyfracikomegabetanufrachat sigmasigma system solved cubic dispersion relation form nnanaa tag coefficient leftfracnudrightkfractrm tag leftfracdnufracnurightk leftfracdtrm sfracfracnutrm fracbetadtrm srightk fractrm somega leftfracdnurightkleftfracfracdnu trm sfracnutrm sbetadrightk leftdomegafracdtrm sfracbetadt rm somegabetanurightk dimensionless quantity convenient write dispersion relation term commonly used dimensionless quantity orbital frequency introduces time unit write dimensionless stopping time taurm sequiv trm somega tag general distinct socalled stokes number defined ratio stopping time turbulent correlation time also known eddy time integral time cuzzi et al youdin lithwick particle taurm sll wellcoupled gas taurm sgg applies looselycoupled dust reference length unit gas pressure scale height ratio gas sound speed crm orbital frequency hcrm somega write dimensionless wave number kequiv kh dimensionless version ground state diffusivity eq viscosity eq introduced delta equivfracdcrm sh tag alpha equivfracnucrm sh tag use nomenclature wellknown shakura sunyaev alphaparameter shakura sunyaev albeit work alpha describes effective viscosity dust fluid viscosity gas often adopted model angular momentum transport protoplanetary disk corresponding power law slope diffusivity viscosity defined eq ie betarm diffpartiallndeltapartiallnsigma betarm viscpartiallnalphapartiallnsigma respectively typical value diffusivity slope lesssimdeltalesssim lesssimbetarm difflesssim high dusttogas ratio schreiber klahr gerbig li appropriate constraint particle viscosity alpha le clear resistive simulation magnetorotational instability balbus hawley yang et al measured shear viscosity alphasim gas however value includes albeit presumably small contribution maxwell stress constitutes average value throughout particle layer aware applicable constraint alpha particle layer measurement betarm visc define hydrodynamic schmidt number ratio viscosity mass diffusion coefficient particle fluid ie mathrmscequivfracalphadelta tag analogous definition used pure gas protoplanetary disk johansen klahr carballido et al pointed youdin lithwick context particle protoplanetary disk schmidt number suffers oversubscribed also used describe ratio gas viscosity particle diffusivity cuzzi et al schreiber klahr binkert primarily interested dust component hence assign sc characterize relative importance particle viscosity particle diffusivity stem particle coupling gas turbulence lastly notice delta dispersion relation includes degeneracy wave number diffusivity define xiequivdelta kfracdkomega tag note since herein utilized description dustpressure appropriate taurm sggdelta equivalently require xilltaurm sk noted sect model appropriate scale larger scale underlying turbulence thus require xilesssim pideltahreta typical value hr etasim fiducial diffusivities deltasim corresponds maximum xi order unity remainder study mostly concerned longwavelength limit xi dimensionless complex frequency denoted sigmaequivfracnomegaequivgammaiomega tag gammaresigma growth rate omegaimsigma oscillation frequency dimensionless version cubic dispersion relation eq given sigmasigmaasigma aa tag leftfractextscrightxifractautexts tag fractextsclefttextscrightxi leftfractextscbetatextdiffrightfrac xitautextsfractautexts fractextscxifractextsctautexts leftfracbetatextdiffrightxi leftfractautextsleftbetatextdiff righttextscleftbetatextviscrightrightxi aaa real coefficient implies sufficient condition nonoscillatory instability least one real positive root eq full complex dispersion relation also cast two equation growth rate oscillation frequency need hold independently omegaomegagammaomegagamma aomega tag gammaomegagammaomegaagammaa gamma aa tag diffusive instability section investigates diffusive instability associated real root dispersion relation eq consider however first case zero diffusivity viscosity ie textsc xi limit dispersion relation reduces sigmaleftsigmafractautextssigmafractautexts right tag solved damped epicyclic wave oscillation frequency omega negative growth rate ttexts purely real root static null solution sigmagammaomega mode get destabilized diffusion andor viscosity discus following section concerned nonoscillatory purely real solution set omega replace sigmagamma redirect attention oscillatory mode sect inviscid case first investigate purely diffusive case textsc limit dispersion relation figure growth rate inviscid textsc diffusive instability driven diffusiondependent pressure xi black dashed line corresponds eq instability operate perturbation exponentially damped figure growth rate inviscid textsc diffusive instability driven diffusiondependent pressure betatextdiff various stopping time hatched region corresponds xi model seizes appropriate line tautexts tautexts overlap written gammaleftxifractaurm srightgamma leftbetarm difffracxitaurm sfractau rm srightgamma tag xileftfractaurm sleftbetarm diff rightright lead unconditional instability betarm difftaurm tag realistic power law slope betarm diffgtrsimschreiber klahr gerbig li inviscid sc diffusive instability thus requires taurm slesssim small growth rate gammall find eq gammafracxilefttaurm sbetarm diffrighttau rm sxitaurm sbetarm diff tag small stopping time equal gammasimeqxileftbetarm diffrightquadtaurm sll tag fig show growth rate inviscid diffusive instability choice slope betarm diff stopping time taurm mode xi fiducial delta corresponds k note instability requires betarm diff consistent general condition eq limit taurm sll fig show growth rate inviscid diffusive instability betarm diff various stopping time system either stable tausgtrsim unstable tauslesssim xi fact note inviscid diffusive instability damped small scale display fastest growth rate scale xi model break indicated hatched region fig physical origin inviscid diffusive instability lie dust pressure term eq betarm diff pressure term act destabilizing accelerates particle towards annulus high density low diffusivity betarm diff sufficiently steep eq hold ie betarm difftaurm pressure forcing overcome stabilizing mass diffusion term eq drag term momentum equation increase density process decreasing diffusion resulting positive feedback instability large stopping time limit drag term vanish destabilizing pressure term remaining term mass diffusion term continuity equation diffusion flux term eq act repell particle away density maximum hence onset instability requires stopping time small sc case next consider case dnu equivalently mathrmsc equilibrium value momentum figure like fig viscousdiffusive instability assuming equal mass momentum diffusion mathrmsc betarm diffbetarm visc various stopping time viscosity term damp instability small scale albeit xi expect model break line taurm taurm overlap figure like fig growth rate viscousdiffusive instability xi assuming equal mass momentum diffusion mathrmsc betarm diffbetarm visc black curve corresponds eq instability operate perturbation exponentially damped note part depicted parameter space allow viscous overstability figure showing purely real solution see sect diffusion equal mass diffusion also power law slope diffusion viscosity identical ie betarm viscbetarm diff assumption dispersion relation beginsplitgammaleftfracxifractaurm rightgamma leftfracxileftfracbetarm diff rightfracxitaurm sfractaurm srightgamma fracxileftfracbetarm diffright fracxitaurm leftfractaurm sleftfractaurm rightbetarm diffrightxiendsplit tag pure instability achieved betarm difffracxitaurm sxitaurm staurm xitaurm staurm tag long wavelength limit xi recover finding inviscid case power law gradient betarm diff suffices instability stopping time sufficiently small taurm sll small stopping time large radial length scale destabilizing pressure term dominates viscosity term large stopping time taurm sgg explicit drag term pressure term become neglible case long wavelength limit xi yield betarm difflesssimfracxitaurm sxitaurm xiapproxfrac tag diffusive instability behaves analogously classical viscous instability ward lin bodenheimer instability driven density slope shear viscosity appears azimuthal momentum equation slope sufficiently steep net flux towards density maximum amplifies linear perturbation criterion classical viscous instability given betarm visc modification eq due inclusion mass diffusion term continuity equation diffusion flux eq term always stabilizing hence required viscosity slope diffusive instability driven viscosity operates taurm sgg limit steeper classical case easy see eq taurm sll slope mass diffusion dominate whereas taurm sgg slope momentum diffusion dominate thus leading diffusive instability driven pressure term viscosity term respectively marginally coupled particle taurm ssim instability utilize slope large scale xilesssim betarm diff sufficiently negative system unstable regardless stopping time small growth rate gammall small xi real root eq behaves gammasimeqfraclefttaurm slefttaurm sright betarm diffrightxitaurm sbetarm diffxitau rm tag limit wellcoupled decoupled particle equal gammasimeqbegincasesxileftbetarm diffrighttaurm sll xibetarm difftaurm sgg endcases tag respectively thus recover eq limit small stopping time fig show real root full cubic eq xi black curve corresponds eq given betarm diff growth rate greater large stopping time fig depicts growth rate viscousdiffusive instability betarm diffbetarm visc various stopping time unlike inviscid case eq satisfied mode xi unstable see fig viscous diffusive instability damped small scale xigtrsim viscosity regularizes system prohibiting growth arbitrarily small scale model applicable large xi one expect growth rate increase without bound everdecreasing scale advantage including viscosity model general case given numerical constraint effective viscosity highdensity particle midplane protoplanetary disk sparse finally investigate general case model allows remain agnostic value sc retain two independent power law slope delta alpha pure instability achieved small xi result condition fractaurm sleftbetarm diffrightrm scleft betarm viscright tag general case growth rate diffusive instability well existence thereof first place thus depends five parameter stopping time taurm schmidt number sc diffusion slope betarm diff viscosity slope betarm visc dimensionless wave number xi schmidt number sc act amplification viscosity slope context diffusive instability like previous two case wellcoupled particle taurm sll result instability betarm difftaurm sapprox account diffusive instability hand looselycoupled particle taurm sgg unstable betarm viscfracrm sc tag rm scgg exactly recover classical criterion viscous instability planetary ring ward lin bodenheimer pure instability small growth rate gammall eq yield gammaaa xi result gammafracxilefttaurm sleftbetarm diffright rm scleftbetarm viscrightrighttaurm srm sc betarm diffxitaurm tag wellcoupled limit taurm sll equal inviscid case eq looselycoupled limit taurm sgg get gammaxileftrm scleftbetarm viscrightrightquadtau rm sgg tag overstability direct attention overstable mode nonzero omega figure show growth rate oscillatory mode obtained full dispersion relation demonstrates large stopping time required achieve growing mode caution regime fluid approximation dust grain underlies model start break also see sect well appendix proceed analysis completeness oscillating solution omeganeq eq implies omegagammagamma aa tag positive definite xill seen fig inserted result cubic growth rate wave ie gammaagammaleftaarightgammaaaa tag small growth rate gammall aa root gammasimeqfracaaaaa tag xill gammasimeq biggfractaurm sfracxitaurm leftrm scbetarm diffrightfractaurm tag xileftrm scleftfracbetarm viscright rightbigg timesleftfractaurm sfracxitaurm leftfracrm scbetarm diffrightright assuming large stopping time taurm sgg becomes gammasimfracxileftrm scleftfracbetarm visc rightright tag plotted fig comparison root full cubic overstability ie growing oscillation growth rate must positive ie gamma equivalently betarm viscgtrsimfracrm scfrac tag equal rm sc since overstability characterized restoring force lack case pure instability requirement betarm visc opposite direction compared criterion instability discussed previous section also compare classical viscous overstability eg latter ogilvie also note sc term eq originates advection angular momentum carried background shear due diffusive flux ie second term right hand side eq rm scgg ie negligible diffusion compared viscosity term vanishes recover classical criterion viscous overstability planetary ring schmit tscharnuter interestingly term allows overstability even inviscid case setting rm sc growth rate resulting eq becomes gammafracxitaurm sleftbetarm diffrighttaurm xitaurm staurm sxitaurm sleftbetarm diff righttaurm tag tends gammaxi large stopping time taurm sgg compare eq thus limit diffusion flux given second term right hand side eq alone able grow epicyclic oscillation fig depict growth rate diffusive overstability obtained eq function stopping time smallest scale fastest growth rate least stringent restriction stopping time depicted set parameter taurm sgtrsim would lead overstability smallest scale requirement relaxed larger rm sc positive betarm visc taurm slesssim oscillating mode damped reason overstable mode discussed section little physical relevance context particle generate streaming instability turbulence largest available dust grain limited typically taurm slesssim eg birnstiel et al elaborate well explore alternative situation diffusive overstability may find applicability sect discussion previous section showed dust fluid protoplanetary disk governed eq unstable sect overstable sect otherwise constant background state linearly perturbed depending stopping time particle steepness diffusion viscosity slope respect dust surface mass density discus contextualize finding physical picture first reiterate physical mechanism drive newly found instability figure show growth rate full system including overstability instability inviscid mathrmsc viscous mathrmsc case respectively guided depicted parameter space broadly assign unstable region four category diffusive instability driven diffusiondependent pressure small stopping time utilized dust pressure prescription velocity dispersion cmathrmdpropto dproptosigmabetamathrmdiff lead linear instability diffusion slope betamathrmdiff sufficiently negative see eq drive particle towards density maximum instability damped small scale viscosity nonzero fastest growth rate smallest unstable scale instability requires taumathrmslesssim betamathrmdifflesssim mathrmscgtrsim also xilesssim fiducial deltasim corresponds wavelength lambdagtrsim h associated growth rate shown top two panel fig well left side top panel fig small stopping time figure growth rate diffusive overstability driven viscosity slope mathrmsc left panel driven diffusion slope mathrmsc right panel various stopping time obtained full dispersion relation eq set betamathrmviscbetamathrmdiff order allow type overstability dashed line correspond eq differ substantially two panel due choice betamathrmvisc line end mode become nonoscillatory thus damped large stopping time occurs xi approach hatched region model applicable figure growth rate diffusive overstability driven viscosity slope mathrmsc v stopping time various value xi setting betamathrmviscbetamathrmdiff following eq assumes xill smallest scale model applies given chosen set parameter stopping time taumathrmsgtrsim would allow overstability diffusive instability driven viscosity slope nonzero viscosity viscosity term dominates pressure term sufficiently large stopping time leading version viscous instability ward lin bodenheimer modified mass diffusion diffusion flux instability requires taurm sgtrsim mathrmscgtrsim xilesssim betarm visclesssim seen top two panel fig large stopping time diffusive overstability driven background diffusion flux inclusion diffusion flux eq radially distributes azimuthal momentum carried background shear provides additional repellent term amplify o figure like fig viscousdiffusive instability modified viscous overstability mathrmsc top panel show combination diffusive instability driven diffusiondependent pressure viscous instability driven negative viscosity slope small large stopping time respectively compare fig panel second top eq remains satisfied eq instability driven viscosity slope alone thus restricted large taurm third panel top neither instability active eq satisfied mathrmsc betarm visc exceeds modified viscous overstability driven viscosity slope active large stopping time note mathrmsc see purely diffusive overstability damped viscosity figure growth rate inviscid mathrmsc diffusive instability overstability diffusion slope betarm diff increase top bottom diffusive instability driven diffusiondependent pressure active mode xi betarm difftaurm see eq case upper two panel small stopping time large stopping time diffusive overstability driven background diffusion flux active first order regardless value betarm diff cillatory mode stopping time large viscosity small overstability requires taurm sgtrsim rm scll seen panel fig large stopping time diffusive overstability driven viscosity slope analogously classical viscous overstability schmit tscharnuter repellent term amplifies oscillation provided viscosity slope overstability requires taurm sgtrsim rm scgtrsim xilesssim betarm viscgtrsim associated growth rate shown bottom panel fig linear theory describing diffusive instability overstabilities presented work largely similar classical viscous instability ward lin bodenheimer axisymmetric viscous overstability schmit tscharnuter planetary ring least neglect selfgravity thermal effect given appropriate limit model ie taurm sgg rm scgg noted though physical origin viscosity pressure planetary ring lie mutual particle collision contrast situation depicted work result selfgenerated turbulence external insofar model concerned also thin disk version viscous overstability ie large radial length scale gg hg generated constant kinematic shear viscosity principle also exist gaseous protoplanetary disk latter ogilvie addition mention dustdriven viscous ringinstability pioneered dullemond penzlin well related instability johansen et al although operating larger scale similar spirit paper diffusive instability consider disk gas viscosity set turbulence generated magnetorotational instability balbus hawley weakens increasing dust density ionization fraction viscous gas disk unstable linear perturbation increase gas density attracts dust grain tend drift towards gas pressure maximum eg sano et al turbulence weakens gas viscosity drop thereby increasing gas density attracts dust model consider dust fluid decrease viscosity diffusivity dust pressure dust surface density increase likewise physically motivated dust feedback lowering local diffusive property turbulence generated smallscales indeed motivate model streaming instability turbulence associated measurement diffusion slope schreiber klahr gerbig li may well applicable source turbulence example azimuthal streaming instability discovered hsu lin likewise observed evolve filament linear mode saturated moreover one considers pure gas instability source turbulence vertical shear instability urpin brandenburg nelson et al lin youdin barker latter pfeil klahr convective overstability klahr hubbard lyra latter may generate environment suitable secondary diffusive instability dependence diffusivity viscosity disk parameter would need clarified detailed simulation zeroth order one expects drop turbulence increasing dustloading similar magnetorotational instability discussed dust feedback tends stabilize vertical shear instability lin lehmann lin linear convective overstability lehmann lin filament formation diffusive instability based analytic finding sect hypothesize diffusive instability driven sufficiently negative density dependence dust pressure physically motivated dust loading reducing diffusivity may act amplify density perturbation perturbation could saturate become marginally figure filament formation shown space time diagram linear perturbation subject diffusive instability driven pressure plot chose rm sc taurm betarm diff also chose value delta fast growing mode xi corresponds physical wave number kh eigenvector scaled hatsigmasigma stable filament seen many past simulation eg johansen youdin johansen et al carrera et al klahr schreiber yang et al li et al schreiber klahr sekiya onishi gerbig et al flock mignone li youdin hsu lin gerbig li visualize growth linear perturbation filamentlike overdensities space time diagram perturbed density sigmaprime following eq fig show perturbation subject diffusive instability chosen set parameter produce overdensities radial spacing h consistent first emergent filament found streaming instability simulation eg li youdin indeed diffusive instability fastest growth rate smallest scale limited viscosity xirm max order xirm maxsim corresponding fastest growing mode thus expected around fraclambdarm fgmhfracpikpisqrtfracdeltaxirm max approx pisqrtdelta tag deltasim eg schreiber klahr klahr schreiber gerbig li would correspond consistent value lambdarm fgmsim heg li youdin note filament separation simulation found depend external gas pressure slope stopping time dust abundance eg schreiber klahr gerbig et al li youdin property influence streaming instability turbulence eg johansen youdin expected map onto diffusivity ultimately fastest growing mode eq hand commonly used fiducial value filament feeding zone hyang johansen directly compared scale interest already involves postformation nonlinear dynamic merger breakup fig visualizes streaming motion arises diffusive instability dust moving towards density maximum act particle trap process amplifying perturbation comparison fig show traveling wave driven diffusive overstability shearing sheet symmetric x wave traveling towards positive x correspond complex conjugate depicted solution equally valid note radial bulk velocity entirely caused overstability one include background pressure gradient flow would pick tofirstorder constant background drift affect stability since shift comoving frame figure diffusive instability driven diffusiondependent pressure parameter fig shown map xy space particle surface density time omega superimposed rescaled velocity vector vxprimevyprime fluid motion towards density maximum thus amplifying perturbation producing filament show ycoordinate better visualization even though model axisymmetric figure like fig oscillatory mode linear perturbation subject diffusive overstability powered background diffusion flux chose mathrmsc taurm betarm diff hatsigmasigma took delta mode xi corresponds physical wave number kh note shearing sheet symmetric x wave traveling towards positive x equally valid diffusive instability context past numerical simulation aim study present simple linear model emergence first filament streaming instability turbulence seen number simulation including schreiber klahr gerbig et al li youdin gerbig li within model required linear growth rate corresponding required stopping time expected result filament formation depend value diffusion viscosity slope betarm diff betarm visc respectively therefore aim contextualize finding existing numerical study measurement aforementioned slope presented theory readily compared numerical result presented schreiber klahr performed twodimensional nonaxisymmetric nonselfgravitating shearing sheet simulation streaming instability conducting number simulation different dusttogas ratio measuring average particle diffusivity simulation able obtain slope diffusion respect dust surface mass density resulting value lesssimbetarm difflesssim exact value depended box size particle stopping time used simulation simulation schreiber klahr revealed emergence filament particle concentration significantly enhanced relative ambient background context linear diffusive instability discovered work requires betarm difflesssim see fig instability simulation schreiber klahr hence expected marginally stable recently gerbig li measured diffusion slope within single vertically stratified shearing box simulation streaming instability also found betarm diffsim value obtained formation filament simulation also consistent simulation marginally unstable respect diffusive instability provided saturation filament growth result marginallystable state connection planetesimal formation within streaming instability paradigm planetesimal formation filament often thought necessary precursor planetesimal formation provide necessary condition subsequent selfgravitational fragmentation therefore interest compare parameter space active diffusive instability within model determined numerical simulation planetesimal formation specifically clumping threshold streaming instability simu figure growth rate diffusive instabilty driven diffusiondependent pressure term depending metallicity z stopping time taurm compared clumping threshold streaming instability simulation yang et al li youdin associate given metallicity z fastest growing allowed mode xi model via recipe discussed sect assuming epsilon lambdarm crith shown growth rate also chose betarm diffbetarm visc mathrmsc favorable set parameter diffusive instability small stopping time figure like fig mathrmsc allows instability driven viscosity slope large stopping time addition instability driven diffusiondependent pressure term parameter choice identical fig lations purpose relate metallicity z dusttogas ratio epsilonrhorm prhorm g diffusivity via eg lin zfracsigmasigmarm gsimeqepsilonfrachrm dhsimeqepsilon sqrtfracdeltadeltataurm tag hrm vertical scale height dust assuming taurm sggdelta deltasimtaurm szepsilon since model therefore also diffusive instability mechanism implicitly depends delta via xi change diffusivity due metallicity increase decrease compensated decrease increase wavenumber k towards larger smaller radial length scale example typically fast growing mode xisim would correspond wave number ksimepsilonzsqrttaurm proceed imposing minimum scale lambdarm critsim h model apply cf sect use restrict maximum allowed xi given value z specifically xirm maxztaurm sfracpideltaztaurm slambda rm crithsimeqleftfracpi zepsilonlambdarm crith righttaurm tag assume fastest growing mode admitted model given xiztaurm sminxirm fgmxirm max xirm fgm mathematically fastest growing mode obtained numerically full dispersion relation eq xirm fgm typically order unity see fig may larger either absence viscosity small stopping time see fig respectively smaller viscosity slope marginally negative critically required slope see top panel fig figure show growth rate associated preferred mode assuming epsilon lambdarm crith also take betarm diffbetarm visc figure fig show inviscid case rm sc diffusive instability driven diffusiondependent pressure possible given set parameter thus suppressing growth larger stopping time overplotted clumping threshold obtained yang et al li youdin also see carrera et al another version streaming instability clumping unlikely occur one take filament formation due diffusive instability precursor clumping model depicted fig would inconsistent result aforementioned simulation instability occurs stopping time taurm slesssim contrast result simulation hand fig show growth rate associated set parameter except rm sc principle particle value taurm slesssim unstable diffusive instability driven viscosity slope produce similar growth rate thus model entire parameter space probed study yang et al li youdin would subject diffusive instability rendering model consistent hypothesis planetesimal formation triggered emergence filament induced diffusive instability note model displayed fig contain number parameter lambdarm critepsilonbetarm diffbetarm viscrm sc chose relatively freely assumed independent taurm order get prototype idea may connection planetesimal formation resulting first estimation insinuate model includes viscosity addition mass diffusion able explain threshold planetesimal formation determined simulation diffusive instability also operate stopping time taurm sgtrsim agreement planetesimal formation simulation detailed calculation concert additional numerical constraint diffusion viscosity slope required ass diffusion instability role planetesimal formation instability overstability large stopping time local axisymmetric viscous overstability thin astrophysical disk extensively studied context saturn dense ring employing hydrodynamic model schmit tscharnuter spahn et al schmidt et al schmidt salo latter ogilvie lehmann et al kinetic model latter ogilvie nbody simulation salo et al rein latter ballouz et al lehmann et al mondinollermanos salo based result hydrodynamic nbody simulation overstability saturn ring typically saturates form nonlinear traveling wave train could principle carry appreciable amount angular momentum wave train often interspersed defect structure may act source sink former indeed viscous overstability promising mechanism explain occurrence periodic fine structure sim scale part saturn b ring directly observed thomson et al colwell et al hedman et al thus interest explore condition expect diffusive overstability operate overdense particle layer protoplanetary disk since requires taurm sgtrsim preface discussion reiterating hydrodynamical model strictly applicable large stopping time instead kinetic model used see sect outlined sect addition diffusive instability driven pressure term three type instability arise large stopping time instability overstability driven viscosity slope specific requirement betarm visc diffusive overstability operate mathrmscll regardless value diffusion slope betarm diff see fig question extent inviscid hydrodynamic model still appropriately describe system tausgtrsim whether particle sufficiently large stopping time b exist c turbulent behavior still well characterized diffusive flux model shape continuity equation pressure model angular momentum conserving term momentum equation indeed classical picture particle growth protoplanetary disk stopping time limited around taurm ssim eg birnstiel et al individual particle qualify diffusive overstability would already considered planetesimalsized object another possible pathway getting object large stopping time suggested johansen youdin effort explain unexpected drift rate particle clump found streaming instability simulation hypothesize clump may collectively increased stopping time relative individual grain due shielding gas stream providing orderofmagnitude scaling taurm srm effsimepsilonfracrrm clumpeta rfraceta r omegadelta v tag rrm clump clump radius delta v velocity relative gas clump far number density appropriately modeled fluid approach adapt hypothesized collective shielding effect situation specifically applying johansen youdins argument quasisteady turbulent dust layer envision equilibrium set rrm clumphrm dust scale height using hrm dzhepsilon eq find taurm srm effsim zpi piequivetahr reduced radial pressure gradient parameter taking delta vsimeta romega diffusive overstabilitys requirement taurm srm effgtrsim translates zgtrsimpi applies diffusive instability driven viscosity slope coincidentally bai stone find clumping via streaming instability becomes easier smaller pi similarly fixed taurm stopping time individual grain sekiya onishi find filament formation streaming instability simulation sqrtpizpigtrsim interpret result within model filament form effective stopping time realized zpi exceeds unity order trigger diffusive overstability diffusive instability driven viscosity slope streaming instability formally still operates taurm sgtrsim growth rate decrease slowly stopping time pan however due lack numerical constraint diffusivity regime unclear extent instability overstabilities would develop scale within model validity even diffusion viscosity slope remain unchanged since order achieve instability relevant scale diffusivities arbitrarily small consider possibility diffusion selfgenerated instead diffusion may stem directly turbulent gas diffusivity viscosity denote deltarm g alpharm g respectively preceding section exclusively concerned particle diffusivity delta treated wholly independent taurm mathematically selfconsistent necessarily reflect physical condition indeed increased particle response time turbulence diminishes diffusion experienced particle youdin deltafractaurm staurm staurm sdelta rm g tag reduces deltasimdeltarm g small stopping time becomes deltasimdeltarm gtaurm large stopping time large grain feel much reduced turbulence gas consider example gas fiducial diffusivity deltarm gsimalpharm gsim typical value numerical simulation vertical shear instability magnetorotational instability eg flock et al taurm ssim would lead deltasim comparable diffusivities generated streaming instability smaller particle fastest growing scale per eq remains unchanged sim h indeed since diffusive instability discussed paper depend xidelta k decrease diffusivity due particle response turbulence would shift fastest growing mode smaller scale prohibit mechanism operating thus argue large stopping time instability overstabilities may find applicability big enough collection large stopping time particle available protoplanetary disk dust layer collective stopping time exceeds unity note estimation ignored effect particle layer gas turbulence ie deltarm g example turbulence driven vertical shear instability damped dust feedback even dusttogas ratio le unity eg lin caveat additional consideration vertically averaged model neglect vertical motion therefore inertial wave discarded classical axisymmetric streaming instability captured model squire hopkins even include gas equation radial background pressure gradient attribute underlying turbulence characterized diffusion viscosity dust fluid streaming instability equivalent mechanism filament formation model direct result underlying smallscale instability instead originates one intrinsic largescale instability midplane dust layer described model order neglect gas perturbation model timeaveraged one turbulent correlation time result linear mode frequency smaller one inverse correlation time considered caution future work include dynamical equation describing gas well vertical dimension investigate filament formation via streamingtype instability variable viscosity diffusivity rigorous manner model diffusion viscosity slope assumed depend dust surface density primarily available numerical constraint schreiber klahr gerbig li due analogy isothermal hydrodynamic model viscous instability planetary ring however diffusion viscosity indeed arise smallscale streaming instability dependency conceivable namely relative dustgas streaming velocity power streaming instability first place also neglect particle selfgravity filament already form selfgravity turned simulation eg schreiber klahr gerbig et al gerbig li nonetheless selfgravity may importance modifying instability criterion growth rate first order destabilizing effect would amplify density enhancement well permit gravitational instability eg youdin shu youdin tominaga et al gerbig et al gerbig li tominaga et al reserve topic subsequent study lastly also ignored possibility polydisperse dust fluid distribution stopping time instead asserted single stopping time reasonable topheavy size distribution eg birnstiel et al still damping effect particle size distribution streaming instability krapp et al paardekooper et al zhu yang yang zhu underscore relevant point keep mind future investigation diffusive instability summary work present novel vertically averaged axisymmetric hydrodynamic model dense particle layer embedded gaseous protoplanetary disk dust dominant model effect gas perturbation dust dynamic evoking drag force mass diffusion viscosity pressure dust pressure assumed depend dust diffusivity following sedimentationdiffusion ansatz diffusivity viscosity allowed depend dustsurface mass density find model support variety linear diffusion oscillatory instability diffusion instability arise dust particle diffusion andor viscosity decrease sufficiently fast increasing particle surface mass density motivated result past simulation specifically wellcoupled particle taurm sll diffusiondependent pressure destabilize particle flow mass diffusion slope respect dust surface mass density sufficiently negative hand decoupled particle taurm sgtrsim instability driven viscosity slope similar viscous instability planetary ring main application model dense midplane particle layer subject turbulence generated streaming instability smallscales indeed diffusivities associated streaming instability turbulence measured past simulation found sufficient diffusive instability model posse appreciable growth rate order dynamical time scale radial length scale characteristic overdense particle filament seen numerical simulation streaming instability based finding argue diffusive instability captured model may play role filament formation within dusty protoplanetary disk key step within streaming instability paradigm planetesimal formation addition model also give rise growing oscillatory mode inviscid case large stopping time taurm principle result overstable mode wide range radial length scale regardless diffusion slope radial diffusion flux alone provide necessary repellent acceleration presence viscosity overstability damped unless viscosity slope sufficiently flat case overstabilitybehaves similar axisymmetric viscous overstability planetary ring whether instability applicability protoplanetary disk unclear relies strongly particle possessing large stopping time taurm well interaction gas turbulence detailed analytical investigation including vertical motion explicit inclusion gas within twofluid formalism accompanied additional numerical constraint diffusivity viscosity well slope crucial pinpoint relevance diffusive instability dusty protoplanetary disk filament formation therein planetesimal formation appreciative reviewer whose discerning feedback invaluable refining paper kg thanks rixin li ryosuke tominaga tiger lu greg laughlin efficacious discussion work supported national science technology council grant academia sinica career development award ascdam numpy harris et al matplotlib hunter cmasher van der velden appendix justification chosen hydrodynamic equation utilize reynolds averaging justify basic equation used model hereby decompose instantaneous physical variable average langle arangle shortterm fluctuation delta property langledelta arangle consider continuity equation surface density fracpartialsigmapartial tfracrfracpartialrsigma vr partial r radial azimuthal momentum equation fracpartialsigma vrpartial tfracrfrac partialpartial rrsigma vrsigmafracvphirsigma omegarsigmafracvrurtrm fracpartialsigma vphipartial tfracrfrac partialpartial rrsigma vphivrsigmafracvphivrr sigmafracvphiuphitrm respectively axisymmetric dust disk left hand side momentum equation rate change momentum expressed sum eulerian derivative advection term right hand side eq includes curvature term external gravitational potential drag term right hand side eq includes curvature term drag term reynolds decomposition subsequent averaging yield compare eg cuzzi et al tominaga et al fracpartiallanglesigmaranglepartial fracrfracpartialrlanglesigmaranglelangle vr partial rfracrfracpartialpartial rrlangledeltasigma delta vrrangle langlesigmaranglefracpartiallangle vrranglepartial fracpartialpartial tlangledeltasigmadelta vr ranglelanglesigmaranglelangle vrranglefracpartiallangle vr ranglepartial rlanglesigmaranglefraclangle vphirangler langlesigmarangleomegarlanglesigmaranglefraclangle vr ranglelangle urrangletrm sfraclangledeltasigmadelta v rdelta urrangletrm fracrfracpartialrsigmarrpartial rfrac sigmaphiphirfraclangledeltasigmadelta vphiranglelangle v phiranglerlangledeltasigmadelta vrranglefracpartiallangle v rranglepartial rlangle vrranglefracrfracpartial partial rrlangledeltasigmadelta vrrangle langlesigmaranglefracpartiallangle vphiranglepartial fracpartialpartial tlangledeltasigmadelta vphi ranglelanglesigmaranglelangle vrranglefracpartiallangle vphi ranglepartial rlanglesigmaranglefraclangle vrrangle langle vphiranglerlanglesigmaranglefraclangle vphirangle langle uphirangletrm sfraclangledeltasigmadelta vphi delta uphirangletrm langledeltasigmadelta vrranglefraclangle vphi ranglerfracrfracpartialpartial rleftrlangledeltasigma delta vphiranglelangle vrranglerightlangledeltasigmadelta v rranglefracpartiallangle vphiranglepartial rlangledeltasigma delta vphiranglefraclangle vrranglerfracrfracpartial partial rrsigmarphifracsigmarphir introduced component reynolds stress tensor sigmarrlanglesigmaranglelangledelta vrrangle langledeltasigmadelta vrrangle sigmaphiphilanglesigmaranglelangledelta vphi ranglelangledeltasigmadelta vphirangle sigmarphilanglesigmaranglelangledelta vrdelta v phiranglelangledeltasigmadelta vrdelta vphirangle afollowing cuzzi et al tominaga et al ignore second term left hand side momentum equation also assume term trm sdeltasigmadelta vrdelta ur trm sdeltasigmadelta vphidelta uphi vanish case delta vrdelta ur delta vphidelta uphi assumed cuzzi et al tominaga et al next assert following set closure relation langledeltasigmadelta vrrangle dfracpartiallanglesigmaranglepartial r langledeltasigmadelta vphirangle fracdrfracpartiallanglesigmaranglepartialphi langledeltasigmadelta vrranglelangledeltasigma delta vphirangle trrtphiphi langlesigmaranglelangledelta vrdelta vphirangle langledeltasigmadelta vrdelta vphirangle trphitphi r langledelta vrranglelangledelta vphirangle crm eq gradient diffusion hypothesis see cuzzi et al goodman pindor schrapler henning shariff cuzzi huang bai binkert eq defines effective particle velocity dispersion cuzzi et al tominaga et al finally eq employ boussinesq hypothesis also see binkert dust fluid process introduce viscosity problem via viscous stress tensor eq choice relates reynolds stress tensor component via sigmarrlanglesigmarangle crm dtrrsigma phiphilanglesigmarangle crm dtphiphi sigmarphitrphisigmaphi rtphi r correlation eq dropped tominaga et al nu closure relation thus identical huang bai additionally drop pressure term eq closure relation eq establish newtonian stressstrain relation particle fluid process removing need evolution equation stress tensor becomes questionable taurm kinetic approach preferred fluid dynamical treatment see jacquet et al sect using gradient diffusion hypothesis continuity equation directly rewritten advectiondiffusion equation ie fracpartiallanglesigmaranglepartial tfracrfracpartialr langlesigmaranglelangle vrranglepartial rfracrfrac partialpartial rleftrdfracpartiallanglesigmaranglepartial r right momentum equation term containing langledeltasigmadelta vphirangle drop due axisymmetry left langlesigmaranglefracpartiallangle vrranglepartial langlesigmaranglelangle vrranglefracpartiallangle vrrangle partial r langlesigmaranglefraclangle vphirangler langlesigmarangleomegarlanglesigmaranglefraclangle vr ranglelangle urrangletrm sfracpartialcrm dlangle sigmaranglepartial rlanglesigmarangletildefr langlesigmaranglefracpartiallangle vphirangle partial tlanglesigmaranglelangle vrranglefracpartiallangle v phiranglepartial r langlesigmaranglefraclangle vrranglelangle vphi ranglerlanglesigmaranglefraclangle vphiranglelangle u phirangletrm slanglesigmarangletildefphi defined langlesigmarangletildefr fracrfracpartialpartial rrtrrfractphi phirfracrfracpartialpartial rleftrdlangle vrrangle fracpartiallanglesigmaranglepartial rrightdfracpartiallangle sigmaranglepartial rfracpartiallangle vrranglepartial r langlesigmarangletildefphi fracrfracpartialpartial rrtrphifractr phirfraclangle vphiranglerdfracpartiallanglesigma ranglepartial rdfracpartiallanglesigmaranglepartial rfrac partiallangle vphiranglepartial r first two term equation radial azimuthal component divergence cylindrical coordinate viscous stress tensor respectively ie fr fraclanglesigmaranglenablacdot tijrfrac langlesigmarangleleftfracrfracpartialpartial rrtrr fractphiphirright fphi fraclanglesigmaranglenablacdot tijphifrac langlesigmarangleleftfracrfracpartialpartial rrsigmar phifracsigmarphirright athe remaining term langlesigmarangletildefrm r langlesigmarangletildefphi already derived tominaga et al associated bulk transport momentum diffusion flux well diffusive transport bulk momentum thus rewrite momentum equation form beginsplitlanglesigmaranglefracpartiallangle vr ranglepartial tleftlanglesigmaranglelangle vrrangledfrac partiallanglesigmaranglepartial rrightfracpartiallangle vr ranglepartial rlanglesigmaranglefraclangle vphi ranglerlanglesigmarangleomegarlanglesigmaranglefrac langle vrranglelangle urrangletrm sfracpartialcrm langlesigmaranglepartial r fracrfracpartialpartial rleftrdlangle vr ranglefracpartiallanglesigmaranglepartial rrightlanglesigma rangle fr langlesigmaranglefracpartiallangle vphirangle partial tleftlanglesigmaranglelangle vrrangledfracpartial langlesigmaranglepartial rrightfracpartiallangle vphi ranglepartial rfraclangle vphiranglerleft langlesigmaranglelangle vrrangledfracpartiallanglesigma ranglepartial rrightlanglesigmaranglefraclangle vphi ranglelangle uphirangletrm slanglesigmarangle fphi endsplit dividing langlesigmarangle lead eq clarity omit bracket langlerangle paper main text note unlike klahr schreiber specifically keep drag term azimuthal momentum equation appendix b dust pressure model appendix us reynolds averaging derive pressurelike force term form partial ppartial r radial momentum equation pcrm dsigma understood effective dust pressure velocity dispersion crm allow vary density specifically following klahr schreiber employ sedimentationdiffusion ansatz model dependence dust velocity dispersion diffusivity heuristic argument compare settling time linear gravity terminal velocity trm settrm somega diffusion time trm diffdk across length scale sim k mass diffusion coefficient dust similar brownian motion einstein sedimentationdiffusion equilibrium lead dtrm somegakequiv crm regularized expression diverge limit taurm requires consideration gas also leading dust layer thickness hrm dsqrtdeltadeltataurm shsee eg lin define effective particle velocity dispersion via footnote note argument made radial direction replacing stellar vertical gravity restoring force radial epicyclic oscillation omegax crm dequivomega hrm dsqrtfracdeltadeltataurm sc rm ssqrtfracddtrm scrm scrm b also noted klahr schreiber sedimentationdiffusion velocity dispersion crm thus closure relation general different root mean square rms velocity particle hinzetchen formalism turbulent transport neglecting orbital oscillation external force tchen hinze give rms velocity also see eg fan zhu youdin lithwick binkert vrm rmsfractrm ctrm ctrm surm rms b gas velocity dispersion urm rms correlation time turbulence trm c connect gas diffusivity drm g via drm gtrm curm rms drm gsim dsee eq trm sgg trm c rms velocity equal velocity dispersion following sedimentation diffusion ansatz former fairly well grounded numerical simulation eg schreiber klahr latter somewhat ambigous kolmogorov turbulence correlation time equal turnover time largest eddy protoplanetary disk equal omegayoudin lithwick hand schreiber klahr find simulation value active streaming instability value trm csim omega indeed ignoring orbital oscillation good model trm strm cll larger particle epicyclic oscillation important particle decouple turbulence velocity dispersion thus diffusion need modified see youdin lithwick youdin also eq neglect effect work pressure term vanishes large stopping time like prescription used eg youdin umurhan et al diffusivity instead treated independent parameter important kept mind evaluating model particular large stopping time limit klahr schreiber call crm pseudo sound speed appropriate long crm constant work allow diffusivity depend density thus crm dpropto dproptosigmabetarm diff result dust pressure take form polytropic equation state ie prm dproptosigmabetarm diff one formally define dust sound speed arm via arm dfracpartial ppartialsigmaproptobetarm diffsigma betarm diff b betad effective squared sound speed negative result also associated pressure perturbation indeed negative pressure perturbation necessary sufficient requirement diffusiondependent pressure driven diffusive instability may operate taurm slesssim discussed paper reference bai stone bai xn stone j apj l doi balbus hawley balbus hawley j f apj doi ballouz et al ballouz rl richardson c morishima r aj doi aabe barker latter barker j latter h n mnras doi mnrasstv binkert binkert f arxiv eprints arxiv doi arxiv birnstiel et al birnstiel fang johansen ssrv doi birnstiel et al birnstiel klahr h ercolano b aa doi blum blum j ssrv doi carballido et al carballido fromang papaloizou j mnras doi jx carrera et al carrera johansen davy b aa doi chamber chamber j e icarus doi jicarus chen lin chen k lin mk apj doi abca colwell et al colwell j e esposito l w sremcevic stewart g r mcclintock w e icarus doi jicarus cuzzi et al cuzzi j n dobrovolskis r champney j icarus doi icar dullemond penzlin dullemond c p penzlin b aa doi einstein einstein annalen der physik doi andp fan zhu fan l zhu c principle gassolid flow cambridge series chemical engineering v cambridge university press httpsbooksgooglecombooksidzquqbtfmuychttpsbooksgooglecombooksidzquqbtfmuyc flock mignone flock mignone aa doi flock et al flock nelson r p turner n j et al apj doi aaf garaud et al garaud p barrierefouchet l lin n c apj doi gerbig li gerbig k li r apj doi accaa gerbig et al gerbig k murrayclay r klahr h baehr h apj doi abd goodman pindor goodman j pindor b icarus doi icar harris et al harris c r millman k j van der walt j et al nature doi hartlep cuzzi hartlep cuzzi j n apj doi abc hedman et al hedman nicholson p salo h aj httpsarxivorgabshttpsarxivorgabs hinze hinze j turbulence introduction mechanism theory mcgrawhill series mechanical engineering mcgrawhill httpsbooksgooglecombooksidlropbtahochttpsbooksgooglecombooksidlropbtahoc hsu lin hsu cy lin mk apj doi acdf huang bai huang p bai xn apjs doi accb hunter hunter j computing science engineering doi mcse jacquet et al jacquet e balbus latter h mnras doi jx johansen et al johansen kato sano advance plasma astrophysics ed bonanno e de gouveia dal pino g kosovichev vol doi johansen klahr johansen klahr h apj doi johansen et al johansen mac low mm lacerda p bizzarro science advance doi sciadv johansen youdin johansen youdin apj doi johansen youdin mac low mm apj l doi xl klahr hubbard klahr h hubbard apj doi x klahr schreiber klahr h schreiber asteroid new observation new model ed r chesley morbidelli r jedicke farnocchia vol doi klahr schreiber klahr h schreiber apj doi abac klahr schreiber apj doi abcab krapp et al krapp l benitezllambay p gressel pessah e apj l doi ab latter latter h n mnras doi mnrasstv latter ogilvie latter h n ogilvie g mnras doi jx latter ogilvie b b icarus doi jicarus latter ogilvie icarus doi jicarus latter ogilvie icarus httpsarxivorgabshttpsarxivorgabs latter ogilvie icarus httpsarxivorgabshttpsarxivorgabs lehmann lin lehmann lin k aa doi lehmann lin lehmann lin mk mnras doi mnrasstad lehmann et al lehmann schmidt j salo h apj doi aade lehmann et al aa doi li youdin li r youdin n apj doi acef li et al li r youdin n simon j b apj doi aaca lin bodenheimer lin n c bodenheimer p apj l doi lin lin mk mnras doi mnrasstz lin youdin apj doi abcdb lin youdin lin mk youdin n apj doi x lin stewart apj doi aacd lyra lyra w apj doi x mondinollermanos salo mondinollermanos e salo h mnras doi mnrasstad nelson et al nelson r p gressel umurhan mnras doi mnrasstt onishi sekiya onishi k sekiya earth planet space doi sz paardekooper et al paardekooper sj mcnally c p lovascio f mnras doi mnrasstaa pan pan l apj doi aba pfeil klahr pfeil klahr h apj doi ac rein latter rein h latter h n mnras doi mnrasstt riols et al riols lesur g menard f aa doi salo schmidt salo h schmidt j icarus doi jicarus salo et al salo h schmidt j spahn f icarus sano et al sano miyama umebayashi nakano apj doi schafer et al schafer u yang cc johansen aa doi schmidt salo schmidt j salo h physical review letter schmidt et al schmidt j salo h spahn f petzschmann icarus doi icar schmit tscharnuter schmit u tscharnuter w icarus schmit tscharnuter icarus schrapler henning schrapler r henning apj doi schreiber klahr schreiber klahr h apj doi aacd sekiya onishi sekiya onishi k apj doi aaca shakura sunyaev shakura n sunyaev r aa shariff cuzzi shariff k cuzzi j n apj doi x shibaike alibert shibaike alibert aa doi shu stewart shu f h stewart g r icarus spahn et al spahn f schmidt j petzschmann salo h icarus squire hopkins squire j hopkins p f mnras doi mnrassty stewart et al stewart g r lin n c bodenheimer p planetary ring ed r greenberg brahic tucson arizona univ arizona press takahashi inutsuka takahashi z inutsuka si apj doi x thomson et al thomson f marouf e tyler g l french r g rappoport n j grl tominaga et al tominaga r inutsuka si takahashi z arxiv eprints arxiv doi arxiv tominaga et al tominaga r takahashi z inutsuka si apj doi abea tominaga et al apj doi abad umurhan et al umurhan estrada p r cuzzi j n apj doi abd urpin brandenburg urpin v brandenburg mnras doi jx van der velden van der velden e journal open source software doi joss ward ward w r ward ward w r origin earth moon ed r canup k righter et al xu bai xu z bai xn apj l doi acdiff yang johansen yang cc johansen apj doi x yang et al yang cc johansen carrera aa doi yang et al yang cc mac low mm johansen apj doi aaed yang zhu yang cc zhu z mnras doi mnrasstab youdin youdin n apj doi x youdin goodman youdin n goodman j astrophysical journal doi youdin lithwick youdin n lithwick icarus doi jicarus youdin shu youdin n shu f h apj doi zhu yang zhu z yang cc mnras doi mnrasstaa title gaussn bayesian timedelay estimation strongly lensed supernova transcription gausssn bayesian timedelay estimation strongly lensed supernova erin e hayes stephen thorp kaisey mandel nikki arendse matthew grayling suhail dhawan institute astronomy kavli institute cosmology madingley road cambridge cb ha uk oskar klein centre department physic stockholm university albanova university centre se stockholm sweden statistical laboratory dpmms university cambridge wilberforce road cambridge cb wb uk contact email eehcamacuk accepted xxx received yyy original form zzz abstract present gausssn bayesian semiparametric gaussian process gp model timedelay estimation resolved system gravitationally lensed supernova glsne gausssn model underlying light curve nonparametrically using gp without assuming template light curve sn type gausssn fit time delay image using data number wavelength filter simultaneously also introduce novel timevarying magnification model capture effect microlensing alongside timedelay estimation analysis model timevarying relative magnification sigmoid function well constant comparison existing timedelay estimation approach demonstrate gausssn provides robust timedelay estimate simulation glsne nancy grace roman space telescope vera c rubin observatory legacy survey space time rubinlsst find timedelay estimate roman rubinlsst fractional error le apply gausssn sn refsdal find time delay fifth image consistent original analysis regardless microlensing treatment therefore gausssn maintains level precision accuracy achieved existing timedelay extraction method fewer assumption underlying shape light curve templatebased approach incorporating microlensing statistical error budget rather requiring postprocessing account systematic uncertainty gausssn scalable timedelay cosmography analysis given current projection glsne discovery rate rubinlsst roman keywords gravitational lensing strong gravitational lensing micro method statistical supernova general supernova individual sn refsdal distance scale introduction strong lensing background variable source supernova sn foreground galaxy galaxy cluster result appearance multiple image source refsdal first demonstrate time delay multiple image gravitationally lensed supernova glsn image could related h combined model lens mass distribution independent h estimate strong lensing motivated persistent sigma tension presentday expansion rate universe h measured using light earlytimes ie cosmic microwave background planck collaboration et al latetimes ie distance ladder riess et al known hubble tension determined physical tension may suggestive new physic beyond present model universe lambdacdm mortsell dhawan di valentino et al timedelay distance inferred strong lensing completely independent luminosity distance used distance ladder timedelay cosmography represents promising technique crosschecking local measurement hsee eg treu et al suyu et al recent review paper present gaussn bayesian semiparametric approach extraction time delay glsn system using gaussian process gps gausssn publicly available package found httpsgithubcomerinhaygausssnhttpsgithubcomerinhaygausssn rarity glsne first cosmological constraint strong lensing came quasar eg keeton kochanek wong et al birrer et al however sne several advantage quasar strong lensing analysis potential push field precision accuracy firstly sne disappear month allows study lens host galaxy greater detail improved knowledge lens help break masssheet degeneracy falco et al cited main source uncertainty hlicow estimate hwong et al birrer et al lensed object type ia supernova sn ia leverage gained fact sne ia standardizable candle foxleymarable et al birrer et al secondly relatively simple light curve sne contrast stochastic variability quasar make easier extract time delay system single peak brightness limit degeneracy matching image furthermore sne ia wellknown light curve shape colour distribution help constrain effect microlensing dust extinction system microlensing distort shapeof image light curve lead artificial shift apparent peak light curve microlensing timedelay bonvin et al effect proven difficult effect disentangle underlying variability source foxleymarrable et al pierel et al timedelay estimation glsne also done shorter time frame observation variability constrained period week month compared year required measure reliable time delay lensed quasar bonvin et al course rarity sne short window active make glsne difficult discover therefore november first cosmologically useful glsn sn refsdal discovered kelly et al sn refsdal peculiar type ii sn zkelly et al discovered four image einstein cross due lensing elliptical galaxy mac j galaxy cluster z unfortunately time delay galaxyscale lensing originally estimated rodney et al determined short imprecise obtain measurement h however host galaxy sn refsdal also imaged multiple time predicted rm th image sn refsdal would later appear another image host galaxy time delay year kelly et al oguri sharon johnson grillo et al diego et al jauzac et al kawamata et al treu et al predicted sn refsdal reappeared le year later october kelly et al using time delay sn refsdals fifth image four image kelly et al first measurement h published may kelly et al finding h km mpc precision estimate sn refsdal alone demonstrated importance glsne precise local cosmological probe addition sn refsdal seven glsne found sn psafx chornock et al quimby et al sn geu goobar et al sn requiem rodney et al sn c chen et al sn zwicky goobar et al sn riv kelly et al sn hpe frye et al however sn refsdal one eight used cosmology thus far six others suffered either extremely short time delay sn geus sn zwickys sn requiem image time delay hour extremely long time delay sn requiem final image expected reappear sim found archival search therefore insufficient data sn psafx sn requiem sn c one observed image sn riv sn hpe recently discovered march strong candidate second glsn measurement h analysis sn hpe currently ongoing information glsn expected near future next decade vera c rubin observatory legacy survey space time rubinlsst roman space telescope roman expected discover ten hundred glsne adopt right search strategy huber et al wojtak et al pierel et al craig et al data possible reach percent level constraint cosmological parameter competitive shes planck measurement huber et al arendse et al prep sample glsne grow potential resolve hubble tension precise local measurement h relatively simple wellunderstood variability sne lends timedelay estimation technique based around sn light curve template particular templatebased supernova time delay sntd pierel rodney emerged standard glsne timedelay estimation due flexibility accessibility package built upon smcosno barbary et al contains diverse library sn light curve template addition flexible bazin function bazin et al used underlying template spectroscopic classification unavailable ambiguous given specified sn light curve template sntd us nested sampling functionality available sncosmo yield posterior distribution light curve template parameter time delay magnification however uncertainty relating template choice unknown redshift evolution sn light curve especially type sne sne ia may introduce systematic error timedelay analysis difficult quantify templatebased approach motivated welldescribed nature sn light curve complementary method independent potential systematics needed gausssn templateindependent approach timedelay estimation model underlying light curve nonparametrically using gaussian process gp model motivated previous work quasar timedelay estimation gps particular tak et al well hojjati et al hojjati linder meyer et al modeling underlying light curve nonparametrically gp gausssn able fit light curve type sn without prior knowledge type redshift object addition model naturally fit time delay image observed number band simultaneously fitting image filter together take advantage full information available data leveraging knowledge band multiple image timeseries timeshifted magnified realization underlying light curve gausssn also implement novel microlensing treatment occurs alongside timedelay estimation onestep timedelay measurement timevarying magnification term used account macrolensing microlensing simultaneously timedelay estimate time delay microlensing jointly inferred gausssn require postprocessing account systematic error budget due microlensing instead incorporates uncertainty microlensing statistical uncertainty therefore gausssn provides coherent bayesian timedelay estimate onestep without need postprocessing account systematics template choice microlensing peculiar nature sn refsdals light curve exemplifies need templateindependent approach timedelay estimation glsne gausssn although similar sn woosley et al kelly et al sn refsdals light curve well described existing template although theoretical model developed eg baklanov et al light curve sne ia highly uniform shape light curve type supernova le well studied highly varied object object gps well suited application flexible data driven minimal assumption property true underlying light curve indeed analysis time delay sn refsdals five image bayesian gaussian process method upon gausssn based highly successful kelly et al four method including sntd custom piecewise polynomial template approach tested simulation sn refsdallike light curve determine quality method fit simulation bayesian gaussian process method outperformed templatebased approach extracting time delay bestsampled image relative first image hand sntd custom template approach successful estimating time delay poorly sampled image sx relative first image ultimately custom template generally successful fitting time delay magnification image simulation gaussn provides coherent bayesian timedelay estimate complementary strength existing templatebased timedelay estimation method templateindependent approach gaussn require prior knowledge sn type redshift making model quick easy implement furthermore gaussn subject potential source systematic uncertainty bias template choice fine tuning generic sn template bazin function need construct custom template may feasible larger sample gisne make validation analysis difficult finally model provides bayesian timedelay estimate one step without need postprocessing account systematic uncertainty microlensing incorporating timevarying magnification treatment s describe model gisn fluxspace gps describe microlensing model s sampling algorithm implemented gaussn s s show fit simulated doublyimaged gisn light curve expected seen rubinlsst roman apply gaussn five image sn refsdal s s discus performance gaussn compared leading timedelay extraction technique well comment future work possible gaussn s conclude modelling glsne gaussian process fluxspace strong lensing supernova foreground galaxy galaxy cluster result appearance multiple image copy underlying light curve multiple image observed shift time magnification demagnification relative another model true underlying light curve flux space ft draw gaussian process ftsimmathcalgpctkttprime tag ct mean function depend time case time series data kttprime covariance kernel function give covariance ft ftprime throughout work use zero mean function ct zero mean function encourages inferred function go zero flux outside data reflects physical expectation sn explosion expect average zero backgroundsubtracted flux covariance function choose squared exponential kernel kttprimeaettprimex tag amplitude tau length scale two hyperparameters controlling kernel kernel enforces strong correlation point nearby one another weaker correlation point away considered also stationary invariant overall time shift produce smooth function rasmussen williams squared exponential kernel proven wellsuited fitting sn light curve data used previous work success kim et al boone vincenzi et al qu et al gp defined vector mathbff consisting evaluation continuous function ft finite set point mathbft joint multivariate gaussian prior distribution mathbffmathbftsimmathbfnmathbfmathbfkmathbftmathbft tag element covariance matrix mathbfkmathbftmathbft given kijktitj titjinmathbft note use mathbfxsimmathbfnmathbfmumathbfsigma denote multivariate normal vector mean mathbfmu covariance matrix mathbfsigma pmathbfxmathbfnmathbfxmathbfmumathbfsigma give pdf vector two image one band first consider simplest case two image observed one band ie filter covering defined range wavelength taking image arbitrarily chosen reference image light curve two image described ft ft tag ft beta ftdelta delta relative time delay image compared image beta relative magnification image compared image say observe image set n time mathbfhatf image set n time mathbfhatf define mathbfhatfmathbfhatf mathbfhatfmathbfhatf observation image respectively itextth observation image hatfi hatftiftiepsiloni tag epsiloni simmathbfnsigmai tag jtextth observation image hatfj hatftjbeta ftjdeltaepsilonj tag epsilonj simmathbfnsigmaj tag sigmai sigmaj standard deviation measurement error image image respectively assume measurement error independent rescale flux data measurement standard deviation band image single constant factor determined range flux image band concatenate two vector give flux data vector mathbfhatf mathbfhatfbeginpmatrixmathbfhatf mathbfhatfendpmatrix tag time data vector mathbfhatt mathbfhattbeginpmatrixmathbfhatt mathbfhattendpmatrix tag addition define deshifted time vector mathbfhattdelta depends time delay delta mathbfhattdeltabeginpmatrixmathbfhatf mathbfhatfdeltaendpmatrix tag infer ft data mathbfhatf mathbfhatt fit time delay delta magnification beta addition two kernel hyperparameters therefore mathbfthetaataudeltabeta marginal likelihood mathbftheta given pmathbfhatfmathbfhattmathbfthetamathbfnmathbfhatfmathbfmathbf sigmamathbftheta tag think mathbfsigmamathbftheta four quadrant mathbfsigmamathbfthetabeginpmatrixtextcovbeginpmatrixmathbfhatf mathbfhatf textcovbeginpmatrixmathbfhatfmathbfhatf endpmatrixendpmatrixtextcovbeginpmatrixmathbfhatfmathbfhatf textcovbeginpmatrixmathbfhatfmathbfhatf endpmatrixendpmatrix tag recall gp covariance given textcovbeginpmatrixftftprimetextcovbeginpmatrixmathbf hatf mathbfhatfendpmatrix kleftttprimeright equation covariance first quadrant textcovlefthatfihatfjright textcovleftfiepsilonifjepsilonjright tag klefthattihattjrightdeltaijsigmai assuming covariance fi epsilonj physical process generating light curve independent measurement process second quadrant covariance textcovlefthatfihatfjright textcovleftfiepsilonifjepsilonjright tag beta klefthattihattjdeltaright follows textcovlefthatfihatfjright beta klefthattideltahattjright tag textcovlefthatfihatfjright betaklefthattideltahattjdeltaright deltaijsigmai tag betaklefthattihattjrightdeltaij sigmai remaining two quadrant choice kernel stationary klefthattideltahattjdeltarightklefthatti hattjright based formulation decompose sigmamathbftheta three factor sigmamathbfthetaleftmathbfmodotmathbfkrightmathbfw tag odot represents hadamard product ie elementwise product first factor mathbfm depends beta defining mathbf matrix one mathbfm given mathbfmbeginpmatrixmathbfntimes nbetamathbfntimes n betamathbfntimes nbetamathbfntimes nendpmatrix tag n number observation image n number observation image second factor mathbfk depends delta kernel parameter defined mathbfkmathbfkmathbfhattdeltamathbfhattdeltabeginpmatrixbm kmathbfhattmathbfhattmathbfkhatthattdelta mathbfkmathbfhattdeltamathbfhattmathbfkhatthatt endpmatrix tag mathbfkmathbfhattmathbfhattprime matrix whose ijtextth element klefthattihattjprimeright finally diagonal matrix mathbfw contains variance measurement error hatsigma along diagonal specified prior theta equation construct posterior pmathbfthetamidmathbfhatfmathbfhattpropto pmathbfhatfmidmathbfhat tmathbfthetapmathbfthetamidmathbfhatt tag sample marginalize determine probability distribution parameter dependence pmathbfthetamidmathbfhatt mathbfhatt arises restrict time delay delta within range observation two image two band consider case two image two band band band b two function wish model draw gp ftextatsimmathcalgpkttprime tag ftextbtsimmathcalgpkttprime tag draw gp band independent light curve image therefore defined footnote choose neglect correlation underlying light curve different band correlation principle included example hu tak ftextitextat ftextat tag ftextitextbt ftextbt ftexttextat beta ftextatdelta ftexttextbt beta ftextbtdelta note magnification time delay second image relative first band band b therefore still one beta one delta fit remains mathbfthetaataudeltabeta possible adopt unique gp kernel hyperparameters band find extra parameter unnecessary example follow paper construct flux data vector mathbfhatf mathbfhatfbeginpmatrixmathbfhatftexta mathbfhatftexta mathbfhatftextb mathbfhatftextbendpmatrix tag time data vector mathbfhatt mathbfhattbeginpmatrixmathbfhatttexta mathbfhatttexta mathbfhatttextb mathbfhatttextbendpmatrix tag mathbfhatfmb observation image band b time mathbfhattmb also define deshifted time vector mathbfhattdelta mathbfhattdeltabeginpmatrixmathbfhatttexta mathbfhattdeltadelta mathbfhatttextb mathbfhatttextbdeltaendpmatrix tag marginal likelihood pmathbfhatfmidmathbfhattmathbfthetamathcalnmathbfhatfmidmathbf mathbfsigmamathbftheta tag mathbfsigmamathbfthetaleftmathbfmodotmathbfkrightmathbfw make simplifying assumption shared information band beyond time delay magnification word covariance either image band either image band b mind write mathbfk mathbfkbeginpmatrixmathbfktextamathbf mathbfmathbfktextbendpmatrix tag mathbf denotes matrix zero mathbfktexta mathbfktextb defined equation band separately point need number observation image band band b therefore shape mathbf need necessarily square finally posterior case equation new marginal likelihood term defined data case case two image two band generalized fit multiple image multiple band fit simulated multiband data expected rubinlsst roman s multiimage data sn refsdal s microlensing effect microlensing star substructure lensing galaxy galaxy cluster additionally introduce additional timevarying magnification individual image microlensing system glsne extremely difficult model complex layout star dark substructure foreground lensing system discrepancy modelpredicted brightness four image sn zwicky without consideration microlensing observed brightness image mag one image demonstrates difficulty modeling effect significant impact microlensingsubstructure system pierel et al goobar et al following tak et al model microlensing timedependent extension beta previously constant beta becomes betat learn relative magnification effect light curve data available take magnification relative arbitrarily chosen image therefore equation become hatfi hatftiftiepsiloni tag epsiloni simmathcalnsigmai hatfj hatftjbetatjftjdeltaepsilonj epsilonj simmathcalnsigmaj tag sigmai sigmaj standard deviation measurement error image image respectively figure foxleymarrable et al figure pierel et al illustrate microlensing map example microlensing function time example microlensing curve period constant magnification typically interrupted one change brightness occurs range timescales le day week physically shape corresponds sn crossing microcaustic photosphere expands change observed magnification appears remain constant small size sn microlensing substructure mean photosphere often cross one significant microcaustic therefore chosen model microlensing sigmoid function given betatbetafracbetaertt tag beta macrolensing effect beta scale microlensing effect r rate change microlensing effect location change microlensing make simplifying assumption achromatic microlensing microlensing identical across band given image demonstrated goldstein et al huber et al assumption valid first three restframe week lensed sn ia time microlensing predicted largely achromatic model time delay magnification therefore take parameter per image parameter fit doublyimaged system thetaataudeltabetabetataut consider case two image observed one band image observed set n time image observed set n time system matrix equation mbeginpmatrixmathbfmathbfmathsftmathbfboldsymbolbeta mathsft boldsymbolbetamathbfmathsftboldsymbolbetaboldsymbol betamathsftendpmatrix tag mathbf vector one length n boldsymbolbeta vector length n whose jtextth element given betajbetahattjdelta formulation generalizes arbitrary number image observed arbitrary number band refer model constant beta constant magnification model model timevarying magnification term sigmoid magnification model figure demonstrates timevarying magnification term significant impact shape sn light curve point inferred time delay could significantly skewed glsn system fit constant magnification model combined treatment macrolensing microlensing mitigates potential source bias arises magnification effect considered separately explore effect greater detail appendix sampling algorithm within publicly available gausssn framework implement three method sampling posterior distribution emcee affine invariant mcmc ensemble sampler foremanmackey et al goodman weare dynesty nested sampling speagle skilling skilling zeus mcmc ensemble slice sampler karamanis beutler karamanis et al choose sample parameter dynesty analysis paper nested sampling approach best able handle multimodal nature posterior time delay magnification parameter therefore accurate timedelay estimate associated uncertainty opt dynesty within dynesty use uniform sampling multiellipsoidal bounding feroz et al system fewer data point fewer parameter random slice sampling system data point parameter live point slice sampling technique developed neal first implemented within nested sampling framework handley et al retain default stopping criterion dynesty met remaining unaccounted evidence le threshold depends number live point used speagle note specification dynesty sampling sampling method figure effect increase brightness due timevarying magnification term day shape sn light curve upper panel show rband flux unlensed sn ia light curve hsiao et al template blue dashed line microlensed version underlying light curve red solid line emphasize true time delay delta although peak microlensed light curve appears later timevarying magnification term bottom panel show timevarying relative magnification affecting second image boldsymbolbetat easily adjusted within gaussn parameter optimization function given specification gaussn performs follows object total data point ie observation image band single evaluation marginal likelihood take sim m using standard cpu resource desktop computer stopping criterion typically met evaluation likelihood function roughly corresponds nested sampling iteration therefore nested sampling algorithm take minute run object depending quantity quality data sampling may take anywhere hour simulated rubinlsst roman data given rarity glsne even best case scenario future observatory run time barrier future application model real data test simulated data roman simulation data recently pierel et al hereafter p simulated million glsn light curve type ia ibc iin iip expected roman space telescope cadence depth detection threshold simulation based roman sn survey allz strategy described hounsell et al modification made recent survey update based current plan instrument p predicts roman discover glsne z footnote publicly available httpsdxdoiorgtkkwzkhttpsdxdoiorgtkkwzk simulation pipeline work follows sn subclass sample simulated galaxyscale lens used simulate distinct glsn light curve image based structure lens system subject iteration microlensing microlensing map yielding variation glsn light curve p assumes achromatic microlensing individual image experience microlensing effect across wavelength space microlensing map based different choice stellar mass model vary effective radius initial mass function sersic index galaxy profile object required pas series data cut described p simplicity consider doublyimaged glsne p roman simulation fit object constant magnification model sigmoid magnification model constant magnification model use following prior two kernel parameter time delay magnification footnote use mathcaluab denote uniform distribution b mathcaltnmusigmacd denote truncated normal distribution mu sigma mean variance untruncated normal distribution truncated left location c right location simmathcalu tag tau simmathcalutextdays deltahatmathbft simmathcaltnmudeltaminhatmathbft maxhatmathbftmaxhatmathbftminhatmathbft textdays beta simmathcaltnmubetainfty tag mudelta difference time brightest observation image mubeta ratio brightest observation image relative brightest observation image define hatmathbft hatmathbft time observation image respectively prior delta therefore requires always overlap data image data image although scaled flux data maximum value allow prior range overly restrict amplitude underlying light curve adopt wide prior parameter ensure diversity behavior present simulation represented parameter space real glsn event fit individual basis rarity prior adjusted account additional contextual information specific event sigmoid model set following prior three additional magnification parameter beta simmathcaln tag r simmathcaln thatmathbftdelta simmathcaluminhatmathbftdeltamaxhatmathbft delta tag hatmathbft defined equation hatmathbftdelta defined equation analysis individual object basis gp fit data posterior distribution show gaussn effectively accurately inferring time delay glsne system figure demonstrate quality fit light curve level sigmoid magnification model plot observed data draw posterior predictive distribution bottom panel figure show realization magnification function posterior sample notably able constrain relative magnification magnification function show greater uncertainty around beginning end time series region light curve lack overlapping data two image figure show posterior constant magnification fit gaussn recovers delta day capture true time delay day well within credible interval ci dont necessarily expect posterior gaussian calculate ci textth textth percentile posterior sample magnification well recovered gaussn find betapm true beta attribute discrepancy presence microlensing lens substructure indeed uncertainty recovered magnification fitting sigmoid magnification model model gaussn find beta consistent truth uncertainty time delay however increased fitting sigmoid magnification model expected delta represents precision timedelay estimate sigmoid magnification model precision constant magnification model course constant magnification model give statistical uncertainty take consideration systematic uncertainty microlensing separate systematic microlensing error would accounted postprocessing therefore time delay estimate sigmoid magnification model may end precise population level gaussn performs well across subclass sne mass model note true parameter sn iip sc sc mass model available result excluded reported statistic left column figure show distribution deltarm fitdeltarm true sigmoid constant magnification model also compare result sntd included p simulated roman data release constant magnification model find time delay within pm day within pm day within pm day sigmoid magnification model find time delay recovered within pm day recovered within pm day recovered within pm day comparison sntd recovers within pm day within pm day within pm day also consider fractional error deltarm fitdeltarm truedeltarm true timedelay estimate metric give better sense closeness truth scaled size time delay constant magnification model find system fractional error le sigmoid magnification model system fractional error le result comparable sntd result find system fractional error le gaussn therefore effective estimating time delay close absolute fractional value true time delay sigmoid magnification model general truth according metric constant magnification model sntd unexpected model flexibility often leading complex posterior point estimate time delay may truth full posterior give accurate sense timedelay estimate given model right column figure show cdf standardised error deltarm fitdeltarm truesigmadelta distribution sigmoid constant gausssn magnification model sntd unit normal distribution reference uncertainty wellcalibrated expect across sample sne deltarm true fall within ci deltarm true fall within ci although full posterior distribution sntd available compare statistic fraction sne time delay recovered within sigma sigma truth sntd point estimate uncertainty constant magnification model find ci ci sigmoid magnification model find sne deltarm true ci ci sntd sne deltarm true fall sigma ci fall sigma ci statistic meet benchmark set normal distribution comparable slight improvement result sntd therefore gaussn provides timedelay estimate close closer absolute value truth relatively wellcalibrated uncertainty compared sntd leading timedelay estimation technique glsne variation different type sne report statistic broken subclass sn three model table figure corner plot constant magnification fit gisn data shown figure constant magnification model four parameter kernel amplitude kernel length scale tau time delay delta relative magnification b three dashed line posterior distribution plot show th th th percentile left right respectively red line show true time delay relative magnification time delay well recovered precision magnification well recovered potentially indicating additional magnification effect microlensing captured constant magnification model figure example romanlike simulated gisn system fitted sigmoid magnification model first image shown blue second red object z time delay delta day relative magnification beta redshift roman j hbands roughly cover aa rest frame u g rband wavelength regime top three panel show fitted flux data bottom panel figure show fitted sigmoid magnification betatau gaussn seems improved calibration uncertainty compared sntd arise large uncertainty gaussn mean uncertainty time delay day constant magnification model comparable mean uncertainty day sntd day sigmoid magnification model furthermore compare fraction glsns time delay measured certain level precision sigmadeltadeltarm fill le threshold find constant magnification model fitted roman object measured precision sigmadeltadeltarm fill measured precision sigmoid magnification model object measured precision respectively finally sntd measure glsne precision precision median precision constant magnification model sigmoid magnification model sntd result suggest gaussn providing timedelay estimate wellcalibrated uncertainty without compromising precision note glsne deltarm fitdeltarm truesigmadelta sigmoid constant magnification model respectively unsurprising conservative sigmoid magnification treatment fewer catastrophic outlier compared constant magnification model however still exceed rate sigma outlier consistent normal distribution concerningly many outlier particularly constant magnification fit fitted light curve appear convincing based visual inspection likely significant effect microlensing may cause timevarying magnification well described sigmoid function play simulation testing additional parameterizations microlensing using model comparison metric necessary analysis real glsne significant microlensing effect said outlier remain issue cosmological analysis glsne uncertainty due presence outlier propagated analysis additional outlier arise multimodal posterior time delay welldescribed mean standard deviation sample le concern two reason firstly many object informative prior time delay resolve issue careful tailoring prior based visual inspection light curve contextual information possible real glsne due rarity though difficult large scale needed analysis secondly full posterior rather point estimate used cosmological analysis glsn also outlier low snr one image making constraint time delay difficult two type outlier also expected low rate see concern ease identified needing careful treatment furthermore rate outlier inconsistent existing method timedelay estimation reference sntd fit roman simulation deltarm fitdeltarm truesigmadelta gaussn fewer outlier consistent statistic reported table show gaussn uncertainty better calibrated addition method presented kelly et al b show similar rate outlier therefore gaussn meet exceeds benchmark set existing timedelay estimation method together result demonstrate gaussn provides com
Original Title: Filament formation due to diffusive instabilities in dusty
  protoplanetary disks
Original Transcription: # Filament formation due to diffusive instabilities in dusty protoplanetary disks

[

Department of Astronomy, Yale University, New Haven, CT 06511, USA

Min-Kai Lin (LinLin)

Institute of Astronomy and Astrophysics, Academia Sinica, Taipei 10617, Taiwan Physics Division, National Center for Theoretical Sciences, Taipei 10617, Taiwan

[

Institute of Astronomy and Astrophysics, Academia Sinica, Taipei 10617, Taiwan Physics Division, National Center for Theoretical Sciences, Taipei 10617, Taiwan

[

Institute of Astronomy and Astrophysics, Academia Sinica, Taipei 10617, Taiwan Physics Division, National Center for Theoretical Sciences, Taipei 10617, Taiwan

[

Institute of Astronomy and Astrophysics, Academia Sinica, Taipei 10617, Taiwan Physics Division, National Center for Theoretical Sciences, Taipei 10617, Taiwan

###### Abstract

We report the finding of a new, local diffusion instability in a protoplanetary disk, which can operate in a dust fluid, subject to mass diffusion, shear viscosity, and dust-gas drag, provided diffusivity, viscosity, or both decrease sufficiently rapidly with increasing dust surface mass density. We devise a vertically averaged, axisymmetric hydrodynamic model to describe a dense, mid-plane dust layer in a protoplanetary disk. The gas is modeled as a passive component, imposing an effective, diffusion-dependent pressure, mass diffusivity, and viscosity onto the otherwise collisionless dust fluid, via turbulence excited by the gas alone, or dust and gas in combination. In particular, we argue that such conditions are met when the dust-gas mixture generates small-scale turbulence through the streaming instability, as supported by recent measurements of dust mass diffusion slopes in simulations. We hypothesize that the newly discovered instability may be the origin of filamentary features, almost ubiquitously found in simulations of the streaming instability. In addition, our model allows for growing oscillatory modes, which operate in a similar fashion as the axisymmetric viscous overstability in dense planetary rings. However, it remains speculative if the required conditions for such modes can be met in protoplanetary disks.

0000-0002-8181-788]Konstantin Gerbig

0000-0002-4188-7885]Marius Lehmann

## 1 Introduction

Protoplanetary disks are the birthplaces of planets. One key stage within the core-accretion scenario for planet formation involves the conversion of small dust particles into km-sized planetesimals. The formation of planetesimals is associated with a multitude of challenges. Specifically, coagulational growth is thought to be inhibited at around meter sizes by both radial drift and fragmentation of small solids (Birnstiel et al., 2012; Blum, 2018).

For the last two decades, the attention has therefore been directed towards gravitational contraction of sufficiently massive disk regions, particle filaments, or local over-densities. Since the required dust-to-gas ratio are super-solar, one must invoke additional processes that can effectively concentrate dust particles. This includes secular gravitational instability (Ward, 2000; Youdin, 2011; Takahashi and Inutsuka, 2014; Tominaga et al., 2019, 2020, 2023), particle traps such as pressure maxima (Onishi and Sekiya, 2017; Shibaike and Alibert, 2020; Xu and Bai, 2022), turbulent concentration (Chambers, 2010; Hartlep and Cuzzi, 2020), and dust-gas drag instabilities (Johansen et al., 2015; Schafer et al., 2017; Gerbig et al., 2020; Gerbig and Li, 2023), the most prominent of which is the so-called streaming instability (Youdin and Goodman, 2005; Jacquet et al., 2011; Squire and Hopkins, 2018).

In its linear phase, the streaming instability utilizes the relative equilibrium velocity between dust and gas, in the classical picture induced by the background gas pressure gradient, to drive exponentially-growing modes (Youdin and Goodman, 2005). The streaming instability saturates, after a few dynamic timescales, into a quasi-steady-state characterized by turbulent particle density and velocity fluctuations (Johansen and Youdin, 2007). Eventually, this system self-organizes into azimuthally elongated filaments which can drift inwards and merge (see e.g., Yang and Johansen, 2014; Li et al., 2018; Li and Youdin, 2021). The above three-step evolution has been readily observed in 3D shearing-box simulations of both vertically stratified and unstratified protoplanetary disks where drag and dust feedback is included.

The formation of planetesimals within the streaming instability framework requires the additional component of dust self-gravity, and albeit a priori not obvious, is thought to occur during the streaming instability's non-linear phase, either before or after the emergence of the over-dense filaments. The non-linear phase has been investigated numerically on numerous occasions. Specifically, Schreiber and Klahr (2018) found in two-dimensional simulations that dust diffusivities tend to decrease with dust-to-gas ratio. This behavior was also seen in three-dimensional, stratified simulations by Gerbig and Li (2023), and is typically attributed to the particles carrying too much collective inertia to be effectively diffused away by residual gas turbulence, and conversely, the back-reaction of the particles' inertia onto the gas may lead to a decrease in diffusion with increasing dust-to-gas ratio. An alternative picture views particle diffusion similar to gas pressure (a model we aim to discuss thoroughly in this paper): a region of high diffusion expels particles towards regions of low diffusion.

Either way, the implication of particle diffusion decreasing with increasing dust density has hitherto not been investigated analytically in the context of the stability of dusty protoplanetary disks. Previous models by Chen and Lin (2020); Umurhan et al. (2020) had diffusion depend on stopping time and gas viscosity only, both of which are taken to be constant. In this paper, we perform an instability analysis of a sheet of particles, subject to dust-gas drag forces, and mass and momentum diffusion, where the diffusion coefficients are allowed to vary with particle density. The existence of such a dependence has been established in hydrodynamic simulations by Schreiber and Klahr (2018); Gerbig and Li (2023). Our treatment bears thus some similarity to hydrodynamic studies of the viscous instability (Lin and Bodenheimer, 1981; Ward, 1981; Salo and Schmidt, 2010) and viscous overstability (Schmit and Tscharnuter, 1995, 1999; Schmidt et al., 2001; Latter and Ogilvie, 2009, 2010; Lehmann et al., 2017, 2019) in planetary rings.

This paper is structured as follows. We outline our hydrodynamical model, specifically focusing on the diffusion terms and their physical relevance, as well as perform a linear perturbation analysis in Sect. 2. Next, we discuss the arising non-oscillatory and overstable modes in Sects. 3 and 4 respectively. We discuss and contextualize our results in Sect. 5. Lastly, Sect. 6 concludes the paper with a summary of our findings.

## 2 Hydrodynamic model

### Diffusion and viscosity in particle-laden protoplanetary disks

Dust diffusion has long been identified to be of immense importance for dust dynamics and consequently planetesimal formation (see e.g., Cuzzi et al., 1993). We deem it worth explicitly defining for this work the relevant properties terms and putting them into the context of previous studies related to particle diffusion. For a recent comprehensive discussion on turbulent diffusion in protoplanetary disks we refer to Binkert (2023).

Generally speaking, diffusion acts to minimize free energy. In this work, we describe dust as a fluid subject to diffusion of mass, driven by a gradient in dust concentration, and momentum, driven by pressure gradients and shear stresses.

Under typical conditions, dust particles in protoplanetary disks are not collisional, and therefore do not experience collisional pressure forces. Instead, their dynamics are influenced by their coupling to the gas, namely via their stopping time \(t_{\rm s}\), which appears in the drag term of the momentum equation, i.e. \(\mathbf{F}_{\rm d}\propto(\mathbf{v}-\mathbf{u})/t_{\rm s}\), where \(\mathbf{v}\) and \(\mathbf{u}\) are particle and gas velocity respectively. If the gas turbulence were fully characterized by the gas velocities \(\mathbf{u}\), no additional diffusion terms would be needed in modeling dust diffusion in protoplanetary disks. Indeed, numerical simulations typically do not employ explicit diffusivity or viscosity, and instead compute diffusive effects indirectly via dust-gas interaction reflected in \(\mathbf{u}\)(e.g., Yang et al., 2018; Riols et al., 2020). As such a treatment is often not practical for analytical progress, we employ a diffusion subgrid model and describe diffusion and viscosity due to the particles' coupling to the gas by using explicit terms in the hydrodynamical equations.

### Governing equations

Specifically, in this work, we will consider an isothermal, infinitesimally thin, axisymmetric particle disk in the absence of self-gravity, embedded in a gas that enters the system through diffusion, viscosity and drag. In polar coordinates \((r,\phi)\), the system is governed by the set of vertically averaged fluid equations

\[\frac{\partial\Sigma}{\partial t}+\frac{1}{r}\frac{\partial(r \Sigma v_{r})}{\partial r}=\frac{1}{r}\frac{\partial}{\partial r}\left(rD \frac{\partial\Sigma}{\partial r}\right), \tag{1}\] \[\frac{\partial v_{r}}{\partial t}+\left(v_{r}-\frac{D}{\Sigma} \frac{\partial\Sigma}{\partial r}\right)\frac{\partial v_{r}}{\partial r}= \frac{v_{\phi}^{2}}{r}-\Omega^{2}r-\frac{v_{r}-u_{r}}{t_{\rm s}}\] (2) \[-\frac{1}{\Sigma}\frac{\partial(c_{\phi}^{2}\Sigma)}{\partial r} +\frac{1}{\Sigma r}\frac{\partial}{\partial r}\left(rv_{r}D\frac{\partial \Sigma}{\partial r}\right)+F_{r},\] (3) \[\frac{\partial v_{\phi}}{\partial t}+\left(v_{r}-\frac{D}{\Sigma }\frac{\partial\Sigma}{\partial r}\right)\frac{\partial v_{\phi}}{\partial r }=-\frac{v_{\phi}}{r}\left(v_{r}-\frac{D}{\Sigma}\frac{\partial\Sigma}{ \partial r}\right)\] \[-\frac{v_{\phi}-u_{\phi}}{t_{\rm s}}+F_{\phi}.\]

Eqs. (1) to (3) describe the dynamical evolution of the surface mass density \(\Sigma\), the radial velocity \(v_{r}\) and azimuthal velocity \(v_{\phi}\), respectively, where \(\Omega=\sqrt{GM_{*}/r^{3}}\) is the Keplerian angular frequency, with stellar mass \(M_{*}\) and gravitational constant \(G\). The continuity equation (1) takes the form of an advection-diffusion equation, with mass diffusivity for dust \(D\). The momentum equations incorporate advection both by \(v_{r}\) and by the diffusion flux. This leads to the modified gradient advection terms on the left hand sides of the momentum equations, as well as the modified curvature-related advection term on the right hand side of Eq. (3). In addition, the fifth term on the right hand side of Eq. (2) incorporates \(v_{r}\)-advection of the momentum carried in the diffusion flux itself. We refer to Tominaga et al. (2019) for a discussion on these additional advection terms associated with the diffusion flux and their implications when the full dust-gas mixture is considered, but note that they allow the total gas and dust angular momentum to be conserved.

We provide a more rigorous justification for our set of hydrodynamical equations in Appendix A, using mean-field theory based on Reynolds averaging and the application of a set of plausible closure relations. Given this context, the fields \(\Sigma,\mathbf{v}\) should be interpreted as mean fields separated in scale from the underlying small fluctuations that characterize turbulence.

Eq. (2) includes the vertically averaged, effective dust pressure \(P_{\rm d}=\Sigma c_{\rm d}^{2}\), with velocity dispersion \(c_{\rm d}^{2}\) of the dust fluid. Since the dust is assumed to be collisionless, this effective velocity dispersion is assumed to be generated solely by the particles' coupling to the turbulence with \(c_{\rm d}^{2}\propto D\). Specifically, we follow Klahr and Schreiber (2021); Gerbig and Li (2023) and write

\[c_{\rm d}^{2}=\frac{Dc_{\rm s}^{2}}{t_{\rm s}c_{\rm s}^{2}+D}\approx\frac{D}{ t_{\rm s}}, \tag{4}\]

which follows from a balance between diffusion and sedimentation. The latter approximation requires \(D\ll t_{\rm s}c_{\rm s}^{2}\), which is the case in numerical simulations (e.g., Schreiber and Klahr, 2018; Gerbig and Li, 2023). We discuss this pressure model in Appendix B.

Finally, we include explicit momentum diffusion terms, modeled by Navier-Stokes stress terms \(F_{r}\) and \(F_{\phi}\). They can be calculated via

\[\mathbf{F}=\frac{1}{\Sigma}\nabla\cdot T \tag{5}\]

with viscous stress tensor \(T\), the components of which are

\[T_{ij}=\nu\Sigma\left(\frac{\partial v_{i}}{\partial x_{j}}+\frac{\partial v _{j}}{\partial x_{i}}-\frac{2}{3}\delta_{ij}\nabla\cdot\mathbf{v}\right), \tag{6}\]

where \(\nu\) is the effective vertically averaged, kinematic, shear viscosity of the particle fluid. The inclusion of these shear stress terms differentiates Eq. (2) and Eq. (3) from the dust momentum equations used by Tominaga et al. (2019). Our model also distinguishes itself from other works concerning dusty protoplanetary disks on the scales of planetesimal formation as we consider diffusivity \(D\) and viscosity \(\nu\), and consequently via Eq. (4) also the velocity dispersion \(c_{\rm d}\) and dust pressure, to depend on surface mass density \(\Sigma\). Specifically, we assert power law dependencies of the form

\[D \propto\left(\frac{\Sigma}{\Sigma_{0}}\right)^{\beta_{\rm diff}}, \tag{7}\] \[\nu \propto\left(\frac{\Sigma}{\Sigma_{0}}\right)^{\beta_{\rm visc}}, \tag{8}\]

where \(\beta_{\rm diff}\) and \(\beta_{\rm visc}\) are dimensionless exponents. We also introduce the corresponding dimensional slopes

\[\beta_{D} =\frac{\partial(D\Sigma)}{\partial\Sigma}=D(1+\beta_{\rm diff}), \tag{9}\] \[\beta_{\nu} =\frac{\partial(\nu\Sigma)}{\partial\Sigma}=\nu(1+\beta_{\rm visc}). \tag{10}\]

At high dust-to-gas ratios, \(\beta_{\rm D}\) has been found to be negative (Schreiber and Klahr, 2018; Gerbig and Li, 2023). We are not aware of any numerical constraints on \(\beta_{\nu}\) within the context of turbulent diffusion in dusty protoplanetary disks.

### Model applicability

Equations. (1)-(3) can be applied if the combined inertia of the disk is dominated by the particle fluid, for dust-to-gas volume mass density ratios \(\rho_{\rm p}/\rho_{\rm g}\gtrsim 1\). In this case, the presence of the gas can be reduced to perturbations that evoke drag, mass diffusion, and momentum diffusion (aka viscosity). While the analytic model itself is agnostic to the source of diffusion and viscosity, in this paper, we specifically apply it to particle layers in the midplane of a protoplanetary disk, subject to non-linear streaming instability.

Given this context, our model is restricted to radial length scales exceeding the characteristic scale of the underlying turbulence, in this case, the characteristic scale of streaming instability, which for \(\tau_{\rm s}\sim 1\), is of order \(l_{\rm SI}\sim\eta r\)(e.g., Youdin and Goodman, 2005; Squire and Hopkins, 2018; Gerbig et al., 2020), where \(\eta\sim 0.01\) characterizes the radial pressure gradient in the disk, and thus scales with the equilibrium relative velocity between dust and gas. For smaller stopping times, this restriction is relaxed, as the characteristic scale of the linear streaming instability decreases (e.g. Lin and Youdin, 2017, Appendix D). Also note that in the vertical direction, this restriction is formally always satisfied as our model is vertically unstratified, implying a vanishing vertical wavenumber of all modes. Whether or not such modes are supported by an actual vertically stratified dust layer requires a stratified analysis and is thus subject to future work.

We further point out that a fluid description for particles in protoplanetary disks as applied here, is strictly only valid if \(t_{\rm s}<\Omega^{-1}\), since for decoupled grains the dynamical evolution of the stress tensor can, in general, not be ignored (see e.g., Garaud et al., 2004; Jacquet et al., 2011), and must be modeled using a kinetic approach. In this work, we instead assume that the 'external' turbulence is able to establish a simple Newtonian stress-strain relation for the particle fluid, characterized by shear viscosity \(\nu\) and isotropic velocity dispersion \(c_{\rm d}\), as discussed in Sect. 2.2 and Appendix A. This is to some extent similar to the effect of mutual particle collisions in planetary rings, which indeed, if frequent enough, are known to establish a Newtonian stress-strain relation of the particle flow (e.g. Stewart et al., 1984; Shu and Stewart, 1985). However, streaming instability turbulence, which is the main application of our model, is not expected to occur for large stopping times, which withdraws the physical justification for this assumption (at least given this context). In addition, mutual collisions, which are ignored in our model, may in principle become relevant if the velocity dispersion \(c_{\rm d}\propto t_{\rm s}^{-1/2}\) becomes sufficiently small.

Despite these limitations, we will also present and discuss results assuming larger particles with \(t_{\rm s}>\Omega^{-1}\). In doing so, we retain a concrete connection to the viscous instability and overstability in planetary rings. Also, if large grains in protoplanetary disks do experience momentum and mass diffusion by some means (see discussion in Sect. 5.5), our model may still provide useful insights, despite lacking the stress tensor evolution contained in a kinetic approach.

### Linearized equations and dispersion relation

We adopt a local, co-rotating Cartesian reference frame at distance \(R\) from the star such that \((x,y)=(r-R,R(\phi-\Omega t))\) and \(v_{x}=v_{r},v_{y}=v_{\phi}-R\Omega\). We then perturb the system around a background state such that \(\Sigma=\Sigma_{0}+\Sigma^{\prime},v_{x}=v_{x}^{\prime},v_{y}=-q\Omega x+v_{y}^ {\prime}\) with \(\Sigma_{0}=\rm const.\), and linearize in perturbed quantities. Following Appendix B in Klahr and Schreiber (2021), we neglect the perturbed gas velocity \(\mathbf{u}^{\prime}\) such that the linearized drag terms are \(\propto-\mathbf{v}^{\prime}/t_{\rm s}\), which is justified if the mean field quantities derived in Appendix A are time-averaged over one turbulent correlation time. This assumption conveniently decouples dust and gas equations and allows us to isolate the effects of dust density-dependent turbulence alone.

For Keplerian shear where \(q=3/2\), Eqs. (1)-(3) thus become

\[\frac{1}{\Sigma_{0}}\frac{\partial\Sigma^{\prime}}{\partial t}+ \frac{\partial v_{x}^{\prime}}{\partial x}= \frac{1}{\Sigma_{0}}\frac{\partial}{\partial x}\left(D\frac{ \partial\Sigma^{\prime}}{\partial x}\right), \tag{11}\] \[\frac{\partial v_{x}^{\prime}}{\partial t}-2\Omega v_{y}^{\prime}= -\frac{v_{x}^{\prime}}{t_{\rm s}}\] (12) \[-\frac{1}{\Sigma_{0}t_{\rm s}}\frac{\partial(D\Sigma)}{\partial \Sigma}\frac{\partial\Sigma^{\prime}}{\partial x}+\nu\frac{4}{3}\frac{\partial ^{2}v_{x}^{\prime}}{\partial x^{2}},\] \[\frac{\partial v_{y}^{\prime}}{\partial t}+\frac{\Omega v_{x}^{ \prime}}{2}= -\frac{v_{y}^{\prime}}{t_{\rm s}}-\frac{\Omega}{2}\frac{D}{\Sigma_{0}} \frac{\partial\Sigma^{\prime}}{\partial x}\] (13) \[+\nu\frac{\partial^{2}v_{y}^{\prime}}{\partial x^{2}}-\frac{3 \Omega}{2\Sigma_{0}}\frac{\partial(\nu\Sigma)}{\partial\Sigma}\frac{\partial \Sigma^{\prime}}{\partial x}.\]

This set of linearized equations is novel in that it includes a Navier-Stokes viscosity for the particle fluid, relates the particle pressure to diffusion and stopping time via Eq.(4), which produces the second term on the r.h.s. of the radial momentum equation, and takes into account the dependence of diffusion and viscosity on the particle surface mass density, as motivated by simulations of Schreiber and Klahr (2018) and Gerbig and Li (2023). As a consequence, the radial and azimuthal momentum equations respectively contain the slope of diffusion and viscosity with respect to particle surface mass density. Depending on the slope, these terms can act both stabilizing or destabilizing on perturbations to the equilibrium state defined above, as we discuss below. The mass diffusion term in the continuity equation, the terms \(\propto\partial/\partial x^{2}\) (assuming \(\nu>0\)), and the term describing advection of background shear by the diffusion flux (second term on r.h.s of Eq. (3)) are always stabilizing. Note, that this diffusion flux term is the only term from the four angular momentum conserving terms in Eqs. (2) and (3) added by Tominaga et al. (2019) that survives linearization. Notably, it behaves like the fourth term on the right hand side of Eq. (13) containing the viscosity gradient. For the rest of the paper, 'diffusion flux' references this term specifically unless stated otherwise. Lastly, the drag terms have a stabilizing effect. In our analysis, we include both radial and azimuthal drag terms, which is in contrast to Klahr and Schreiber (2021) who drop the azimuthal drag term.

We proceed by introducing axisymmetric modes of the form

\[f^{\prime}=\Re\left(\hat{f}e^{-ikx+nt}\right), \tag{14}\]

with complex frequency \(n\) and (radial) wavenumber \(k\). We take \(k>0\) without loss of generality. Modes grow and decay for \(\Re(n)>0\) and \(\Re(n)<0\) respectively, and \(\Im(n)\) corresponds to the oscillation frequency, the sign of which sets the wave travel direction. We get

\[n\frac{\hat{\Sigma}}{\Sigma_{0}}= ik\hat{v}_{x}-Dk^{2}\frac{\hat{\Sigma}}{\Sigma_{0}}, \tag{15}\] \[n\hat{v}_{x}-2\Omega\hat{v}_{y}= -\frac{\hat{v}_{x}}{t_{\rm s}}+\frac{ik}{t_{\rm s}}\beta_{D}\frac{ \hat{\Sigma}}{\Sigma_{0}}-\frac{4}{3}\nu k^{2}\hat{v}_{x},\] (16) \[n\hat{v}_{y}+\frac{\Omega}{2}\hat{v}_{x}= -\frac{\hat{v}_{y}}{t_{\rm s}}+\frac{ik}{2}D\Omega\frac{\hat{ \Sigma}}{\Sigma_{0}}\] (17) \[-\nu k^{2}\hat{v}_{y}+\frac{3}{2}ik\Omega\beta_{\nu}\frac{\hat{ \Sigma}}{\Sigma_{0}}.\]

This system is solved by a cubic dispersion relation of the form

\[n^{3}+n^{2}a_{2}+na_{1}+a_{0}=0, \tag{18}\]

with coefficients

\[a_{2}= \left(\frac{7}{3}\nu+D\right)k^{2}+\frac{2}{t_{\rm s}}, \tag{19}\] \[a_{1}= \left(\frac{7}{3}D\nu+\frac{4}{3}\nu^{2}\right)k^{4}\] (20) \[+\left(\frac{2D}{t_{\rm s}}+\frac{7}{3}\frac{\nu}{t_{\rm s}}+ \frac{\beta_{D}}{t_{\rm s}}\right)k^{2}\] \[+\frac{1}{t_{\rm s}^{2}}+\Omega^{2}\] \[a_{0}= \left(\frac{4}{3}D\nu^{2}\right)k^{6}+\left(\frac{7}{3}\frac{D\nu }{t_{\rm s}}+\frac{\nu}{t_{\rm s}}\beta_{D}\right)k^{4}\] (21) \[+\left(2D\Omega^{2}+\frac{D}{t_{\rm s}^{2}}+\frac{\beta_{D}}{t_{ \rm s}^{2}}+3\Omega^{2}\beta_{\nu}\right)k^{2}\]

### Dimensionless quantities

It is convenient to write the dispersion relation in terms of commonly used dimensionless quantities. The orbital frequency introduces a time unit, such that we write the dimensionless stopping time as

\[\tau_{\rm s}\equiv t_{\rm s}\Omega, \tag{22}\]

which, in general, is distinct from the so-called Stokes number defined as the ratio of stopping time and turbulent correlation time (also known as eddy time or integral time) (Cuzzi et al., 1993; Youdin & Lithwick, 2007). Particles with \(\tau_{\rm s}\ll 1\) are well-coupled to the gas; while \(\tau_{\rm s}\gg 1\) applies to loosely-coupled dust.

Our reference length unit is the gas pressure scale height, which is the ratio of the (gas) sound speed \(c_{\rm s}\) and orbital frequency, \(H=c_{\rm s}/\Omega\). We write the dimensionless wave number as \(K\equiv kH\). Dimensionless versions for ground state diffusivity in Eq.(7) and viscosity in Eq. (8) are introduced as

\[\delta \equiv\frac{D}{c_{\rm s}H}, \tag{23}\] \[\alpha \equiv\frac{\nu}{c_{\rm s}H}, \tag{24}\]

where we use the same nomenclature as the well-known Shakura Sunyaev \(\alpha\)-parameter (Shakura & Sunyaev, 1973), albeit in our work, \(\alpha\) describes the effective viscosity of the dust fluid, and not the viscosity of the gas that is often adopted to model angular momentum transport in protoplanetary disks. The corresponding power law slopes of diffusivity and viscosity were defined in Eqs. (7) and (8), i.e. \(\beta_{\rm diff}=\partial\ln\delta/\partial\ln\Sigma\) and \(\beta_{\rm visc}=\partial\ln\alpha/\partial\ln\Sigma\) respectively. Typical values for diffusivity and its slope are \(10^{-5}\lesssim\delta\lesssim 10^{-4}\), and \(-3\lesssim\beta_{\rm diff}\lesssim-1\) at high dust-to-gas ratios (Schreiber & Klahr, 2018; Gerbig & Li, 2023). Appropriate constraints on particle viscosity \(\alpha\) are less clear. In resistive simulations of the magneto-rotational instability (Balbus & Hawley, 1991), Yang et al. (2018) measured a shear viscosity of \(\alpha\sim 10^{-4}\) in the gas. However, that value includes (albeit presumably small) contributions from Maxwell stresses, and constitutes an average value throughout the particle layer. We are not aware of any other applicable constraints on \(\alpha\) in the particle layer, or any measurements of \(\beta_{\rm visc}\).

We define the hydrodynamic Schmidt number as the ratio of viscosity and mass diffusion coefficient for our particle fluid, i.e.

\[\mathrm{Sc}\equiv\frac{\alpha}{\delta}, \tag{25}\]

which is analogous to the definition used for pure gas in protoplanetary disks by Johansen & Klahr (2005); Carballido et al. (2006). As pointed out in Youdin & Lithwick (2007), in the context of particles in protoplanetary disks, the Schmidt number suffers from being over-subscribed, as it is also used to describe the ratio of gas viscosity and particle diffusivity (Cuzzi et al., 1993; Schreiber & Klahr, 2018; Binkert, 2023). Here, we are primarily interested in the dust component, hence we assign Sc to characterize the relative importance of particle viscosity and particle diffusivity, both of which stem from the particles' coupling to gas turbulence.

Lastly, we notice that for \(\delta>0\), the dispersion relation includes a degeneracy in wave number and diffusivity, such that we can define

\[\xi\equiv\delta K^{2}=\frac{Dk^{2}}{\Omega}, \tag{26}\]

Note, that since the herein utilized description for dust-pressure is only appropriate for \(\tau_{\rm s}\gg\delta\), we equivalently require \(\xi\ll\tau_{\rm s}K^{2}\). As noted in Sect. 2.3, our model is only appropriate for scales larger than the scale of the under-lying turbulence. We thus require, \(\xi\lesssim 4\pi^{2}\delta/((H/r)^{2}\eta^{2})\). For typical values of \(H/r=0.1\), \(\eta\sim 1\%\), and for fiducial diffusivities of \(\delta\sim 10^{-5}-10^{-4}\), this corresponds to maximum \(\xi\) of order unity. This is why, for the remainder of this study, we will mostly be concerned with the long-wavelength limit where \(\xi<1\).

The dimensionless complex frequency is denoted as

\[\sigma\equiv\frac{n}{\Omega}\equiv\gamma+i\omega, \tag{27}\]

where \(\gamma=\Re(\sigma)\) is the growth rate and \(\omega=\Im(\sigma)\) is the oscillation frequency. The dimensionless version of the cubic dispersion relation in Eq. (18) is given by

\[\sigma^{3}+\sigma^{2}A_{2}+\sigma A_{1}+A_{0}=0, \tag{28}\]

with

\[A_{2}= \left(\frac{7}{3}\text{Sc}+1\right)\xi+\frac{2}{\tau_{\text{s}}}, \tag{29}\] \[A_{1}= \frac{\text{Sc}}{3}\left(7+4\text{Sc}\right)\xi^{2}\] (30) \[+\left(\frac{7}{3}\text{Sc}+3+\beta_{\text{diff}}\right)\frac{ \xi}{\tau_{\text{s}}}+\frac{1}{\tau_{\text{s}}^{2}}+1,\] \[A_{0}= \frac{4}{3}\text{Sc}^{2}\xi^{3}+\frac{\text{Sc}}{\tau_{\text{s}} }\left(\frac{10}{3}+\beta_{\text{diff}}\right)\xi^{2}\] (31) \[+\left[2+\frac{1}{\tau_{\text{s}}^{2}}\left(2+\beta_{\text{diff} }\right)+3\text{Sc}\left(1+\beta_{\text{visc}}\right)\right]\xi,\]

where \(A_{0},A_{1},A_{2}\) are real coefficients. This implies that \(A_{0}<0\) is a sufficient condition for non-oscillatory instability, as then there is at least one real positive root of Eq. (28). The full, complex dispersion relation can also be cast into two equations for the growth rate and oscillation frequency, which need to hold independently:

\[\omega^{3}-3\omega\gamma^{2}-2\omega\gamma A_{2}-\omega A_{1} =0, \tag{32}\] \[\gamma^{3}-3\omega^{2}\gamma-\omega^{2}A_{2}+\gamma^{2}A_{2}+ \gamma A_{1}+A_{0} =0. \tag{33}\]

## 3 Diffusive Instability

This section investigates the diffusive instability associated with the real roots of the dispersion relation in Eq. (28). Consider, however, first the case with zero diffusivity and viscosity, i.e. \(\text{Sc}=0\), \(\xi=0\). In this limit, the above dispersion relation reduces to

\[\sigma\left(\sigma^{2}+\frac{2}{\tau_{\text{s}}}\sigma+\frac{1}{\tau_{\text{s }}^{2}}+1\right)=0, \tag{34}\]

which is solved by damped, epicyclic waves with oscillation frequency \(\Omega\) and negative growth rate \(-t_{\text{s}}^{-1}\). The purely real root is the static null solution with \(\sigma=\gamma=\omega=0\). It is this mode that will get destabilized by diffusion and/or viscosity, as we discuss in the following. As this section is only concerned with the non-oscillatory, purely real solution, we set \(\omega=0\), and replace \(\sigma=\gamma\). We will redirect our attention to oscillatory modes in Sect. 4.

### Inviscid case

We first investigate the purely diffusive case, where \(\text{Sc}=0\). In this limit the dispersion relation can be

Figure 1: Growth rates for the inviscid (\(\text{Sc}=0\)) diffusive instability driven by the diffusion-dependent pressure for \(\xi=0.1\). The black dashed line corresponds to Eq. (36), below which the instability can operate, and above which, perturbations are exponentially damped.

Figure 2: Growth rates for the inviscid (\(\text{Sc}=0\)) diffusive instability driven by the diffusion-dependent pressure for \(\beta_{\text{diff}}=-3\) and various stopping times. The hatched region corresponds to \(\xi>1\), for which our model seizes to be appropriate. Lines for \(\tau_{\text{s}}=10\) and \(\tau_{\text{s}}=100\) overlap.

written as

\[\gamma^{3}+\left(\xi+\frac{2}{\tau_{\rm s}}\right)\gamma^{2}\] \[+\left[(3+\beta_{\rm diff})\,\frac{\xi}{\tau_{\rm s}}+\frac{1}{\tau_ {\rm s}^{2}}+1\right]\gamma \tag{35}\] \[+\xi\left[2+\frac{1}{\tau_{\rm s}^{2}}\left(2+\beta_{\rm diff} \right)\right]=0,\]

which leads to unconditional instability if

\[\beta_{\rm diff}<-2-2\tau_{\rm s}^{2}. \tag{36}\]

For realistic power law slopes of \(\beta_{\rm diff}\gtrsim-3\)(Schreiber and Klahr, 2018; Gerbig and Li, 2023), inviscid (Sc = 0) diffusive instability thus requires \(\tau_{\rm s}\lesssim 1\).

For small growth rates \(\gamma\ll 1\), we find from Eq. (35),

\[\gamma=-\frac{\xi\left[2+\tau_{\rm s}^{-2}(2+\beta_{\rm diff})\right]}{1+\tau _{\rm s}^{-2}+\xi\tau_{\rm s}^{-1}(3+\beta_{\rm diff})}, \tag{37}\]

which for small stopping times equals

\[\gamma\simeq-\xi\left(2+\beta_{\rm diff}\right)\quad(\tau_{\rm s}\ll 1). \tag{38}\]

Fig. 1 shows the growth rate for the inviscid diffusive instability for choices of slope \(\beta_{\rm diff}\) and stopping time \(\tau_{\rm s}\) for modes with \(\xi=0.1\), which for a fiducial \(\delta=10^{-5}\) corresponds to \(K=100\). Note that instability requires \(\beta_{\rm diff}<-2\), which is consistent with the more general condition Eq. 36 in the limit \(\tau_{\rm s}\ll 1\).

Fig. 2 shows the growth rates of the inviscid diffusive instability for \(\beta_{\rm diff}=-3\) for various stopping times. The system is either stable (for \(\tau_{s}\gtrsim 1\)) or unstable (for \(\tau_{s}\lesssim 1\)) for all \(\xi\). In fact, we note that inviscid diffusive instability is not damped at small scales, but displays fastest growth rates at scales \(\xi>1\), which is where our model breaks down, as indicated by the hatched region in Fig. 2.

The physical origin of the inviscid diffusive instability lies in the dust pressure term in Eq. (2). For \(\beta_{\rm diff}<0\), this pressure term acts destabilizing and accelerates particles towards annuli of high density and low diffusivity. If \(\beta_{\rm diff}\) is sufficiently steep for Eq. (36) to hold, i.e. \(\beta_{\rm diff}<-2-2\tau_{\rm s}^{2}\), this pressure forcing can overcome the stabilizing mass diffusion term in Eq. (1) and the drag terms in the momentum equations. This increases the density, in the process further decreasing diffusion, resulting in positive feedback and instability. While in the large stopping time limit, the drag terms vanish, the destabilizing pressure term does too. The only remaining terms are the mass diffusion term in the continuity equation, and the diffusion flux term in Eq. (13), both of which act to repell particles away from density maxima. Hence, the onset of this instability requires that stopping times are small.

### Sc = 1 case

Next, we consider the case where \(D=\nu\), equivalently \(\mathrm{Sc}=1\), such that the equilibrium value of momentum

Figure 4: Like Fig. 2, but for the viscous-diffusive instability assuming equal mass and momentum diffusion with \(\mathrm{Sc}=1\) and \(\beta_{\rm diff}=\beta_{\rm visc}=-3\), for various stopping times. The viscosity terms damp the instability on small scales, albeit only for \(\xi>1\), where we expect the model to break down. Lines for \(\tau_{\rm s}=10\) and \(\tau_{\rm s}=100\) overlap.

Figure 3: Like Fig. 1. Growth rates for the viscous-diffusive instability for \(\xi=0.1\), assuming equal mass and momentum diffusion with \(\mathrm{Sc}=1\) and \(\beta_{\rm diff}=\beta_{\rm visc}\). The black curve corresponds to Eq. (40), below which the instability can operate, and above which perturbations are exponentially damped. Note that while parts of the depicted parameter space allow for viscous overstability, this figure is only showing the purely real solution. See Sect. 4.

diffusion equals that of the mass diffusion, and also the power law slopes of diffusion and viscosity are identical, i.e. \(\beta_{\rm visc}=\beta_{\rm diff}\). Under these assumptions, the dispersion relation is

\[\begin{split}\gamma^{3}+\left(\frac{10}{3}\xi+\frac{2}{\tau_{\rm s }}\right)\gamma^{2}\\ +\left[\frac{11}{3}\xi^{2}+\left(\frac{16}{3}+\beta_{\rm diff} \right)\frac{\xi}{\tau_{\rm s}}+\frac{1}{\tau_{\rm s}^{2}}+1\right]\gamma\\ +\frac{4}{3}\xi^{3}+\left(\frac{10}{3}+\beta_{\rm diff}\right) \frac{\xi^{2}}{\tau_{\rm s}}\\ +\left[5+\frac{2}{\tau_{\rm s}^{2}}+\left(3+\frac{1}{\tau_{\rm s} ^{2}}\right)\beta_{\rm diff}\right]\xi=0.\end{split} \tag{39}\]

Pure instability is achieved if

\[\beta_{\rm diff}<-\frac{4\xi^{2}\tau_{\rm s}^{2}+10\xi\tau_{\rm s}+15\tau_{\rm s }^{2}+6}{3\xi\tau_{\rm s}+9\tau_{\rm s}^{2}+3}. \tag{40}\]

In the long wavelength limit of \(\xi<1\), we recover our finding for the inviscid case where a power law gradient \(\beta_{\rm diff}<-2\) suffices for instability, if stopping times are sufficiently small: \(\tau_{\rm s}\ll 1\). This is because for small stopping times and at large radial length scales, the destabilizing pressure term dominates over the viscosity terms.

For large stopping times of \(\tau_{\rm s}\gg 1\), the explicit drag terms and the pressure term become neglible. In this case, the long wavelength limit \(\xi<1\) yields

\[\beta_{\rm diff}\lesssim-\frac{(4\xi^{2}+15)\tau_{\rm s}+10\xi}{9\tau_{\rm s}+ 3\xi}\approx-\frac{5}{3}. \tag{41}\]

The diffusive instability behaves now analogously to the classical viscous instability (Ward, 1981; Lin & Bodenheimer, 1981), in that the instability is driven by the density slope of shear viscosity that appears in the azimuthal momentum equation (13). If the slope is sufficiently steep, there is a net flux towards density maxima that amplifies the linear perturbation. The criterion for the classical viscous instability is given by \(\beta_{\rm visc}<-1\). Our modification in Eq. (41) is due to the inclusion of the mass diffusion term in the continuity equation (11) and the diffusion flux in Eq. (13). Both of these terms are always stabilizing, and hence the required viscosity slope for diffusive instability driven by viscosity that operates in the \(\tau_{\rm s}\gg 1\) limit is steeper than in the classical case.

It is easy to see in Eq. (31), that if \(\tau_{\rm s}\ll 1\), the slope of mass diffusion will dominate, whereas for \(\tau_{\rm s}\gg 1\), the slope in momentum diffusion will dominate, thus leading to diffusive instability driven by the pressure term and viscosity terms respectively. For marginally coupled particles \(\tau_{\rm s}\sim 1\), the instability can utilize both slopes. Because of this, on large scales \(\xi\lesssim 1\), if \(\beta_{\rm diff}\) is sufficiently negative, the system is unstable regardless of stopping time.

For small growth rates \(\gamma\ll 1\), and for small \(\xi\), the real root of Eq. (39) behaves as

\[\gamma\simeq-\frac{\left[5+2\tau_{\rm s}^{-2}+\left(3+\tau_{\rm s}^{-2}\right) \beta_{\rm diff}\right]\xi}{\tau_{\rm s}^{-1}(16/3+\beta_{\rm diff})\xi+\tau_{ \rm s}^{-2}+1}, \tag{42}\]

which in the limits of well-coupled and decoupled particles equals

\[\gamma\simeq\begin{cases}-\xi\left(2+\beta_{\rm diff}\right)&\tau_{\rm s}\ll 1 \\ -\xi(5+3\beta_{\rm diff})&\tau_{\rm s}\gg 1\end{cases} \tag{43}\]

respectively. We thus recover Eq. (38), in the limit of small stopping times.

Fig. 3 shows the real root of the full cubic in Eq. (39) for \(\xi=0.1\). The black curve corresponds to Eq. (40). For a given \(\beta_{\rm diff}\), growth rates are greater for large stopping times. Fig. 4 depicts the growth rate of the viscous-diffusive instability for \(\beta_{\rm diff}=\beta_{\rm visc}=-3\) for various stopping times. Unlike in the inviscid case, where if Eq. (36) is satisfied, all modes \(\xi\) are unstable (see Fig. 2), the viscous diffusive instability is damped at small scales (\(\xi\gtrsim 1\)) by viscosity. This regularizes the system, by prohibiting growth on arbitrarily small scales. While our model itself is not applicable to large \(\xi\), one does not expect growth rates to increase without bound at ever-decreasing scales, which is an advantage of including viscosity in the model.

### General case

Given that the numerical constraints on the effective viscosity in high-density particle mid-plane of protoplanetary disks are sparse, we finally investigate the most general case our model allows, where we remain agnostic to the value of Sc and retain two independent power law slopes in \(\delta\) and \(\alpha\). As before, pure instability is achieved for \(A_{0}<0\), which for small \(\xi\) results in the condition

\[\frac{1}{\tau_{\rm s}^{2}}\left(2+\beta_{\rm diff}\right)+3{\rm Sc}\left(1+ \beta_{\rm visc}\right)<-2. \tag{44}\]

In the general case, the growth rate of the diffusive instability, as well as the existence thereof in the first place, thus depends on five parameters: the stopping time \(\tau_{\rm s}\), Schmidt number Sc, diffusion slope \(\beta_{\rm diff}\), viscosity slope \(\beta_{\rm visc}\) and dimensionless wave number \(\xi\). The Schmidt number Sc acts as an amplification to the viscosity slope in the context of the diffusive instability.

Like in the previous two cases, well-coupled particles with \(\tau_{\rm s}\ll 1\) result in instability if \(\beta_{\rm diff}<-2-2\tau_{\rm s}^{2}\approx-2\), on account of the diffusive instability. On the other hand, loosely-coupled particles with \(\tau_{\rm s}\gg 1\) are unstable if

\[\beta_{\rm visc}<-\frac{2}{3}{\rm Sc}^{-1}-1. \tag{45}\]

If \({\rm Sc}\gg 1\), we exactly recover the classical criterion for viscous instability in planetary rings (Ward, 1981; Lin & Bodenheimer, 1981).

For pure instability with small growth rates, \(\gamma\ll 1\), Eq. 28 yields \(\gamma=-A_{0}/A_{1}\), which for \(\xi<1\) results in

\[\gamma=-\frac{\xi\left[2+\tau_{\rm s}^{-2}\left(2+\beta_{\rm diff}\right)+3{ \rm Sc}\left(1+\beta_{\rm visc}\right)\right]}{\tau_{\rm s}^{-1}(7{\rm Sc}/3+3+ \beta_{\rm diff})\xi+\tau_{\rm s}^{-2}+1}. \tag{46}\]

In the well-coupled limit \(\tau_{\rm s}\ll 1\), this equals the inviscid case in Eq. (38). In the loosely-coupled limit with \(\tau_{\rm s}\gg 1\), we get

\[\gamma=-\xi\left[2+3{\rm Sc}\left(1+\beta_{\rm visc}\right)\right]\quad(\tau_{ \rm s}\gg 1). \tag{47}\]

## 4 Overstability

We now direct our attention to overstable modes with nonzero \(\omega\). Figure. 5 shows growth rates of such oscillatory modes as obtained from the full dispersion relation, and demonstrates that large stopping times are required to achieve growing modes. We caution that in this regime, the fluid approximation for the dust grains that underlies our model starts to break down (also see Sects. 2.3, 5.5 as well as Appendix A). We proceed with the analysis for completeness.

For oscillating solutions with \(\omega\neq 0\), Eq. (32) implies

\[\omega^{2}=3\gamma^{2}+2\gamma A_{2}+A_{1}, \tag{48}\]

which is positive definite for \(\xi\ll 1\) as seen in Fig. 5. When inserted into (33), this results in a cubic for the growth rate of the wave, i.e.

\[8\gamma^{3}+8A_{2}\gamma^{2}+2\left(A_{1}+A_{2}^{2}\right)\gamma+A_{1}A_{2}-A _{0}=0. \tag{49}\]

For small growth rates \(\gamma\ll 1,A_{1},A_{2}\), the root is

\[\gamma\simeq-\frac{A_{1}A_{2}-A_{0}}{2(A_{1}+A_{2}^{2})}. \tag{50}\]

For \(\xi\ll 1\), we have

\[\gamma\simeq -\Bigg{\{}\frac{2}{\tau_{\rm s}^{3}}+\frac{\xi}{\tau_{\rm s}^{2}} \left(7{\rm Sc}+5+\beta_{\rm diff}\right)+\frac{2}{\tau_{\rm s}} \tag{51}\] \[-\xi\left[1+3{\rm Sc}\left(\frac{2}{9}+\beta_{\rm visc}\right) \right]\Bigg{\}}\] \[\times\left(\frac{10}{\tau_{\rm s}^{2}}+\frac{\xi}{\tau_{\rm s}} \left(\frac{70}{3}{\rm Sc}+14+2\beta_{\rm diff}\right)+2\right)^{-1}.\]

Assuming large stopping times \(\tau_{\rm s}\gg 1\), this becomes

\[\gamma\sim\frac{\xi}{2}\left[1+3{\rm Sc}\left(\frac{2}{9}+\beta_{\rm visc} \right)\right], \tag{52}\]

which is plotted in Fig. 5 in comparison to the root of the full cubic. For overstability, i.e. growing oscillations, the growth rate must be positive, i.e. \(\gamma>0\), or equivalently,

\[\beta_{\rm visc}\gtrsim-\frac{{\rm Sc}^{-1}}{3}-\frac{2}{9}, \tag{53}\]

which equals \(-5/9\) for \({\rm Sc}=1\). Since overstability is characterized by a restoring force which lacks in case of pure instability, this requirement on \(\beta_{\rm visc}\) is opposite in direction compared to the criteria for instability discussed in the previous sections (also compare to the classical viscous overstability e.g., in Latter & Ogilvie (2006a)).

We also note that the 1/Sc term in Eq. (53) originates from advection of angular momentum carried by background shear due to the diffusive flux, i.e. the second term on the right hand side of Eq. (13). For \({\rm Sc}\gg 1\), i.e. negligible diffusion compared to viscosity, this term vanishes and we recover the classical criterion for the viscous overstability in planetary rings (Schmit & Tscharnuter, 1995). Interestingly, it is this same term, that allows for overstability even in the inviscid case. That is, by setting \({\rm Sc}=0\), the growth rate resulting from Eq. (51) becomes

\[\gamma=-\frac{2+\xi\tau_{\rm s}\left(5+\beta_{\rm diff}\right)+2\tau_{\rm s}^{ 2}-\xi\tau_{\rm s}^{3}}{10\tau_{\rm s}+\xi\tau_{\rm s}^{2}\left(14+2\beta_{\rm diff }\right)+2\tau_{\rm s}^{3}}, \tag{54}\]

which tends to \(\gamma=\xi/2\) for large stopping times \(\tau_{\rm s}\gg 1\) (compare to Eq. (52)). Thus, in this limit, the diffusion flux given by the second term on the right hand side of Eq. (13) alone is able to grow epicyclic oscillations.

In Fig. 6, we depict growth rates of the diffusive overstability obtained from Eq. (51) as a function of the stopping time. The smallest scales have fastest growth rates, and, have the least stringent restrictions on stopping time. For the depicted set of parameters, \(\tau_{\rm s}\gtrsim 10\) would lead to overstability on the smallest scales. While this requirement can be further relaxed for larger \({\rm Sc}\) or more positive \(\beta_{\rm visc}\), for \(\tau_{\rm s}\lesssim 1\), all oscillating modes are damped.

For this reason, the overstable modes discussed in this section have little physical relevance in the context of particles that generate streaming instability turbulence, where the largest available dust grains are limited at typically \(\tau_{\rm s}\lesssim 1\)(e.g., Birnstiel et al., 2016). We elaborate on this, as well as explore alternative situations where the diffusive overstability may find applicability in Sect. 5.5.

## 5 Discussion

In the previous sections, we showed that a dust fluid in protoplanetary disks, which is governed by Eqs. (1) --(3) can be unstable (Sect. 3) and over-stable (Sect. 4) when an otherwise constant background state is linearly perturbed, depending on the stopping time of particles and the steepness of the diffusion and viscosity slopes with respect to the dust surface mass density. Here, we discuss and contextualize our findings.

### Physical picture

First, we reiterate the physical mechanisms that drive the newly found instabilities. Figures 7 and 8 show the growth rates of the full system including both overstability and instability, for the inviscid (\(\mathrm{Sc}=0\)) and viscous (\(\mathrm{Sc}=1\)) case respectively. Guided by the depicted parameter space we can broadly assign the unstable regions into four categories

1. _Diffusive instability driven by diffusion-dependent pressure_: For small stopping times, the utilized dust pressure prescription (with velocity dispersion \(c_{\mathrm{d}}^{2}\propto D\propto\Sigma^{\beta_{\mathrm{diff}}}\)) can lead to linear instability if the diffusion slope \(\beta_{\mathrm{diff}}\) is sufficiently negative (see Eqs. (36) and (40)), and drives particles towards density maxima. The instability is only damped on small scales if viscosity is nonzero, and has fastest growth rates on the smallest unstable scales. This instability requires \(\tau_{\mathrm{s}}\lesssim 1\), \(\beta_{\mathrm{diff}}\lesssim-2\), and if \(\mathrm{Sc}\gtrsim 1\) also \(\xi\lesssim 1\), which for a fiducial \(\delta\sim 10^{-5}\) corresponds to wavelengths of \(\lambda\gtrsim 0.01H\). Associated growth rates are shown in the top two panels of Fig. 7 as well the left side of the top panel of Fig. 8 for small stopping times.

Figure 5: Growth rates for diffusive overstability driven by viscosity slope (\(\mathrm{Sc}=1\), left panel) and driven by diffusion slope (\(\mathrm{Sc}=0\), right panel) for various stopping times obtained from the full dispersion relation in Eq. (28). We set \(\beta_{\mathrm{visc}}=\beta_{\mathrm{diff}}=0\) in order to allow for both types of overstability. The dashed lines correspond to Eq. (52), which only do not differ substantially between the two panels due to the choice of \(\beta_{\mathrm{visc}}=0\). The lines end once modes become non-oscillatory (and thus damped), which for large stopping times occurs as \(\xi\) approaches the hatched region where our model is not applicable.

Figure 6: Growth rates for diffusive overstability driven by viscosity slope (\(\mathrm{Sc}=1\)) vs stopping time for various values of \(\xi\); setting \(\beta_{\mathrm{visc}}=\beta_{\mathrm{diff}}=0\) following Eq. (51), which assumes \(\xi\ll 1\). For the smallest scales our model applies to, and, given the chosen set of parameters, stopping times of \(\tau_{\mathrm{s}}\gtrsim 8\) would allow for overstability.

2. _Diffusive instability driven by viscosity slope_: For nonzero viscosity, the viscosity term dominates over the pressure term for sufficiently large stopping times, leading to a version of the viscous instability (Ward, 1981; Lin & Bodenheimer, 1981), modified by mass diffusion and the diffusion flux. This instability requires \(\tau_{\rm s}\gtrsim 1\), \(\mathrm{Sc}\gtrsim 1\), \(\xi\lesssim 1\), \(\beta_{\rm visc}\lesssim-5/3\), and is seen in the top two panels of Fig. 8 for large stopping times.
3. _Diffusive overstability driven by background diffusion flux_: The inclusion of the diffusion flux in Eq. (13), which radially distributes azimuthal momentum carried by the background shear, provides an additional repellent term that can amplify os

Figure 8: Like Fig. 7 but for the viscous-diffusive instability and (modified) viscous overstability with \(\mathrm{Sc}=1\). The top panel shows combination of diffusive instability driven by diffusion-dependent pressure and viscous instability driven by the negative viscosity slope for small and large stopping times respectively (compare to Fig. 3). In the panel second from the top, Eq. (40) remains satisfied, while Eq. (36) is not, so instability is driven by the viscosity slope alone and thus restricted to large \(\tau_{\rm s}\). In the third panel from the top, neither instability is active. When Eq. (53) is satisfied (for \(\mathrm{Sc}=1\) when \(\beta_{\rm visc}\) exceeds \(-5/9\), the (modified) viscous overstability driven by the viscosity slope can be active for large stopping times. Note that for \(\mathrm{Sc}=1\), we do not see the purely diffusive overstability as it is damped by viscosity.

Figure 7: Growth rates for inviscid (\(\mathrm{Sc}=0\)) diffusive instability and overstability. The diffusion slope \(\beta_{\rm diff}\) increases from top to bottom. The diffusive instability driven by diffusion-dependent pressure is active for all modes \(\xi\) if \(\beta_{\rm diff}<-2\,\tau_{\rm s}^{2}\) (see Eq. (36)), which is the case in the upper two panels for small stopping times. For large stopping times, the diffusive overstability driven by the background diffusion flux is active, to first order regardless of the value of \(\beta_{\rm diff}\).

cillatory modes if stopping times are large and viscosity is small. This overstability requires \(\tau_{\rm s}\gtrsim 10\), \({\rm Sc}\ll 1\), and is seen in all panels of Fig. 7, for large stopping times.
4. _Diffusive overstability driven by viscosity slope_: Analogously to the classical viscous overstability (Schmit and Tscharnuter, 1995), the repellent term that amplifies oscillations is provided by a viscosity slope. This overstability requires \(\tau_{\rm s}\gtrsim 10\), \({\rm Sc}\gtrsim 1\), \(\xi\lesssim 1\), and \(\beta_{\rm visc}\gtrsim-5/9\). The associated growth rates are shown in the bottom panel of Fig. 8.

The linear theory describing the diffusive instabilities and overstabilities presented in this work is largely similar to that of the classical viscous instability (Ward, 1981; Lin and Bodenheimer, 1981) and axisymmetric viscous overstability (Schmit and Tscharnuter, 1995) in planetary rings, at least under the neglect of self-gravity and thermal effects, and given the appropriate limits in our model, i.e. \(\tau_{\rm s}\gg 1\), \({\rm Sc}\gg 1\). It should be noted though that the physical origin of viscosity and pressure in planetary rings lies in mutual particle collisions, in contrast to the situation depicted in this work, where it results from self-generated turbulence, that is external insofar as the model is concerned. Also, a 'thin disk' version of the viscous overstability (i.e. on large radial length scales \(\gg H_{g}\)), generated by a constant kinematic shear viscosity, can in principle also exist in gaseous protoplanetary disks (Latter and Ogilvie, 2006).

In addition, we mention the dust-driven viscous ring-instability pioneered by Dullemond and Penzlin (2018) as well as the related instability in Johansen et al. (2011), both of which, although operating on larger scales, are similar in spirit to this paper's diffusive instabilities. They consider a disk where the gas viscosity is set by turbulence generated from magnetorotational instability (Balbus and Hawley, 1991), which weakens with increasing dust density through the ionization fraction. It is the viscous gas disk itself that can now be unstable to linear perturbations: an increase in gas density attracts dust grains as they tend to drift towards gas pressure maxima (e.g. Sano et al., 2000), turbulence weakens and the gas viscosity drops, thereby increasing the gas density further, which attracts more dust, and so on. In our model, we only consider the dust fluid but the decrease in its viscosity, diffusivity, and dust pressure as the dust surface density increases is likewise physically motivated by dust feedback lowering the local diffusive properties of the turbulence generated on small-scales.

Indeed, while we motivate our model with streaming instability turbulence and associated measurements of diffusion slopes (Schreiber and Klahr, 2018; Gerbig and Li, 2023), it may as well be applicable to other sources of turbulence. For example, the azimuthal streaming instability discovered by Hsu and Lin (2022) has likewise been observed to evolve into filaments once linear modes are saturated. Moreover, if one considers pure gas instabilities as sources of turbulence, the vertical shear instability (Urpin and Brandenburg, 1998; Nelson et al., 2013; Lin and Youdin, 2015; Barker and Latter, 2015; Pfeil and Klahr, 2021) or the convective overstability (Klahr and Hubbard, 2014; Lyra, 2014; Latter, 2016) may generate environments suitable for secondary diffusive instabilities. The dependence of diffusivity and viscosity on disk parameters would need to be clarified with detailed simulations, but to zeroth order, one expects a drop in turbulence with increasing dust-loading, similar to that for the magnetorotational instability discussed above, because dust feedback tends to stabilize the vertical shear instability (Lin, 2019; Lehmann and Lin, 2022), and linear convective overstability (Lehmann and Lin, 2023).

### Filament formation through diffusive instability

Based on the analytic findings in Sects. 3 and 4, we hypothesize, that the diffusive instability, driven by a sufficiently negative density dependence of the dust pressure, physically motivated by dust loading reducing diffusivity, may act to amplify density perturbations. These perturbations then could saturate to become marginally

Figure 9: Filament formation shown in a space time diagram of a linear perturbation subject to diffusive instability driven by pressure. For this plot, we chose \({\rm Sc}=0\), \(\tau_{\rm s}=0.1\), \(\beta_{\rm diff}=-3\). We also chose a value of \(\delta=10^{-4}\), and a fast growing mode of \(\xi=0.1\), this corresponds to a physical wave number of \(k=100/H\). The eigenvector is scaled with \(\hat{\Sigma}=0.01\Sigma_{0}\).

stable filaments, as seen in many past simulations (e.g., Johansen & Youdin, 2007; Johansen et al., 2009; Carrera et al., 2015; Klahr & Schreiber, 2016; Yang et al., 2018; Li et al., 2018; Schreiber & Klahr, 2018; Sekiya & Onishi, 2018; Gerbig et al., 2020; Flock & Mignone, 2021; Li & Youdin, 2021; Hsu & Lin, 2022; Gerbig & Li, 2023).

We visualize the growth of the linear perturbations into such filament-like overdensities in a space - time diagram of the perturbed density \(\Sigma^{\prime}\) following Eq. (14). Fig. 9 shows a perturbation subject to diffusive instability. The chosen set of parameters produces overdensities with a radial spacing of about \(0.02H\), which is consistent with the first emergent filaments found in streaming instability simulations (e.g., Li & Youdin, 2021).

Indeed, the diffusive instability has the fastest growth rates on the smallest scale not limited by viscosity \(\xi_{\rm max}\), which is of order \(\xi_{\rm max}\sim 1\). The corresponding fastest growing mode is thus expected to be around

\[\frac{\lambda_{\rm fgm}}{H}=\frac{2\pi}{K}=2\pi\sqrt{\frac{\delta}{\xi_{\rm max }}}\approx 2\pi\sqrt{\delta} \tag{55}\]

For \(\delta\sim 10^{-5}\)(e.g. Schreiber & Klahr, 2018; Klahr & Schreiber, 2020; Gerbig & Li, 2023) this would correspond to a consistent value of \(\lambda_{\rm fgm}\sim 0.02H\)(e.g., Li & Youdin, 2021). Note that, the filament separation in simulations has been found to depend on external gas pressure slope, stopping time, and dust abundance (e.g. Schreiber & Klahr, 2018; Gerbig et al., 2020; Li & Youdin, 2021). If these properties influence streaming instability turbulence (e.g., Johansen & Youdin, 2007), they are expected to map onto diffusivity and ultimately on the fastest growing mode in Eq. (55). On the other hand, the commonly used fiducial value for the filament feeding zone of \(0.2H\)(Yang & Johansen, 2014), cannot be directly compared to the scales of interest, as it already involves post-formation nonlinear dynamics, such as mergers and breakups.

Fig. 11 visualizes the streaming motion that arises from the diffusive instability. Dust is moving towards density maxima which act as particle traps, in the process amplifying the perturbation.

For comparison, Fig. 10 shows traveling waves driven by the diffusive overstability. The shearing sheet is symmetric in \(x\), so waves traveling towards positive \(x\) correspond to the complex conjugate of the depicted solution and are equally valid. Note, that the radial bulk velocity is entirely caused by to the overstability. If one were to include the background pressure gradient, the flow would pick up a to-first-order, constant background drift, which does not affect stability since we can shift into the co-moving frame.

Figure 11: Diffusive instability driven by diffusion-dependent pressure with same parameters as in Fig. 9. Shown is a map in \(x-y\) space of the particle surface density after a time of \(3\Omega^{-1}\), with super-imposed re-scaled velocity vectors \((v_{x}^{\prime},v_{y}^{\prime})\). The fluid motion is towards density maxima, thus amplifying the perturbation and producing filaments. We show the \(y\)-coordinate for better visualization, even though the model itself is axisymmetric.

Figure 10: Like Fig. 9, but for an oscillatory mode. The linear perturbation is subject to diffusive overstability powered by the background diffusion flux. We chose, \(\mathrm{Sc}=0\), \(\tau_{\rm s}=1000\), \(\beta_{\rm diff}=0\), and \(\hat{\Sigma}=0.01\Sigma_{0}\). We took \(\delta=10^{-7}\), at which a mode of \(\xi=0.1\) corresponds to a physical wave number of \(k=1000/H\). Note, that the shearing sheet is symmetric in \(x\), so waves traveling towards positive \(x\) are equally valid.

### Diffusive instability in the context of past numerical simulations

The aim of this study is to present a simple linear model for the emergence of the first filaments out of streaming instability turbulence, as seen in a number of simulations including Schreiber and Klahr (2018); Gerbig et al. (2020); Li and Youdin (2021); Gerbig and Li (2023). Within our model, the required linear growth rates and corresponding required stopping times that are expected to result in filament formation depend on the values of the diffusion and viscosity slopes \(\beta_{\rm diff}\) and \(\beta_{\rm visc}\), respectively. Therefore, we aim to contextualize our findings with existing numerical studies and measurements of the aforementioned slopes. As such, our presented theory can most readily be compared to the numerical results presented in Schreiber and Klahr (2018), who performed two-dimensional, non-axisymmetric, non-selfgravitating shearing sheet simulations of the streaming instability. By conducting a number of simulations at different dust-to-gas ratios and measuring the average particle diffusivity in each simulation, they were able to obtain the slope of diffusion with respect to the dust surface mass density, resulting in values \(-2\lesssim\beta_{\rm diff}\lesssim-1\), where the exact value depended on box size and particle stopping time used in their simulations.

While some of the simulations of Schreiber and Klahr (2018) revealed the emergence of filaments with particle concentrations significantly enhanced relative to the ambient background, most did not. In the context of the linear diffusive instability discovered in our work, which requires \(\beta_{\rm diff}\lesssim-2\) (see Fig. 3) for instability, the simulations in Schreiber and Klahr (2018) are hence expected to be marginally stable. More recently, Gerbig and Li (2023) measured the diffusion slope within a single vertically stratified shearing box simulation of the streaming instability. They also found \(\beta_{\rm diff}\sim-2\). As this value was obtained _after_ the formation of filaments in their simulations, this is also consistent with their simulations being marginally unstable with respect to diffusive instability, provided the saturation of filament growth results in such a marginally-stable state.

### Connection to planetesimal formation

Within the streaming instability paradigm of planetesimal formation, filaments are often thought to be a necessary precursor for planetesimal formation, as they provide the necessary conditions for subsequent self-gravitational fragmentation. It is therefore of interest to compare the parameter space for active diffusive instability within our model to that determined in numerical simulations of planetesimal formation, specifically clumping thresholds in streaming instability simu

Figure 12: Growth rates of diffusive instabilty driven by diffusion-dependent pressure term, depending on metallicity \(Z\) and stopping time \(\tau_{\rm s}\), compared to clumping thresholds in streaming instability simulations by Yang et al. (2017) and Li and Youdin (2021). We associate a given metallicity \(Z\) with the fastest growing, allowed mode \(\xi\) of our model via the recipe discussed in Sect. 5.4 assuming \(\epsilon=1\), \(\lambda_{\rm crit}=0.01H\). For the shown growth rates, we also chose \(\beta_{\rm diff}=\beta_{\rm visc}=-2.2\) and \(\mathrm{Sc}=0\), a favorable set of parameters for diffusive instabilities for small stopping times only.

Figure 13: Like Fig. 12 but now for \(\mathrm{Sc}=1\), which allows for instability driven by the viscosity slope at large stopping times in addition to the instability driven by the diffusion-dependent pressure term. Other parameter choices are identical to those in Fig. 12.

lations. For this purpose, we can relate metallicity \(Z\) to the dust-to-gas ratio \(\epsilon=\rho_{\rm p}/\rho_{\rm g}\) and diffusivity via (e.g., Lin, 2021)

\[Z=\frac{\Sigma}{\Sigma_{\rm g}}\simeq\epsilon\frac{H_{\rm d}}{H}\simeq\epsilon \sqrt{\frac{\delta}{\delta+\tau_{\rm s}}}, \tag{56}\]

where \(H_{\rm d}\) is the vertical scale height of dust.

Assuming \(\tau_{\rm s}\gg\delta\), we have \(\delta\sim\tau_{\rm s}(Z/\epsilon)^{2}\). Since our model, and therefore also the diffusive instability mechanism only implicitly depends on \(\delta\) via \(\xi\), a change in diffusivity due to metallicity increase (decrease) can be compensated by a decrease (increase) in wavenumber \(K\) towards larger (smaller) radial length scales. For example, the typically fast growing mode of \(\xi\sim 1\), would correspond to wave numbers of \(K\sim\epsilon/(Z\sqrt{\tau_{\rm s}})\).

We proceed by imposing a minimum scale of \(\lambda_{\rm crit}\sim 0.01H\), below which the model does not apply (cf. Sect. 2.2), and use this to restrict the maximum allowed \(\xi\), given some value of \(Z\). Specifically, we have

\[\xi_{\rm max}(Z,\tau_{\rm s})=\frac{4\pi^{2}\delta(Z,\tau_{\rm s})}{(\lambda_ {\rm crit}/H)^{2}}\simeq\left(\frac{2\pi Z/\epsilon}{\lambda_{\rm crit}/H} \right)^{2}\tau_{\rm s}. \tag{57}\]

We then assume that the fastest growing mode admitted by our model is given by \(\xi(Z,\tau_{\rm s})=\min(\xi_{\rm fgm},\xi_{\rm max})\), where \(\xi_{\rm fgm}\) is the mathematically fastest growing mode, which is obtained numerically from the full dispersion relation in Eq. (28). \(\xi_{\rm fgm}\) is typically of order unity (see Fig. 2), but may be larger, either in the absence of viscosity or for very small stopping times (see Figs. 2 and 4 respectively); or smaller, if the viscosity slope is only marginally more negative than the critically required slope (see top panel in Fig. 8).

Figures 12 and 13 show the growth rates associated with this preferred mode assuming \(\epsilon=1\), and \(\lambda_{\rm crit}=0.01H\). We also take \(\beta_{\rm diff}=\beta_{\rm visc}=-2.2\) in both Figures. Fig. 12 shows the inviscid case with \({\rm Sc}=0\), where only the diffusive instability driven by diffusion-dependent pressure is possible given the set of parameters, thus suppressing growth for larger stopping times. Over-plotted are the clumping thresholds obtained by Yang et al. (2017) and Li and Youdin (2021) (also see Carrera et al. (2015) for another version), below which, streaming instability clumping is unlikely to occur. If one takes filament formation due to diffusive instability as a precursor to clumping, then the model depicted in Fig. 12 would be inconsistent with the results from aforementioned simulations, as instability only occurs for stopping times \(\tau_{\rm s}\lesssim 0.3\), in contrast to the results of the simulations.

On the other hand, Fig. 13 shows growth rates associated with the same set of parameters, except that now \({\rm Sc}=1\). Now, in principle, particles with any value \(\tau_{\rm s}\lesssim 1\) can be unstable to diffusive instability driven by the viscosity slope, which produces similar growth rates. Thus, in this model, the entire parameter space, probed by the studies Yang et al. (2017) and Li and Youdin (2021) would be subject to diffusive instabilities, rendering the model consistent with the hypothesis that planetesimal formation is triggered by the emergence of filaments induced by diffusive instability.

We note, that the models displayed in Figs. 12 and 13 contain a number of parameters \((\lambda_{\rm crit},\epsilon,\beta_{\rm diff},\beta_{\rm visc},{\rm Sc})\), which we chose relatively freely and assumed to be independent of \(\tau_{\rm s}\) in order to get a prototype idea if there may be a connection to planetesimal formation. The resulting first estimations insinuate that a model which includes viscosity in addition to mass diffusion is more able to explain the threshold for planetesimal formation as determined in simulations, as only then, diffusive instability can also operate for stopping times of \(\tau_{\rm s}\gtrsim 0.3\), in agreement with planetesimal formation in simulations. More detailed calculations, in concert with additional numerical constraints on diffusion and viscosity slopes, are required to further assess diffusion instability's role in planetesimal formation.

### Instability and overstability at large stopping times?

The local axisymmetric viscous overstability of a thin astrophysical disk has extensively been studied in the context of Saturn's dense rings, employing hydrodynamic models (Schmit and Tscharnuter, 1995, 1999; Spahn et al., 2000; Schmidt et al., 2001; Schmidt and Salo, 2003; Latter and Ogilvie, 2009, 2010; Lehmann et al., 2017, 2019), kinetic models (Latter and Ogilvie, 2006, 2008), and N-body simulations (Salo et al., 2001; Rein and Latter, 2013; Ballouz et al., 2017; Lehmann et al., 2017; Mondino-Llermanos and Salo, 2023). Based on results from hydrodynamic and N-body simulations, overstability in Saturn's rings typically saturates in the form of nonlinear traveling wave trains that could in principle carry appreciable amounts of angular momentum. Wave trains are often interspersed by defect structures, which may act as sources or sinks of the former. Indeed, viscous overstability is the most promising mechanism to explain the occurrence of periodic fine structures on a \(\sim 100\)m scale in parts of Saturn's A and B rings, that has directly been observed (Thomson et al., 2007; Colwell et al., 2007; Hedman et al., 2014). It is thus of interest to explore the conditions under which we expect the diffusive overstability to operate in over-dense particle layers in protoplanetary disks.

Since this requires \(\tau_{\rm s}\gtrsim 1\), we preface further discussion, by reiterating that the hydrodynamical model is strictly not applicable for large stopping times, and instead a kinetic model should be used (see Sect. 2.3).

As outlined in Sect. 5.1, in addition to the diffusive instability driven by the pressure term, there are three types of instabilities that can arise for large stopping times. While instability and overstability driven by viscosity slope have specific requirements on \(\beta_{\rm visc}\), the diffusive overstability can operate if \(\mathrm{Sc}\ll 1\) regardless of the value of the diffusion slope \(\beta_{\rm diff}\) (see Fig. 7).

The questions are (a) to what extent the inviscid, hydrodynamic model can still appropriately describe the system for \(\tau_{s}\gtrsim 1\), and whether or not particles with sufficiently large stopping times (b) can exist and (c) are in their turbulent behavior still well characterized by the diffusive flux model that shapes the continuity equation, the pressure model and the angular momentum conserving terms in the momentum equations.

Indeed, in the classical picture of particle growth in protoplanetary disks, stopping times are limited at around \(\tau_{\rm s}\sim 1\)(e.g., Birnstiel et al., 2012, 2016), and as such, individual particles that qualify for diffusive overstability would already be considered planetesimal-sized objects. Another possible pathway of getting objects with large stopping times was suggested by Johansen & Youdin (2007). In an effort to explain unexpected drift rates of particle clumps found in their streaming instability simulations, they hypothesize that a clump may collectively have an increased stopping time relative to the individual grains, due to shielding each other from the gas stream and providing an order-of-magnitude scaling

\[\tau_{\rm s}^{\rm eff}\sim\epsilon\frac{R_{\rm clump}}{\eta r}\frac{\eta r \Omega}{\Delta v}, \tag{58}\]

with \(R_{\rm clump}\) being the clump's radius, and \(\Delta v\) its velocity relative to the gas. While such clumps are far too few in number density to be appropriately modeled by a fluid approach, we adapt this hypothesized collective shielding effect to our situation.

Specifically, applying Johansen & Youdin's argument to the quasi-steady, turbulent dust layer that we envision as the equilibrium, we set \(R_{\rm clump}=H_{\rm d}\), the dust scale height. Then, using \(H_{\rm d}=ZH/\epsilon\) from Eq. (56), we find \(\tau_{\rm s}^{\rm eff}\sim Z/\Pi\), where \(\Pi\equiv\eta/(H/r)\) is the reduced radial pressure gradient parameter, again taking \(\Delta v\sim\eta r\Omega\). The diffusive overstability's requirements of \(\tau_{\rm s}^{\rm eff}\gtrsim 1\) translates to \(Z\gtrsim\Pi\), and the same applies for the diffusive instability driven by viscosity slope. Coincidentally, Bai & Stone (2010) find that clumping via the streaming instability becomes easier with smaller \(\Pi\). Similarly, at fixed \(\tau_{\rm s}\) (the stopping time for individual grains), Sekiya & Onishi (2018) find filament formation in their streaming instability simulations if \(\sqrt{2\pi}Z/\Pi\gtrsim 1\). We can interpret these results within our model as filaments only form if the effective stopping time, realized through \(Z/\Pi\), exceeds unity in order to trigger the diffusive overstability (or the diffusive instability driven by viscosity slope).

The streaming instability formally still operates for \(\tau_{\rm s}\gtrsim 1\) as growth rates only decrease slowly with stopping time (Pan, 2020). However, due to the lack of numerical constraints on diffusivity in this regime, it is unclear to what extent instabilities and overstabilities would develop on scales within our model's validity; even if diffusion and viscosity slopes were to remain unchanged. Since, in order to achieve instability on relevant scales, diffusivities cannot be arbitrarily small, we consider the possibility of diffusion to not be self-generated. Instead, diffusion may stem directly from a turbulent gas, the diffusivity and viscosity of which we denote as \(\delta_{\rm g}\) and \(\alpha_{\rm g}\) respectively.

In the preceding sections, we were exclusively concerned with particle diffusivity \(\delta\), which we treated as wholly independent from \(\tau_{\rm s}\). While this is mathematically self-consistent, it does not necessarily reflect physical conditions. Indeed, an increased particle response time to turbulence diminishes the diffusion experienced by the particles as (Youdin, 2011)

\[\delta=\frac{1+\tau_{\rm s}+4\tau_{\rm s}^{2}}{(1+\tau_{\rm s}^{2})^{2}}\delta _{\rm g}, \tag{59}\]

which reduces to \(\delta\sim\delta_{\rm g}\) for small stopping times, but becomes \(\delta\sim\delta_{\rm g}/\tau_{\rm s}^{2}\) large stopping times. That is, large grains feel a much reduced turbulence than that in the gas.

Consider, for example, gas with a fiducial diffusivity of \(\delta_{\rm g}\sim\alpha_{\rm g}\sim 10^{-3}\), which is a typical value in numerical simulations of vertical shear instability or magnetorotational instability (e.g., Flock et al., 2017). For \(\tau_{\rm s}\sim 10\), this would lead to \(\delta\sim 10^{-5}\), that is comparable to the diffusivities generated by streaming instability with smaller particles. The fastest growing scale per Eq. (55) remains unchanged at \(\sim 0.02H\). Indeed, since the diffusive instabilities discussed in this paper depend on \(\xi=\delta K^{2}\) only, any decrease in diffusivity due to particle response to turbulence would only shift the fastest growing mode down to smaller scales, but not prohibit the mechanism itself from operating.

We thus argue that the large stopping time instability and overstabilities may find applicability, if a big enough collection of large stopping time particles are available in protoplanetary disks, or if the dust layer has a collective stopping time that exceeds unity. Note, that this estimation ignored the effect of the particle layer on gas turbulence, i.e. \(\delta_{\rm g}\) itself. For example, turbulence driven by the vertical shear instability is damped by dust feedback, even when the dust-to-gas ratio is less than unity (e.g., Lin, 2019).

### Caveats and additional considerations

Our vertically averaged model neglects vertical motions. Therefore, inertial waves are discarded, such that the classical, axisymmetric streaming instability is not captured by our model (Squire and Hopkins, 2018), even if we were to include the gas equations with a radial background pressure gradient. While we attribute the underlying turbulence, characterized by diffusion and viscosity of the dust fluid, to the streaming instability (or an equivalent mechanism), filament formation in our model is not a direct result of this underlying, small-scale instability. Instead, it originates from one or more intrinsic large-scale instabilities of the mid-plane dust layer, described by our model. In order to neglect gas perturbations, our model is time-averaged over one turbulent correlation time. As a result, linear modes with frequency smaller than one inverse correlation time should be considered with caution. Future work should include the dynamical equations describing the gas, as well as the vertical dimension, to investigate filament formation via streaming-type instabilities with variable viscosity and diffusivity in a more rigorous manner.

In our model, the diffusion and viscosity slope is assumed to depend on dust surface density only, primarily because of the available numerical constraints from Schreiber and Klahr (2018); Gerbig and Li (2023) and due to the analogy to isothermal hydrodynamic models for viscous instabilities in planetary rings. However, if diffusion and viscosity indeed arise from small-scale streaming instability, other dependencies are conceivable, namely relative dust-gas streaming velocity which powers the streaming instability in the first place.

We also neglect particle self-gravity as filaments already form before self-gravity is turned on in simulations (e.g., Schreiber and Klahr, 2018; Gerbig et al., 2020; Gerbig and Li, 2023). Nonetheless, self-gravity may have importance, modifying instability criteria and growth rates. To first order, it has a destabilizing effect and would amplify density enhancements, as well as permit gravitational instabilities (e.g., Youdin and Shu, 2002; Youdin, 2011; Tominaga et al., 2019; Gerbig et al., 2020; Gerbig and Li, 2023; Tominaga et al., 2023). We reserve this topic for subsequent studies.

Lastly, we also ignored the possibility of a polydisperse dust fluid with a distribution of stopping times, and instead asserted a single stopping time, which is reasonable for a top-heavy size distribution (e.g. Birnstiel et al., 2012). Still, the damping effect of particle size distributions on streaming instability (Krapp et al., 2019; Paardekooper et al., 2020; Zhu and Yang, 2021; Yang and Zhu, 2021) underscores that this is a relevant point to keep in mind in future investigations of diffusive instabilities.

## 6 Summary

In this work we present a novel, vertically averaged axisymmetric hydrodynamic model for a dense particle layer embedded in a gaseous protoplanetary disk. The dust being dominant, we model the effect of gas as a perturbation on the dust dynamics by evoking drag forces, mass diffusion, viscosity, and pressure of the dust. The pressure is assumed to depend on the dust diffusivity following a sedimentation-diffusion ansatz, and diffusivity and viscosity are allowed to depend on the dust-surface mass density. We find that our model supports a variety of linear diffusion and oscillatory instabilities.

The diffusion instabilities arise if the dust particles' diffusion and/or viscosity decrease sufficiently fast with increasing particle surface mass density, which is motivated by the results of past simulations. Specifically, for well-coupled particles with \(\tau_{\rm s}\ll 1\), the diffusion-dependent pressure can destabilize the particle flow if the mass diffusion slope with respect to dust surface mass density is sufficiently negative. On the other hand, for decoupled particles \(\tau_{\rm s}\gtrsim 1\), instability is driven by the viscosity slope, similar to the viscous instability in planetary rings.

The main application of our model is a dense mid-plane particle layer subject to turbulence generated by the streaming instability on small-scales. Indeed, the diffusivities associated with streaming instability turbulence measured in past simulations are found to be sufficient for the diffusive instabilities in our model to possess appreciable growth rates on the order of the dynamical time scale, and radial length scales that are characteristic of over-dense particle filaments seen in numerical simulations of the streaming instability. Based on these findings we argue that diffusive instabilities as captured by our model may play a role in filament formation within dusty protoplanetary disks, which is a key step within the streaming instability paradigm of planetesimal formation.

In addition, our model can also give rise to growing oscillatory modes. In the inviscid case, large stopping times \(\tau_{\rm s}\) can in principle result in overstable modes on a wide range of radial length scales, regardless of the diffusion slope, as the radial diffusion flux alone can provide the necessary repellent acceleration. In the presence of viscosity, this overstability is damped, unless the viscosity slope is sufficiently flat. In this case, the overstabilitybehaves similar to the axisymmetric viscous overstability in planetary rings. Whether or not this instability has applicability in protoplanetary disks is unclear, as it relies strongly on the particles possessing large stopping times \(\tau_{\rm s}>1\), as well as their interaction with the gas turbulence.

More detailed analytical investigations including vertical motions and an explicit inclusion of gas within a two-fluid formalism, accompanied by additional numerical constraints on diffusivity, viscosity, as well as their slopes, will be crucial to further pinpoint the relevance of diffusive instabilities in dusty protoplanetary disk, filament formation therein, and planetesimal formation.

We are appreciative to the reviewer, whose discerning feedback was invaluable in refining the paper. KG thanks Rixin Li, Ryosuke Tominaga, Tiger Lu and Greg Laughlin for efficacious discussions. This work is supported by the National Science and Technology Council through grants 112-2112-M-001-064- and 112-2124-M-002-003- and through an Academia Sinica Career Development Award (AS-CDA-110-M06). NumPy (Harris et al., 2020), Matplotlib (Hunter, 2007), CMasher (van der Velden, 2020).

## Appendix A Justification for chosen hydrodynamic equations

We utilize Reynolds averaging to justify the basic equations used in our model. Hereby, we decompose the instantaneous physical variable \(A\) into average \(\langle A\rangle\) and short-term fluctuation \(\Delta A\) with the property \(\langle\Delta A\rangle=0\).

Consider the continuity equation for surface density,

\[\frac{\partial\Sigma}{\partial t}+\frac{1}{r}\frac{\partial(r\Sigma v_{r})}{ \partial r}=0,\] (A1)

and the radial and azimuthal momentum equations

\[\frac{\partial(\Sigma v_{r})}{\partial t}+\frac{1}{r}\frac{ \partial}{\partial r}(r\Sigma v_{r}^{2})=\Sigma\frac{v_{\phi}^{2}}{r}+\Sigma \Omega^{2}r-\Sigma\frac{v_{r}-u_{r}}{t_{\rm s}},\] (A2) \[\frac{\partial(\Sigma v_{\phi})}{\partial t}+\frac{1}{r}\frac{ \partial}{\partial r}(r\Sigma v_{\phi}v_{r})=-\Sigma\frac{v_{\phi}v_{r}}{r}- \Sigma\frac{v_{\phi}-u_{\phi}}{t_{\rm s}},\] (A3)

respectively, for an axisymmetric dust disk. The left hand side of both momentum equations is the rate of change of the momentum expressed as the sum of Eulerian derivative and advection term. The right hand side of Eq. (A2) includes curvature term, external gravitational potential and drag term. The right hand side of Eq. (A3) includes curvature term and drag term only. Reynolds decomposition and subsequent averaging yields (compare to e.g. Cuzzi et al., 1993; Tominaga et al., 2019)

\[\frac{\partial\langle\Sigma\rangle}{\partial t} +\frac{1}{r}\frac{\partial(r\langle\Sigma\rangle\langle v_{r})}{ \partial r}=-\frac{1}{r}\frac{\partial}{\partial r}r\langle\Delta\Sigma \Delta v_{r}\rangle,\] (A4) \[\langle\Sigma\rangle\frac{\partial\langle v_{r}\rangle}{\partial t} +\frac{\partial}{\partial t}\langle\Delta\Sigma\Delta v_{r} \rangle+\langle\Sigma\rangle\langle v_{r}\rangle\frac{\partial\langle v_{r} \rangle}{\partial r}=\langle\Sigma\rangle\frac{\langle v_{\phi}\rangle^{2}}{r }+\langle\Sigma\rangle\Omega^{2}r-\langle\Sigma\rangle\frac{\langle v_{r} \rangle-\langle u_{r}\rangle}{t_{\rm s}}-\frac{\langle\Delta\Sigma(\Delta v_{ r}-\Delta u_{r})\rangle}{t_{\rm s}}\] (A5) \[+\frac{1}{r}\frac{\partial(r\sigma_{rr})}{\partial r}-\frac{ \sigma_{\phi\phi}}{r}+\frac{2\langle\Delta\Sigma\Delta v_{\phi}\rangle\langle v _{\phi}\rangle}{r}-2\langle\Delta\Sigma\Delta v_{r}\rangle\frac{\partial\langle v _{r}\rangle}{\partial r}-\langle v_{r}\rangle\frac{1}{r}\frac{\partial}{ \partial r}(r\langle\Delta\Sigma\Delta v_{r}\rangle),\] \[\langle\Sigma\rangle\frac{\partial\langle v_{\phi}\rangle}{\partial t} +\frac{\partial}{\partial t}\langle\Delta\Sigma\Delta v_{\phi} \rangle+\langle\Sigma\rangle\langle v_{r}\rangle\frac{\partial\langle v_{\phi }\rangle}{\partial r}=-\langle\Sigma\rangle\frac{\langle v_{r}\rangle \langle v_{\phi}\rangle}{r}-\langle\Sigma\rangle\frac{\langle v_{\phi}\rangle- \langle u_{\phi}\rangle}{t_{\rm s}}-\frac{\langle\Delta\Sigma(\Delta v_{\phi} -\Delta u_{\phi})\rangle}{t_{\rm s}}\] (A6) \[-\langle\Delta\Sigma\Delta v_{r}\rangle\frac{\langle v_{\phi} \rangle}{r}-\frac{1}{r}\frac{\partial}{\partial r}\left(r\langle\Delta\Sigma \Delta v_{\phi}\rangle\langle v_{r}\rangle\right)-\langle\Delta\Sigma\Delta v _{r}\rangle\frac{\partial\langle v_{\phi}\rangle}{\partial r}-\langle\Delta\Sigma \Delta v_{\phi}\rangle\frac{\langle v_{r}\rangle}{r}+\frac{1}{r}\frac{\partial}{ \partial r}(r\sigma_{r\phi})+\frac{\sigma_{r\phi}}{r},\]

where we introduced the components of the Reynolds stress tensor as

\[\sigma_{rr}=-\langle\Sigma\rangle\langle\Delta v_{r}^{2}\rangle- \langle\Delta\Sigma\Delta v_{r}^{2}\rangle,\] (A7) \[\sigma_{\phi\phi}=-\langle\Sigma\rangle\langle\Delta v_{\phi}^{2} \rangle-\langle\Delta\Sigma\Delta v_{\phi}^{2}\rangle,\] (A8) \[\sigma_{r\phi}=-\langle\Sigma\rangle\langle\Delta v_{r}\Delta v_{ \phi}\rangle-\langle\Delta\Sigma\Delta v_{r}\Delta v_{\phi}\rangle.\] (A9)Following Cuzzi et al. (1993) and Tominaga et al. (2019), we ignore the second terms on the left hand side of both momentum equations. We also assume that the terms \(t_{\rm s}^{-1}(\Delta\Sigma(\Delta v_{r}-\Delta u_{r}))\) and \(t_{\rm s}^{-1}(\Delta\Sigma(\Delta v_{\phi}-\Delta u_{\phi}))\) vanish, which is the case if \(\Delta v_{r}=\Delta u_{r}\) and \(\Delta v_{\phi}=\Delta u_{\phi}\) as assumed in Cuzzi et al. (1993) and Tominaga et al. (2019).

Next, we assert the following set of closure relations

\[\langle\Delta\Sigma\Delta v_{r}\rangle =-D\frac{\partial\langle\Sigma\rangle}{\partial r},\] (A10) \[\langle\Delta\Sigma\Delta v_{\phi}\rangle =-\frac{D}{r}\frac{\partial\langle\Sigma\rangle}{\partial\phi}=0,\] (A11) \[\langle\Delta\Sigma\Delta v_{r}^{2}\rangle=\langle\Delta\Sigma \Delta v_{\phi}^{2}\rangle =-T_{rr}=-T_{\phi\phi},\] (A12) \[\langle\Sigma\rangle\langle\Delta v_{r}\Delta v_{\phi}\rangle+ \langle\Delta\Sigma\Delta v_{r}\Delta v_{\phi}\rangle =-T_{r\phi}=-T_{\phi r},\] (A13) \[\langle\Delta v_{r}^{2}\rangle=\langle\Delta v_{\phi}^{2}\rangle =c_{\rm d}^{2}.\] (A14)

Eqs. (A10) and (A11) are the gradient diffusion hypothesis (see Cuzzi et al., 1993; Goodman and Pindor, 2000; Schrapler and Henning, 2004; Shariff and Cuzzi, 2011; Huang and Bai, 2022; Binkert, 2023). Eq. (A14) defines the effective particle velocity dispersion (Cuzzi et al., 1993; Tominaga et al., 2019). Finally, Eqs. (A12) and (A13) employ the Boussinesq hypothesis (also see Binkert, 2023) for the dust fluid and in the process introduce viscosity into the problem via the viscous stress tensor in Eq. (6) -- a choice that relates it to the Reynolds stress tensor components via

\[\sigma_{rr}=-\langle\Sigma\rangle c_{\rm d}^{2}+T_{rr}=\sigma_{ \phi\phi}=-\langle\Sigma\rangle c_{\rm d}^{2}+T_{\phi\phi},\] (A15) \[\sigma_{r\phi}=T_{r\phi}=\sigma_{\phi r}=T_{\phi r}.\] (A16)

The correlations in Eqs. (A12) and (A13) are dropped in Tominaga et al. (2019). For \(\nu=0\), our closure relations are thus identical to theirs. Huang and Bai (2022) additionally drop the pressure term in Eq. (A14).

The closure relations in Eqs. (A10) - (A14) establish a Newtonian stress-strain relation for the particle fluid, in the process removing the need for an evolution equation for the stress tensor. This becomes questionable for \(\tau_{\rm s}>1\), where a kinetic approach is preferred over this fluid dynamical treatment (see Jacquet et al., 2011, and Sect. 2.3).

Using the gradient diffusion hypothesis, the continuity equation can directly be rewritten as an advection-diffusion equation, i.e.

\[\frac{\partial\langle\Sigma\rangle}{\partial t}+\frac{1}{r}\frac{\partial(r \langle\Sigma\rangle\langle v_{r}\rangle)}{\partial r}=\frac{1}{r}\frac{ \partial}{\partial r}\left(rD\frac{\partial\langle\Sigma\rangle}{\partial r} \right).\] (A17)

In the momentum equations, all terms containing \(\langle\Delta\Sigma\Delta v_{\phi}\rangle\) drop due to the axisymmetry. We are left with

\[\langle\Sigma\rangle\frac{\partial\langle v_{r}\rangle}{\partial t }+\langle\Sigma\rangle\langle v_{r}\rangle\frac{\partial\langle v_{r}\rangle }{\partial r} =\langle\Sigma\rangle\frac{\langle v_{\phi}\rangle^{2}}{r}+ \langle\Sigma\rangle\Omega^{2}r-\langle\Sigma\rangle\frac{\langle v_{r} \rangle-\langle u_{r}\rangle}{t_{\rm s}}-\frac{\partial(c_{\rm d}^{2}\langle \Sigma\rangle)}{\partial r}+\langle\Sigma\rangle\tilde{F}_{r},\] (A18) \[\langle\Sigma\rangle\frac{\partial\langle v_{\phi}\rangle}{ \partial t}+\langle\Sigma\rangle\langle v_{r}\rangle\frac{\partial\langle v _{\phi}\rangle}{\partial r} =-\langle\Sigma\rangle\frac{\langle v_{r}\rangle\langle v_{\phi} \rangle}{r}-\langle\Sigma\rangle\frac{\langle v_{\phi}\rangle-\langle u_{ \phi}\rangle}{t_{\rm s}}+\langle\Sigma\rangle\tilde{F}_{\phi},\] (A19)

where we defined

\[\langle\Sigma\rangle\tilde{F}_{r} =\frac{1}{r}\frac{\partial}{\partial r}(rT_{rr})-\frac{T_{\phi \phi}}{r}+\frac{1}{r}\frac{\partial}{\partial r}\left(rD\langle v_{r}\rangle \frac{\partial\langle\Sigma\rangle}{\partial r}\right)+D\frac{\partial\langle \Sigma\rangle}{\partial r}\frac{\partial\langle v_{r}\rangle}{\partial r}.\] (A20) \[\langle\Sigma\rangle\tilde{F}_{\phi} =\frac{1}{r}\frac{\partial}{\partial r}(rT_{r\phi})+\frac{T_{r \phi}}{r}+\frac{\langle v_{\phi}\rangle}{r}D\frac{\partial\langle\Sigma \rangle}{\partial r}+D\frac{\partial\langle\Sigma\rangle}{\partial r}\frac{ \partial\langle v_{\phi}\rangle}{\partial r}.\] (A21)

The first two terms in both equations are just the radial and azimuthal component of the divergence (in cylindrical coordinates) of the viscous stress tensor, respectively, i.e.

\[F_{r} =\frac{1}{\langle\Sigma\rangle}(\nabla\cdot T_{ij})_{r}=\frac{1}{ \langle\Sigma\rangle}\left(\frac{1}{r}\frac{\partial}{\partial r}(rT_{rr})- \frac{T_{\phi\phi}}{r}\right),\] (A22) \[F_{\phi} =\frac{1}{\langle\Sigma\rangle}(\nabla\cdot T_{ij})_{\phi}=\frac{ 1}{\langle\Sigma\rangle}\left(\frac{1}{r}\frac{\partial}{\partial r}(r\sigma_{r \phi})+\frac{\sigma_{r\phi}}{r}\right)\] (A23)The remaining terms in \(\langle\Sigma\rangle\tilde{F}_{\rm r}\) and \(\langle\Sigma\rangle\tilde{F}_{\phi}\) were already derived by Tominaga et al. (2019) and are associated with bulk transport of momentum by the diffusion flux as well as diffusive transport of bulk momentum. We thus can rewrite the momentum equations into the form

\[\begin{split}\langle\Sigma\rangle\frac{\partial\langle v_{r} \rangle}{\partial t}+\left(\langle\Sigma\rangle\langle v_{r}\rangle-D\frac{ \partial\langle\Sigma\rangle}{\partial r}\right)\frac{\partial\langle v_{r} \rangle}{\partial r}=&\langle\Sigma\rangle\frac{\langle v_{\phi} \rangle^{2}}{r}+\langle\Sigma\rangle\Omega^{2}r-\langle\Sigma\rangle\frac{ \langle v_{r}\rangle-\langle u_{r}\rangle}{t_{\rm s}}-\frac{\partial(c_{\rm d }^{2}\langle\Sigma\rangle)}{\partial r}\\ &+\frac{1}{r}\frac{\partial}{\partial r}\left(rD\langle v_{r} \rangle\frac{\partial\langle\Sigma\rangle}{\partial r}\right)+\langle\Sigma \rangle F_{r},\\ \langle\Sigma\rangle\frac{\partial\langle v_{\phi}\rangle}{ \partial t}+\left(\langle\Sigma\rangle\langle v_{r}\rangle-D\frac{\partial \langle\Sigma\rangle}{\partial r}\right)\frac{\partial\langle v_{\phi} \rangle}{\partial r}=&-\frac{\langle v_{\phi}\rangle}{r}\left( \langle\Sigma\rangle\langle v_{r}\rangle-D\frac{\partial\langle\Sigma \rangle}{\partial r}\right)-\langle\Sigma\rangle\frac{\langle v_{\phi} \rangle-\langle u_{\phi}\rangle}{t_{\rm s}}+\langle\Sigma\rangle F_{\phi}. \end{split}\] (A24)

Dividing by \(\langle\Sigma\rangle\) leads to Eqs. (2) and (3). For clarity we omit the brackets \(\langle\rangle\) in the paper main text. Note, that unlike Klahr & Schreiber (2021), we specifically keep the drag term in the azimuthal momentum equation.

## Appendix B Dust Pressure Model

Appendix A uses Reynolds averaging to derive a pressure-like force term of the form \(\partial P/\partial r\) in the radial momentum equation, where \(P=c_{\rm d}^{2}\Sigma\) can be understood as the effective dust pressure, with velocity dispersion \(c_{\rm d}\), which we allow to vary with density.

Specifically, following Klahr & Schreiber (2021), we employ a sedimentation-diffusion ansatz to model the dependence of the dust velocity dispersion on the diffusivity. The heuristic argument is to compare the settling time under linear gravity at terminal velocity \(t_{\rm set}=1/(t_{\rm s}\Omega^{2})\) with the diffusion time \(t_{\rm diff}=1/(Dk^{2})\) across a length scale \(\sim 1/k\), where \(D\) is the mass diffusion coefficient of dust. Similar to Brownian motion (Einstein, 1905), sedimentation-diffusion equilibrium1 leads to \(D/t_{\rm s}=\Omega^{2}/k^{2}\equiv c_{\rm d}^{2}\). The regularized expression, that does not diverge in the limit of \(\tau_{\rm s}=0\), requires consideration of the gas also, leading to a dust layer thickness of \(H_{\rm d}=\sqrt{\delta/(\delta+\tau_{\rm s})}H\)(see e.g., Lin, 2021). We define the effective particle velocity dispersion via

Footnote 1: Note, that this same argument can be made in the radial direction by replacing stellar vertical gravity with the restoring force from radial epicyclic oscillations as \(-\Omega^{2}x\).

\[c_{\rm d}\equiv\Omega H_{\rm d}=\sqrt{\frac{\delta}{\delta+\tau_{\rm s}}}c_{ \rm s}=\sqrt{\frac{D}{D+t_{\rm s}c_{\rm s}^{2}}}c_{\rm s}.\] (B26)

As also noted by Klahr & Schreiber (2021), the sedimentation-diffusion velocity dispersion \(c_{\rm d}\) and thus our closure relation, is in general different to the root mean square (RMS) velocity of the particles. The Hinze-Tchen formalism for turbulent transport neglecting orbital oscillations or other external forces (Tchen, 1947; Hinze, 1959), gives the RMS velocity as (also see e.g., Fan & Zhu, 1998; Youdin & Lithwick, 2007; Binkert, 2023)

\[v_{\rm rms}^{2}=\frac{t_{\rm c}}{t_{\rm c}+t_{\rm s}}u_{\rm rms}^{2}\] (B27)

with gas velocity dispersion \(u_{\rm rms}\), and correlation time of the turbulence \(t_{\rm c}\), which connect to the gas diffusivity \(D_{\rm g}\) via \(D_{\rm g}=t_{\rm c}u_{\rm rms}^{2}\). Only if \(D_{\rm g}\sim D\)(see Eq. (59)) and for \(t_{\rm s}\gg t_{\rm c}\), the RMS velocity equals the velocity dispersion following from the sedimentation diffusion ansatz. While the former is fairly well grounded in numerical simulations (e.g., Schreiber & Klahr, 2018), the latter is somewhat more ambigous. For Kolmogorov turbulence, the correlation time equals the turnover time of the largest eddies, which in protoplanetary disks equals \(\Omega^{-1}\)(Youdin & Lithwick, 2007). On the other hand, Schreiber & Klahr (2018) find for simulations values with active streaming instability values of \(t_{\rm c}\sim 0.1\Omega^{-1}\). Indeed, ignoring orbital oscillations is only a good model if \(t_{\rm s},t_{\rm c}\ll 1\). For larger particles, epicyclic oscillations are important, particles can decouple from the turbulence, and the velocity dispersion and thus diffusion needs to be modified (see Youdin & Lithwick, 2007; Youdin, 2011, and also Eq. (59)). We neglect this effect in this work. While our pressure term does vanishes for large stopping times like the prescriptions used by e.g., Youdin (2011); Umurhan et al. (2020), the diffusivity itself does not, and is instead treated as an independent parameter. This is important to be kept in mind when evaluating our model in particular in the large stopping time limit.

Klahr & Schreiber (2021) call \(c_{\rm d}\) the pseudo sound speed, which is appropriate as long as \(c_{\rm d}\) is constant. In our work, we allow the diffusivity to depend on density, and thus \(c_{\rm d}^{2}\propto D\propto\Sigma^{\beta_{\rm diff}}\). As a result, the dust pressure takes the form of a polytropic equation of state, i.e. \(P_{\rm d}\propto\Sigma^{1+\beta_{\rm diff}}\). One can can now formally define a dust sound speed \(a_{\rm d}\) via

\[a_{\rm d}^{2}=\frac{\partial P}{\partial\Sigma}\propto(1+\beta_{\rm diff})\Sigma^ {\beta_{\rm diff}}.\] (B28)

If \(\beta_{D}<-1\), this effective squared sound speed is negative and as a result also the associated pressure perturbations. Indeed, such a negative pressure perturbation is a necessary (but not sufficient) requirement for the diffusion-dependent pressure driven diffusive instability that may operate for \(\tau_{\rm s}\lesssim 1\), as discussed in this paper.

## References

* Bai & Stone (2010) Bai, X.-N., & Stone, J. M. 2010, ApJ, 722, L220, doi: 10.1088/2041-8205/722/220
* Balbus & Hawley (1991) Balbus, S. A., & Hawley, J. F. 1991, ApJ, 376, 214, doi: 10.1086/170270
* Ballouz et al. (2017) Ballouz, R.-L., Richardson, D. C., & Morishima, R. 2017, AJ, 153, 146, doi: 10.3847/1538-3881/aa60be
* Barker & Latter (2015) Barker, A. J., & Latter, H. N. 2015, MNRAS, 450, 21, doi: 10.1093/mnras/stv640
* Binkert (2023) Binkert, F. 2023, arXiv e-prints, arXiv:2306.06103, doi: 10.48550/arXiv.2306.06103
* Birnstiel et al. (2016) Birnstiel, T., Fang, M., & Johansen, A. 2016, SSRv, 205, 41, doi: 10.1007/s11214-016-0256-1
* Birnstiel et al. (2012) Birnstiel, T., Klahr, H., & Ercolano, B. 2012, A&A, 539, A148, doi: 10.1051/0004-6361/201118136
* Blum (2018) Blum, J. 2018, SSRv, 214, 52, doi: 10.1007/s11214-018-0486-5
* Carballido et al. (2006) Carballido, A., Fromang, S., & Papaloizou, J. 2006, MNRAS, 373, 1633, doi: 10.1111/j.1365-2966.2006.11118.x
* Carrera et al. (2015) Carrera, D., Johansen, A., & Davies, M. B. 2015, A&A, 579, A43, doi: 10.1051/0004-6361/201425120
* Chambers (2010) Chambers, J. E. 2010, Icarus, 208, 505, doi: 10.1016/j.icarus.2010.03.004
* Chen & Lin (2020) Chen, K., & Lin, M.-K. 2020, ApJ, 891, 132, doi: 10.3847/1538-4357/ab76ca
* Colwell et al. (2007) Colwell, J. E., Esposito, L. W., Sremcevic, M., Stewart, G. R., & McClintock, W. E. 2007, "Icarus", 190, 127, doi: 10.1016/j.icarus.2007.03.018
* Cuzzi et al. (1993) Cuzzi, J. N., Dobrovolskis, A. R., & Champney, J. M. 1993, Icarus, 106, 102, doi: 10.1006/icar.1993.1161
* Dullemond & Penzlin (2018) Dullemond, C. P., & Penzlin, A. B. T. 2018, A&A, 609, A50, doi: 10.1051/0004-6361/201731878
* Einstein (1905) Einstein, A. 1905, Annalen der Physik, 322, 549, doi: 10.1002/andp.19053220806
* Fan & Zhu (1998) Fan, L., & Zhu, C. 1998, Principles of Gas-Solid Flows, Cambridge Series in Chemical Engineering No. v. 1 (Cambridge University Press). [https://books.google.com/books?id=zqUQBT2fMUYC](https://books.google.com/books?id=zqUQBT2fMUYC)
* Flock & Mignone (2021) Flock, M., & Mignone, A. 2021, A&A, 650, A119, doi: 10.1051/0004-6361/202040104
* Flock et al. (2017) Flock, M., Nelson, R. P., Turner, N. J., et al. 2017, ApJ, 850, 131, doi: 10.3847/1538-4357/aa943f
* Garaud et al. (2004) Garaud, P., Barriere-Fouchet, L., & Lin, D. N. C. 2004, ApJ, 603, 292, doi: 10.1086/381385
* Gerbig & Li (2023) Gerbig, K., & Li, R. 2023, ApJ, 949, 81, doi: 10.3847/1538-4357/acca1a
* Gerbig et al. (2020) Gerbig, K., Murray-Clay, R. A., Klahr, H., & Baehr, H. 2020, ApJ, 895, 91, doi: 10.3847/1538-4357/ab8d37
* Goodman & Pindor (2000) Goodman, J., & Pindor, B. 2000, Icarus, 148, 537, doi: 10.1006/icar.2000.6467
* Harris et al. (2020) Harris, C. R., Millman, K. J., van der Walt, S. J., et al. 2020, Nature, 585, 357, doi: 10.1038/s41586-020-2649-2
* Hartlep & Cuzzi (2020) Hartlep, T., & Cuzzi, J. N. 2020, ApJ, 892, 120, doi: 10.3847/1538-4357/ab76c3
* Hedman et al. (2014) Hedman, M. M., Nicholson, P. D., & Salo, H. 2014, AJ, 148, 15. [https://arxiv.org/abs/1404.6440](https://arxiv.org/abs/1404.6440)
* Hinze (1959) Hinze, J. 1959, Turbulence: An Introduction to Its Mechanism and Theory, McGraw-Hill series in mechanical engineering (McGraw-Hill). [https://books.google.com/books?id=L9Rop-BtAHoC](https://books.google.com/books?id=L9Rop-BtAHoC)
* Hsu & Lin (2022) Hsu, C.-Y., & Lin, M.-K. 2022, ApJ, 937, 55, doi: 10.3847/1538-4357/ac8df9
* Huang & Bai (2022) Huang, P., & Bai, X.-N. 2022, ApJS, 262, 11, doi: 10.3847/1538-4365/ac76cb
* Hunter (2007) Hunter, J. D. 2007, Computing in Science & Engineering, 9, 90, doi: 10.1109/MCSE.2007.55
* Jacquet et al. (2011) Jacquet, E., Balbus, S., & Latter, H. 2011, MNRAS, 415, 3591, doi: 10.1111/j.1365-2966.2011.18971.x
* Johansen et al. (2011) Johansen, A., Kato, M., & Sano, T. 2011, in Advances in Plasma Astrophysics, ed. A. Bonanno, E. de Gouveia Dal Pino, & A. G. Kosovichev, Vol. 274, 50-55, doi: 10.1017/S1743921311006569
* Johansen & Klahr (2005) Johansen, A., & Klahr, H. 2005, ApJ, 634, 1353, doi: 10.1086/497118
* Johansen et al. (2015) Johansen, A., Mac Low, M.-M., Lacerda, P., & Bizzarro, M. 2015, Science Advances, 1, 1500109, doi: 10.1126/sciadv.1500109
* Johansen & Youdin (2007) Johansen, A., & Youdin, A. 2007, ApJ, 662, 627, doi: 10.1086/516730Johansen, A., Youdin, A., & Mac Low, M.-M. 2009, ApJ, 704, L75, doi: 10.1088/0004-637X/704/2/L75
* Klahr & Hubbard (2014) Klahr, H., & Hubbard, A. 2014, ApJ, 788, 21, doi: 10.1088/0004-637X/788/1/21
* Klahr & Schreiber (2016) Klahr, H., & Schreiber, A. 2016, in Asteroids: New Observations, New Models, ed. S. R. Chesley, A. Morbidelli, R. Jedicke, & D. Farnocchia, Vol. 318, 1-8, doi: 10.1017/S1743921315010406
* Klahr & Schreiber (2020) Klahr, H., & Schreiber, A. 2020, ApJ, 901, 54, doi: 10.3847/1538-4357/abac58
* Klahr & Schreiber (2021) --. 2021, ApJ, 911, 9, doi: 10.3847/1538-4357/abca9b
* Krapp et al. (2019) Krapp, L., Benitez-Llambay, P., Gressel, O., & Pessah, M. E. 2019, ApJ, 878, L30, doi: 10.3847/2041-8213/ab2596
* Latter (2016) Latter, H. N. 2016, MNRAS, 455, 2608, doi: 10.1093/mnras/stv2449
* Latter & Ogilvie (2006a) Latter, H. N., & Ogilvie, G. I. 2006a, MNRAS, 372, 1829, doi: 10.1111/j.1365-2966.2006.11014.x
* Latter & Ogilvie (2006b) --. 2006b, Icarus, 184, 498, doi: 10.1016/j.icarus.2006.05.015
* Latter & Ogilvie (2008) --. 2008, Icarus, 195, 725, doi: 10.1016/j.icarus.2008.02.001
* Latter & Ogilvie (2009) --. 2009, Icarus, 202, 565. [https://arxiv.org/abs/0904.0143](https://arxiv.org/abs/0904.0143)
* Latter & Ogilvie (2010) --. 2010, Icarus, 210, 318. [https://arxiv.org/abs/1006.3419](https://arxiv.org/abs/1006.3419)
* Lehmann & Lin (2022) Lehmann, M., & Lin, M. K. 2022, A&A, 658, A156, doi: 10.1051/0004-6361/202142378
* Lehmann & Lin (2023) Lehmann, M., & Lin, M.-K. 2023, MNRAS, 522, 5892, doi: 10.1093/mnras/stad1349
* Lehmann et al. (2017) Lehmann, M., Schmidt, J., & Salo, H. 2017, apj, 851, 125, doi: 10.3847/1538-4357/aa97de
* Lehmann et al. (2019) --. 2019, A&A, 623, A121, doi: 10.1051/0004-6361/201833613
* Li & Youdin (2021) Li, R., & Youdin, A. N. 2021, ApJ, 919, 107, doi: 10.3847/1538-4357/ac0e9f
* Li et al. (2018) Li, R., Youdin, A. N., & Simon, J. B. 2018, ApJ, 862, 14, doi: 10.3847/1538-4357/aaca99
* Lin & Bodenheimer (1981) Lin, D. N. C., & Bodenheimer, P. 1981, ApJ, 248, L83, doi: 10.1086/183629
* Lin (2019) Lin, M.-K. 2019, MNRAS, 485, 5221, doi: 10.1093/mnras/stz701
* Lin & Youdin (2021) --. 2021, ApJ, 907, 64, doi: 10.3847/1538-4357/abcd9b
* Lin & Youdin (2015) Lin, M.-K., & Youdin, A. N. 2015, ApJ, 811, 17, doi: 10.1088/0004-637X/811/1/17
* Lin & Stewart (2017) --. 2017, ApJ, 849, 129, doi: 10.3847/1538-4357/aa92cd
* Lyra (2014) Lyra, W. 2014, ApJ, 789, 77, doi: 10.1088/0004-637X/789/1/77
* Mondino-Llermanos & Salo (2023) Mondino-Llermanos, A. E., & Salo, H. 2023, MNRAS, doi: 10.1093/mnras/stad500
* Nelson et al. (2013) Nelson, R. P., Gressel, O., & Umurhan, O. M. 2013, MNRAS, 435, 2610, doi: 10.1093/mnras/stt1475
* Onishi & Sekiya (2017) Onishi, I. K., & Sekiya, M. 2017, Earth, Planets and Space, 69, 50, doi: 10.1186/s40623-017-0637-z
* Paardekooper et al. (2020) Paardekooper, S.-J., McNally, C. P., & Lovascio, F. 2020, MNRAS, 499, 4223, doi: 10.1093/mnras/staa3162
* Pan (2020) Pan, L. 2020, ApJ, 898, 8, doi: 10.3847/1538-4357/aba046
* Pfeil & Klahr (2021) Pfeil, T., & Klahr, H. 2021, ApJ, 915, 130, doi: 10.3847/1538-4357/ac0054
* Rein & Latter (2013) Rein, H., & Latter, H. N. 2013, MNRAS, 431, 145, doi: 10.1093/mnras/stt152
* Riols et al. (2020) Riols, A., Lesur, G., & Menard, F. 2020, A&A, 639, A95, doi: 10.1051/0004-6361/201937418
* Salo & Schmidt (2010) Salo, H., & Schmidt, J. 2010, Icarus, 206, 390, doi: 10.1016/j.icarus.2009.07.038
* Salo et al. (2001) Salo, H., Schmidt, J., & Spahn, F. 2001, Icarus, 153, 295
* Sano et al. (2000) Sano, T., Miyama, S. M., Umebayashi, T., & Nakano, T. 2000, ApJ, 543, 486, doi: 10.1086/317075
* Schafer et al. (2017) Schafer, U., Yang, C.-C., & Johansen, A. 2017, A&A, 597, A69, doi: 10.1051/0004-6361/201629561
* Schmidt & Salo (2003) Schmidt, J., & Salo, H. 2003, Physical Review Letters, 90, 061102
* Schmidt et al. (2001) Schmidt, J., Salo, H., Spahn, F., & Petzschmann, O. 2001, Icarus, 153, 316, doi: 10.1006/icar.2001.6679
* Schmit & Tscharnuter (1995) Schmit, U., & Tscharnuter, W. 1995, Icarus, 115, 304
* Schmit & Tscharnuter (1999) --. 1999, Icarus, 138, 173
* Schrapler & Henning (2004) Schrapler, R., & Henning, T. 2004, ApJ, 614, 960, doi: 10.1086/423831
* Schreiber & Klahr (2018) Schreiber, A., & Klahr, H. 2018, ApJ, 861, 47, doi: 10.3847/1538-4357/aac3d4
* Sekiya & Onishi (2018) Sekiya, M., & Onishi, I. K. 2018, ApJ, 860, 140, doi: 10.3847/1538-4357/aac4a7
* Shakura & Sunyaev (1973) Shakura, N. I., & Sunyaev, R. A. 1973, A&A, 24, 337
* Shariff & Cuzzi (2011) Shariff, K., & Cuzzi, J. N. 2011, ApJ, 738, 73, doi: 10.1088/0004-637X/738/1/73
* Shibaike & Alibert (2020) Shibaike, Y., & Alibert, Y. 2020, A&A, 644, A81, doi: 10.1051/0004-6361/202039086
* Shu & Stewart (1985) Shu, F. H., & Stewart, G. R. 1985, Icarus, 62, 360
* Spahn et al. (2000) Spahn, F., Schmidt, J., Petzschmann, O., & Salo, H. 2000, Icarus, 145, 657
* Squire & Hopkins (2018) Squire, J., & Hopkins, P. F. 2018, MNRAS, 477, 5011, doi: 10.1093/mnras/sty854
* Stewart et al. (1984) Stewart, G. R., Lin, D. N. C., & Bodenheimer, P. 1984, in Planetary Rings, ed. R. Greenberg & A. Brahic (Tucson Arizona: Univ. of Arizona Press), 447-512
* Takahashi & Inutsuka (2014) Takahashi, S. Z., & Inutsuka, S.-i. 2014, ApJ, 794, 55, doi: 10.1088/0004-637X/7* Thomson et al. (2007) Thomson, F. S., Marouf, E. A., Tyler, G. L., French, R. G., & Rappoport, N. J. 2007, GRL, 34, 24203
* Tominaga et al. (2023) Tominaga, R. T., Inutsuka, S.-i., & Takahashi, S. Z. 2023, arXiv e-prints, arXiv:2303.15607, doi: 10.48550/arXiv.2303.15607
* Tominaga et al. (2019) Tominaga, R. T., Takahashi, S. Z., & Inutsuka, S.-i. 2019, ApJ, 881, 53, doi: 10.3847/1538-4357/ab25ea
* Tominaga et al. (2020) --. 2020, ApJ, 900, 182, doi: 10.3847/1538-4357/abad36
* Umurhan et al. (2020) Umurhan, O. M., Estrada, P. R., & Cuzzi, J. N. 2020, ApJ, 895, 4, doi: 10.3847/1538-4357/ab899d
* Urpin & Brandenburg (1998) Urpin, V., & Brandenburg, A. 1998, MNRAS, 294, 399, doi: 10.1046/j.1365-8711.1998.01118.x
* van der Velden (2020) van der Velden, E. 2020, The Journal of Open Source Software, 5, 2004, doi: 10.21105/joss.02004
* Ward (1981) Ward, W. R. 1981, 8, 641
* Ward (2000) Ward, W. R. 2000, in Origin of the Earth and Moon, ed. R. M. Canup, K. Righter, & et al., 75-84
* Xu & Bai (2022) Xu, Z., & Bai, X.-N. 2022, ApJ, 937, L4, doi: 10.3847/2041-8213/ac8diff
* Yang & Johansen (2014) Yang, C.-C., & Johansen, A. 2014, ApJ, 792, 86, doi: 10.1088/0004-637X/792/2/86
* Yang et al. (2017) Yang, C.-C., Johansen, A., & Carrera, D. 2017, A&A, 606, A80, doi: 10.1051/0004-6361/201630106
* Yang et al. (2018) Yang, C.-C., Mac Low, M.-M., & Johansen, A. 2018, ApJ, 868, 27, doi: 10.3847/1538-4357/aae7d4
* Yang & Zhu (2021) Yang, C.-C., & Zhu, Z. 2021, MNRAS, 508, 5538, doi: 10.1093/mnras/stab2959
* Youdin (2011) Youdin, A. N. 2011, ApJ, 731, 99, doi: 10.1088/0004-637X/731/2/99
* Youdin & Goodman (2005) Youdin, A. N., & Goodman, J. 2005, The Astrophysical Journal, 620, 459, doi: 10.1086/426895
* Youdin & Lithwick (2007) Youdin, A. N., & Lithwick, Y. 2007, Icarus, 192, 588, doi: 10.1016/j.icarus.2007.07.012
* Youdin & Shu (2002) Youdin, A. N., & Shu, F. H. 2002, ApJ, 580, 494, doi: 10.1086/343109
* Zhu & Yang (2021) Zhu, Z., & Yang, C.-C. 2021, MNRAS, 501, 467, doi: 10.1093/mnras/staa3628

Title: GausSN: Bayesian Time-Delay Estimation for Strongly Lensed Supernovae
Transcription: # GaussSN: Bayesian Time-Delay Estimation for Strongly Lensed Supernovae

Erin E. Hayes,\({}^{1}\) Stephen Thorp,\({}^{2}\) Kaisey S. Mandel,\({}^{1,3}\) Nikki Arendse,\({}^{2}\) Matthew Grayling,\({}^{1}\) and Suhail Dhawan\({}^{1}\)

\({}^{1}\)Institute of Astronomy and Kavli Institute for Cosmology, Madingley Road, Cambridge CB3 0HA, UK

\({}^{2}\)The Oskar Klein Centre, Department of Physics, Stockholm University, AlbaNova University Centre, SE 106 91 Stockholm, Sweden

\({}^{3}\)Statistical Laboratory, DPMMS, University of Cambridge, Wilberforce Road, Cambridge, CB3 0WB, UK

Contact e-mail: eeh55@cam.ac.uk

Accepted XXX. Received YYY; in original form ZZZ

###### Abstract

We present GaussSN, a Bayesian semi-parametric Gaussian Process (GP) model for time-delay estimation with resolved systems of gravitationally lensed supernovae (glSNe). GaussSN models the underlying light curve non-parametrically using a GP. Without assuming a template light curve for each SN type, GaussSN fits for the time delays of all images using data in any number of wavelength filters simultaneously. We also introduce a novel time-varying magnification model to capture the effects of microlensing alongside time-delay estimation. In this analysis, we model the time-varying relative magnification as a sigmoid function, as well as a constant for comparison to existing time-delay estimation approaches. We demonstrate that GaussSN provides robust time-delay estimates for simulations of glSNe from the Nancy Grace Roman Space Telescope and the Vera C. Rubin Observatory's Legacy Survey of Space and Time (Rubin-LSST). We find that up to 43.6% of time-delay estimates from Roman and 52.9% from Rubin-LSST have fractional errors of less than 5%. We then apply GaussSN to SN Refsdal and find the time delay for the fifth image is consistent with the original analysis, regardless of microlensing treatment. Therefore, GaussSN maintains the level of precision and accuracy achieved by existing time-delay extraction methods with fewer assumptions about the underlying shape of the light curve than template-based approaches, while incorporating microlensing into the statistical error budget rather than requiring post-processing to account for its systematic uncertainty. GaussSN is scalable for time-delay cosmography analyses given current projections of glSNe discovery rates from Rubin-LSST and Roman.

keywords: gravitational lensing: strong - gravitational lensing: micro - methods: statistical - supernovae: general - supernovae: individual: SN Refsdal - distance scale

## 1 Introduction

Strong lensing of a background variable source, such as a supernova (SN), by a foreground galaxy or galaxy cluster, can result in the appearance of multiple images of the source. Refsdal (1964) was the first to demonstrate that the time delay between the multiple images of a gravitationally lensed supernova (glSN) images could be related to \(H_{0}\) when combined with a model of the lens mass distribution. A independent \(H_{0}\) estimate from strong lensing is motivated by the persistent 5\(\sigma\) tension between the present-day expansion rate of the universe, \(H_{0}\), measured using light from early-times (i.e. the Cosmic Microwave Background; Planck Collaboration et al.2020) and from late-times (i.e. the distance ladder; Riess et al.2022), known as the Hubble tension. If determined to be physical, this tension may be suggestive of new physics beyond our present model of the universe, \(\Lambda\)CDM (Mortsell and Dhawan, 2018; Di Valentino et al.2021). As time-delay distances inferred from strong lensing are completely independent of the luminosity distances used in the distance ladder, time-delay cosmography represents a promising technique for cross-checking local measurements of \(H_{0}\)(see e.g. Treu et al.2022; Suyu et al.2023 for recent reviews). In this paper, we present GaussN: a Bayesian semi-parametric approach for the extraction of time delays from glSN systems using Gaussian Processes (GPs). GaussSN is a publicly available package that can be found at: [https://github.com/erinhay/gausssn](https://github.com/erinhay/gausssn).

Because of the rarity of glSNe, the first cosmological constraints from strong lensing came from quasars (e.g. Keeton and Kochanek, 1997; Wong et al., 2020; Birrer et al., 2020). However, SNe have several advantages over quasars for strong lensing analyses which have the potential to push the field further in precision and accuracy. Firstly, that SNe disappear after a few months allows for the study of the lens and host galaxy in greater detail. Improved knowledge of the lens helps to break the mass-sheet degeneracy (Falco et al., 1985), which was cited as the main source of uncertainty in the H0LiCOW estimate of \(H_{0}\)(Wong et al., 2020; Birrer et al., 2020). If the lensed object is a Type Ia supernova (SN Ia), further leverage can be gained from the fact that SNe Ia are standardizable candles (Foxley-Marable et al., 2018; Birrer et al., 2022). Secondly, the relatively simple light curves of SNe, in contrast to the stochastic variability of quasars, makes it easier to extract time delays from the systems. The single peak in brightness limits the degeneracies in matching the images. Furthermore, for SNe Ia, the well-known light curve shapes and colour distributions can help to constrain the effects of microlensing and dust extinction on the system. Microlensing can distort the shapeof an image's light curve and lead to artificial shifts in the apparent peak of the light curve - a "microlensing time-delay" (Bonvin et al., 2019). This effect has proven to be a difficult effect to disentangle from underlying variability from the source (Foxley-Marrable et al., 2018; Pierel et al., 2023). Time-delay estimation with glSNe can also be done with a shorter time frame of observations because their variability is constrained to a period of a few weeks to months, compared to the years required for measure reliable time delays from lensed quasars (Bonvin et al., 2017, 2018, 2019). Of course, the rarity of SNe and short window in which they are active make glSNe more difficult to discover.

Therefore, it was not until November 2014 that the first cosmologically useful glSN, SN Refsdal, was discovered (Kelly et al., 2015). SN Refsdal, a peculiar Type II SN at \(z=1.49\)(Kelly et al., 2016), was discovered with four images in an Einstein cross due to lensing by an elliptical galaxy in the MACS J1149.6+2223 galaxy cluster at \(z=0.54\). Unfortunately, the time delays from galaxy-scale lensing, originally estimated in (Rodney et al., 2016), were determined to be too short and imprecise to obtain a measurement of \(H_{0}\). However, the host galaxy of SN Refsdal was also imaged multiple times. It was predicted that a 5\({}^{\rm th}\) image of SN Refsdal would later appear in another image of the host galaxy with a time delay of just under a year (Kelly et al., 2015; Oguri, 2015; Sharon and Johnson, 2015; Grillo et al., 2016; Diego et al., 2016; Jauzac et al., 2016; Kawamata et al., 2016; Treu et al., 2016). As predicted, SN Refsdal reappeared less than a year later in October 2015 (Kelly et al., 2016). Using the time delay between SN Refsdal's fifth image and the other four images (Kelly et al., 2023), the first measurement of \(H_{0}\) was published in May 2023 (Kelly et al., 2023). Finding \(H_{0}=64.8^{+4.4}_{-4.3}\) km s\({}^{-1}\) Mpc\({}^{-1}-\) a 6.0% precision estimate - SN Refsdal alone has demonstrated the importance of glSNe as precise local cosmological probes.

In addition to SN Refsdal, seven glSNe have been found: SN PS1-10afx (Chornock et al., 2013; Quimby et al., 2013), SN 2016geu (Goobar et al., 2017), SN Requiem (Rodney et al., 2021), SN C22 (Chen et al., 2022), SN Zwicky (Goobar et al., 2023), SN 2022riv (Kelly et al., 2022), and SN H0pe (Frye et al., 2023, 2023). However, SN Refsdal has been the only one of these eight that has been used for cosmology thus far. Six of the others have suffered from either having extremely short time delays (SN 2016geu's, SN Zwicky's, and some of SN Requiem's images have time delays of only a few hours), having extremely long time delays (SN Requiem's final image is expected to reappear in \(\sim\) -2037), being found only in an archival search and therefore having insufficient data (SN PS1-10afx, SN Requiem, and SN C22), or having only one observed image (SN 2022riv). SN H0pe, recently discovered in March 2023, is a strong candidate for a second glSN measurement of \(H_{0}\). Analysis of SN H0pe is currently ongoing and more information about this glSN is expected in the near future.

In the next decade, the Vera C. Rubin Observatory's Legacy Survey of Space and Time (Rubin-LSST) and Roman Space Telescope (Roman) are expected to discover tens to hundreds of glSNe, if we adopt the right search strategies (Huber et al., 2019; Wojtak et al., 2019; Pierel et al., 2021; Craig et al., 2021). With this data, it will be possible to reach percent level constraints on the cosmological parameters competitive with SH0ES and Planck measurements (Huber et al., 2019, Arendse et al., 2023, in prep). As samples of glSNe grow, so does their potential to resolve the Hubble tension with precise local measurements of \(H_{0}\).

The relatively simple and well-understood variability of SNe lends itself to time-delay estimation techniques based around SN light curve templates. In particular, template-based Supernova Time Delays (sntd; Pierel and Rodney, 2019) has emerged as the standard for glSNe time-delay estimation due to its flexibility and accessibility. The package is built upon smcosno (Barbary et al., 2023), which contains a diverse library of SN light curve templates. In addition, a flexible Bazin function (Bazin et al., 2009) can be used as the underlying template, if spectroscopic classification is unavailable or ambiguous. Given a specified SN light curve template, sntd uses the nested sampling functionality available through sncosmo to yield posterior distributions for the light curve template parameters, the time delay, and the magnification.

However, uncertainties relating to template choice and the unknown redshift evolution of SN light curves, especially for types of SNe other than SNe Ia, may introduce systematic errors into the time-delay analysis that are difficult to quantify. While template-based approaches are motivated by the well-described nature of some SN light curves, a complementary method which is independent of these potential systematics is needed. GaussSN is a template-independent approach for time-delay estimation that models the underlying light curve non-parametrically using a Gaussian Process (GP). This model is motivated by previous work on quasar time-delay estimation with GPs, in particular that of Tak et al. (2017), as well as that of Hojjati et al. (2013); Hojjati and Linder (2014); Meyer et al. (2023).

By modeling the underlying light curve non-parametrically with a GP, GaussSN is able to fit the light curves of any type of SN without prior knowledge of the type or the redshift of the object. In addition, the model naturally fits for the time delays of all images, observed in any number of bands, simultaneously. By fitting all images in all filters together, we take advantage of the full information available from the data by leveraging the knowledge that for each band, the multiple images' time-series are time-shifted and magnified realization of the same underlying light curve. GaussSN also implements a novel microlensing treatment which occurs alongside time-delay estimation for a one-step time-delay measurement. A time-varying magnification term is used to account for both macrolensing and microlensing simultaneously with the time-delay estimate. Because the time delay and microlensing are jointly inferred, GaussSN does not require post-processing to account for a systematic error budget due to microlensing, but instead incorporates uncertainty from microlensing in the statistical uncertainty. Therefore, GaussSN provides a coherent Bayesian time-delay estimate in one-step, without the need for post-processing to account for systematics from template choice or microlensing.

The peculiar nature of SN Refsdal's light curve exemplifies the need for a template-independent approach for time-delay estimation for glSNe, such as GaussSN. Although most similar to SN 1987A (Woosley et al., 1988; Kelly et al., 2016), SN Refsdal's light curves are not well described by any existing templates (although some theoretical models have been developed, e.g. Baklanov et al., 2021). While the light curves of SNe Ia are highly uniform, the shapes of the light curves of other types of supernovae are less well studied and more highly varied from object to object. GPs are well suited for this application, as they are flexible and data driven, with minimal assumptions about the properties of the true underlying light curve.

Indeed, in the analysis of the time delays of SN Refsdal's five images, the Bayesian Gaussian Process method, upon which GaussSN is based, was highly successful (Kelly et al., 2023). Four methods, including sntd and a custom piecewise polynomial template approach, were tested on simulations of SN Refsdal-like light curves to determine the quality of each method's fits. In simulations, the Bayesian Gaussian Process method outperformed the template-based approaches for extracting the time delays of the 2 best-sampled images S2 and S3 relative to the first image. On the other hand, sntd and the custom template approach were more successful in estimating the time delay of the more poorly sampled images S4 and SX relative to the first image. Ultimately, the custom template was the most generally successful in fitting for time delays and magnifications for all the images in simulations.

GausSN provides coherent Bayesian time-delay estimates with complementary strengths to existing template-based time-delay estimation methods. As a template-independent approach, GausSN does not require prior knowledge of SN type or redshift, making the model quick and easy to implement. Furthermore, GausSN is not subject to potential sources of systematic uncertainties and biases from template choice; fine tuning of generic SN templates, such as the Bazin function; or the need to construct custom templates, which may not be feasible for larger samples of gISNe and makes validation of an analysis difficult. Finally, the model provides Bayesian time-delay estimates in one step, without the need for post-processing to account for systematic uncertainty from microlensing, by incorporating a time-varying magnification treatment.

In SS2, we describe how we model gISN in flux-space with GPs. We describe the microlensing model in SS3 and the sampling algorithms implemented in GausSN in SS4. In SS5, we show the fits to simulated doubly-imaged gISN light curves as expected to be seen from Rubin-LSST and Roman. We then apply GausSN to the five images of SN Refsdal in SS6. In SS7, we discuss the performance of GausSN compared to other leading time-delay extraction techniques, as well as comment on future work possible with GausSN. In SS8, we conclude.

## 2 Modelling GLSNE with Gaussian Processes in Flux-Space

Strong lensing of a supernova by a foreground galaxy or galaxy cluster results in the appearance of multiple images, which are copies of the same underlying light curve. These multiple images are observed with some shift in time and magnification or de-magnification relative to each another. We model the true underlying light curve in flux space, \(f(t)\), as a draw from a Gaussian Process:

\[f(t)\sim\mathcal{GP}(c(t),k(t,t^{\prime})) \tag{1}\]

where \(c(t)\) is the mean function, which can depend on time, t, in the case of time series data, and \(k(t,t^{\prime})\) is the covariance (or kernel) function, which gives the covariance between \(f(t)\) and \(f(t^{\prime})\).

Throughout this work, we use a zero mean function, such that \(c(t)=0\). The zero mean function encourages the inferred function to go to zero flux outside of where there is data, which reflects the physical expectation that before and after the SN explosion, we expect an average of zero background-subtracted flux. For the covariance function, we choose the squared exponential kernel:

\[k(t,t^{\prime})=A^{2}e^{-(t-t^{\prime})^{2}/2}x^{2} \tag{2}\]

where \(A\), the amplitude, and \(\tau\), the length scale, are the two hyperparameters controlling the kernel. This kernel enforces strong correlation between points nearby to one another, with weaker correlation as points further away are considered. It is also stationary, or invariant to overall time shifts, and produces smooth functions (Rasmussen and Williams, 2006). The squared exponential kernel has proven to be well-suited for fitting SN light curve data, as it has been used to do so in previous work with success (Kim et al., 2013; Boone, 2019; Vincenzi et al., 2019; Qu et al., 2021).

The GP is defined such that any vector \(\mathbf{f}\) consisting of the evaluations of this continuous function, \(f(t)\), at the finite set of points, \(\mathbf{t}\), has a joint multivariate Gaussian prior distribution:

\[\mathbf{f}(\mathbf{t})\sim\mathbf{N}(\mathbf{0},\mathbf{K}(\mathbf{t},\mathbf{t})) \tag{3}\]

where the elements of the covariance matrix, \(\mathbf{K}(\mathbf{t},\mathbf{t})\), are given by \(K_{ij}=k(t_{i},t_{j})\) for \(t_{i},t_{j}\in\mathbf{t}\). Note that we use \(\mathbf{X}\sim\mathbf{N}(\mathbf{\mu},\mathbf{\Sigma})\) to denote a multivariate normal vector with mean \(\mathbf{\mu}\) and covariance matrix \(\mathbf{\Sigma}\). Then, \(P(\mathbf{X})=\mathbf{N}(\mathbf{X}|~{}\mathbf{\mu},\mathbf{\Sigma})\) gives the PDF of the vector.

### Two Images in One Band

We first consider the simplest case of two images observed in one band, i.e. a filter covering a defined range of wavelengths. Taking image 1 to be the arbitrarily chosen reference image, the light curves of the two images are described by:

\[f_{1}(t) =f(t) \tag{4}\] \[f_{2}(t) =\beta f(t-\Delta)\]

where \(\Delta\) is the relative time delay of image 2 compared to image 1 and \(\beta\) is the relative magnification of image 2 compared to image 1.

Say we observe image 1 at a set of \(N_{1}\) times, \(\mathbf{\hat{f}}_{1}\), and image 2 at a set of \(N_{2}\) times, \(\mathbf{\hat{f}}_{2}\). We define \(\mathbf{\hat{f}}_{1}(\mathbf{\hat{f}}_{1})\) and \(\mathbf{\hat{f}}_{2}(\mathbf{\hat{f}}_{2})\), the observations of image 1 and 2 respectively, such that for the \(i^{\text{th}}\) observation of image 1:

\[\hat{f}_{1,i} =\hat{f}_{1}(t_{i})=f(t_{i})+\epsilon_{1,i} \tag{5}\] \[\epsilon_{1,i} \sim\mathbf{N}(0,\sigma_{1,i}^{2}) \tag{6}\]

and for the \(j^{\text{th}}\) observation of image 2:

\[\hat{f}_{2,j} =\hat{f}_{2}(t_{j})=\beta f(t_{j}-\Delta)+\epsilon_{2,j} \tag{7}\] \[\epsilon_{2,j} \sim\mathbf{N}(0,\sigma_{2,j}^{2}) \tag{8}\]

where \(\sigma_{1,i}\) and \(\sigma_{2,j}\) are the standard deviations of the measurement errors of image 1 and image 2, respectively. We assume that the measurement errors are independent. We re-scale the flux data and measurement standard deviations for each band and image by a single, constant factor determined by the range of fluxes over all images and bands.

We concatenate these two vectors to give the flux data vector, \(\mathbf{\hat{F}}\), as:

\[\mathbf{\hat{F}}=\begin{pmatrix}\mathbf{\hat{f}}_{1}\\ \mathbf{\hat{f}}_{2}\end{pmatrix} \tag{9}\]

and the time data vector, \(\mathbf{\hat{T}}\), as:

\[\mathbf{\hat{T}}=\begin{pmatrix}\mathbf{\hat{t}}_{1}\\ \mathbf{\hat{t}}_{2}\end{pmatrix}. \tag{10}\]

In addition, we define the de-shifted time vector, \(\mathbf{\hat{T}}_{\Delta}\), which depends on the time delay, \(\Delta\):

\[\mathbf{\hat{T}}_{\Delta}=\begin{pmatrix}\mathbf{\hat{f}}_{1}\\ \mathbf{\hat{f}}_{2}-\Delta\end{pmatrix}. \tag{11}\]

To infer \(f(t)\) from the data \(\mathbf{\hat{F}}\) and \(\mathbf{\hat{T}}\), we fit for a time delay, \(\Delta\), and magnification, \(\beta\), in addition to the two kernel hyperparameters. Therefore, \(\mathbf{\theta}=(A,\tau,\Delta,\beta)\).

The marginal likelihood over \(\mathbf{\theta}\) is given as:

\[P(\mathbf{\hat{F}}|~{}\mathbf{\hat{T}},\mathbf{\theta})=\mathbf{N}(\mathbf{\hat{F}}|~{}\mathbf{0},\mathbf{ \Sigma}_{\mathbf{\theta}}) \tag{12}\]

where we can think of \(\mathbf{\Sigma}_{\mathbf{\theta}}\) in four quadrants:

\[\mathbf{\Sigma}_{\mathbf{\theta}}=\begin{pmatrix}\text{Cov}\begin{pmatrix}\mathbf{\hat{f}}_{ 1},\mathbf{\hat{f}}_{1}\\ \text{Cov}\begin{pmatrix}\mathbf{\hat{f}}_{2},\mathbf{\hat{f}}_{1}\\ \end{pmatrix}\end{pmatrix}\text{Cov}\begin{pmatrix}\mathbf{\hat{f}}_{1},\mathbf{\hat{f}}_{2 }\\ \text{Cov}\begin{pmatrix}\mathbf{\hat{f}}_{2},\mathbf{\hat{f}}_{1}\\ \end{pmatrix}\end{pmatrix}. \tag{13}\]

Recall that for a GP, the covariance is given as \(\text{Cov}\begin{pmatrix}f(t),f(t^{\prime}))=\text{Cov}\begin{pmatrix}\mathbf{ \hat{f}}_{1}\\ \mathbf{\hat{f}}_{2}\end{pmatrix}\).

\(k\left(t,t^{\prime}\right)\). With Equations 5-8, the covariances in the first quadrant are:

\[\text{Cov}\left(\hat{f}_{1,i},\hat{f}_{1,j}\right) =\text{Cov}\left(f_{1,i}+\epsilon_{1,i},f_{1,j}+\epsilon_{1,j}\right) \tag{14}\] \[=k\left(\hat{t}_{1,i},\hat{t}_{1,j}\right)+\delta_{ij}\sigma_{1,i} ^{2}\]

assuming there is no covariance between \(f_{1,i}\) and \(\epsilon_{1,j}\), as the physical process generating the light curve is independent of the measurement process. In the second quadrant, the covariances are:

\[\text{Cov}\left(\hat{f}_{1,i},\hat{f}_{2,j}\right) =\text{Cov}\left(f_{1,i}+\epsilon_{1,i},f_{2,j}+\epsilon_{2,j}\right) \tag{15}\] \[=\beta k\left(\hat{t}_{1,i},\hat{t}_{2,j}-\Delta\right).\]

It follows that:

\[\text{Cov}\left(\hat{f}_{2,i},\hat{f}_{1,j}\right) =\beta k\left(\hat{t}_{2,i}-\Delta,\hat{t}_{1,j}\right) \tag{16}\]

and

\[\text{Cov}\left(\hat{f}_{2,i},\hat{f}_{2,j}\right) =\beta^{2}k\left(\hat{t}_{2,i}-\Delta,\hat{t}_{2,j}-\Delta\right) +\delta_{ij}\sigma_{2,i}^{2} \tag{17}\] \[=\beta^{2}k\left(\hat{t}_{2,i},\hat{t}_{2,j}\right)+\delta_{ij} \sigma_{2,i}^{2}\]

for the remaining two quadrants. Because our choice of kernel is stationary, \(k\left(\hat{t}_{2,i}-\Delta,\hat{t}_{2,j}-\Delta\right)=k\left(\hat{t}_{2,i}, \hat{t}_{2,j}\right)\).

Based on this formulation, we can decompose \(\Sigma_{\mathbf{\theta}}\) into three factors:

\[\Sigma_{\mathbf{\theta}}=\left(\mathbf{M}\odot\mathbf{K}\right)+\mathbf{W} \tag{18}\]

where \(\odot\) represents a Hadamard product (i.e. the elementwise product). The first factor, \(\mathbf{M}\), depends only on \(\beta\). Defining \(\mathbf{1}\) as a matrix of ones, \(\mathbf{M}\) is given as:

\[\mathbf{M}=\begin{pmatrix}\mathbf{1}_{N_{1}\times N_{1}}&\beta\mathbf{1}_{N_{1}\times N_{2 }}\\ \beta\mathbf{1}_{N_{2}\times N_{1}}&\beta^{2}\mathbf{1}_{N_{2}\times N_{2}}\end{pmatrix} \tag{19}\]

where, again \(N_{1}\) is the number of observations of image 1 and \(N_{2}\) is the number of observations of image 2. The second factor, \(\mathbf{K}\), depends on \(\Delta\) and the kernel parameters and is defined as:

\[\mathbf{K}=\mathbf{k}(\mathbf{\hat{T}}_{\Delta},\mathbf{\hat{T}}_{\Delta})=\begin{pmatrix}\bm {k}(\mathbf{\hat{t}}_{1},\mathbf{\hat{t}}_{1})&\mathbf{k}(\hat{t}_{1},\hat{t}_{2}-\Delta) \\ \mathbf{k}(\mathbf{\hat{t}}_{2}-\Delta,\mathbf{\hat{t}}_{1})&\mathbf{k}(\hat{t}_{2},\hat{t}_{2 })\end{pmatrix} \tag{20}\]

where \(\mathbf{k}(\mathbf{\hat{t}},\mathbf{\hat{t}}^{\prime})\) is the matrix whose \((i,j)^{\text{th}}\) element is \(k\left(\hat{t}_{i},\hat{t}_{j}^{\prime}\right)\). Finally, the diagonal matrix \(\mathbf{W}\) contains the variances of the measurement errors, \(\hat{\sigma}^{2}\), along the diagonal.

With a specified prior on \(\theta\) and Equation 12, we can construct the posterior:

\[P(\mathbf{\theta}\mid\mathbf{\hat{F}},\mathbf{\hat{T}})\propto P(\mathbf{\hat{F}}\mid\mathbf{\hat {T}},\mathbf{\theta})P(\mathbf{\theta}\mid\mathbf{\hat{T}}) \tag{21}\]

which we can sample from and marginalize over to determine the probability distributions over the parameters. The dependence of \(P(\mathbf{\theta}\mid\mathbf{\hat{T}})\) on \(\mathbf{\hat{T}}\) arises because we will restrict the time delay, \(\Delta\), to be within the range of observations.

### Two Images in Two Bands

We will now consider the case with two images in two bands - band A and band B. We now have two functions we wish to model as a draw from a GP:

\[f_{\text{A}}(t)\sim\mathcal{GP}(0,k(t,t^{\prime})) \tag{22}\]

and

\[f_{\text{B}}(t)\sim\mathcal{GP}(0,k(t,t^{\prime})) \tag{23}\]

where the draws from the GP for each band are independent1. The light curves of the images are therefore defined by:

Footnote 1: While we choose to neglect correlations between the underlying light curves in different bands, these correlations can in principle be included, for example as in Hu and Tak (2020).

\[f_{\text{I},\text{A}}(t) =f_{\text{A}}(t) \tag{24}\] \[f_{\text{I},\text{B}}(t) =f_{\text{B}}(t)\] \[f_{\text{2},\text{A}}(t) =\beta f_{\text{A}}(t-\Delta)\] \[f_{\text{2},\text{B}}(t) =\beta f_{\text{B}}(t-\Delta)\]

We note that the magnification and time delay of the second image relative to the first is the same in band A as it is in band B. Therefore, there is still only one \(\beta\) and one \(\Delta\) for which to fit, so it remains that \(\mathbf{\theta}=(A,\tau,\Delta,\beta)\). It is possible to adopt unique GP kernel hyperparameters for each band, but we find that these extra parameters are unnecessary for the examples that follow in this paper.

We construct the flux data vector, \(\mathbf{\hat{F}}\), as:

\[\mathbf{\hat{F}}=\begin{pmatrix}\mathbf{\hat{f}}_{1,\text{A}}\\ \mathbf{\hat{f}}_{2,\text{A}}\\ \mathbf{\hat{f}}_{1,\text{B}}\\ \mathbf{\hat{f}}_{2,\text{B}}\end{pmatrix} \tag{25}\]

and the time data vector, \(\mathbf{\hat{T}}\), as:

\[\mathbf{\hat{T}}=\begin{pmatrix}\mathbf{\hat{t}}_{1,\text{A}}\\ \mathbf{\hat{t}}_{2,\text{A}}\\ \mathbf{\hat{t}}_{1,\text{B}}\\ \mathbf{\hat{t}}_{2,\text{B}}\end{pmatrix} \tag{26}\]

where \(\mathbf{\hat{f}}_{m,b}\) are the observations of image \(m\) in band \(b\) at times \(\mathbf{\hat{t}}_{m,b}\). We also define the de-shifted time vector, \(\mathbf{\hat{T}}_{\Delta}\), as:

\[\mathbf{\hat{T}}_{\Delta}=\begin{pmatrix}\mathbf{\hat{t}}_{1,\text{A}}\\ \mathbf{\hat{t}}_{2,\Delta}-\Delta\\ \mathbf{\hat{t}}_{1,\text{B}}\\ \mathbf{\hat{t}}_{2,\text{B}}-\Delta\end{pmatrix}. \tag{27}\]

The marginal likelihood is:

\[P(\mathbf{\hat{F}}\mid\mathbf{\hat{T}},\mathbf{\theta})=\mathcal{N}(\mathbf{\hat{F}}\mid\mathbf{0}, \mathbf{\Sigma}_{\mathbf{\theta}}) \tag{28}\]

where, again, \(\mathbf{\Sigma}_{\mathbf{\theta}}=\left(\mathbf{M}\odot\mathbf{K}\right)+\mathbf{W}\).

We make the simplifying assumption that there is no shared information between bands beyond the time delay and magnification. In other words, there is no covariance of either image in band A with either image in band B. With this in mind, we write \(\mathbf{K}\) as:

\[\mathbf{K}=\begin{pmatrix}\mathbf{K}_{\text{A}}&\mathbf{0}\\ \mathbf{0}&\mathbf{K}_{\text{B}}\end{pmatrix} \tag{29}\]

where \(\mathbf{0}\) denotes a matrix of all zeros and \(\mathbf{K}_{\text{A}}\) and \(\mathbf{K}_{\text{B}}\) are defined as in Equation 20 for each band separately. We point out that there does not need to be the same number of observations of the images in band A as there are in band B. Therefore, the shape of \(\mathbf{0}\) need not necessarily be square.

Finally, the posterior is the same in this case as in Equation 21 with the new marginal likelihood terms defined for this data case. The case of two images in two bands can be generalized to fit multiple (\(>2\)) images in multiple (\(>2\)) bands. We fit simulated multi-band data as expected from Rubin-LSST and Roman in SS5 and multi-image data from SN Refsdal in SS6.

## 3 Microlensing

The effect of microlensing from stars and substructure in the lensing galaxy or galaxy cluster can additionally introduce additional time-varying magnification to individual images. Microlensing in systems of glSNe is extremely difficult to model because of complex layouts of stars and dark substructure in the foreground of lensing systems. The discrepancy in the model-predicted brightnesses of the four images from SN Zwicky without considerations of microlensing and the observed brightnesses of the images - up to 1.5 mag for one image - demonstrates the difficulty of modeling this effect and the significant impact which microlensing/substructure can have on a system (Pierel et al., 2023; Goobar et al., 2023).

Following Tak et al. (2017), we model microlensing as a time-dependent extension of \(\beta\), so the previously constant \(\beta\) becomes \(\beta(t)\). Because we can only learn relative magnification effects from the light curve data available, we take all magnification to be relative to an arbitrarily chosen image 1. Therefore, Equations 5-8 become:

\[\hat{f}_{1,i} =\hat{f}_{1}(t_{i})=f(t_{i})+\epsilon_{1,i} \tag{30}\] \[\epsilon_{1,i} \sim\mathcal{N}(0,\sigma_{1,i}^{2})\] (31) \[\hat{f}_{2,j} =\hat{f}_{2}(t_{j})=\beta(t_{j})f(t_{j}-\Delta)+\epsilon_{2,j}\] (32) \[\epsilon_{2,j} \sim\mathcal{N}(0,\sigma_{2,j}^{2}) \tag{33}\]

where again \(\sigma_{1,i}\) and \(\sigma_{2,j}\) are the standard deviations of the measurement errors of image 1 and image 2, respectively.

Figure 3 in Foxley-Marrable et al. (2018) and Figure 3 in Pierel et al. (2023) illustrate from microlensing maps examples of microlensing as a function of time. In these example microlensing curves, a period of constant magnification is typically interrupted by one change in brightness which occurs over a range of timescales, from less than a day to weeks. Physically, this shape corresponds to the SN crossing a microcaustic as the photosphere expands. After this change, the observed magnification appears to remain constant, as the small size of the SN and microlensing sub-structures means the photosphere most often crosses only one significant microcaustic. Therefore, we have chosen to model microlensing as a sigmoid function, given by:

\[\beta(t)=\beta_{0}+\frac{\beta_{1}}{1+e^{-r(t-t_{0})}} \tag{34}\]

where \(\beta_{0}\) is the macrolensing effect, \(\beta_{1}\) is the scale of the microlensing effect, \(r\) is the rate of change in the microlensing effect, and \(t_{0}\) is the location of a change in microlensing.

We make the simplifying assumption of achromatic microlensing, or microlensing which is identical across bands for a given image. It is demonstrated by Goldstein et al. (2018); Huber et al. (2021) that this assumption is valid for the first three rest-frame weeks of lensed SN Ia, in which time microlensing is predicted to be largely achromatic. This model for the time delay and magnification therefore takes 5 parameters per image. The parameters we fit for in a doubly-imaged system are now \(\theta=(A,\tau,\Delta,\beta_{0},\beta_{1},\tau,t_{0})\).

Consider again the case of two images observed in one band, where image 1 is observed at a set of \(N_{1}\) times and image 2 is observed at a set of \(N_{2}\) times. For this system, the matrix \(M\) from Equation 19 is now:

\[M=\begin{pmatrix}\mathbf{1}\mathbf{1}^{\mathsf{T}}&\mathbf{1}\boldsymbol{\beta }_{2}^{\mathsf{T}}\\ \boldsymbol{\beta}_{2}\mathbf{1}^{\mathsf{T}}&\boldsymbol{\beta}_{2}\boldsymbol {\beta}_{2}^{\mathsf{T}}\end{pmatrix} \tag{35}\]

where \(\mathbf{1}\) is a vector of ones of length \(N_{1}\) and \(\boldsymbol{\beta}_{2}\) is a vector of length \(N_{2}\) whose \(j^{\text{th}}\) element is given by \(\beta_{2,j}=\beta(\hat{t}_{2,j}-\Delta)\). This formulation generalizes to an arbitrary number of images observed in an arbitrary number of bands. We will refer to the model with a constant \(\beta\) as the "constant magnification" model and the model with a time-varying magnification term as the "sigmoid magnification" model.

Figure 1 demonstrates how a time-varying magnification term can have a significant impact on the shape of a SN light curve, to the point that the inferred time delay could be significantly skewed if the glSN system is fit with a constant magnification model. A combined treatment of macrolensing and microlensing mitigates the potential source of bias that arises if these magnification effects are considered separately. We explore this effect in greater detail in Appendix A.

## 4 Sampling Algorithms

Within the publicly available GaussSN framework, we implement three methods for sampling from the posterior distributions:

* emcee: affine invariant MCMC ensemble sampler (Foreman-Mackey et al., 2013; Goodman and Weare, 2010)
* dynesty: nested sampling (Speagle, 2020; Skilling, 2004; Skilling, 2006)
* zeus: MCMC ensemble slice sampler (Karamanis and Beutler, 2021; Karamanis et al., 2021)

We choose to sample parameters with dynesty for the analyses in this paper. The nested sampling approach is best able to handle the multi-modal nature of the posteriors on the time delay and other magnification parameters. Therefore, for the most accurate time-delay estimates and associated uncertainties, we opt for dynesty.

Within dynesty, we use both uniform sampling with multi-ellipsoidal bounding (Feroz et al., 2009), for systems with fewer than 100 data points and fewer than 5 parameters, and random slice sampling, for systems with more than 100 data points or more than 5 parameters, with 500 live points. The slice sampling technique was developed by Neal (2003) and first implemented within the nested sampling framework by Handley et al. (2015, 2015). We retain the default stopping criteria in dynesty, which is met when the remaining, unaccounted for evidence is less than a threshold which depends on the number of live points used (Speagle, 2020). We note that the specifications of dynesty sampling, and all other sampling methods, can

Figure 1: The effect that a 10% increase in brightness due to a time-varying magnification term over 5 days can have on the shape of a SN light curve. The upper panel shows the \(r\)-band flux of an unlensed SN Ia light curve from the Hsiao et al. (2007) template (blue, dashed line) and a microlensed version of the same underlying light curve (red, solid line). We emphasize that the true time delay is \(\Delta=0\), although the peak in the microlensed light curve appears to be later because of the time-varying magnification term. The bottom panel shows the time-varying relative magnification affecting the second image, \(\boldsymbol{\beta}(t)\).

be easily adjusted within the GausSN parameter optimization function.

Given these specifications, GausSN performs as follows. For an object with 320 total data points, i.e. 40 observations of 2 images in 4 bands, a single evaluation of the marginal likelihood takes \(\sim\) 2 ms using standard CPU resources on a desktop computer. The stopping criteria is typically met after 200,000-800,000 evaluations of the likelihood function, which roughly corresponds to 5,000-15,000 nested sampling iterations. Therefore, the nested sampling algorithm takes between 5 and 30 minutes to run for such an object. Depending on the quantity and quality of the data, sampling may take anywhere from 30 s to an hour for the simulated Rubin-LSST and Roman data. Given the rarity of glSNe, even in the best case scenarios for future observatories, such run times will not be a barrier for future applications of our model to real data.

## 5 Tests on Simulated Data

### Roman Simulations

#### 5.1.1 Data

Recently, Pierel et al. (2021) (hereafter P21) simulated 2.4 million glSN light curves - 600,000 each of Type Ia, Ib/c, IIn, and IIP - as expected from the Roman Space Telescope.2 The cadence, depth, and detection thresholds for the simulations are based on the Roman SN survey "All-z" strategy described in Hounsell et al. (2018), with modifications made for more recent survey updates. Based on the current plans for the instrument, P21 predicts Roman will discover glSNe up to \(z=4\).

Footnote 2: Publicly available at: [https://dx.doi.org/10.17909/t9-kkw9-zk32](https://dx.doi.org/10.17909/t9-kkw9-zk32).

The simulation pipeline works as follows: for each SN subclass, a sample of 50 simulated galaxy-scale lenses are used to simulate 10 distinct glSN light curves with 2-4 images based on the structure of the lens. Each of these 500 systems are then subject to 100 iterations of microlensing for each of 12 microlensing maps, yielding 1200 variations of each glSN light curve. P21 assumes achromatic microlensing, so any individual image experiences the same microlensing effects across wavelength space. The 12 microlensing maps are based on different choices of stellar mass model, which vary the effective radius, initial mass function, and Sersic index of the galaxy profile. Objects are required to pass a series of data cuts, which are described in P21. For simplicity, we consider only the doubly-imaged glSNe from the P21 Roman simulations.

We fit each object with both the constant magnification model and the sigmoid magnification model. For the constant magnification model, we use the following priors on the two kernel parameters, the time delay, and the magnification3:

Footnote 3: We use \(\mathcal{U}(a,b)\) to denote a uniform distribution over (a, b) and \(\mathcal{TN}(\mu,\sigma^{2},c,d)\) to denote a truncated normal distribution where \(\mu\) and \(\sigma\) are the mean and variance of an untruncated normal distribution, which is then truncated on the left at location \(c\) and on the right at location \(d\).

\[A \sim\mathcal{U}(0,5) \tag{36}\] \[\tau \sim\mathcal{U}(10,40)\;\text{days},\] (37) \[\Delta|\,\hat{\mathbf{T}} \sim\mathcal{TN}(\mu_{\Delta},\,50^{2},\,\min(\hat{\mathbf{t}}_{1})- \max(\hat{\mathbf{t}}_{2}),\,\max(\hat{\mathbf{t}}_{1})-\min(\hat{\mathbf{t}}_{2}))\; \text{days}\] (38) \[\beta_{0} \sim\mathcal{TN}(\mu_{\beta},10^{2},0,\infty) \tag{39}\]

where \(\mu_{\Delta}\) is the difference between the times of the brightest observations of image 2 and 1 and \(\mu_{\beta}\) is the ratio of the brightest observation of image 2 relative to the brightest observation of image 1. We define \(\hat{\mathbf{t}}_{1}\) and \(\hat{\mathbf{t}}_{2}\) to be all the times of observation of image 1 and 2, respectively. The prior on \(\Delta\) therefore requires that there always be overlap between data from image 1 and data from image 2. Although the scaled flux data has a maximum value of 1, we allow the prior on \(A\) to range from 0 to 5 so as not to overly restrict the amplitude of the underlying light curve.

We adopt wide priors on all parameters to ensure the diversity of behavior present in the simulations is represented in our parameter space. With real glSN events, which will be fit on an individual basis because of their rarity, these priors can be adjusted to account for additional contextual information for each specific event.

For the sigmoid model, we set the following priors on the three additional magnification parameters:

\[\beta_{1} \sim\mathcal{N}(0,0.5^{2}) \tag{40}\] \[r \sim\mathcal{N}(0,0.5^{2})\] (41) \[t_{0}|\,\hat{\mathbf{T}},\Delta \sim\mathcal{U}(\min(\hat{\mathbf{T}}_{\Delta}),\max(\hat{\mathbf{T}}_{ \Delta})) \tag{42}\]

with \(\hat{\mathbf{T}}\) as defined in Equation 10 and \(\hat{\mathbf{T}}_{\Delta}\) as defined in Equation 11.

#### 5.1.2 Analysis

On an individual object basis, the GP fits to the data and posterior distributions show that GausSN is effectively and accurately inferring the time delays from the glSNe systems. In Figure 2, we demonstrate the quality of the fit on the light curve level from the sigmoid magnification model. We plot the observed data with draws from the posterior predictive distribution. The bottom panel of the figure shows realizations of the magnification function for each posterior sample. Notably, because we are only able to constrain the relative magnification, the magnification function shows greater uncertainty around the beginning and end of the time series because these regions are where the light curve lacks overlapping data from the two images.

In Figure 3, we show the posteriors of the constant magnification fit. GausSN recovers \(\Delta=38.44^{+1.23}_{-1.30}\) days, which captures the true time delay of 38.53 days well within the 68% credible interval (CI). As we don't necessarily expect the posteriors to be Gaussian, we calculate the 68% CI from the \(16^{\text{th}}\) and \(84^{\text{th}}\) percentiles of the posterior samples. The magnification is not well recovered, as GausSN finds \(\beta=0.60\pm 0.02\), when the true \(\beta=0.24\). We attribute this discrepancy to the presence of microlensing from lens substructure. Indeed, there is more uncertainty in the recovered magnification when fitting with the sigmoid magnification model. With this model, GausSN finds \(\beta_{0}=0.59^{+0.05}_{-0.30}\), which is more consistent with the truth. The uncertainty on the time delay is however increased when fitting with the sigmoid magnification model, as expected, with \(\Delta=37.72^{+1.76}_{-1.97}\). This represents a 5.22% precision time-delay estimate with the sigmoid magnification model, up from 3.38% precision with the constant magnification model. Of course, the constant magnification model gives only a statistical uncertainty, so it does not take into consideration systematic uncertainty from microlensing. A separate systematic microlensing error would have to be accounted for in post-processing. Therefore, the time delay estimate with the sigmoid magnification model may, in the end, be more precise.

On a population level, GausSN performs well across all subclasses of SNe and mass models. We note that the true parameters for the SN IIP SC2 and SC4 mass models were not available, so these results are excluded from the reported statistics. The left column of Figure4 shows the distribution of \(\Delta_{\rm fit}-\Delta_{\rm true}\) for the sigmoid and constant magnification models. We also compare to the results from sntd, which are included in the P21 simulated Roman data release. With the constant magnification model we find 35.32% of time delays within \(\pm 1\) day, 70.33% within \(\pm 3\) days, and 83.73% within \(\pm 5\) days. With the sigmoid magnification model, we find that 27.13% of time delays are recovered within \(\pm 1\) day, 62.12% are recovered within \(\pm 3\) days and 79.07% are recovered within \(\pm 5\) days. For comparison, sntd recovers 31.95% within \(\pm 1\) day, 66.25% within \(\pm 3\) days, and 81.28% within \(\pm 5\) days.

We also consider the fractional error, \(|\Delta_{\rm fit}-\Delta_{\rm true}|/\Delta_{\rm true}\), on the time-delay estimates. This metric gives a better sense of closeness to the truth scaled by the size of the time delay. For the constant magnification model, we find that 32.55% of systems have fractional errors of less than 5% and for the sigmoid magnification model, 26.48% of systems have fractional errors of less than 5%. These results are comparable to the sntd results, which find 30.84% of systems to have a fractional error of less than 5%.

GausSN, therefore, is effective at estimating time delays close in absolute and fractional value to the true time delay. That the sigmoid magnification model is in general further from the truth according to this metric than the constant magnification model or sntd is not unexpected. As this model has more flexibility, often leading to more complex posteriors, the point estimate for the time delay may be further from the truth. The full posteriors give a more accurate sense of the time-delay estimate by a given model.

In the right column of Figure 4, we show the CDF of the standardised error, \((\Delta_{\rm fit}-\Delta_{\rm true})/\sigma_{\Delta}\) distribution for the sigmoid and constant GaussSN magnification models, sntd, and a unit normal distribution for reference. If the uncertainties are well-calibrated, we expect that across the sample of SNe, 68% of \(\Delta_{\rm true}\) will fall within the 68% CI and 95% of \(\Delta_{\rm true}\) will fall within the 95% CI. Although the full posterior distributions from sntd are not available, we can compare these statistics to the fraction of SNe which have time delays recovered within \(1\sigma\) and \(2\sigma\) of the truth from the sntd point estimate and uncertainty.

For the constant magnification model, we find 54.46% in 68% CI and 81.31% in 95% CI. For the sigmoid magnification model, we find 54.65% of SNe with \(\Delta_{\rm true}\) in 68% CI and 82.65% in 95% CI. For sntd, 50.92% of SNe have \(\Delta_{\rm true}\) which fall in the \(1\sigma\) CI and 78.33% fall in the \(2\sigma\) CI. While these statistics do not meet the benchmark set by the normal distribution, they are comparable to, if not a slight improvement on, the results from sntd. Therefore, GausSN provides time-delay estimates that are as close, if not closer, in absolute value to the truth with relatively well-calibrated uncertainties compared to sntd, the leading time-delay estimation technique for glSNe. As there are some variations for different types of SNe, we report the above statistics broken down by subclass of SN for all three models in Table 1.

Figure 3: The corner plot for the constant magnification fit to the giSN data shown in Figure 2. The constant magnification model has four parameters: the kernel amplitude, \(A\), the kernel length scale, \(\tau\), the time delay, \(\Delta\), and the relative magnification, \(B\). The three dashed lines in each of the 1D posterior distribution plots shows the 16th, 50th, and 84th percentiles from left to right, respectively, and the red line shows the true time delay and relative magnification. The time delay is well recovered and to 3.38% precision. The magnification is not as well recovered, potentially indicating additional magnification effects from microlensing that are not captured by the constant magnification model.

Figure 2: An example Roman-like simulated giSN system fitted with the sigmoid magnification model. The first image is shown in blue and the second in red. This object is at \(z=1.93\) and has time delay, \(\Delta=38.53\) days and relative magnification, \(\beta=0.24\). At this redshift, the Roman \(Y\)-, \(J\)-, and \(H\)-bands roughly cover \(3000-6000\)\(\AA\) in the rest frame, or the \(u\)-, \(g\)-, and \(r\)-band wavelength regimes. The top three panels show the fitted flux data and the bottom panel of the figure shows the fitted sigmoid magnification, \(\beta(\tau)\).

GausSN seems to have an improved calibration of uncertainties compared to sntd, which does not just arise from large uncertainties from GausSN. The mean uncertainty on the time delay is 2.90 days from the constant magnification model - comparable to the mean uncertainty of 3.02 days from sntd - and 3.81 days from the sigmoid magnification model. Furthermore, we can compare the fraction of glSNs with time delays measured to a certain level of precision, or which have \(|\sigma_{\Delta}/\Delta_{\rm fill}|\) less than a threshold. We find that with the constant magnification model, 5.10% of fitted Roman objects are measured to 1% precision - or have \(|\sigma_{\Delta}/\Delta_{\rm fill}|<0.01\) - and 25.50% are measured to 5% precision. For the sigmoid magnification model, 2.88% and 17.87% of objects are measured to 1% and 5% precision, respectively. Finally, sntd measures 5.94% of glSNe to 1% precision and 25.85% to 5% precision. The median precision is 14.55% for the constant magnification model, 22.44% for the sigmoid magnification model, and 14.57% for sntd. Again, these results suggest that GausSN is providing time-delay estimates with well-calibrated uncertainties without compromising on precision.

We note that 2.30% and 4.81% of glSNe have \((|\Delta_{\rm fit}-\Delta_{\rm true}|)/\sigma_{\Delta}\) > 5 for the sigmoid and constant magnification model, respectively. It is unsurprising that the more conservative sigmoid magnification treatment has fewer catastrophic outliers compared to the constant magnification model. However, we still exceed the rate of 5\(\sigma\) outliers consistent with a normal distribution. Concerningly, many of the outliers, particularly from the constant magnification fit, have fitted light curves that appear convincing based on visual inspection. It is likely that significant effects from microlensing, which may cause a time-varying magnification that is not well described by a sigmoid function, are at play in these simulations. Testing additional parameterizations of microlensing and using model comparison metrics will be necessary in analyses of real glSNe with significant microlensing effects. That said, these outliers will remain an issue for cosmological analyses of glSNe and uncertainties due to the presence of such outliers should be propagated through further analyses.

There are some additional outliers which arise from multi-modal posteriors on the time delay which are not well-described by the mean and standard deviation of the samples. These are of less concern for two reasons. Firstly, for many objects, a more informative prior on the time delay can resolve this issue. More careful tailoring of priors based on visual inspection of the light curves and other contextual information will be possible with real glSNe, due to their rarity, though it is difficult to do on the large scales needed for this analysis. Secondly, the full posterior, rather than a point estimate, should be used in the cosmological analysis of any glSN. There are also some outliers with very low SNR for one or both images, making any constraint on the time delay difficult. These two types of outliers are also expected at the low rates we see and are not of concern because of the ease with which they can be identified as needing more careful treatment.

Furthermore, such rates of outliers are not inconsistent with existing methods for time-delay estimation. For reference, 5.96% of sntd fits to the Roman simulations have \((|\Delta_{\rm fit}-\Delta_{\rm true}|)/\sigma_{\Delta}\) > 5. That GausSN has fewer outliers is consistent with the statistics reported in Table 1, which show the GausSN uncertainties are better calibrated. In addition, the methods presented in Kelly et al. (2023b) show similar rates of outliers. Therefore, GausSN again meets, if not exceeds, the benchmarks set by existing time-delay estimation methods.

Together, these results demonstrate that GausSN provides com

Tuple 41:
Cleaned Title: timedependent background dimensional string theory
Cleaned Transcription: time dependent background dimensional string theory bruno balthazar jinwei chu david kutasov kadanoff center theoretical physic enrico fermi institute university chicago chicago il center cosmology particle physic new york university new york ny brunobalthazarnyuedu jinweichuuchicagoedu dkutasovuchicagoedu perturbative string theory one generally interested asymptotic observables smatrix flat spacetime boundary correlation function antide sitter spacetime however background observables exist study example background dimensional string theory example liouville wall accelerates become spacelike past andor future happens corresponding null infinity standard scattering state defined shielded liouville wall compute scattering particle production amplitude background region parameter space wall remains timelike discus continuation picture spacelike regime also discus physic point view dynamic free fermion background timedependent fermi surface content introduction standard background timedependent background strategy calculation wick rotation standard background amplitude timedependent background nto amplitude particle production p generalization free fermion perspective summary discussion summary observables p property scattering amplitude limit pto closed string radiation moving mirror matrix model dual dimensional string theory b closed string amplitude b one outgoing particle b two outgoing particle b three four outgoing particle b number outgoing particle introduction since inception late string theory dimensional spacetime played important role development subject see eg review particular dual description term matrix quantum mechanic double scaling limit early example holography precursor adscft correspondence little string theory fact theory solvable allows one use test general idea string theory holography setting explicit calculation performed example study nonperturbative effect string coupling see eg recent discussion theory originally formulated static background natural set observables given smatrix element scattering massless tachyons known theory solvable timedependent background well see eg however background nature observables le clear main goal paper discus physic class background try learn treat background similar feature realistic setting higher dimension background cosmological singularity standard background set stage start brief review situation standard background euclidean two dimensional spacetime euclidean worldsheet metric hatg described action sefracpiint dzsqrthatgleftlefthatnablaxright lefthatnablaphirightphi rhatgpimuphi ephi right tag linear dependence dilaton phi lead string coupling behaves like gsphisimexpphi one think phi conformal factor dynamical metric conformal gauge description worldsheet gravity coupled massless scalar field x worldsheet theory becomes free region phitoinfty string coupling gsphi go zero region boundary two dimensional spacetime labeled xphi conversely phi increase string coupling increase one might think perturbative string theory break due strong coupling effect associated large positive phi region however cosmological constant term action give rise potential phi prevents exploring region potential often referred liouville wall lead fact background g expansion essentially mu expansion physical observables background correlation function vertex operator characterized behavior near boundary large set operator corresponds mode massless tachyon field described vertex operator footnote take worldsheet metric hatg flat iez coordinate complex plane flat metric tpsimeqfracgammapgammapint dzepphieipx tag chose normalize operator conventional way see eg simeq mean describes behavior operator phitoinfty finite phi form operator complicated physical observables correlation function operator tp langle tptpcdots tplrangle tag correlation function uniquely determined asymptotic form important feature operator nonnormalizable indeed wavefunctions behave limit phitoinfty like psipxphisim eipxpphi thus adding worldsheet lagrangian corresponds deformation lagrangian spacetime theory note future reference wavefunctions psip property positive negative p depend antiholomorphic variable phimp ix worldsheet field x often taken compact xsim xpi r eg study theory finite temperature case momentum p quantized prin z also winding mode latter play role discussion related momentum mode tduality used relate correlation function momentum mode cosmological term worldsheet action written mu prefactor pole p pole responsible factor phi front exponential differentiating path integral wrt mu give insertion use fact calculation correlation function property correlation function useful dependence mu known kpz scaling analyzing behavior shift phi one show leading order g langle tptpcdots tplranglesimmua tagwith determined sumjlleftpjrighta tag coefficient mua contains nontrivial dependence momentum pj order determine one need solve worldsheet theory lorentzian analog obtained taking xtoit give slfracpiint dzleftleftnabla trightleftnabla phirightpimuphi ephiright tag target spacetime dimensional spacelike linear dilaton liouville wall spatial phi direction shield strong coupling region depicted figure red line liouville wall defined surface along liouville potential vphi order one shaded region shielded liouville potential footnote wall soft sense particle higher energy penetrate larger phi see eg discussion figure correlation function describe scattering process n rightmoving tachyons cal come boundary phitoinfty scatter liouville wall depicted red nprime leftmoving tachyons cal go back towards boundary missingpagefail dual matrix model allows one calculate amplitude much efficiently also allows one calculate quantum correction leading term worldsheet perspective come higher genus contribution correlation function use matrix model result timedependent background mentioned main interest timedependent background obtained deforming background discussed past eg use result special case background recently revisited particular deformation consider correspond adding worldsheet action term footnote take p without loss generality delta sllambdatplambdatpfracgammapgammap int dzepphileftlambdaeptlambdaeptright tag coupling lambdapm taken real worldsheet action remains real deformation lambdapm nonzero one take satisfy lambdapmlambda shifting origin time mostly focus case one two coupling vanishes case remaining coupling control time perturbation becomes important obviously lambda perturbation becomes important future lambda becomes important past see qualitative difference case p p former case perturbation go zero near boundary spacetime phitoinfty fixed latter grows approach boundary origin behavior well understood p operator exppm pt relevant thus coupling phi effective coupling go zero uv region phitoinfty conversely p operator irrelevant modify uv behavior restrict case p addition perturbation worldsheet lagrangian modifies worldsheet potential focus case lambda unless explicitly stated otherwise worldsheet potential take case form large negative phi vrm wstphimuphi ephihatlambdaepphipt tag hatlambdalambdafracgammapgammap situation described figure generalizes figure hatlambda solid red line figure surface vtphisim thought timedependent liouville wall early time ttoinfty perturbation proportional hatlambda go zero recover static liouville wall described previous subsection late time ttoinfty velocity modified liouville wall approach finite constant indicated figure transition two regime occurs around point phitphit phitbigfraclnmufracplnhatlambda fracpplnmubig tag depicted figure regime liouville wall accelerates initial final velocity evident figure qualitative difference case p p former case exhibited figure trajectory liouville wall timelike hand p figure b liouville wall spacelike large ie move faster light late time note inconsistent special relativity since liouville wall dynamical object rather nonnormalizable background thus used propagate information faster light dynamical field tachyon massless used transmit information speed light important subtlety discussion play role analysis holographic map dimensional string theory matrix quantum mechanic tachyon field worldsheet whose momentum mode given figure presence perturbation liouville wall becomes timedependent ttoinfty approach static wall unperturbed system ttoinfty velocity approach fracpp p liouville wall remains timelike p eventually becomes spacelike b exponential equation matrix model analog related momentum dependent factor ratio gamma function formula ratio thought due nonzero mode worldsheet field phit therefore deformation give rise worldsheet interaction int dzvrm wstzbarzphizbarz yield potential vrm sttphimu tlambdatpmu ephilambdaep phipt tag zero mode worldsheet field phizbarztzbarz timedependent liouville wall described equation vrm sttphi qualitative discussion worldsheet potential vrm w mostly go replaced vrm st couple important change first timedependent term positive lambda whereas hatlambda must positive p two notion coincide p differ take point view spacetime potential vrm st important one dynamic tachyon field thus take lambda positive see later give coherent picture physic second change point phit figure still given hatlambda replaced lambda phitbigfraclnmufracplnlambdafrac pplnmubig tag play role analysis form timedependent liouville wall important impact observables background past lightlike infinity part boundary p therefore define observables cal tomega figure nonzero lambda p however future lightlike infinity part boundary p hence outgoing particle cal tomega defined asymptotic observables regime thus p compute scattering amplitude sort nnprimegeq depicted figure however p define amplitude nprime since region operator cal tomega defined shielded potential issue especially significant lambda lambda positive p case seems like good observables since cal tomega cal tomega appear exist reason mainly focus case lambda p comment p lambda various point analysis fact background lambda timedependent implies energy conserved example consider amplitude form biglangleprodjncal tomegajbigrangle tagwhere n particle incident wall absorbed timedependent background p also consider amplitude biglangleprodlnprimecal tomegaprimelbigrangle tag corresponding creation nprime outgoing particle timedependent liouville potential course consider general amplitude form nonnegative nnprime energy omegajomegaprimel case liouville wall static kpz scaling provides insight dynamic suggests scattering process figure generically happen vicinity liouville wall thus interesting generalize scaling analysis case figure example amplitude one biglangleprodjncal tomegajbigranglesimmua lambdab tag power ab determined analyzing behavior amplitude shift phi give sumjnleftiomegajrightaleftprightb tag isumjnomegajbp tag respectively solution equation afracipsumjnomegajnquad bfracipsumjn omegaj tag plugging see dependence correlator energy omegaomegaj via phase factor leftfraclambdamurightfraciomegapexpleftfraci omegaplnfraclambdamuright tag factor similar interpretation one discussed static background eq evaluating vertex operator cal tomega location phit near liouville wall accelerates see figure given find location vertex operator given mu multiplying phase factor former factor g relates vertex operator wavefunction latter implies amplitude dominated region near phit word one would expected timedependent liouville wall figure best absorb incident tachyons region velocity change zero finite value precise location width region depends parameter lambda mu energy particle omegaj mentioned actually compute amplitude one need evaluate coefficient mualambdab address problem next section discussion repeated amplitude corresponds process particle incident timedependent liouville wall nprime particle energy omegalprime emitted wall biglangleprodlnprimecal tomegalprimebigrangle simmualambdab tag ab determined condition sumlnprimeleftiomegalprimerightaleftp rightb tag isumlnprimeomegalprimebp tag solution aifracppsumlnprimeomegalprimenquad b fracipsumlnprimeomegalprime tag analog phase factor case leftlambdamuprightfraciomegapexpleftfraci omegaplnlambdamupright tag phase factor interpretation obtained evaluating vertex operator cal tomega location phit expected conclude emission tachyons timedependent liouville wall figure centered region wall accelerates finish subsection comment looking back figure one ask whether process incoming tachyons reflected liouville wall far region wall accelerates eg tll process course possible clear figure insensitive lambda particular conserve energy found amplitude violate energy conservation general due physic vicinity phit discussion took either n nprime vanish easy generalize nonnegative n nprime expected one find energy violating process sort depicted figure dominated region liouville wall accelerates since background consider time translation invariant amplitude compute receive general contribution disconnected diagram focus connected diagram easy include disconnected one mentioned compute amplitude like need calculate coefficient mualambdab general requires use matrix model next subsection explain strategy calculation strategy calculation take approach problem proved fruitful studying timedependent solution open string theory see eg review start euclidean problem add worldsheet action term delta selambdatplambdatpfracgammapgammap int dzepphileftlambdaeipxlambdaeipxright tag mentioned mostly consider case lambda first sight look problematic since worldsheet action real unless lambdalambda however standard field theory string theory study theory complex action understanding really interested lorentzian theory obtained taking xrightarrowit theory lambda lambda independent real coupling take field x live circle radius r anticipating lorentzian background interest thermal feature order perturbation make sense momentum p must integer multiple r see discussion simplifies significantly take pfracr tagie perturbation carry one unit quantized momentum good understanding case comment happens make choice use euclidean action dual matrix model calculate correlation function form biglangleprodjntqjprodlnprimetql primebigranglelambda tag qjqlprimegeq lambda correlation function must satisfy selection rule sumjqjsumlqlprime due x translation invariance however lambda sum rule need satisfied since deformation break symmetry particular study amplitude n vanish lambda dont finite lambda also study amplitude nprime result read calculation existing literature wick rotate euclidean result lorentzian signature find convenient first fourier transform momentum space result position space wick rotate position space result finally fourier transform back lorentzian momentum space obtain smatrix element plan rest paper following section describe procedure employ later section case accelerating liouville wall usual static case start euclidean momentum space amplitude transform position space wick rotate lorentzian signature finally fourier transform back lorentzian momentum energy space section generalize procedure timedependent case consider background correspond liouville wall static far past approach finite velocity far future final velocity either smaller larger speed light discus case former case compute scattering amplitude n incoming particle one outgoing one eq nprime also compute amplitude creation n particle timedependent background show amplitude thermal character phenomenon reminiscent unruh effect latter case future null infinity shielded potential discus observables one define case section discus generalization analysis section main goal section study case liouville wall accelerates far past far future corresponding eq lambdapm figure regime trajectory liouville wall timelike compute amplitude particle creation find amplitude singularity finite value coupling lambdalambda hartlehawking construction singularity appears correspond disappearance time section describe result previous section matrix model point view well known double scaling limit matrix model reduces dynamic free fermion inverted quadratic potential massless tachyon field corresponds perturbation fermi surface fermion timedependent background study section correspond model background timedependent fermi surface discus dynamic perturbation surface focusing difference case p p relate free fermion description term accelerating liouville wall show dynamic perturbation fermi surface compatible seen bulk dimensional string theory perspective section discus result possible extension two appendix contain review technical result useful analysis wick rotation standard background section illustrate procedure follow timedependent background usual timeindependent background two dimensional string theory corresponding static liouville wall start euclidean theory take x live circle radius r theory known continuum matrix model perspective euclidean continuation nto scattering amplitude take form leftlangleprodjntqjtqprimerightranglepi r npartialmunmuqprimedeltamprimesumjn mj tag mprimeqprimer mjqjr jcdotsn integer momentum order wick rotate amplitude lorentzian signature proceed follows start fourier transforming operator tq position space define complex coordinate yequiv yiy write tyfracpi rsumminftyeifracmrytfracmr qquadbartbaryfracpi rsumminftyeifracmrbar ytfracmr tag clear compact coordinate ysim ypi r parameterizes cylinder using find leftlangleprodjntyjbartbaryrightranglepi rn npartialmunfracmuprodjnfracmufrac refraciryjbary tag wick rotate yiy mean yiu baryiv uyy vyy lightlike coordinate r corresponding wick rotation xphi space xtoit described section looking back see wick rotation one identify u tphi v tphi least asymptotically ie near boundary wick rotation correlation function take form leftlangleprodjncal tujcal tvrightrangle pi rnnpartialmunfracmuprodjnfrac mufracrefracrujv tag next step fourier transform back lorentzian momentum space cal tomegaintinftyinftydueiomega ucal tu qquadcal tomegaintinftyinftydveiomega vcal v tag nto smatrix element given leftlangleprodjncal tomegajcal tomega primerightranglepinpartialmunfracmudelta omegaprimesumjnomegajprodjnmuiomegajg omegajr tag gxequivintinftyinftydzfraceixzez tag integral divergent ztoinfty divergence regularized iepsilon prescription replacing xto xiepsilon contribution integral region ztoinfty becomes convergent integrand also pole origin zplane treated usual deforming integration contour go either case integral computed standard contour deformation technique closing contour upper half plane using fact interested case x positive real part get integral receives contribution residue pole zpi ik integer k ranging infty gxpi isumk rm inftyepi xkpi ifracepi x epi x rm pi ifracepi x tagin application xomega r r related temperature via betatpi r zero temperature rtoinfty first choice gomega r approach constant second go zero therefore get finite zero temperature limit choose first expression checked finite temperature amplitude obtained via wick rotation described consistent calculated limit rtoinfty amplitude take form leftlangleprodjncal tomegajcal tomega primerightranglepi indeltaomegaprimesumjnomega jpartialmunmuisumjnomegaj tag result consistent would obtained simple continuation lorentzian signature present discussion obtained limit finite temperature contains information particular factor gomega r incoming particle written gpi ifracefracomegat tag function constant omegagg varies omegasim fact diverges omegato section discussed fact insertion zero momentum tachyon thought differentiating path integral wrt mu see finite temperature lorentzian signature situation bit subtle equation imply limomegato fracpical tomegagomega rlimomega fraciomegacal tomegatpartialmu tag different situation zero temperature see limit omegato cal tomega give partialmu time multiplicative omegaindependent factor surprising two case different since range energy omegall responsible exist amplitude timedependent background section generalize discussion section case timedependent background described section starting point discussion euclidean analysis finite value radius euclidean time r natural generalize present case calculation section done r perturbed system r must satisfy constraint prmpinmathbbz mp quantized momentum euclidean time direction mentioned section analysis simplifies significantly mp ie rp mainly restrict case comment next section happens mp rest section study example amplitude background lambda start nto amplitude analog nonzero lambda move amplitude production n particle also note calculation section involve connected diagram given external leg general amplitude receive contribution disconnected diagram well fact generally dominant weak coupling limit nto amplitude generalize analysis section case nonzero lambda need first find analog case euclidean theory compact x expect euclidean amplitude perturbative lambda expanding exponential explambdatp need evaluate amplitude form langle tpmprodjntqjtqprimerangle standard background two dimensional string theory momentum qjqprime integer multiple fracr qjfracmjr qprimefracmprimer tag pr iemp momentum integer multiple p analysis subsection performed mp mentioned restrict case mp section comment mp later amplitude interest essentially given leftlangle tpmprodjntqjtqprimerightrangle fracpipmnpartialmumnmuqprimedeltamsum jnmjmprime tag correlator lh computed lambda qj qprime given finite lambda leftlangleprodjntqjtqprimerightranglelambda nfracpipsumminftyfraclambdamm partialmumnmuqprimedeltamsumjnmjm prime tag section next pas position space using give leftlangleprodjntyjbartbaryrightranglelambda leftfracppirightnsumminftyeimpbary partialmumnmumpfraclambdammprodjn fraceipyjbarymup tagnext wick rotate position space expression replacing yjtoiuj barytoiv find leftlangleprodjncal tujcal tvrightrangle lambdaleftfracppirightnsumminftyfraclambda mmempvpartialmumnmumpprodjnfrac epujvmup tag fourier transforming back lorentzian momentum space find leftlangleprodjncal tomegajcal tomega primerightranglelambdapinintinftyinftydve iomegaprimesumjnomegajvpartialmunmui sumjnomegajfracrisumjnomegajisumj nomegajprodjngomegajp tag fracrrpequiv epvmuplambda tag gx given p lambda v varies infty infty r varies changing variable v r find leftlangleprodjncal tomegajcal tomega primerightranglelambdapinfracgammaalphagamma betapgammaalphabetapartialmunmubetalambda alphaprodjngomegajp tag alphafracipomegaprimesumjnomegajequivfracip deltaomegaqquadbetafracipsumjnomegajifracppomega primeiomegaprimealpha tag thus alpha measure extent energy conservation violated alphabeta measure energy outgoing particle next discus special case general expression incoming momentum omegaj go zero use eliminate corresponding operator correlation function one check structure consistent resulting relation amplitude n n incoming particle another interesting limit one process conserve energy corresponds alphato limit amplitude approach leftlangleprodjncal tomegajcal tomega primerightranglelambdapinleftfraclnlambda prightpartialmunmuiomegaprimeprodjngomegajp tag structure understood follows energy conserving process require timedependent perturbation proportional lambda happen arbitrarily far timedependent part liouville wall lnlambda dependence thought parametrizing length time point available energy conserving process indeed eq energy conservation deltafunction latter equation replaced fraclnlambdap expected discussion n correlation function reduces one point function leftlanglecal tomegaprimerightranglelambdafrac gammafracipomegaprimegammaifracppomegaprimep gammaiomegaprimemuifracppomegaprimelambda fracipomegaprime tag one think amplitude creation one outgoing particle energy omegaprime timedependent background consideration discus connected amplitude production multiple particle next subsection particle production subsection compute amplitude production n particle energy omegaomegacdotsomegan timedependent background lambda amplitude discussed section around eq omit prime various variable notational simplicity amplitude defined p since p null future infinity part boundary comment case p later section follow procedure previous subsection thus first goal compute euclidean amplitude langle tqtqcdotcdotcdot tqnranglelambda order need compute amplitude langle tpmtqtqcdotcdotcdot tqnrangle standard c background unlike situation subsection amplitude computed literature therefore calculated using matrix model technique calculation described appendix b calculation simplify significantly case mp ierp subsection present result case found following expression correlation function footnote consistency check take qjp ie mj reduces amplitude computed result agree langle tpmtqtqcdotcdotcdot tqnrangle nfracpipfracmpartialmunmupmprodjn gammaleftpmjrightprodjngammamjgammapmj deltamsumjnmj tag qj integer multiple p qjmjp eq lead langle tqtqcdots tqnranglelambdan fracpipfraclambdasumjnmjpartialmunmu psumjnmjprodjngammaleftpmjright prodjngammamjgammapmj tag position space langlebartbarybartbarycdotsbartbaryn ranglelambdaleftfracppirightnpartialmun fracmuprodjnfeipbaryjlambdamup tag fxequiv summinftyfracxmgammaleftmprightm gammamp fracpartialpartial xsumminftyfracxm gammaleftmpprightmgammampp tag fracpartialpartial xfracrpp rx defined similarly fracrrpx tag wick rotating baryjivj give langlecal tvcal tvcdotscal tvnrangle lambdaleftfracppirightnpartialmunfrac muprodjnfepvjlambdamup tag finally fourier transforming omega space find langlecal tomegacal tomegacdotscal omeganranglelambdaleftfracpirightnfracp partialmunfracmuprodjnfracgammaleftfraci omegajprightgammaleftfracppiomegajrightgammai omegajlambdamupifracomegajp tag better understand structure useful consider position space correlator basic building block correlator factor function fx xepvlambdamup tag external leg momentum space correlator obtained f fourier transforming v whch related x via left panel figure plot function fx value p chose value close one since discussed section one interesting issue happens particle creation amplitude pto point beyond future null infinity disappears see p approach function fx approach step function centered x right panel figure verify focusing behavior function f close x p close one form function f figure seems agreement physical picture suggested figure particle created throughout whole process acceleration liouville wall corresponds v infty infty indeed general p function f support x range infty however p approach velocity wall late time approach speed light atp upper bound value v corresponding position wall thus natural limit f approach step function location step vtphi phit appear figure given eq one check eq implies vtphi equal v corresponds x figure via eq steep decline function f near x p close corresponds physically fact pto region vsimeq v corresponds larger larger utphi speed liouville wall already approximately equal final value thus region doesnt radiate contribution fourier transform performed going small interesting take limit omegato following logic figure position space amplitude includes factor function f created particle figure plot function range value p demonstrate approach step function pto get finite answer must take limit follows limomegato fracpi iomegacal tomegappartialmu tag recalling temperature given tpi rppi see limit compatible taken another interesting limit pto clear eq figure limit go back timeindependent background corresponding stationary liouville wall section thus limit particle production amplitude go zero see indeed case note limit phase given together contribution beta function prefactor rapidly oscillating nonzero omega thus amplitude create particle finite distribution energy go zero limit pto discussion also interesting consequence result subsection equation finite limit omegaprimeto leftlangleprodjncal tomegajcal trightrangle lambdafracnpinpisumjnomegajsinh leftfracpisumjnomegajprightpartialmunmu fracipsumjnomegajlambdafracipsumjn omegajprodjngomegajr tag using conclude amplitude vanishes n energy omegaj word amplitude process n tachyons come past null infinity absorbed timedependent liouville wall tachyons come late time vanishes p p general discussion section lead one believe p observables cal tomega problematic indeed looking back figure see p future null infinity shielded dynamical liouville wall smatrix defined interesting see reflected calculation reported earlier section goal subsection following discussion subsection euclidean result clearly valid p wick rotate get position space correlation function important difference case p present one concern equation recalling variable x equation related v via eq see p v go infty infty x go infty r go however p situation different case one write xrrp r go x first increase maximal value xrm max decrease back r maximum function xr occurs rp xrm maxxppppp tag term variable v r varies v increase infty vrm max related xrm max via go back infty mean fourier transform done p going position space momentum space longer done since range v extend way infty discussion nice correspondence property potential figure eq solid line figure obtained setting vrm sttphi since interested process emission tachyons accelerating liouville wall interested value v along wall clear figure p move along liouville wall v varies infty infty p behavior different case wall start vinfty early time move larger v reach maximal value v vrm max figure b velocity reach speed light start decreasing going back vinfty late time short calculation using eq show vrm maxfracplnfracpppplambdamup tag discussion function xr obtained value vrm max plugging interestingly two value vrm max computed different way coincide footnote general expect agreement order one constant fact could set vrm sttphi constant neq happens v agreement appears exact also explains function xr property p xxrm max appears twice r varies term figure b reflection fact vvrm max appears twice timelike part trajectory liouville wall spacelike one former corresponds rp latter pr p interesting plot function fx p value p figure expected function f two branch upper one corresponds timelike part trajectory liouville wall start x ier vinfty f like p figure case monotonically increase diverges xto xrm max divergence appears due fact acceleration liouville wall diverges speed approach light viewed function r f single pole rp thus transition spacelike part trajectory liouville wall rp described lower branch curve figure f start infty rapidly go zero decline becomes pronounced pto order understand behavior one need make sense observables case p related fourier transform amplitude detecting particle future null infinity mentioned p amplitude make sense reflected analysis fact variable vj case bounded vrm max thus usual fourier transform done two attitude one take state affair one p physical observables associated future region seems problematic especially given fact discussed introduction next section one turn lambda lambda case asymptotic particle state cease exist since past future null infinity shielded potential possible attitude correlation function make sense p seems case analysis case one need interpret physically return question later section figure form function fx p singularity function xxrm max two branch correspond rp upper rp lower equivalently timelike spacelike part trajectory liouville wall generalization main goal section discus generalization analysis section case lambda lambda positive however start two brief comment issue mentioned earlier first involves quantum correction result section analysis section done leading order g ie worldsheet taken spherical topology matrix model allows one compute higher order g correction result example b b present result first subleading correction euclidean correlation function langle ttpmtqrangle langle ttpmtqtqrangle respectively correction come worldsheet torus section used calculate torus contribution one twopoint function cal tomega leave detailed study contribution future work second issue want comment involves eq said section euclidean calculation one could principle consider value quantized momentum ie take prmp seems right value mp one reason believe mp structure amplitude becomes much involved would like explain mean general integer mpgeq calculation mp lead give following result n qjfracmjr sumjnmj integer multiple mp find langle tqtqtqranglelambdafracpi rmu lambdamupfracmpsumjmjprodjh qj tag hqequivpqpqpprodiqpleftfracqiright tag one check mp agree mp complicated follows pattern still product factor associated external leg four point function factorized structure break find langle tqtqtqtqranglelambdafrac pi rmulambdamupfracmpsumjmjh qcdotsqprodjhqj tag hqqqqequiv mpmsumtsubseteqqqq qfractsumlmqtlp taghere subset qqqq qt denote number sum element respectively one check qjp integer case mp eq reduces however general mp qjp integer complicated complexity increase number insertion n increase believe resulting theory correspond wick rotation theory described section would interesting understand whether physical interpretation left future work next turn case lambda lambda positive start comment section discussed case lambda liouville wall stationary past timedependent form future case lambda similarly studied taking ttot exchanging role cal cal turning tp tp potential take form vrm sttphimu ephilambdaepphiptlambdae pphipt take coupling lambdapm positive principle could take momentum lambda deformation different negative lambda one however discussed euclidean space technique make natural take r consistent show perturbation lead thermodynamic behavior temperature ppi thus restrict case two momentum equal opposite lambdapm set lambdalambdalambda shifting origin time case depicted figure worldsheet theory symmetry ttot allows one use hartlehawking construction replace region background euclidean analog similarly xtox symmetry view providing initial state lorentzian evolution lambdapm nonzero ambiguity definition mu either coupling vanishes go region liouville wall stationary read mu however lambdalambdaneq region exist ambiguity play role rest section generalize discussion section case lambdalambda use method start euclidean calculation go position space wick rotate go back lorentzian momentum space consider amplitude emission n outgoing tachyons amplitude absorption n tachyons obtained using time reversal symmetry mentioned fortunately euclidean amplitude needed analysis calculated particular beginsplitlangle tpmmprimetpmprimetq tqcdots tqnranglenmprime fracpipmmprimepartialmunmprimemupmm prime pmprimeprodjnfracgammaleftpmj rightgammamjgammapmjdeltamsumjnmjendsplit tag therefore beginsplitlangle tqtqcdots tqn ranglelambdalambdasummmprime inftyfraclambdammprimelambdamprimemm primemprimelangle tpmmprimetpmprimetq tqcdots tqnrangle summprimeinftyfraclambda sumjnmjmprimelambdamprimemprime nmprimefracpippartialmunmprime mupsumjnmjmprimepmprime prodjnfracgammaleftpmjrightgammamjgamma pmjendsplit tag figure general lambda lambda trajectory liouville wall take qualitative form depicted missingpagefail next comment property one property p diverge stofracp value corresponds maximal value coupling lambdalambda according physic singularity discussed euclidean system case worldsheet potential proportional co px singularity associated field x settling minimum potential disappearing dynamic footnote p singularity since sfracp outside physical regime leq lorentzian system would correspond disappearance time exotic phenomenon leave complete understanding phenomenon future work note setting question happens approach critical value fracp addressed hartlehawking construction mentioned another interesting feature effect nonzero function f change argument multiplicative factor sp one possible way interpret use observation made earlier coupling lambdapm nonzero notion mu ambiguous thus view multiplicative factor argument f due renormalization mu indeed make replacement mutomus tag argument f go back choice natural since also simplifies eq becomes footnote note since p implies leq term rescaled mu rh bounded different parametrization coupling space standard phenomenon qft splambdalambdamup tag note also replacement found simplify expression partition sum euclidean theory see discussion around eq paper see replacement also natural point view dynamic free fermion matrix model however whether make replacement important thing nonzero ambiguity rescaling mu function different description theory may differ rescalings section showed lambda lambda npoint function vanishes see discussion around eq note feature also follows indeed symmetry tleftrightarrowt leftrightarrow implies amplitude proportional lambdafracipsumomegaj lambda decrease factor lead rapidly oscillating phase amplitude vanishes limit lambdato another calculation section interesting generalize case lambdapm comparison vrm max obtained potential amplitude lambda found precise agreement two general lambda second way determining vrm max give answer term renormalized cosmological constant since redefinition argument function f determine vrm max potential need calculate value v liouville wall associated reach speed light short calculation lead result epvrm maxfracppfspplambdamup tag f determined fsleftfracppsppspfsrightp tag give f agrees expected sto behaves fsto simeqleftfracpprightfracpppsp tag general sin interpolates two behavior demonstrated figure thus agree two differ redefinition mu similar mutomu gsfracp tag g ratio two f function ratio smooth finite function sin view agreement redefinition sufficient difference two calculation seems due fact one figure solution several value p one amplitude includes quantum effect worldsheet theory one based form liouville potential classical note fact vrm max take general form follows symmetry problem shift phi appropriate rescaling mu lambdapm potential invariant together freedom rescale mu function seems make agreement different calculation superfluous believe main test agreement different calculation mentioned resulting ratio g finite free fermion perspective analysis previous section performed perspective dimensional string theory bulk theory holographic correspondence use result dual boundary theory matrix quantum mechanic mqm double scaling limit tool computing correlation function standard background section discus physical picture obtained earlier section point view boundary theory reviewed appendix double scaled mqm viewed theory ntoinfty free fermion inverted harmonic potential standard background corresponds state energy level mu filled figure fermi surface take form figure background paper correspond fermi surface timedependent dynamic fermi surface studied particular background general pleq discussed lambda background correspond fermi surface take parametric form beginsplitlambdaacosh waepw pt plambdaasinh waepwptendsplit tag inftywinfty asqrtmuqquad afracsqrtlambdamufracp tag eliminating w fermi surface take form footnote note imply plambdalambda p w lambdaplambdafracaapeptplambda lambdapa tagin figure plot p p illustrate time evolution fermi surface p p respectively early time ttoinfty fermi surface approximately static given lambda branch hyperbola lambdaplambdamu fermion fill region inftylambdaleqsqrtmu lambda space term coordinate phi related lambda via relation lambdasqrtephi tag inftyphileqfraclnmu increase fermi surface move left rightmost edge lambdarm maxt determined solving equation partialwlambda large p one find wsimfracppt lambdarm maxsim efracppt phirm maxsimfracppt edge distribution move left speed fracpp smaller speed light note velocity liouville wall see figure though see two edge fermi surface liouville wall distinct object p lambdarm maxt corresponds large wsim lambdarm maxsim et phirm maxsimt thus case edge fermi surface move left speed light lower branch fermi surface figure corresponds asymptotically wtoinfty limit plambdalambdaaewto fermi surface approach line plambdalambda figure profile fermi sea p b p term parametrization wtopminfty correspond asymptotic region lower upper branch respectively asymptotic region upper branch figure corresponds wtoinfty using fact plambdalambdaaewaepwpt see p plambdalambdato limit p plambdalambdatoinfty footnote note however sum plambdalambda grows slower w two quantity separately massless tachyon bulk dimensional string theory description corresponds fermion language ripple fermi surface standard background described fermi surface figure incoming tachyon described ripple start early time upper branch hyperbola large negative lambda phi since plambda positive ripple propagates right corresponds cal figure time go ripple propagates fermi surface figure eventually time reach lambda axis move lower branch hyperbola plambda thus moving left corresponds asymptotically large cal transition two regime happens plambda ielambdasqrtmu phifraclnmu latter precisely location liouville wall see figure expected clearly description generalized case nonzero lambda case incoming tachyons correspond ripple starting early time upper left region figure propagate right change direction value lambda timedependent fermi surface intersects lambda axis thus position liouville wall given setting plambda expression fermi surface using one check give precisely equation vrm sttphi vrm st given previous section saw qualitative difference case p trajectory liouville wall remains timelike p eventually becomes spacelike interesting see difference manifest free fermion language purpose turn detailed description ripple fermi surface correspond language tachyon perturbation dimensional string theory small ripple thought point fermi surface follow trajectory plambdadotlambdaqquadlambdadotplambda tag solution equation lambdarhocoshtsigmaqquad plambdarhosinhtsigma tagwhere rho sigma determined initial condition take rho since want consider perturbation fermi surface extends lambdatoinfty parameter sigma independent rho since trajectory question must lie fermi surface plugging get sigmarhofracplnfracrhoaapaa rhop tag trajectory following qualitative structure ttoinfty eq implies lambdatoinfty plambdatoinfty plambdasimlambda thus early time describes ripple moving right large negative lambda speed close speed light tsigmarho ripple turn around start going left ieplambda change sign time ripple lambdarho thus position liouville wall tsigmarho ttoinfty lambda plambdatoinfty plambdasimlambda ie speed ripple approach speed light plot example trajectory figure eq implies constant rho varies infinity rhotoa sigmatoinfty describes trajectory coincides shape earlytime fermi surface trajectory cross lambda axis tsigma also go infty limit thus limit describes ripple reflected timedependent liouville wall early time ripple finite time egt lambdarhocoshsigmasim aesigmatoinfty much larger absolute value lambdarm max time furthermore plambdasimlambda time mean ripple approach speed light corresponds ripple propagates left along lower branch fermi surface figure well separated tip fermi surface large rho implies sigmasimfracpplnrho ripple reflected liouville wall late time tsigma fate ripple depends sign p see useful ask time ripple given rho pas tip fermi surface time obtained solving equation leftpartialrholambdarightttcoshtsigmarhorho sinhtsigmarhosigmaprimerho tag give etfracprhoapleftfracrhoa apaarightfracp tag check equation clear figure must trhosigmarho ie ripple given rho first encounter liouville wall turn around later time approach tip fermi surface one check rho real solution indeed case rhotoa trhotoinfty consistent discussed saw rhotoa ripple cross lambda axis tsigmatoinfty early time hyperbola describing fermi surface symmetric plambdatoplambda fermi surface approximately static time plambda approximately coincides tip fermi surface sigmarhosim trho rho increase trho increase monotonically p rho varies infty run infty infty word ripple rho start upper branch fermi surface early time reach tip fermi surface finite time trho move lower branch fermi surface figure smatrix discussed section case corresponds process hand p increase rho get critical rho rhocsqrtfracppa tag diverges arhorhoc picture like p illustrated two rightmost dashed line figure rhorhoc ripple never get tip fermi surface stay upper branch case trajectory described two leftmost dashed line figure rhorhoc ripple approach tip fermi surface ttoinfty interestingly bound rhorhoc described corresponds bound v encountered section indeed calculate value vtphi figure solid line describe form fermi surface p value dashed black line describe ripple various value rho ripple rhorhoc reflected liouville wall time reflected tcsigmarhoc spatial position lambdacrhoc see discussion phiclnfracrhocsqrt one check tcphicvrm max given ripple rhorhoc reflected vrhovrm max expected discussion function vrho maximum rhorhoc seen follows vrhotrhophirhosigmarholnfracrhosqrt tag thus vprime equivalent sigmaprimerhofracrho tag see relation satisfied rhorhoc look back recalling rhotorhoc ttoinfty conversely satisfied rho sigmarho finite must go infinity mean rhorhoc therefore vrho following qualitative structure monotonically increase rho critical value given vrm max monotonically decrease rhorhoc precisely behavior one expects form liouville wall figure b rhorhoc ievvrm max picture similar p particular appears ripple value rho smatrix describing propagation asymptotic past infinity upper branch asymptotic future infinity lower one return observables next section want mention two thing one similar position space observables defined section eg eq particular range v physical interpretation similar two case footnote direct analog discussion two point function langlecal tcal trangle second case puzzle associated observables language section incoming ripple reflected liouville wall vrhovrm max propagate left lower branch fermi surface however eventually overtaken liouville wall corresponds intersection fermi surface lambda axis figure b asymptotically move faster light thus physical interpretation string theory observables unclear since latter defined far liouville wall section discussed generalization analysis case lambda lambda nonzero interesting describe case free fermion language fermi surface take form beginsplitlambdaacosh waepwpta epwpt plambdaasinh waepwptae pwptendsplit tag apmfracplambdapmap satisfies equation mufracaplambdalambdaleftfraca rightp tag eq generalize case lambda lambda nonzero figure plot resulting fermi surface understand useful define quantity psi via equation fracamupsi tag plugging comparing see psifracs tag figure profile fermi sea p b p apm note symmetry ttot thus one think fraca renormalized cosmological constant discussed section around eq qualitative picture expected case discussion special case lambda p ripple fermi surface propagate upper branch hyperbola figure early time lower branch late time one define smatrix p maximal value v vrm max beyond remain trapped make asymptotic infinity lower branch next calculate vrm max recall vrho value tphi point ripple certain rho reflected liouville wall rho approach critical value v approach vrm max time ripple pass edge fermi surface go infinity used calculate vrm max general case tip fermi surface obtained solving equation fracpartiallambdapartial wasinh wpaepwptpa epwpt tag w plugging back calculate vrm max need take ttoinfty limit solution wsimeq tfracplnfracpaa tag plugging get lambdatsimeqfracetleftfracppapap prightfracp tag hand learn large lambdatsimeqfracetrhocesigmac tag comparing two equation rhocesigmacleftfracppapapp rightfracp tag expression lh nice interpretation discussed earlier section critical ripple reflected liouville wall tlambdasigmacrhoc term tphi tcphicsigmaclnfracrhocsqrt thus evrm maxephicsigmacfracsqrtrhocesigmac tagplugging conclude evrm maxsqrtleftfracppppapa rightfracp tag epvrm maxfracpppplambdaap tag result got analysis amplitude section also agrees result got lambda written term renormalized cosmological constant summary discussion summary main goal paper study dimensional string theory timedependent background building previous work subject bulk point view holographic duality dimensional string theory double scaled matrix quantum mechanic background correspond solution liouville wall accelerating one velocity far past another far future boundary theory correspond solution fermi surface free fermion inverted harmonic potential timedependent discussed different type background kind background studied detail section liouville wall move towards boundary velocity go zero ttoinfty finite value ttoinfty final velocity wall smaller larger speed light former case depicted figure one define smatrix n incoming tachyons go nprime tachyons used wick rotation euclidean spacetime study particular process nto scattering production n outgoing tachyons timedependent background final velocity liouville wall larger speed light asymptotic future null infinity shielded liouville wall outgoing massless tachyons longer defined nevertheless found one seems able define asymptotic observables vjvrm max latter given one think observables associated outgoing tachyons produced timedependent background bound null coordinate vtphi related fact tachyons produced liouville wall case maximal value v see figure b section discussed generalization system velocity liouville wall approach equal opposite finite value early late time see figure velocity smaller speed light found similar structure section one define nto nprime smatrix tachyon scattering compute using matrix model worldsheet technique demonstrated computing amplitude creation n tachyons given eq amplitude qualitatively similar encountered section become even rescaling mu given new feature amplitude divergence finite value coupling determines local acceleration liouville wall closely related euclidean problem corresponding divergence signal decoupling euclidean time x worldsheet dynamic kind dynamical dimensional reduction proposed similarly divergence may due decoupling time though complete understanding required section discussed timedependent background described point view dual matrix quantum mechanic double scaling limit theory reduces theory free fermion different background correspond different choice shape fermi surface tachyon perturbation bulk dimensional string theory described language ripple fermi surface presented fermi surface corresponding background section studied dynamic ripple surface function parameter found nice agreement picture based scattering amplitude section free fermion description region parameter space liouville wall follows timelike trajectory found ripple fermi surface propagate upper branch figure early time lower branch late time thus giving analog smatrix section showed trajectory viewed due reflection timedependent wall coincides liouville wall discussed section also showed fermi surface picture exists critical value coupling agrees precisely found section region liouville wall turn spacelike early andor late time showed trajectory ripple fermi surface make corresponding asymptotic infinity value parameter describing ripple found bound parameter found seemingly different point view studying amplitude section summary found nice agreement three seemingly quite different point view tachyon dynamic timedependent background studied scattering timedependent liouville wall amplitude obtained wick rotation euclidean correlation function dynamic ripple timedependent fermi surface section much remains done next list issue require attention observables p one surprising result analysis background priori asymptotic observables associated past andor future asymptotic infinity nevertheless found observables moreover found two different point view study scattering amplitude section study ripple timedependent fermi surface section example analysis section found one define observables depend lightlike position variable vj bounded vrm max one think observables describing emission tachyons timedependent liouville wall vrm max largest value vtphi along wall figure b analysis section observables correspond ripple rhorhoc start early time upper branch hyperbola figure b make late time lower branch along propagate asymptotic infinity existence observables first sight puzzling mentioned term figure b appear correspond outgoing tachyons cal tomega emitted accelerating liouville wall however regardless value v emitted eventually liouville wall catch absorbed term picture section correspond ripple propagating left lower branch hyperbola figure b picture liouville wall corresponds intersection hyperbola lambda axis asymptotically late time move faster light thus eventually ripple find behind wall raise question define cal observables make future region well outside liouville wall leave detailed analysis issue future work possible resolution tension following seems clear operator cal tomega defined real omega make sense future null infinity behind liouville wall however possible observables defined omega finite imaginary part imaginary part must taken positive since otherwise corresponding operator normalizable would imply existence normalizable state general write omegawriomegai omegai resulting operator cal tomega behave late time like expomegait ie go exponentially zero late time consistent picture suggested figure b correspond tachyons penetrate liouville wall late time also resolve puzzle regarding definition observables since defined boundary spacetime phirightarrowinfty remains outside liouville wall proposal late time observables decay exponentially trightarrowinfty suggests system asymptotically spacelike liouville wall unique final state reminiscent proposal unique final state associated black hole singularity hartlehawking proposal unique wavefunction universe associated big bang singluarity proposal also reminiscent studied string dynamic background cosmological singularity background contain big bang big crunch singularity thus one define standard string theory smatrix observables time described solvable worldsheet theory contain physical observables studied using standard worldsheet technique author showed resolution tension cosmological spacetimes studied contain additional region referred whisker natural string observables nonnormalizable vertex operator defined boundary region approach linear dilaton spacetimes setup similar one depicted figure p like liouville wall figure shield past future null infinity thus provides soft version big bang big crunch singularity therefore one define standard smatrix according proposal one define nonnormalizable observables timelike boundary phirightarrowinfty analog boundary one whisker case one advantage system described paper one one study behavior spacelike singularity p one p contrast system past future spacelike singularity always present proposal observables made p correct one need understand implication fermi surface picture section particular one need understand see fact observables correspond nonnormalizable operator decay exponentially early andor late time may one generalize description ripple fermi surface point follow trajectory study dynamic finite size ripple leave issue future work another puzzle may require going beyond description tachyons dimensional string theory pointlike ripple fermi surface following section showed coupling increase encounter singularity amplitude finite value coupling section argued fermion language corresponds fact timedependent fermi surface exists region parameter space showed region section however one look critical fermi surface plugging sp one find smooth fermi surface show sign divergence encountered section possible understand divergence language section one need study dynamic finite size ripple another possibility suggested form divergence eq feature vacuum insensitive perturbation left future work property scattering amplitude string scattering amplitude computed work relied worldsheet analysis background indeed mqm used computational tool evaluate string scattering amplitude undeformed dimensional string theory section reviewed fermi surface picture dual timedependent background used study property timedependent liouville wall trajectory pointlike ripple would interesting use free fermion description compute scattering amplitude p would nontrivial check procedure compute scattering amplitude followed work well proposed fermi surface dual timedependent background leave question future work region parameter space p scattering amplitude satisfy constraint coming unitarity causality timedependent background constraint straightforwardly implemented would interesting explore scattering amplitude satisfy limit pto timedependent background similar one considered work recently discussed see also background work similar limit pto lambda lambdaneq focused section opposite case lambda lambdaneq two related timereversal symmetry interestingly result correlators different example found npoint function vanish analog paper important difference two construction notation lambda lambdamu see applying timereversal related system lambdamu lambda hand took lambda positive possible difference responsible difference correlation function note flipping sign lambda construction important effect positive lambda analysis potential vrm st go infinity everywhere shaded region figure negative lambda region along positive v axis potential remains small thus incoming mathcalt wave penetrate potential direction possible process captured correlation function note also limit pto worldsheet theory lambdalambda factorizes direct product theory phi one phi theory liouville theory c timelike liouville c factorization played important role analysis p subject paper factorization break one use technique analyze resulting background one reason used matrix model result analyze dynamic also note lambdapm nonzero look superficially p worldsheet theory still factorizes product theory phi fact case reason would theory wick rotated version sinegordon model coupling lambdalambda case marginal truly marginal thus theory exhibit rg flow coupling phi rg happens function phi closed string radiation timedependent background considered work reminiscent rolling tachyon solution openstring analogue timedependent background p however case fate background known rolling tachyon case brane decay emitting closed string particular shown closed string radiation produced rolling tachyon given coherent state form ecadaggerrangle tag adagger creation operator closed string alpha proportional disk point function closed string vertex operator rolling tachyon boundary condition closed string radiation state produced timedependent background case similar except alpha computed sphere point function p particular order g follow compute total number n energy e closed string produced timedependent background find beginsplit nintinftydomega omegaleftleftlanglecal tomegaprimerightranglelambda right eintinftydomega omegaleftleftlanglecal omegaprimerightranglelambdarightendsplit tag polynomial factor omega relative come normalization tachyon operator using expression find integral converges large omega p note however n e order g since leftlanglecal tomegaprimerightranglelambdasim g mean total number energy closed string produced timedependent background order original background backreaction taken account leave detailed understanding backreaction future work footnote expression ir divergence small omega region dealt introducing ir cutoff moving mirror description dynamic term scattering tachyons timedependent liouville wall reminiscent moving mirror problem qft model often used toy model black hole physic application mirror taken receding observer approaching speed light late time generally mirror taken move away towards observer final speed different light see eg recent discussion model liouville wall qualitatively similar moving mirror analogy precise since case moving mirror one typically take quantum field vanish mirror whereas liouville wall soft mentioned earlier paper another difference two problem since liouville wall physical object move faster light something possible physical mirror nevertheless would interesting study relation result moving mirror problem example comparing particle production scattering amplitude get obtained studying moving mirror follows similar trajectory left future work acknowledgement thank ahmed almheiri amit giveon finn larsen massimo porrati victor rodriguez zixia wei xi yin discussion work supported part doe grant desc bsf grant work bb also supported nsf grant phy phy phy appendix matrix model dual dimensional string theory calculate correlation function use matrix quantum mechanic dual dimensional string theory following approach appendix briefly review approach hamiltonian matrix quantum mechanic hfracrm trleftpxright x nbyn hermitian matrix p canonically conjugate momentum closed string excitation dual state singlet sector matrix quantum mechanic study sector convenient diagonalize x writing xulambda u uin un lambdarm diaglambdacdotslambdan singlet sector wavefunction psi depends eigenvalue lambdai completely symmetric exchange pair eigenvalue psicdotslambdaicdotslambdajcdotspsicdotslambdaj cdotslambdaicdots useful make similarity transformation hdeltawidetildehdelta deltaprodijnlambdailambdaj vandermonde determinant widetildehfracsuminleftpartiallambdai lambdairight hamiltonian widetildeh act wavefunction widetildepsilambdaideltapsilambdai wavefunction widetildepsilambdai antisymmetric exchanging pair eigenvalue thus hamiltonian widetildeh describes system n nonrelativistic noninteracting fermion moving potential vlambdafraclambda potential vlambda unbounded arrive theory dual twodimensional string theory consider following doublescaling limit study system fixed fermi energy emu send nrightarrowinfty thus fermion fill state energy le emu see figure state dual closed string vacuum vertex operator correspond infinitesimal perturbation closed string vacuum sufficient consider perturbation fermi surface one side potential figure say one lambda clear figure effect mix two side nonperturbative mu correspond nonperturbative effect string theory see eg recent discussion semiclassical description fermion fill fermi sea surface lambdasqrtplambdamu plambda denotes momentum conjugate lambda see figure string coupling g given pi gsequivmu closed string excitation dual perturbation fermi surface see detail fermi surface written term fermion density fermion bilinear using correlation function tachyon operator calculated using dual matrix quantum mechanic description formalism allows one express figure fermi sea shaded region corresponding standard background dimensional string theory described section figure semiclassical description closed string vacuum dual c matrix quantum mechanic missingpagefail equivalent qqfj definition eqalignrqqfjmuqqfjsqrtoverpieipicos leftpiover imuqqfjrightcrgammaleftover muqqfjright hand tsubseteq fjfj mean qt therefore qqfj eqalignrqqfjmuqqfjsqrtoverpieipi cosleftpiover imuqqfjrightcrgammaleft imuqqfjright combining two reflection amplitude find interesting property musumjnqjprodjkrqqfjrqqfj depends mu q combination imuq matrix model smatrix cal rqjqprimel dual string theory scattering amplitude closed string relation given biglangleprodjntqjprodlnprimetqprimel bigranglemusumjnqjcal rqjqprimelover prodjnqjprodlnprimeqprimel practice easier calculate scattering amplitude insertion cosmological constant operator discussed insertion equivalent acting partialmu correlation function stripped thus eqalignbiglangletprodjntqjprodlnprimet qprimelbigranglelimepsilonto biglangletn epsilonprodjntqjepsilonprodlnprimetq primelbigranglecrlimepsilonto partialmubiglangleprodjntq jepsilonprodlnprimetqprimelbigranglecr limepsilonto overprodjnqjprodlnprimeq primelpartialoverpartialmuleftmusumjnqjcal r qjepsilonqprimelright since cal rqjqprimel depends mu q combination imuq follows convert muderivative qderivative moreexplicitly fracpartialpartialmuleftmusumjnqjmathcal rqjepsilonqlprimerightdeltaleftsumjnqjepsilon sumlnprimeqlprimerightinnprimemusumjn qj qquadsumkminnnprimefracksummathrmaf kint dqbiggpartialqbiggprodjksumtsubseteq f jfjtthetabigqtbigqqfjbig big prodjksumtsubseteq fjfjt thetabigqqfjqtbigbiggprodjkrqqfj rqqfjbigg integrated part q derivative theta function delta function integration give finite sum finally note compact case xsim xpi r dirac delta function momentum conservation replaced kronecker delta time pi r appendix b closed string amplitude appendix outline calculation closed string amplitude langle ttpmprodjntqjrangle using matrix model technique discussed appendix one outgoing particle qmp min z lead beginsplitlangle ttpmtqrangle limepsilonto langle tttpepsilonmtqrangle limepsilonto pi rfracimpmqmump int dqbiggpartialqbiggsumtsubseteq ff tthetabigqtbigqqfbigbig b ffq b ffunderbracepepsiloncdotspepsilonm bperforming integration q find beginsplitlangle ttpmtqranglelimepsilon pi rfracimpmqmump biggsumtsubseteq fftrqt mprqtsumtsubseteq ffttheta bigqtqtbig sumtsubseteq fftrqtmp rqtsumtsubseteq fftthetabig qtqtbigbiggendsplit b first term square bracket simplified sumbmbbinommbrbmprbp b second term square bracket vanishes see consider two possible choice tvarnothing sumtsubseteq fftthetabigqtqt bigsumtsubseteq fftthetabigqt bigsumbmbbinomnb b hand tq qtqtqtqleqmepsilon theta function give zero therefore langle ttpmtqranglepi rfracimpmqmumpsumb mbbinommbrbmprbp b leading order mu expansion ie leading order string perturbation theory find beginsplitlangle ttpmtqrangle mpi rmumpmprodimqipi rmumpmfracgammam pgammampendsplit b checked b follows b leq mleq conjecture result hold integer case conjecture known correct since scattering amplitude b known exactly see eg however u warmup exercise towards case answer known work using b one compute correction b mu expansion leading correction given beginsplitlangle ttpmtqrangletexttorus pi rmumpmfracgammampgammampfracmpmp muendsplit b two outgoing particle subsection calculate correlation function langle ttpmtqtqrangle qmp qmmp integer mm first beginsplitlangle ttpmtqtqrangle limepsilonto pi rimmump fracpmqqsumkfracksumtextafkint dq prodjkbiggrqqfjrqqfj partialqbiggprodjksumtsubseteq fj fjtthetabigqtbigqqfjbigbig prodjksumtsubseteq fjfjt thetabigqqfjqtbigbiggbiggendsplit b k ffqq b ffunderbracepepsiloncdotspepsilonm b without loss generality take mmm contribution textaf rh b beginsplitint dqbiggsumbmbbinommb deltabigbpqbigsumtsubseteqqqt thetabigqqtbigrqmprq sumbmbbinommbthetabigbpqbigsum tsubseteqqqtdeltabigqqtbig rqmprqbigg sumbmbbinommbrmbpr bpsumbmmmbbinommbrmbprbp mbinommmrqrqm mbinommmmrqrqendsplit b k rh b f either q q due symmetry exchanging ffleftrightarrow ff ffleftrightarrow ff b possibility lead contribution need look one namely fjfjqj b besides fjfjunderbracepepsiloncdotspepsilonnj bwith integer nn nnm contribution af rh b given beginsplit sumnmfracmnmn biggnmbinommnmrrqnprq rnp sumbminmmnmnbinom nbbinommnmnbrqbprnbprbprq nbp sumbmnmbinommnbbinomn bnmrqbprmnbprbprbnpq biggendsplit b note overall factor come contribution case fq cancel factor frack b extrapolating case leq mleq conjecture following general formula leading order mu beginsplitlangle ttpmtqtqrangle mpi rmumpmfracmmmmprodimq iprodimmqi pi rmumpmmfracgammaleftpm rightgammaleftmrightgammapmfracgammaleftpm rightgammaleftmrightgammapmendsplit b leading correction b beginsplitlangle ttpmtqtqrangle texttoruslangle ttpmtqtq rangletextspherefracmpmmuleftmmmmp right leftmmmmpmmmp rightendsplit b three four outgoing particle let consider amplitude three outgoing particle langle ttpmprodjtqjrangle using let mjqjp integer mmmm leading order mu find beginsplitlangle ttpmtqtqtq ranglempi rmumpmmmpmprodj fracprodimjqjimj pi rmumpmmmpmprodjfrac gammaleftpmjrightgammaleftmjrightgammapmj endsplit b checked result leq mleq conjectured general formula four outgoing particle langle ttpmprodjtqjrangle start qjmjp mjin z mmmmm find beginsplitlangle ttpmtqtqtqt qrangle mpi rmumpmmmpmmpmprod jfracprodimjmjpimj pi rmumpmmmpmmpmprodj fracgammaleftpmjrightgammaleftmjrightgammapmj endsplit b checked result leq mmmmmleq number outgoing particle interestingly result langle ttpmprodjntqjrangle n find correlation function expressed universal way langle ttpmprodjntqjranglenpi rpartial munmumpmmprodjnfracgammaleftpmjright gammaleftmjrightgammapmj b integrating wrt mu get rid using tpartialmu find langle tpmprodjntqjranglenpi rpartial munmumpmmprodjnfracgammaleftpmjright gammaleftmjrightgammapmj b conjecture result hold n reference n seiberg note quantum liouville theory quantum gravity prog theor phys suppl r klebanov string theory twodimensions spring school string theory quantum gravity followed workshop hepth p h ginsparg g w moore lecture gravity string theory theoretical advanced study institute tasi black hole string particle pp hepth jevicki development string theory workshop string theory gauge theory quantum gravity hepth doi nakayama liouville field theory decade revolution int j mod phys hepth e j martinec matrix model string theory nato advanced study institute marie curie training course application random matrix physic pp hepth anninos b muhlmann note matrix model matrix musing j stat mech j maldacena large n limit superconformal field theory supergravity adv theor math phys hepth gubser r klebanov polyakov gauge theory correlators noncritical string theory phys lett b hepth e witten antide sitter space holography adv theor math phys hepth aharony gubser j maldacena h ooguri oz large n field theory string theory gravity phys rept hepth aharony berkooz kutasov n seiberg linear dilatons n fivebranes holography jhep hepth aharony brief review little string theory class quant grav hepth kutasov introduction little string theory ictp lect note ser b balthazar v rodriguez x yin zz instantons nonperturbative dual c string theory jhep b balthazar v rodriguez x yin multiinstanton calculus c string theory jhep sen fixing ambiguity two dimensional string theory using string field theory jhep sen divergent complex amplitude two dimensional string theory jhep sen cutkosky rule unitarity violation dinstanton amplitude jhep sen dinstantons string field theory two dimensional string theory jhep sen normalization dinstanton amplitude jhep dewolfe r roiban spradlin volovich j walcher matrix type string theory jhep hepth b balthazar v rodriguez x yin smatrix type b string theory part ii dinstanton effect jhep j chakravarty sen normalization instanton amplitude two dimensional type b string theory jhep sen infrared finite semiinclusive cross section two dimensional type b string theory jhep eniceicu r mahajan p maity c murdia sen zz annulus onepoint function noncritical string theory string field theory analysis jhep alexandrov r mahajan sen instantons sineliouville theory g w moore r plesser classical scattering dimensional string theory phys rev hepth g w moore gravitational phase transition sinegordon model hepth r dijkgraaf g w moore r plesser partition function string theory nucl phys b hepth e hsu kutasov gravitational sinegordon model nucl phys b hepth v kazakov k kostov kutasov matrix model twodimensional black hole nucl phys b hepth alexandrov v kazakov k kostov time dependent background string theory nucl phys b hepth alexandrov v kazakov thermodynamics string theory jhep hepth alexandrov background string theory matrix model hepth j l karczmarek strominger matrix cosmology jhep hepth r da j l davis f larsen p mukhopadhyay particle production matrix cosmology phys rev hepth r da j l karczmarek spacelike boundary c matrix model phys rev hepth r da l h santos open string description spacelike singularity two dimensional string theory phys rev hepth kutasov property noncritical string spring school string theory quantum gravity followed workshop hepth n seiberg h shenker note background independence phys rev hepth v rodriguez twodimensional string cosmology jhep v rodriguez torus onepoint diagram twodimensional string cosmology jhep collier l eberhardt b muhlmann v rodriguez virasoro minimal string sen tachyon dynamic open string theory int j mod phys hepth w g unruh note black hole evaporation phys rev g w moore r plesser ramgoolam exact matrix string theory nucl phys b hepth p p prudnikov brychkov marichev integral series ap prudnikov yu brychkov oi marichev translated russian nm queen gordon breach science publisher new york j polchinski string theory nato advanced study institute le houches summer school session fluctuating geometry statistical mechanic field theory hepth j polchinski classical limit dimensional string theory nucl phys b g horowitz j maldacena black hole final state jhep hepth j b hartle w hawking wave function universe phys rev elitzur giveon kutasov e rabinovici big bang big crunch beyond jhep hepth n lambert h liu j maldacena closed string decaying dbranes jhep hepth n birrell p c w davy quantum field curved space cambridge monograph mathematical physic cambridge university press cbo p c w davy fulling radiation moving mirror black hole proc roy soc lond r carlitz r willey reflection moving mirror phys rev almheiri j sully uneventful horizon two dimension jhep akal kusuki n shiba takayanagi z wei entanglement entropy holographic moving mirror page curve phys rev lett akal kawamoto sm ruan takayanagi z wei zoo holographic moving mirror jhep title limit anisotropy oneway maximum attainable speed electron transcription limit anisotropy oneway maximum attainable speed electron w bergan cornell university ithaca ny mj forster cornell university ithaca ny v khachatryan cornell university ithaca ny n rider cornell university ithaca ny dl rubin cornell university ithaca ny b vlahovic north carolina central university durham nc b wojtsekhowski bwojtsekhowskiiitacuk college william mary williamsburg va thomas jefferson national accelerator facility newport news va november abstract report first experimental result anisotropy oneway maximum attainable speed electron delta ce obtained via study sidereal time dependence difference electron positron beam momentum cesr storage ring cornell university percent confidence upper limit component delta cec perpendicular earth rotational axis found time pac k introduction theory special relativity tsr formulated postulate whose experimental test important universal acceptance foundation modern physic principle relativity confirmed perfect agreement tsr prediction experiment universal value speed light inertial reference system also tested experimentally since precision test improved many order experiment represent important approach search physic degree lorentz invariance violation liv according original theory einstein speed light vacuum isotropic maximum attainable speed particle equal speed light however important differentiate twoway speed average closed path c whose isotropy light addressed first time michelsonmorley experiment oneway speed c whose isotropy general postulate number later formulation tsr based postulate relativity isotropy twoway speed see review time high precision measurement c isotropy well developed approach test liv several framework including standardmodel extension sme maximum attainable speed elementary particle could differ speed light current limit deviation maximum attainable speed particle speed light related bound anisotropy maximum attainable speed amas discussed ref current upper bound photon amas delta cphotonc see ref already domain quantum gravity qg effect challenging experiment delta cphotonc bound sim time according ref number tsr prediction also tested increasing accuracy see ref example test relativistic doppler transformation performed high speed atom provided liv test level momentum anisotropy tsr momentum particle fourvector whose transformation inertial reference frame follows lorentz transformation space component momentum vecpmcdotvecvsqrtvc particle mass vecv particle velocity v absolute value vecv c speed light taking account difference maximum attainable speed particle cpart possible directional anisotropy amas speed light c avoid nonphysical result p expression written vecpmcdotvecvsqrtvcpart cpart maximum attainable speed particle direction particle velocity vecv immediate prediction tsr process preserve absolute value particle speed absolute value particle momentum unchanged testing prediction different orientation momentum one obtain bound liv method momentum anisotropy especially sensitive particle large lorentz factor gammasqrtvcpart expression momentum gamma enhancement delta ppapproxgammadelta cpartc tag delta p variation momentum similar kinematical enhancement sensitivity liv high gamma factor process obtained previously see eg ref current report present first experiment carried using momentum anisotropy method obtained limit electron amas independent high precision test tsr search sidereal time variation maximum attainable oneway speed particle provides interesting way study directional isotropy universe test directional isotropy conducted high precision nmr since review andperspectives current mrbased search method see ref simple model c anisotropy based concept local ether distinct global ether ruled famous experiment possible local ether move relative solar system tiny refractive index example local ether may related cosmic microwave background radiation magnetic deflection amas searchwe implemented momentum anisotropy method search electron amas particle momentum precisely measured via deflection transverse magnetic field magnetic field transverse direction motion also allows u change direction particle momentum repeat momentum measurement example particle moving reverse direction impact amas reach maximum word circ magnetic arc act heavy mirror reflects electron positron elastically search liv effect conventional form lorentz force need corrected textbook form suppresses possible liv contribution example rotational noninvariant option nature exact form correction unknown current analysis kinematics particle motion transverse magnetic field using minimum number parameter consideration vector particle speed vecv another vector magnetic field vecb axial vector first assumption proportionality acceleration magnitude vector absence nonlinear term assume parity conserving nature acceleration charged particle moving transverse magnetic field acceleration particle directed along vector product vecvtimesvecb direction acceleration absolute value particle speed remains constant important consideration used later interpretation experimental observable limit variation difference particle speed maximum attainable speed direction particle motion vce searched variation particle momentum allowed according qg dispersion relation assumed energy conservation experimental considerationsour experiment performed bunched beam high energy electron positron circulating storage ring precision experiment delta cec benefit large value beam lorentz factor gamma high precision measurement beam centroid location transverse direction especially high beam current storage ring stable geometry magnetic field accelerator magnet paramount importance method requirement significantly relaxed experiment us two counterpropagating beam particle antiparticle one set magnet difference counterrotating particle momentum relatively insensitive drift storage ring magnetic field geometry sensitivity delta cec doubled assuming anisotropy electron positron validity cpt amas equality mass opposite sign equal value electrical charge electron positron also important analysis confirmed experiment much higher precision essential experiment beam momentum p accelerator lattice dispersion function eta coordinate along reference orbit beam relate deviation horizontal beam position x nominal beam position accelerator location xsxnomsetastimesppnomp xnoms horizontal closed orbit momentum pnom ppnom deviation momentum nominal value variation measured position difference two beam thus corresponds measurement variation momentum difference measurement beam position area free accelerating element beam momentum variation different direction motion found uncertainty absolute position beam irrelevant attempting measure time dependence momentum frequency sidereal rotation particle energy varies coordinate due synchrotron radiation energy loss beam acceleration rf cavity energy stable calculable high precision primary experimental observable momentum difference time moment two counterrotating beam defined delta ppmstleftxtxtrightetas allows u search potential signal using following equation dipole form amas delta ppmstaperptimescosomegacdot phicospsis sinthetacesrsinomegacdot tphisinpsis tag aperpgammatimesdelta ceperpc fit parameter gamma beam lorentz factor delta ceperpc amas value omega sidereal frequency close earth rotational frequency phi phase defined direction anisotropy psi phase beam position monitor location position storage ring thetacesr geographic latitude cornell electron storage ring experimentour experiment used beam electron positron energy gev cornell electron storage ring cesr fig ring layout mirror symmetric northsouth diameter circumference lattice focusingdefocusing fodo type half cell consisting dipole quadrupole sextupole magnet design magnetic lattice minimizes beta function collision point order mitigate current dependence beambeam interaction closed orbit impact remaining beambeam interaction investigated collected orbit data found much smaller detected achieved accuracy beam position monitor bpm consistent theoretical expectation dispersion function value one two meter orbit rf accelerating cavity located symmetrically near south straight section beam electrostatic separation system automatic beam orbit feedback system turned ring filled one electron bunch one positron bunch time particle bunch corresponding collision point chosen location interaction point former cleo detector diametric counterpart north straight section beam life time average hour typical data taking cyclefill lasted hour beam current dropped level measurement beam position performed mean cesr bpm system includes bpm cesr fourelectrode bpm configuration shown fig allows determination horizontal vertical coordinate bpm signal amplified digitized sampling rate mhz four electrode programmable delay ensure bunch signal sampled peak delay step p standard daq allows accumulation data many thousand turn bpm beam electron positron sign bipolar pulse depends particle specie signal sampled peak leading pulse opposite sign electron positron two group measurement performed first group data electron beam data positron beam recorded close different moment time moment shifted second due time needed loading different version local readout code bpm electronics called combined information timeconsecutive position measurement two beam data shot measurement beam used set electronics allowed u reduce impact electronic instability beam position difference raw data included amplitude four electrode bpm combined electron plus positron beam current data one shot collected beam turn cesr total covered m time period data analyzed paper obtained several multihour period december october total group data shot taken using fill ring second group b beam data recorded bpm sequential bunch passage turn time difference readout le two microsecond different electronics amplifier digitizer two specie electron beam data turn similar positron beam data constitute pair synchronized measurement shot interval sequential shot second information group b collected january total group b data shot taken hour period using five fill ring experiment sensitivity electron amasthe experiment sensitivity signal interest defined coordinate resolution bpm lattice function storage ring statistic measurement duration data taking systematics due remaining beambeam interaction electronics instability combined sensitivity data effect analysis procedure detected parameter signal aperp phi investigated adding actual bpm data test wave shape potential signal adding test wave full analysis procedure performed wave parameter reconstructed sensitivity study performed signal amplitude range figure cesr ring geometry feature rf indicates location rf cavity cleo indicates location used collider detector chess stand cornell high energy synchrotron source figure cesr fourelectrode bpm see aperp ppm show reconstructed amplitude reduced factor typical effect multiparameter fit analysis phase phi defines preferable direction amas lowest amplitude test wave reconstructed accuracy radian drift bpm electronics magnet introduces systematical effect create artificial signal analysis data presented excluded bpm exceedingly large noise drift addition run group instability horizontal steering magnet kicker introduced large orbit distortion effect kicker corrected fitting procedure data analyzed various grouping allowed u evaluate systematics spread result obtain best estimate upper limit amas value analysis datafor analysis data group arranged five set six eight hour long data group b used one set analysis performed independently six set analysis procedure started evaluation noise raw amplitude fourelectrode bpm purpose checked correlation signal individual electrode bpm ai bpm beam current ibeam rms correlation alphaaiibeam analyzed found relative value rms sigmaalphaalpha averaged usable bpm sigmaalphaalpha exceeded four time larger value corresponds mum position change ppm momentum change corresponding bpm removed analysis applied cut eliminated average bpm available cesr accepted bpm beam horizontal position x positron x electron calculated corresponding four amplitude bpm electrode using updated iterative procedure start linearized expression value xpmxx provides beam position difference contribution difference beam energy varies along orbit time independent ii offset due electronic calibration bpm sufficiently stable selected period several hour iii small random difference magnetic system moment measurement coordinate electron positron beam essential group iv potential amas signal time dependence according sidereal period earth rotation smooth variation along beam orbit within one data shot group set time delay x x measurement second sometimes lead orbit position change large mum location common reason magnet changed value field kicker identified analysis beam position function parameter kicker obtained fit data closed orbit function fsjthetajcdotfracsqrtbetasbetasjsinpi qx cosphisphisjpi qx tag fsj closed orbit function kicker j thetaj beam deflection angle beam kicker j beta betasj ring lattice beta function location kicker location sj qx horizontal betatron frequency equal cesr phi phisj lattice betatron phase advance location location kicker sj change beam momentum due application kick observed amplitude region finite dispersion negligibly small determination kicker location preliminary amplitude given shot divided data set several minute time interval short relative earth rotation period stability contribution delta xpm except kicker much higher kicker impact minute data group set fifty shot nsh provide nbpmnsh coordinate value delta xpm use fit nbpm total number used bpm fit per eq used determination parameter kicker delta xpmref contribution combined total number fit parameter eight kicker data shot offset nbpm bpm maximum nshnbpm small compared number fit point figure show delta xpm v bpm location along orbit storage ring typical data shot residual delta xpm corresponding rms significant variation delta xpm shown upper panel fig due kicker rms delta xpm mum fit closed orbit function eq several kicker actual number kicker defined significance chi improvement allowed u find residual delta xpmdelta xpmsum fsj sum fsj sum closed orbit function observed kicker delta xpm value typical rms mum shown one data shot lower panel fig kicker identified number location shot fixed fit redone optimization amplitude kicker shot offset delta xpmref bpm fixed group minute time interval amas amplitude phase fixed within given severalhour measurement set group b analysis needed synchronized readout bpm completely suppressed kicker effect time group b required additional electronics channel added noise overall data group b similar accuracy second step analysis group b includes following data fitted twoparameter function signal one parameter per bpm delta xpmref delta xpmetastimes aperptimesleftcos omegacdot tphicospsisright leftsinthetacesrsinomegacdot tphisin psisrightdelta xpmref tag data set analysis amas signal calculated realtime phase phi relative midnight october geographic location cesr fit amas signal took account bpm significant drift determined rate bpm drift onebpm fit per eq result plotted fig presentation search result used aperpx aperpy component projection anisotropy vector veca plane cesr ring along geographical meridian orthogonal respectively mean value onebpm analysis aperpx ppm aperpy ppm rms ppm easy see tail distribution width dominated systematics systematic uncertainty much larger statistical uncertainty individual data point data point corresponding bpm extra large deviation ppm excluded next step analysis accuracy average value ppm close expected data point final method combining data based four group bpm group used every fourth bpm among selected analysis starting took group starting bpm group includes bpm distributed almost uniformly around ring six set measurement fitted signal using four group bpm total data point obtained result shown fig combined fit data point lead value aperpxpm ppm aperpypm ppm aperpxaperptimescosphi aperpyaperptimessinphi per eq corresponds value combined fit amplitude aperppm ppm phase phi radian summarythe search anisotropy oneway maximum attainable speed electron performed mean precision monitoring variation difference momentum electron positron beam versus location along orbit cesr storage ring gev beam energy sidereal time anisotropy delta cece combined result set data time sim confidence twosigma level follows eq aperpsqrtaperpxaperpy limit three time better previously reported accurate experiment accuracy experiment limited drift individual electronics channel lesser extent figure run group kicker analysis example position difference delta xpmdelta xpmref v bpm location typical data shot psipicdot sp p perimeter orbit upper left panel show raw data black point fit value open red square three kicker whose intensity location indicated vertical red dashed line obtained fit closed orbit function upper right plot show distribution delta xpm value rms lower panel show distribution residual delta xpm subtraction kicker contribution open black circle signal fit function delta xeta dashed blue curve see scale right signal contribution delta xpm open red circle corresponding projection open black circle shown right side rms mum figure onebpm fit result amas function parameter pink contour ppm time ppm left plot contained data point obtained distribution right side plot fitted gaussian function central area pm ppm readout rate associated daq resolution issue technique allow investigation delta ce region potentially sensitive qg effect performing experiment different beam energy provide additional handle discrimination systematics possible amas effect interesting lhc collider whose magnetic system two beam coupled magnetically geometrically provides possibility test amas proton would also like mention synchronized measurement beam deflection several storage ring high accuracy open additional opportunity search transient effect proposed number model physic beyond sm many recent experiment liv interpreted within framework sme theory would interesting perform smebased analysis measurement well however minimal sme theory sensitivity magnetic deflection dipole form amas obtained limit could also used test underlying assumption sme time within sme framework already prediction nonvanishing eccentricity particle trajectory magnetic deflection could investigated using beam trajectory storage ring sufficient stability magnet achieved pleasure thank cesr staff smooth operation storage ring would like extend special thanks v zelevinsky recommendation sagan b schmookler contribution data analysis initial stage experiment g cates productive discussion support experiment work supported national science foundation grant phys dge reference einstein annalen der physik aa michelson ew morley j sci r anderson et al physic report colladay va kostelecky phys rev phys rev va kostelecky n russell rev mod phys nagel et al nature communication mattingly living review relativity liberati class quantum grav vg gurzadyan et al mod phys lett jp bocquet et al phys rev lett cm living rev relativity jay tasson rep prog phys b botermann et al phys rev lett vg gurzadyan margarian phys scr coleman sl glashow phys rev b altschul phys rev b wojtsekhowski euro physic letter vw hughes et al phys rev lett rwp drever philosophical magazine m safronova et al rev mod phys budker vv flambaum private communication tanabashi et al particle data group phys rev da edward mj syphers introduction physic high energy accelerator wiley new york cesr storage ring httpswwwclassecornelledupubliclabinfocesrhtmlhttpswwwclassecornelledupubliclabinfocesrhtml palmer et al proceeding international particle accelerator conference p n rider et al proceeding ecloud th icfa advanced beam dynamic workshop electron cloud physic ithaca ny k smolenski ed ithaca ny pp cornell university mg billins et al jinst dl rubin et al phys rev st accel beam j wenninger private communication budker derevianko physic today qg bailey va kostelecky phys rev hohensee va kostelecky mewes private communication b altschul phys rev figure result six measurement presented data point point black red show result run group b respectively error bar individual point represent statistical accuracy rms calculated distribution data point mean value aperpxpm ppm aperpypm ppm solid dashed blue contour show border one two sigma exclusion area respectively per one data point obtained title first observation excited b state transcription first observation excited omegab state lhcb collaboration author listed end letter abstract report four narrow peak xibk mass spectrum obtained using pp collision centerofmass energy tev corresponding total integrated luminosity fb recorded lhcb experiment referring state mass mass value momegab pm pm pm mathrmmev momegab pm pm pm mathrmmev momegab pm pm pm mathrmmev momegab pm pm pm mathrmmev uncertainty statistical systematic last due knowledge xib mass natural width three lower mass state consistent zero confidencelevel upper limit determined gammaomegabmathrmmev gammaomegab mathrmmev gammaomegabmathrmmev natural width omegab peak pm mathrmmev sigma zero corresponds upper limit mathrmmev peak local significance ranging sigma sigma accounting lookelsewhere effect significance omegab omegab peak reduced sigma sigma respectively two higher mass peak exceed sigma observed peak consistent expectation excited omegab resonance ep lhcbpaper feb missingpageempty study hadron containing heavy b c quark undergone renaissance last couple decade time plethora new state observed including candidate fourquark tetraquark state recently fivequark pentaquark state see ref recent review addition number observation peaking structure invariantmass spectrum final state containing xick xibpi lambdabpi lambdabpipi provided valuable experimental information improve understanding quantum chromodynamics qcd theory strong interaction fueled observation renewed interest gaining deeper theoretical understanding hadronic structure constituent quark model successful describing type hadron form nature fit multiplets based quantum number state conventional baryon understood state contain three valence quark deep understanding best describe multiquark state term fundamental constituent still open question example qcd two quark exhibit attraction jp quantum state giving rise notion conventional baryon described bound state quark qqprime diquark idea naturally extensible describe tetraquark pentaquark candidate recently lhcb experiment observed five narrow state assumed excited varomegac baryon decay xick state analyzed perspective constituent quark model lattice qcd quarkdiquark model well molecular model pentaquark state several model seek describe peak also make prediction xibk resonance since quark content varomegac varomegab baryon cs bs respectively great interest search analogous state xibk mass spectrum letter report search narrow resonance xibk mass spectrum close kinematic threshold search us data collected pp collision lhcb detector centerofmass energy tev corresponding integrated luminosity fb respectively chargeconjugate process implicitly included natural unit hbarc used throughout lhcb detector singlearm forward spectrometer covering pseudorapidity range eta designed study particle containing b c quark event selected online trigger consists hardware stage based information calorimeter muon system followed software stage applies full event reconstruction simulated data sample produced using software package described ref used optimize selection requirement quantify invariantmass resolution lhcb detector sample xib candidate formed pairing xic pi candidate xic decay reconstructed pkpi final state finalstate hadron must particleidentification pid information consistent assigned particle hypothesis finalstate particle also required inconsistent originating primary pp collision vertex pv requiring large chirm ip respect pvs event quantity chirm ip difference chi vertex fit given pv particle p k pi included excluded fit xic candidate must fitted vertex significantly displaced pvs event invariant mass within mev known xic mass xic background comprises misidentified dto kpipi dto kkpi dsto kkpi dtodto kpipi decay well misidentified phi meson phito kk combined additional particle elsewhere event background contribution removed employing tighter pid requirement candidate consistent decay hypothesis resulting loss signal efficiency pkpi invariantmass distribution xic candidate satisfying selection requirement shown fig left xib candidate formed xicpi combination significantly displaced decay vertex pvs event trajectory consistent originating one pv xib candidate smallest chirm ip assigned associated pv used subsequently compute quantity xib decay time candidate satisfying requirement mxicpimboxrm gekernptv retained designates invariant mass system suppress background xibtoxicpi sample boosted decision tree bdt discriminant used bdt exploit input variable decay time xic xib candidate chi value associated decayvertex fit angle xib momentum vector line join xib decay vertex associated pv final state particle momentum transverse momentum chirm ip pid response variable pid response finalstate hadron signal decay obtained large dtodto kpipi mathchar relaxto ppi calibration sample data simulated signal decay background xic mass sidebands mpkpimxicmboxrm mekernptv data used train bdt refers mass indicated particle chosen requirement bdt response provides relative signal efficiency reduces combinatorial background factor overall offline selection requirement efficient simulated decay reducing background factor figure right show xicpi mass spectrum candidate passing figure invariantmass spectrum left xicto pkpi right xibtoxicpi candidate data passing selection requirement described text arrow indicate requirement invariant mass applied subsequent stage analysis selection criterion spectrum fit sum two crystal ball function common mean oppositeside powerlaw tail model signal exponential function describe background distribution fitted xib signal yield pm search peaking structure xibk mass spectrum requirement mxicpimxibmev imposed reduces number xib signal decay xib candidate combined k candidate consistent originating pv event xib k trajectory fitted common vertex vertex kinematically constrained coincide pv associated xib candidate additional pv constraint improves resolution mass difference delta mequiv mxibkmxib factor two random combination xib baryon k candidate largest source background xibk mass spectrum improve expected signaltobackground ratio figure merit epsilonsqrtb used optimize requirement pid information k candidate epsilon efficiency determined simulation b number wrongsign xibk combination region delta mmev passing pid requirement scaled mev mass window mev width chosen based search narrow peak since low signal yield expected would make wide peak difficult separate combinatorial background optimal requirement k pid provides efficiency suppresses background factor decay resonance xibk produce peak delta spectrum experimental delta resolution obtained simulated sample generated several mass mrm re resolution function described sum two gaussian function common mean addition width narrower gaussian component sigmarm core fixed wider component contribution required constitute total shape smooth monotonically increasing function denoted sigmamrm re used parameterize sigmarm core function mrm re delta interval interest sigmamrm re range mev delta distribution rightsign r wrongsign w candidate shown fig along fit spectrum described four peak seen r spectrum xibk candidate red curve whereas significant peak seen corresponding w xibk distribution obtain parameter peak simultaneous unbinned extended maximumlikelihood fit performed r w spectrum signal peak described swave relativistic breitwigner function blattweisskopf barrier factor convoluted resolution function sigmamrm re described common background shape used describe r w spectrum described smooth threeparameter monotonic function account xibk threshold peak value delta natural width signal yield local global significance summarized table local significance obtained mathcalsrm datasqrtlogmathcallrm maxmathcall mathcallrm max maximum value fit likelihood mathcall value obtained given peak yield fixed zero peak natural width consistent zero highestmass peak largest width differs zero standard deviation determined likelihood scan width parameter account lookelsewhere effect considers peak search extends mev wide mass region large number pseudoexperimentspe generated pseudoexperiments use nominal parameter fit data signal yield peak turn set zero full mass region scanned mathrmmekernptv step identify significant positive fluctuation outside region three retained peak significance mathcalsmathrmpe computed corresponding distribution mathcalsmathrmpe value mathcalsmathrmdata pvalue expressed gaussian standard deviation obtained peak shown table source systematic uncertainty affect measured mass summarized table momentum scale uncertainty assessed shifting momentum scale charged track pm simulated decay evaluating change delta imperfect modeling energy loss detector material result systematic uncertainty mathrmmekernptv uncertainty due choice signal model assigned fitting data alternative signal model composed two gaussian function common mean largest change mathrmmekernptv assigned systematic uncertainty peak position background shape uncertainty assessed figure distribution mass difference top rightsign xibk candidate bottom wrongsign xibk candidate described text removing influence w data background shape fitting r data difference peak position respect nominal fit assigned systematic uncertainty relativistic breitwigner signal shape nominal fit assumes decay proceeds swave interaction radius blattweisskopf barrier factor rmboxgekernptv changing angular momentum decay l dwave separately varying r mboxgekernptv lead negligible change peak position absolute mass determination worldaverage xib mass pm mboxmekernptv used uncertainty mboxmekernptv mass dominates systematic uncertainty quoted separately final result primary source systematic uncertainty natural width observed peak imperfect knowledge delta resolution obtained simulation based previous study dto dpi decay delta resolution simulation agrees data within impact pm variation resolution evaluated using pseudoexperiments experiment generated using nominal signal resolution function fitted smaller larger delta resolution deviation pm mboxmekernptv relative true value width found range input width corresponding observed data upper limit natural width observed peak evaluated convoluting likelihood mboxmekernptv uncertainty finding value width contain
Original Title: On Time-Dependent Backgrounds In 1+1 Dimensional String Theory
Original Transcription: On Time - Dependent Backgrounds

In \(1+1\) Dimensional String Theory

Bruno Balthazar\({}^{1,2}\), Jinwei Chu\({}^{1}\), David Kutasov\({}^{1}\)

\({}^{1}\)_Kadanoff Center for Theoretical Physics and Enrico Fermi Institute_

_University of Chicago, Chicago IL 60637_

\({}^{2}\)_Center for Cosmology and Particle Physics_

_New York University, New York NY 10003_

brunobalthazar@nyu.edu, jinweichu@uchicago.edu, dkutasov@uchicago.edu

In perturbative string theory, one is generally interested in asymptotic observables, such as the S-matrix in flat spacetime, and boundary correlation functions in anti-de Sitter spacetime. However, there are backgrounds in which such observables do not exist. We study examples of such backgrounds in \(1+1\) dimensional string theory. In these examples, the Liouville wall accelerates and can become spacelike in the past and/or future. When that happens, the corresponding null infinity, at which the standard scattering states are defined, is shielded by the Liouville wall. We compute scattering and particle production amplitudes in these backgrounds in the region in parameter space where the wall remains timelike, and discuss the continuation of this picture to the spacelike regime. We also discuss the physics from the point of view of the dynamics of free fermions in backgrounds with a time-dependent Fermi surface.

###### Contents

* 1 Introduction
	* 1.1 The standard background
	* 1.2 Time-dependent backgrounds
	* 1.3 Strategy of the calculation
* 2 Wick rotation in the standard background
* 3 Amplitudes in time-dependent backgrounds
	* 3.1 \(n\to 1\) amplitude
	* 3.2 Particle production
	* 3.3 \(p>1\)
* 4 Generalizations
* 5 Free fermion perspective
* 6 Summary and discussion
	* 6.1 Summary
	* 6.2 Observables for \(p>1\)
	* 6.3 Properties of scattering amplitudes
	* 6.4 The limit \(p\to 2\)
	* 6.5 Closed string radiation
	* 6.6 Moving mirror
* A Matrix model dual of \(1+1\) dimensional string theory
* B Closed string amplitudes
* B.1 One outgoing particle
* B.2 Two outgoing particles
* B.3 Three and four outgoing particles
* B.4 Any number of outgoing particles

Introduction

Since its inception in the late 1980's, string theory in a \(1+1\) dimensional spacetime has played an important role in the development of the subject (see _e.g._[1, 2, 3, 4, 5, 6, 7] for reviews). In particular, its dual description in terms of matrix quantum mechanics in a double scaling limit was an early example of holography, a precursor to the AdS/CFT correspondence [8, 9, 10, 11] and Little String Theory [12, 13, 14]. The fact that the theory is solvable allows one to use it to test general ideas in string theory and holography in a setting where explicit calculations can be performed. An example is the study of non-perturbative effects (in the string coupling); see _e.g._[15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27] for some recent discussions.

The theory was originally formulated in a static background, where a natural set of observables is given by S-matrix elements for scattering of (massless) "tachyons". It is known that the theory is solvable in time-dependent backgrounds as well (see _e.g._[28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39]), however in some of these backgrounds the nature of the observables is less clear. The main goal of this paper is to discuss the physics of a class of such backgrounds, and try to learn from them how to treat backgrounds with similar features in more realistic settings in higher dimensions, such as backgrounds with cosmological singularities.

### The standard background

To set the stage, we start with a brief review of the situation in the standard background [1, 2, 3, 4, 5, 6, 7]. In Euclidean two dimensional spacetime with (Euclidean) worldsheet metric \(\hat{g}\), it is described by the action

\[S_{E}=\frac{1}{4\pi}\int d^{2}z\sqrt{\hat{g}}\left[\left(\hat{\nabla}X\right)^ {2}+\left(\hat{\nabla}\phi\right)^{2}+2\phi R(\hat{g})-4\pi\mu\phi e^{2\phi} \right]. \tag{1.1}\]

The linear dependence of the dilaton on \(\phi\) leads to a string coupling that behaves like \(g_{s}(\phi)\sim\exp(2\phi)\). One can think of \(\phi\) as the conformal factor of a dynamical metric, and of (1.1) as a conformal gauge description of worldsheet gravity coupled to a massless scalar field, \(X\).

The worldsheet theory (1.1) becomes free in the region \(\phi\to-\infty\), where the string coupling \(g_{s}(\phi)\) goes to zero. This region is the boundary of the two dimensional spacetime labeled by \((X,\phi)\). Conversely, as \(\phi\) increases, the string coupling increases, and one might think that perturbative string theory breaks down due to strong coupling effects associated with the large positive \(\phi\) region. However, the cosmological constant term in the action (1.1) gives rise to a potential for \(\phi\) that prevents it from exploring this region.1 This potential is often referred to as the _Liouville wall_. It leads to the fact that in the background (1.1) the \(g_{s}\) expansion is essentially a \(1/\mu\) expansion.

Physical observables in the background (1.1) are correlation functions of vertex operators characterized by their behavior near the boundary. A large set of such operators corresponds to modes of the massless "tachyon" field, described by the vertex operators2

Footnote 2: Here and below we take the worldsheet metric \(\hat{g}\) to be flat, _i.e._\(z\) is a coordinate on the complex plane with flat metric.

\[T_{p}\simeq\frac{\Gamma(|p|)}{\Gamma(1-|p|)}\int d^{2}ze^{(2-|p|)\phi}e^{ipX}. \tag{1.2}\]

In (1.2) we chose to normalize the operators in a conventional way; see _e.g._[3, 40]. The \(\simeq\) means that (1.2) describes the behavior of the operators as \(\phi\to-\infty\); the finite \(\phi\) form of the operators (1.2) is more complicated. The physical observables are correlation functions of the operators \(T_{p}\),

\[\langle T_{p_{1}}T_{p_{2}}\cdots T_{p_{l}}\rangle. \tag{1.3}\]

These correlation functions are uniquely determined by the asymptotic form (1.2).

An important feature of the operators (1.2) is that they are non-normalizable. Indeed, their wavefunctions behave in the limit \(\phi\to-\infty\) like \(\Psi_{p}(X,\phi)\sim e^{(ipX-|p|\phi)}\). Thus, adding them to the worldsheet Lagrangian corresponds to a deformation of the Lagrangian of the spacetime theory. We note, for future reference, that the wavefunctions \(\Psi_{p}\) have the property that for positive (negative) \(p\) they depend on the (anti-)holomorphic variable \(\phi\mp iX\).

The worldsheet field \(X\) is often taken to be compact, \(X\sim X+2\pi R\), _e.g._ to study the theory at finite temperature. In that case the momentum \(p\) is quantized, \(pR\in Z\), and there are also winding modes. The latter will not play a role in our discussion below. They are related to momentum modes by T-duality, which can be used to relate their correlation functions to those of momentum modes, (1.3).

The cosmological term in the worldsheet action (1.1) can be written as \(\mu T_{0}\). The prefactor in (1.2) has a pole at \(p=0\); this pole is responsible for the factor of \(\phi\) in front of the exponential in (1.1). Differentiating the path integral w.r.t. \(\mu\) gives an insertion of \(-T_{0}\). We will use this fact in the calculation of the correlation functions (1.3).

A property of these correlation functions that will be useful below is their dependence on \(\mu\), known as KPZ scaling. By analyzing the behavior of (1.3) under a shift of \(\phi\), one can show that (to leading order in \(g_{s}\))

\[\langle T_{p_{1}}T_{p_{2}}\cdots T_{p_{l}}\rangle\sim\mu^{a}, \tag{1.4}\]with \(a\) determined by

\[\sum_{j=1}^{l}\left(2-|p_{j}|\right)+2a=4. \tag{1.5}\]

The coefficient of \(\mu^{a}\) in (1.4) contains the non-trivial dependence of (1.3) on the momenta \(p_{j}\). In order to determine it, one needs to solve the worldsheet theory (1.1).

The Lorentzian analog of (1.1) is obtained by taking \(X\to-it\), which gives

\[S_{L}=\frac{1}{4\pi}\int d^{2}z\left(-\left(\nabla t\right)^{2}+\left(\nabla \phi\right)^{2}-4\pi\mu\phi e^{2\phi}\right). \tag{1.6}\]

The target spacetime is now \(1+1\) dimensional, with a spacelike linear dilaton and a Liouville wall in the spatial (\(\phi\)) direction, which as before shields the strong coupling region. This is depicted in figure 1, where the red line is the Liouville wall, defined as the surface along which the Liouville potential \(V(\phi)\) is of order one.3 The shaded region is shielded by the Liouville potential.

Footnote 3: This wall is soft, in the sense that particles with higher energy penetrate it to larger \(\phi\); see _e.g._[41] for a discussion.

Figure 1: The correlation functions (1.8) describe scattering processes, where \(n\) right-moving tachyons \({\cal T}^{+}\) come in from the boundary \(\phi\to-\infty\) and scatter off the Liouville wall (depicted in red) into \(n^{\prime}\) left-moving tachyons \({\cal T}^{-}\) that go back towards the boundary.

[MISSING_PAGE_FAIL:6]

dual matrix model allows one to calculate these amplitudes much more efficiently. It also allows one to calculate quantum corrections to the leading terms, which from the worldsheet perspective come from higher genus contributions to the correlation functions (1.8). We will use some of the matrix model results below.

### Time-dependent backgrounds

As mentioned above, our main interest will be in time-dependent backgrounds, that are obtained by deforming (1.6). Such backgrounds were discussed in the past, _e.g._ in [28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39], and we will use some of their results. A special case of these backgrounds was recently revisited in [42, 43, 44].

The particular deformations we will consider correspond to adding to the worldsheet action the terms5

Footnote 5: Here and below, we take \(p>0\), without loss of generality.

\[\delta S_{L}=\lambda_{+}T_{p}+\lambda_{-}T_{-p}=\frac{\Gamma(p)}{\Gamma(1-p)} \int d^{2}ze^{(2-p)\phi}\left(\lambda_{+}e^{pt}+\lambda_{-}e^{-pt}\right). \tag{1.11}\]

The couplings \(\lambda_{\pm}\) are taken to be real, so that the worldsheet action remains real after deformation. If \(\lambda_{\pm}\) are both non-zero, one can take them to satisfy \(\lambda_{+}=\pm\lambda_{-}\) by shifting the origin of time. We will mostly focus on the case where one of the two couplings vanishes, in which case the remaining coupling controls the time at which the perturbation (1.11) becomes important. Obviously, for \(\lambda_{-}=0\) the perturbation (1.11) becomes important in the future, while for \(\lambda_{+}=0\) it becomes important in the past.

We see from (1.11) that there is a qualitative difference between the cases \(0<p<2\) and \(p>2\). In the former case, the perturbation goes to zero near the boundary of spacetime \(\phi\to-\infty\) (for fixed \(t\)). In the latter, it grows as we approach the boundary. The origin of this behavior is well understood. For \(p<2\), the operators \(\exp(\pm pt)\) are relevant, and thus, after coupling to \(\phi\), their effective coupling in (1.11) goes to zero in the UV region \(\phi\to-\infty\). Conversely, for \(p>2\) these operators are irrelevant, and modify the UV behavior. We will restrict to the case \(p<2\) below.

The addition of the perturbation (1.11) to the worldsheet Lagrangian (1.6) modifies the worldsheet potential. From now on, we will focus on the case \(\lambda_{-}=0\), unless explicitly stated otherwise. The worldsheet potential takes in this case the form (at large negative \(\phi\))

\[V_{\rm ws}(t,\phi)=-\mu\phi e^{2\phi}+\hat{\lambda}_{+}e^{(2-p)\phi+pt}\, \tag{1.12}\]

where \(\hat{\lambda}_{+}=\lambda_{+}\frac{\Gamma(p)}{\Gamma(1-p)}\). The situation is described in figure 2, which generalizes figure 1 to \(\hat{\lambda}_{+}>0\). The solid red line in figure 2 is the surface \(V(t,\phi)\sim 1\), which can be thought of as a _time-dependent Liouville wall_.

For early time (\(t\to-\infty\)), the perturbation proportional to \(\hat{\lambda}_{+}\) in (1.12) goes to zero, and we recover the static Liouville wall described in the previous subsection. For late time (\(t\to\infty\)), the velocity of the modified Liouville wall approaches a finite constant, as indicated in figure 2. The transition between the two regimes occurs around the point \((\phi,t)=(\phi^{*},t^{*})\),

\[(\phi^{*},t^{*})=\Big{(}-\frac{1}{2}\ln\mu,-\frac{1}{p}\ln\hat{\lambda}_{+}+ \frac{2-p}{2p}\ln\mu\Big{)} \tag{1.13}\]

depicted in figure 2. This is the regime in which the Liouville wall accelerates from its initial to its final velocity.

As is evident from the figure, there is a qualitative difference between the cases \(0<p<1\) and \(1<p<2\). In the former case, exhibited in figure 2a, the trajectory of the Liouville wall is timelike for all \(t\). On the other hand, for \(1<p<2\), figure 2b, the Liouville wall is spacelike at large \(t\), _i.e._ it moves faster than light at late times. Note that this is not inconsistent with special relativity, since the Liouville wall is not a dynamical object. It is rather a non-normalizable background, and thus cannot be used to propagate information faster than light. The dynamical field - the tachyon - is massless, and can be used to transmit information at the speed of light.

There is an important subtlety in the above discussion that will play a role in our analysis. In the holographic map between \(1+1\) dimensional string theory and matrix quantum mechanics, the tachyon field on the worldsheet, whose momentum modes are given by the

Figure 2: In the presence of the perturbation (1.12), the Liouville wall becomes time-dependent. As \(t\to-\infty\), it approaches the static wall of the unperturbed system, while as \(t\to+\infty\), its velocity approaches \(-\frac{p}{2-p}\). For \(p<1\), the Liouville wall remains timelike for all \(t\), (a), while for \(p>1\) it eventually becomes spacelike, (b).

exponentials in equations (1.2), (1.7), and its matrix model analog, are related by a momentum dependent factor - the ratio of Gamma functions in these formulae. This ratio can be thought of as due to the non-zero modes of the worldsheet fields \((\phi,t)\). Therefore, the deformation (1.11), that gives rise to the worldsheet interaction \(\int d^{2}zV_{\rm ws}(t(z,\bar{z}),\phi(z,\bar{z}))\), (1.12), yields the potential

\[V_{\rm st}(t,\phi)=\mu T_{0}+\lambda_{+}T_{p}=\mu e^{2\phi}+\lambda_{+}e^{(2-p) \phi+pt} \tag{1.14}\]

for the zero modes of the worldsheet fields \((\phi(z,\bar{z}),t(z,\bar{z}))\). The time-dependent Liouville wall is described by the equation \(V_{\rm st}(t,\phi)=1\).

The qualitative discussion above of the worldsheet potential \(V_{\rm ws}\) mostly goes through when it is replaced by \(V_{\rm st}\), but there are a couple of important changes. First, the time-dependent term in (1.14) is positive for \(\lambda_{+}>0\), whereas in (1.12) it is \(\hat{\lambda}_{+}\) that must be positive. For \(0<p<1\) the two notions coincide, but for \(1<p<2\) they differ. We will take the point of view that the spacetime potential \(V_{\rm st}\) is the important one for the dynamics of the tachyon field, and thus take \(\lambda_{+}\) to be positive. We will see later that this gives a coherent picture of the physics. The second change is that the point \((\phi^{*},t^{*})\) in figure 2 is still given by (1.13), but with \(\hat{\lambda}_{+}\) replaced by \(\lambda_{+}\),

\[(\phi^{*},t^{*})=\Big{(}-\frac{1}{2}\ln\mu,-\frac{1}{p}\ln\lambda_{+}+\frac{2- p}{2p}\ln\mu\Big{)}. \tag{1.15}\]

This too will play a role in our analysis.

The form of the time-dependent Liouville wall has an important impact on the observables in this background. Past lightlike infinity is part of the boundary for all \(p<2\), and therefore we can define the observables \({\cal T}^{+}_{\omega}\) in figure 2 for non-zero \(\lambda_{+}\), \(p\). However, future lightlike infinity is only part of the boundary for \(p<1\). Hence, the outgoing particles \({\cal T}^{-}_{\omega}\) can only be defined as asymptotic observables in that regime. Thus, for \(p<1\), we can compute scattering amplitudes of the sort (1.8) with any \(n,n^{\prime}\geq 0\), as depicted in figure 2. However, for \(1<p<2\) we cannot define amplitudes with \(n^{\prime}>0\), since the region where the operators \({\cal T}^{-}_{\omega}\) are to be defined is shielded by the potential (1.14).

This issue is especially significant when both \(\lambda_{+}\) and \(\lambda_{-}\) are positive and \(1<p<2\). In that case it seems like there are no good observables, since both \({\cal T}^{+}_{\omega}\) and \({\cal T}^{-}_{\omega}\) appear not to exist, for the same reason as above. We will mainly focus on the case \(\lambda_{-}=0\) and \(p<1\) below, but will comment on \(p>1\) and \(\lambda_{-}>0\) at various points in our analysis.

The fact that the background (1.11) with \(\lambda_{-}=0\) is time-dependent implies that energy is not conserved. For example, we can consider amplitudes of the form

\[\big{\langle}\prod_{j=1}^{n}{\cal T}^{+}_{\omega_{j}}\big{\rangle}\, \tag{1.16}\]where \(n\) particles are incident on the wall and are absorbed by the time-dependent background. For \(p<1\) we can also consider the amplitudes

\[\big{\langle}\prod_{l=1}^{n^{\prime}}{\cal T}^{-}_{\omega^{\prime}_{l}}\big{\rangle}\, \tag{1.17}\]

corresponding to the creation of \(n^{\prime}\) outgoing particles in the time-dependent Liouville potential (1.12). And, of course, we can consider general amplitudes of the form (1.8) with any non-negative \((n,n^{\prime})\), and any energies \((\omega_{j},\omega^{\prime}_{l})\).

In the case where the Liouville wall is static, KPZ scaling (1.9), (1.10) provides insight into the dynamics - it suggests that the scattering processes of figure 1 generically happen in the vicinity of the Liouville wall. It is thus interesting to generalize the scaling analysis to the case of figure 2. For example, for the amplitude (1.16) one has

\[\big{\langle}\prod_{j=1}^{n}{\cal T}^{+}_{\omega_{j}}\big{\rangle}\sim\mu^{a} \lambda^{b}_{+}. \tag{1.18}\]

The powers \(a,b\) can be determined by analyzing the behavior of the amplitude (1.18) under shifts of \(\phi\) and \(t\). This gives

\[\sum_{j=1}^{n}\left(2+i\omega_{j}\right)+2a+\left(2-p\right)b=4\, \tag{1.19}\]

and

\[-i\sum_{j=1}^{n}\omega_{j}+bp=0\, \tag{1.20}\]

respectively. The solution of these equations is

\[a=-\frac{i}{p}\sum_{j=1}^{n}\omega_{j}-n+2\,\quad b=\frac{i}{p}\sum_{j=1}^{n} \omega_{j}. \tag{1.21}\]

Plugging (1.21) into (1.18), we see that the dependence of the correlator on each of the energies \(\omega=\omega_{j}\) is via the phase factor

\[\left(\frac{\lambda_{+}}{\mu}\right)^{\frac{i\omega}{p}}=\exp\left(\frac{i \omega}{p}\ln\frac{\lambda_{+}}{\mu}\right) \tag{1.22}\]

These factors have a similar interpretation to the one discussed for the static background after eq. (1.10). Evaluating the vertex operator \({\cal T}^{+}_{\omega}\) (1.7) at the location \((\phi^{*},t^{*})\) near which the Liouville wall accelerates (see figure 2), given in (1.15), we find that at that location the vertex operator is given by \(1/\mu\) multiplying the phase factor (1.22). The former is the factor of \(g_{s}\) that relates a vertex operator to the wavefunction, while the latter implies that the amplitude (1.18) is dominated by the region near \((\phi^{*},t^{*})\).

In other words, as one would have expected, the time-dependent Liouville wall of figure 2 can best absorb incident tachyons in the region where its velocity changes from zero to a finite value. The precise location and width of this region depends on the parameters, \(\lambda_{+}\), \(\mu\), and the energies of the particles \(\omega_{j}\). And, as mentioned above, to actually compute this amplitude one needs to evaluate the coefficient of \(\mu^{a}\lambda_{+}^{b}\) in (1.18). We will address this problem in the next sections.

The above discussion can be repeated for the amplitude (1.17), which corresponds to a process where no particles are incident on the time-dependent Liouville wall, and \(n^{\prime}\) particles with energies \(\{\omega_{l}^{\prime}\}\) are emitted by the wall. As before, we have

\[\big{\langle}\prod_{l=1}^{n^{\prime}}{\cal T}_{\omega_{l}^{\prime}}^{-}\big{\rangle} \sim\mu^{a}\lambda_{+}^{b}\, \tag{1.23}\]

with \((a,b)\) determined by the conditions

\[\sum_{l=1}^{n^{\prime}}\left(2+i\omega_{l}^{\prime}\right)+2a+\left(2-p \right)b=4\, \tag{1.24}\]

and

\[i\sum_{l=1}^{n^{\prime}}\omega_{l}^{\prime}+bp=0. \tag{1.25}\]

The solution is

\[a=i\frac{1-p}{p}\sum_{l=1}^{n^{\prime}}\omega_{l}^{\prime}-n+2\,\quad b=- \frac{i}{p}\sum_{l=1}^{n^{\prime}}\omega_{l}^{\prime}. \tag{1.26}\]

The analog of the phase factor (1.22) is in this case

\[\left(\lambda_{+}\mu^{p-1}\right)^{-\frac{i\omega}{p}}=\exp\left[-\frac{i \omega}{p}\ln(\lambda_{+}\mu^{p-1})\right]. \tag{1.27}\]

The phase factor (1.27) has the same interpretation as before - it is obtained by evaluating the vertex operator \({\cal T}_{\omega}^{-}\) (1.7) at the location \((\phi^{*},t^{*})\). As expected, we conclude that the emission of tachyons from the time-dependent Liouville wall of figure 2 is centered in the region where the wall accelerates.

We finish this subsection with some comments:* Looking back at figure 2, one can ask whether there are processes in which incoming tachyons are reflected from the Liouville wall far from the region where the wall accelerates, _e.g._ at \(t\ll t^{*}\). Such processes are of course possible, but as is clear from the figure, they are insensitive to \(\lambda_{+}\), and in particular conserve energy. What we found above is that amplitudes that _violate_ energy conservation are in general due to physics in the vicinity of \((\phi^{*},t^{*})\).
* In the discussion above we took either \(n\) or \(n^{\prime}\) to vanish, but it is easy to generalize to any non-negative \(n\) and \(n^{\prime}\). As expected, one finds that energy violating processes of the sort depicted in figure 2 are dominated by the region where the Liouville wall accelerates.
* Since the backgrounds we consider are not time translation invariant, the amplitudes we compute below receive, in general, contributions from disconnected diagrams. We will focus on connected diagrams, but it is easy to include disconnected ones.
* As mentioned above, to compute amplitudes like (1.16), (1.17), we need to calculate the coefficients of \(\mu^{a}\lambda_{+}^{b}\) in (1.18), (1.23). In general, this requires the use of the matrix model. In the next subsection we explain our strategy for doing this calculation.

### Strategy of the calculation

We will take an approach to this problem that proved fruitful in studying time-dependent solutions in open string theory (see _e.g._[45] for a review). We start with the Euclidean problem (1.1), and add to the worldsheet action the term

\[\delta S_{E}=\lambda_{+}T_{p}+\lambda_{-}T_{-p}=\frac{\Gamma(p)}{\Gamma(1-p)} \int d^{2}ze^{(2-p)\phi}\left(\lambda_{+}e^{ipX}+\lambda_{-}e^{-ipX}\right). \tag{1.28}\]

As mentioned above, we will mostly consider the case \(\lambda_{-}=0\). At first sight this looks problematic, since the worldsheet action is not real unless \(\lambda_{-}=\lambda_{+}^{*}\), however this is standard in field theory (and string theory). We can study the theory with complex action (1.28), with the understanding that we are really interested in the Lorentzian theory obtained by taking \(X\rightarrow-it\). In that theory, \(\lambda_{+}\) and \(\lambda_{-}\) are independent (real) couplings.

We will take the field \(X\) to live on a circle of radius \(R\), anticipating that the Lorentzian background of interest has thermal features. In order for the perturbation (1.28) to make sense, the momentum \(p\) must be an integer multiple of \(1/R\). We will see that the discussion simplifies significantly if we take

\[p=\frac{1}{R}\, \tag{1.29}\]_i.e._ the perturbation (1.28) carries one unit of quantized momentum. We do not have a good understanding why this is the case, but will comment on what happens if we make other choices.

We will use the Euclidean action (1.1), (1.28), and the dual matrix model, to calculate some correlation functions of the form (1.2),

\[\big{\langle}\,\prod_{j=1}^{n}T_{q_{j}}\prod_{l=1}^{n^{\prime}}T_{-q_{l}^{ \prime}}\big{\rangle}_{\lambda_{+}} \tag{1.30}\]

(with \(q_{j},q_{l}^{\prime}\geq 0\)). For \(\lambda_{+}=0\), these correlation functions must satisfy the selection rule \(\sum_{j}q_{j}=\sum_{l}q_{l}^{\prime}\), due to \(X\) translation invariance. However, for \(\lambda_{+}>0\) this sum rule does not need to be satisfied, since the deformation (1.28) breaks this symmetry.

In particular, we will study the amplitudes (1.30) with \(n=0\), which vanish for \(\lambda_{+}=0\), but don't for finite \(\lambda_{+}\). We will also study the amplitudes with \(n^{\prime}=1\), for which the result can be read off from calculations in the existing literature.

We will then Wick rotate the Euclidean results (1.30) to Lorentzian signature. We will find it convenient to first Fourier transform the momentum space results to position space, then Wick rotate the position space result, and finally Fourier transform back to (Lorentzian) momentum space, to obtain the S-matrix elements (1.8).

The plan of the rest of the paper is the following. In section 2, we describe the procedure we employ in later sections for the case of an accelerating Liouville wall, for the usual static case. We start with Euclidean momentum space amplitudes, transform them to position space, then Wick rotate to Lorentzian signature, and finally Fourier transform back to Lorentzian momentum (energy) space.

In section 3 we generalize this procedure to the time-dependent case. We consider backgrounds that correspond to a Liouville wall that is static in the far past, and approaches a finite velocity in the far future. The final velocity can be either smaller or larger than the speed of light, and we discuss both cases. For the former case we compute the scattering amplitude of \(n\) incoming particles to one outgoing one (eq. (1.8) with \(n^{\prime}=1\)). We also compute the amplitude for creation of \(n\) particles in the time-dependent background, (1.17). We show that these amplitudes have a thermal character, a phenomenon reminiscent of the Unruh effect [46]. For the latter case, future null infinity is shielded by the potential, and we discuss the observables that one can define in this case.

In section 4 we discuss some generalizations of the analysis of section 3. The main goal of this section is to study the case where the Liouville wall accelerates both in the far past and in the far future, corresponding to eq. (1.11) with \(\lambda_{\pm}>0\) and figure 5. In the regime where the trajectory of the Liouville wall is timelike for all \(t\), we compute the amplitude for particle creation. We find that these amplitudes have a singularity at a finite value of the coupling \(\lambda_{+}\lambda_{-}\) (1.11). In a Hartle-Hawking construction, this singularity appears to correspond to the disappearance of time.

In section 5 we describe the results of the previous sections from the matrix model point of view. As is well known, in the double scaling limit the matrix model reduces to the dynamics of free fermions in an inverted quadratic potential. The massless tachyon field corresponds to a perturbation of the Fermi surface of these fermions. The time-dependent backgrounds we study in sections 3, 4 correspond in this model to backgrounds with a time-dependent Fermi surface. We discuss the dynamics of perturbations of such surfaces, focusing on the difference between the cases \(p<1\) and \(p>1\). We relate the free fermion description to that in terms of an accelerating Liouville wall, and show that the dynamics of perturbations of the Fermi surface is compatible with that seen from the bulk \(1+1\) dimensional string theory perspective.

In section 6 we discuss our results and possible extensions. Two appendices contain reviews of technical results useful for our analysis.

## 2 Wick rotation in the standard background

In this section we illustrate the procedure we will follow for the time-dependent backgrounds, in the usual, time-independent, background of two dimensional string theory, corresponding to a static Liouville wall.

We start with the Euclidean theory (1.1) and take \(X\) to live on a circle of radius \(R\). In this theory, it is known from both continuum and matrix model perspectives [3, 40] that the Euclidean continuation of the \(n\to 1\) scattering amplitude takes the form

\[\left\langle\,\prod_{j=1}^{n}T_{q_{j}}T_{-q^{\prime}}\right\rangle=2\pi R(-1) ^{n}\partial_{\mu}^{n-2}\mu^{q^{\prime}-1}\delta_{m^{\prime},\,\sum_{j=1}^{n} m_{j}}. \tag{2.1}\]

Here \(m^{\prime}=q^{\prime}R\) and \(m_{j}=q_{j}R\), \(j=1,\cdots,n\) are integer momenta.

In order to Wick rotate this amplitude to Lorentzian signature, we proceed as follows. We start by Fourier transforming the operators \(T_{q}\) (1.2) to position space. We define a complex coordinate \(y\equiv y_{1}+iy_{2}\), and write

\[T(y)=\frac{1}{2\pi R}\sum_{m=0}^{\infty}e^{-i\frac{m}{R}y}T_{\frac{m}{R}}, \qquad\bar{T}(\bar{y})=\frac{1}{2\pi R}\sum_{m=0}^{\infty}e^{i\frac{m}{R}\bar {y}}T_{-\frac{m}{R}}. \tag{2.2}\]

As is clear from (2.2), \(y_{1}\) is a compact coordinate, \(y_{1}\sim y_{1}+2\pi R\), so \(y\) parameterizes a cylinder.

Using (2.1), (2.2), we find:

\[\left\langle\,\prod_{j=1}^{n}T(y_{j})\bar{T}(\bar{y})\right\rangle=(2\pi R)^{-n}( -1)^{n}\partial_{\mu}^{n-2}\frac{1}{\mu}\prod_{j=1}^{n}\frac{1}{1-\mu^{\frac{1 }{R}}e^{-\frac{i}{R}(y_{j}-\bar{y})}}. \tag{2.3}\]

We now Wick rotate \(y_{1}=-iy_{0}\), which means \(y=-iu\) and \(\bar{y}=-iv\), where \(u=y_{0}-y_{2}\), \(v=y_{0}+y_{2}\) are lightlike coordinates on \(R^{1,1}\). The corresponding Wick rotation in \((X,\phi)\) space is \(X\to-it\), as described in section 1. Looking back at (1.2) we see that after Wick rotation one can identify \(u\) with \(t-\phi\) and \(v\) with \(t+\phi\), at least asymptotically (_i.e._ near the boundary).

After Wick rotation, the correlation function (2.3) takes the form

\[\left\langle\,\prod_{j=1}^{n}{\cal T}^{+}(u_{j}){\cal T}^{-}(v)\right\rangle=( 2\pi R)^{-n}(-1)^{n}\partial_{\mu}^{n-2}\frac{1}{\mu}\prod_{j=1}^{n}\frac{1}{ 1-\mu^{\frac{1}{R}}e^{-\frac{1}{R}(u_{j}-v)}}. \tag{2.4}\]

The next step is to Fourier transform back to Lorentzian momentum space. With

\[{\cal T}^{+}_{\omega}=\int_{-\infty}^{\infty}due^{-i\omega u}{\cal T}^{+}(u) \,\qquad{\cal T}^{-}_{\omega}=\int_{-\infty}^{\infty}dve^{i\omega v}{\cal T}^{- }(v)\, \tag{2.5}\]

the \(n\to 1\) S-matrix elements are given by

\[\left\langle\,\prod_{j=1}^{n}{\cal T}^{+}_{\omega_{j}}{\cal T}^{-}_{\omega^{ \prime}}\right\rangle=-(-2\pi)^{-n+1}\partial_{\mu}^{n-2}\frac{1}{\mu}\delta( \omega^{\prime}-\sum_{j=1}^{n}\omega_{j})\prod_{j=1}^{n}\mu^{-i\omega_{j}}g( \omega_{j}R)\, \tag{2.6}\]

where

\[g(x)\equiv\int_{-\infty}^{+\infty}dz\frac{e^{ixz}}{1-e^{z}}. \tag{2.7}\]

The integral (2.7) is divergent from \(z\to-\infty\). This divergence can be regularized by an \(i\epsilon\) prescription. Replacing \(x\to x-i\epsilon\) in (2.7), the contribution to the integral from the region \(z\to-\infty\) becomes convergent.

The integrand in (2.7) also has a pole at the origin of the \(z\)-plane, which can be treated as usual by deforming the integration contour to go either above or below it. In both cases the integral can be computed by standard contour deformation techniques. Closing the contour in the upper half plane, using the fact that in (2.6) we are interested in the case where \(x\) in (2.7) has a positive real part, we get that the integral receives contributions from the residues of the poles at \(z=2\pi ik\), with integer \(k\) ranging from \(0\) (or \(1\)) to \(\infty\):

\[g(x)=-2\pi i\sum_{k=0\ {\rm or}\ 1}^{\infty}e^{-2\pi xk}=-2\pi i\frac{e^{2\pi x }}{e^{2\pi x}-1}\ \ {\rm or}\ -2\pi i\frac{1}{e^{2\pi x}-1}. \tag{2.8}\]In our application (2.6), \(x=\omega R\), where \(R\) is related to the temperature via \(\beta=1/T=2\pi R\). At zero temperature, \(R\to\infty\), with the first choice in (2.8), \(g(\omega R)\) approaches a constant, while for the second it goes to zero. Therefore, to get a finite zero temperature limit, we choose the first expression in (2.8). We have checked that the finite temperature amplitudes (2.6), obtained via the Wick rotation described above, are consistent with those calculated in [23].

In the limit \(R\to\infty\), the amplitude (2.6) takes the form:

\[\left\langle\,\prod_{j=1}^{n}{\cal T}^{+}_{\omega_{j}}{\cal T}^{-}_{\omega^{ \prime}}\right\rangle=2\pi i^{n}\delta(\omega^{\prime}-\sum_{j=1}^{n}\omega_{ j})\partial_{\mu}^{n-2}\mu^{-i\sum_{j=1}^{n}\omega_{j}-1}. \tag{2.9}\]

This result is consistent with what we would have obtained by a simple continuation of (2.1) to Lorentzian signature, but in the present discussion it is obtained as a limit from finite temperature of (2.6), which contains more information. In particular, the factor \(g(\omega R)\) for each incoming particle can be written as

\[g=-2\pi i\frac{1}{1-e^{-\frac{\omega}{T}}}. \tag{2.10}\]

This function is constant for \(\omega\gg T\), but varies for \(\omega\sim T\), and in fact diverges as \(\omega\to 0\).

In section 1 we discussed the fact that an insertion of a zero momentum tachyon can be thought of as differentiating the path integral w.r.t. \(\mu\). We see that at finite temperature in Lorentzian signature, the situation is a bit more subtle. Equations (2.6), (2.10) imply that

\[\lim_{\omega\to 0}\frac{2\pi{\cal T}^{+}_{\omega}}{g(\omega R)}=\lim_{\omega \to 0}\frac{i\omega{\cal T}^{+}_{\omega}}{T}=-\partial_{\mu}. \tag{2.11}\]

This is different from the situation at zero temperature, where we can see from (2.9) that the limit \(\omega\to 0\) of \({\cal T}^{+}_{\omega}\) gives \(\partial_{\mu}\) times a multiplicative, \(\omega\)-independent factor. It is not surprising that the two cases are different, since the range of energies \(\omega\ll T\) that is responsible for (2.11) does not exist for \(T=0\).

## 3 Amplitudes in time-dependent backgrounds

In this section we generalize the discussion of section 2 to the case of the time-dependent backgrounds described in section 1. The starting point of that discussion was a Euclidean analysis at a finite value of the radius of Euclidean time, \(R\), and it is natural to generalize it to the present case.

The calculation of section 2 can be done for any \(R\), but in the perturbed system (1.28), \(R\) must satisfy the constraint \(pR=m_{p}\in\mathbb{Z}\). Here \(m_{p}\) is the quantized momentum in the Euclidean time direction. As mentioned in section 1, the analysis simplifies significantly for \(m_{p}=1\), _i.e._ for \(R=1/p\) as in (1.29), and we will mainly restrict to this case below. We will comment in the next section on what happens for \(m_{p}>1\).

In the rest of this section we will study some examples of amplitudes in the background (1.11) with \(\lambda_{-}=0\). We start with the \(n\to 1\) amplitude, the analog of (2.6) for non-zero \(\lambda_{+}\), and then move on to the amplitude for production of \(n\) particles.

We also note that the calculations in this section involve the connected diagrams with given external legs. In general, these amplitudes receive contributions from disconnected diagrams as well, which are in fact generally dominant in the weak coupling limit.

### \(n\to 1\) amplitude

To generalize the analysis of section 2 to the case of non-zero \(\lambda_{+}\), we need first to find the analog of (2.1) for this case. In the Euclidean theory with compact \(X\), we expect the Euclidean amplitude to be perturbative in \(\lambda_{+}\). Expanding the exponential \(\exp(-\lambda_{+}T_{p})\), we need to evaluate amplitudes of the form \(\langle T_{p}^{m}\prod_{j=1}^{n}T_{q_{j}}T_{-q^{\prime}}\rangle\) in the standard background of two dimensional string theory. The momenta \(q_{j},q^{\prime}\) are integer multiples of \(\frac{1}{R}\),

\[q_{j}=\frac{m_{j}}{R}\,\ \ q^{\prime}=\frac{m^{\prime}}{R}\, \tag{3.1}\]

as in (2.1). For \(p=1/R\), _i.e._\(m_{p}=1\), the momenta (3.1) are integer multiples of \(p\), but the analysis of this subsection can be performed for any \(m_{p}\). As mentioned above, we will restrict to the case \(m_{p}=1\) in this section, and will comment on \(m_{p}>1\) later.

The amplitude of interest is essentially the same as (2.1). It is given by

\[\left\langle T_{p}^{m}\prod_{j=1}^{n}T_{q_{j}}T_{-q^{\prime}}\right\rangle= \frac{2\pi}{p}(-1)^{m+n}\partial_{\mu}^{m+n-2}\mu^{q^{\prime}-1}\delta_{m+\sum _{j=1}^{n}m_{j},m^{\prime}}\, \tag{3.2}\]

where the correlator on the l.h.s. is computed at \(\lambda_{+}=0\), and \(q_{j}\), \(q^{\prime}\) are given by (3.1). At finite \(\lambda_{+}\), we have

\[\left\langle\,\prod_{j=1}^{n}T_{q_{j}}T_{-q^{\prime}}\right\rangle_{\lambda_{ +}}=(-1)^{n}\frac{2\pi}{p}\sum_{m=0}^{\infty}\frac{\lambda_{+}^{m}}{m!} \partial_{\mu}^{m+n-2}\mu^{q^{\prime}-1}\delta_{m+\sum_{j=1}^{n}m_{j},m^{ \prime}}. \tag{3.3}\]

As in section 2, we next pass to position space using (2.2), which gives

\[\left\langle\,\prod_{j=1}^{n}T(y_{j})\bar{T}(\bar{y})\right\rangle_{\lambda_{ +}}=\left(-\frac{p}{2\pi}\right)^{n}\sum_{m=0}^{\infty}e^{imp\bar{y}} \partial_{\mu}^{m+n-2}\mu^{mp-1}\frac{\lambda_{+}^{m}}{m!}\prod_{j=1}^{n} \frac{1}{1-e^{-ip(y_{j}-\bar{y})}\mu^{p}}. \tag{3.4}\]Next we Wick rotate the position space expression, by replacing \(y_{j}\to-iu_{j}\), and \(\bar{y}\to-iv\). We find

\[\left\langle\,\prod_{j=1}^{n}{\cal T}^{+}(u_{j}){\cal T}^{-}(v)\right\rangle_{ \lambda_{+}}=\left(-\frac{p}{2\pi}\right)^{n}\sum_{m=0}^{\infty}\frac{\lambda_ {+}^{m}}{m!}e^{mpv}\partial_{\mu}^{m+n-2}\mu^{mp-1}\prod_{j=1}^{n}\frac{1}{1- e^{-p(u_{j}-v)}\mu^{p}}. \tag{3.5}\]

Fourier transforming back to (Lorentzian) momentum space, as in (2.5), we find

\[\left\langle\,\prod_{j=1}^{n}{\cal T}^{+}_{\omega_{j}}{\cal T}^{-}_{\omega^{ \prime}}\right\rangle_{\lambda_{+}}=-(-2\pi)^{-n}\int_{-\infty}^{+\infty}dve ^{i(\omega^{\prime}-\sum_{j=1}^{n}\omega_{j})v}\partial_{\mu}^{n-1}\mu^{-i \sum_{j=1}^{n}\omega_{j}}\frac{(1-r)^{i\sum_{j=1}^{n}\omega_{j}}}{i\sum_{j=1}^ {n}\omega_{j}}\prod_{j=1}^{n}g(\omega_{j}/p)\, \tag{3.6}\]

where

\[\frac{r}{(1-r)^{1-p}}\equiv e^{pv}\mu^{p-1}\lambda_{+}\, \tag{3.7}\]

and \(g(x)\) is given by (2.8).

For \(p<1\) and \(\lambda_{+}>0\), as \(v\) varies from \(-\infty\) to \(\infty\), \(r\) varies from \(0\) to \(1\). Changing variables from \(v\) to \(r\) in (3.6), we find

\[\left\langle\,\prod_{j=1}^{n}{\cal T}^{+}_{\omega_{j}}{\cal T}^{-}_{\omega^{ \prime}}\right\rangle_{\lambda_{+}}=-(-2\pi)^{-n}\frac{\Gamma(\alpha)\Gamma( \beta)}{p\Gamma(\alpha+\beta+1)}\partial_{\mu}^{n-1}\mu^{-\beta}\lambda_{+}^ {-\alpha}\prod_{j=1}^{n}g(\omega_{j}/p)\, \tag{3.8}\]

where

\[\alpha=\frac{i}{p}(\omega^{\prime}-\sum_{j=1}^{n}\omega_{j})\equiv\frac{i}{p} \Delta\omega\,\qquad\beta=\frac{i}{p}\sum_{j=1}^{n}\omega_{j}+i\frac{p-1}{p}\omega^{ \prime}=i\omega^{\prime}-\alpha. \tag{3.9}\]

Thus, \(\alpha\) measures the extent to which energy conservation is violated, and \(\alpha+\beta\) measures the energy of the outgoing particle.

We next discuss some special cases of the general expression (3.8). When any of the incoming momenta \(\omega_{j}\) goes to zero, we can use (2.11) to eliminate the corresponding operator from the correlation function. One can check that the structure of (3.8) is consistent with the resulting relation between the amplitudes with \(n\) and \(n-1\) incoming particles.

Another interesting limit is the one in which the process (3.8) conserves energy, which corresponds to \(\alpha\to 0\) in (3.8). In this limit the amplitude approaches

\[\left\langle\,\prod_{j=1}^{n}{\cal T}^{+}_{\omega_{j}}{\cal T}^{-}_{\omega^{ \prime}}\right\rangle_{\lambda_{+}}=(-2\pi)^{-n}\left(-\frac{\ln\lambda_{+}}{ p}\right)\partial_{\mu}^{n-2}\mu^{-i\omega^{\prime}-1}\prod_{j=1}^{n}g(\omega_{j}/p ). \tag{3.10}\]

The structure of (3.10) can be understood as follows. An energy conserving process does not require the time-dependent perturbation proportional to \(\lambda_{+}\) - it can happen arbitrarily far from the time-dependent part of the Liouville wall. The \(\ln\lambda_{+}\) dependence in (3.10) can be thought of as parametrizing the length of time up to the point (1.15), available to the energy conserving process. Indeed, eq. (3.10) is the same as (2.6), with the energy conservation \(\delta\)-function in the latter equation replaced by \(-\frac{\ln\lambda_{+}}{p}\), as expected from the discussion above.

For \(n=0\), the correlation function (3.8) reduces to the one point function

\[\left\langle{\cal T}^{-}_{\omega^{\prime}}\right\rangle_{\lambda_{+}}=\frac{ \Gamma(\frac{i}{p}\omega^{\prime})\Gamma(i\frac{p-1}{p}\omega^{\prime}-1)}{p \Gamma(i\omega^{\prime}+1)}\mu^{-i\frac{p-1}{p}\omega^{\prime}+1}\lambda_{+}^ {-\frac{i}{p}\omega^{\prime}}. \tag{3.11}\]

One can think of (3.11) as the amplitude for creation of one outgoing particle with energy \(\omega^{\prime}\) in the time-dependent background under consideration. We will discuss the (connected) amplitude for production of multiple particles in the next subsection.

### Particle production

In this subsection we compute the amplitudes for the production of \(n\) particles of energies \((\omega_{1},\omega_{2},\cdots,\omega_{n})\) in the time-dependent background (1.11) with \(\lambda_{-}=0\). These amplitudes were discussed in section 1, around eq. (1.17), (1.23) - (1.27). Here we will omit the primes on the various variables, for notational simplicity. These amplitudes are only defined for \(p<1\), since for \(p>1\) null future infinity is not part of the boundary. We will comment on the case \(p>1\) later in this section.

We follow the same procedure as in the previous subsection. Thus, our first goal is to compute the Euclidean amplitude \(\langle T_{-q_{1}}T_{-q_{2}}\cdot\cdot\cdot T_{-q_{n}}\rangle_{\lambda_{+}}\). In order to do that, we need to compute the amplitudes \(\langle T_{p}^{m}T_{-q_{1}}T_{-q_{2}}\cdot\cdot\cdot T_{-q_{n}}\rangle\) in the standard \(c=1\) background. Unlike the situation in subsection 3.1, here these amplitudes were not computed in the literature. Therefore, we calculated them ourselves, using the (matrix model) techniques of [47]. The calculation is described in appendix B.

The calculations simplify significantly for the case \(m_{p}=1\), _i.e._\(R=1/p\), (1.29). In this subsection we will present the results for this case. We found the following expression for the above correlation functions 6:

Footnote 6: As a consistency check, if we take all \(q_{j}=p\), _i.e._ all \(m_{j}=1\), (3.12) reduces to the amplitude computed in [29], and the results agree.

\[\langle T_{p}^{m}T_{-q_{1}}T_{-q_{2}}\cdot\cdot\cdot T_{-q_{n}}\rangle=(-1)^{ n-1}\frac{2\pi}{p}\frac{m!\partial_{\mu}^{n-3}\mu^{(p-1)m-1}\prod_{j=1}^{n} \Gamma\left((1-p)m_{j}+1\right)}{\prod_{j=1}^{n}\Gamma(m_{j}+1)\Gamma(1-pm_{j })}\delta_{m,\sum_{j=1}^{n}m_{j}}. \tag{3.12}\]

Here \(q_{j}\) are integer multiples of \(p\), \(q_{j}=m_{j}p\), as in (3.1) with (1.29).

Eq. (3.12) leads to

\[\langle T_{-q_{1}}T_{-q_{2}}\cdots T_{-q_{n}}\rangle_{\lambda_{+}}=(-1)^{n-1} \frac{2\pi}{p}\frac{(-\lambda_{+})^{\sum_{j=1}^{n}m_{j}}\partial_{\mu}^{n-3}\mu ^{(p-1)\sum_{j=1}^{n}m_{j}-1}\prod_{j=1}^{n}\Gamma\left((1-p)m_{j}+1\right)}{ \prod_{j=1}^{n}\Gamma(m_{j}+1)\Gamma(1-pm_{j})}\, \tag{3.13}\]

and in position space (2.2),

\[\langle\bar{T}(\bar{y}_{1})\bar{T}(\bar{y}_{2})\cdots\bar{T}(\bar{y}_{n}) \rangle_{\lambda_{+}}=\left(-\frac{p}{2\pi}\right)^{n-1}\partial_{\mu}^{n-3} \frac{1}{\mu}\prod_{j=1}^{n}f(e^{ip\bar{y}_{j}}\lambda_{+}\mu^{p-1})\, \tag{3.14}\]

where [48]

\[f(x)\equiv \sum_{m=0}^{\infty}\frac{(-x)^{m}\Gamma\left(m(1-p)+1\right)}{m! \Gamma(-mp+1)}\] \[= -\frac{\partial}{\partial x}\sum_{m=0}^{\infty}\frac{(-x)^{m} \Gamma\left(m(1-p)+p\right)}{m!\Gamma(-mp+p+1)} \tag{3.15}\] \[= -\frac{\partial}{\partial x}\frac{(1-r)^{p}}{p}\,\]

and \(r(x)\) is defined similarly to (3.7),

\[\frac{r}{(1-r)^{1-p}}=x. \tag{3.16}\]

Wick rotating as before, \(\bar{y}_{j}=-iv_{j}\), gives

\[\langle{\cal T}^{-}(v_{1}){\cal T}^{-}(v_{2})\cdots{\cal T}^{-}(v_{n})\rangle_ {\lambda_{+}}=\left(-\frac{p}{2\pi}\right)^{n-1}\partial_{\mu}^{n-3}\frac{1}{ \mu}\prod_{j=1}^{n}f(e^{pv_{j}}\lambda_{+}\mu^{p-1}). \tag{3.17}\]

Finally, Fourier transforming to \(\omega\) space, as in (2.5), we find

\[\langle{\cal T}^{-}_{\omega_{1}}{\cal T}^{-}_{\omega_{2}}\cdots{\cal T}^{-}_{ \omega_{n}}\rangle_{\lambda_{+}}=\left(-\frac{1}{2\pi}\right)^{n-1}\frac{1}{p }\partial_{\mu}^{n-3}\frac{1}{\mu}\prod_{j=1}^{n}\frac{\Gamma\left(\frac{i \omega_{j}}{p}\right)\Gamma\left(\frac{p-1}{p}i\omega_{j}+1\right)}{\Gamma(i \omega_{j}+1)}(\lambda_{+}\mu^{p-1})^{-i\frac{\omega_{j}}{p}}. \tag{3.18}\]

To better understand the structure of (3.18), it is useful to consider the position space correlator (3.17). The basic building block of this correlator is a factor of the function \(f(x)\) (3.15), with

\[x=e^{pv}\lambda_{+}\mu^{p-1}\, \tag{3.19}\]

for each external leg. The momentum space correlator (3.18) is obtained from \(f\) by Fourier transforming in \(v\), whch is related to \(x\) via (3.19).

In the left panel of figure 3 we plot the function \(f(x)\) for a few values of \(p\). We chose values close to one since, as we discussed in section 1, one of the interesting issues is what happens to the particle creation amplitudes as \(p\to 1\), a point beyond which future null infinity disappears. We see that as \(p\) approaches \(1\), the function \(f(x)\) approaches a step function centered at \(x=1\). In the right panel of figure 3 we verify this by focusing on the behavior of the function \(f\) very close to \(x=1\) for \(p\) very close to one.

The form of the function \(f\) in figure 3 seems in agreement with the physical picture suggested by figure 2. The particles are created throughout the whole process of the acceleration of the Liouville wall, which corresponds to \(v\) between \(-\infty\) and \(+\infty\), and indeed for general \(p\) between \(0\) and \(1\) the function \(f\) has support for all \(x\) in the range \((0,\infty)\). However, as \(p\) approaches \(1\), the velocity of the wall at late times approaches the speed of light, and _at_\(p=1\) there is an upper bound on the value of \(v\), corresponding to the position of the wall. Thus, it is natural that in this limit \(f\) approaches a step function. The location of the step is at \(v^{*}=t^{*}+\phi^{*}\), where \((\phi^{*},t^{*})\) appear in figure 2 and are given by eq. (1.15). One can check that eq. (1.15) implies that \(v^{*}=t^{*}+\phi^{*}\) is equal to the \(v\) that corresponds to \(x=1\) in figure 3 via eq. (3.19).

The steep decline of the function \(f\) near \(x=1\) for \(p\) close to \(1\) corresponds physically to the fact that as \(p\to 1\) the region \(v\simeq v^{*}\) corresponds to larger and larger \(u(=t-\phi)\), where the speed of the Liouville wall is already approximately equal to its final value. Thus, this region doesn't radiate, and its contribution to the Fourier transform performed in going from (3.17) to (3.18) is small.

It is interesting to take the limit \(\omega\to 0\) of (3.18), following the same logic as in (2.11).

Figure 3: The position space amplitude (3.17) includes a factor of the function \(f\) for each created particle. In this figure we plot this function for a range of values of \(p\), and demonstrate that it approaches a step function as \(p\to 1\).

To get a finite answer, we must take the limit as follows:

\[\lim_{\omega\to 0}\frac{2\pi i\omega{\cal T}_{\omega}^{-}}{p}=-\partial_{\mu}. \tag{3.20}\]

Recalling that the temperature \(T\) is given by \(T=1/2\pi R=p/2\pi\), we see that the limit (3.20) is compatible with that taken in (2.11).

Another interesting limit is \(p\to 0\). As is clear from eq. (1.12) and figure 2, in this limit we go back to the time-independent background corresponding to a stationary Liouville wall of section 2. Thus, in this limit the particle production amplitudes (3.18) should go to zero. To see that this is indeed the case, note that in this limit the phase in (3.18), which is given in (1.27), together with a contribution from the beta function prefactor, is more and more rapidly oscillating for any non-zero \(\omega\). Thus, the amplitude to create particles with a finite distribution of energies goes to zero in the limit \(p\to 0\).

The above discussion also has an interesting consequence for the results of subsection 3.1. Equation (3.8) has a finite limit as \(\omega^{\prime}\to 0\):

\[\left\langle\prod_{j=1}^{n}{\cal T}_{\omega_{j}}^{+}{\cal T}_{0}^{-}\right\rangle _{\lambda_{+}}=\frac{(-1)^{n+1}(2\pi)^{-n}\pi}{\sum_{j=1}^{n}\omega_{j}}\sinh^ {-1}\left(\frac{\pi\sum_{j=1}^{n}\omega_{j}}{p}\right)\partial_{\mu}^{n-1}\mu ^{-\frac{i}{p}\sum_{j=1}^{n}\omega_{j}}\lambda_{+}^{\frac{i}{p}\sum_{j=1}^{n} \omega_{j}}\prod_{j=1}^{n}g(\omega_{j}R). \tag{3.21}\]

Using (3.20), we conclude that the amplitude (1.18) vanishes, for all \(n\) and energies \(\{\omega_{j}\}\). In other words, the amplitude for a process in which \(n\) tachyons come in from past null infinity, are absorbed by the time-dependent Liouville wall, and no tachyons come out at late time, vanishes for all \(p<1\).

### \(p>1\)

The general discussion in section 1 leads one to believe that for \(p>1\) the observables \({\cal T}_{\omega}^{-}\) (1.7) should be problematic. Indeed, looking back at figure 2, we see that for \(p>1\) future null infinity is shielded by the dynamical Liouville wall, so an S-matrix cannot be defined. It is interesting to see how this is reflected in the calculations reported earlier in this section. This is the goal of this subsection.

Following the discussion of subsection 3.2, the Euclidean results (3.12) - (3.14) are clearly valid for all \(p\). We can again Wick rotate and get the position space correlation function (3.17). An important difference between the case \(p<1\) and the present one concerns equation (3.16). Recalling that the variable \(x\) in that equation is related to \(v\) via eq. (3.19), we see that for \(p<1\) as \(v\) goes from \(-\infty\) to \(\infty\), \(x\) goes from \(0\) to \(\infty\), and \(r\) goes from \(0\) to \(1\). However, for \(p>1\) the situation is different. In that case, one can write (3.16) as \(x=r(1-r)^{p-1}\) and as \(r\) goes from \(0\) to \(1\), \(x\) first increases, from \(0\) to a maximal value, \(x_{\rm max}\), and then decreases back to \(0\) at \(r=1\). The maximum of the function \(x(r)\) occurs at \(r=1/p\), so

\[x_{\rm max}=x(1/p)=(p-1)^{p-1}p^{-p}. \tag{3.22}\]

In terms of the variable \(v\) (3.19), as \(r\) varies between \(0\) and \(1\), \(v\) increases from \(-\infty\), to some \(v_{\rm max}\), related to \(x_{\rm max}\) (3.22) via (3.19), and then goes back to \(-\infty\). This means that the Fourier transform (2.5) that was done for \(p<1\) in going from position space, (3.17), to momentum space, (3.18), can no longer be done since the range of \(v\) does not extend all the way to \(+\infty\).

The above discussion is in nice correspondence with properties of the potential of figure 2 and eq. (1.14). The solid line in that figure is obtained by setting \(V_{\rm st}(t,\phi)=1\). Since we are interested in the process of emission of tachyons from the accelerating Liouville wall, we are interested in the value of \(v\) along the wall. It is clear from figure 2a, that for \(p<1\), as we move along the Liouville wall, \(v\) varies from \(-\infty\) to \(\infty\), but for \(p>1\), the behavior is different.

In that case, the wall starts at \(v=-\infty\) at early times, moves to larger \(v\), but then reaches a maximal value of \(v\), \(v_{\rm max}\) in figure 2b, at which its velocity reaches the speed of light, and then it starts decreasing, going back to \(v=-\infty\) at late times. A short calculation using eq. (1.14) shows that

\[v_{\rm max}=\frac{1}{p}\ln\frac{(p-1)^{p-1}}{p^{p}\lambda_{+}\mu^{p-1}}. \tag{3.23}\]

In our discussion of the function \(x(r)\) above, we obtained the value of \(v_{\rm max}\) by plugging (3.22) into (3.19). Interestingly, the two values of \(v_{\rm max}\) computed in these different ways coincide.7

Footnote 7: In general, we expect agreement up to an order one constant, that has to do with the fact that we could have set \(V_{\rm st}(t,\phi)\) (1.14) to a constant \(\neq 1\), but as it happens, for \(V=1\) the agreement appears to be exact.

This also explains why the function \(x(r)\) has the property (for \(p>1\)) that each \(x<x_{\rm max}\) appears twice as \(r\) varies from \(0\) to \(1\). In terms of figure 2b, this is a reflection of the fact that each \(v<v_{\rm max}\) appears twice, once in the timelike part of the trajectory of the Liouville wall, and once in the spacelike one. The former corresponds to \(0<r<1/p\); the latter, to \(1/p<r<1\).

As for \(p<1\), it is interesting to plot the function \(f(x)\) for \(p>1\). We do this for a few values of \(p\) in figure 4. As expected, the function \(f\) has two branches. The upper one corresponds to the timelike part of the trajectory of the Liouville wall. It starts at \(x=0\) (_i.e._\(r=0\), \(v=-\infty\)) at \(f=1\), just like for \(p<1\) (figure 3), but in this case it monotonically increases, and diverges as \(x\to x_{\rm max}\), (3.22). This divergence appears to be due to the fact that the acceleration of the Liouville wall diverges as its speed approaches that of light.

Viewed as a function of \(r\), (3.16), \(f\) has a single pole at \(r=1/p\). Thus, as we transition to the spacelike part of the trajectory of the Liouville wall, \(r>1/p\), described by the lower branch of the curve in figure 4, \(f\) starts from \(-\infty\) and rapidly goes to zero. Its decline becomes more and more pronounced as \(p\to 1\) (from above).

In order to understand this behavior, one needs to make sense of the observables (3.17) in this case. For \(p<1\), they were related by a Fourier transform to amplitudes for detecting particles at future null infinity, (3.18). As mentioned above, for \(p>1\) such amplitudes do not make sense. This is reflected in our analysis in the fact that the variables \(v_{j}\) in (3.17) are in this case bounded from above by \(v_{\rm max}\) (3.23). Thus, the usual Fourier transform cannot be done.

There are two attitudes that one can take to this state of affairs. One is that for \(p>1\) there are no physical observables associated with the future region. This seems problematic, especially given the fact that as discussed in the introduction and in the next section, one can turn on both \(\lambda_{+}\) and \(\lambda_{-}\), (1.11), in which case all asymptotic particle states cease to exist, since both past and future null infinities are shielded by the potential. The other possible attitude is that the correlation functions (3.17) do make sense for \(p>1\), as seems to be the case from the above analysis. In that case, one needs to interpret them physically. We will return to this question in later sections.

Figure 4: The form of the function \(f(x)\), (3.15), for \(p>1\). The singularity of the function is at \(x=x_{\rm max}\) (3.22). The two branches correspond to \(r<1/p\) (upper) and \(r>1/p\) (lower) or, equivalently, to the timelike and spacelike parts of the trajectory of the Liouville wall.

Generalizations

The main goal of this section is to discuss the generalization of the analysis of section 3 to the case where both \(\lambda_{+}\) and \(\lambda_{-}\) in (1.11) are positive. However, we start with two brief comments about other issues that were mentioned earlier.

The first involves quantum corrections to the results of section 3. The analysis of that section was done at leading order in \(g_{s}\), _i.e._ the worldsheet was taken to have spherical topology. The matrix model allows one to compute higher order (in \(g_{s}\)) corrections to these results. For example, in (B.9) and (B.18) we present the results for the first subleading corrections to the Euclidean correlation functions \(\langle T_{0}T_{p}^{m}T_{-q}\rangle\) and \(\langle T_{0}T_{p}^{m}T_{-q_{1}}T_{-q_{2}}\rangle\), respectively. These corrections come from the worldsheet torus and, as in section 3, they can be used to calculate the torus contributions to the one and two-point functions of \({\cal T}_{\omega}^{-}\). We will leave a detailed study of these contributions to future work.

The second issue we want to comment on involves eq. (1.29). We said there (and in section 3) that in the Euclidean calculation one could in principle consider other values of the quantized momentum, _i.e._ take \(pR=m_{p}>1\), but it seems that the right value is \(m_{p}=1\). One of the reasons we believe this is that for \(m_{p}>1\) the structure of the amplitudes becomes much more involved. Here we would like to explain what we mean by this.

For general integer \(m_{p}\geq 1\), the calculation that for \(m_{p}=1\) leads to (3.13), gives the following results. For \(n=3\), \(q_{j}=\frac{m_{j}}{R}\) and \(\sum_{j=1}^{n}m_{j}\) an integer multiple of \(m_{p}\), we find

\[\langle T_{-q_{1}}T_{-q_{2}}T_{-q_{3}}\rangle_{\lambda_{+}}=\frac{2\pi R}{\mu }(\lambda_{+}\mu^{p-1})^{\frac{1}{m_{p}}\sum_{j=1}^{3}m_{j}}\prod_{j=1}^{3}h_{ 1}(q_{j})\, \tag{4.1}\]

where

\[h_{1}(q)\equiv(p-1)^{q/p-[q/p]}\prod_{i=1}^{[q/p]}\left(\frac{q}{i}-1\right). \tag{4.2}\]

One can check that for \(m_{p}=1\), (4.1) and (4.2) agree with (3.13). For \(m_{p}>1\), (4.1) is more complicated, but it follows the same pattern as (3.13) - it is still a product of factors associated with the external legs.

For the four point function the factorized structure breaks down. We find

\[\langle T_{-q_{1}}T_{-q_{2}}T_{-q_{3}}T_{-q_{4}}\rangle_{\lambda_{+}}=-\frac{ 2\pi R}{\mu^{2}}(\lambda_{+}\mu^{p-1})^{\frac{1}{m_{p}}\sum_{j=1}^{3}m_{j}}h_{ 2}(q_{1},\cdots,q_{4})\prod_{j=1}^{4}h_{1}(q_{j})\, \tag{4.3}\]

where

\[h_{2}(q_{1},q_{2},q_{3},q_{4})\equiv mp-m-1+\sum_{T\subseteq\{q_{1},q_{2},q_ {3},q_{4}\}}\frac{(-1)^{|T|}\sum_{l=1}^{m-1}|q(T)-lp|}{4}. \tag{4.4}\]Here \(T\) is any subset of \(\{q_{1},q_{2},q_{3},q_{4}\}\), and \(|T|\) and \(q(T)\) denote the number and sum of the elements in \(T\), respectively. One can check that when \(q_{j}/p\) are integers, which is the case for \(m_{p}=1\), eq. (4.3) reduces to (3.13). However, for general \(m_{p}>1\), \(q_{j}/p\) is not an integer, and (4.3) is more complicated.

This complexity increases as the number of insertions \(n\) increases, and we believe that the resulting theory does not correspond after Wick rotation to the theory described in section 1. It would be interesting to understand whether it has a physical interpretation. This too is left for future work.

We next turn to the case where both \(\lambda_{+}\) and \(\lambda_{-}\) in (1.11) are positive. We start with a few comments:

* In section 3 we discussed the case \(\lambda_{-}=0\), in which the Liouville wall is stationary in the past and has a time-dependent form in the future. The case \(\lambda_{+}=0\) can be similarly studied by taking \(t\to-t\), and exchanging the roles of \({\cal T}^{+}\) and \({\cal T}^{-}\).
* Turning on both \(T_{p}\) and \(T_{-p}\) in (1.11), the potential (1.14) takes the form \[V_{\rm st}(t,\phi)=\mu e^{2\phi}+\lambda_{+}e^{(2-p)\phi+pt}+\lambda_{-}e^{(2 -p)\phi-pt}\.\] (4.5) We will take the couplings \(\lambda_{\pm}\) to be positive, as before.
* In principle, we could take the momentum of the \(\lambda_{-}\) deformation in (4.5) to be different from (the negative of) that of the \(\lambda_{+}\) one. However, as discussed above, our Euclidean space techniques make it natural to take both of them to be \(1/R\), (1.29). This is consistent with [34], who show that the perturbation (4.5) leads to thermodynamic behavior with temperature \(p/2\pi\). Thus, we will restrict to the case where the two momenta are equal (and opposite).
* When \(\lambda_{\pm}>0\), we can set \(\lambda_{+}=\lambda_{-}=\lambda\) in (4.5), by shifting the origin of time. In this case, which is depicted in figure 5, the worldsheet theory has a symmetry \(t\to-t\). This allows one to use the Hartle-Hawking construction: replace the \(t<0\) region of the background by its Euclidean analog, (1.28), which similarly has an \(X\to-X\) symmetry, and view it as providing an initial state for the Lorentzian evolution at \(t>0\).
* When \(\lambda_{\pm}\) are both non-zero, there is an ambiguity in the definition of \(\mu\). If either of these couplings vanishes, we can go to a region where the Liouville wall is stationary and read off \(\mu\) there. However, when \(\lambda_{+}\lambda_{-}\neq 0\), such a region does not exist. This ambiguity will play a role below.

In the rest of this section we will generalize the discussion of section 3 to the case \(\lambda_{+},\lambda_{-}>0\). We will use the same method as there: start with the Euclidean calculation, go to position space, Wick rotate, and go back to (Lorentzian) momentum space. We will only consider the amplitude for emission of \(n\) outgoing tachyons (1.17). The amplitude for absorption of \(n\) tachyons, (1.16), can be obtained from it by using the time reversal symmetry mentioned above.

Fortunately, the Euclidean amplitudes needed for the analysis have been calculated before. In particular, from (3.12), we have

\[\begin{split}\langle T_{p}^{m+m^{\prime}}T_{-p}^{m^{\prime}}T_{-q _{1}}T_{-q_{2}}\cdots T_{-q_{n}}\rangle=&(-1)^{n+m^{\prime}-1} \frac{2\pi}{p}(m+m^{\prime})!\partial_{\mu}^{n+m^{\prime}-3}\mu^{(p-1)(m+m^{ \prime})-1}\\ &(1-p)^{m^{\prime}}\prod_{j=1}^{n}\frac{\Gamma\left((1-p)m_{j}+1 \right)}{\Gamma(m_{j}+1)\Gamma(1-pm_{j})}\delta_{m,\sum_{j=1}^{n}m_{j}}\,\end{split} \tag{4.6}\]

and therefore

\[\begin{split}\langle T_{-q_{1}}T_{-q_{2}}\cdots T_{-q_{n}} \rangle_{\lambda_{+},\lambda_{-}}=&\sum_{m,m^{\prime}=0}^{ \infty}\frac{(-\lambda_{+})^{m+m^{\prime}}(-\lambda_{-})^{m^{\prime}}}{(m+m^{ \prime})!m^{\prime}!}\langle T_{p}^{m+m^{\prime}}T_{-p}^{m^{\prime}}T_{-q_{1}} T_{-q_{2}}\cdots T_{-q_{n}}\rangle\\ =&\sum_{m^{\prime}=0}^{\infty}\frac{(-\lambda_{+}) ^{\sum_{j=1}^{n}m_{j}+m^{\prime}}(-\lambda_{-})^{m^{\prime}}}{m^{\prime}!}(-1) ^{n+m^{\prime}-1}\frac{2\pi}{p}\partial_{\mu}^{n+m^{\prime}-3}\\ &\mu^{(p-1)(\sum_{j=1}^{n}m_{j}+m^{\prime})-1}(1-p)^{m^{\prime}} \prod_{j=1}^{n}\frac{\Gamma\left((1-p)m_{j}+1\right)}{\Gamma(m_{j}+1)\Gamma(1 -pm_{j})}\,\end{split} \tag{4.7}\]

Figure 5: For general \(\lambda_{+}\) and \(\lambda_{-}\), the trajectory of the Liouville wall takes the qualitative form depicted here.

[MISSING_PAGE_FAIL:28]

We next comment on some properties of (4.11) - (4.13).

One property is that for \(p<1\),9 (4.11), (4.13) diverge as \(s\to\frac{1}{p-1}\). That value of \(s\) corresponds to the maximal value of the coupling \(\lambda_{+}\lambda_{-}\), according to (4.12). The physics of this singularity was discussed in [31, 32] in the Euclidean system. In that case, the worldsheet potential is proportional to \(\cos pX\), and the singularity is associated with the field \(X\) settling at the minimum of the potential and disappearing from the dynamics.

Footnote 9: For \(p>1\) there is no such singularity, since \(s=\frac{1}{p-1}\) is outside the physical regime \(0\leq s<1\).

In our Lorentzian system, this would correspond to the disappearance of time - an exotic phenomenon. We leave a more complete understanding of this phenomenon to future work. Here, we note that a setting in which the question what happens as \(s\) approaches the critical value \(\frac{1}{p-1}\) can be addressed is the Hartle-Hawking construction mentioned above.

Another interesting feature of (4.13) is that the effect of non-zero \(s\) on the function \(f\) is to change its argument by the multiplicative factor \((1-s)^{1-p}\). One possible way to interpret this is to use an observation we made earlier. When both couplings \(\lambda_{\pm}\) are non-zero, the notion of what is \(\mu\) is ambiguous. Thus, we can view the multiplicative factor in the argument of \(f\) in (4.13) as due to a renormalization of \(\mu\). Indeed, if we make the replacement

\[\mu\to\mu(1-s)\, \tag{4.14}\]

the argument of \(f\) in (4.13) goes back to that in (3.17). This choice is natural since it also simplifies eq. (4.12), which becomes10

Footnote 10: Note that since for \(p>1\) (4.12) implies that \(0\leq s<1\), in terms of the rescaled \(\mu\) the r.h.s. of (4.15) is bounded from above. This is just a different parametrization of coupling space, a standard phenomenon in QFT.

\[s=(p-1)\lambda_{+}\lambda_{-}\mu^{p-2}. \tag{4.15}\]

Note also that the replacement (4.14) was found in [32] to simplify the expression for the partition sum of the Euclidean theory (1.28); see the discussion around eq. (3.11) in that paper.

We will see that the replacement (4.14) is also natural from the point of view of the dynamics of the free fermions in the matrix model. However, whether we make this replacement or not, the important thing is that for non-zero \(s\) we have an ambiguity of rescaling \(\mu\) by a function of \(s\), and different descriptions of the theory may differ by such rescalings.

In section 3, we showed that for \(\lambda_{+}>0\), \(\lambda_{-}=0\), the \(n\)-point function (1.16) vanishes (see the discussion around eq. (3.21)). Here we note that this feature also follows from (4.11). Indeed, the symmetry under \(t\leftrightarrow-t\), \(+\leftrightarrow-\) implies that the amplitude (1.16) is proportional to \(\lambda_{-}^{-\frac{i}{p}\sum\omega_{j}}\). As \(\lambda_{-}\) decreases, this factor leads to a rapidly oscillating phase and the amplitude vanishes in the limit \(\lambda_{-}\to 0\).

Another calculation from section 3 that is interesting to generalize to the case \(\lambda_{\pm}>0\) is the comparison of \(v_{\rm max}\), (3.23), obtained from the potential (1.14) and from the amplitudes (3.17). For \(\lambda_{-}=0\) we found a precise agreement between the two. For general \(\lambda_{-}\), the second way of determining \(v_{\rm max}\) gives the same answer, (3.23), in terms of the renormalized cosmological constant, since after the redefinition (4.14) the argument of the function \(f\) in (4.13) is the same as before.

To determine \(v_{\rm max}\) from the potential, we need to calculate the value of \(v\) for which the Liouville wall associated with (4.5) reaches the speed of light. A short calculation leads to the result

\[e^{pv_{\rm max}}=\frac{(p-1)^{p-1}F(s)}{p^{p}\lambda_{+}\mu^{p-1}}. \tag{4.16}\]

where \(F(s)\) is determined by

\[F(s)\left(1+\frac{p^{p}s}{(p-1)^{p}(1-s)^{2-p}F(s)}\right)^{p-1}=1. \tag{4.17}\]

For \(s=0\), (4.17) gives \(F(0)=1\), and (4.16) agrees with (3.23), as expected. As \(s\to 1\), it behaves as

\[F(s\to 1)\simeq\left(\frac{p}{p-1}\right)^{\frac{p(p-1)}{p-2}}(1-s)^{p-1}. \tag{4.18}\]

For general \(s\in(0,1)\), (4.17) interpolates between the two behaviors, as demonstrated in figure 6. Thus, it does not agree with (3.23). The two differ by a redefinition of \(\mu\), similar to that in (4.14),

\[\mu\to\mu G(s)^{\frac{1}{p-1}}\, \tag{4.19}\]

where \(G(s)\) is the ratio of the two \(F\) functions (4.16). This ratio is a smooth finite function for all \(s\in[0,1]\). Our view is that agreement up to such a redefinition is sufficient. The difference between the two calculations seems to be due to the fact that one of them (the

Figure 6: Solutions of (4.17) for several values of \(p\).

one from the amplitudes) includes quantum effects in the worldsheet theory, while the other one (based on the form of the Liouville potential) is classical.

Note that the fact that \(v_{\rm max}\) takes the general form (4.16) follows from the symmetry of the problem under shifts of \(t\), \(\phi\), with the appropriate rescaling of \(\mu\), \(\lambda_{\pm}\), such that the potential (4.5) is invariant. This, together with the freedom to rescale \(\mu\) by a function of \(s\), (4.19), seems to make the agreement between the different calculations superfluous. We believe that the main test of the agreement between the different calculations is that, as mentioned above, the resulting ratio \(G(s)\) is finite for all \(s\).

## 5 Free fermion perspective

The analysis of the previous sections was performed from the perspective of \(1+1\) dimensional string theory - the bulk theory in the holographic correspondence. We did use some results from the dual boundary theory, matrix quantum mechanics (MQM) in a double scaling limit, but only as a tool for computing correlation functions in the standard background (1.1). In this section we discuss the physical picture obtained in these earlier sections from the point of view of the boundary theory.

As reviewed in appendix A, double scaled MQM can be viewed as a theory of \(N\to\infty\) free fermions in an inverted harmonic potential, (A.1). The standard background corresponds to a state in which all energy levels up to \(-\mu\) are filled (figure 10), and the Fermi surface takes the form in figure 11.

The backgrounds of this paper correspond to Fermi surfaces that are time-dependent. The dynamics of such Fermi surfaces was studied in [33, 34, 35, 36, 37, 38, 39]. In particular, the backgrounds (1.11) with general \(0<p\leq 2\) were discussed in [33, 34, 35]. For \(\lambda_{-}=0\), these backgrounds correspond to Fermi surfaces that take the parametric form

\[\begin{split}\lambda&=a_{0}\cosh w+a_{+}e^{(1-p)w +pt}\,\\ p_{\lambda}&=a_{0}\sinh w+a_{+}e^{(1-p)w+pt}\,\end{split} \tag{5.1}\]

with \(-\infty<w<\infty\), and

\[a_{0}=-\sqrt{2\mu}\,\qquad a_{+}=-\frac{1}{\sqrt{2}}\lambda_{+}\mu^{\frac{p- 1}{2}}. \tag{5.2}\]

Eliminating \(w\) in (5.1), the Fermi surface takes the form11

Footnote 11: Note that (5.1), (5.2) imply that \(p_{\lambda}>\lambda\) for all \(p\), \(w\).

\[\lambda^{2}-p_{\lambda}^{2}+\frac{2a_{+}}{(-a_{0})^{p-1}}e^{pt}(p_{\lambda}- \lambda)^{p}=a_{0}^{2}. \tag{5.3}\]In figure 7, we plot (5.3) for \(p=0.5\) and \(p=1.5\), to illustrate the time evolution of the Fermi surface for \(p<1\) and \(p>1\), respectively. At early times, \(t\to-\infty\), the Fermi surface is approximately static, given by the \(\lambda<0\) branch of the hyperbola \(\lambda^{2}-p_{\lambda}^{2}=2\mu\). The fermions fill the region \(-\infty<\lambda\leq-\sqrt{2\mu}\) in \(\lambda\) space. In terms of the coordinate \(\phi\), related to \(\lambda\) via the relation [49]

\[\lambda=-\sqrt{2}e^{-\phi}\, \tag{5.4}\]

it is \(-\infty<\phi\leq-\frac{1}{2}\ln\mu\).

As \(t\) increases, the Fermi surface moves to the left. Its rightmost edge, \(\lambda_{\rm max}(t)\), can be determined by solving the equation \(\partial_{w}\lambda=0\). At large \(t\) and \(p<1\) one finds, from (5.1), \(w\sim-\frac{p}{2-p}t\), \(\lambda_{\rm max}\sim e^{\frac{p}{2-p}t}\), and (5.4), \(\phi_{\rm max}\sim-\frac{p}{2-p}t\). So, the edge of the distribution moves to the left with speed \(\frac{p}{2-p}\), which is smaller than the speed of light. Note that this velocity is the same as that of the Liouville wall (see figure 2), though we will see that the two (the edge of the Fermi surface and the Liouville wall) are distinct objects. For \(p>1\), \(\lambda_{\rm max}(t)\) corresponds at large \(t\) to \(w\sim t\). So \(\lambda_{\rm max}\sim e^{t}\), and \(\phi_{\rm max}\sim-t\). Thus, in this case the edge of the Fermi surface moves to the left with the speed of light.

The lower branch of the Fermi surface in figure 7 corresponds asymptotically to \(w\to\infty\) in (5.1). In this limit, \(p_{\lambda}-\lambda=|a_{0}|e^{-w}\to 0\), so the Fermi surface approaches the line \(p_{\lambda}=\lambda\)

Figure 7: Profile of Fermi sea for (a) \(p=0.5\) and (b) \(p=1.5\), with \(a_{0}=-1\) and \(a_{+}=-0.1\). In terms of the parametrization (5.1), (5.2), \(w\to\pm\infty\) correspond to the asymptotic regions of the lower and upper branch, respectively.

for all \(t\). The asymptotic region of the upper branch in figure 7 corresponds to \(w\to-\infty\). Using the fact that \(p_{\lambda}+\lambda=a_{0}e^{w}+2a_{+}e^{(1-p)w+pt}\), we see that for \(p<1\), \(p_{\lambda}+\lambda\to 0\) in this limit, while for \(p>1\), \(p_{\lambda}+\lambda\to-\infty\).12

Footnote 12: Note, however, that the sum \(p_{\lambda}+\lambda\) grows slower with \(|w|\) than each of the two quantities separately.

The massless tachyon in the bulk \(1+1\) dimensional string theory description corresponds in the fermion language to a ripple on the Fermi surface. In the standard background, which is described by the Fermi surface of figure 11, an incoming tachyon is described by a ripple that starts at early time on the upper branch of the hyperbola, at large negative \(\lambda\) (or \(\phi\), (5.4)). Since \(p_{\lambda}\) is positive there, the ripple propagates to the right. It corresponds to \({\cal T}^{+}\) in figure 1.

As time goes by, the ripple propagates down the Fermi surface of figure 11. Eventually, at some time, it reaches the \(\lambda\) axis, after which it moves to the lower branch of the hyperbola. There, it has \(p_{\lambda}<0\), and thus is moving to the left. It corresponds (asymptotically, at large \(t\)) to \({\cal T}^{-}\). The transition between the two regimes happens at \(p_{\lambda}=0\), _i.e._\(\lambda=-\sqrt{2\mu}\), and (5.4) \(\phi=-\frac{1}{2}\ln\mu\). The latter is precisely the location of the Liouville wall (see figure 1), as expected.

Clearly, the above description can be generalized to the case of non-zero \(\lambda_{+}\). In this case, the incoming tachyons correspond to ripples starting at early times in the upper left region in figure 7, propagate to the right, and change direction at the value of \(\lambda\) where the time-dependent Fermi surface intersects the \(\lambda\) axis. Thus, the position of the Liouville wall is given by setting \(p_{\lambda}=0\) in the expression for the Fermi surface (5.3). Using (1.14), (5.2), (5.4), one can check that this gives precisely the equation \(V_{\rm st}(t,\phi)=1\), with \(V_{\rm st}\) given by (1.14).

In the previous sections, we saw that there is a qualitative difference between the case \(p<1\), where the trajectory of the Liouville wall remains timelike for all \(t\), and \(p>1\), where it eventually becomes spacelike. It is interesting to see how this difference manifests itself in the free fermion language.

For this purpose, we turn to a more detailed description of the ripples on the Fermi surface, that correspond in this language to tachyon perturbations in the \(1+1\) dimensional string theory. Small ripples can be thought of as points on the Fermi surface that follow the trajectories [50]

\[p_{\lambda}=\dot{\lambda}\,\qquad\lambda=\dot{p}_{\lambda}. \tag{5.5}\]

The solution of these equations is

\[\lambda=-\rho\cosh(t-\sigma)\,\qquad p_{\lambda}=-\rho\sinh(t-\sigma)\, \tag{5.6}\]where \(\rho\) and \(\sigma\) are determined by the initial conditions. We will take \(\rho>0\), since we want to consider perturbations on the Fermi surface that extends to \(\lambda\to-\infty\).

The parameter \(\sigma\) is not independent of \(\rho\), since the trajectories in question must lie on the Fermi surface. Plugging (5.6) in (5.3), we get

\[\sigma(\rho)=\frac{1}{p}\ln\frac{(\rho^{2}-a_{0}^{2})(-a_{0})^{p}}{2a_{0}a_{+} \rho^{p}}. \tag{5.7}\]

The trajectories (5.6), (5.7) have the following qualitative structure. As \(t\to-\infty\), eq. (5.6) implies that \(\lambda\to-\infty,\ p_{\lambda}\to\infty\), with \(p_{\lambda}\sim-\lambda\). Thus, at early times (5.6) describes a ripple moving to the right from large negative \(\lambda\), with speed close to the speed of light. At \(t=\sigma(\rho)\), (5.7), the ripple turns around, and starts going to the left (_i.e._\(p_{\lambda}\) changes sign). At that time, the ripple is at \(\lambda=-\rho\), which is thus the position of the Liouville wall at \(t=\sigma(\rho)\). As \(t\to\infty\), \(\lambda,\ p_{\lambda}\to-\infty\), with \(p_{\lambda}\sim\lambda\), _i.e._ the speed of the ripple approaches the speed of light again. We plot a few examples of these trajectories in figure 8.

Eq. (5.7) implies that the constant \(\rho\) varies from \(|a_{0}|\) to infinity. As \(\rho\to|a_{0}|\), \(\sigma\to-\infty\), and (5.6) describes a trajectory which coincides with the shape of the early-time Fermi surface. The trajectory crosses the \(\lambda\) axis at \(t=\sigma\), which also goes to \(-\infty\) in this limit. Thus, this limit describes ripples that are reflected from the time-dependent Liouville wall at a very early time.

For such ripples, at finite times, _e.g._\(t=0\), \(\lambda=-\rho\cosh(-\sigma)\sim a_{0}e^{-\sigma}\to-\infty\), which is much larger (in absolute value) than \(\lambda_{\rm max}\) at that time. Furthermore, \(p_{\lambda}\sim\lambda\) at that time, which means that the ripple approaches the speed of light. This corresponds to a ripple that propagates to the left along the lower branch of the Fermi surface in figure 7, and is well separated from the tip of the Fermi surface.

For large \(\rho\), (5.7) implies that \(\sigma\sim\frac{2-p}{p}\ln\rho\). Such ripples are reflected from the Liouville wall at a late time, \(t=\sigma\). The fate of these ripples depends on the sign of \(p-1\). To see that, it is useful to ask at what time does a ripple with given \(\rho\) pass the tip of the Fermi surface. This time is obtained by solving the equation

\[\left.\partial_{\rho}\lambda\right|_{t=t_{0}}=-\cosh(t_{0}-\sigma(\rho))+\rho \sinh(t_{0}-\sigma(\rho))\sigma^{\prime}(\rho)=0\, \tag{5.8}\]

which gives

\[e^{2t_{0}}=\frac{1}{(1-p)\rho^{2}+a_{0}^{2}p}\left(\frac{(\rho^{2}-a_{0}^{2})( -a_{0})^{p}}{2a_{0}a_{+}}\right)^{\frac{2}{p}}. \tag{5.9}\]

As a check of this equation, it is clear from figures 7, 8, that it must be that \(t_{0}(\rho)>\sigma(\rho)\), _i.e._ a ripple with given \(\rho\) first encounters the Liouville wall, turns around, and at a later time approaches the tip of the Fermi surface. One can check that for all \(\rho\) for which (5.9) has a real solution, this is indeed the case.

As \(\rho\to|a_{0}|\), \(t_{0}(\rho)\to-\infty\). This is consistent with what we discussed above, where we saw that for \(\rho\to|a_{0}|\), the ripple crosses the \(\lambda\) axis at \(t=\sigma\to-\infty\), (5.7). At that early time, the hyperbola describing the Fermi surface is symmetric under \(p_{\lambda}\to-p_{\lambda}\) (the Fermi surface is approximately static), so the time at which \(p_{\lambda}=0\) approximately coincides with the tip of the Fermi surface, \(\sigma(\rho)\sim t_{0}(\rho)\).

As \(\rho\) increases, \(t_{0}(\rho)\), (5.9), increases monotonically. For \(p<1\), as \(\rho\) varies from \(|a_{0}|\) to \(\infty\), \(t_{0}\) runs from \(-\infty\) to \(+\infty\). In other words, a ripple with any \(\rho\) starts on the upper branch of the Fermi surface at early time, reaches the tip of the Fermi surface at some finite time \(t_{0}(\rho)\), (5.9), and then moves to the lower branch of the Fermi surface in figure 7a. The S-matrix discussed in section 3 for this case corresponds to such processes.

On the other hand, for \(p>1\), as we increase \(\rho\), we get to a critical \(\rho\),

\[\rho_{c}=\sqrt{\frac{p}{p-1}}|a_{0}|\, \tag{5.10}\]

at which \(t_{0}\) (5.9) diverges. For \(|a_{0}|<\rho<\rho_{c}\), the picture is like for \(p<1\), as illustrated by the two rightmost dashed lines in figure 8. But for \(\rho>\rho_{c}\), the ripple never gets to the tip of the Fermi surface, and stays on the upper branch for all \(t\). This is the case for the trajectories described by the two leftmost dashed lines in figure 8. For \(\rho=\rho_{c}\), the ripple approaches the tip of the Fermi surface as \(t\to\infty\).

Interestingly, the bound \(\rho<\rho_{c}\) described above corresponds to the bound on \(v\), (3.23), encountered in section 3 above. Indeed, we can calculate the value of \(v=t+\phi\) at which

Figure 8: The solid lines describe the form of the Fermi surface for \(p=1.5\), \(a_{0}=-1\), \(a_{+}=-0.1\) and a few values of \(t\). The dashed black lines describe ripples with various values of \(\rho\).

a ripple with \(\rho=\rho_{c}\) is reflected from the Liouville wall. The time at which it is reflected is \(t_{c}=\sigma(\rho_{c})\) (5.7). The spatial position is \(\lambda_{c}=-\rho_{c}\) (see the discussion after (5.6)), or \(\phi_{c}=-\ln\frac{\rho_{c}}{\sqrt{2}}\), (5.4). One can check that \(t_{c}+\phi_{c}=v_{\rm max}\) given in (3.23).

Ripples with \(\rho<\rho_{c}\) are reflected at \(v(\rho)<v_{\rm max}\). As expected from the above discussion, the function \(v(\rho)\), has a maximum at \(\rho=\rho_{c}\). This can be seen as follows. We have

\[v(\rho)=t(\rho)+\phi(\rho)=\sigma(\rho)-\ln\frac{\rho}{\sqrt{2}}. \tag{5.11}\]

Thus, \(v^{\prime}=0\) is equivalent to

\[\sigma^{\prime}(\rho)=\frac{1}{\rho}. \tag{5.12}\]

To see that this relation is satisfied at \(\rho=\rho_{c}\), we look back at (5.8), recalling that as \(\rho\to\rho_{c}\), \(t_{0}\to\infty\). Conversely, if (5.12) is satisfied at some \(\rho\), and \(\sigma(\rho)\) is finite, \(t_{0}\) must go to infinity, which means that \(\rho=\rho_{c}\), (5.9).

Therefore, \(v(\rho)\) has the following qualitative structure. It monotonically increases with \(\rho\) until the critical value (5.10), at which it is given by \(v_{\rm max}\), (3.23), and then monotonically decreases for \(\rho>\rho_{c}\). This is precisely the behavior one expects from the form of the Liouville wall of figure 2b.

For \(\rho<\rho_{c}\), _i.e._\(v<v_{\rm max}\), we have a picture similar to that for \(p<1\). In particular, it appears that for ripples with these values of \(\rho\) there is an S-matrix, describing the propagation from asymptotic past infinity on the upper branch to asymptotic future infinity on the lower one. We will return to these observables in the next section. Here, we want to mention two things about them. One is that they are very similar to the position space observables we defined in section 3, _e.g._ in eq. (3.17).13 In particular, the range of \(v\) and the physical interpretation are very similar in the two cases.

Footnote 13: The direct analog of the discussion here is the two point function \(\langle{\cal T}^{+}{\cal T}^{-}\rangle\).

The second is that in both cases there is a puzzle associated with these observables. In the language of this section, an incoming ripple that is reflected from the Liouville wall at a \(v(\rho)<v_{\rm max}\), can propagate to the left on the lower branch of the Fermi surface. However, eventually it is overtaken by the Liouville wall, which corresponds to the intersection of the Fermi surface with the \(\lambda\) axis in figure 7b, and asymptotically moves faster than light. Thus, their physical interpretation as string theory observables is unclear, since the latter should be defined far from the Liouville wall.

In section 4 we discussed the generalization of the above analysis to the case where both \(\lambda_{+}\) and \(\lambda_{-}\) are non-zero. It is interesting to describe this case in the free fermion language.

he Fermi surface takes now the form [35]

\[\begin{split}\lambda&=a_{1}\cosh w+a_{+}e^{(1-p)w+pt}+a_ {-}e^{-(1-p)w-pt}\,\\ p_{\lambda}&=a_{1}\sinh w+a_{+}e^{(1-p)w+pt}-a_{-}e^{ -(1-p)w-pt}\,\end{split} \tag{5.13}\]

where \(a_{\pm}=-2^{-\frac{p}{2}}\lambda_{\pm}|a_{1}|^{p-1}\) and \(a_{1}\) satisfies the equation

\[\mu=\frac{a_{1}^{2}}{2}+(1-p)\lambda_{+}\lambda_{-}\left(\frac{a_{1}^{2}}{2} \right)^{p-1}. \tag{5.14}\]

Eqs. (5.13), (5.14) generalize (5.1), (5.2) to the case where both \(\lambda_{+}\) and \(\lambda_{-}\) are non-zero. In figure 9 we plot the resulting Fermi surfaces.

To understand (5.14), it is useful to define a quantity \(\psi\), via the equation

\[\frac{a_{1}^{2}}{2}=\mu\psi. \tag{5.15}\]

Plugging (5.15) into (5.14), and comparing to (4.12), we see that

\[\psi=\frac{1}{1-s}. \tag{5.16}\]

T

Figure 9: The profile of the Fermi sea (5.13) for (a) \(p=0.5\) and (b) \(p=1.5\), with \(a_{1}=-1\) and \(a_{\pm}=-0.1\). Note the symmetry under \(t\to-t\).

Thus, one can think of \(\frac{a_{1}^{2}}{2}\) as the renormalized cosmological constant discussed in section 4, around eq. (4.14).

The qualitative picture is expected to be the same for this case, as in the discussion of the special case \(\lambda_{-}=0\) above. For \(p<1\), ripples on the Fermi surface propagate from the upper branch of the hyperbolas in figure 9a at early times to the lower branch at late times, and one can define an S-matrix. For \(p>1\), there is a maximal value of \(v\), \(v_{\rm max}\), beyond which they remain trapped, and do not make it to asymptotic infinity on the lower branch. We next calculate \(v_{\rm max}\).

Recall that \(v(\rho)\) is the value of \(t+\phi\) at the point where the ripple with a certain \(\rho\) is reflected from the Liouville wall. As \(\rho\) approaches its critical value, \(v\) approaches \(v_{\rm max}\), and the time at which the ripple passes the edge of the Fermi surface goes to infinity. This can be used to calculate \(v_{\rm max}\) for the general case (5.13).

The tip of the Fermi surface can be obtained by solving the equation

\[\frac{\partial\lambda}{\partial w}=a_{1}\sinh w+(1-p)a_{+}e^{(1-p)w+pt}-(1-p)a _{-}e^{-(1-p)w-pt}=0 \tag{5.17}\]

for \(w\), and plugging back into (5.13). To calculate \(v_{\rm max}\), we need to take \(t\to\infty\). In this limit, the solution of (5.17) is

\[w\simeq t+\frac{1}{p}\ln\frac{2(p-1)a_{+}}{a_{1}}. \tag{5.18}\]

Plugging (5.18) into (5.13), we get

\[\lambda(t)\simeq-\frac{e^{t}}{2}\left(\frac{2p^{p}|a_{1}|^{p-1}|a_{+}|}{(p-1)^ {p-1}}\right)^{\frac{1}{p}}. \tag{5.19}\]

On the other hand, from (5.6) we learn that at large \(t\),

\[\lambda(t)\simeq-\frac{e^{t}}{2}\rho_{c}e^{-\sigma_{c}}. \tag{5.20}\]

Comparing the two equations, we have

\[\rho_{c}e^{-\sigma_{c}}=\left(\frac{2p^{p}|a_{1}|^{p-1}|a_{+}|}{(p-1)^{p-1}} \right)^{\frac{1}{p}}. \tag{5.21}\]

The expression on the l.h.s. of (5.21) has a nice interpretation. As discussed earlier in this section, the critical ripple is reflected from the Liouville wall at \((t,\lambda)=(\sigma_{c},-\rho_{c})\), or in terms of \((t,\phi)\) at \((t_{c},\phi_{c})=(\sigma_{c},-\ln\frac{\rho_{c}}{\sqrt{2}})\). Thus,

\[e^{v_{\rm max}}=e^{\phi_{c}+\sigma_{c}}=\frac{\sqrt{2}}{\rho_{c}}e^{\sigma_{c }}. \tag{5.22}\]Plugging (5.22) in (5.21), we conclude that

\[e^{v_{\rm max}}=\sqrt{2}\left(\frac{(p-1)^{p-1}}{2p^{p}|a_{1}|^{p-1}|a_{+}|} \right)^{\frac{1}{p}}\, \tag{5.23}\]

or

\[e^{pv_{\rm max}}=\frac{(2p-2)^{p-1}}{p^{p}\lambda_{+}a_{1}^{2p-2}}. \tag{5.24}\]

This is the same result we got from an analysis of the amplitudes in section 4, and as there, it also agrees with the result we got for \(\lambda_{-}=0\), (3.23), written in terms of the renormalized cosmological constant (5.15).

## 6 Summary and discussion

### Summary

The main goal of this paper was to study \(1+1\) dimensional string theory in time-dependent backgrounds, building on previous work on this subject. From the bulk point of view in the holographic duality between \(1+1\) dimensional string theory and double scaled matrix quantum mechanics, these backgrounds correspond to solutions in which the Liouville wall is accelerating from one velocity in the far past to another in the far future. In the boundary theory, they correspond to solutions in which the Fermi surface of free fermions in an inverted harmonic potential is time-dependent.

We discussed different types of backgrounds of this kind. In the background we studied in detail in section 3, the Liouville wall moves towards the boundary, with a velocity that goes from zero as \(t\to-\infty\), to a finite value as \(t\to\infty\). The final velocity of the wall can be smaller or larger than the speed of light. In the former case, depicted in figure 2a, one can define an S-matrix for \(n\) incoming tachyons to go to \(n^{\prime}\) tachyons. We used a Wick rotation from Euclidean spacetime to study some particular processes: \(n\to 1\) scattering (3.8), and production of \(n\) outgoing tachyons (3.18) in the time-dependent background.

When the final velocity of the Liouville wall is larger than the speed of light, asymptotic future null infinity is shielded by the Liouville wall, and the outgoing massless tachyons can no longer be defined. Nevertheless, we found that one seems to be able to define asymptotic observables, (3.17) with \(v_{j}<v_{\rm max}\), the latter given by (3.23). One can think of these observables as associated with outgoing tachyons produced in the time-dependent background. The bound on the null coordinate \(v=t+\phi\) is related to the fact that these tachyons are produced at the Liouville wall, which in this case has a maximal value of \(v\), see figure 2b.

In section 4 we discussed a generalization of the above system, in which the velocity of the Liouville wall approaches (equal and opposite) finite values at early and late times (see figure 5). When these velocities are smaller than the speed of light, we found a similar structure to that of section 3. One can again define an \(n\to n^{\prime}\) S-matrix for tachyon scattering, and compute it using matrix model and worldsheet techniques. We demonstrated this by computing the amplitude for creation of \(n\) tachyons, given in eq. (4.11). These amplitudes are qualitatively similar to those encountered in section 3, (3.18), and become even more so after a rescaling of \(\mu\) given in (4.14).

A new feature of these amplitudes is a divergence at a finite value of the coupling (4.15), that determines the local acceleration of the Liouville wall. In the closely related Euclidean problem, the corresponding divergence signals the decoupling of the Euclidean time \(X\) from the worldsheet dynamics - a kind of dynamical dimensional reduction. We proposed that similarly, the divergence of (4.11) may be due to a decoupling of time, though a more complete understanding is required.

In section 5 we discussed the time-dependent backgrounds described above from the point of view of the dual matrix quantum mechanics. In the double scaling limit this theory reduces to a theory of free fermions, and different backgrounds correspond to different choices of the shape of the Fermi surface. Tachyon perturbations in the bulk \(1+1\) dimensional string theory are described in this language by ripples on the Fermi surface.

We presented the Fermi surfaces corresponding to the backgrounds of sections 3, 4, and studied the dynamics of ripples on these surfaces as a function of the parameters. We found a nice agreement between the picture based on scattering amplitudes in sections 3, 4, and the free fermion description.

In the region of parameter space where the Liouville wall follows a timelike trajectory, we found that ripples on the Fermi surface propagate from the upper branch in figure 9a at early times to the lower branch at late times, thus giving an analog of the \(1\to 1\) S-matrix of section 3. We showed that their trajectories can be viewed as due to reflection from a time-dependent wall, that coincides with the Liouville wall discussed in section 1. We also showed that the Fermi surface picture only exists below some critical value of the coupling (4.15), which agrees precisely with that found in section 4.

In the region where the Liouville wall turns spacelike at early and/or late times, we showed that the trajectories of ripples on the Fermi surface make it to the corresponding asymptotic infinity only for some values of the parameters describing the ripple. We found that the bounds on these parameters are the same as those found from a seemingly very different point of view, by studying the amplitudes in sections 3, 4.

In summary, we found a nice agreement between three, seemingly quite different, points of view on tachyon dynamics in the time-dependent backgrounds we studied: (1) scattering from the time-dependent Liouville wall (1.14), (4.5); (2) amplitudes obtained by Wick rotation from the Euclidean correlation functions; (3) the dynamics of ripples on the time-dependent Fermi surfaces of section 5.

Much remains to be done. We next list some issues that require further attention.

### Observables for \(p>1\)

One of the surprising results of our analysis was that in backgrounds where a priori there should not be asymptotic observables associated with past and/or future asymptotic infinity, we nevertheless found such observables. Moreover, we found them from two different points of view: the study of scattering amplitudes in sections 3, 4, and the study of ripples on a time-dependent Fermi surface in section 5.

As an example, in the analysis of section 3.3, we found that one can define observables, (3.17), which depend on lightlike position variables \(v_{j}\), that are bounded from above by \(v_{\rm max}\), (3.23). One can think of these observables as describing the emission of tachyons from the time-dependent Liouville wall, and of \(v_{\rm max}\) as the largest value of \(v=t+\phi\) along the wall (figure 2b). In the analysis of section 5, these observables correspond to ripples (5.6), with \(\rho<\rho_{c}\) (5.10), which start at early times on the upper branch of the hyperbola of figure 7b and make it at late times to the lower branch, along which they propagate to asymptotic infinity.

The existence of these observables is at first sight puzzling. As mentioned above, in terms of figure 2b they appear to correspond to outgoing tachyons, \({\cal T}_{\omega}^{-}\), emitted by the accelerating Liouville wall. However, regardless of the value of \(v\) at which they were emitted, eventually the Liouville wall catches up with them, and they are absorbed by it. In terms of the picture of section 5, they correspond to ripples propagating to the left on the lower branch of the hyperbolas in figure 7b. In that picture, the Liouville wall corresponds to the intersection of the hyperbolas with the \(\lambda\) axis, which asymptotically, at late times, moves faster than light, and thus eventually these ripples find themselves behind the wall.

This raises the question how we can define the \({\cal T}^{-}\) observables, when they do not make it to the future region well outside the Liouville wall. We will leave a detailed analysis of this issue to future work, but a possible resolution of this tension is the following. It seems clear that the operators \({\cal T}_{\omega}^{-}\) defined in (1.7) _with real \(\omega\)_ do not make sense when future null infinity is behind the Liouville wall. However, it is possible that these observables can be defined when \(\omega\) has a finite imaginary part. This imaginary part must be taken to be positive, since otherwise the corresponding operators (1.7) are normalizable, which would imply the existence of normalizable states, that are in general not there.

If we write \(\omega=w_{r}+i\omega_{i}\), with \(\omega_{i}>0\), the resulting operators \({\cal T}^{-}_{\omega}\), behave at late times like \(\exp(-\omega_{i}t)\), _i.e._ they go exponentially to zero at late times, which is consistent with the picture suggested by figure 2b, that they correspond to tachyons that penetrate the Liouville wall at late times. It also resolves the puzzle regarding the definition of these observables, since they are now defined at the boundary of the spacetime, \(\phi\rightarrow-\infty\), which remains outside the Liouville wall for all \(t\).

The proposal that the late time observables decay exponentially as \(t\rightarrow\infty\) suggests that the system with an asymptotically spacelike Liouville wall has a unique final state. This is reminiscent of the proposal by [51] of a unique final state associated with the black hole singularity, and of the Hartle-Hawking proposal for a unique wavefunction of the universe, which is associated to the Big Bang singluarity [52].

This proposal is also reminiscent of [53], who studied string dynamics in backgrounds with cosmological singularities. These backgrounds contain big bang and big crunch singularities, and thus one cannot define standard string theory S-matrix observables. At the same time, they are described by solvable worldsheet theories, which contain physical observables that can be studied using standard worldsheet techniques.

The authors of [53] showed that the resolution of this tension is that the cosmological spacetimes they studied contain additional regions, referred to as "whiskers", and the natural string observables are non-normalizable vertex operators defined at the boundaries of these regions, where they approach linear dilaton spacetimes.

The setup of [53] is similar to the one depicted in our figure 5 with \(p>1\). Like there, the Liouville wall of figure 5 shields the past and future null infinities, and thus provides soft versions of big bang and big crunch singularities. Therefore, one cannot define a standard S-matrix but, according to our proposal above, one can define non-normalizable observables at the timelike boundary \(\phi\rightarrow-\infty\), which is the analog of the boundary of one of the whiskers for this case.

One advantage of the systems described in this paper over those in [53] is that in the ones here one can study the behavior both when there is no spacelike singularity (\(p<1\)) and when there is one (\(p>1\)). In contrast, in the system of [53], a past and future spacelike singularity is always present.

If the proposal for the observables we made before for \(p>1\) is correct, one needs to understand its implications for the Fermi surface picture of section 5. In particular, one needs to understand how to see the fact that the observables correspond to non-normalizable operators that decay exponentially at early and/or late time. It may be that to do that one will have to generalize the description of ripples on the Fermi surface as points that follow the trajectories (5.6) to a study of the dynamics of finite size ripples. We will leave all these issues to future work.

Another puzzle that may require going beyond the description of tachyons in \(1+1\) dimensional string theory as pointlike ripples on the Fermi surface is the following. In section 4 we showed that when the coupling (4.15) increases, we encounter a singularity of the amplitudes (4.11), (4.13) at a finite value of the coupling. In section 5 we argued that in the fermion language this corresponds to the fact that the time-dependent Fermi surface (5.13), (5.14) only exists in some region in parameter space, and showed that this region is the same as that in section 4. However, if one looks at the critical Fermi surface, by plugging \(s=1/(p-1)\) in (5.16), one finds a smooth Fermi surface, that does not show any signs of the divergences encountered in section 4. It is possible that to understand these divergence in the language of section 5, one needs to study the dynamics of finite size ripples. Another possibility, suggested by the form of the divergences in eq. (4.11), is that they are a feature of the vacuum, and are insensitive to the perturbations. This too will be left to future work.

### Properties of scattering amplitudes

The string scattering amplitudes computed in this work relied on a worldsheet analysis of the background (1.11). Indeed, the MQM was used only as a computational tool to evaluate string scattering amplitudes in the undeformed \(1+1\) dimensional string theory. In section 5, we reviewed the Fermi surface picture that is dual to the time-dependent background (1.11), but used it only to study properties of the time-dependent Liouville wall, and the trajectories of pointlike ripples. It would be interesting to use this free fermion description to compute the scattering amplitudes (3.6), (3.18) for \(p<1\). This would be a non-trivial check of the procedure to compute the scattering amplitudes followed in this work, as well as of the proposed Fermi surface dual to the time-dependent background. We leave this question to future work.

In the region of parameter space for which \(p<1\), the scattering amplitudes should satisfy constraints coming from unitarity and causality. In time-dependent backgrounds, these constraints are not straightforwardly implemented, and it would be interesting to explore how the scattering amplitudes (3.6), (3.18) satisfy them.

### The limit \(p\to 2\)

A time-dependent background similar to the one considered in this work was recently discussed in [42, 43] (see also [44]). The background in these works is similar to the limit \(p\to 2\) of our (1.11), with \(\lambda_{+}=0\), \(\lambda_{-}\neq 0\). We focused (in section 3) on the opposite case, \(\lambda_{-}=0\), \(\lambda_{+}\neq 0\); the two are related by time-reversal symmetry. Interestingly, the results for the correlators in [42, 43, 44] were different from ours. As an example, we found that the \(n\)-point functions (1.16) vanish, while their analogs in the above papers did not.

An important difference between the two constructions is that in [42, 43], in our notation, \(\lambda_{+}=0\) and \(\lambda_{-}=-\mu<0\), see [44]. After applying time-reversal, this is related to our system with \(\lambda_{+}=-\mu\), \(\lambda_{-}=0\). We, on the other hand, took \(\lambda_{+}\) to be positive. It is possible that this difference is responsible for the above difference in the correlation functions. Note that flipping the sign of \(\lambda_{+}\) in our construction has an important effect. For positive \(\lambda_{+}\) (our analysis), the potential \(V_{\rm st}\), (1.14), goes to infinity everywhere in the shaded region in figure 2. For negative \(\lambda_{+}\), there is a region along the positive \(v\) axis, where the potential remains small. Thus, incoming \(\mathcal{T}^{+}\) waves can penetrate the potential in this direction, and it is possible that these are the processes captured by the correlation functions of [42, 43, 44].

Note also that in the limit \(p\to 2\), the worldsheet theory (1.6), (1.11), with \(\lambda_{+}\lambda_{-}=0\) factorizes into a direct product of a theory for \(\phi\) and one for \(t\). The \(\phi\) theory is a Liouville theory with \(c=25\), while that of \(t\) is timelike Liouville with \(c=1\). This factorization played an important role in the analysis of [42, 43, 44]. For \(p<2\), the subject of our paper, this factorization breaks down, and one cannot use the techniques of [42, 43, 44] to analyze the resulting background. This is one of the reasons we used matrix model results to analyze the dynamics.

We also note that if \(\lambda_{\pm}\) are both non-zero, it looks superficially from (1.6), (1.11) that for \(p=2\) the worldsheet theory still factorizes into a product of theories for \(\phi\) and \(t\), but in fact this is not the case. The reason is that the would be theory for \(t\) is a Wick rotated version of the Sine-Gordon model, and the coupling \(\lambda_{+}\lambda_{-}\) is in this case marginal but not truly marginal. Thus, the \(t\) theory exhibits an RG flow, and after coupling to \(\phi\) this RG happens as a function of \(\phi\), [31].

### Closed string radiation

The time-dependent background considered in this work is reminiscent of the rolling tachyon solution [45], which is an open-string analogue of our time-dependent background for \(p=2\). However, while in our case the fate of the background is not known, in the rolling tachyon case the brane decays by emitting closed strings. In particular, it was shown in [54] that the closed string radiation produced by the rolling tachyon is given by a coherent state of the form

\[e^{ca^{\dagger}}|0\rangle\, \tag{6.1}\]

where \(a^{\dagger}\) is the creation operator for a closed string, and \(\alpha\) is proportional to the disk 1-point function for the closed string vertex operator, with rolling tachyon boundary condition. The closed string radiation state produced by the time-dependent background in our case is similar, except now \(\alpha\) is computed from the sphere 1-point function (3.11) (for \(p<1\)), and in particular is of order \(1/g_{s}\).

From (6.1), we can follow [54] and compute the total number \(N\) and energy \(E\) of closed strings produced by the time-dependent background. We find

\[\begin{split}& N=\int_{0}^{\infty}d\omega\ \omega\left|\left\langle{\cal T}_{\omega^{\prime}}^{-}\right\rangle_{\lambda_{+ }}\right|^{2}\,\\ & E=\int_{0}^{\infty}d\omega\ \omega^{2}\left|\left\langle{\cal T }_{\omega^{\prime}}^{-}\right\rangle_{\lambda_{+}}\right|^{2}\,\end{split} \tag{6.2}\]

where the polynomial factors of \(\omega\) relative to [54] come from the normalization of the tachyon operator, (1.7). Using the expression (3.11) in (6.2), we find that the integral converges14 at large \(\omega\) for \(p<1\). Note however that \(N,\ E\) are of order \(1/g_{s}^{2}\), since \(\left\langle{\cal T}_{\omega^{\prime}}^{-}\right\rangle_{\lambda_{+}}\sim 1/g_{s}\). This means that the total number and energy of closed strings produced by the time-dependent background is of the same order as those of the original background, so backreaction should be taken into account. We leave a more detailed understanding of this backreaction to future work.

Footnote 14: The expressions (6.2) have IR divergences from the small \(\omega\) region. These can be dealt with by introducing an IR cutoff.

### Moving mirror

Our description of the dynamics in terms of scattering of tachyons off a time-dependent Liouville wall is reminiscent of the moving mirror problem in QFT [55]. That model is often used as a toy model of black hole physics. In that application, the mirror is taken to be receding from the observer, and approaching the speed of light at late times [56, 57, 58, 59]. More generally, the mirror can be taken to move away or towards the observer, and have a final speed different from that of light; see _e.g._[60] for a recent discussion.

In our model, the Liouville wall is qualitatively similar to a moving mirror. The analogy is not precise, since in the case of the moving mirror one typically takes the quantum fields to vanish at the mirror, whereas the Liouville wall is soft, as mentioned earlier in the paper. Another difference between the two problems is that since the Liouville wall is not a physical object, it can move faster than light, something that is not possible for a physical mirror.

Nevertheless, it would be interesting to study the relation between our results and the moving mirror problem, for example by comparing the particle production and scattering amplitudes we get to those obtained by studying a moving mirror that follows a similar trajectory. This too will be left for future work.

## Acknowledgements

We thank Ahmed Almheiri, Amit Giveon, Finn Larsen, Massimo Porrati, Victor A. Rodriguez, Zixia Wei, and Xi Yin for discussions. This work was supported in part by DOE grant DE-SC0009924 and BSF grant 2018068. The work of BB was also supported by NSF grants PHY-2210349, PHY-2210420, and PHY-2112839.

## Appendix A Matrix model dual of \(1+1\) dimensional string theory

To calculate the correlation functions (1.3), we use the matrix quantum mechanics dual to \(1+1\) dimensional string theory, following the approach of [29, 47]. In this appendix, we briefly review this approach.

The Hamiltonian of the matrix quantum mechanics is

\[H=\frac{1}{2}{\rm Tr}\left(P^{2}-X^{2}\right)\,\] (A.1)

where \(X\) is an \(N\)-by-\(N\) Hermitian matrix and \(P\) its canonically conjugate momentum. Closed string excitations are dual to states in the singlet sector of the matrix quantum mechanics. To study that sector, it is convenient to diagonalize \(X\) by writing \(X=U^{-1}\Lambda U\), where \(U\in U(N)\), and \(\Lambda={\rm diag}(\lambda_{1},\cdots,\lambda_{N})\). The singlet sector wavefunction \(\Psi\) depends only on the eigenvalues \(\lambda_{i}\), and is completely symmetric under exchange of any pair of eigenvalues,

\[\Psi(\cdots,\lambda_{i},\cdots,\lambda_{j}\cdots)=\Psi(\cdots,\lambda_{j}, \cdots,\lambda_{i}\cdots)\.\] (A.2)

It is useful to make a similarity transformation, \(H=\Delta\widetilde{H}\Delta^{-1}\), where \(\Delta=\prod_{i<j}^{N}(\lambda_{i}-\lambda_{j})\) is the Vandermonde determinant, and

\[\widetilde{H}=\frac{1}{2}\sum_{i=1}^{N}\left(-\partial_{\lambda_{i}}^{2}- \lambda_{i}^{2}\right)\.\] (A.3)

The Hamiltonian \(\widetilde{H}\) acts on the wavefunction \(\widetilde{\Psi}(\lambda_{i})=\Delta\Psi(\lambda_{i})\). The wavefunction \(\widetilde{\Psi}(\lambda_{i})\) is antisymmetric under exchanging any pair of eigenvalues. Thus, the Hamiltonian \(\widetilde{H}\) describes a system of \(N\) non-relativistic, non-interacting fermions, moving in the potential \(V(\lambda)=-\frac{\lambda^{2}}{2}\).

The potential \(V(\lambda)\) is unbounded from below. To arrive at the theory that is dual to two-dimensional string theory, we consider the following _double-scaling limit_. We study the system at fixed Fermi energy \(E=-\mu<0\), and send \(N\rightarrow\infty\). Thus, the fermions fill all states with energy less than \(E=-\mu\); see figure 10. This is the state that is dual to the closed string vacuum.

The vertex operators (1.2) correspond to infinitesimal perturbations of the closed string vacuum. It is sufficient to consider perturbations of the Fermi surface on one side of the potential in the figure, say the one with \(\lambda<0\). As is clear from figure 10, effects that mix the two sides are non-perturbative in \(1/\mu\). They correspond to non-perturbative effects in string theory; see _e.g._[15, 16, 17, 20, 21, 23, 27] for recent discussions.

In a semiclassical description, the fermions fill a Fermi sea up to the surface \(\lambda=\sqrt{p_{\lambda}^{2}+2\mu}\), where \(p_{\lambda}\) denotes the momentum conjugate to \(\lambda\) (see figure 11). The string coupling \(g_{s}\) is given by \(2\pi g_{s}\equiv\mu^{-1}\), while closed string excitations are dual to perturbations of the Fermi surface; see [3, 4, 50] for details.

The Fermi surface can be written in terms of the fermion density, which is a fermion bilinear. Using this, correlation functions of tachyon operators (1.2) can be calculated using the dual matrix quantum mechanics description. This formalism allows one to express the

Figure 11: The Fermi sea (shaded region) corresponding to the standard background of \(1+1\) dimensional string theory described in section 2.

Figure 10: Semiclassical description of the closed string vacuum in the dual \(c=1\) matrix quantum mechanics.

[MISSING_PAGE_FAIL:48]

which is equivalent to \(Q+q(F_{2j-1})<0\). So, from the definition (A.4),

\[\eqalign{R_{Q+q(F_{2j-1})}=&\mu^{Q+q(F_{2j-1})}\sqrt{2\over\pi}e^{i\pi/4}\cos \left({\pi\over 2}({1\over 2}+i\mu+Q+q(F_{2j-1}))\right)\cr&\Gamma\left({1\over 2}-i \mu-Q-q(F_{2j-1})\right)\.}\]

On the other hand, in (A.9) \(T_{-}\subseteq F_{2j+1}-F_{2j}\), which means that \(q(T_{-})<0\). Therefore, \(Q+q(F_{2j})>0\) and

\[\eqalign{R^{*}_{Q+q(F_{2j})}=&\mu^{-Q-q(F_{2j})}\sqrt{2\over\pi}e^{-i\pi/4} \cos\left({\pi\over 2}({1\over 2}-i\mu-Q-q(F_{2j}))\right)\cr&\Gamma\left({1 \over 2}+i\mu+Q+q(F_{2j})\right)\.}\]

Combining the two reflection amplitudes, we find the interesting property that

\[\mu^{\sum_{j=1}^{n}q_{j}}\prod_{j=1}^{k}R_{Q+q(F_{2j+1})}R^{*}_{Q+q(F_{2j+2})}\]

depends on \(\mu\) and \(Q\) only through the combination \(i\mu+Q\).

The matrix model S-matrix \({\cal R}(q_{j},-q^{\prime}_{l})\) is dual to string theory scattering amplitude of closed strings. The relation between them is given by

\[\Big{\langle}\prod_{j=1}^{n}T_{q_{j}}\prod_{l=1}^{n^{\prime}}T_{-q^{\prime}_{l }}\Big{\rangle}={\mu^{\sum_{j=1}^{n}q_{j}}{\cal R}(q_{j},-q^{\prime}_{l})\over \prod_{j=1}^{n}q_{j}\prod_{l=1}^{n^{\prime}}q^{\prime}_{l}}\.\]

In practice, it is easier to calculate scattering amplitudes with an insertion of the cosmological constant operator \(T_{0}\). As discussed below (1.3), the insertion of \(T_{0}\) is equivalent to acting with \(-\partial_{\mu}\) on the correlation function with \(T_{0}\) stripped off. Thus, we have

\[\eqalign{\Big{\langle}T_{0}\prod_{j=1}^{n}T_{q_{j}}\prod_{l=1}^{n^{\prime}}T_{ -q^{\prime}_{l}}\Big{\rangle}&=\lim_{\epsilon\to 0^{+}}\Big{\langle}T_{n \epsilon}\prod_{j=1}^{n}T_{q_{j}-\epsilon}\prod_{l=1}^{n^{\prime}}T_{-q^{ \prime}_{l}}\Big{\rangle}\cr&=-\lim_{\epsilon\to 0^{+}}\partial_{\mu}\Big{\langle}\prod_{j=1}^{n}T_{q_ {j}-\epsilon}\prod_{l=1}^{n^{\prime}}T_{-q^{\prime}_{l}}\Big{\rangle}\cr&=- \lim_{\epsilon\to 0^{+}}{1\over\prod_{j=1}^{n}q_{j}\prod_{l=1}^{n^{\prime}}q^{ \prime}_{l}}{\partial\over\partial\mu}\left(\mu^{\sum_{j=1}^{n}q_{j}}{\cal R}( q_{j}-\epsilon,-q^{\prime}_{l})\right)\.}\]

Then, since from (A.5) and (A.13) \({\cal R}(q_{j},-q^{\prime}_{l})\) depends on \(\mu\) and \(Q\) only through the combination \(i\mu+Q\), it follows that we can convert the \(\mu\)-derivative into a \(Q\)-derivative. Moreexplicitly,

\[\frac{\partial}{\partial\mu}\left(\mu^{\sum_{j=1}^{n}q_{j}}\mathcal{ R}(q_{j}-\epsilon,-q_{l}^{\prime})\right)=\delta\left(\sum_{j}^{n}(q_{j}-\epsilon)- \sum_{l}^{n^{\prime}}q_{l}^{\prime}\right)i^{n+n^{\prime}+1}\mu^{\sum_{j=1}^{n }q_{j}}\] (A.16) \[\qquad\sum_{k=1}^{\min\{n,n^{\prime}\}}\frac{1}{k}\sum_{\mathrm{AF }_{k}}\int dQ\Bigg{\{}\partial_{Q}\bigg{[}\prod_{j=2}^{k+1}\sum_{T_{+}\subseteq F _{2j}-F_{2j-1}}(-1)^{|T_{+}|}\theta\Big{(}q(T_{+})-\big{(}Q+q(F_{2j})\big{)} \Big{)}\] \[\prod_{j=1}^{k}\sum_{T_{-}\subseteq F_{2j+1}-F_{2j}}(-1)^{|T_{-}| }\theta\Big{(}Q+q(F_{2j})+q(T_{-})\Big{)}\bigg{]}\prod_{j=1}^{k}R_{Q+q(F_{2j+ 1})}R_{Q+q(F_{2j+2})}^{*}\Bigg{\}}\,\]

where we have integrated by parts in \(Q\). The derivative of the theta functions are just delta functions, which after the integration give a finite sum.

Finally, note that in the compact case \(X\sim X+2\pi R\), the Dirac delta function for momentum conservation should be replaced by a Kronecker delta times \(2\pi R\).

## Appendix B Closed string amplitudes

In this appendix, we outline the calculations of the closed string amplitudes, \(\langle T_{0}T_{p}^{m}\prod_{j=1}^{n}T_{-q_{j}}\rangle\) using the matrix model techniques discussed in appendix A.

### One outgoing particle

For \(q=mp\) (\(m\in Z^{+}\)), (A.15) and (A.16) lead to

\[\begin{split}\langle T_{0}T_{p}^{m}T_{-q}\rangle&= \lim_{\epsilon\to 0^{+}}\langle T_{t}T_{p-\epsilon}^{m}T_{-q}\rangle\\ &=\lim_{\epsilon\to 0^{+}}2\pi R\frac{i^{m}}{p^{m}q}\mu^{mp} \int dQ\Bigg{\{}\partial_{Q}\bigg{[}\sum_{T_{+}\subseteq F_{4}-F_{3}}(-1)^{| T_{+}|}\theta\Big{(}q(T_{+})-\big{(}Q+q(F_{4})\big{)}\Big{)}\] (B.1)

where

\[F_{3}-F_{2}=\{-q\}\,\] (B.2)

and

\[F_{4}-F_{3}=\{\underbrace{p-\epsilon,\cdots,p-\epsilon}_{m}\}\.\] (B.3)Performing the integration over \(Q\) we find,

\[\begin{split}&\langle T_{0}T_{p}^{m}T_{-q}\rangle=\lim_{\epsilon \to 0^{+}}2\pi R\frac{i^{m}}{p^{m}q}\mu^{mp}\\ &\Bigg{[}-\sum_{T_{+}\subseteq F_{4}-F_{3}}(-1)^{|T_{+}|}R_{q(T_ {+})-mp}R_{q(T_{+})}^{*}\sum_{T_{-}\subseteq F_{3}-F_{2}}(-1)^{|T_{-}|}\theta \Big{(}q(T_{+})+q(T_{-})\Big{)}\\ &+\sum_{T_{-}\subseteq F_{3}-F_{2}}(-1)^{|T_{-}|}R_{-q(T_{-})-mp }R_{-q(T_{-})}^{*}\sum_{T_{+}\subseteq F_{4}-F_{3}}(-1)^{|T_{+}|}\theta\Big{(} q(T_{+})+q(T_{-})\Big{)}\Bigg{]}\.\end{split}\] (B.4)

The first term in the square bracket can be simplified to

\[-\sum_{b=0}^{m}(-1)^{b}\binom{m}{b}R_{(b-m)p}R_{bp}^{*}\.\] (B.5)

The second term in the square bracket vanishes. To see this, consider the two possible choices for \(T_{-}\). If \(T_{-}=\varnothing\),

\[\sum_{T_{+}\subseteq F_{4}-F_{3}}(-1)^{|T_{+}|}\theta\Big{(}q(T_{+})+q(T_{-} )\Big{)}=\sum_{T_{+}\subseteq F_{4}-F_{3}}(-1)^{|T_{+}|}\theta\Big{(}q(T_{+} )\Big{)}=\sum_{b=0}^{m}(-1)^{b}\binom{n}{b}=0\.\] (B.6)

On the other hand, if \(T_{-}=\{-q\}\), \(q(T_{+})+q(T_{-})=q(T_{+})-q\leq-m\epsilon<0\). So, the theta function gives zero. Therefore,

\[\langle T_{0}T_{p}^{m}T_{-q}\rangle=-2\pi R\frac{i^{m}}{p^{m}q}\mu^{mp}\sum_{b =0}^{m}(-1)^{b}\binom{m}{b}R_{(b-m)p}R_{bp}^{*}\.\] (B.7)

To leading order in the \(1/\mu\) expansion (_i.e._ to leading order in string perturbation theory), we find

\[\begin{split}\langle T_{0}T_{p}^{m}T_{-q}\rangle=&( -1)^{m+1}2\pi R\mu^{mp-m}\prod_{i=1}^{m-1}(q-i)=2\pi R\mu^{mp-m}\frac{\Gamma(m (1-p))}{\Gamma(1-mp)}\.\end{split}\] (B.8)

We have checked that (B.8) follows from (B.7) for \(1\leq m\leq 20\), and conjecture that the result holds for all integers \(m\). In this case, this conjecture is known to be correct, since the scattering amplitude in (B.7) is known exactly, see _e.g._[3, 40]. However, for us this is a warmup exercise towards other cases, where the answer is not known from other work.

Using (B.7) one can compute corrections to (B.8) in the \(1/\mu\) expansion. The leading correction is given by

\[\begin{split}\langle T_{0}T_{p}^{m}T_{-q}\rangle_{\text{torus}}=& -2\pi R\mu^{mp-m}\frac{\Gamma(m(1-p)+2)}{\Gamma(1-mp)}\frac{mp^{2}-mp-1}{24 \mu^{2}}\.\end{split}\] (B.9)

### Two outgoing particles

In this subsection, we calculate the correlation function \(\langle T_{0}T_{p}^{m}T_{-q_{1}}T_{-q_{2}}\rangle\), for \(q_{1}=m_{1}p>0\) and \(q_{2}=(m-m_{1})p>0\) with integers \(0<m_{1}<m\). First, from (A.15) and (A.16),

\[\begin{split}&\langle T_{0}T_{p}^{m}T_{-q_{1}}T_{-q_{2}}\rangle\\ =&\lim_{\epsilon\to 0^{+}}2\pi Ri^{m+1}\mu^{mp} \frac{1}{p^{m}q_{1}q_{2}}\sum_{k=1}^{2}\frac{1}{k}\sum_{\text{AF}_{k}}\int dQ \prod_{j=1}^{k}\Bigg{\{}R_{Q+q(F_{2j+1})}R_{Q+q(F_{2j+2})}^{*}\\ &\partial_{Q}\bigg{[}\prod_{j=2}^{k+1}\sum_{T_{+}\subseteq F_{2j} -F_{2j-1}}(-1)^{|T_{+}|}\theta\Big{(}q(T_{+})-\big{(}Q+q(F_{2j})\big{)}\Big{)} \\ &\prod_{j=1}^{k}\sum_{T_{-}\subseteq F_{2j+1}-F_{2j}}(-1)^{|T_{- }|}\theta\Big{(}Q+q(F_{2j})+q(T_{-})\Big{)}\bigg{]}\Bigg{\}}\.\end{split}\] (B.10)

When \(k=1\),

\[F_{3}-F_{2}=\{-q_{1},-q_{2}\}\,\] (B.11)

and

\[F_{4}-F_{3}=\{\underbrace{p-\epsilon,\cdots,p-\epsilon}_{m}\}\.\] (B.12)

Without loss of generality, we take \(m_{1}<m-m_{1}\). Then, the contribution of \(\text{AF}_{1}\) to the r.h.s. of (B.10) is

\[\begin{split}&\int dQ\Bigg{\{}-\sum_{b=0}^{m}(-1)^{b}\binom{m}{b} \delta\Big{(}bp-Q\Big{)}\sum_{T_{-}\subseteq\{-q_{1},-q_{2}\}}(-1)^{|T_{-}|} \theta\Big{(}Q+q(T_{-})\Big{)}R_{Q-mp}R_{Q}^{*}\\ &+\sum_{b=0}^{m}(-1)^{b}\binom{m}{b}\theta\Big{(}bp-Q\Big{)}\sum _{T_{-}\subseteq\{-q_{1},-q_{2}\}}(-1)^{|T_{-}|}\delta\Big{(}Q+q(T_{-})\Big{)} R_{Q-mp}R_{Q}^{*}\Bigg{\}}\\ =&-\sum_{b=0}^{m_{1}}(-1)^{b}\binom{m}{b}R_{(m-b)p}R_ {bp}^{*}+\sum_{b=m-m_{1}+1}^{m}(-1)^{b}\binom{m}{b}R_{(m-b)p}R_{bp}^{*}\\ &-(-1)^{m_{1}+1}\binom{m-1}{m_{1}}R_{q_{2}}R_{q_{1}}^{*}-(-1)^{m -m_{1}+1}\binom{m-1}{m-m_{1}}R_{q_{1}}R_{q_{2}}^{*}\.\end{split}\] (B.13)

When \(k=2\) on the r.h.s. of (B.10), \(F_{3}\) can be either \(\{-q_{1}\}\) or \(\{-q_{2}\}\). Due to the symmetry of exchanging \(F_{3}-F_{2}\leftrightarrow F_{5}-F_{4}\) and \(F_{4}-F_{3}\leftrightarrow F_{6}-F_{5}\) in (B.10), both the possibilities lead to the same contribution. So we only need to look at one of them, namely

\[F_{2j+1}-F_{2j}=\{-q_{j}\}\.\] (B.14)

Besides,

\[F_{2j}-F_{2j-1}=\{\underbrace{p-\epsilon,\cdots,p-\epsilon}_{n_{j}}\}\,\] (B.15)with any integers \(n_{1},n_{2}>0\) such that \(n_{1}+n_{2}=m\). Then, the contribution of AF\({}_{2}\) to the r.h.s. of (B.10) is given by

\[\begin{split}& 2\sum_{n_{1}=1}^{m-1}\frac{m!}{n_{1}!(m-n_{1})!} \Bigg{[}-(-1)^{n_{1}+m_{1}+1}\binom{m-n_{1}-1}{m_{1}}R_{0}R_{q_{2}-n_{1}p}R_{q_ {1}}^{*}R_{n_{1}p}^{*}\\ &-\sum_{b=0}^{\min\{m-m_{1},n_{1}-1\}}(-1)^{m_{1}-n_{1}+1}\binom{ n_{1}}{b}\binom{m-n_{1}-1}{m_{1}-n_{1}+b}R_{q_{2}-bp}R_{(n_{1}-b)p}R_{bp}^{*}R_{q_ {1}-(n_{1}-b)p}^{*}\\ &-\sum_{b=0}^{m_{1}}(-1)^{n_{1}-m_{1}}\binom{m-n_{1}}{b}\binom{n_ {1}-1}{b+n_{1}-m_{1}-1}R_{q_{1}-bp}R_{(m-n_{1}-b)p}R_{bp}^{*}R_{(b+n_{1})p-q_{ 1}}^{*}\Bigg{]}\.\end{split}\] (B.16)

Note that the overall factor of 2 comes from the same contribution for the case \(F_{3}=\{-q_{2}\}\), and it will cancel with the factor \(\frac{1}{k}\) in (B.10).

Extrapolating from the cases \(1\leq m\leq 12\), we conjecture the following general formula at leading order in \(1/\mu\):

\[\begin{split}\langle T_{0}T_{p}^{m}T_{-q_{1}}T_{-q_{2}}\rangle=& (-1)^{m}2\pi R\mu^{mp-m-1}\frac{m!}{m_{1}!(m-m_{1})!}\prod_{i_{1}=1}^{m_{1}}(q _{1}-i_{1})\prod_{i_{2}=1}^{m-m_{1}}(q_{2}-i_{2})\\ =& 2\pi R\mu^{mp-m-1}m!\frac{\Gamma\left((1-p)m_{1}+1 \right)}{\Gamma\left(m_{1}+1\right)\Gamma(1-pm_{1})}\frac{\Gamma\left((1-p)m_ {2}+1\right)}{\Gamma\left(m_{2}+1\right)\Gamma(1-pm_{2})}\.\end{split}\] (B.17)

The leading correction to B.17 is

\[\begin{split}\langle T_{0}T_{p}^{m}T_{-q_{1}}T_{-q_{2}}\rangle_ {\text{torus}}=&\langle T_{0}T_{p}^{m}T_{-q_{1}}T_{-q_{2}} \rangle_{\text{sphere}}\frac{mp-m-2}{24\mu^{2}}\left(m+1+(m^{2}-m_{1}m_{2})p \right.\\ &\left.+(-2m^{2}-m+2m_{1}m_{2})p^{2}+(m^{2}-m_{1}m_{2})p^{3} \right)\.\end{split}\] (B.18)

### Three and four outgoing particles

Let's now consider the amplitude for three outgoing particles, \(\langle T_{0}T_{p}^{m}\prod_{j=1}^{3}T_{-q_{j}}\rangle\). Using (A.15) and (A.16), let \(m_{j}=q_{j}/p\) be integers and \(m=m_{1}+m_{2}+m_{3}\). To leading order in \(1/\mu\) we find

\[\begin{split}\langle T_{0}T_{p}^{m}T_{-q_{1}}T_{-q_{2}}T_{-q_{3}} \rangle=&-(-1)^{m}2\pi R\mu^{mp-m-2}m!(mp-m-1)\prod_{j=1}^{3} \frac{\prod_{i=1}^{m_{j}}(q_{j}-i)}{m_{j}!}\\ =&-2\pi R\mu^{mp-m-2}m!(mp-m-1)\prod_{j=1}^{3}\frac {\Gamma\left((1-p)m_{j}+1\right)}{\Gamma\left(m_{j}+1\right)\Gamma(1-pm_{j})} \,\end{split}\] (B.19)

where we checked this result for \(1\leq m\leq 10\) and conjectured the general formula.

For four outgoing particles, \(\langle T_{0}T_{p}^{m}\prod_{j=1}^{4}T_{-q_{j}}\rangle\), we again start with \(q_{j}=m_{j}p\), \(m_{j}\in Z_{+}\), where \(m_{1}+m_{2}+m_{3}+m_{4}=m\). We find

\[\begin{split}&\langle T_{0}T_{p}^{m}T_{-q_{1}}T_{-q_{2}}T_{-q_{3}}T_{- q_{4}}\rangle\\ =&(-1)^{m}2\pi R\mu^{mp-m-3}m!(mp-m-1)(mp-m-2)\prod_ {j=1}^{4}\frac{\prod_{i=1}^{m_{j}}(m_{j}p-i)}{m_{j}!}\\ =& 2\pi R\mu^{mp-m-3}m!(mp-m-1)(mp-m-2)\prod_{j=1}^{4} \frac{\Gamma\left((1-p)m_{j}+1\right)}{\Gamma\left(m_{j}+1\right)\Gamma(1-pm_{j })}\,\end{split}\] (B.20)

where we checked the result for \(1\leq m=m_{1}+m_{2}+m_{3}+m_{4}\leq 10\).

### Any number of outgoing particles

Interestingly, from the results of \(\langle T_{0}T_{p}^{m}\prod_{j=1}^{n}T_{-q_{j}}\rangle\) with \(n=1,2,3,4\), we find that the correlation functions can be expressed in a universal way:

\[\langle T_{0}T_{p}^{m}\prod_{j=1}^{n}T_{-q_{j}}\rangle=(-1)^{n}2\pi R\partial _{\mu}^{n-2}\mu^{mp-m-1}m!\prod_{j=1}^{n}\frac{\Gamma\left((1-p)m_{j}+1\right) }{\Gamma\left(m_{j}+1\right)\Gamma(1-pm_{j})}\.\] (B.21)

Integrating w.r.t. \(\mu\) once, we can get rid of \(T_{0}\) by using \(T_{0}=-\partial_{\mu}\), to find

\[\langle T_{p}^{m}\prod_{j=1}^{n}T_{-q_{j}}\rangle=(-1)^{n-1}2\pi R\partial_{ \mu}^{n-3}\mu^{mp-m-1}m!\prod_{j=1}^{n}\frac{\Gamma\left((1-p)m_{j}+1\right)} {\Gamma\left(m_{j}+1\right)\Gamma(1-pm_{j})}\.\] (B.22)

We conjecture that this result holds for all \(n\).

## References

* [1] N. Seiberg, _Notes on quantum Liouville theory and quantum gravity_, _Prog. Theor. Phys. Suppl._**102** (1990) 319-349.
* [2] I. R. Klebanov, _String theory in two-dimensions_, in _Spring School on String Theory and Quantum Gravity (to be followed by Workshop)_, 7, 1991, hep-th/9108019.
* [3] P. H. Ginsparg and G. W. Moore, _Lectures on 2-D gravity and 2-D string theory_, in _Theoretical Advanced Study Institute (TASI 92): From Black Holes and Strings to Particles_, pp. 277-469, 10, 1993, hep-th/9304011.
* [4] A. Jevicki, _Development in 2-d string theory_, in _Workshop on String Theory, Gauge Theory and Quantum Gravity_, 9, 1993, hep-th/9309115, DOI.

* [5] Y. Nakayama, _Liouville field theory: A Decade after the revolution_, _Int. J. Mod. Phys. A_**19** (2004) 2771-2930, [hep-th/0402009].
* [6] E. J. Martinec, _Matrix models and 2D string theory_, in _NATO Advanced Study Institute: Marie Curie Training Course: Applications of Random Matrices in Physics_, pp. 403-457, 10, 2004, hep-th/0410136.
* [7] D. Anninos and B. Muhlmann, _Notes on matrix models (matrix musings)_, _J. Stat. Mech._**2008** (2020) 083109, [2004.01171].
* [8] J. M. Maldacena, _The Large N limit of superconformal field theories and supergravity_, _Adv. Theor. Math. Phys._**2** (1998) 231-252, [hep-th/9711200].
* [9] S. S. Gubser, I. R. Klebanov and A. M. Polyakov, _Gauge theory correlators from noncritical string theory_, _Phys. Lett. B_**428** (1998) 105-114, [hep-th/9802109].
* [10] E. Witten, _Anti-de Sitter space and holography_, _Adv. Theor. Math. Phys._**2** (1998) 253-291, [hep-th/9802150].
* [11] O. Aharony, S. S. Gubser, J. M. Maldacena, H. Ooguri and Y. Oz, _Large N field theories, string theory and gravity_, _Phys. Rept._**323** (2000) 183-386, [hep-th/9905111].
* [12] O. Aharony, M. Berkooz, D. Kutasov and N. Seiberg, _Linear dilatons, NS five-branes and holography_, _JHEP_**10** (1998) 004, [hep-th/9808149].
* [13] O. Aharony, _A Brief review of 'little string theories'_, _Class. Quant. Grav._**17** (2000) 929-938, [hep-th/9911147].
* [14] D. Kutasov, _Introduction to little string theory_, _ICTP Lect. Notes Ser._**7** (2002) 165-209.
* [15] B. Balthazar, V. A. Rodriguez and X. Yin, _ZZ instantons and the non-perturbative dual of c = 1 string theory_, _JHEP_**05** (2023) 048, [1907.07688].
* [16] B. Balthazar, V. A. Rodriguez and X. Yin, _Multi-instanton calculus in c = 1 string theory_, _JHEP_**05** (2023) 050, [1912.07170].
* [17] A. Sen, _Fixing an Ambiguity in Two Dimensional String Theory Using String Field Theory_, _JHEP_**03** (2020) 005, [1908.02782].
* [18] A. Sen, _Divergent complex amplitudes in two dimensional string theory_, _JHEP_**02** (2021) 086, [2003.12076].
* [19] A. Sen, _Cutkosky rules and unitarity (violation) in D-instanton amplitudes_, _JHEP_**07** (2021) 205, [2012.00041].
* [20] A. Sen, _D-instantons, string field theory and two dimensional string theory_, _JHEP_**11** (2021) 061, [2012.11624].
* [21] A. Sen, _Normalization of D-instanton amplitudes_, _JHEP_**11** (2021) 077, [2101.08566].

* [22] O. DeWolfe, R. Roiban, M. Spradlin, A. Volovich and J. Walcher, _On the S matrix of type 0 string theory_, _JHEP_**11** (2003) 012, [hep-th/0309148].
* [23] B. Balthazar, V. A. Rodriguez and X. Yin, _The S-matrix of 2D type 0B string theory. Part II. D-instanton effects_, _JHEP_**05** (2023) 235, [2204.01747].
* [24] J. Chakravarty and A. Sen, _Normalization of D instanton amplitudes in two dimensional type 0B string theory_, _JHEP_**02** (2023) 170, [2207.07138].
* [25] A. Sen, _Infrared finite semi-inclusive cross section in two dimensional type 0B string theory_, _JHEP_**04** (2023) 101, [2208.07385].
* [26] D. S. Eniceicu, R. Mahajan, P. Maity, C. Murdia and A. Sen, _The ZZ annulus one-point function in non-critical string theory: A string field theory analysis_, _JHEP_**12** (2022) 151, [2210.11473].
* [27] S. Alexandrov, R. Mahajan and A. Sen, _Instantons in sine-Liouville theory_, 2311.04969.
* [28] G. W. Moore and R. Plesser, _Classical scattering in (1+1)-dimensional string theory_, _Phys. Rev. D_**46** (1992) 1730-1736, [hep-th/9203060].
* [29] G. W. Moore, _Gravitational phase transitions and the Sine-Gordon model_, hep-th/9203061.
* [30] R. Dijkgraaf, G. W. Moore and R. Plesser, _The Partition function of 2-D string theory_, _Nucl. Phys. B_**394** (1993) 356-382, [hep-th/9208031].
* [31] E. Hsu and D. Kutasov, _The Gravitational Sine-Gordon model_, _Nucl. Phys. B_**396** (1993) 693-707, [hep-th/9212023].
* [32] V. Kazakov, I. K. Kostov and D. Kutasov, _A Matrix model for the two-dimensional black hole_, _Nucl. Phys. B_**622** (2002) 141-188, [hep-th/0101011].
* [33] S. Y. Alexandrov, V. A. Kazakov and I. K. Kostov, _Time dependent backgrounds of 2-D string theory_, _Nucl. Phys. B_**640** (2002) 119-144, [hep-th/0205079].
* [34] S. Y. Alexandrov and V. A. Kazakov, _Thermodynamics of 2-D string theory_, _JHEP_**01** (2003) 078, [hep-th/0210251].
* [35] S. Alexandrov, _Backgrounds of 2-D string theory from matrix model_, hep-th/0303190.
* [36] J. L. Karczmarek and A. Strominger, _Matrix cosmology_, _JHEP_**04** (2004) 055, [hep-th/0309138].
* [37] S. R. Das, J. L. Davis, F. Larsen and P. Mukhopadhyay, _Particle production in matrix cosmology_, _Phys. Rev. D_**70** (2004) 044017, [hep-th/0403275].
* [38] S. R. Das and J. L. Karczmarek, _Spacelike boundaries from the c=1 matrix model_, _Phys. Rev. D_**71** (2005) 086006, [hep-th/0412093].

* [39] S. R. Das and L. H. Santos, _Open string descriptions of space-like singularities in two dimensional string theory_, _Phys. Rev. D_**75** (2007) 126001, [hep-th/0702145].
* [40] D. Kutasov, _Some properties of (non)critical strings_, in _Spring School on String Theory and Quantum Gravity (to be followed by Workshop)_, 9, 1991, hep-th/9110041.
* [41] N. Seiberg and S. H. Shenker, _A Note on background (in)dependence_, _Phys. Rev. D_**45** (1992) 4581-4587, [hep-th/9201017].
* [42] V. A. Rodriguez, _A two-dimensional string cosmology_, _JHEP_**06** (2023) 161, [2302.06625].
* [43] V. A. Rodriguez, _The torus one-point diagram in two-dimensional string cosmology_, _JHEP_**07** (2023) 050, [2304.13043].
* [44] S. Collier, L. Eberhardt, B. Muhlmann and V. A. Rodriguez, _The Virasoro Minimal String_, 2309.10846.
* [45] A. Sen, _Tachyon dynamics in open string theory_, _Int. J. Mod. Phys. A_**20** (2005) 5513-5656, [hep-th/0410103].
* [46] W. G. Unruh, _Notes on black hole evaporation_, _Phys. Rev. D_**14** (1976) 870.
* [47] G. W. Moore, M. R. Plesser and S. Ramgoolam, _Exact S matrix for 2-D string theory_, _Nucl. Phys. B_**377** (1992) 143-190, [hep-th/9111035].
* [48] A. P. A. P. Prudnikov, I. A. I. A. Brychkov and O. I. O. I. Marichev, _Integrals and series / A.P. Prudnikov, Yu. A. Brychkov, O.I. Marichev ; translated from the Russian by N.M. Queen._ Gordon and Breach Science Publishers, New York, 1986.
* [49] J. Polchinski, _What is string theory?_, in _NATO Advanced Study Institute: Les Houches Summer School, Session 62: Fluctuating Geometries in Statistical Mechanics and Field Theory_, 11, 1994, hep-th/9411028.
* [50] J. Polchinski, _Classical limit of (1+1)-dimensional string theory_, _Nucl. Phys. B_**362** (1991) 125-140.
* [51] G. T. Horowitz and J. M. Maldacena, _The Black hole final state_, _JHEP_**02** (2004) 008, [hep-th/0310281].
* [52] J. B. Hartle and S. W. Hawking, _Wave Function of the Universe_, _Phys. Rev. D_**28** (1983) 2960-2975.
* [53] S. Elitzur, A. Giveon, D. Kutasov and E. Rabinovici, _From big bang to big crunch and beyond_, _JHEP_**06** (2002) 017, [hep-th/0204189].
* [54] N. D. Lambert, H. Liu and J. M. Maldacena, _Closed strings from decaying D-branes_, _JHEP_**03** (2007) 014, [hep-th/0303139].

* [55] N. D. Birrell and P. C. W. Davies, _Quantum Fields in Curved Space_. Cambridge Monographs on Mathematical Physics. Cambridge University Press, 1982, 10.1017/CBO9780511622632.
* [56] P. C. W. Davies and S. A. Fulling, _Radiation from Moving Mirrors and from Black Holes_, _Proc. Roy. Soc. Lond. A_**356** (1977) 237-257.
* [57] R. D. Carlitz and R. S. Willey, _REFLECTIONS ON MOVING MIRRORS_, _Phys. Rev. D_**36** (1987) 2327-2335.
* [58] A. Almheiri and J. Sully, _An Uneventful Horizon in Two Dimensions_, _JHEP_**02** (2014) 108, [1307.8149].
* [59] I. Akal, Y. Kusuki, N. Shiba, T. Takayanagi and Z. Wei, _Entanglement Entropy in a Holographic Moving Mirror and the Page Curve_, _Phys. Rev. Lett._**126** (2021) 061604, [2011.12005].
* [60] I. Akal, T. Kawamoto, S.-M. Ruan, T. Takayanagi and Z. Wei, _Zoo of holographic moving mirrors_, _JHEP_**08** (2022) 296, [2205.02663].

Title: A limit on the anisotropy of the one-way maximum attainable speed of the
  electron
Transcription: # A limit on the anisotropy of the one-way maximum attainable speed of the electron

W. Bergan

Cornell University, Ithaca, NY 14853

M.J. Forster

Cornell University, Ithaca, NY 14853

V. Khachatryan

Cornell University, Ithaca, NY 14853

N. Rider

Cornell University, Ithaca, NY 14853

D.L. Rubin

Cornell University, Ithaca, NY 14853

B. Vlahovic

North Carolina Central University, Durham, NC 27707

B. Wojtsekhowski

b.wojtsekhowski@iit.ac.uk College of William and Mary, Williamsburg, VA Thomas Jefferson National Accelerator Facility, Newport News, VA 23606

November 4, 2021

###### Abstract

We report here the first experimental result for the anisotropy of the one-way maximum attainable speed of the electron, \(\Delta c_{1,e}\), obtained via the study of a sidereal time dependence of a difference between the electron and positron beam momenta in the CESR storage ring at Cornell University. At 95 percent confidence, an upper limit for the component of \(\Delta c_{1,e}/c\) perpendicular to Earth's rotational axis is found to be \(5.5\times 10^{-15}\).

pacs: 98.80.-k _Introduction.\(-\)_ The Theory of Special Relativity (TSR) [1] was formulated from a few postulates whose experimental tests were important for the universal acceptance of this foundation of modern physics. The principle of relativity has been confirmed by perfect agreement between the TSR predictions and experiments. The universal value of the speed of light in inertial reference systems has been also tested experimentally. Since 1905 the precision of the tests has improved by many orders, and now such experiments represent an important approach to the search for physics which has some degree of Lorentz invariance violation (LIV). According to the original theory by A. Einstein, the speed of light in a vacuum is isotropic and the maximum attainable speed for all particles is equal to the speed of light. However, it is important to differentiate between the two-way speed (average over a closed path, \(c_{2}\)), whose isotropy for light was addressed for the first time in the Michelson-Morley experiment [2], and the one-way speed, \(c_{1}\), whose isotropy is a more general postulate.

A number of later formulations of TSR are based on the postulate of relativity and the isotropy of the two-way speed, see for review [3]. At the same time, high precision measurement of \(c_{1}\) isotropy is a well developed approach for tests of LIV in several frameworks including the Standard-Model Extension (SME) [4]. The maximum attainable speed of elementary particles could differ from the speed of light. The current limits on deviations of the maximum attainable speed of particles from the speed of light and related bounds on the anisotropies of the maximum attainable speed (AMAS) are discussed in Ref. [5].

The current upper bound for the photon AMAS, \(\Delta c_{2,photon}/c\) is \(10^{-18}\), see Ref. [6], which is already in the domain of Quantum Gravity (QG) effects [7]. The more challenging for experiment, the \(\Delta c_{1,photon}/c\) bound is \(\sim 1.6\times 10^{-14}\), according to Ref. [8]. A number of TSR predictions have also been tested with increasing accuracy, see Ref. [9]. For example, the test of the relativistic Doppler transformation performed with high speed atoms provided an LIV test on the level of \(10^{-9}\)[10].

_Momentum anisotropy.\(-\)_ In the TSR the momentum of the particle is a four-vector whose transformation between the inertial reference frames follows Lorentz's transformations. The space component of the momentum is \(\vec{p}=m\cdot\vec{v}/\sqrt{1-(v/c)^{2}}\), where \(m\) is the particle mass, \(\vec{v}\) is the particle velocity, \(v\) is the absolute value of \(\vec{v}\); and \(c\) is the speed of light. When taking into account the difference between the maximum attainable speed of the particle, \(c_{part}\) (with a possible directional anisotropy AMAS) and the speed of light, \(c\), we should avoid non-physical results for \(p\), and the expression above should be written as: \(\vec{p}=m\cdot\vec{v}/\sqrt{1-(v/c_{1,part})^{2}}\), where \(c_{1,part}\) is the maximum attainable speed of the particle in the direction of the particle velocity \(\vec{v}\).

The immediate prediction of the TSR is that in process which preserves the absolute value of particle speed, the absolute value of particle momentum is unchanged. By testing such a prediction for different orientations of the momentum one can obtain a bound on LIV. This method (momentum anisotropy) is especially sensitive for a particle with a large Lorentz factor, \(\gamma=1/\sqrt{1-(v/c_{1,part})^{2}}\), in the expression above for the momentum, because of a \(\gamma^{2}\) enhancement:

\[\Delta p/p\,\approx\,-\gamma^{2}(\Delta c_{1,part}/c), \tag{1}\]

where \(\Delta p\) is a variation of the momentum. Similar kinematical enhancement of the sensitivity to LIV for other high \(\gamma\) factor processes was obtained previously, see e.g. Refs. [11; 12; 13].

In the current report we present the first experiment carried out by using the momentum anisotropy method [14] and the obtained limit for the electron AMAS.

Independent of the high precision test of TSR, the search for sidereal time variation of the maximum attainable one-way speed of particles provides an interesting way to study the directional isotropy of the universe. Tests of directional isotropy have been conducted by high precision NMR since the 1960's [15]. For a review andperspectives on the current MR-based search methods, see Ref. [16].

A simple model for the \(c_{1}\) anisotropy is based on the concept of a local ether, as distinct from the global ether ruled out in the famous experiment [2]. This possible local ether moves relative to the solar system and has a tiny refractive index [17]. For example, this local ether may be related to the Cosmic Microwave Background radiation.

Magnetic deflection for the AMAS search.\(-\)We implemented the momentum anisotropy method for a search of the electron AMAS. The particle momentum was precisely measured via deflection in a transverse magnetic field. The magnetic field transverse to the direction of motion also allows us to change the direction of the particle's momentum and repeat the momentum measurement, for example, when the particle is moving in the reverse direction (where the impact of AMAS reaches its maximum). In other words, the \(180^{\circ}\) magnetic arc acts as a heavy mirror which reflects an electron (positron) elastically.

In the search for an LIV effect the conventional form of the Lorentz force needs to be corrected because its textbook form suppresses possible LIV contributions, for example the rotational non-invariant options. The nature and exact form of such a correction are unknown, so in the current analysis of kinematics of the particle motion in the transverse magnetic field we are using a minimum number of parameters and considerations. These are a vector of the particle speed \(\vec{v}\) and another vector of the magnetic field \(\vec{B}\), which is an axial vector.

The first assumption is a proportionality of the acceleration and the magnitude of each of these vectors - the absence of non-linear terms. We assume here the parity conserving nature of the acceleration of a charged particle moving in a transverse magnetic field, so the acceleration of the particle should be directed along the vector product \(\vec{v}\times\vec{B}\). For such a direction of the acceleration, the absolute value of the particle speed remains constant, which is an important consideration used later in the interpretation of the experimental observable: the limit on a variation of the difference between the particle speed and the maximum attainable speed in direction of the particle motion, \(v-c_{1,e}\). We searched for a variation of the particle momentum allowed according to the QG dispersion relations [7] and assumed energy conservation.

Experimental considerations.\(-\)Our experiment was performed with bunched beams of high energy electrons and positrons circulating in a storage ring. The precision of the experiment for \(\Delta c_{1,e}/c\) benefits from a large value of the beam Lorentz factor, \(\gamma\), and the high precision of the measurement of the beam centroid location in the transverse direction (especially at high beam current in a storage ring).

The stable geometry and magnetic field of the accelerator magnets are of paramount importance in our method. These requirements are significantly relaxed when the experiment uses two counter-propagating beams of a particle and an antiparticle in one set of magnets. The difference between the counter-rotating particle momenta is relatively insensitive to drifts in the storage ring magnetic fields and geometry, while the sensitivity to \(\Delta c_{1,e}/c\) is doubled, assuming that the anisotropy is the same for the electron and positron (validity of CPT for AMAS). The equality of the masses and opposite sign and equal value of the electrical charges for the electron and positron, which are also important for our analysis, are confirmed by the experiments [18] to a much higher precision than is essential to our experiment.

The beam momentum, \(p\), and accelerator lattice dispersion function, \(\eta(s)\), where \(s\) is a coordinate along the reference orbit of the beam, relate to the deviation of the horizontal beam position, \(x(s)\), and to the nominal beam positions in the accelerator at location \(s\) as: \(x(s)-x_{nom}(s)=\eta(s)\times(p-p_{nom})/p\), where \(x_{nom}(s)\) is the horizontal closed orbit at momentum \(p_{nom}\) and \((p-p_{nom})\) is a deviation of the momentum from its nominal value [19]. Variation in the measured position difference of the two beams at \(s\) thus corresponds to the measurement of variation in their momenta difference. By measurement of the beam position in an area free from accelerating elements, the beam momenta variations in different directions of motion can be found. The uncertainty in the absolute position of the beams is irrelevant as we are attempting to measure only the time dependence of the momenta at the frequency of a sidereal rotation. While the particle energy varies with the coordinate \(s\) due to synchrotron radiation energy loss and beam acceleration in the RF cavities, the energy at any \(s\) is stable and calculable with high precision.

The primary experimental observable is a momentum difference at time moment \(t\) between the two counter-rotating beams defined as \(\Delta p_{\pm}(s,t)=\left[x_{+}(t)\:-\:x_{-}(t)\right]/\eta(s)\), which allows us to search for a potential signal using the following equation (for the dipole form of AMAS):

\[\Delta p_{\pm}(s,t)\,=\,a_{\perp}\times[\,\cos(\Omega\cdot t- \Phi)*\cos(\Psi(s))+\] \[+\sin(\theta_{{}_{CESR}})*\sin(\Omega\cdot t-\Phi)*\sin(\Psi(s))], \tag{2}\]

where \(a_{\perp}=2\gamma^{2}\times\Delta c_{1,e}^{\perp}/c\) is a fit parameter, \(\gamma\) is the beam Lorentz factor, \(\Delta c_{1,e}^{\perp}/c\) is an AMAS value, \(\Omega\) is a sidereal frequency which is close to the Earth's rotational frequency, \(\Phi\) is the phase which is defined by the direction of anisotropy, \(\Psi(s)\) is the phase of the beam position monitor location at position \(s\) in the storage ring, and \(\theta_{{}_{CESR}}\) is the geographic latitude of the Cornell Electron Storage Ring.

The experiment.\(-\)Our experiment used beams of electrons and positrons with an energy of 5.29 GeV in the Cornell Electron Storage Ring (CESR) [20], Fig. 1.

The ring layout is mirror symmetric about its north-south diameter and has a 768 m circumference. Its lattice is of the focusing-defocusing (FODO) type, with each half cell consisting of a dipole, quadrupole, and sextupole magnet. The design of the magnetic lattice minimizes beta functions at the collision points, in order to mitigate current dependence of the beam-beam interaction on the closed orbits. The impact of the remaining beam-beam interaction was investigated in the collected orbit data and found to be much smaller than can be detected at the achieved accuracy of the Beam Position Monitor (BPM) and consistent with theoretical expectations. The dispersion function has a value of between one and two meters in most of the orbit. The RF accelerating cavities are located symmetrically near the south straight section.

The beams' electrostatic separation system and automatic beam orbit feedback system were turned off. The ring was filled with one electron bunch and one positron bunch with \(1.2\times 10^{10}\) particles in each bunch corresponding to 0.75 mA. The collision points were chosen to be at the location of the interaction point for the former CLEO detector and its diametric counterpart in the north straight section. The beam life time was an average of 5 hours. A typical data taking cycle/fill lasted about 1-2 hours, during which the beam currents dropped to a level of 0.5-0.6 mA.

The measurement of the beam positions was performed by means of the CESR BPM system, which includes 99 BPMs [21]. The CESR four-electrode BPM configuration shown in Fig. 2 allows determination of both the horizontal and vertical coordinates. The BPM signal is amplified and digitized at a sampling rate of 125 MHz. Each of the four electrodes has a programmable delay to ensure that the bunch signal is sampled at the peak. The delay step is 10 ps. Standard DAQ allows accumulation of data for many thousands of turns from each BPM for each beam (electron or positron). The sign of the bipolar pulse depends on the particle species. The signal is sampled at the peak of the leading pulse which is of the opposite sign for electrons and positrons [22].

Two groups of measurements were performed. In the first group (A), the data for the electron beam and the data for the positron beam were recorded at close but different moments in time. These moments are shifted by 20-30 seconds due to the time needed for loading different versions of the local readout code into the BPM electronics. We called the combined information from the time-consecutive position measurements for the two beams a data "shot". Measurements for both beams used the same set of electronics, which allowed us to reduce the impact of the electronic instability in the beam position difference. The raw data included the amplitudes from four electrodes from each of 99 BPMs and the combined (electron plus positron) beam current. Data for one shot were collected for each beam over 4000 turns in CESR, which in total covered about a 10 ms time period. Data analyzed in this paper were obtained during several multi-hour periods in December 2016 and October 2017. In total, in group A, 1714 data shots were taken using 35 fills of the ring.

In the second group (B), beam data were recorded at each BPM for each sequential bunch passage on each turn (the time difference between readouts is less than two microseconds) but with different electronics (amplifier and digitizer) for the two species. The electron beam data for 4000 turns and similar positron beam data constitute a pair of synchronized measurements (a shot). The interval between the sequential shots was about 200 seconds. Information for group B was collected in January 2018. In total, in group B, 228 data shots were taken over a 14-hour period using five fills of the ring.

Experiment sensitivity to the electron AMAS.\(-\)The experiment's sensitivity to the signal of interest is defined by the coordinate resolution of the BPMs, the lattice functions of the storage ring, statistics of measurements, duration of data taking and systematics due to remaining beam-beam interaction and electronics instabilities. The combined sensitivity of the data and effect of the analysis procedure on the detected parameters of the signal (\(a_{\perp}\) and \(\Phi\)) was investigated by adding to the actual BPM data a "test wave" which has the shape of a potential signal. After the adding of the test wave, a full analysis procedure was performed and the wave parameters were reconstructed. The sensitivity studies performed for the signal with an amplitude in the range down to

Figure 1: CESR ring geometry and features. RF indicates locations of the RF cavities. CLEO indicates the location used for the collider detector and CHESS stands for the Cornell High Energy Synchrotron Source.

Figure 2: CESR four-electrode BPM, see [23].

\(a_{\perp}=0.25\) ppm show that the reconstructed amplitude is reduced by a factor of 0.74, which is a typical effect for a multi-parameter fit analysis. The phase, \(\Phi\), which defines the preferable direction for AMAS for the lowest amplitude of the test wave was reconstructed with an accuracy of 0.5 radian.

The drift of the BPM electronics and magnets introduces systematical effects which can create artificial signals. In the analysis of the data, as presented below, we excluded some BPMs with exceedingly large noise or drift. In addition, for run group A, the instability of the horizontal steering magnets (kickers) introduced large orbit distortions. The effect of the kickers has been corrected by a fitting procedure. The data were analyzed with various groupings which allowed us to evaluate the systematics from the spread of the results and obtain a best estimate for an upper limit on the AMAS value.

Analysis of the data.-For analysis, the data from group A were arranged in five sets, each from six to eight hours long, and the data from group B were used in one set. Analysis was performed independently for each of these six sets.

The analysis procedure started from an evaluation of the noise in the raw amplitudes of the four-electrode BPMs. For this purpose we checked the correlation between the signal from an individual electrode of each BPM, \(A_{i}\), of a BPM and the beam current, \(I_{beam}\). The rms of the correlation \(\alpha=A_{i}/I_{beam}\) was analyzed. It was found that the relative value of the rms, \(\sigma_{\alpha}/\alpha\), averaged over all usable BPMs, was 0.002. When the \(\sigma_{\alpha}/\alpha\) exceeded a four times larger value (0.008), which corresponds to about a 200 \(\mu\)m position change or about a 100 ppm momentum change, the corresponding BPM was removed from further analysis. The applied cut eliminated on average a few BPMs of the 99 available in CESR.

For all accepted BPMs the beam horizontal position \(x_{+}\) for positrons (\(x_{-}\) for electrons) was calculated from the corresponding four amplitudes in the BPM electrodes by using an updated iterative procedure which starts from a linearized expression [23]. The value of \(x_{\pm}=x_{+}-x_{-}\) provides the beam position difference. It has contributions from i) the difference in the beam energies, which varies along the orbit but is time independent, ii) the offset, which is due to electronic calibration and for most BPMs is sufficiently stable over selected periods of several hours, iii) the small random differences in the magnetic system between the moments of measurements of the coordinates of the electron and positron beams (essential for group A), and iv) a potential AMAS signal, which has time dependence according to the sidereal period of the Earth's rotation and smooth variation along the beam orbit.

Within one data shot in the group A set, the time delay between the \(x_{+}\) and \(x_{-}\) measurements (20-30 seconds) sometimes leads to an orbit position change as large as 30 \(\mu\)m in some locations. The most common reason is magnets with a changed value of the field (kickers). They can be identified by analysis of the beam position as a function of \(s\). The parameters of the kicker were obtained from the fit of the data with the closed orbit function [19]:

\[f(s,j)=\theta_{j}\cdot\frac{\sqrt{\beta(s)\beta(s_{j})}}{2\sin(\pi Q_{x})} \cos[|\phi(s)-\phi(s_{j})|-\pi Q_{x}], \tag{3}\]

where \(f(s,j)\) is the closed orbit function for a kicker \(j\), \(\theta_{j}\) is the beam deflection angle of the beam by the kicker \(j\), \(\beta(s)\) and \(\beta(s_{j})\) are the ring lattice beta functions at location \(s\) and at the kicker location \(s_{j}\), \(Q_{x}\) is the horizontal betatron frequency equal to 10.55 for CESR, and \(\phi(s)\) and \(\phi(s_{j})\) are the lattice betatron phase advances at location \(s\) and at the location of the kicker \(s_{j}\). The change in beam momentum due to the application of a kick of the observed amplitude in a region of finite dispersion is negligibly small.

For determination of the kickers' locations and preliminary amplitudes in a given shot, we divided the data set into several 30-minute time intervals (short relative to the Earth's rotation period) during which the stability of all other contributions to \(\Delta x_{\pm}\) (except the kickers') is much higher than the kicker impact. In 30 minutes the data in the group A set had about fifty shots, \(N_{sh}\), which provide \(N_{{}_{BPM}}*N_{sh}\) coordinate values \(\Delta x_{\pm}\) for use in the fit. Here \(N_{{}_{BPM}}\) is the total number of used BPMs, which was 80 or more. The fit per Eq. 3 was used for determination of the parameters of the kickers and \(\Delta x_{\pm}^{ref}\) for all other contributions combined. The total number of fit parameters for eight kickers in each data shot and the off-sets for \(N_{{}_{BPM}}\) BPMs is at a maximum of \(8*N_{sh}*2+N_{{}_{BPM}}\), which is small compared to the number of fit points.

Figure 3 shows \(\Delta x_{\pm}\) vs. the BPM location along the orbit in the storage ring for a typical data shot, residual \(\delta x_{\pm}\), and the corresponding rms. The significant variations of the \(\Delta x_{\pm}\), shown in the upper panel of Fig. 3, are due to the kickers. The rms for \(\Delta x_{\pm}\) is about 12 \(\mu\)m. The fit of the closed orbit function (Eq. 3) with several kickers (the actual number of kickers was defined by the significance of the \(\chi^{2}\) improvement) allowed us to find the residual \(\delta x_{\pm}=\Delta x_{\pm}-\sum f(s,j)\), where \(\sum f(s,j)\) is the sum of the closed orbit functions for all observed kickers. The \(\delta x_{\pm}\) values have a typical rms of 3 \(\mu\)m as is shown for one data shot in the lower panel of Fig. 3.

After the kickers were identified, their number and locations in each shot were fixed, and the fit was redone with optimization of the amplitudes of the kickers for each shot, off-sets, \(\Delta x_{\pm}^{ref}\), for each BPM (fixed in each group of 30-minute time intervals), the AMAS amplitude and phase (fixed within a given several-hour measurement set).

For group B the analysis above was not needed because the synchronized readout of BPMs completely suppressed the kicker effect. At the same time group B required additional electronics channels which added noise. Overall the data from groups A and B have similar accuracies.

The second step of the analysis is the same for groups A and B and includes the following: The data were fitted by a two-parameter function of the signal and one parameter per BPM \(\Delta x_{\pm}^{ref}\) as:

\[\Delta x_{\pm}^{*}=\eta^{-1}(s)\times a_{\perp}\times\left[\cos( \Omega\cdot t-\Phi)*\cos(\Psi(s))\right.+\\ +\left.\sin(\theta_{{}_{CESR}})*\sin(\Omega\cdot t-\Phi)*\sin( \Psi(s))\right]\,+\,\Delta x_{\pm}^{ref}. \tag{4}\]

For all data sets in the analysis of the AMAS signal we calculated the realtime phase \(\Phi\) relative to midnight, October 22, 2017, at the geographic location of CESR.

In the fit of the AMAS signal we took into account that some of the BPMs have a significant drift. We determined the rate of BPM drifts by doing one-BPM fits per Eq. 4, for which the results are plotted in Fig. 4. For presentation of the search results below we used the \(a_{\perp,x}\) and \(a_{\perp,y}\) which are the components of a projection of the anisotropy vector \(\vec{a}\) to the plane of the CESR ring along the geographical meridian and orthogonal to it, respectively.

The mean values for the one-BPM analysis are \(a_{\perp,x}=0.72\) ppm and \(a_{\perp,y}=-0.40\) ppm with the rms of 7 ppm. It is easy to see that the tails in the distribution of the widths are dominated by the systematics. The systematic uncertainty is much larger than the statistical uncertainty for the individual data points. Data points (corresponding BPMs) with a extra large deviation (above 15 ppm) were excluded from the next step of the analysis. The accuracy of the average values (0.72/0.40 ppm) is close to expected for these 500 data points.

The final method for combining of the data is based on four groups of BPMs. In group #1 we used every fourth BPM among those selected for the analysis starting from #1, then took #5, #9 and so on. In group #2 the starting BPM is #2, then #6, #10 and so on. Each group includes about 20 BPMs distributed almost uniformly around the ring. In each of six sets of measurements we fitted the signal by using those four groups of BPMs. A total of 24 data points were obtained and the results are shown in Fig. 5. The combined fit of these data points leads to the values \(a_{\perp,x}=0.32\pm 0.31\) ppm and \(a_{\perp,y}=-0.12\pm 0.29\) ppm, where \(a_{\perp,x}=a_{\perp}\times\cos(\Phi)\) and \(a_{\perp,y}=a_{\perp}\times\sin(\Phi)\) per Eq. 2, which corresponds to the value of a combined fit amplitude \(a_{\perp}=0.34\pm 0.42\) ppm and phase \(\Phi=-0.36\) radian.

Summary.\(-\)The search for the anisotropy of the one-way maximum attainable speed of the electron was performed by means of precision monitoring of the variation of the difference in momenta of electron and positron beams versus location along the orbit of the CESR storage ring for 5.29 GeV beam energy. The sidereal time anisotropy \(\Delta c_{1,e}/c_{e}\) (the combined result from all 24 sets of data) is below \(5.5\times 10^{-15}\) with \(\sim\)95% confidence (two-sigma level) as follows from Eqs. 1 and 2 with \(a_{\perp}=\sqrt{a_{\perp,x}^{2}+a_{\perp,y}^{2}}\). This limit is about three times better than previously reported by the most accurate experiment [8].

The accuracy of this experiment is limited by the drift of individual electronics channels and to a lesser extent

Figure 3: Run group A kicker analysis. An example of position difference \(\Delta x_{\pm}-\Delta x_{\pm}^{ref}\) vs. BPM location for a typical data shot. Here the \(\Psi=2\pi\cdot s/P\), where \(P\) is the perimeter of the orbit. The upper left panel shows the raw data as black points and the fit values as open red squares with three kickers whose intensities and locations (indicated by vertical red dashed lines) were obtained from the fit of a closed orbit function. The upper right plot shows the distribution of the \(\Delta x_{\pm}\) values and its rms. The lower panel shows the distribution of the residual \(\delta x_{\pm}\) (after subtraction of the kickers’ contribution) as open black circles, the signal fit function (\(\delta x/\eta\)) as a dashed blue curve (see the scale on the right), the signal contribution to \(\delta x_{\pm}\) as open red circles. The corresponding projection of open black circles shown on the right side has an rms of 3.1 \(\mu\)m.

Figure 4: One-BPM fit results for the AMAS function parameters. The pink contour 30 ppm \(\times\) 30 ppm on the left plot contained 359 data points out of the 500 obtained. The distributions in the right side plots were fitted by a Gaussian function for the central areas of \(\pm\)15 ppm.

by the readout rate of the associated DAQ. With resolution of these issues, the technique will allow investigation of the \(\Delta c_{1,e}\) in the region potentially sensitive to a QG effect. Performing the experiment at different beam energies will provide an additional handle for the discrimination of the systematics and the possible AMAS effect.

It is interesting that the LHC collider, whose magnetic systems for two beams are coupled magnetically and geometrically, provides the possibility of doing a test of AMAS for the proton [24]. We would also like to mention that a synchronized measurement of the beam deflection in several storage rings with high accuracy opens additional opportunity for a search for the transient effects [25], which were proposed in a number of models for the physics beyond SM.

Many recent experiments on LIV were interpreted within the framework of the SME theory. It would be interesting to perform an SME-based analysis of our measurement as well. However, in the minimal SME theory there is no sensitivity of the magnetic deflection to the dipole form of the AMAS [26], so the obtained limit could also be used for a test of the underlying assumption of SME. At the same time, within the SME framework there is already a prediction of a nonvanishing eccentricity of the particle trajectory in the magnetic deflection [27] which could be investigated by using the beam trajectory in a storage ring, as we did here, when sufficient stability of the magnets is achieved.

It is our pleasure to thank the CESR staff for the smooth operation of the storage ring. We would like to extend special thanks to V. Zelevinsky for his recommendations, D. Sagan and B. Schmookler for their contributions to data analysis at the initial stage of the experiment, and G. Cates for productive discussions and support of the experiment. This work supported by National Science Foundation under grants PHYS-1416318, and DGE-1144153.

## References

* (1) A. Einstein, Annalen der Physik, **17**, 891 (1905).
* (2) A.A. Michelson and E.W. Morley, Am. J. Sci. **34**, 333 (1887).
* (3) R. Anderson _et al._, Physics Reports **295**, 93 (1998).
* (4) D. Colladay and V.A. Kostelecky, Phys. Rev. D **55**, 6760 (1997); Phys. Rev. D **58**, 116002 (1998).
* (5) V.A. Kostelecky and N. Russell, Rev. Mod. Phys. **83**, 11 (2011);
* (6) M. Nagel _et al._, Nature Communications **6**, 8174 (2015).
* (7) D. Mattingly, Living Reviews in Relativity **8**, 5 (2005); S. Liberati, Class. Quantum Grav. **30**, 133001 (2013).
* (8) V.G. Gurzadyan _et al._, Mod. Phys. Lett. A **20**, 19 (2005); J.-P. Bocquet _et al._, Phys. Rev. Lett. **104**, 241601 (2010).
* (9) C.M. Will, Living Rev. Relativity **17**, 4 (2014); Jay D. Tasson, Rep. Prog. Phys. **77**, 062901 (2014).
* (10) B. Botermann _et al._, Phys. Rev. Lett. **113**, 120405 (2014).
* (11) V.G. Gurzadyan and A.T. Margarian, Phys. Scr., **53**, 513 (1996).
* (12) S. Coleman and S.L. Glashow, Phys. Rev. D **59**, 116008 (1999).
* (13) B. Altschul, Phys. Rev. D **72**, 085003 (2005).
* (14) B. Wojtsekhowski, Euro Physics Letters, **108**, 31001 (2014).
* (15) V.W. Hughes _et al._, Phys. Rev. Lett. **4**, 342 (1960); R.W.P. Drever, Philosophical Magazine, **6**, 683 (1961).
* (16) M.S. Safronova _et al._, Rev. Mod. Phys. **90**, 025008 (2018).
* (17) D. Budker and V.V. Flambaum, private communication, 2017.
* (18) M. Tanabashi _et al._, (Particle Data Group), Phys. Rev. D **98**, 030001 (2018).
* (19) D.A. Edwards and M.J. Syphers, Introduction to The Physics of High Energy Accelerators, Wiley, New York, 1993.
* (20) CESR storage ring, [https://www.classe.cornell.edu/public/lab-info/cesr.html](https://www.classe.cornell.edu/public/lab-info/cesr.html)
* (21) M. Palmer _et al._, Proceedings of the 2010 International Particle Accelerator Conference, p. 1191; N. Rider _et al._, in Proceedings of ECLOUD 2010: 49th ICFA Advanced Beam Dynamics Workshop on Electron Cloud Physics, Ithaca, NY (K. Smolenski, ed.), (Ithaca, NY), pp. 88-90, Cornell University, 2013.
* (22) M.G. Billins _et al._, JINST 12 T09005 (2017).
* (23) D.L. Rubin _et al._, Phys. Rev. ST Accel. Beams **13**, 092802 (2010).
* (24) J. Wenninger, private communication, 2018.
* (25) D. Budker and A. Derevianko, Physics Today **68**, 10 (2015).
* (26) Q.G. Bailey and V.A. Kostelecky, Phys. Rev. D **70**, 076006 (2004); M. Hohensee, V.A. Kostelecky, and M. Mewes, private communications, 2015.
* (27) B. Altschul, Phys. Rev. D **84**, 076006 (2011).

Figure 5: The results for all six measurements presented by 24 data points. The points in black and red show the results from the run groups A and B, respectively. The error bars at individual points represent statistical accuracy. The RMS is calculated from the distribution of the data points. The mean values are \(a_{\perp,x}=0.32\pm 0.31\) ppm and \(a_{\perp,y}=-0.12\pm 0.29\) ppm. The solid and dashed blue contours show the borders of one and two sigma exclusion areas, respectively, per one data point out of the 24 obtained.

Title: First observation of excited $Ω_b^-$ states
Transcription: # First observation

of excited \(\Omega_{b}^{-}\) states

LHCb collaboration

Authors are listed at the end of this Letter.

###### Abstract

We report four narrow peaks in the \(\Xi_{b}^{0}K^{-}\) mass spectrum obtained using \(pp\) collisions at center-of-mass energies of 7, 8 and 13 TeV, corresponding to a total integrated luminosity of 9 fb\({}^{-1}\) recorded by the LHCb experiment. Referring to these states by their mass, the mass values are

\[m(\Omega_{b}(6316)^{-}) =6315.64\pm 0.31\pm 0.07\pm 0.50\,\mathrm{MeV},\] \[m(\Omega_{b}(6330)^{-}) =6330.30\pm 0.28\pm 0.07\pm 0.50\,\mathrm{MeV},\] \[m(\Omega_{b}(6340)^{-}) =6339.71\pm 0.26\pm 0.05\pm 0.50\,\mathrm{MeV},\] \[m(\Omega_{b}(6350)^{-}) =6349.88\pm 0.35\pm 0.05\pm 0.50\,\mathrm{MeV},\]

where the uncertainties are statistical, systematic and the last is due to the knowledge of the \(\Xi_{b}^{0}\) mass. The natural widths of the three lower mass states are consistent with zero, and the 90% confidence-level upper limits are determined to be \(\Gamma(\Omega_{b}(6316)^{-})<2.8\,\mathrm{MeV},\ \Gamma(\Omega_{b}(6330)^{-})<3.1\, \mathrm{MeV}\) and \(\Gamma(\Omega_{b}(6340)^{-})<1.5\,\mathrm{MeV}\). The natural width of the \(\Omega_{b}(6350)^{-}\) peak is \(1.4^{+1.0}_{-0.8}\pm 0.1\,\mathrm{MeV}\), which is \(2.5\sigma\) from zero and corresponds to an upper limit of \(2.8\,\mathrm{MeV}\). The peaks have local significances ranging from \(3.6\sigma\) to \(7.2\sigma\). After accounting for the look-elsewhere effect, the significances of the \(\Omega_{b}(6316)^{-}\) and \(\Omega_{b}(6330)^{-}\) peaks are reduced to \(2.1\sigma\) and \(2.6\sigma\) respectively, while the two higher mass peaks exceed \(5\sigma\). The observed peaks are consistent with expectations for excited \(\Omega_{b}^{-}\) resonances.

EP-2019-278

LHCb-PAPER-2019-042

Feb. 25, 2020

[MISSING_PAGE_EMPTY:2]

The study of hadrons containing heavy (\(b\) or \(c\)) quarks has undergone a renaissance over the last couple of decades. During this time a plethora of new states have been observed, including candidates for four-quark (tetraquark) states, and more recently five-quark (pentaquark) states [1, 2, 3] (see Refs. [4, 5, 6] for recent reviews). In addition, a number of observations of peaking structures in the invariant-mass spectra of final states containing \(\Xi_{c}^{+}K^{-}\)[7], \(\Xi_{b}^{0}\pi^{-}\)[8], \(\Lambda_{b}^{0}\pi^{-}\)[9], and \(\Lambda_{b}^{0}\pi^{+}\pi^{-}\)[10, 11] have provided valuable experimental information to improve our understanding of quantum chromodynamics (QCD), the theory of the strong interaction.

Fueled by these observations, there has been a renewed interest in gaining a deeper theoretical understanding of hadronic structure. The constituent quark model [12, 13] has been very successful in describing the types of hadrons that form in nature and how they fit into multiplets [14] based on the quantum numbers of the states. While conventional baryons are understood to be states that contain three valence quarks, a deep understanding of how best to describe these and other multi-quark states in terms of their fundamental constituents is still an open question. For example, in QCD, two quarks can exhibit attraction when in a \(J^{P}=0^{+}\) quantum state, giving rise to the notion that conventional baryons can be described as the bound state of a quark and a \(qq^{\prime}\) diquark [15, 16]. These ideas are naturally extensible to describe tetraquark and pentaquark candidates [4, 5, 6].

Recently, the LHCb experiment observed five narrow states, assumed to be excited \(\varOmega_{c}^{0}\) baryons, which decay into \(\Xi_{c}^{+}K^{-}\)[7]. These states have been analyzed from the perspective of constituent quark models and lattice QCD [17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33], quark-diquark models [34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44], as well as molecular models [45, 46, 47, 48, 49, 50] and pentaquark states [51, 52, 53]. Several of the models that seek to describe these peaks also make predictions for \(\Xi_{b}^{0}K^{-}\) resonances. Since the quark contents of the \(\varOmega_{c}^{0}\) and \(\varOmega_{b}^{-}\) baryons are \(css\) and \(bss\), respectively, it is of great interest to search for analogous states in the \(\Xi_{b}^{0}K^{-}\) mass spectrum.

This Letter reports on a search for narrow resonances in the \(\Xi_{b}^{0}K^{-}\) mass spectrum close to the kinematic threshold. The search uses data collected in \(pp\) collisions with the LHCb detector at center-of-mass energies of 7, 8 and 13 TeV, corresponding to integrated luminosities of 1, 2 and 6 fb\({}^{-1}\), respectively. Charge-conjugate processes are implicitly included, and natural units with \(\hbar=c=1\) are used throughout.

The LHCb detector [54, 55] is a single-arm forward spectrometer covering the pseudorapidity range \(2<\eta<5\), designed for the study of particles containing \(b\) or \(c\) quarks. Events are selected online by a trigger, which consists of a hardware stage, based on information from the calorimeter and muon systems, followed by a software stage, which applies a full event reconstruction [56, 57]. Simulated data samples are produced using the software packages described in Refs. [58, 59, 60, 61, 62, 63, 64], and are used to optimize selection requirements and to quantify the invariant-mass resolution of the LHCb detector.

Samples of \(\Xi_{b}^{0}\) candidates are formed by pairing \(\Xi_{c}^{+}\) and \(\pi^{-}\) candidates, where the \(\Xi_{c}^{+}\) decays are reconstructed in the \(pK^{-}\pi^{+}\) final state. All final-state hadrons must have particle-identification (PID) information consistent with the assigned particle hypothesis. The final-state particles are also required to be inconsistent with originating from a primary \(pp\) collision vertex (PV) by requiring that they have large \(\chi_{\rm IP}^{2}\) with respect to all PVs in the event. The quantity \(\chi_{\rm IP}^{2}\) is the difference in \(\chi^{2}\) of the vertex fit of a given PV when the particle (here \(p\), \(K^{-}\) or \(\pi^{+}\)) is included and excluded from the fit.

The \(\Xi_{c}^{+}\) candidates must have a fitted vertex that is significantly displaced from all PVs in the event and have an invariant mass within 18 MeV of the known \(\Xi_{c}^{+}\) mass [14]. About20% of the \(\Xi_{c}^{+}\) background comprises misidentified \(D^{+}\to K^{-}\pi^{+}\pi^{+},\ D^{+}\to K^{+}K^{-}\pi^{+}\), \(D_{s}^{+}\to K^{+}K^{-}\pi^{+}\) and \(D^{*+}\to(D^{0}\to K^{-}\pi^{+})\pi^{+}\) decays, as well as misidentified \(\phi\) mesons with \(\phi\to K^{+}K^{-}\) combined with an additional particle from elsewhere in the event. These background contributions are removed by employing tighter PID requirements on candidates that are consistent with any of these decay hypotheses, resulting in about 1% loss of signal efficiency. The \(pK^{-}\pi^{+}\) invariant-mass distribution of \(\Xi_{c}^{+}\) candidates satisfying these selection requirements is shown in Fig. 1 (left).

The \(\Xi_{b}^{0}\) candidates are formed from \(\Xi_{c}^{+}\pi^{-}\) combinations that have a significantly displaced decay vertex from all PVs in the event and a trajectory that is consistent with originating from one of them. The PV for which the \(\Xi_{b}^{0}\) candidate has the smallest \(\chi_{\rm IP}^{2}\) is assigned to be the associated PV, and it is used subsequently to compute quantities such as the \(\Xi_{b}^{0}\) decay time. Candidates satisfying the requirement \(5.6<M(\Xi_{c}^{+}\pi^{-})<6.0\,\mbox{\rm Ge\kern-1.0ptV}\) are retained, where \(M\) designates the invariant mass of the system.

To further suppress background in the \(\Xi_{b}^{0}\to\Xi_{c}^{+}\pi^{-}\) sample, a boosted decision tree (BDT) discriminant [65] is used. The BDT exploits 21 input variables: the decay times of the \(\Xi_{c}^{+}\) and \(\Xi_{b}^{0}\) candidates and the \(\chi^{2}\) values associated with their decay-vertex fits; the angle between the \(\Xi_{b}^{0}\) momentum vector and the line that joins the \(\Xi_{b}^{0}\) decay vertex and its associated PV; and for each final state particle the momentum, transverse momentum, \(\chi_{\rm IP}^{2}\) and a PID response variable. The PID response for final-state hadrons in the signal decay is obtained from large \(D^{*+}\to(D^{0}\to K^{-}\pi^{+})\pi^{+}\) and \(\mathchar 28935\relax\to p\pi^{-}\) calibration samples in data [66, 67]. Simulated signal decays and background from the \(\Xi_{c}^{+}\) mass sidebands (\(30<|M(pK^{-}\pi^{+})-m_{\Xi_{c}^{+}}|<50\,\mbox{\rm Me\kern-1.0ptV}\)) in data are used to train the BDT, where \(m\) refers to the mass of the indicated particle [14]. The chosen requirement on the BDT response provides a relative signal efficiency of 90%, and reduces the combinatorial background by about a factor of 2.5. Overall, the offline selection requirements are about 75% efficient on simulated decays, while reducing the background by about a factor of 40.

Figure 1 (right) shows the \(\Xi_{c}^{+}\pi^{-}\) mass spectrum for candidates passing the above

Figure 1: Invariant-mass spectrum for (left) \(\Xi_{c}^{+}\to pK^{-}\pi^{+}\) and (right) \(\Xi_{b}^{0}\to\Xi_{c}^{+}\pi^{-}\) candidates in data passing the selection requirements described in the text. The arrows indicate the requirements on the invariant masses that are applied in the subsequent stages of the analysis.

selection criteria. The spectrum is fit with the sum of two Crystal Ball [68] functions with a common mean and opposite-side power-law tails to model the signal, and an exponential function to describe the background distribution. The fitted \(\Xi_{b}^{0}\) signal yield is \(19\,200\pm 200\).

To search for peaking structures in the \(\Xi_{b}^{0}K^{-}\) mass spectrum, a requirement that \(|M(\Xi_{c}^{+}\pi^{-})-m_{\Xi_{b}^{0}}|<40\,\)MeV is imposed, which reduces the number of \(\Xi_{b}^{0}\) signal decays to about \(18\,000\). Each \(\Xi_{b}^{0}\) candidate is combined with a \(K^{-}\) candidate that is consistent with originating from a PV in the event. The \(\Xi_{b}^{0}\) and \(K^{-}\) trajectories are fitted to a common vertex, and that vertex is kinematically constrained to coincide with the PV associated with the \(\Xi_{b}^{0}\) candidate [69]. The additional PV constraint improves the resolution on the mass difference \(\delta M\equiv M(\Xi_{b}^{0}K^{-})-M(\Xi_{b}^{0})\) by about a factor of two.

Random combinations of \(\Xi_{b}^{0}\) baryons with a \(K^{-}\) candidate are the largest source of background in the \(\Xi_{b}^{0}K^{-}\) mass spectrum. To improve the expected signal-to-background ratio, a figure of merit, \(\epsilon/(\sqrt{B}+5/2)\)[70], is used to optimize the requirements on the PID information of the \(K^{-}\) candidates. Here, \(\epsilon\) is the efficiency as determined from simulation, and \(B\) is the number of wrong-sign \(\Xi_{b}^{0}K^{+}\) combinations in the region \(520<\delta M<570\,\)MeV passing the PID requirement, scaled to a \(10\,\)MeV mass window. The \(10\,\)MeV width is chosen based on the search for narrow peaks, since the low signal yields expected would make wide peaks difficult to separate from the combinatorial background. The optimal requirement on the \(K^{-}\) PID provides an efficiency of about \(85\%\) and suppresses the background by a factor of about \(2.5\).

The decay of a resonance to \(\Xi_{b}^{0}K^{-}\) will produce peaks in the \(\delta M\) spectrum. The experimental \(\delta M\) resolution is obtained from simulated samples generated at several masses, \(m_{\rm res}\). The resolution function is described by the sum of two Gaussian functions with a common mean. In addition, the width of the narrower Gaussian component, \(\sigma_{\rm core}\), is fixed to be \(45\%\) of that of the wider component, and its contribution is required to constitute \(80\%\) of the total shape. A smooth, monotonically increasing function, denoted as \(\sigma(m_{\rm res})\), is then used to parameterize \(\sigma_{\rm core}\) as a function of \(m_{\rm res}\). In the \(\delta M\) interval of interest, \(\sigma(m_{\rm res})\) is in the range of \(0.7\)-\(0.8\,\)MeV.

The \(\delta M\) distributions for right-sign (RS) and wrong-sign (WS) candidates are shown in Fig. 2, along with fits to the spectra as described below. Four peaks are seen in the RS spectrum of \(\Xi_{b}^{0}K^{-}\) candidates (red curves), whereas no significant peaks are seen in the corresponding WS \(\Xi_{b}^{0}K^{+}\) distribution. To obtain the parameters of the peaks, a simultaneous unbinned extended maximum-likelihood fit is performed to the RS and WS spectra. Each signal peak is described by an \(S\)-wave relativistic Breit-Wigner function [71] with a Blatt-Weisskopf barrier factor [72], convoluted with the resolution function \(\sigma(m_{\rm res})\) described above. A common background shape is used to describe both the RS and WS spectra, and is described by a smooth three-parameter monotonic function that accounts for the \(\Xi_{b}^{0}K^{-}\) threshold.

The peak values of \(\delta M\), natural widths, signal yields, and the local and global significances are summarized in Table 1. The local significance is obtained as \(\mathcal{S}_{\rm data}=\sqrt{2\log(\mathcal{L}_{\rm max}/\mathcal{L}_{0})}\), where \(\mathcal{L}_{\rm max}\) is the maximum value of the fit likelihood and \(\mathcal{L}_{0}\) is the value obtained when a given peak's yield is fixed to zero. All peaks have natural width consistent with zero. The highest-mass peak has the largest width, which differs from zero by \(2.5\) standard deviations, as determined from a likelihood scan of the width parameter.

To account for the look-elsewhere effect [73], which considers that the peak search extends over about a \(200\,\)MeV wide mass region, a large number of pseudoexperiments(pe) are generated. The pseudoexperiments use the nominal parameters from the fit to the data, with the signal yield of each peak, in turn, set to zero. The full mass region is scanned in 0.5\(\,\mathrm{Me\kern-1.0ptV}\) steps to identify the most significant positive fluctuation outside of the region of the three retained peaks, from which the significance \(\mathcal{S}_{\mathrm{pe}}\) is computed. From the corresponding distribution of \(\mathcal{S}_{\mathrm{pe}}\) and the value \(\mathcal{S}_{\mathrm{data}}\), a \(p\)-value -- expressed in Gaussian standard deviations -- is obtained for each peak, as shown in Table 1.

The sources of systematic uncertainty that affect the measured masses are summarized in Table 2. The momentum scale uncertainty is assessed by shifting the momentum scale of all charged tracks by \(\pm 0.03\%\)[74] in simulated decays, and evaluating the change in \(\delta M\). The imperfect modeling of the energy loss in the detector material results in a systematic uncertainty of 0.04\(\,\mathrm{Me\kern-1.0ptV}\)[75]. The uncertainty due to the choice of signal model is assigned by fitting the data with an alternative signal model composed of two Gaussian functions with a common mean. The largest change, 0.02\(\,\mathrm{Me\kern-1.0ptV}\), is assigned as a systematic uncertainty to all of the peak positions. The background shape uncertainty is assessed

Figure 2: Distribution of the mass difference for (top) right-sign \(\Xi_{b}^{0}K^{-}\) candidates, and (bottom) wrong-sign \(\Xi_{b}^{0}K^{+}\) candidates, as described in the text.

by removing the influence of the WS data on the background shape, and fitting only the RS data; the difference in the peak positions with respect to the nominal fit is assigned as a systematic uncertainty. The relativistic Breit-Wigner signal shape in the nominal fit assumes that the decay proceeds through an \(S\)-wave, with an interaction radius in the Blatt-Weisskopf barrier factor of \(R=3\,\mbox{Ge\kern-1.0ptV}^{-1}\). Changing the angular momentum in the decay to \(L=2\) (\(D\)-wave), and separately varying \(R\) between 1 and 5 \(\,\mbox{Ge\kern-1.0ptV}^{-1}\), leads to a negligible change in the peak positions. For the absolute mass determination, the world-average \(\Xi_{b}^{0}\) mass of \(5791.9\pm 0.5\,\mbox{Me\kern-1.0ptV}\)[14] is used. The uncertainty of 0.5\(\,\mbox{Me\kern-1.0ptV}\) on this mass dominates the systematic uncertainty and is quoted separately in the final results.

The primary source of systematic uncertainty on the natural widths of the observed peaks is from an imperfect knowledge of the \(\delta M\) resolution, which is obtained from simulation. Based on previous studies of \(D^{*+}\to D^{0}\pi^{+}\) decays [76], the \(\delta M\) resolution in simulation agrees with that of data within 10%. The impact of a \(\pm 10\%\) variation in the resolution is evaluated using pseudoexperiments, where each experiment is generated using the nominal signal resolution function, and fitted with a 10% smaller or larger \(\delta M\) resolution. Deviations of \(\pm 0.10\,\mbox{Me\kern-1.0ptV}\) relative to the true value of the width are found for a range of input widths corresponding to that which is observed in data. The upper limits on the natural width of the observed peaks are evaluated by convoluting the likelihoods with this 0.10\(\,\mbox{Me\kern-1.0ptV}\) uncertainty, and finding the values of the widths that contain 90% and

Tuple 42:
Cleaned Title: triangular number finitely stable
Cleaned Transcription: missingpageempty result main result need following fact completeness proof second given theorem gauss operatornamenumdeltadeltadelta theorem set triangular number additive basis order proof see chapter section proposition nequiv pmod n sum two triangular number proof suppose absurd nequiv pmod sum two triangular number exists x yinmathbbn mfracxxfracyy implies mxxyy taking equation mod equiv xxyypmod equation solution mod contradiction analogously case nequiv pmod corollary triangular number finitely stable additive basis proof since ot previous proposition show hypothesis theorem fulfilled finitely stable additive basis corollary together next two result show polygonal number finitely stable additive base square mathbbn triangular number theorem fermatcauchy polygonal number theorem let kinmathbbn kgeq mathbbnk denotes set kgonal number omathbbnkk proof see theorem legendre polygonal number theorem let mgeq ngeq odd n sum four polygonal number order even n sum five polygonal number order least one proof see chapter section corollary polygonal number finitely stable additive base square mathbbn triangular number tproof fix minmathbbn mgeq consider set mathbbnmcupjinmathbbn jm compare order set order mathbbnm reference ferreira l finitely stable additive base bulletin australian mathematical society nathanson b short proof cauchys polygonal number theorem proceeding american mathematical society nathanson b additive number theory classical base grad text math springer new york title exploring solar pole last great frontier sun transcription primary author dibyendu nandy coauthor dipankar banerjee prantika bhowmik allan sacha brun robert h cameron e gibson shravan hanasoge louise harra donald hassler rekha jain jie jiang laurene jouve duncan h mackay sushant mahajan cristina h mandrini mathew owen shaonwita pal rui f pinto chitradeep saha xudong sun durgesh tripathi ilya g usoskin center excellence space science india indian institute science education research kolkata india aryabhatta research institute observational science india department mathematical science durham university uk dept dastrophysiqueaii universite paris et parissaclay france max planck institute solar system research germany ncarhao usa tata institute fundamental research india physikalischmeteorologisches observatorium davosworld radiation center switzerland southwest research institute boulder usa school mathematics statistic university sheffield uk school space environment beihang university beijing china irap universite de toulouse france university st andrew uk w w hansen experimental physic laboratory stanford university stanford ca usa instituto de astronomia fisica del espacio buenos aire argentina dept meteorology university reading institute astronomy university hawaii manoa interuniversity centre astronomy astrophysics india university oulu finland white paper submitted consideration decadal survey solar space physic u national academy science synopsis despite investment multiple space groundbased solar observatory global community sun polar region remain unchartered territory last great frontier solar observation breaching frontier fundamental understanding solar cycle ultimate driver shorttolong term solar activity encompasses space weather space climate magnetohydrodynamic dynamo model empirically observed relationship established polar field primary determinant future solar cycle amplitude model solar surface evolution tilted active region indicate midtohigh latitude surge magnetic flux govern dynamic leading reversal buildup polar field theoretical understanding numerical model high latitude magnetic field dynamic plasma flow critical component sunspot cycle lack precise observational constraint currently limited large projection effect due location plane ecliptic limitation compromise ability observe enigmatic kilogauss polar flux patch quantitatively constrain polar field distribution high latitude extension lack observation handicap understanding high latitude magnetic field power polar jet plume fast solar wind extend boundary heliosphere modulate solar open flux cosmic ray flux within solar system accurate observation sun polar region therefore single outstanding challenge confronts heliophysics solar polar exploration mission isolation conjunction multivantage point observation across inner heliosphere stand revolutionize field heliophysics like mission concept relevance transcends spatial regime solar interior heliosphere white paper argues scientific case novel outofecliptic observation sun polar region conjunction existing future multivantage point heliospheric observatory big picture genesis solarstellar magnetic activity traced back magnetohydrodynamic mhd dynamo mechanism operating interior plasma flow magnetic field interact complex process generate largescale magnetic field charbonneau brun et al magnetic active region generated solar dynamo emerge sun surface jouve brun aulanier outer atmosphere subsequent dynamical interaction often lead energetic transient event solar flare coronal mass ejection cmes create severe space weather schrijver emergence evolution solar surface magnetic field mediated via nearsurface flux transport process result redistribution surface field govern structuringand dynamic largescale solar corona solar wind born propagates throughout heliosphere combined action surface field mediated open flux evolution turbulent solar wind transport modulates open flux consequently cosmic ray flux heliosphere define ambient space environment solar system planet earth upon solar magnetic storm act transient perturbation governing space weather understanding predicting space weather critical protection spacebased asset schrijver daglis et al uncovering influence longterm solar magnetic variability usoskin forcing planetary magnetosphereatmosphere system profound implication space climate planetary habitability solar system stellarexoplanetary system nandy et al many advance made direction last couple decade generated knowledge also exposed critical shortcoming foremost inability observationally constrain fully comprehend magnetic fieldassociated dynamic sun polar region flux content whose influence transcends process spanning sun interior atmosphere heliosphere petrie note humanity never accomplished spatially resolved precise observation polar magnetic field star routine basis solar orbiter mission halfstep direction enough follows inspire expedition sun polar region focusing transformative knowledge generate awareness might new discovery surprise even anticipate sun polar field sunspot cycle prediction solar cycle governs occurrence probability severe space weather event decadalscale forcing planetary environment predicting future cycle remained outstanding challenge petrovay analysis recent progress demonstrate polar field cycle minimum best indicator future solar cycle amplitude physicsbased dynamo model based babcockleighton mechanism converged indicate weakmoderate cycle nandy babcockleighton mechanism involves process emergence active region tilted bipolar sunspot pair subsequent decay dispersal largescale separation opposite polarity flux via nearsurface plasma transport process meridional circulation turbulent diffusion pumping jiang et al analytic theory indicates surface field primary driver internal dynamo cameron schussler particular crossequatorial cancellation midtohigh latitude surge active latitude apparent figure e primary determinant solar polar field amplitude turn solar polar field distribution determines dipole moment solar minimum main contributor amplitude future cycle dynamic currently poorly constrained observation direct observation polar field associated dipole moment variation rely proxy polar facula validating predictive surface flux transport dynamo model even debilitating fact current polar field observation suffer largeprojection effect figure succinctly demonstrates observe location direct view sun pole compared compromised view planeofecliptic summarize polar mission capable imaging magnetic field least degree ecliptic plane return transformative information high latitude magnetic field dynamic constrain polar field figure left top panel show observed sunspot number time series last century middle panel show hemispheric polar field variation reconstructed polar facula data wilcox solar observatory data blue north red south bottom panel depicts solar butterfly diagram right top panel depicts observed evolution radial field solar surface gleaned kitt peak vacuum telescope kpvt michelson doppler imager mdi helioseismic magnetic imager hmi observation bottom panel depicts radial field evolution simulated datadriven solar surface flux transport model bhowmik nandy figure left drive home point polar field amplitude preceding sunspot cycle determines strength latter figure right illuminates role propagating tongue surge magnetic flux midtohigh latitude reversal buildup sun polar field distribution like never leading validation magnetic field evolution model accurate datadriven prediction sunspot cycle constraint high latitude solar plasma flow high beta plasma domain nearsurface layer within convection zone plasma flow drive magnetic field dynamic flow remain poorly constrained polar region highlatitude measurement surface velocity field potential overcome loptien et al particular dopplergram data would allow u apply helioseismic method christensendalsgaard gizon birch infer solar internal structure dynamic meridional circulation play critical role setting timescale amplitude largescale solar dynamo action magnetism rempel hanasoge rather poorly constrained pole significant improvement flow measurement vicinity polar cap including polar extent meridional circulation possible magnetic feature tracking technique mahajan et al applied observation suffer projection effect highlatitude observation used concurrently data existing observatory helioseismic magnetic imager hmi generate definitive constraint polar meridional flow figure left snapshot surface distribution magnetic field solar surface magnetic field evolution model depicting perspective close planeoftheecliptic solar obliquity ignored right equivalent perspective top sun north pole reveals detail polar cap missing lowlatitude perspective mission navigate least degree ecliptic plane would reveal detail constrain high latitude dynamic return accurate measurement plasma flow magnetic field distribution pole govern solar activity power fast solar wind measurement open possibility stereoscopic helioseismic imaging plasma flow deeper layer greater fidelity deep component meridional flow thought play critical role equatorward propagation latitude emergence sunspot nandy choudhuri structure variability remain illconstrained solar internal rotation measurement one greatest success helioseismology quite noisy vicinity pole high latitude flow polar vortex associated weak rotation hint significant subsurface variability rotation among outstanding issue polar observation resolve new constraint rotation meridional circulation polar region generate powerful constraint interplay flow field sustain solar dynamo action unravelling enigma kilogauss polar flux patch observation hinode solar optical telescope sot uncovered existence intense smallscale kilogauss flux patch high latitude region sun often coexisting within polarity largescale polar cap tsuneta et al ito et al red region figure unipolar flux patch polar region appear different nature compared smallscale mixed polarity flux patch quiet sun believed sustain open magnetic field line solar corona could power fast solar wind unipolar figure hinode sot observation unipolar kilogauss flux patch near solar north pole acquired september ito et al field view extends degree north polar cap patch contribute significantly overall flux content polar cap therefore may participate dynamo mechanism convert poloidal field component toroidal field component following cycle intense flux concentration also relevant context solar open flux problem linker et al wang et al namely mismatch expected observed open flux origin polar kilogauss flux patch evolution flux content solar cycle relation high latitude propagation magnetic field leading polar field build reversal remain poorly understood high latitude vantage point observation magnetic field flow different phase solar cycle crucial deciphering mystery surrounding origin polar kilogauss flux patch conjunction insitu solar wind characterization establish whether fundamental origin fast solar wind pole dynamic polar atmosphere jet plume wind sun pole often characterized presence coronal hole open solar magnetic field line intense kilogauss flux tube polar plume jet hanaoka et al sometimes pseudostreamers open coronal field line ubiquitous polar region excellent pathway alfven wave turbulent dissipation mediated solar wind acceleration hassler et al krishna prasad banerjee gupta morton tomczyk pinto strength solar polar field different phase cycle minimum influence boundary open closed field line tilt largescale streamer dash et al recent finding hint interchange reconnection coronal hole may power solar wind however proving would require polar magnetic field measurement tripathi nived solanki upendran tripathi polar phenomenon play role acceleration global structuring fast solar wind leave imprint heliosphere nearearth space weather cranmer gibson riley adequate constraint landscape polar magnetic field transient phenomenon solar cycle achieved via outofecliptic space mission concept designed multiple pass solar pole would transform ability ass predict largescale structuring global solar wind heliospheric space weather consequence bring fore magnetic connectivity bridging solar interior farthest reach heliosphere summary recommendation nasa program addressing novel science presented necessitates space mission whose scope may either moderatescale largescale depending whether singlevantage point multivantage point mission concept planned address science believe proofofconcept singlevantage point mission quick turnaround time imaging magnetic field polar region solar atmosphere least degree planeofthe ecliptic high latitude dynamic leading next solar minimum ie time frame nominal mission lifetime year would prudent approach eg whitepaper hassler et al concurrently experience mission assimilated multivantage point mission concept may explored constrain solar activity insitu space environment across inner heliosphere nsf program theory numerical simulation data analysis existing observation ground space directly contribute holistic understanding physical process encompassing solar interior atmosphere space environment solar system planet view establishing causality necessary element community preparedness eventual success future space mission believe midscale research infrastructure innovation program supported nsf therefore crucial complement nasa space mission specifically propose supporting large team center leverage assimilate u global expertise develop theoretical modeling data analysis tool stand complement enable transformative scientific return outofecliptic multivantage point space mission envisaged white paper globally coordinated multivantage point observation heliosphere note existing mission parker solar probe solar orbiter solar dynamic observatory ace wind dscovr upcoming mission cnsa advanced spacebased solar observatory isros adityal esas vigil offer possibility globally coordinated observation conjunction novel solar polar mission recommend taken full advantage cementing mechanism data exchange across mission team leveraging modeling data analysis expertise across border synergy may catalyze ambitious multiagency international program system wide exploration heliophysics deployment multiple spacecraft cover whole nt steradian heliosphere eg whitepaper raouafi et al may prohibitively expensive one nation alone ultimate goal humanity together understand space share use understanding guide exploration world beyond reference bhowmik p nandy nat commun httpsdoiorgshttpsdoiorgs brun et al space sci rev httpsdoiorgshttpsdoiorgs cameron r schussler science httpsdoiorgsciencehttpsdoiorgscience charbonneau p living rev sol phys httpsdoiorgshttpsdoiorgs christensendalsgaard j review modern physic httpsdoiorgrevmodphyshttpsdoiorgrevmodphys cranmer sr gibson se riley p space sci rev httpsdoiorgsvhttpsdoiorgsv daglis ia et al annales geophysicae httpsdoiorgangeohttpsdoiorgangeo dash et al astrophysical journal httpsdoiorgabahttpsdoiorgaba gizon l birch c living review solar physic httpsdoiorglrsphttpsdoiorglrsp hanaoka et al astrophysical journal httpsdoiorgaacbhttpsdoiorgaacb hanasoge living review solar physic httpsdoiorgshttpsdoiorgs hassler dm et al science httpsdoiorgsciencehttpsdoiorgscience hassler dm et al white paper solaris mission ssp decadal survey u national academy science ito h et al astrophysical journal httpsdoiorgxhttpsdoiorgx jiang j et al space sci rev httpsdoiorgshttpsdoiorgs jouve l brun aulanier g astrophysical journal httpsdoiorgaabbhttpsdoiorgaabb krishna prasad banerjee gupta g aa httpsdoiorghttpsdoiorg linker ja et al apj httpsdoiorgaaahttpsdoiorgaaa loptien b et al space sci rev httpsdoiorgshttpsdoiorgs mahajan s et al apj httpsdoiorgacahttpsdoiorgaca morton r tomczyk pinto r nat commun httpsdoiorgncommshttpsdoiorgncomms nandy sol phys httpsdoiorgshttpsdoiorgs nandy et al progress earth planetary science httpsdoiorgsxhttpsdoiorgsx nandy choudhuri ar science httpsdoiorgsciencehttpsdoiorgscience petrie gjd living rev sol phys httpsdoiorglrsphttpsdoiorglrsp petrovay k living rev sol phys httpsdoiorgszhttpsdoiorgsz raouafi ne et al white paper firefly mission ssp decadal survey u national academy science rempel astrophysical journal httpsdoiorghttpsdoiorg schrijver cj et al adv space re httpsdoiorgjasrhttpsdoiorgjasr tripathi nived v n solanki k apj httpsdoiorgabccbhttpsdoiorgabccb tsuneta et al astrophysical journal httpsdoiorghttpsdoiorg upendran v tripathi apj httpsdoiorgacdhttpsdoiorgacd usoskin ig living rev sol phys httpsdoiorgshttpsdoiorgs wang ym et al apj httpsdoiorgachttpsdoiorgac title evae evolutionary variational autoencoder transcription evae evolutionary variational autoencoder zhangkai wu longbing cao lei qi university technology sydney southeast university berenwugmailcom longbingcaoutseduau qileiseueducn abstract surrogate loss variational autoencoders vaes pose various challenge training inducing imbalance task fitting representation inference avert existing strategy vaes focus adjusting tradeoff introducing hyperparameters deriving tighter bound mild assumption decomposing loss component per certain neural setting vaes still suffer uncertain tradeoff learning propose novel evolutionary variational autoencoder evae building variational information bottleneck vib theory integrative evolutionary neural learning evae integrates variational genetic algorithm vae variational evolutionary operator including variational mutation crossover evolution innerouterjoint training mechanism synergistically dynamically generates update uncertain tradeoff learning evidence lower bound elbo without additional constraint apart learning lossy compression representation data vib assumption evae present evolutionary paradigm tune critical factor vaes deep neural network address premature convergence random search problem integrating evolutionary optimization deep learning experiment show evae address klvanishing problem text generation low reconstruction loss generates disentangled factor sharp image improves image generation qualityrespectively evae achieves better reconstruction loss disentanglement generationinference balance competitor introduction variational autoencoders vaes attracted significant interest capability learning continuous smooth distribution observation integrating probabilistic deep neural learning principle however vaes still face significant issue including dynamic uncertainty learning variational inference tradeoff representation compression task fitting despite various recent vae mechanism variant briefly analyze issue gap existing solution novel evolutionary vae evae framework introduced address issue gap vaes gap analysisvaes demonstrated significant advantage incorporating prior knowledge mapping input probabilistic representation approximating likelihood output integration stochastic gradient variational bayes sgvb estimator neural setting learns narrow probabilistic latent space infer representative attribute hidden space vaes applied various domain including time series forecasting outofdomain detection image generating image spiking signal generating text language modeling theoretically bound optimization variational inference introduced substitute loglikelihood function surrogate function make optimized gradient descent practice evidence lower bound elbo approach maximum conditional likelihood close gap posterior prior cause dynamic uncertainty inference failed tradeoff representation robustness reconstruction effectiveness weak kl divergence could incur kl vanishing strong kl divergence could result bad likelihood tradeoff sensitive posterior distribution disjoint data characteristic network architecture recently various technique proposed address issue first set aim adjust balance objective function example betavae incorporating hyperparameter beta infovae adding scaling parameter kl term savae cyclical annealing schedule progressively increase beta reducing kl vanishing controlvae introducing proportionalintegralderivative pid control tune hyperparameter partial solution adjusting one part objective failing weigh resolve balance issue dynamic setting another set tune network architecture vae setting eg vqvae variant spiking vae multimodal vae mixtureofexperts multimodal vae tuning elbo building product expert structure however model subject specifictasks data setting evae information bottleneck perspective vaes treated lossy information compression process adjusting kl within range control information bottleneck flowing representing latent variable reconstructing sample thus benefiting tradeoff compression reconstruction variational information bottleneck inspires u improve vae mechanism objective function directly address generationinference balance evolving dynamic setting without constraint network input introduce novel evolutionary vae evae evae incorporates integrates variational evolutionary learning variational information bottleneck vae achieve better optimum exploration tradeoff representation compression generation fitting however integrating evolutionary learning vae open topic propose variational genetic algorithm evae optimize vae objective modeling exploration evolving manner consequently evae dynamically optimizes vae inference kl term evolutionary probabilistic manner tune vae generation toward balancing generation inference avert premature convergence evae introduces probabilistic chromosome selection smooth search avoid exhaustive random search apply simulated binary crossover cauchy distributional mutation guide training toward stable convergence main contribution work follows propose evae model balance tradeoff generation inference specifically cauchybased variational mutation operator sbxbased variational crossover operator proposed train model evolving innerouterjoint training algorithm tackling premature convergence random search problem optimizing deep model assisted variational genetic algorithm illustrate evae deriving lower bound betavae related model information bottleneck theory analyze information flow corresponding lower bound per ratedistortion theory show iterationspecific lower bound evae capture optimization trend train effectively evaluate evae three task disentangled representation learning dsprites image generation celeba text generation ptb corpus respectively evae form first evolutionary vae framework without empowering constraint vae architecture input setting objective function elbo integrates variational encoding decoding information bottleneck evolutionary learning deep neural framework evaluation stateoftheart vaes show evae achieves better disentanglement reconstruction loss solve kl vanishing effectively vae background issue briefly introduce background vaes focusing objective approach addressing inferencegeneration balance since mostly relevant work development vaes adjusting vae network structure input setting learning constraint excluded due irrelevance work vaes mitigate autoencoder issue like sparse representation learning continuous smooth representation distribution px xinmathcalx observation mathcalx latent variable mathbfz learning encoding distribution qphimathbfzmidmathbfx encoding neural network vaes apply variational inference approximate posterior distribution pthetamathbfxmidmathbfz learning task reconstructed generated output sampled learned distribution generative process sgvb estimator reparameterization trick gradient become tractable generative parameter theta inference parameter phi learnable objective vaes converted elbo expectation empirical distribution ptextdata data towards reconstruction mathcallmathrmr inference mathcallmathrmi beginsplitmathcallelboexsim ptext datalefteqphimathbfzmidmathbfxleftlog pthetamathbfxmidmathbf zrightright leftmathrmklleftqphimathbfzmidmathbfxmiddlep mathbfzrightright exsim ptextdatamathcallmathrmrmathcall mathrmiendsplit tag vae issuesto solve elbo inference model qphizx trained jointly maximizing elbo acquire reasonable compression task fitting however weak capacity decoder variety data could make expressive posterior favor task fitting rather optimal inference example variational language generation decoder built autoregressive model lstm pixelcnn generate language sample autoregressive property rather posteriorbased latent variable vae degenerate autoregressive model kl divergence posterior prior reach zero quickly training result kl vanishing poor generalization test lack diversity approach learning orthogonal transformation prior distribution decoder may sacrifice accurate inference optimal representation generalization fitting data research attribute training conflict inherent property bound optimization example solid factorial assumption posterior distribution ie pmathbfxmathbfzpmathbfxmidmathbfzprodipleftziright tag elbo constraining variational sample favor data fitting fails maximize probability mass loglikelihood addition vanilla vae optimizer strengthens disjointness qphizxi ie muirightarrowinftysigmaito separate loglikelihood concentrated sample resulting maximizing mass joint distribution vae enhancementone way address issue tighten loglikelihood lower bound correct variational approximation posterior prior decomposition elbo mild assumption example betavae add hyperparameter beta weigh mathcallkl term elbo minimizes mathcallr convergence data fitting collectively regularization mathcalli varying beta beginsplitmathcallelbo exsim pdatalefteqphimathbfz mathbfxleftlog pthetamathbfxmidmathbfzrightright leftbeta dklleftqphimathbfzmidmathbfx pmathbfzrightright exsim ptextdataleftmathcalltextr betamathcalltextirightendsplit tag betavae introduces fundamental limitation trigger various followup research infovae introduces scaling parameter lambda klterm convert objective beginsplitmathcallelboalpha iq mathbfxmathbfzdklleftqphimathbfzmidmathbfxp mathbfzright eqzleftdklleftqphimathbfzmidmathbfx pthetamathbfxmathbfzrightrightendsplit tag iq mutual information weight alpha alphalambda linear tuning kl show limitation dynamic uncertainty conditional vae cvae introduces initial guess conditional variable objective function multimodal data savae involves cyclical annealing schedule split training multiple cycle starting beta progressively increase beta beta reduce kl vanishing controlvae pid control compare kl divergence set point difference feedback controller tune hyperparameter betat controlvae thus optimizes kl dynamically constrained pid controller follows separate tuning mechanism vae existing work leaf gap building approximate weight allocation reconstruction inference tuning external hypberparameters within vae working mechanism handling issue dynamic manner evolutionary learning process evae address gap incorporating variational genetic learning balancing inference generation evolutionarily involving effect adjusting vae learning behavior toward better uncertain tradeoff learning evae model evae also tune representationgeneration balance eq jointly addressing following issue eq tuning hyperparameter outer circle irrelevant vae behavior nondynamic optimization constrained setting data network figure illustrates evae framework variational evolutionary learning improve vae balance evae evolving innerouterjoint training evae implement evolving learning process optimizing vae evolutionary parameter innerouterjoint iterative training process shown figure time given input xtinmathcalx vae inner training process train vae model mathcalv constrain vae framework generality use betavae case study paper initialization beta learn encoder qphimathbfztmidmathbfxt posterior pthetamathbfxtmidmathbfzt prior pmathbfz obtain vae inner objective function initial weight beta beginsplitmathcallelbot extsim p mathcalxlefteqphimathbfztmathbfxtleftlog p thetaleftmathbfxtmidmathbfztrightrightright leftbetadklleftqphileftmathbfztmid mathbfxtrightpmathbfzrightrightendsplit tag applying sgvb reparameterization trick generative process mathcalv estimate posterior pthetamathbfxmidmathbfzprodtpthetamathbfxtmid mathbfzt tag mathbfxtmidmathbfztsimmathcalnmumathbfzttheta sigmamathbfzttheta mathbfztmuxtepsilonsigmaxt epsilonsimmathcalni introduce outer variational evolutionary learner mathcale illustrated variational genetic algorithm introduced variational evolution optimize objective eq outer process mathcale fitness function f sample chromosome betat evolving distribution betatsimmathcalr evolves taking variational crossover mutation generate improve parameter betat evolved parameter incorporated mathcalvt next iteration training relevant elbo information backpropagated tune vae network optimize relevant parameter obtain updated reconstruction inference performance consequently eq evolved beginsplitmathcallelbot ext sim pmathcalxlefteqphimathbfztmathbfxt leftlog pthetaleftmathbfxtright leftmidmathbfztrightbetatdklleftq phileftmathbfztmidmathbfxtrightpmathbfzright rightendsplit tag fitness eq satisfied update beta betat result updated mathcalvt parameter phit thetat betat iteration repeat vga mathcale obtain another set parameter retrain model mathcalvt converges innerouter iterative training progress time sample generative process iteratively optimize balance reconstruction ie minimizing mathcallrxthatxt reconstructed hatxt inference ie seeking appropriate mathcalli vae learning behavior vae mathcalv optimized converges accordingly evae generative process optimizes following objective function beginsplitmathcallevaeminthetat phitsumtnmathcallelbotleftthetatphit right leftfleftmathcaleleftphitthetatbeta mathcallelbotrightrightmathbfxtrightendsplit tag approach beta optimal balance representation construction betasim fleftmathcaleleftbetamidphitthetat mathcallelbotrightright tagthe overall elbo evae represented beginarraylmathcallevaeexphi dthetamathbfzi mathbfxilog pthetamathbfxtmidmathbfzt fbetatsim rbetatmathcaledklqphileftmathbfzt midmathbfxtrightleftpmathbfzright extsim pmathcalemathcallrfbetamathcalli mathcaledeltamathcallelboendarray tag variational evolution evae introduce variational evolutionary learner mathcale optimizing parameter instantiate mathcale variational genetic algorithm vga variational crossover mutation operation avoids typical issue including premature convergence random search discordant exploitation exploration variational genetic algorithm evae integrates vgabased outer parameter optimization combined vaeinternal gradient descentbased optimization accordingly vga consists variational step operation initialization variational crossover vcrossover variational mutation vmutation variational evaluation vevaluation shown bottom part figure introduce respectively chromosome selection enable larger smooth ga search space compatible vaes chromosome embedded continuous variable beta sampled evolving distribution mathcalr eg crossover assume l individual chromosome forming candidate group betalbetaldotsbetal chromosome chosen candidate group train vae associated fitness value f vga operation vae retraining thus chromosomefitness pair embedded vga evolution offspring selection generation betafbetafldotsbetalfl tag optimizing innerouter joint training vcrossover paired chromosome time crossovered generate new gene improving genetic variety offspring following simulated binary crossover sbx method implement following crossover operation mathcalc induce large search space evolving chromosome betat time chromosome betat selected chromosome candidate group betal time obtain offspring candidate chromosome betat next time mathcalc strategy mathcalcleftbeginarraylbetatfracrcbeta ttrcbetattextitor betatfracrcbetattrcbetatendarrayright tag rc crossover rate drawn probability density function pcrc pcleftrcrightbegincasesetarcntextif rcleq etafracrcfracntextotherwiseendcases tag concentrating corresponding parent betat betalt sampling rc following function rcbegincasesufracntextif uleq leftfracurightfracetatextotherwiseendcases tag u random variable eta hyperparameter scaling offspring betat created selecting better mathcalc strategy ie better satisfying eq vmutation crossovergenerated offspring mutated improve genomic diversity evolutionary capacity aligning vcrossover variational mutation strategy mathcalm taken diversify offspring update betat inherited crossover betat current moment relatively small probability pm chromosome betat selected group mutated mathcalmbetatbetatrm tag rm random variable sampled cauchy distribution pm pmfracpifracbetat tag figure framework evae vae result inform chromosome sampling gene updated variational vcrossover vmutation evolved result checked per fitness retraining giving converging vevaluation vga fitness functionthe chromosome updated vcrossover vmutation operation evaluated alignment vae objective determine whether transferable next generation within vae framework take following heuristic fitness function f guide evolution chromosome fitness vae objective fitness function integrates direction vaeoriented stochastic gradient descent distance optimal kl divergence achieve multiobjectives ftdeltamathcallelbotkltbetatc tag deltamathcallelbot deltamathcallelbotmathcallelbotbetatmathcal lelbotbetat tag denoting vaes elbo difference applying evolved beta c taskspecific information bottleneck ensures bound optimization evae evolutionary optimization vevaluation fitness f guide evae converge balance reconstruction inference enhanced evolutionary parameterization larger fitness value stronger chromosome candidate group form strong pair betaf whole training process evae model illustrated algorithm supplementary material theoretical analysis paper evae take betavae case study evolutionary vae hence analyze effect evae adjusting betavae parameter tradeoff reconstruction regularization training performance betavae directly tune hyperparameter beta setting taskrelevant ratio inference loss mathcall generation loss mathcalltextr essence incrementally regularizing mathcall beta equivalent maximizing likelihood experimentspecific threshold ie constant c higgins et al maxphithetaexsimtextptextdatamathcallrquadtext st betamathcallic tag learning process interpreted information bottleneck ib theory alemi et al betamathcalli constraint operates bottleneck compressing capacity latent variable z organized input x expressively represent target hatxalemi et al accordingly ib maximizes izhatx acquire concise representation max izhatxquadtext st ixzleq ic tag variational information bottleneck vib introduces experimentspecific lower bound optimization mathcallbetavaethetaphidbetacrleqbetacid tag r refers compression rate refers distortion measuring representation relevance task betac experimentspecific constant vaes thus viewed process achieving ratedistortion tradeoff controlvae variant betavae tuning klspecific betakl pid control desired kl point mathcallcontrolvaethetaphidbetaklrleqbetaklid tag evae extends betavae tuning information bottleneck beta ixz variational evolutionary learner mathcale iteration outer training betat evolves fit task training phase guided fitness function f evae generates lower bound optimize iteration inner training phase mathcallevaeleqmathcalebetatitmathcalebetatdt tag evolving iterationspecific lower bound strike compromise task fitting mathcalebetatdt inference quality mathcalebetatit derivation eq eq found supplementary material b c compare vib effect evae vae betavae controlvae ratedistortion rd curve figure vae yellow tends sacrifice empirical error minimization representation learning early stage rate optimized decrease quarter iteration betavae green due experimentspecific lower bound betacid distortion minimized controlvae pink concentrate optimizing distortion initially fit data optimizing rate eventually acquire smooth representation resorting klspecific lower bound betaklid however directly modifying beta given pid controller lead fluctuation inference capacity reconstruction quality iteration rather monitoring optimization process evae generates iterationspecific lower bound mathcalebetatitmathcalebetatdt achieve balance minimizing distortion controlling rate experiment evaluate evae three typical task disentangled representation image generation language modeling figure evae innerouter joint evolutionary training process upper part show vae training time objective incorporated lower part outer training variational genetic algorithm whose fitnessbased optimized result fed vae training dataset baseline three different learning task datasets listed evaluate evae vae baseline disentangled representation learns independent latent variable generate image validate evae dsprites dshape dataset binary image generated six groundtruth factor shape square ellipse heart scale orientation position x position examine disentanglement performance image generation equally comprehensively betavae controlvae compared image generation reconstructs imagery sample based given datapoints celeba dataset cropped version used realworld celebrity face dataset rgb image baseline betavae controlvae language modeling conduct wordlevel text generation penn treebank dataset ptb english corpus used reveal performance restraining kl vanishing compare evae three heuristic method cost annealing noted costk cyclical annealing cyc pid control pid fair comparison adopt embedding network betavae tune evae achieve kl set point controlvae vae architecture hyperparameter setting given supplementary material performance evaluation performance disentangled representation learning validate performance reconstructing sharp image disentangled feature figure show evae achieves lower reconstruction loss compared controlvae expected kl divergence kl moreover figure b show evae present stable training curve vaes dynamic weighting guided vga fitness function rather direct modification betavae controlvae variation disentangled factor illustrated figure c figure demonstrates reliable disentanglement factor sharp reconstruction quality evae set point kl contrast controlvae capture generative factor scale x betavae entangles four factor except scale performance image generation evaluate evae celeba image generation fair concise comparison kl set point set achieving best reconstruction quality evae tuned achieve desired kl point similar controlvae figure show evae lowest reconstruction error compared vanilla vae controlvae guided evolving beta kl divergence evae achieve desired point dynamically illustrated figure b performance language modeling show validity evae preventing variational language model degenerating standard language model draw learning curve kl reconstruction loss weight kl iteration evolution beta shown figure demonstrating evae learn tune beta iteration automatically rather heuristic setting figure b show cost annealing costk model still suffers kl vanishing kl approaching end iteration contrast cyclical annealing cyc pid ga converge nonzero divergence evae achieves lowest reconstruction loss word generation illustrated figure c compared pid control vga find path toward stable stage without undergoing reconstruction fluctuation training even nonzero learned beta fixed conclusion propose evolutionary vae evae dynamically learn tradeoff reconstruction effectiveness inference robustness vaes evae involves variational evolving operator solve premature convergence random search problem sgd optimization genetic algorithm synergistically follow innerouterjoint training mechanism evae following variational information bottleneck theory evae derives iterationspecific lower bound balancing capacity compression decompression iteration multiple task experiment show evae outperforms sota vaes traversing sample disentangled feature generating sharp image lower reconstruction loss resolving kl vanishing automatically variational language modeling extend evae vae model task figure performance comparison different vaes image generation celeba figure information plane rd curve vae betavae controlvae evae dsprites figure learning curve dsprites ab indicate evae lowest reconstruction loss compared vae beta betavae beta controlvae kl fixed kl point kl c elementwise kl divergence function iteration evae observe evae retains stable reasonable kl divergence generator dimension factor positiony z scale z shape z positionx z orientation z comparison term generated kl divergence found supplementary material emore comparison term generated kl divergence found supplementary material e figure latent traversal dsprites distinguish latent factor visually take ellipse illustration row represents latent factor traversal keeping others fixed first column refers seed image initialization manipulate latent dimension z across range figure learning curve ptb language modeling suffix pid vga refer kl set point ie kl cyc indicates iteration cycle weight increase linearly costk refers k iteration weight increase sigmoid function iteratively reference alemi et al alemi poole b fischer dillon j saurous r murphy k fixing broken elbo icml alemi et al alemi fischer dillon j v murphy k deep variational information bottleneck iclr berliner et al berliner rotman g adi reichart r hazan learning discrete structured variational autoencoder using natural evolution strategy iclr bowman et al bowman r vilnis l vinyals dai jozefowicz r bengio generating sentence continuous space conll bozkurt et al bozkurt esmaeili b tristan jb brook h dy j g van de meent jw rateregularization generalization vaes aistats burda grosse salakhutdinov burda grosse r salakhutdinov r importance weighted autoencoders iclr burgess et al burgess c p higgins pal matthey l watters n desjardins g lerchner understanding disentangling betavae neurips deb beyer deb k beyer hg selfadaptive genetic algorithm simulated binary crossover evolutionary computation domke sheldon domke j sheldon r divide couple using monte carlo variational objective posterior approximation neurips esmaeili et al esmaeili b wu h jain bozkurt siddharth n paige b brook h dy j meent jw structured disentangled representation aistats fortuin et al fortuin v huser locatello f strathmann h ratsch g somvae interpretable discrete representation learning time series iclr fu et al fu h li c liu x gao j celikyilmaz carin l cyclical annealing schedule simple approach mitigating kl vanishing naacl ghosh et al ghosh p sajjadi vergari black scholkopf b variational deterministic autoencoders iclr havtorn et al havtorn j frellsen j hauberg maaloe l hierarchical vaes know dont know icml higgins et al higgins matthey l pal burgess c glorot x botvinick mohamed lerchner betavae learning basic visual concept constrained variational framework iclr jankowiak phan jankowiak phan surrogate likelihood variational annealed importance sampling icml kamata mukuta harada kamata h mukuta harada fully spiking variational autoencoder aaai khemakhem et al khemakhem kingma monti r hyvarinen variational autoencoders nonlinear ica unifying framework aistats kingma welling kingma p welling autoencoding variational bayes arxiv klushyn et al klushyn chen n kurle r cseke b van der smagt p learning hierarchical prior vaes neurips kviman et al kviman melin h koptagel h elvira v lagergren j multiple importance sampling elbo deep ensemble variational approximation aistats liu et al liu z luo p wang x tang x deep learning face attribute wild iccv locatello et al locatello f abbati g rainforth bauer scholkopf b bachem fairness disentangled representation neurips marcinkiewicz marcinkiewicz building large annotated corpus english penn treebank using large corpus mita filippone michiardi mita g filippone michiardi p identifiable double vae disentangled representation icml nalisnick et al nalisnick e matsukawa teh w gorur lakshminarayanan b deep generative model know dont know iclr ran et al ran x xu mei l xu q liu q detecting outofdistribution sample via variational autoencoder reliable uncertainty estimation neural network razavi et al razavi van den oord vinyals generating diverse highfidelity image vqvae neurips ruiz et al ruiz f j titsias k cemgil doucet unbiased gradient estimation variational autoencoders using coupled markov chain uai shao et al shao h yao sun zhang liu liu wang j abdelzaher controlvae controllable variational autoencoder icml shi et al shi paige b torr p et al variational mixtureofexperts autoencoders multimodal deep generative model neurips sohn et al sohn k lee h yan x learning structured output representation using deep conditional generative model neurips sutter et al sutter daunhawer vogt j e generalized multimodal elbo arxiv tolstikhin et al tolstikhin bousquet gelly schoelkopf b wasserstein autoencoders arxiv tomczak welling tomczak j welling vae vampprior aistats wang wang wang p z wang w neural gaussian copula variational autoencoder emnlp wu wang zhang wu wang l zhang p solving statistical mechanic using variational autoregressive network physical review letter xiao yan amit xiao z yan q amit likelihood regret outofdistribution detection score variational autoencoder neurips zhang et al zhang wang zhang l zhang z gai k improve diverse text generation self labeling conditional variational auto encoder icassp zhao song ermon zhao song j ermon infovae balancing learning inference variational autoencoders aaai reference alemi et al alemi poole b fischer dillon j saurous r murphy k fixing broken elbo icml alemi et al alemi fischer dillon j v murphy k deep variational information bottleneck iclr berliner et al berliner rotman g adi reichart r hazan learning discrete structured variational autoencoder using natural evolution strategy iclr bowman et al bowman r vilnis l vinyals dai jozefowicz r bengio generating sentence continuous space conll bozkurt et al bozkurt esmaeili b tristan jb brook h dy j g van de meent jw rateregularization generalization vaes aistats burda grosse salakhutdinov burda grosse r salakhutdinov r importance weighted autoencoders iclr burgess et al burgess c p higgins pal matthey l watters n desjardins g lerchner understanding disentangling betavae neurips deb beyer deb k beyer hg selfadaptive genetic algorithm simulated binary crossover evolutionary computation domke sheldon domke j sheldon r divide couple using monte carlo variational objective posterior approximation neurips esmaeili et al esmaeili b wu h jain bozkurt siddharth n paige b brook h dy j meent jw structured disentangled representation aistats fortuin et al fortuin v huser locatello f strathmann h ratsch g somvae interpretable discrete representation learning time series iclr fu et al fu h li c liu x gao j celikyilmaz carin l cyclical annealing schedule simple approach mitigating kl vanishing naacl ghosh et al ghosh p sajjadi vergari black scholkopf b variational deterministic autoencoders iclr havtorn et al havtorn j frellsen j hauberg maaloe l hierarchical vaes know dont know icml higgins et al higgins matthey l pal burgess c glorot x botvinick mohamed lerchner betavae learning basic visual concept constrained variational framework iclr jankowiak phan jankowiak phan surrogate likelihood variational annealed importance sampling icml kamata mukuta harada kamata h mukuta harada fully spiking variational autoencoder aaai khemakhem et al khemakhem kingma monti r hyvarinen variational autoencoders nonlinear ica unifying framework aistats kingma welling kingma p welling autoencoding variational bayes arxiv klushyn et al klushyn chen n kurle r cseke b van der smagt p learning hierarchical prior vaes neurips kviman et al kviman melin h koptagel h elvira v lagergren j multiple importance sampling elbo deep ensemble variational approximation aistats liu et al liu z luo p wang x tang x deep learning face attribute wild iccv locatello et al locatello f abbati g rainforth bauer scholkopf b bachem fairness disentangled representation neurips marcinkiewicz marcinkiewicz building large annotated corpus english penn treebank using large corpus mita filippone michiardi mita g filippone michiardi p identifiable double vae disentangled representation icml nalisnick et al nalisnick e matsukawa teh w gorur lakshminarayanan b deep generative model know dont know iclr ran et al ran x xu mei l xu q liu q detecting outofdistribution sample via variational autoencoder reliable uncertainty estimation neural network razavi et al razavi van den oord vinyals generating diverse highfidelity image vqvae neurips ruiz et al ruiz f j titsias k cemgil doucet unbiased gradient estimation variational autoencoders using coupled markov chain uai shao et al shao h yao sun zhang liu liu wang j abdelzaher controlvae controllable variational autoencoder icml shi et al shi paige b torr p et al variational mixtureofexperts autoencoders multimodal deep generative model neurips sohn et al sohn k lee h yan x learning structured output representation using deep conditional generative model neurips sutter et al sutter daunhawer vogt j e generalized multimodal elbo arxiv tolstikhin et al tolstikhin bousquet gelly schoelkopf b wasserstein autoencoders arxiv tomczak welling tomczak j welling vae vampprior aistats wang wang wang p z wang w neural gaussian copula variational autoencoder emnlp wu wang zhang wu wang l zhang p solving statistical mechanic using variational autoregressive network physical review letter xiao yan amit xiao z yan q amit likelihood regret outofdistribution detection score variational autoencoder neurips zhang et al zhang wang zhang l zhang z gai k improve diverse text generation self labeling conditional variational auto encoder icassp zhao song ermon zhao song j ermon infovae balancing learning inference variational autoencoders aaai supplementary material evae evolutionary variational autoencoder present supplemental material main content including evae algorithm experimental setting latent traversal square heart derivation variational lower upper bound appendix evae algorithm algorithm illustrates modeling process evae enables innerouterjoint training vae evolutionary learning iteratively input crossover rate prc mutation rate prm batch data x outputbetaf initialization parameter decoder theta parameter encoder phi betalbetadotsbetalinitialize group whilettdo prtleftarrow sample nleftrightprobability evolve ifprtprmthen thetat phitsavecurrent variational parameter generate betat vcrossover operation mathcalcbetatbetat eq evaluate betat fmathcalephitthetatbetamathcallelbot eq elseifprtprcthen thetat phitsavecurrent variational parameter generate betat vmutation operation mathcalmbetat eq evaluate betat fitness function fmathcalephitthetatbetamathcallelbot eq else betafleftarrowbetalselect strongest pair thetatphitleftarrowmathcallevaethetatphitbeta mathbfxtupdate variational parameter endif returnbetaf endwhile algorithm evolving innerouterjoint training appendix b derivation betavae lower bound according vib theory elbo bounded distortion deqthetaxzlog pthetaxmid z rate reqthetaxzdklqphizxpz ixz upper bound ileq r beginsplit rint qxint qthetazmid x logfracqthetazmid xpz ixztcz geq ixzendsplit tag lower bound igeq hd beginsplit iint dxdzpxzlogfracpxmid z px geqint dxdzpxzlogfracqxmid zpx int dxdzpxzlog qxmid z int dxpxlog px int dxdzpxzlog qxmid z hx hdendsplit tag variational information bottleneck regarded hdleq ileq r tag h entropy data betavae framework betac impose experimentspecific constraint compressor decompressor giving variational lower bound beginsplit hdleq ileq r hdleqbeta ileqbeta r hleqbeta idleqbeta rdendsplit tag summary lower bound denoted mathcallbetavaethetaphidbetacrleqbetacid tag appendix c derivation evae lower bound according eq eq obtain loss function evae iteration follows beginsplitmathcallevaeemathbfxsim q phimathbfxtmathbfxtlog pthetamathbfxtmid mathbfzt fbetatsim rbetatmathcaledklqphi mathbfztmidmathbfxtpmathbfz extsim pxmathcallrfbetatmathcall imathcaledeltamathcallelbo extsim pxmathcallrfbetatmathcall mathcaledeltamathcallelbotkltbetat c endsplit tag according vib theory rt set upper bound information bottleneck itxtzt tth iteration beginsplit rtint qxtint qthetazt mid xtlogfracqthetaztmid xtpzt itxtzttczt geq itxtztendsplit tagand dt set lower bound beginsplit itint dxdzpxtztlogfracp xtmid ztpxt geqint dxdzpxtztlogfracqxtmid ztpxt int dxdzpxtztlog qxtmid zt int dxpxtlog pxt int dxdzpxtztlog qxtmid zt hx hdtendsplit tag optimized variational evolutionary learner mathcale loss function evae constrained dynamic lower bound follows beginsplitmathcallevaeemathbfzsim q phimathbfztmathbfxtlog pthetamathbfxtmid mathbfzt fbetatsim rleftbetatmathcalerightdklq phimathbfztmidmathbfxtpmathbfz extsim pmathcalxmathcallrfbetat mathcallimathcaledeltamathcallelbo extsim pmathcalxmathcallrfbetat mathcalli mathcaledeltamathcallelbotkltbetat c dtbetatrtmathcaledtbetatrtd tc leqmathcalebetatdtmathcalebetatit endsplit tag c desired kl point betat chromosome sample tth iteration appendix experimental setting table show experimental setting three learning task evaluating evae give setting encoderdecoder network architecture parameter evolutionary learning three datasets dsprites celeba ptb corresponding optimizers appendix e analysis elementwise kl divergence disentangled representation learning figure show elementwise kl divergence evolving iteration three vae model betavae controlave comparison evae dataset dsprites
Original Title: The triangular numbers are finitely stable
Original Transcription: [MISSING_PAGE_EMPTY:1]

## 2. The result

For the main result we will need the following facts. For completeness, a proof of the second will be given.

**Theorem 2.1** (Gauss' \(\operatorname{num}=\Delta+\Delta+\Delta\) theorem).: _The set of the triangular numbers \(T\) is an additive basis of order \(3\)._

Proof.: See [3], chapter 1, section 1.7. 

**Proposition 2.2**.: _If \(n\equiv 5\) or \(8\pmod{9}\), then \(n\) is not the sum of two triangular numbers._

Proof.: Suppose by absurd that \(n\equiv 5\pmod{9}\) is the sum of two triangular numbers. Then there exists \(m\), \(x\), \(y\in\mathbb{N}\) such that

\[9m+5=\frac{x(x+1)}{2}+\frac{y(y+1)}{2}.\]

This implies

\[18m+10=x(x+1)+y(y+1).\]

Taking this equation mod 9,

\[1\equiv x(x+1)+y(y+1)\pmod{9}.\]

But this equation does not have a solution mod 9, contradiction. Analogously for the case \(n\equiv 8\pmod{9}\). 

**Corollary 2.3**.: _The triangular numbers \(T\) is a finitely stable additive basis._

Proof.: Since \(o(T)=3\), the previous proposition shows that the hypotheses of theorem 1.1 are fulfilled for \(T\). Then \(T\) is a finitely stable additive basis. 

This corollary, together with the next two results, show that the only polygonal numbers that are finitely stable additive bases are the squares \(\mathbb{N}^{2}\) and triangular numbers \(T\).

**Theorem 2.4** (Fermat-Cauchy polygonal number theorem).: _Let \(k\in\mathbb{N}\), \(k\geq 3\). If \(\mathbb{N}_{k}\) denotes the set of the \(k\)-gonal numbers, then \(o(\mathbb{N}_{k})=k\)._

Proof.: See [2]. 

**Theorem 2.5** (Legendre polygonal number theorem).: _Let \(m\geq 3\) and \(N\geq 28m^{3}\). If \(m\) is odd, then \(N\) is the sum of four polygonal numbers of order \(m+2\). If \(m\) is even, then \(N\) is the sum of five polygonal numbers of order \(m+2\), at least one of which is \(0\) or \(1\)._

Proof.: See [3], chapter 1, section 1.7. 

**Corollary 2.6**.: _The only polygonal numbers that are finitely stable additive bases are the squares \(\mathbb{N}^{2}\) and triangular numbers \(T\)._Proof.: Fix \(m\in\mathbb{N}\), \(m\geq 3\). Now consider the set

\[\mathbb{N}_{m+2}\cup\{j\in\mathbb{N};\ j<28m^{3}\}\]

and compare the order of this set with the order of \(\mathbb{N}_{m+2}\). 

## References

* [1] Ferreira, L. A.: Finitely stable additive bases. _Bulletin of the Australian Mathematical Society_ (3) **97** (2018), 360-362.
* [2] Nathanson, M. B.: A short proof of Cauchy's polygonal number theorem. _Proceedings of the American Mathematical Society_ (1) **99** (1987), 22-24.
* [3] Nathanson, M. B.: _Additive Number Theory: The Classical Bases_. Grad. Texts in Math. 164, Springer, New York, 1996.

Title: Exploring the Solar Poles: The Last Great Frontier of the Sun
Transcription: **Primary Author:** Dibyendu Nandy\({}^{1^{*}}\)

**Co-authors:** Dipankar Banerjee\({}^{2}\), Prantika Bhowmik\({}^{3}\), Allan Sacha Brun\({}^{4}\), Robert H. Cameron\({}^{5}\), S. E. Gibson\({}^{6}\), Shravan Hanasoge\({}^{7}\), Louise Harra\({}^{8}\), Donald M. Hassler\({}^{9}\), Rekha Jain\({}^{10}\), Jie Jiang\({}^{11}\), Laurene Jouve\({}^{12}\), Duncan H. Mackay\({}^{13}\), Sushant S. Mahajan\({}^{14}\), Cristina H. Mandrini\({}^{15}\), Mathew Owens\({}^{16}\), Shaonwita Pal\({}^{1}\), Rui F Pinto\({}^{4,12}\), Chitradeep Saha\({}^{1}\), Xudong Sun\({}^{17}\), Durgesh Tripathi\({}^{18}\), Ilya G. Usoskin\({}^{19}\)

\({}^{1^{*}}\)_Center of Excellence in Space Sciences India, Indian Institute of Science Education and Research Kolkata, India, \({}^{2}\)Aryabhatta Research Institute of Observational Sciences, India, \({}^{3}\)Department of Mathematical Sciences, Durham University, UK, \({}^{4}\)Dept. d'Astrophysique/AII, Universite Paris et Paris-Saclay, France, \({}^{5}\)Max Planck Institute for Solar System Research, Germany, \({}^{6}\)NCAR/HAO, USA, \({}^{7}\)Tata Institute of Fundamental Research, India, \({}^{8}\)Physikalisch-Meteorologisches Observatorium Davos/World Radiation Center, Switzerland, \({}^{9}\)Southwest Research Institute, Boulder, USA, \({}^{10}\)School of Mathematics and Statistics, University of Sheffield, UK, \({}^{11}\)School of Space and Environment, Beihang University, Beijing, China, \({}^{12}\)IRAP, Universite de Toulouse, France, \({}^{13}\)University of St Andrews, UK, \({}^{14}\)W. W. Hansen Experimental Physics Laboratory, Stanford University, Stanford, CA, USA, \({}^{15}\)Instituto de Astronomia y Fisica del Espacio, Buenos Aires, Argentina, \({}^{16}\)Dept. of Meteorology, University of Reading, \({}^{17}\)Institute for Astronomy, University of Hawaii at Manoa, \({}^{18}\)Inter-University Centre for Astronomy and Astrophysics, India, \({}^{19}\)University of Oulu, Finland A white paper submitted for consideration of the Decadal Survey in Solar and Space Physics 2024-2033 of the US National Academy of Sciences

## Synopsis

Despite investments in multiple space and ground-based solar observatories by the global community, the Sun's polar regions remain unchartered territory - the last great frontier for solar observations. Breaching this frontier is fundamental to understanding the solar cycle - the ultimate driver of short-to-long term solar activity that encompasses space weather and space climate. Magnetohydrodynamic dynamo models and empirically observed relationships have established that the polar field is the primary determinant of future solar cycle amplitude. Models of solar surface evolution of tilted active regions indicate that the mid-to-high latitude surges of magnetic flux govern the dynamics leading to the reversal and build-up of polar field. Our theoretical understanding and numerical models of this high latitude magnetic field dynamics and plasma flows - that are a critical component of the sunspot cycle - lack precise observational constraints, currently limited by large projection effects due to our location in the plane of the ecliptic. This limitation compromises our ability to observe the enigmatic kilo-Gauss polar flux patches and to quantitatively constrain the polar field distribution at high latitudes. By extension, the lack of these observations handicap our understanding of how high latitude magnetic fields power polar jets, plumes, and the fast solar wind that extend to the boundaries of the heliosphere and modulate solar open flux and cosmic ray flux within the solar system. Accurate observation of the Sun's polar regions, therefore, is the single most outstanding challenge that confronts Heliophysics. A solar polar exploration mission, in isolation, or in conjunction with multi-vantage point observations across the inner heliosphere, stands to revolutionize the field of Heliophysics like no other mission concept has - with relevance that transcends spatial regimes from the solar interior to the heliosphere. This white paper argues the scientific case for novel out-of-ecliptic observations of the Sun's polar regions, in conjunction with existing, or future multi-vantage point heliospheric observatories.

## The Big Picture

The genesis of solar-stellar magnetic activity can be traced back to a magnetohydrodynamic (MHD) dynamo mechanism operating in their interior, where plasma flows and magnetic fields interact through complex processes to generate large-scale magnetic fields (Charbonneau, 2020; Brun et al., 2015). Magnetic active regions generated by the solar dynamo emerge through the Sun's surface (Jouve, Brun and Aulanier, 2018) to its outer atmosphere, where subsequent dynamical interactions often lead to energetic, transient events such as solar flares and coronal mass ejections (CMEs) - which create severe space weather (Schrijver, 2015). The emergence and evolution of solar surface magnetic fields, mediated via near-surface flux transport processes result in the redistribution of the surface fields which govern the structuringand dynamics of the large-scale solar corona. Solar wind is born here and propagates throughout the heliosphere. The combined action of surface field mediated open flux evolution and turbulent solar wind transport modulates the open flux, and consequently the cosmic ray flux in the heliosphere; these define the ambient space environment of solar system planets such as the Earth, upon which solar magnetic storms act as transient perturbations governing space weather. Understanding and predicting space weather is critical for protection of our space-based assets (Schrijver 2015, Daglis et al. 2021). Uncovering the influence of long-term solar magnetic variability (Usoskin 2017) and its forcing on planetary magnetosphere-atmosphere systems have profound implications for space climate and planetary habitability in the solar system and other stellar-(exo)planetary systems (Nandy et al. 2021).

While many advances have been made in these directions in the last couple of decades, the generated knowledge have also exposed critical shortcomings; the foremost being our inability to observationally constrain and fully comprehend magnetic field-associated dynamic in the Sun's polar regions and its flux content - whose influence transcends processes spanning the Sun's interior, its atmosphere and the heliosphere (Petrie 2015). _We note that humanity has never accomplished spatially resolved precise observations of the polar magnetic fields of any star on a routine basis._ The Solar Orbiter mission is half-step in that direction, but that is not enough. In what follows, we inspire an expedition to the Sun's polar regions focusing on some of the transformative knowledge this can generate; we do so, with the awareness that there might be new discoveries and surprises that we cannot even anticipate now.

## Sun's Polar Fields and Sunspot Cycle Predictions

While the solar cycle governs the occurrence probability of severe space weather events and the decadal-scale forcing of planetary environments, predicting future cycles had remained an outstanding challenge (Petrovay 2018). Analyses of recent progress demonstrate that the polar field during cycle minima is the best indicator of the future solar cycle amplitude and that physics-based dynamo models based on the Babcock-Leighton mechanism have converged to indicate a weak-moderate cycle 25 (Nandy 2021). The Babcock-Leighton mechanism involves the processes of emergence of active regions (tilted bipolar sunspot pairs) and the subsequent decay, dispersal and large-scale separation of opposite polarity flux via near-surface plasma transport processes such as meridional circulation, turbulent diffusion and pumping (Jiang et al. 2014). Analytic theory indicates that surface fields are the primary driver of the internal dynamo (Cameron and Schussler 2015). In particular, cross-equatorial cancellation and mid-to-high latitude surges from active latitudes (apparent in Figure 1d - e) are the primary determinants of solar polar field amplitude. In turn the solar polar field distribution (which determines the dipole moment) at solar minimum is the main contributor to the amplitude of the future cycle. These dynamics are currently poorly constrained by observations.

We do not have direct observations of the polar field and associated dipole moment variation and have to rely on proxies such as the polar faculae for validating predictive surface flux transport and dynamo models. Even more debilitating is the fact that current polar field observations suffer from large-projection effects. Figure 2 succinctly demonstrates what we can observe from a location with a direct view of the Sun's poles compared to the compromised view from plane-of-ecliptic.

_To summarize, a polar mission capable of imaging magnetic fields from at least 60 degrees above or below the ecliptic plane can return transformative information on high latitude magnetic field dynamics, constrain the polar field

Figure 1: Left: The top panel shows the observed sunspot number time series over the last century, the middle panel shows the hemispheric polar field variation reconstructed from polar faculae data and Wilcox Solar Observatory data (blue: north, red: south) and the bottom panel depicts the solar butterfly diagram. Right: The top panel depicts the observed evolution of the radial field on the solar surface (gleaned from Kitt Peak Vacuum Telescope (KPVT), Michelson Doppler Imager (MDI) and Helioseismic and Magnetic Imager (HMI) observations) while the bottom panel depicts the radial field evolution as simulated from a data-driven solar surface flux transport model (Bhowmik and Nandy 2018). The figure on the left drives home the point that the polar field amplitude preceding a sunspot cycle determines the strength of the latter. The figure on the right illuminates the role of propagating “tongues” (surges) of magnetic flux from mid-to-high latitudes in the reversal and build-up of the Sun’s polar field.

distribution like never before, leading to the validation of magnetic field evolution models and accurate data-driven predictions of the sunspot cycle._

## 2 Constraints on high latitude solar plasma flows

In the high beta plasma domain in near-surface layers and within the convection zone, plasma flows drive the magnetic field dynamics. These flows remain poorly constrained in the polar regions which high-latitude measurements of the surface velocity field have the potential to overcome (Loptien et al., 2015). In particular, Dopplergram data would allow us to apply helioseismic methods (Christensen-Dalsgaard, 2002; Gizon and Birch, 2005) to infer solar internal structure and dynamics. Meridional circulation - which plays a critical role in setting the timescale and amplitude of large-scale solar dynamo action and magnetism (Rempel, 2006; Hanasoge, 2022) is rather poorly constrained at the poles. Significant improvements in flow measurements in the vicinity of the polar cap, including the polar extent of the meridional circulation are possible with the magnetic feature tracking technique (Mahajan et al., 2021) applied to observations that do not suffer from projection effects. Such high-latitude observations, when used concurrently with data from existing observatories such as the Helioseismic and Magnetic Imager (HMI), can generate definitive constraints on the polar meridional flow. Such

Figure 2: Left: A snapshot of the surface distribution of magnetic fields from a solar surface magnetic field evolution model depicting a perspective close to the plane-of-the-ecliptic (solar obliquity ignored). Right: The equivalent perspective from the top of the Sun’s North pole reveals details of the polar cap missing from the low-latitude perspective. A mission that can navigate to at least 60 degrees above (or below) the ecliptic plane would reveal these details, constrain the high latitude dynamics and return accurate measurements of plasma flows and magnetic field distribution at the poles that govern solar activity and power fast solar winds.

measurements open up the possibility of (stereoscopic) helioseismic imaging of the plasma flows at deeper layers with greater fidelity; the deep component of the meridional flow is thought to play a critical role in the equatorward propagation and latitude of emergence of sunspots (Nandy and Choudhuri 2002), but its structure and variability remain ill-constrained. Solar internal rotation measurements - one of the greatest successes of helioseismology, is quite noisy in the vicinity of the poles.

_High latitude flows, polar vortices and associated weak rotation, and hints of significant subsurface variability of rotation are among outstanding issues that polar observations can resolve; these new constraints on rotation and meridional circulation in the polar regions can generate powerful constraints on the interplay of flow and fields that sustain solar dynamo action._

**UNRAVELLING THE ENIGMA OF KILO-GAUSS POLAR FLUX PATCHES**

Observations by the Hinode Solar Optical Telescope (SOT) have uncovered the existence of intense small-scale kilo-Gauss flux patches in the high latitude regions of the Sun, often co-existing within, and having the same polarity as the large-scale polar cap (Tsuneta et al. 2008, Ito et al. 2010; red regions in Figure 3). These unipolar flux patches in the polar region appear to be different in nature compared to small-scale mixed polarity flux patches in the quiet Sun, and are believed to sustain open magnetic fields lines in the solar corona which could power the fast solar winds. These unipolar

**Figure 3**: Hinode SOT observations of unipolar, kilo-Gauss flux patches near the solar north pole acquired on 2007 September 25 (from Ito et al. 2010). The field of view extends over 20 degrees of the north polar cap.

patches contribute significantly to the overall flux content in the polar cap and therefore may participate in the dynamo mechanism which converts the poloidal field component to the toroidal field component of the following cycle. These intense flux concentrations are also relevant in the context of the solar open flux problem (Linker et al. 2017; Wang et al. 2022), namely, a mismatch between the expected and observed open flux. The origin of these polar kilo-Gauss flux patches, the evolution of their flux content through the solar cycle, and their relation to the high latitude propagation of magnetic fields leading to polar field build up and reversal remain poorly understood.

High latitude vantage point observations of magnetic fields and flows at different phases of the solar cycle are crucial to deciphering the mystery surrounding the origin of these polar kilo-Gauss flux patches and in conjunction with in-situ solar wind characterization - establish whether they are fundamental to the origin of fast solar winds from the poles.

## Dynamics of the polar atmosphere: jets, plumes and winds

The Sun's poles are often characterized by the presence of coronal holes, open solar magnetic field lines, intense kilo-Gauss flux tubes, polar plumes and jets (Hanaoka et al. 2018), and sometimes pseudo-streamers. Open coronal field lines, ubiquitous in the polar regions are excellent pathways for Alfven wave (turbulent dissipation) mediated solar wind acceleration (Hassler et al. 1999; Krishna Prasad, Banerjee and Gupta 2011; Morton, Tomczyk and Pinto 2015). The strength of the solar polar field during different phases of the cycle and at minima influences the boundaries of open and closed field lines and the tilts of large-scale streamers (Dash et al. 2019). Recent findings hint that Interchange reconnection in coronal holes may power the solar wind; however, proving this would require polar magnetic field measurements (Tripathi, Nived and Solanki 2021; Upendran and Tripathi 2022). All of these polar phenomena play a role in the acceleration and global structuring of fast solar winds, which leave their imprint in the heliosphere and near-Earth space weather (Cranmer, Gibson and Riley 2017).

Adequate constraints on the landscape of the polar magnetic fields and transient phenomena through the solar cycle - achieved via an out-of-ecliptic space mission concept designed for multiple passes over the solar poles - would transform our ability to assess and predict the large-scale structuring of the global solar winds and their heliospheric and space weather consequences, and bring to the fore magnetic connectivity bridging the solar interior to the farthest reaches of the heliosphere.

## Summary Recommendations

_NASA Programs:_ Addressing the novel science presented here necessitates space mission whose scope may either be Moderate-scale to Large-scale depending on whether a single-vantage point, or a multi-vantage point mission concept is planned to address the science. We believe that a proof-of-concept, single-vantage point mission with a quick turn-around time for imaging the magnetic fields of the polar regions and solar atmosphere from at least 60 degrees above the plane-of-the ecliptic during the high latitude dynamics leading up to the next solar minimum (i.e., 2026-2032) time frame, with a nominal mission lifetime of 5-10 years would be a prudent approach (e.g., whitepaper by Hassler et al. 2022). Concurrently, and with the experience of this mission assimilated, a multi-vantage point mission concept may be explored to constrain solar activity and in-situ space environment across the inner heliosphere.

_NSF Programs:_ Theory, numerical simulations, and data analysis of existing observations from ground and space that directly contribute to a holistic understanding of physical processes encompassing the solar interior, atmosphere and the space environment of solar system planets, with a view to establishing causality are necessary elements for community preparedness and the eventual success of future space missions. We believe that mid-scale Research Infrastructure and Innovation programs supported by NSF are therefore crucial to complement any NASA space mission. Specifically, we propose supporting large teams or Centers that leverage and assimilate US and global expertise to develop the theoretical, modeling and data analysis tools that will stand to complement and enable transformative scientific returns from the out-of-ecliptic, multi-vantage point space missions envisaged in this white paper.

_Globally Coordinated Multi-Vantage Point Observations of the Heliosphere:_ We note that existing missions such as Parker Solar Probe, Solar Orbiter, Solar Dynamics Observatory, ACE, WIND, DSCOVR and upcoming missions such as CNSA Advanced Space-based Solar Observatory, ISRO's Aditya-L1 and ESA's Vigil offer the possibility of globally coordinated observations in conjunction with a novel solar polar mission. We recommend that this be taken full advantage of by cementing mechanisms for data exchange across mission teams and leveraging modeling and data analysis expertise across borders. This synergy may catalyze more ambitious, multiagency international programs for system wide exploration of Heliophysics through the deployment of multiple spacecrafts to cover the whole 4nT steradian of the heliosphere (e.g., whitepaper by Raouafi et al. 2022) that may be prohibitively expensive for any one nation alone; this should be the ultimate goal for humanity, to together understand the space we share and use this understanding to guide explorations of other worlds, beyond our own.

## References

* [1]
* [2]Bhowmik, P. and Nandy, D. 2018, Nat Commun 9, 5209 [https://doi.org/10.1038/s41467-018-07690-0](https://doi.org/10.1038/s41467-018-07690-0)
* [3]Brun, A.S. et al. 2015., Space Sci. Rev. 196, 303 [https://doi.org/10.1007/s11214-014-0117-8](https://doi.org/10.1007/s11214-014-0117-8)
* [4]Cameron, R. and Schussler, M. 2015, Science 347, 1333 [https://doi.org/10.1126/science.1261470](https://doi.org/10.1126/science.1261470)
* [5]Charbonneau, P. 2020, Living Rev. Sol. Phys., 17, 4 [https://doi.org/10.1007/s41116-020-00025-6](https://doi.org/10.1007/s41116-020-00025-6)
* [6]Christensen-Dalsgaard, J. 2002, Reviews of Modern Physics, 74, 1073 [https://doi.org/10.1103/RevModPhys.74.1073](https://doi.org/10.1103/RevModPhys.74.1073)
* [7]Cranmer, S.R., Gibson, S.E. and Riley, P. 2017, Space Sci. Rev. 212, 1345 [https://doi.org/10.1007/s11214-017-0416-v](https://doi.org/10.1007/s11214-017-0416-v)
* [8]Daglis, I.A. et al. 2021, Annales Geophysicae, 39, 1013 [https://doi.org/10.5194/angeo-39-1013-2021](https://doi.org/10.5194/angeo-39-1013-2021)
* [9]Dash, S. et al. 2019, Astrophysical Journal, 890, 37 [https://doi.org/10.3847/1538-4357/ab6a91](https://doi.org/10.3847/1538-4357/ab6a91)
* [10]Gizon, L., and Birch, A. C. 2005, Living Reviews in Solar Physics, 2, 6 [https://doi.org/10.12942/lrsp-2005-6](https://doi.org/10.12942/lrsp-2005-6)
* [11]Hanaoka, Y. et al. 2018, Astrophysical Journal, 860, 142 [https://doi.org/10.3847/1538-4357/aac49b](https://doi.org/10.3847/1538-4357/aac49b)
* [12]Hanasoge, S. M. 2022, Living Reviews in Solar Physics, 19, 3 [https://doi.org/10.1007/s41116-022-00034-7](https://doi.org/10.1007/s41116-022-00034-7)
* [13]Hassler, D.M. et al. 1999, Science, 283, 5403 [https://doi.org/10.1126/science.283.5403.810](https://doi.org/10.1126/science.283.5403.810)
* [14]Hassler, D.M. et al. 2022, White paper on Solaris mission SSP Decadal Survey 2024-2033, US National Academy of Sciences
* [15]Ito, H. et al. 2010, Astrophysical Journal, 719, 131 [https://doi.org/10.1088/0004-637X/719/1/131](https://doi.org/10.1088/0004-637X/719/1/131)
* [16]Jiang, J. et al. 2014, Space Sci. Rev., 186, 491 [https://doi.org/10.1007/s11214-014-0083-1](https://doi.org/10.1007/s11214-014-0083-1)
* [17]Jouve, L, Brun, A.S., Aulanier, G. 2018, Astrophysical Journal, 857, 83 [https://doi.org/10.3847/1538-4357/aab5b6](https://doi.org/10.3847/1538-4357/aab5b6)
* [18]Krishna Prasad, S., Banerjee, D., and Gupta, G. 2011, A&A, 528, 4 [https://doi.org/10.1051/0004-6361/201016405](https://doi.org/10.1051/0004-6361/201016405)
* [19]Linker, J.A. et al. 2017, ApJ, 848, 70 [https://doi.org/10.3847/1538-4357/aa8a70](https://doi.org/10.3847/1538-4357/aa8a70)
* [20]Loptien, B., et al. 2015, Space Sci. Rev., 196, 251 [https://doi.org/10.1007/s11214-014-0065-3](https://doi.org/10.1007/s11214-014-0065-3)
* [21]Mahajan, S.S. et al. 2021, ApJ, 917, 100

[https://doi.org/10.3847/1538-4357/ac0a80](https://doi.org/10.3847/1538-4357/ac0a80)

Morton, R., Tomczyk, S. and Pinto, R. 2015, Nat Commun 6, 7813

[https://doi.org/10.1038/ncomms8813](https://doi.org/10.1038/ncomms8813)

Nandy, D. 2021, Sol. Phys., 296, 54

[https://doi.org/10.1007/s11207-021-01797-2](https://doi.org/10.1007/s11207-021-01797-2)

Nandy, D. et al. 2021, Progress in Earth and Planetary Sciences, 8, 1

[https://doi.org/10.1186/s40645-021-00430-x](https://doi.org/10.1186/s40645-021-00430-x)

Nandy, D. and Choudhuri, A.R. 2002, Science 296, 1671

[https://doi.org/10.1126/science.1070955](https://doi.org/10.1126/science.1070955)

Petrie, G.J.D. 2015, Living Rev. Sol. Phys., 12, 5

[https://doi.org/10.1007/lrsp-2015-5](https://doi.org/10.1007/lrsp-2015-5)

Petrovay, K. 2020, Living Rev. Sol. Phys., 17, 2

[https://doi.org/10.1007/s41116-020-0022-z](https://doi.org/10.1007/s41116-020-0022-z)

Raouafi, N.E. et al. 2022, White paper on Firefly mission

SSP Decadal Survey 2024-2033, US National Academy of Sciences

Rempel, M. 2006, Astrophysical Journal, 647, 662

[https://doi.org/10.1086/498440](https://doi.org/10.1086/498440)

Schrijver, C.J. et al. 2015, Adv Space Res., 55, 2745

[https://doi.org/10.1016/j.asr.2015.03.023](https://doi.org/10.1016/j.asr.2015.03.023)

Tripathi, D., Nived, V. N. and Solanki, S. K. 2021, ApJ, 908, 28

[https://doi.org/10.3847/1538-4357/abcc6b](https://doi.org/10.3847/1538-4357/abcc6b)

Tsuneta, S. et al. 2008, Astrophysical Journal, 668, 1374

[https://doi.org/10.1086/592226](https://doi.org/10.1086/592226)

Upendran, V. and Tripathi, D. 2022, ApJ, 926, 138

[https://doi.org/10.3847/1538-4357/ac3d88](https://doi.org/10.3847/1538-4357/ac3d88)

Usoskin, I.G. 2017, Living Rev Sol Phys, 14, 3

[https://doi.org/10.1007/s41116-017-0006-9](https://doi.org/10.1007/s41116-017-0006-9)

Wang, Y.-M. et al. 2022, ApJ, 926, 113

[https://doi.org/10.3847/1538-4357/ac4491](https://doi.org/10.3847/1538-4357/ac4491)

Title: eVAE: Evolutionary Variational Autoencoder
Transcription: # eVAE: Evolutionary Variational Autoencoder

 Zhangkai Wu,1 Longbing Cao, 1 Lei Qi 2

1 University of Technology Sydney

2 Southeast University

berenwu1938@gmail.com, Longbing.Cao@uts.edu.au, qilei@seu.edu.cn

###### Abstract

The surrogate loss of variational autoencoders (VAEs) poses various challenges to their training, inducing the imbalance between task fitting and representation inference. To avert this, the existing strategies for VAEs focus on adjusting the tradeoff by introducing hyperparameters, deriving a tighter bound under some mild assumptions, or decomposing the loss components per certain neural settings. VAEs still suffer from uncertain tradeoff learning. We propose a novel _evolutionary variational autoencoder_ (eVAE) building on the variational information bottleneck (VIB) theory and integrative evolutionary neural learning. eVAE integrates a variational genetic algorithm into VAE with variational evolutionary operators including variational mutation, crossover, and evolution. Its inner-outer-joint training mechanism synergistically and dynamically generates and updates the uncertain tradeoff learning in the evidence lower bound (ELBO) without additional constraints. Apart from learning a lossy compression and representation of data under the VIB assumption, eVAE presents an evolutionary paradigm to tune critical factors of VAEs and deep neural networks and addresses the premature convergence and random search problem by integrating evolutionary optimization into deep learning. Experiments show that eVAE addresses the KL-vanishing problem for text generation with low reconstruction loss, generates all disentangled factors with sharp images, and improves the image generation quality,respectively. eVAE achieves better reconstruction loss, disentanglement, and generation-inference balance than its competitors.

## Introduction

Variational autoencoders [16] (VAEs) have attracted significant interest for their capability of learning continuous and smooth distributions from observations by integrating probabilistic and deep neural learning principles. However, VAEs still face some significant issues, including dynamic uncertainty learning during variational inference and the tradeoff between representation compression and task fitting, despite various recent VAE mechanisms and variants. Below, we briefly analyze these issues and the gaps of existing solutions. A novel evolutionary VAE (eVAE) framework is then introduced to address some of these issues and gaps.

VAEs and Gap AnalysisVAEs have demonstrated significant advantages of incorporating prior knowledge, mapping inputs to probabilistic representations, and approximating the likelihood of outputs. The integration of stochastic gradient variational Bayes (SGVB) estimator [16] with neural settings learns a narrow probabilistic latent space to infer more representative attributes in the hidden space. VAEs have been applied in various domains, including time series forecasting [14], out-of-domain detection in images [15, 16, 17, 18], generating images with spiking signals [19], and generating text by language modeling [20].

Theoretically, the bound optimization of variational inference was introduced to substitute the log-likelihood function with a surrogate function to make it optimized by gradient descent. In practice, the evidence lower bound (ELBO) cannot approach the maximum of conditional likelihood with a close gap between posterior and prior. It causes dynamic uncertainty during inference and failed tradeoff between representation robustness and reconstruction effectiveness. Weak KL divergence could incur KL vanishing while strong KL divergence could result in bad likelihood. The tradeoff is sensitive to posterior distribution disjoint, data characteristics, and network architectures [1].

Recently, various techniques have been proposed to address these issues. The first set aims to adjust the balance in objective functions. Examples are \(\beta\)-VAE incorporating a hyperparameter \(\beta\)[10], InfoVAE adding a scaling parameter to the KL term [17], SA-VAE having a cyclical annealing schedule to progressively increase \(\beta\) for reducing KL vanishing [12], and ControlVAE introducing the proportional-integral-derivative (PID) control to tune the hyperparameter [18]. They are partial solutions only adjusting one part of the objectives, failing to weigh and resolve the balance issue in dynamic settings. Another set is to tune network architectures or VAE settings, e.g., VQ-VAE and their variants [19, 18], spiking VAE [19, 17], multimodal VAE [20], mixture-of-experts multimodal VAE [21] and tuning of their ELBO [19, 18] building on the product of experts structure. However, these models are subject to specifictasks or data settings.

**eVAE** From the information bottleneck perspective, VAEs can be treated as a lossy information compression process. Adjusting the KL within a range controls the information bottleneck flowing from representing latent variables to reconstructing samples, thus benefiting the trade-off between compression and reconstruction [1, 17]. This variational information bottleneck inspires us to improve the VAE mechanism and objective function. To directly address the generation-inference balance in an evolving dynamic setting without constraints on networks and inputs, we introduce a novel evolutionary VAE (eVAE). eVAE incorporates and integrates variational evolutionary learning and variational information bottleneck into VAE to achieve better optimum exploration and the tradeoff between representation compression and generation fitting. However, integrating evolutionary learning into VAE is an open topic. We propose the variational genetic algorithm into eVAE to optimize VAE objectives and its modeling exploration in an evolving manner.

Consequently, eVAE dynamically optimizes the VAE inference (the KL terms) in an evolutionary and probabilistic manner, which further tunes the VAE generation toward balancing generation and inference. To avert premature convergence, eVAE introduces probabilistic chromosome selection for smooth search. To avoid exhaustive random search, we apply the simulated binary crossover [1] and Cauchy distributional mutation to guide the training toward a stable convergence. The main contributions of this work are as follows:

* We propose the eVAE model to balance the tradeoff between generation and inference. Specifically, a Cauchy-based variational mutation operator and an SBX-based variational crossover operator are proposed to train a model with an evolving inner-outer-joint training algorithm, tackling the premature convergence and random search problem when optimizing deep models assisted with a variational genetic algorithm.
* We illustrate eVAE by deriving the lower bound on \(\beta\)-VAE related models under the information bottleneck theory. We analyze the information flow in the corresponding lower bound per the rate-distortion theory to show that only the iteration-specific lower bound in eVAE can capture the optimization trend to train effectively.
* We evaluate eVAE on three tasks: disentangled representation learning on dSprites, image generation on CelebA, and text generation on PTB corpus, respectively.

eVAE forms the first evolutionary VAE framework without empowering constraints on VAE architectures, input settings, and objective function (ELBO). It integrates variational encoding and decoding, information bottleneck, and evolutionary learning into the deep neural framework. The evaluation against the state-of-the-art VAEs shows that eVAE achieves better disentanglement, reconstruction loss, and solve the KL vanishing effectively.

## VAE Background and Issues

Here, we briefly introduce the background of VAEs by focusing on their objectives and approaches to addressing the inference-generation balance since they are mostly relevant to this work. Other developments on VAEs such as adjusting VAE network structures, input settings, and learning constraints are excluded due to their irrelevance to this work.

VaEs mitigate autoencoder issues like sparse representation [10] by learning continuous and smooth representation distribution \(p(x)\), \(x\in\mathcal{X}\) from observations \(\mathcal{X}\) over latent variables \(\mathbf{z}\). After learning an encoding distribution \(q_{\phi}(\mathbf{z}\mid\mathbf{x})\) in encoding neural networks, VAEs apply variational inference to approximate the posterior distribution \(p_{\theta}(\mathbf{x}\mid\mathbf{z})\). Learning tasks such as reconstructed and generated outputs can then be sampled from this learned distribution in a generative process. With the SGVB estimator and reparameterization trick, the gradients become tractable, and the generative parameters \(\theta\) and inference parameters \(\phi\) are learnable. The objectives of VAEs can be converted to ELBO with the expectation over empirical distribution \(p_{\text{data}}\) of the data towards both reconstruction \(\mathcal{L}_{\mathrm{R}}\) and inference \(\mathcal{L}_{\mathrm{I}}\)[10, 1].

\[\begin{split}\mathcal{L}_{ELBO}&=E_{x\sim p_{\text{ data}}}\left[E_{q_{\phi}(\mathbf{z}\mid\mathbf{x})}\left[\log p_{\theta}(\mathbf{x}\mid\mathbf{ z})\right]\right.\\ &\left.-\mathrm{KL}\left(q_{\phi}(\mathbf{z}\mid\mathbf{x})\middle\|p( \mathbf{z})\right)\right]\\ &=E_{x\sim p_{\text{data}}}\mathcal{L}_{\mathrm{R}}+\mathcal{L} _{\mathrm{I}}\end{split} \tag{1}\]

Vae IssuesTo solve ELBO, the inference model \(q_{\phi}(z|x)\) can be trained jointly by maximizing the ELBO to acquire reasonable compression for task fitting. However, a weak capacity of the decoder and the variety of data could make the expressive posterior favor task fitting rather than optimal inference [11]. For example, in variational language generation, the decoder built on autoregressive models such as LSTM and PixelCNN can generate language samples by the autoregressive property rather than the posterior-based latent variables [22]. The VAE degenerates to an autoregressive model where the KL divergence between posterior and prior reaches zero quickly during training. This results in KL vanishing and poor generalization in test for the lack of diversity. The approaches of learning orthogonal transformation of priors with the same distribution by the decoder [10, 11] may sacrifice accurate inference in optimal representation and generalization of fitting the data. Other research attributes the training conflict to the inherent property of bound optimization. For example, under a solid factorial assumption about the posterior distribution [10], i.e.,

\[p(\mathbf{x},\mathbf{z})=p(\mathbf{x}\mid\mathbf{z})\prod_{i}p\left(z_{i}\right), \tag{2}\]

the ELBO constraining the variational samples favors the data fitting [10] but fails to maximize the probability mass on log-likelihood. In addition, the vanilla VAE optimizer strengthens the disjointness between \(q_{\phi}(z|x_{i})\), i.e., \(\mu_{i}\rightarrow\infty,\sigma_{i}\to 0^{+}\), to separate the log-likelihood concentrated on each sample, resulting in maximizing the mass of joint distribution [14].

VAE EnhancementOne way to address the above issues is to tighten the log-likelihood lower bound for correct variational approximation in posterior [1, 13, 15, 16, 17], prior [18, 19] and decomposition of ELBO [14, 15] under some mild assumptions. For example, \(\beta\)-VAE [14] adds the hyper-parameter \(\beta\) to weigh the \(\mathcal{L}_{KL}\) term. Then, ELBO minimizes \(\mathcal{L}_{R}\) to the convergence of data fitting collectively with the regularization \(\mathcal{L}_{I}\) by varying \(\beta\):

\[\begin{split}\mathcal{L}_{ELBO}=& E_{x\sim p_{data}}\left[E_{q_{\phi}(\mathbf{z}| \mathbf{x})}\left[\log p_{\theta}(\mathbf{x}\mid\mathbf{z})\right]\right.\\ &\left.-\beta D_{KL}\left(q_{\phi}(\mathbf{z}\mid\mathbf{x}) \|p(\mathbf{z})\right)\right]\\ =& E_{x\sim p_{\text{data}}}\left[\mathcal{L}_{\text{R}}+ \beta\mathcal{L}_{\text{I}}\right]\end{split} \tag{3}\]

\(\beta\)-VAE introduces some fundamental limitations, which trigger various follow-up research. InfoVAE introduces a scaling parameter \(\lambda\) on the KL-term and converts the objective to [14]:

\[\begin{split}\mathcal{L}_{ELBO}=&\alpha I_{q}( \mathbf{x};\mathbf{z})-D_{KL}\left(q_{\phi}(\mathbf{z}\mid\mathbf{x})\|p( \mathbf{z})\right)\\ &-E_{q(z)}\left[D_{KL}\left(q_{\phi}(\mathbf{z}\mid\mathbf{x}) \|p_{\theta}(\mathbf{x}\|\mathbf{z})\right)\right]\end{split} \tag{4}\]

where \(I_{q}\) is the mutual information with weight \(\alpha\) and \(\alpha+\lambda-1=0\). This linear tuning on the KL shows limitation to dynamic uncertainty.

Further, conditional VAE (CVAE) [15] introduces an initial guess as a conditional variable into the objective function for multimodal data. The SA-VAE involves a cyclical annealing schedule to split the training to multiple cycles starting at \(\beta=0\) and progressively increases \(\beta\) until \(\beta=1\) to reduce the KL vanishing [16]. In ControlVAE, the PID control compares the KL divergence with a set point, with their difference as feedback to the controller to tune the hyperparameter \(\beta(t)\)[14]. ControlVAE thus optimizes KL dynamically but is constrained by the PID controller which follows a separate tuning mechanism from the VAE itself.

The existing work leaves gaps for building an approximate weight allocation between reconstruction and inference, tuning external hypberparameters within the VAE working mechanism and handling these issues in a dynamic manner over an evolutionary learning process. Our eVAE addresses these gaps by incorporating the variational genetic learning into balancing inference and generation and evolutionarily involving their effect into adjusting the VAE learning behaviors toward better uncertain tradeoff learning.

## The eVAE Model

eVAE also tunes the representation-generation balance in Eq. (1) by jointly addressing the following issues in Eqs. (3) and (4): tuning hyperparameter in an outer circle irrelevant to VAE behaviors, non-dynamic optimization, and constrained settings on data and networks. Figure 1 illustrates the eVAE framework of variational evolutionary learning to improve the VAE balance.

eVAE - Evolving Inner-outer-joint Training eVAE implements an evolving learning process of optimizing both VAE and its evolutionary parameters through an inner-outer-joint iterative training process, as shown in Figure 2. At time \(t\), given the input \(x_{t}\in\mathcal{X}\), a VAE inner training process trains a VAE model \(\mathcal{V}\) (we do not constrain the VAE framework, for generality, we use \(\beta\)-VAE for case study in this paper) with some initialization \(\beta_{0}\) to learn the encoder \(q_{\phi}(\mathbf{z}_{t}\mid\mathbf{x}_{t})\), the posterior \(p_{\theta}(\mathbf{x}_{t}\mid\mathbf{z}_{t})\) with prior \(p(\mathbf{z})\). We obtain the VAE inner objective function with initial weight \(\beta_{0}\):

\[\begin{split}\mathcal{L}_{ELBO_{t}}=& E_{x_{t}\sim p _{\mathcal{X}}}\left[E_{q_{\phi}(\mathbf{z}_{t}|\mathbf{x}_{t})}\left[\log p_ {\theta}\left(\mathbf{x}_{t}\mid\mathbf{z}_{t}\right)\right]-\right.\\ &\left.\beta_{0}D_{KL}\left(q_{\phi}\left(\mathbf{z}_{t}\mid \mathbf{x}_{t}\right)\|p(\mathbf{z})\right)\right]\end{split} \tag{5}\]

By applying SGVB and reparameterization trick, the generative process of \(\mathcal{V}\) estimates the posterior as

\[p_{\theta}(\mathbf{x}\mid\mathbf{z})=\prod_{t}p_{\theta}(\mathbf{x}_{t}\mid \mathbf{z}_{t}) \tag{6}\]

where \(\mathbf{x}_{t}\mid\mathbf{z}_{t}\sim\mathcal{N}(\mu(\mathbf{z}_{t};\theta), \Sigma(\mathbf{z}_{t};\theta))\) with \(\mathbf{z}_{t}=\mu_{x_{t}}+\epsilon\Sigma_{x_{t}}\) and \(\epsilon\sim\mathcal{N}(0,I)\).

Then, we introduce an outer variational evolutionary learner \(\mathcal{E}\) (illustrated by a variational genetic algorithm introduced below on Variational Evolution) to optimize the objective in Eq. (5) in an outer process. \(\mathcal{E}\) with the fitness function \(f\) samples a chromosome \(\beta_{t}\) from an evolving distribution \(\beta_{t}\sim\mathcal{R}\) and evolves it by taking variational crossover and mutation to generate and improve parameters \(\beta_{t+1}\).

The evolved parameter is then incorporated into \(\mathcal{V}_{t}\) for the next iteration \(t+1\) training. With the relevant ELBO information back-propagated to tune the VAE network and optimize the relevant parameters, we obtain the updated reconstruction and inference performance. Consequently, Eq. (5) is evolved to:

\[\begin{split}\mathcal{L}_{ELBO_{t+1}}=& E_{x_{t+1} \sim p_{\mathcal{X}}}\left[E_{q_{\phi}(\mathbf{z}_{t+1}|\mathbf{x}_{t+1})} \left[\log p_{\theta}\left(\mathbf{x}_{t+1}\right.\\ &\left.\mid\mathbf{z}_{t+1})\right]-\beta_{t+1}D_{KL}\left(q_{ \phi}\left(\mathbf{z}_{t+1}\mid\mathbf{x}_{t+1}\right)\|p(\mathbf{z})\right) \right]\end{split} \tag{7}\]

If the fitness Eq. (17) is satisfied, we update \(\beta\) by \(\beta_{t+1}\). This then results in updated \(\mathcal{V}_{t+1}\) and its parameters \(\phi_{t+1}\), \(\theta_{t+1}\) and \(\beta_{t+1}\) for iteration \(t+1\). We further repeat the above VGA \(\mathcal{E}\) to obtain another set of parameters and retrain model \(\mathcal{V}_{t+1}\) until it converges.

The above inner-outer iterative training progresses over time and samples in the generative process to iteratively optimize the balance between reconstruction (i.e., minimizing \(\mathcal{L}_{R}=\|x_{t}-\hat{x}_{t}\|\) with the reconstructed \(\hat{x}_{t}\)) and inference (i.e., seeking appropriate \(\mathcal{L}_{I}\)) and the VAE learning behaviors. The VAE \(\mathcal{V}\) is then optimized until converges.

Accordingly, the eVAE generative process optimizes the following objective function:

\[\begin{split}\mathcal{L}_{eVAE}=&\min_{\theta_{t}, \phi_{t}}\sum_{t=1}^{N}\mathcal{L}_{ELBO_{t+1}}\left(\theta_{t},\phi_{t}\ ;\right.\\ &\left.f\left(\mathcal{E}\left(\phi_{t},\theta_{t},\{\beta\}, \mathcal{L}_{ELBO_{t}}\right)\right),\mathbf{x}_{t}\right)\end{split} \tag{8}\]

to approach \(\beta^{*}\) for the optimal balance between representation and construction:

\[\beta^{*}\sim f\left(\mathcal{E}\left(\{\beta\}\mid\phi_{t},\theta_{t}, \mathcal{L}_{ELBO_{t}}\right)\right) \tag{9}\]The overall ELBO of eVAE can then be represented by:

\[\begin{array}{l}\mathcal{L}_{eVAE}=E_{x_{\phi d_{\theta}}(\mathbf{z}_{i}| \mathbf{x}_{i})}\log p_{\theta}(\mathbf{x}_{t}\mid\mathbf{z}_{t})+\\ f_{\beta_{t}\sim R}(\beta_{t},\mathcal{E})D_{KL}(q_{\phi}\left(\mathbf{z}_{t} \mid\mathbf{x}_{t}\right)\left\|p(\mathbf{z})\right)\\ =E_{x_{t+1}\sim p_{\mathcal{E}}}[\mathcal{L}_{R}+f(\beta)\mathcal{L}_{I}+ \mathcal{E}(\Delta\mathcal{L}_{ELBO})]\end{array} \tag{10}\]

### Variational Evolution in eVAE

Here, we introduce the variational evolutionary learner \(\mathcal{E}\) optimizing the parameters. We instantiate \(\mathcal{E}\) by a variational genetic algorithm (VGA) with its variational crossover and mutation operations. This avoids typical issues including premature convergence and random search during discordant exploitation and exploration.

#### Variational Genetic Algorithm

eVAE integrates the VGA-based outer parameter optimization combined with the VAE-internal gradient descent-based optimization. Accordingly, VGA consists of a few variational steps and operations, initialization, variational crossover (V-crossover), variational mutation (V-mutation), and variational evaluation (V-evaluation). As shown in the bottom part of Figure 2, below, we introduce them respectively.

_Chromosome selection_: To enable a larger and more smooth GA search space compatible with VAEs, chromosomes are embedded by a continuous variable \(\beta\), sampled from an evolving distribution \(\mathcal{R}\) (e.g., in the crossover). Assume \(L\) individual chromosomes forming a candidate group \(\{\beta_{l}\}=\{\beta_{1},\ldots,\beta_{L}\}\), a chromosome is chosen from this candidate group to train the VAE, which is associated with a fitness value \(f\) after the VGA operations and VAE retraining. We thus have the chromosome-fitness pairs embedded for the VGA evolution and offspring selection over generations, such as:

\[\{\beta,f\}=((\beta_{1},f_{1}),\ldots,(\beta_{L},f_{L})) \tag{11}\]

for optimizing the inner-outer joint training.

_V-crossover_: Paired chromosomes at time \(t-1\) and \(t\) are crossovered to generate new genes for improving the genetic variety of offsprings. Following the simulated binary crossover (SBX) [4] method, we implement the following crossover operations \(\mathcal{C}\) to induce a large search space evolving over chromosome \(\beta_{t-1}\) at time \(t-1\) and chromosome \(\beta_{t}\) selected from the chromosome candidate group \(\{\beta_{l}\}\) at time \(t\) to obtain the offspring candidate chromosome \(\beta_{t+1}\) for the next time \(t+1\) in \(\mathcal{C}\) strategy:

\[\mathcal{C}:\left\{\begin{array}{l}\beta_{t+1}=\frac{1}{2}[(1+r_{c})\beta_{ t,t}+(1-r_{c})\beta_{t-1}],\textit{or}\\ \beta_{t+1}=\frac{1}{2}[(1-r_{c})\beta_{t,t}+(1+r_{c})\beta_{t-1}]\end{array}\right. \tag{12}\]

where \(r_{c}\) is the crossover rate, which is drawn from a probability density function \(P_{c}(r_{c})\):

\[P_{c}\left(r_{c}\right)=\begin{cases}0.5(\eta+1)r_{c}^{n},&\text{if }r_{c}\leq 1\\ 0.5(\eta+1)\frac{1}{r_{c}^{\frac{1}{n+2}}},&\text{otherwise}\end{cases} \tag{13}\]

by concentrating their corresponding parents \(\beta_{t-1}\) and \(\beta_{l,t}\). By sampling \(r_{c}\) from the following function:

\[r_{c}=\begin{cases}(2u)^{\frac{1}{n+1}},&\text{if }u\leq 0.5\\ \left(\frac{1}{2(1-u)}\right)^{\frac{1}{\eta+1}},&\text{otherwise}\end{cases} \tag{14}\]

where \(u\) is a random variable, and \(\eta\) is a hyper-parameter for scaling, the offsprings \(\beta_{t+1}\) can then be created by selecting the better \(\mathcal{C}\) strategy (i.e., better satisfying Eq. (17)).

_V-mutation_: The crossover-generated offsprings can be further mutated to improve their genomic diversity and evolutionary capacity. Aligning with the V-crossover, a variational mutation strategy \(\mathcal{M}\) is taken to diversify the offspring to update \(\beta_{t+1}\) inherited from crossover or \(\beta_{t}\) from the current moment. With a relatively small probability \(p_{m}\), a chromosome \(\beta_{t+1}\) selected from group is mutated as:

\[\mathcal{M}:\beta_{t+1}=\beta_{t+1}+r_{m} \tag{15}\]

where \(r_{m}\) is a random variable sampled from the Cauchy distribution \(p_{m}\):

\[P_{m}=\frac{1}{\pi}(\frac{1}{1+\beta_{t+1}^{2}}) \tag{16}\]

Figure 1: The framework of eVAE. The VAE results inform the chromosome sampling. The genes are then updated by variational V-crossover and V-mutation. The evolved results are checked per fitness for \(t+1\) retraining, giving up, or converging.

V-evaluation & VGA fitness functionThe chromosomes updated by the V-crossover and V-mutation operations are evaluated in alignment with the VAE objectives to determine whether they are transferable to the next generation. Within the VAE framework, we take the following heuristic fitness function \(f\) to guide the evolution of chromosomes and their fitness to VAE objectives. The fitness function integrates the direction of VAE-oriented stochastic gradient descent and the distance to the optimal KL divergence to achieve multi-objectives.

\[f_{t+1}=\Delta\mathcal{L}_{ELBO_{t+1}}+||KL_{t+1}(\beta_{t+1})-c|| \tag{17}\]

where \(\Delta\mathcal{L}_{ELBO_{t+1}}\) is:

\[\Delta\mathcal{L}_{ELBO_{t+1}}=\mathcal{L}_{ELBO_{t+1}}(\beta_{t+1})-\mathcal{ L}_{ELBO_{t}}(\beta_{t}) \tag{18}\]

denoting the VAE's ELBO difference after applying the evolved \(\beta\). \(c\) is the task-specific information bottleneck, which ensures the bound optimization of eVAE over the evolutionary optimization.

This V-evaluation and the fitness \(f\) guide eVAE to converge and balance the reconstruction and inference with enhanced evolutionary parameterization. The larger the fitness value, the stronger the chromosome in its candidate group, which forms a strong pair \(\{\beta^{*},f^{*}\}\).

The whole training processes of the eVAE model is illustrated in Algorithm 1 in the Supplementary Material A.

## Theoretical Analysis

In this paper, eVAE takes \(\beta\)-VAE as a case study of evolutionary VAE. Hence, we analyze the effects of eVAE in adjusting \(\beta\)-VAE parameters, tradeoff between reconstruction and regularization, and training performance below.

\(\beta\)-VAE directly tunes hyperparameter \(\beta\) setting a task-relevant ratio between the inference loss \(\mathcal{L}_{1}\) and the generation loss \(\mathcal{L}_{\text{R}}\). In essence, incrementally regularizing \(\mathcal{L}_{1}\) by \(\beta\) is equivalent to maximizing the likelihood on an experiment-specific threshold, i.e., a constant \(C\), (Higgins et al., 2017):

\[\max_{\phi,\theta}E_{x\sim\text{p}_{\text{data}}}\mathcal{L}_{R}\quad\text{ s.t. }\beta\mathcal{L}_{I}<C \tag{19}\]

This learning process can be interpreted in information bottleneck (IB) theory (Alemi et al., 2018). The \(\beta\mathcal{L}_{I}\) constraint operates as the bottleneck, compressing the capacity of latent variable \(Z\) organized from input \(X\) to expressively represent the target \(\hat{X}\)(Alemi et al., 2017). Accordingly, IB maximizes \(I(Z,\hat{X})\) to acquire a concise representation:

\[\max I(Z,\hat{X})\quad\text{ s.t. }I(X,Z)\leq I_{c} \tag{20}\]

Further, the variational information bottleneck (VIB) introduces an experiment-specific lower bound for optimization:

\[\mathcal{L}_{\beta-VAE}(\theta,\phi)=-D-\beta_{C}R\leq-\beta_{C}I-D \tag{21}\]

where \(R\) refers to the compression rate, and \(D\) refers to the distortion measuring the representation relevance to a task, and \(\beta_{C}\) is an experiment-specific constant. VAEs can thus be viewed as a process of achieving the rate-distortion tradeoff.

ControlVAE is a variant of \(\beta\)-VAE, tuning the KL-specific \(\beta_{KL}\) with a PID control to a desired KL point:

\[\mathcal{L}_{ControlVAE}(\theta,\phi)=-D-\beta_{KL}R\leq-\beta_{KL}I-D \tag{22}\]

eVAE extends \(\beta\)-VAE tuning the information bottleneck \(\beta I(X,Z)\) by a variational evolutionary learner \(\mathcal{E}\). After iteration \(t\) of outer training, \(\beta_{t}\) evolves to fit the task and training phase, guided by the fitness function \(f\). eVAE generates a lower bound to optimize iteration \(t+1\) of the inner training phase:

\[\mathcal{L}_{eVAE}\leq-\mathcal{E}(\beta_{t})I_{t}-\mathcal{E}(\beta_{t})D_{t} \tag{23}\]

where an evolving iteration-specific lower bound can strike a compromise between task fitting in \(-\mathcal{E}(\beta_{t})D_{t}\) and inference quality in \(\mathcal{E}(\beta_{t})I_{t}\). The derivations of Eq. (21) and Eq. (23) can be found in the Supplementary Materials B and C.

We further compare the VIB effects of eVAE against VAE, \(\beta\)-VAE and ControlVAE by the rate-distortion (R-D) curve in Figure 3. VAE (yellow) tends to sacrifice empirical error minimization for representation learning in the early stage, where the rate is optimized to decrease in a quarter of the iterations. As for \(\beta\)-VAE (green), due to the experiment-specific lower bound (\(-\beta_{C}I-D\)), the distortion cannot be minimized. ControlVAE (pink) concentrates on optimizing the distortion initially to fit data and optimizing the rate eventually to acquire smooth representation, resorting to the KL-specific lower bound (\(-\beta_{KL}I-D\)). However, directly modifying \(\beta\) by the given PID controller leads to fluctuations between inference capacity and reconstruction quality during the iterations. Rather than monitoring the optimization process, eVAE generates an iteration-specific lower bound (\(-\mathcal{E}(\beta_{t})I_{t}-\mathcal{E}(\beta_{t})D_{t}\)) to achieve a balance between minimizing distortion and controlling rate.

## Experiments

We evaluate eVAE in three typical tasks: disentangled representation, image generation, and language modeling.

Figure 2: eVAE - inner-outer joint evolutionary training process. The upper part shows the VAE training at time \(t\), the objectives are then incorporated into the lower part - the outer training by variational genetic algorithm, whose fitness-based optimized results are fed to the VAE for further training.

### Dataset and Baselines

Three different learning tasks and their datasets are listed below to evaluate eVAE against the VAE baselines.

**Disentangled representation** learns independent latent variables to generate an image. We validate eVAE on dSprites, a 2D-shape dataset with 737,280 binary images generated by six ground-truth factors: shape (square, ellipse, heart), scale, orientation, position \(x\), and position \(y\). To examine the disentanglement performance and image generation equally and comprehensively, \(\beta\)-VAE and ControlVAE are compared.

**Image generation** reconstructs an imagery sample based on given datapoints. The CelebA dataset (cropped version) [14] is used, which is a real-world celebrity face dataset with 202,599 RGB images. The baselines are \(\beta\)-VAE and ControlVAE.

**Language modeling** conducts the word-level text generation. The Penn Treebank dataset (PTB) with English corpus [17] is used. To reveal the performance of restraining KL vanishing, we compare eVAE with three heuristic methods: cost annealing (noted as Cost-10k) [1], cyclical annealing (Cyc-8) [21], and PID control (PID-3) [20].

For a fair comparison, we adopt the same embedding network as \(\beta\)-VAE and tune eVAE to achieve the same KL set point as ControlVAE. The VAE architectures and hyperparameter settings are given in Supplementary Material D.

### Performance Evaluation

**Performance of disentangled representation learning** Here, we validate the performance of reconstructing a sharp image with disentangled features. Figure 5(a) shows that eVAE achieves a lower reconstruction loss of 9.2, compared with ControlVAE under the same expected KL divergence (KL = 19). Moreover, Figure 5(a) and (b) show that eVAE presents a more stable training curve than other VAEs because of its dynamic weighting guided by the VGA fitness function, rather than a direct modification in \(\beta\)-VAE and ControlVAE. The variation of each disentangled factor is illustrated in Figure 5(c). Figure 6 further demonstrates the reliable disentanglement of all factors and sharp reconstruction quality of eVAE under a set point KL = 19. In contrast, ControlVAE captures the generative factors of scale, \(x\) and \(y\) while \(\beta\)-VAE entangles other four factors except scale.

**Performance of image generation** We evaluate eVAE on CelebA for image generation. For a fair and concise comparison, the KL set point is set to 200 achieving the best reconstruction quality in [20]. eVAE is tuned to achieve the desired KL point similar to ControlVAE. Figure 4(a) shows that eVAE has the lowest reconstruction error compared with vanilla VAE and ControlVAE. Guided by the evolving \(\beta\), the KL divergence in eVAE can achieve a desired point dynamically, as illustrated in Figure 4(b).

**Performance of language modeling** To show the validity of eVAE in preventing the variational language model from degenerating to a standard language model, we draw the learning curves of KL, reconstruction loss, and weight of KL over iterations. The evolution of \(\beta\) is shown in Figure 7(a), demonstrating that eVAE can learn to tune \(\beta\) over iterations automatically rather than by a heuristic setting. Figure 7(b) shows that the Cost annealing (Cost-10k) model still suffers from KL vanishing, with KL approaching 0 at the end of iterations. By contrast, the Cyclical annealing (Cyc-8), PID, and GA can converge to a nonzero divergence, while eVAE achieves the lowest reconstruction loss to 70 in word generation, illustrated in Figure 7(c). Further, compared to the PID control, VGA can find a path toward a more stable stage, without undergoing reconstruction fluctuations during training even if the non-zero learned \(\beta\) is fixed.

## Conclusion

We propose evolutionary VAE (eVAE) to dynamically learn the tradeoff between reconstruction effectiveness and inference robustness in VAEs. eVAE involves variational evolving operators to solve the premature convergence and random search problem. SGD optimization and genetic algorithm synergistically follow an inner-outer-joint training mechanism in eVAE. Following the variational information bottleneck theory, eVAE derives an iteration-specific lower bound balancing the capacity of compression and decompression over iterations. Multiple task experiments show that eVAE outperforms SOTA VAEs in traversing samples with more disentangled features, generating sharp images with lower reconstruction loss, and resolving the KL vanishing automatically in variational language modeling. We will extend eVAE to other VAE models and tasks.

Figure 4: Performance comparison of different VAEs for image generation on CelebA.

Figure 3: The information plane with the \(R-D\) curves of VAE, \(\beta\)-VAE, ControlVAE and eVAE on dSprites.

Figure 5: Learning curves on dSprites1. (a,b) indicate that eVAE has the lowest reconstruction loss compared with VAE (\(\beta=1\)), \(\beta\)-VAE (\(\beta=4\)), and ControlVAE (KL = 19) under a fixed KL point KL=19. (c) is the element-wise KL divergence as a function of iterations in eVAE. We can observe that eVAE retains a stable and reasonable KL divergence of each generator dimension (factor): position-\(y\) (z2), scale (z3), shape (z4), position-\(x\) (z6), orientation (z7). More comparisons in terms of generated KL divergence can be found in Supplementary Material E.More comparisons in terms of generated KL divergence can be found in Supplementary Material E.

Figure 6: Latent traversal on dSprites. To distinguish the latent factors visually, we take the ellipse for illustration. Each row represents a latent factor in the traversal, while keeping others fixed. The first column refers to the seed image for initialization, and we then manipulate the latent dimension \(z\) across the range [-3, 3].

Figure 7: Learning curves on PTB for language modeling. The suffix of PID and VGA refer to a KL set point i.e., KL = 3; Cyc-8 indicates 8 iteration cycles where the weight increases linearly from 0 to 1; Cost-10k refers to 10k iterations during which the weight increases from 0 to 1 by a sigmoid function iteratively.

## References

* Alemi et al. (2018) Alemi, A.; Poole, B.; Fischer, I.; Dillon, J.; Saurous, R. A.; and Murphy, K. 2018. Fixing a broken ELBO. In _ICML_.
* Alemi et al. (2017) Alemi, A. A.; Fischer, I.; Dillon, J. V.; and Murphy, K. 2017. Deep variational information bottleneck. In _ICLR_.
* Berliner et al. (2022) Berliner, A.; Rotman, G.; Adi, Y.; Reichart, R.; and Hazan, T. 2022. Learning discrete structured variational auto-encoder using natural evolution strategies. In _ICLR_.
* Bowman et al. (2016) Bowman, S. R.; Vilnis, L.; Vinyals, O.; Dai, A. M.; Jozefowicz, R.; and Bengio, S. 2016. Generating sentences from a continuous space. In _CONLL_.
* Bozkurt et al. (2021) Bozkurt, A.; Esmaeili, B.; Tristan, J.-B.; Brooks, D. H.; Dy, J. G.; and van de Meent, J.-W. 2021. Rate-regularization and generalization in VAEs. _AISTATS_.
* Burda, Grosse, and Salakhutdinov (2016) Burda, Y.; Grosse, R.; and Salakhutdinov, R. 2016. Importance weighted autoencoders. In _ICLR_.
* Burgess et al. (2018) Burgess, C. P.; Higgins, I.; Pal, A.; Matthey, L.; Watters, N.; Desjardins, G.; and Lerchner, A. 2018. Understanding disentangling in \(\beta\)-VAE. In _NeurIPS_.
* Deb and Beyer (2001) Deb, K.; and Beyer, H.-G. 2001. Self-adaptive genetic algorithms with simulated binary crossover. _Evolutionary Computation_, 9(2): 197-221.
* Domke and Sheldon (2019) Domke, J.; and Sheldon, D. R. 2019. Divide and couple: Using monte carlo variational objectives for posterior approximation. In _NeurIPS_.
* Esmaeili et al. (2019) Esmaeili, B.; Wu, H.; Jain, S.; Bozkurt, A.; Siddharth, N.; Paige, B.; Brooks, D. H.; Dy, J.; and Meent, J.-W. 2019. Structured disentangled representations. In _AISTATS_.
* Fortuin et al. (2019) Fortuin, V.; Huser, M.; Locatello, F.; Strathmann, H.; and Ratsch, G. 2019. Som-vae: Interpretable discrete representation learning on time series. In _ICLR_.
* Fu et al. (2019) Fu, H.; Li, C.; Liu, X.; Gao, J.; Celikyilmaz, A.; and Carin, L. 2019. Cyclical annealing schedule: A simple approach to mitigating KL vanishing. In _NAACL_.
* Ghosh et al. (2019) Ghosh, P.; Sajjadi, M. S.; Vergari, A.; Black, M.; and Scholkopf, B. 2019. From variational to deterministic autoencoders. In _ICLR_.
* Havtorn et al. (2021) Havtorn, J. D. D.; Frellsen, J.; Hauberg, S.; and Maaloe, L. 2021. Hierarchical VAEs know what they don't know. In _ICML_.
* Higgins et al. (2017) Higgins, I.; Matthey, L.; Pal, A.; Burgess, C.; Glorot, X.; Botvinick, M.; Mohamed, S.; and Lerchner, A. 2017. \(\beta\)-VAE: Learning basic visual concepts with a constrained variational framework. In _ICLR_.
* Jankowiak and Phan (2022) Jankowiak, M.; and Phan, D. 2022. Surrogate likelihoods for variational annealed importance sampling. In _ICML_.
* Kamata, Mukuta, and Harada (2022) Kamata, H.; Mukuta, Y.; and Harada, T. 2022. Fully spiking variational autoencoder. _AAAI_.
* Khemakhem et al. (2020) Khemakhem, I.; Kingma, D.; Monti, R.; and Hyvarinen, A. 2020. Variational autoencoders and nonlinear ICA: A unifying framework. In _AISTATS_.
* Kingma and Welling (2013) Kingma, D. P.; and Welling, M. 2013. Auto-encoding variational bayes. _arXiv_.
* Klushyn et al. (2019) Klushyn, A.; Chen, N.; Kurle, R.; Cseke, B.; and van der Smagt, P. 2019. Learning hierarchical priors in VAEs. In _NeurIPS_.
* Kviman et al. (2022) Kviman, O.; Melin, H.; Koptagel, H.; Elvira, V.; and Lagergren, J. 2022. Multiple importance sampling ELBO and deep ensembles of variational approximations. In _AISTATS_.
* Liu et al. (2015) Liu, Z.; Luo, P.; Wang, X.; and Tang, X. 2015. Deep learning face attributes in the wild. In _ICCV_.
* Locatello et al. (2019) Locatello, F.; Abbati, G.; Rainforth, T.; Bauer, S.; Scholkopf, B.; and Bachem, O. 2019. On the fairness of disentangled representations. In _NeurIPS_.
* Marcinkiewicz (1994) Marcinkiewicz, M. A. 1994. Building a large annotated corpus of English: The penn treebank. _Using Large Corpora_.
* Mita, Filippone, and Michiardi (2021) Mita, G.; Filippone, M.; and Michiardi, P. 2021. An identifiable double VAE for disentangled representations. In _ICML_.
* Nalisnick et al. (2019) Nalisnick, E.; Matsukawa, A.; Teh, Y. W.; Gorur, D.; and Lakshminarayanan, B. 2019. Do deep generative models know what they don't know? In _ICLR_.
* Ran et al. (2022) Ran, X.; Xu, M.; Mei, L.; Xu, Q.; and Liu, Q. 2022. Detecting out-of-distribution samples via variational autoencoder with reliable uncertainty estimation. _Neural Networks_.
* Razavi et al. (2019) Razavi, A.; Van den Oord, A.; and Vinyals, O. 2019. Generating diverse high-fidelity images with VQ-VAE-2. In _NeurIPS_.
* Ruiz et al. (2021) Ruiz, F. J.; Titsias, M. K.; Cemgil, T.; and Doucet, A. 2021. Unbiased gradient estimation for variational autoencoders using coupled markov chains. In _UAI_.
* Shao et al. (2020) Shao, H.; Yao, S.; Sun, D.; Zhang, A.; Liu, S.; Liu, D.; Wang, J.; and Abdelzaher, T. 2020. Controlvae: Controllable variational autoencoder. In _ICML_.
* Shi et al. (2019) Shi, Y.; Paige, B.; Torr, P.; et al. 2019. Variational mixture-of-experts autoencoders for multi-modal deep generative models. In _NeurIPS_.
* Sohn et al. (2015) Sohn, K.; Lee, H.; and Yan, X. 2015. Learning structured output representation using deep conditional generative models. In _NeurIPS_.
* Sutter et al. (2021) Sutter, T. M.; Daunhawer, I.; and Vogt, J. E. 2021. Generalized multimodal ELBO. _arXiv_.
* Tolstikhin et al. (2017) Tolstikhin, I.; Bousquet, O.; Gelly, S.; and Schoelkopf, B. 2017. Wasserstein autoencoders. _arXiv_.
* Tomczak and Welling (2018) Tomczak, J.; and Welling, M. 2018. VAE with a vampprior. In _AISTATS_.
* Wang and Wang (2019) Wang, P. Z.; and Wang, W. Y. 2019. Neural gaussian copula for variational autoencoder. In _EMNLP_.
* Wu, Wang, and Zhang (2019) Wu, D.; Wang, L.; and Zhang, P. 2019. Solving statistical mechanics using variational autoregressive networks. _Physical Review Letters_, 122(8): 080602.
* Xiao, Yan, and Amit (2020) Xiao, Z.; Yan, Q.; and Amit, Y. 2020. Likelihood regret: An out-of-distribution detection score for variational auto-encoder. _NeurIPS_.
* Zhang et al. (2019) Zhang, Y.; Wang, Y.; Zhang, L.; Zhang, Z.; and Gai, K. 2019. Improve diverse text generation by self labeling conditional variational auto encoder. In _ICASSP_.
* Zhao, Song, and Ermon (2019) Zhao, S.; Song, J.; and Ermon, S. 2019. InfoVAE: Balancing learning and inference in variational autoencoders. In _AAAI_.

## References

* Alemi et al. (2018) Alemi, A.; Poole, B.; Fischer, I.; Dillon, J.; Saurous, R. A.; and Murphy, K. 2018. Fixing a broken ELBO. In _ICML_.
* Alemi et al. (2017) Alemi, A. A.; Fischer, I.; Dillon, J. V.; and Murphy, K. 2017. Deep variational information bottleneck. In _ICLR_.
* Berliner et al. (2022) Berliner, A.; Rotman, G.; Adi, Y.; Reichart, R.; and Hazan, T. 2022. Learning discrete structured variational autoencoder using natural evolution strategies. In _ICLR_.
* Bowman et al. (2016) Bowman, S. R.; Vilnis, L.; Vinyals, O.; Dai, A. M.; Jozefowicz, R.; and Bengio, S. 2016. Generating sentences from a continuous space. In _CONLL_.
* Bozkurt et al. (2021) Bozkurt, A.; Esmaeili, B.; Tristan, J.-B.; Brooks, D. H.; Dy, J. G.; and van de Meent, J.-W. 2021. Rate-regularization and generalization in VAEs. _AISTATS_.
* Burda, Grosse, and Salakhutdinov (2016) Burda, Y.; Grosse, R.; and Salakhutdinov, R. 2016. Importance weighted autoencoders. In _ICLR_.
* Burgess et al. (2018) Burgess, C. P.; Higgins, I.; Pal, A.; Matthey, L.; Watters, N.; Desjardins, G.; and Lerchner, A. 2018. Understanding disentangling in \(\beta\)-VAE. In _NeurIPS_.
* Deb and Beyer (2001) Deb, K.; and Beyer, H.-G. 2001. Self-adaptive genetic algorithms with simulated binary crossover. _Evolutionary Computation_, 9(2): 197-221.
* Domke and Sheldon (2019) Domke, J.; and Sheldon, D. R. 2019. Divide and couple: Using monte carlo variational objectives for posterior approximation. In _NeurIPS_.
* Esmaeili et al. (2019) Esmaeili, B.; Wu, H.; Jain, S.; Bozkurt, A.; Siddharth, N.; Paige, B.; Brooks, D. H.; Dy, J.; and Meent, J.-W. 2019. Structured disentangled representations. In _AISTATS_.
* Fortuin et al. (2019) Fortuin, V.; Huser, M.; Locatello, F.; Strathmann, H.; and Ratsch, G. 2019. Som-vae: Interpretable discrete representation learning on time series. In _ICLR_.
* Fu et al. (2019) Fu, H.; Li, C.; Liu, X.; Gao, J.; Celikyilmaz, A.; and Carin, L. 2019. Cyclical annealing schedule: A simple approach to mitigating KL vanishing. In _NAACL_.
* Ghosh et al. (2019) Ghosh, P.; Sajjadi, M. S.; Vergari, A.; Black, M.; and Scholkopf, B. 2019. From variational to deterministic autoencoders. In _ICLR_.
* Havtorn et al. (2021) Havtorn, J. D. D.; Frellsen, J.; Hauberg, S.; and Maaloe, L. 2021. Hierarchical VAEs know what they don't know. In _ICML_.
* Higgins et al. (2017) Higgins, I.; Matthey, L.; Pal, A.; Burgess, C.; Glorot, X.; Botvinick, M.; Mohamed, S.; and Lerchner, A. 2017. \(\beta\)-VAE: Learning basic visual concepts with a constrained variational framework. In _ICLR_.
* Jankowiak and Phan (2022) Jankowiak, M.; and Phan, D. 2022. Surrogate likelihoods for variational annealed importance sampling. In _ICML_.
* Kamata, Mukuta, and Harada (2022) Kamata, H.; Mukuta, Y.; and Harada, T. 2022. Fully spiking variational autoencoder. _AAAI_.
* Khemakhem et al. (2020) Khemakhem, I.; Kingma, D.; Monti, R.; and Hyvarinen, A. 2020. Variational autoencoders and nonlinear ICA: A unifying framework. In _AISTATS_.
* Kingma and Welling (2013) Kingma, D. P.; and Welling, M. 2013. Auto-encoding variational bayes. _arXiv_.
* Klushyn et al. (2019) Klushyn, A.; Chen, N.; Kurle, R.; Cseke, B.; and van der Smagt, P. 2019. Learning hierarchical priors in VAEs. In _NeurIPS_.
* Kviman et al. (2022) Kviman, O.; Melin, H.; Koptagel, H.; Elvira, V.; and Lagergren, J. 2022. Multiple importance sampling ELBO and deep ensembles of variational approximations. In _AISTATS_.
* Liu et al. (2015) Liu, Z.; Luo, P.; Wang, X.; and Tang, X. 2015. Deep learning face attributes in the wild. In _ICCV_.
* Locatello et al. (2019) Locatello, F.; Abbati, G.; Rainforth, T.; Bauer, S.; Scholkopf, B.; and Bachem, O. 2019. On the fairness of disentangled representations. In _NeurIPS_.
* Marcinkiewicz (1994) Marcinkiewicz, M. A. 1994. Building a large annotated corpus of English: The penn treebank. _Using Large Corpora_.
* Mita, Filippone, and Michiardi (2021) Mita, G.; Filippone, M.; and Michiardi, P. 2021. An identifiable double VAE for disentangled representations. In _ICML_.
* Nalisnick et al. (2019) Nalisnick, E.; Matsukawa, A.; Teh, Y. W.; Gorur, D.; and Lakshminarayanan, B. 2019. Do deep generative models know what they don't know? In _ICLR_.
* Ran et al. (2022) Ran, X.; Xu, M.; Mei, L.; Xu, Q.; and Liu, Q. 2022. Detecting out-of-distribution samples via variational autoencoder with reliable uncertainty estimation. _Neural Networks_.
* Razavi et al. (2019) Razavi, A.; Van den Oord, A.; and Vinyals, O. 2019. Generating diverse high-fidelity images with VQ-VAE-2. In _NeurIPS_.
* Ruiz et al. (2021) Ruiz, F. J.; Titsias, M. K.; Cemgil, T.; and Doucet, A. 2021. Unbiased gradient estimation for variational autoencoders using coupled markov chains. In _UAI_.
* Shao et al. (2020) Shao, H.; Yao, S.; Sun, D.; Zhang, A.; Liu, S.; Liu, D.; Wang, J.; and Abdelzaher, T. 2020. Controlvae: Controllable variational autoencoder. In _ICML_.
* Shi et al. (2019) Shi, Y.; Paige, B.; Torr, P.; et al. 2019. Variational mixture-of-experts autoencoders for multi-modal deep generative models. In _NeurIPS_.
* Sohn et al. (2015) Sohn, K.; Lee, H.; and Yan, X. 2015. Learning structured output representation using deep conditional generative models. In _NeurIPS_.
* Sutter et al. (2021) Sutter, T. M.; Daunhawer, I.; and Vogt, J. E. 2021. Generalized multimodal ELBO. _arXiv_.
* Tolstikhin et al. (2017) Tolstikhin, I.; Bousquet, O.; Gelly, S.; and Schoelkopf, B. 2017. Wasserstein autoencoders. _arXiv_.
* Tomczak and Welling (2018) Tomczak, J.; and Welling, M. 2018. VAE with a vampprior. In _AISTATS_.
* Wang and Wang (2019) Wang, P. Z.; and Wang, W. Y. 2019. Neural gaussian copula for variational autoencoder. In _EMNLP_.
* Wu, Wang, and Zhang (2019) Wu, D.; Wang, L.; and Zhang, P. 2019. Solving statistical mechanics using variational autoregressive networks. _Physical Review Letters_, 122(8): 080602.
* Xiao, Yan, and Amit (2020) Xiao, Z.; Yan, Q.; and Amit, Y. 2020. Likelihood regret: An out-of-distribution detection score for variational auto-encoder. _NeurIPS_.
* Zhang et al. (2019) Zhang, Y.; Wang, Y.; Zhang, L.; Zhang, Z.; and Gai, K. 2019. Improve diverse text generation by self labeling conditional variational auto encoder. In _ICASSP_.
* Zhao, Song, and Ermon (2019) Zhao, S.; Song, J.; and Ermon, S. 2019. InfoVAE: Balancing learning and inference in variational autoencoders. In _AAAI_.

## Supplementary Materials - eVAE: Evolutionary Variational Autoencoder

Here, we present some supplemental materials to the main content, including the eVAE algorithm, the experimental settings, the latent traversal on square and heart, and derivation of the variational lower and upper bounds.

## Appendix A The eVAE algorithm

Below, Algorithm 1 illustrates the modeling process of eVAE, which enables an inner-outer-joint training of VAE and evolutionary learning iteratively.

```
1:Input: crossover rate \(Pr_{c}\), mutation rate \(Pr_{m}\), batch data x.
2:Output:\(\{\beta^{*},f^{*}\}\)
3:Initialization: parameters of decoder \(\theta\), parameters of encoder \(\phi\), \(\{\beta_{l}\}=\{\beta_{1},\dots,\beta_{L}\}\)//initialize group
4:while\(t<T\)do
5:\(Pr_{t}\leftarrow\) sample from \(N\left(0,1\right)\)//probability to evolve
6:if\(Pr_{t}<Pr_{m}\)then
7:\(\theta_{t}\), \(\phi_{t}\)//savecurrent variational parameters
8: generate \(\beta_{t+1}\) by V-crossover operation \(\mathcal{C}(\beta_{t-1},\beta_{t})\) by Eqs. (12), (13) and (14)
9: evaluate \(\beta_{t+1}\) by \(f(\mathcal{E}(\phi_{t},\theta_{t},\{\beta\},\mathcal{L}_{ELBO_{t}}))\) by Eqs. (17) and (18)
10:elseif\(Pr_{t}<Pr_{c}\)then
11:\(\theta_{t}\), \(\phi_{t}\)//savecurrent variational parameters
12: generate \(\beta_{t+1}\) by V-mutation operation \(\mathcal{M}(\beta_{t})\) by Eqs. (15) and (16)
13: evaluate \(\beta_{t+1}\) by fitness function \(f(\mathcal{E}(\phi_{t},\theta_{t},\{\beta\},\mathcal{L}_{ELBO_{t}}))\) by Eqs. (17) and (18)
14:else
15:\(\{\beta^{*},f^{*}\}\leftarrow\beta_{l}\)//select the strongest pair
16:\(\theta_{t+1},\phi_{t+1}\leftarrow\mathcal{L}_{eVAE}(\theta_{t},\phi_{t},\beta^ {*}|\mathbf{x}_{t})\)//update variational parameters
17:endif
18:Return:\(\{\beta^{*},f^{*}\}\)
19:endwhile
```

**Algorithm 1** Evolving Inner-outer-joint Training

## Appendix B Derivation of \(\beta\)-VAE lower bound

According to the VIB theory, elbo can be bounded by distortion \(D=-E_{q_{\theta}(x,z)}[\log p_{\theta}(x\mid z)]\) and rate \(R=E_{q_{\theta}(x,z)}[D_{KL}(q_{\phi}(z|x)||p(z))]\), where \(I(X,Z)\) has the upper bound \(I\leq R\):

\[\begin{split} R&=\int q(x)\int q_{\theta}(z\mid x )\log\frac{q_{\theta}(z\mid x)}{p(z)}\\ &=I(X,Z)+TC(Z)\\ &\geq I(X,Z)\end{split} \tag{24}\]

and the lower bound \(I\geq H-D\):

\[\begin{split} I&=\int dxdzp(x,z)\log\frac{p(x\mid z )}{p(x)}\\ &\geq\int dxdzp(x,z)\log\frac{q(x\mid z)}{p(x)}\\ &=\int dxdzp(x,z)\log q(x\mid z)\\ &-\int dxp(x)\log p(x)\\ &=\int dxdzp(x,z)\log q(x\mid z)\\ &+H(X)\\ &=H-D\end{split} \tag{25}\]

All in all, the variational information bottleneck can be regarded as:

\[H-D\leq I\leq R \tag{26}\]

where \(H\) is the entropy of the data.

In \(\beta\)-VAE framework, \(\beta_{C}\) impose a experiment-specific constraint on compressor and decompressor, giving the variational lower bound:

\[\begin{split} H-D&\leq I\leq R\\ H-D&\leq\beta I\leq\beta R\\ H&\leq\beta I+D\leq\beta R+D\end{split} \tag{27}\]

In summary, the lower bound can be denoted as:

\[\mathcal{L}_{\beta-VAE}(\theta,\phi)=-D-\beta_{C}R\leq-\beta_{C}I-D \tag{28}\]

## Appendix C Derivation of eVAE lower bound

According to Eq. (10) and Eq. (17), we can obtain the loss function of eVAE in iteration \(t\) as follows:

\[\begin{split}\mathcal{L}_{eVAE}&=E_{\mathbf{x}\sim q _{\phi}(\mathbf{x}_{t}|\mathbf{x}_{t})}\log p_{\theta}(\mathbf{x}_{t}\mid \mathbf{z}_{t})+\\ & f_{\beta_{t}\sim R}(\beta_{t},\mathcal{E})D_{KL}(q_{\phi}( \mathbf{z}_{t}\mid\mathbf{x}_{t})||p(\mathbf{z}))\\ &=E_{x_{t+1}\sim p_{X}}[\mathcal{L}_{R}+f(\beta_{t})\mathcal{L}_ {I}+\mathcal{E}(\Delta\mathcal{L}_{ELBO})]\\ &=E_{x_{t+1}\sim p_{X}}[\mathcal{L}_{R}+f(\beta_{t})\mathcal{L}_ {I}\\ &+\mathcal{E}(\Delta\mathcal{L}_{ELBO_{t+1}}+||KL_{t+1}(\beta_{t+1 })-c||)]\\ \end{split} \tag{29}\]

According to the VIB theory, \(R_{t}\) sets the upper bound on information bottleneck \(I_{t}(X_{t},Z_{t})\) in \(t\)-th iteration :

\[\begin{split} R_{t}&=\int q(x_{t})\int q_{\theta}(z_{t }\mid x_{t})\log\frac{q_{\theta}(z_{t}\mid x_{t})}{p(z_{t})}\\ &=I_{t}(X_{t},Z_{t})+TC(Z_{t})\\ &\geq I_{t}(X_{t},Z_{t})\end{split} \tag{30}\]and \(D_{t}\) sets the lower bound:

\[\begin{split} I_{t}&=\int dxdzp(x_{t},z_{t})\log\frac{p (x_{t}\mid z_{t})}{p(x_{t})}\\ &\geq\int dxdzp(x_{t},z_{t})\log\frac{q(x_{t}\mid z_{t})}{p(x_{t} )}\\ &=\int dxdzp(x_{t},z_{t})\log q(x_{t}\mid z_{t})\\ &-\int dxp(x_{t})\log p(x_{t})\\ &=\int dxdzp(x_{t},z_{t})\log q(x_{t}\mid z_{t})\\ &+H(X)\\ &=H-D_{t}\end{split} \tag{31}\]

After optimized by a variational evolutionary learner \(\mathcal{E}\), the loss function of eVAE constrained by a dynamic lower bound is as follows:

\[\begin{split}\mathcal{L}_{eVAE}&=E_{\mathbf{z}\sim q _{\phi}(\mathbf{z}_{t}|\mathbf{x}_{t})}\log p_{\theta}(\mathbf{x}_{t}\mid \mathbf{z}_{t})+\\ & f_{\beta_{t}\sim R}\left(\beta_{t},\mathcal{E}\right)D_{KL}(q_ {\phi}(\mathbf{z}_{t}\mid\mathbf{x}_{t})\|p(\mathbf{z}))\\ &=E_{x_{t+1}\sim p_{\mathcal{X}}}[\mathcal{L}_{R}+f(\beta_{t}) \mathcal{L}_{I}+\mathcal{E}(\Delta\mathcal{L}_{ELBO})]\\ &=E_{x_{t+1}\sim p_{\mathcal{X}}}[\mathcal{L}_{R}+f(\beta_{t}) \mathcal{L}_{I}\\ &+\mathcal{E}(\Delta\mathcal{L}_{ELBO_{t+1}}+||KL_{t+1}(\beta_{t+ 1})-c||)]\\ &=-D_{t}-\beta_{t}R_{t}-\mathcal{E}(-D_{t+1}-\beta_{t+1}R_{t+1}+D _{t}+c)\\ &\leq-\mathcal{E}(\beta_{t})D_{t}-\mathcal{E}(\beta_{t})I_{t} \end{split} \tag{32}\]

where \(c\) is the desired KL point and \(\beta_{t}\) is a chromosome sample in \(t\)-th iteration.

## Appendix D Experimental settings

Table 1 shows the experimental settings of the three learning tasks for evaluating eVAE. We give the settings of the encoder-decoder network architectures and the parameters for the evolutionary learning on three datasets dSprites, CelebA, and PTB and their corresponding optimizers.

## Appendix E Analysis of element-wise KL divergence in disentangled representation learning

Figure 8 further shows the element-wise KL divergence evolving over iterations of three VAE models: \(\beta\)-VAE and ControlAVE in comparison with our eVAE on the dataset dSprites.

Tuple 43:
Cleaned Title: blockchain technology smart energy system fundamental challenge solution
Cleaned Transcription: blockchain technology smart energy system fundamental challenge solutionsnnnaveed ul hassan chau yuen andnnnaveed ul hassan electrical engineering department lahore university management science lums dha lahore cantt pakistan email naveedhassanlumsedupkchau yuen engineering product development singapore university technology design sutd somapah road singapore email yuenchausutdedusgdusit niyato school computer engineering nanyang technological university singapore email dniyatontuedusgthis research supported lahore university management science faculty initiative fund fif pakistan partly supported natural science foundation china jiangsu province project bknntechnology solution category blockchains posse several unique feature decentralization creation trustless network node resolve conflict without centralized authority data storage tamperproof manner fault tolerance auditability however noted choice technology solution significant impact resulting blockchain feature performancennthe use blockchain smart energy system topic tremendous research interest development system could potentially benefit integration new innovative technology blockchain due unique feature facilitate numerous smart energy application example figure depict blockchain concept potential role two emerging smart energy application figure blockchain technology used facilitate pp energy trading application energy prosumers trade surplus energy neighbor however introduction blockchain intermediary broker eliminated data recorded blockchain verified distributed network node automation achieved computer program called smart contract stored blockchain define contractual obligation well transfer asset peer another application blockchain shown figure verification green energy energy added grid becomes difficult identify green energy traditional energy however consumer verify renewable energy generated prosumer use blockchain technology example demonstrate overall concept blockchain technology use smart energy system however exact blockchain technology solution network data consensus etc converge fulfill requirement application obviousnnfigure pp energy trading help blockchainnnthere several research paper project ongoing trial aim leverage unique blockchain feature advance digitalization smart energy system review blockchain technology energy sector found author provide comprehensive review classification blockchain based project energy sector author explore potential challenge blockchain based pp microgrids discus framework incorporates technological economic social environment institutional dimension paper suggests inclusion economic social environmental dimension bridge gap technology institution author review blockchain based smart grid project discus framework blockchain integration smart grid according framework creation cyber layer designed blockchain application aggregation computing resource microgrids smart grid protection security issue leveraged achieve better integration blockchain smart grid blockchain integration effort internet thing iot also discussed important note none paper identify exact choice blockchain technology solution different smart energy system applicationsnnblockchain technology relatively new although hold tremendous potential number blockchain technology solution implementation platform still developing choice blockchain technology solution fulfill requirement different smart energy application eg shown figure entirely obvious paper provide review blockchain building block followed identification suitable blockchain technology according requirement various smart energy system example blockchain network management technique classified public consortium private category similarly data management technique classified onchain data stored blockchain offchain data hash stored blockchain type different combination technology option result different blockchain implementation platform different feature performance review important existing blockchain platform representative blockchain based smart energy project four different domain include smart infrastructure si energy trading et green initiative gi energy management em review discover reveal existing blockchain platform arennfigure distributed green energy management help blockchainnnnot entirely suitable smart energy system therefore order achieve appropriate integration blockchain technology solution smart energy application first consider sixteen requirement represent need broad selection smart energy application analyze suitability different blockchain technology fulfilling requirement determine appropriate blockchain building block various smart energy application summarize major contribution followingnn present review blockchain fundamental discus various blockchain building block include network data consensus identity automation management techniquesn review existing blockchain platform classify representative blockchainbased smart energy project si et gi em domain show large number project use blockchain building block computing resource intensive hence le efficient term data identity managementn list requirement smart energy system organize different category namely decentralization trust data management security scalability based requirement identify suitable blockchain building block suitable smart energy system applicationsn customize blockchain technology solution multiple energy application within domain si et gi emn also identify open research area related blockchain technology needed fulfill future need smart energy systemsnnthe rest paper organized follows section ii present blockchain fundamental different blockchain technology solution section iii review blockchain integration effort smart energy system section iv identify appropriate blockchain technology solution various smart energy application section v discus blockchain technology gap smart energy integration conclude paper section vinn ii blockchainnnin section present blockchain various blockchain building technology network data consensus identity automation management key point section also summarized table inn blockchain fundamentalsnnblockchain decentralizeddigitaldistributed ledger set transaction may indicate transfer exchange monetary value digital asset information service good produced collected distributed network computing node pp network timestamped data block containing transaction created decentralized consensus mechanism among node according predefined protocol newly created block also contains reference block came parent block form cryptographic hash thus establishing link block new block added front parent block chain like structure block obtained hence get name blockchain shown figure blockchain grows sufficient size transaction recorded become practically immutable resistant change moreover blockchain trustless network node also created trustless network nontrustingnodes interact without centralized entity intermediary conflict automatically resolved help protocolsnn blockchain technology solutionsnnblockchain creation maintenance requires network data consensus identity automation management present various blockchain technology option category discus advantage disadvantagesnnblockchain network management blockchain network management classified three category nnpublic n public blockchain network truly decentralized permissionless node join leave network node full permission maintain complete copy blockchain referred public blockchain node issue transaction participate block creation process according publicly defined protocol algorithmsnnnnconsortium n consortium blockchain network permissioned network ability node join network access blockchain controlled group organization assign permission node across organization join network read modify associated consortium blockchain situation node outside consortium may also allowed access read consortium blockchain content achieve greater transparency however node allowed modify blockchain statennprivate n private blockchain network also permissioned network network controlled single organization allows limited number node within organization join network read modify state private blockchainnndata management blockchain record transaction store data two broad technique blockchain data management nnonchain onchain data management transaction stored blockchain size blockchain continuously grows storage requirement keep increasing method suitable resource constrained nodesnnoffchain offchain data management hash value data transaction stored blockchain raw transaction data stored using traditional method method storage requirement network node significantly reduced however additional requirement eg synchronization database blockchain availability server hosting raw datannconsensus management choice nodenodes entrusted create new block depends consensus algorithm adopted blockchain network consensus algorithm allow node network agree world view state blockchain different type consensus algorithm nnproof work c proof work pow algorithm node compete solve appropriate hashing puzzle requires expensive computing resource block created node fastest solve given puzzle accepted network method useful permissionless network avoid sybil attack sybil attack single node may vote multiple time different identity influence vote outcome however pow energy intensive waste tremendous amount resourcesnnproof stake c proof stake po algorithm node selected create new block pseudorandom fashion probability node selected proportional economic stake network algorithm also suitable permissionless blockchain punishes misbehaving node confiscating stake network however method prone nothing stake attacknnvotingbased c permissioned blockchain network known node join network consensus among validating node content new block achieved voting mechanism voting scheme based byzantine fault tolerant bft algorithm variant tendermint federated bft method multiple round voting might required reach consensus also significant networking overhead negative impact network scalabilitynnauthoritybased c proof authority poau algorithm also used certain blockchain network mechanism authorized trusted node network create new block round robin fashion poau eliminates message exchange among node consensus building resourceefficient however inclusion trustednodes reduces trustless nature resulting blockchain networknnidentity management blockchain network relies public key cryptography node pair publicprivate key sign verify transaction different way manage identity entitlement blockchain node nnselfsovereign identity method every node owns control identity without relying external authority attestation verification node credential central server personal data required identity creation node perform identity proofing gathering attribute ecosystem identity provider node allowed create multiple key required keep identity private node also selectively disclose attribute maintain privacy sovrin uport example selfsovereign identity management systemsnndecentralizedtrusted identity method requires central server perform identity proofing node initial stage node provide identity proof personal information central server bootstrap phase node identity recorded blockchain later validation verified node create key required shocard bitid example decentralizedtrusted identity management systemnnautomation management automation management blockchain carried help smart contract may define contractual obligation custody transfer digital asset right privilege node smart contract provide greater automation replicate action generally performed trusted third party intermediary turingcomplete programming language support arbitrary logic computation generally required develop smart contract broadly classify smart contract two type nndeterministic smart contract deterministic smart contract require information external party necessary information execute smart contract obtained data already stored blockchainnnnondeterministic smart contract nondeterministic smart contract depend information called oracle data feed external party eg may need external weather information execution nondeterministic smart contract provides greater flexibility expense greater vulnerability external attacksnnthere wide variety blockchain technology solution combination blockchain building block also result different tradeoff different blockchain feature addition requirement different smart energy application also different however identifying best possible blockchain technology solution various smart energy application first provide brief review existing blockchain platform blockchain integration effort smart energy systemsnn iii review blockchain integration smart energy systemsnnin section review blockchain integration effort smart energy system please note section intend provide complete survey blockchain integration effort smart energy system comprehensive review classification blockchain based project energy sector available section present selected platform project smart energy domain objective reveal effort use blockchain technology customized energy application thisreview facilitate u identification suitable blockchain technology solution according requirement smart energy system contribution section summarized table ii figure nn review blockchain platform used smart energy systemsnnblockchain platform combine network data consensus identity automation management technology creation blockchain based project blockchain integration smart energy application carried either using opensource proprietary blockchain platform popular opensource platform include ethereum hyperledger tendermint energy web foundation ewf proprietary platform developed suite requirement specific application sometimes platform also develop proprietary management protocol algorithm noted majority opensource proprietary platform nonmodular nnethereum ethereum generic open source blockchain development platform governed ethereum developer widely used developing blockchain application smart energy system platform developed public n blockchain management however opensource code ethereum easily modified maintain consortium n private n network ethereum support onchain data management pow c consensus algorithm currently used plan switch po c algorithm platform support selfsovereign well decentralizedtrusted identity management technique ethereum support turingcomplete programming language solidity serpent used create deterministic well nondeterministic smart contractsnnhyperledger hypberledger opensource blockchain development platform supported linux foundation platform used set consortium n private n network platform support onchain data management votingbased consensus c algorithm platform support selfsovereign well decentralized trusted identity management technique turingcomplete programming language java go solidity fabric rust allow writing deterministic smart contract however support nondeterministic smart contract oracle yet availablenntendermint tendermint another application oriented framework used set public consortium private network pp node nnn platform support onchain data management votingbased c consensus algorithm platform support selfsovereign well decentralizedtrusted identity management technique platform support various turingcomplete programming language currently allows writing deterministic smart contract tnnewf ewf blockchain platform supported company aim integrate accelerate blockchain technology smart energy system ewf platform ethereumcompliant customized smart energy application ewf platform used set consortium n private n network support chaindata management poau c consensus algorithm platform support selfsovereign well decentralizedtrusted identity management technique deterministic nondeterministic smart contract developed turing complete c c programming language tobalaba test version platform already available developersnnnnproprietary several proprietary blockchain platform also exist smart energy application example solar banker developing proprietary consensus algorithm called obelisk run skychain blockchain idea based developing trusted consortium node generate validate data block similarly prosume also developing proprietary blockchain based platform support multitude smart energy application nnin table ii provide summary blockchain technology solution supported platformsnn review blockchain based smart energy projectsnnwe review blockchain based smart energy project four smart energy domain include si et gi em domain broad cover several interesting useful application list domain considered application domain presented figure short notation application also introduced use paper example si notation used automated metering infrastructure ami application scenario figure represents et application figure represents em applicationnndue space limitation following discus representative project domain detail project found reference thereinnnblockchain project si domainnnfigure smart energy system domain applicationsnnnnbankymoon project related ami si application smart meter compute communicate energy consumption industrial residential building regular interval billing automation reduction electricity theft incident however bankymoon project blockchain enabled smart meter developed experimented order automate financial transaction meter loaded cryptocurrencies payment settled realtime smart contract project developed using ethereum platformnnthesunexchange project related asset management si application high initial cost re technology could become barrier taking community offgrid however issue may resolved creating shared asset smart energy system eg purchasing solar pvs crowdfunding thesunexchange project allows user purchase solar panel lease earn passive income blockchain integration enables transparent management asset well management solar energy produced asset therefore project also classified example example em application related distributed emnngridchain ponton project related power grid monitoring si application power grid iot sensor transmission distribution system facilitate monitoring grid parameter order automate fault diagnosis maintain powerbalance grid stability blockchain integration help achieving transparency fixing liability context objective gridchain project developed ponton enable realtime power balance congestion management providing coordination various grid entity project also classified example realtime drm application emnnblockchain project et domainnnenerchain ponton project deal wholesale energy trading et application integration blockchain energy trading application achieves greater transparency automation enerchain project also developed ponton enable wholesale energy trading european regional power market project aim offer wholesale energy trading solution different time frame dayahead monthly quarterly yearlynnbrooklyn microgrid project related pp energy trading et application shown figure smart energy system prosumers engage decentralized energy trading activity directly trade energy prosumers consumer brooklyn microgrid project example realworld development blockchain based pp energy trading solution project prosumers directly sell surplus energy neighbor without needing broker intermediary energy transaction recorded blockchain payment settled automatically smart contractsnnblockchain project gi domainnnnasdaq linq project related management trading green certificate carbon credit gi application encourage re uptake several country state issue green certificate carbon credit also traded however greater integration re power grid management certificate becoming challenging context nasdaq linq project aim bring efficiency quick verification elimination paper record green certificate management integration blockchain projectis developed using proprietary platformnnnrgeoin project related management incentive green behavior gi application project nrgcoins given reward incentivize local production consumption green energy noted nrgcoin equivalent kwh energy use virtual currency project creates additional value around blockchain however unlike bitcoin coin mined issued blockchain developer smart contract framework project based ethereum platformnnblockchain project em domain drm important concept smart energy grid however blockchain based project em em application relatively rarennkeyenergy project related distributed energy management em application project blockchain used energy management multiapartment house objective maximize profit house selling pv energy minimizing energy cost shared facility building platform detail project availablenncar ewallet number ev battery increasing due mobility management ev energy consumption becomes quite challenging car ewallet project related ev em application project provides blockchain based solution car sharing car rental ev charging project also allows automatic processing paymentsnnin table ii blockchain platform used project also identified noted several blockchain platform except ewf exclusively developed smart energy application therefore embedded technology option platform also entirely suitable application example large number project use ethereum embeds computingintensive pow algorithm similarly several platform lack capability support offchain data management well nondeterministic smart contract management also important note blockchain based smart energy project still development trial phase realworld implementation rare context order guide research development field need identify appropriate blockchain technology solution according requirement smart energy system next section discus requirement accordingly identify appropriate choice blockchain technology solution various applicationsnn iv appropriate choice blockchain technology according smart energy system requirementsnnwe first discus suitable blockchain technology solution according requirement smart energy system followed customization solution various application summarize key contribution section table iii ivnn suitable blockchain technology solution according smart energy system requirementsnnwe first discus total sixteen requirement rr four different category applicable broad selection smart energy application listed figure scenario depicted figure nndecentralization trust requirementsnndecentralization r due inclusion re mobile load ev architecture smart energy system becoming decentralized efficient implementation various application different domain requires decentralized networking controlnnconflict resolution mechanism r smart energy domain involve interaction multiple nontrusting node mechanism entity technology therefore required mediate node order resolve conflictsnnintermediaries r several smart energy application intermediary required support activity principal player role intermediary arise due operational technological limitation principal player example financial transaction consumer generator mostly settled bank similarly broker energy trading platform required match buying selling requirement generator consumersnnnonrepudiability r nonrepudiability refers availability irrefutable proof performed certain action even node cooperating smart energy domain nonrepudiability required establish liabilitynndata management requirementsnntamperproof record keeping r recording trading transportation electricity asset resource involved various smart energy system also important note several situation electricity flow occurs almost immediately financial settlement carried later therefore becomes important store data tamperproof mannernndata correction erasure r event malfunction hacking tampering sensor equipment wrong data could get recorded event detected reported data correction data erasure becomes essential increased automation smart energy domain require certain ability correct erase erroneous datanndata backup r data loss create inconvenience disruption financial loss similarly data storage retrieval single database also requires permanent availability data hosting node thus single point failure created centralized system data collected various smart energy system domain often critical important therefore requires adequate backup ensure smooth operationsnnprivacy protection r various smart energy system high requirement keep data node identity private example smart meter data reveals private information habit schedule behavior usersnnsecurity requirementsnnauthentication r authentication concerned determining identity node system order block unauthorized access node authenticated unique credential system eg public key address name smart energy system often involve critical data infrastructure therefore authentication always required smart energy domainsnnauthorization r authorization deal managing access privilege various node network smart energy system node different role therefore require different authorization different applicationsnnin addition also certain role regulatory body government agency therefore appropriate authorization detecting violation privilege right required systemsnndata integrity r data integrity refers detection unauthorized change data decentralized architecture requires large number critical message exchanged various node data integrity violation result safety problem harmful attack critical infrastructurennauditability r auditability concerned ability reconstruct complete history certain event action historical record smart energy system auditability required fix liability case malfunction conflict safeguard commercial financial interest fulfill regulatory requirementsnnscalability requirementsnnthroughput r smart energy system single node often produce small amount data however large number node involved build meaningful application data requirement single node considered single transaction large number transaction happen every second therefore smart energy system require high data throughoutnnlatency r smart energy application require low latency order ensure smooth monitoring control operation appliance equipment process latency critical application eg required grid stabilization msnnprocess automation r smart energy system built promise making re integration energy transportation energy trading efficient achieved increased process automation resulting reduction human intervention simplification legacy proceduresnncost r smart energy system integrate novel technology new equipment smart meter sensor etc help reduce various operating cost however high upfront cost due equipment replacement technology upgradation major barrier adoption various concept context smart energy domain benefit cost reductionsnnbased requirement determine suitability blockchain technology solution various smart energy system application suitability analysis presented table iii analysis carried matching feature advantage disadvantage various blockchain technology solution discussed section ii smart energy system requirement based analysis consortium n private n network management emerge suitable option system offchain data management also fulfill requirement compared onchain data management technique similarly authoritybased consensus management c best consensus algorithm smart energy system selfsovereign identity management deterministic smart contract fulfill requirement analysis enables quick identification appropriate blockchain technology solution smart energy system however different smart energy application pp energy trading distributed green energy management shown figure also slightly different requirement hence also need customize blockchain technology solution various smart energy applicationsnnnn customization blockchain technology solution various smart energy applicationsnnrequirements smart energy application differ necessitate customization blockchain technology solution example application require low latency require high privacy protection etc subsection identify appropriate blockchain technology solution various smart energy application shown figure discussion also summarized table ivnnsi domain ami si application relatively relaxed latency throughput requirement application consortium n private n network management technique used private network management preferred data directly handled utility since smart meter resource constrained node offchain data management technique suitable consensus management po c poau c algorithm better option application requires high privacy protection however regulatory registration requirement smart meter utility company selfsovereign identity management used instead decentralizedtrusted identity management suitable option moreover necessary automation required managed help deterministic smart contract asset management si application relatively low privacy throughput requirement application choice network data consensus automation management si managing shared re po c suitable option however low latency requirement poau c algorithm preferable identity management selfsovereign well decentralizedtrusted identity management suitable however know customer kyc requirement applicable selfsovereign technique also used grid monitoring application extremely stringent latency requirement m application network data identity automation management option identified si application howeverdue extremely low latency requirement poau c suitable consensus management solution application however even algorithm fail meet required performancennet domain wholesale energy trading application relatively low privacy requirement therefore public consortium network management technique nn suitable n used trading platform developed across multiple regional market localized pp energy trading et application consortium network management technique n suitable application offchain data management technique suitable consensus option suitable et et pow c avoided resourceintensive poau c algorithm also avoided et application requires trusted node network dilutes trustless feature blockchain identity management scheme may used et et similarly application choice deterministic nondeterministic smart contract tt made based availability information inside outside network execution smart contract information required ingredient build best blockchain pp energy trading scenario depicted figure easily identifiednngi domain privacy requirement green certificate gi application le stringent suitable blockchain technology solution application identified et application behavior incentive gi application le stringent latency throughput requirement choice network data identity automation management identified si application however consensus votingbased c technique used limited number node network poau c technique also adopted conserve resourcesnnem domain contractbased drm em application suitable technology option identified si application however realtime drm em application due extremely low latency requirement poau c algorithm suitable choice option remain identified em distributed energy management em application suitable technology option network data identity automation management identified et application however application due relatively low latency requirement po c poau c technique suitable consensus management finally suitable technology option ev em application identified et application except em also use poau c algorithm conserve resourcesnn v blockchain technology gap smart energy systemsnnblockchain still evolving several technology gap could limit adaptation smart energy system discus blockchain technology gap smart energy systemsnnnetwork management management blockchain network requires appropriate protocol algorithm protocol required transaction forwarding data dissemination node discovery maintaining list misbehaving node limit number peer connection performance protocol direct impact latency throughput speed transaction processing context need develop delayaware securityaware privacyaware scalable network management protocol blockchain integration smart energy system moreover protocol must also provide flexible parameter order achieve various tradeoff according latency throughput requirement smart energy applicationsnndata management implementation offchain data management mostly required resource constrained node smart energy system challenging requires synchronization availability conventional database context determination optimal amount data kept onchain offchain various application important storage offchain data tamperproof manner also challenging furthermore data model database schema also vary across different organization application novel technique handling multiple type data model database schema query processing blockchain also requirednnconsensus management poau algorithm fastest consensus management algorithm however latency throughput requirement application extremely stringent m even poau may fail fulfill requirement clear need improvement consensus management technique smart energy application example use implicit consensus proposed maybe explorednnidentity management several smart energy application due kyc requirement enforced regulator decentralizedtrusted identity scheme used scheme le advantage compared private selfsovereign identity management scheme recovering compromised identity also become challenge smart energy system particularly node private critical datannautomation management security smart contract critical smart contract wellwritten secure may hacked invoked different circumstance may represent actual intention original programmer nondeterministic smart contract management present even bigger security challenge smart energy application involving critical data industrial infrastructure necessitate appropriate program template development secure wellwritten smart contract smart contract execution often require sequential processing slow transaction verification development appropriate sharding technique parallel processing therefore required match high performance demand various applicationsnnlack suitable implementation platform many popular blockchain platform nonmodular embed appropriate technology solution smart energy system example platform lack support offchain data management nondeterministic smart contract mostly required resource constrained node therefore development open source modular blockchain platform appropriate embedded technology support multiple smart energy application critically needednn vi conclusionnnblockchain technology novel complicated integration domain requires convergence appropriate building block achieve respective desired objective existing blockchain integration effort smart energy system mostly use opensource blockchain platform embedded functionality platform entirely designed energy application development blockchain based energy project platform may provide expected blockchain integration benefit paper adopted systematic approach first collected requirement smart energy system detailing requirement smart energy domain determined suitable blockchain building block respective smart energy system accordingly identified blockchain technology meet requirement customized blockchain technology various smart energy application si et gi em domain analysis paper help design flexible blockchain platform customized smart energy system well reaping benefit blockchain integration smart energy system significant new research blockchain technology still required meet diverse often stringent latency privacy security requirement smart energy application moreover modular blockchain platform embedded technology option changed demand would also required support accelerate blockchain integration wide variety smart energy applicationsnn referencesnn liserre sauter j hung future energy system integrating renewable energy source smart power grid industrial electronics ieee industrial electronics magazine vol pp n h farhangi road map integration perspective smart grid development ieee power energy magazine vol pp n strasser p siano ding method system smart energy city ieee transaction industrial electronics vol pp n hafez k bhattacharya integrating ev charging station smart load demand response provision distribution system ieee transaction smart grid vol pp n sousa soares p pinson f moret baroche e sorin peertopeer communitybased market comprehensive review renewable sustain energy review vol pp n w tushar c yuen h mohsenianrad saha h v poor k l wood transforming energy network via peer peer energy trading potential game theoretic approach ieee signal processing magazine vol pp nn hustveit j frogner se fleten tradable green certificate renewable support role expectation uncertainty energy vol pp n h haider h see w elmenreich review residential demand response smart grid renewable sustainable energy review vol pp n k yu b yang j yang demandside energy management considering price oscillation residential building heating ventilation system ieee transaction industrial informatics n f tschorsch b scheuermann bitcoin beyond technical survey decentralized digital currency ieee communication survey tutorial vol pp n narayanan j bonneau e felten miller goldfeder bitcoin cryptocurrency technology comprehensive introduction princeton university press n vukolic rethinking permissioned blockchains acm workshop blockchain cryptocurrencies contract pp n x xu weber staple l zhu j bosch l bass c pautasso p rimba taxonomy blockchainbased system architecture design ieee icsa pp n dinh r liu zhang g chen b c ooi j wang untangling blockchain data processing view blockchain system ieee transaction knowledge data engineering vol pp n p dunphy f petitcolas first look identity management scheme blockchain ieee security privacy vol pp n alharby van moorsel blockchainbased smart contract systematic mapping study arxiv preprint arxiv n andoni v robu flynn abram geach jenkins p mccallum peacock blockchain technology energy sector systematic review challenge opportunity renewable sustainable energy review vol pp n ahl yarime k tanaka sagawa review blockchainbased distributed energy implication institutional development renewable sustainable energy review vol pp n musleh g yao muyeen blockchain application smart gridreview framework ieee access n panarello n tapa g merlino f longo puliafito blockchain iot integration systematic survey sensor vol p n ali vecchio pincheira k dolui f antonelli h rehmani application blockchains internet thing comprehensive survey ieee comm survey tutorial n belotti n bozic g pujolle secci vademecum blockchain technology jan working paper online available httpshalsorbonneuniversitefrhalhttpshalsorbonneuniversitefrhaln v buterin introductory paper ethereum online available httpsgithubcomethereumwikiwikiwhitepaperhttpsgithubcomethereumwikiwikiwhitepaper n introduction hyperledger online available httpswwwhyperledgerorgwpcontentuploadshlwhitepaperintroductiontohyperledgerpdfhttpswwwhyperledgerorgwpcontentuploadshlwhitepaperintroductiontohyperledgerpdf n tendermint documentation online available httpsmediareadthedocsorgpdfrendermintvtendermintpdfhttpsmediareadthedocsorgpdfrendermintvtendermintpdf n energy web chain accelerating energy transition opensource decentralized blockchain platform online available httpsenergyweborgwpcontentuploadsewfpapertheenergywebchainvfinalpdfhttpsenergyweborgwpcontentuploadsewfpapertheenergywebchainvfinalpdf n solar banker initial coin offering whitepaper online available httpssolarbankerscomwpcontentuploadssbwhitepaperversionpdfhttpssolarbankerscomwpcontentuploadssbwhitepaperversionpdf n prosume online available httpsprosumeiowpcontentuploadswhitepapervpdfhttpsprosumeiowpcontentuploadswhitepapervpdf n j wu n tran application blockchain technology sustainable energy system overview sustainability vol n goranovic meisel l fotiiadis wilker treytl sauter blockchain application microgrids overview current project concept iecon rd annual conference ieee industrial electronics society ieee pp n alahakoon x yu smart electricity meter data intelligence future energy system survey ieee transaction industrial informatics vol pp n kabalci survey smart metering smart grid communication renew sust ener review vol pp n p lam law crowfunding renewable sustainable energy project exploratory case study approach renewable sustainable energy review vol pp n zidan khairalla abdrabou khalifa k shaban abdrabou r el shatshat gaouda fault detection isolation service restoration distribution system stateoftheart future trend ieee transaction smart grid vol pp nn z li j kang r yu ye q deng zhang consortium blockchain secure energy trading industrial internet thing ieee transaction industrial informatics vol pp n j kang r yu x huang maharjan zhang e hossain enabling localized peertopeer electricity trading among plugin hybrid electric vehicle using consortium blockchains ieee transaction industrial informatics vol pp n f silva modern electric hybrid electric fuel cell vehicle book news ieee industrial electronics magazine vol pp n v c gungor sahin kocak ergut c buccella c cecati g p hancke survey smart grid potential application communication requirement ieee transaction industrial informatics vol pp n yan qian h sharif tipper survey cyber security smart grid communication ieee comm survey tutorial vol pp n z ren k cong j pouwelse z erkin implicit consensus blockchain unbounded throughput arxiv preprint arxiv title vulnerability finitelylong blockchains securing data transcription vulnerability finitelylong blockchains securing datannyiming jiang jiangfan zhangnny jiang j zhang department electrical computer engineering missouri university science technology rolla mo usa email yjkzmstedu jiangfanhangmstedunn abstractnnrecently blockchain applied various field secure data exchange storage decentralized system blockchain application task application make use data stored blockchain accomplished time instant employed blockchain essentially finitelylong paper consider general finitelylong blockchain model generalized existing work finitelylong blockchain application take first step towards characterizing vulnerability finitelylong blockchains securing data doublespending attack first time develop general closedform expression probability success launching doublespending attack finitelylong blockchain probability essentially characterizes vulnerability finitelylong blockchains prove probability success launching doublespending attack finitelylong blockchain greater infinitelylong blockchain implies finitelylong blockchains le vulnerable doublespending attack infinitelylong blockchains moreover show unlike infinitelylong blockchains surely paralyzed attack finitelylong blockchains resistant attacksnn finitelylong blockchain doublespending attack proofofwork attacknn introductionnnas cryptocurrencies increasingly gaining popularity financial sector society large underlying technology referred blockchain show great potential many application different engineering discipline blockchain firstly developed financial application provided feasible measure establishing mutual trust among network node defending security threat data storage exchange securitybydesign distributed nature without authority blockchain applied diverse engineering field smart grid vehicular network smart city nnas emerging secure distributed database technology revolutionizes way information secured distributed shared blockchain technology eliminate need central authority operates peertopeer network following vital component chronologically ordered sequence block cryptographically linked shared stored synchronized network ii strong cryptography enabling secure data storage secure data exchange iii consensus protocol enables verification validation authenticity integrity stored exchanged data thus enables mutual trust network instead relying central authority cryptographic algorithm digital signature algorithm blockchain technology effectively prevent impersonation network node attack information exchange among network nodesnnthe consensus procedure every new block added blockchain one version truth agreed upon network node hence ensures local blockchain copy network node reach common agreement way consensus protocol establish mutual trust among network node distributed computing environment without needing central authority several type consensus protocol help blockchain network node achieve common agreement proof work pow proof stake po proof activity poa proof capacity poc pow requires every participant node compete solve computationally challenging puzzle receive right add new block blockchain po involves allocation responsibility validating adding new block blockchain participant node proportion number cryptocurrency token held poc allows sharing memory space contributing node network memory hard disk space node right granted maintaining blockchain poa hybrid make use aspect pow po among blockchain consensus protocol pow widely used consensus protocol example bitcoin litecoin zcash bitcoin cash adopt pow consensus protocol paper unless otherwise noted assume considered blockchains employ pow consensus protocolnnit worth mentioning blockchain technology eradicate security threat data stored blockchain mentioned blockchains prone doublespending attack dsa possibly falsify data stored blockchain considered one devastating attack blockchains recent year dsas occurred several time financial blockchain application expected occur often future example one bitcoin fork bitcoin gold suffered doublespending attack million u dollar lost total blockchain application employed blockchain utilized store data successful dsa modify existing data stored blockchain without perceived hence seriouslycompromise task make use data stored blockchainnnin blockchain application employed blockchain infinitelylong finitelylong task application make use data stored employed blockchain accomplished time instant future block data generated affect accomplished task end perspective task blockchain deemed reach final length stop growing task accomplished even though task accomplished blockchain fact keep growing record future data may used task light adopt following definition distinguish finitelylong blockchains infinitelylong blockchains perspective task blockchain applicationnndefinition finitelylong blockchain blockchain application task application make use past present data stored employed blockchain accomplished time instant perspective task blockchain employed application deemed finitelylongnnin many financial blockchain application employed blockchain play role ledger recording financial transaction see instance view unceasing occurrence transaction task recording transaction carried time accomplished given time instant thus blockchain kind application deemed infinitelylong widely adopted many recent work see instance contrast blockchain application many engineering problem task accomplished timely manner employed blockchains considered finitelylong according definition example consider blockchainaided smart grid monitor system state power grid need estimated based meter measurement stored blockchain estimation accuracy generally determined number meter measurement number meter measurement stored blockchain large enough ensure estimation accuracy meet prescribed requirement estimate state power grid produced hence growth blockchain regarded terminated perspective task state estimation since future data stored blockchain affect value produced state estimate another representative example finitelylong blockchain application blockchainbased evoting system ballot election securely recorded blockchain election result determined hence growth blockchain regarded terminated perspective task election existing work blockchain application power auction evoting vehicular announcement network employed blockchains essentially finitelylong well according definition worth mentioning finitelylong blockchain application attacker aim undermining task application falsifying data stored blockchain effective attack successfully launched blockchain reach final length thus perspective attacker timeliness attack launched finitelylong blockchains matter different infinitelylong blockchains give rise significant difference vulnerability finitelylong blockchains infinitelylong blockchainsnnlately growing tendency negligently assume data stored blockchain perfectly secure lot recent literature finitelylong blockchain application see instance however similar infinitelylong blockchains data stored finitelylong blockchain also subject dsas therefore may perfectly secured adversarial environment basic idea dsa build counterfeit branch storing falsified data blockchain extend counterfeit branch longer authentic branch blockchain counterfeit branch becomes longer authentic branch blockchain dsa deemed launched successfully since counterfeit branch data stored considered valid authentic branch blockchain data considered invalid according longest chain protocol blockchain nnthe dsa infinitelylong blockchains studied previous literature see instance however analysis dsas infinitelylong blockchains applied finitelylong blockchains since time limit adversary attack finitelylong blockchains particular unlike infinitelylong blockchains order falsify data stored finitelylong blockchain dsa launched successfully time instant task accomplished time instant authentic branch blockchain grows predetermined final length best knowledge existing work studying vulnerability finitelylong blockchains analyzing dsas finitelylong blockchains paper consider general finitelylong blockchain model generalized existing work finitelylong blockchain application first time theoretically characterize vulnerability finitelylong blockchain developing closedform expression probability success launching doublespending attack finitelylong blockchainnn summary result main contributionsnnconsidering finitelylong blockchain dsa vulnerability finitelylong blockchain characterized probability success launching dsa finitelylong blockchain starting different block authentic branch show derivation probability cast twosided boundary hitting problem twodimensional random walk two possible walking direction particular two boundary problem orthogonal two possible walking direction random walk orthogonal moreover one walking direction random walk neither orthogonal parallel two boundary twosided boundary hitting problem general closedform expression probability random walk hit one boundary developed describe probability success launching dsa finitelylong blockchain starting block authentic branch probability depends normalized hash rate attacker launch dsa defined ratio computational power owned attacker total computational power blockchain network length authentic branch blockchain time attack ordinal number block dsa start predetermined final length finitelylong blockchainnnmoreover theoretically compare vulnerability finitelylong blockchains infinitelylong blockchains specific prove probability success launching dsa finitelylong blockchain greater infinitelylong blockchain implies finitelylong blockchains le vulnerable dsas infinitelylong blockchains proved previous literature normalized hash rate attacker greater attacker attack infinitelylong blockchain launching dsa called attack probability success launching dsa always one implies attacker able falsify data stored infinitelylong blockchain hence security infinitelylong blockchain completely demolished contrast show unlike infinitelylong blockchains even though normalized hash rate attacker greater probability success launching dsa finitelylong blockchain strictly le one indicates attack completely demolish security finitelylong blockchainsnn related worknnfinitelylong blockchains recently integrated diverse engineering application enhance data security smart home smart grid smart city vehicle network see reference therein example author propose blockchainbased vehicular announcement network blockchain employed protect data tampering make widely available accessible network possibility node failure hacking application employed blockchain actually finitelylong task querying recent accident report stored blockchain accomplished employed blockchain deemed reach final length future accident report affect accomplished querying task traffic jam probability prediction system proposed blockchain help vehicle securely share request live traffic particular location blockchain employed also finitelylong task prediction accomplished growth blockchain considered terminate perspective task prediction future traffic information affect accomplished predicted probability however mentioned work assume data stored finitelylong blockchains perfectly secure true general particular data stored finitelylong blockchain modified dsas motivates u investigate dsas finitelylong blockchainsnnthe dsa infinitelylong blockchains well studied previous literature see reference therein author point infinitelylong blockchains vulnerable dsas author derives probability success launching dsa infinitelylong blockchain moreover author indicates attacker control half computational power blockchain network attacker always successfully launch dsa infinitelylong blockchain based result author provide detailed analysis property dsas infinitelylong blockchains however previous literature theoretically investigates dsa focus infinitelylong blockchains apply finitelylong blockchains paper consider dsas launched finitelylong blockchains develop closedform expression probability attacker successfully launch dsa finitelylong blockchainnnthe paper organized follows section ii general finitelylong blockchain model doublespending attack model introduced section iii analyzes probability attacker successfully launch dsa finitelylong blockchain numerical simulation provided section iv section v provides conclusionsnn ii finitelylong blockchain adversary modelsnnin section first introduce general finitelylong blockchain model subsumes model adopted previous work finitelylong blockchain application doublespending attack model elaboratednn finitelylong blockchain modelnnwe consider general finitelylong blockchain model generalized existing work finitelylong blockchain application see instance working mechanism finitelylong blockchains similar infinitelylong blockchains proposed except finitelylong blockchain considered stop growing longest branch reach predetermined final lengthnndifferent node play different role finitelylong blockchain network main duty node include data generation blockdata routing blockdata verification block mining finitelylong blockchain network mainly two type node wallet miner wallet produce data transaction sensor measurement information main duty miner generate block blockchain store data produced wallet note possible node finitelylong blockchain network play role wallet miner working mechanism finitelylong blockchain network mainly includes two component presented belownn iia data exchangesnnin finitelylong blockchain network wallet first transmit data every miner miner compete generate block store wallet data blockchain process generating new block blockchain elaborated section iia miner generates block sends generated block node retain local copy blockchain internode data exchange asymmetric encryption based public key infrastructure used illustrated fig specific node blockchain owns publicprivate key pair form digital identity node public key available node private key available owner secure hash algorithm sha eg sha sha used data encryption process every data exchange delineate internode data exchange let consider data exchange wallet miner example let djt denote tth data jth wallet time index time index transmitting djt miner jth wallet first process message contains data djt time index employing sha obtains message digest encrypts message digest via private key using digital signature algorithm eg elliptic curve digital signature algorithm produce digital signature finally jth wallet transmits data package consisting message corresponding digital signature miner networknnonce miner receives data package first decrypts received digital signature via public key wallet obtains message digest signified message digest b fig miner process received message via sha obtains another message digest represented message digest fig two message digest exactly match authenticity received data package verified received message used future process otherwise received data package discarded retransmission take place note digital signature received miner decrypted via public key sender hence miner verify identity sender prevent impersonation sender moreover sha digital signature algorithm secure data package transmission since computationally intractable attacker either find different message yield message digest generate valid digital signature fake message digest without private key sender end authenticity data package received miner identity sender validated securednn iia block mining consensus protocolnnfor time every miner first collect data package wallet verifies authenticity collected data package every miner put header wallet data package message djtt j digital signature associated message new block header consists discrete timestamp hash value last block parent block longest valid branch miner local copy blockchain merkle root root merkle tree constructed recursively hashing pair data package one hash number called nonce solution pow puzzle hash value parent block stored header new block essence cryptographically link new block parent block simplified structure block illustrated fig nnnext miner compete solving difficult pow puzzle new block called mining particular miner attempt solve pow puzzle searching valid nonce new block via bruteforce search render hash value new block le prescribed number prefix zero difficulty pow puzzle increase prescribed number prefix zero increase miner solves pow puzzle first among miner ie find valid nonce value meet requirement say miner successfully mine new block miner broadcast new block node retain local copy blockchain receiving newly mined block node carry block validation procedure specifically node first verify authenticity message received block confirm time index contained message received block one greater parent block received block verify hash value received block indeed le prescribed number prefix zero received block pas block validation node add received block parent block local copy blockchain switch work solving pow puzzle next block miner solves pow puzzle first offered incentivennfig internode data exchange based asymmetric encryption mechanismnnthe block mining process described considered hashing competition among miner probability miner solves pow puzzle first proportional normalized hash rate defined ratio computational power total computational power network possible two miner may solve puzzle almost time may lead distinct blockchain branch different miner due decentralized nature blockchain communication delay among node however longest branch miner local copy blockchain called main chain reach consensus due longest chain protocol blockchain nnthe structure wallet message deserves discussion purpose including time index every message mainly twofold one hand exist network latency communication failure miner may lose wallet data package may receive wallet data package chronological order time index included every message help miner discern data package lost rearrange received wallet data package chronological order hand possible wallet data djt value different time index including time index every message distinguish data different time also prevent potential security threat example consider case every message include time index exists malicious miner time forming new block malicious miner falsify data package received jth wallet simply replacing jth wallet data package generated time tt obtained malicious miner copy blockchain falsified block mined falsification pas validation process implemented node since jth wallet data package generated authentic valid contrary every message includes time index kind falsification pas validation process implemented node since time index contained falsified mined block one greater time index parent block mined blocknnas mentioned blockchain application task application accomplished time instant employed blockchain deemed finitelylong let l denote number block mined longest branch employed blockchain task blockchain application accomplished finitelylong blockchain model assume growth blockchain terminates longest branch grows l blocksnn doublespending attack modelnnin order falsify data already stored blockchain attacker successfully launch dsa consider finitelylong blockchain l authentic block store data task application mined form authentic branch attacker control malicious miner network launch dsa finitelylong blockchain attempt falsify data djlajinmathcala subset mathcala wallet already stored lath block laleq l authentic branch blockchain tildedjlajinmathcala step launching dsa finitelylong blockchain summarized follows attacker first hack subset mathcala wallet steal private key generate valid digital signature falsified message containing tildedjlajinmathcala attacker modifies lath authentic block form counterfeit block replacing lath authentic block data package containing djlajinmathcala falsified data message containing tildedjlajinmathcala corresponding digital signature attacker work mining counterfeit block redoing pow puzzle find valid nonce value counterfeit block render hash value counterfeit block le prescribed number prefix zero valid nonce value successfully found attacker broadcast mined counterfeit block node retain local copy blockchain since mined counterfeit block pas block validation conducted node node add counterfeit block lath authentic block local copy blockchain blockchain longest branch valid according longest chain protocol blockchain end order ensure validity lath counterfeit block attacker mine block lath counterfeit block linked one another form counterfeit branch extend counterfeit branch longest branch blockchain process launching dsa illustrated fig worth mentioning mining block counterfeit branch requires malicious miner solve pow puzzle moreover malicious miner work hacking subset mathcala wallet extending counterfeit branch honest miner simultaneously work mining new block extend authentic branch counterfeit branch becomes longest branch blockchainnnas illustrated fig counterfeit branch consists authentic block index la lath counterfeit block block linked authentic branch consists authentic block index l block linked lth authentic block clear counterfeit branch diverges authentic branch lath block authentic branch counterfeit branch becomes longer authentic branch honest miner switch working extending authentic branch working extending authentic branch honest miner switch working extending authentic branch working extending authentic branch working extending authentic branch working authentic branchnnfig structure block blockchainnnthe counterfeit branch according longest chain protocol blockchain result authentic branch stop growing counterfeit branch remain longest branch blockchain time go bynnat last make remark value l practice wallet communicate malicious miner controlled attacker provides attacker opportunity hack wallet generally cybersecurity measure taken wallet prevent attacker hacking wallet stealing private key example basic preventative measure wallet equipped password protection prevent hacking order hack wallet equipped password protection attacker employ brute force attack work possible keystroke hoping guess password correctly may take long time attacker hack wallet subset mathcala honest miner generally successfully mine authentic block authentic branch implies l generally greater practice owing cybersecurity measure taken wallet addition case l trivial task blockchain application already accomplished hence attacker failed launch successful dsa moreover authentic block mined blockchain ie l attacker accomplishes hacking subset mathcala wallet block storing data task blockchain application mined blockchain therefore attacker need launch dsa blockchain anymore attacker already controlled subset mathcala wallet falsify data transmitted miner blockchain record data task blockchain application light assume throughout papernn iii probability success launching doublespending attacknnconsider doublespending attack model described section iib l block mined authentic branch attacker attempt falsify data stored lath authentic block launching dsa attacker build counterfeit branch longer authentic branch task finitelylong blockchain application accomplished time instant authentic branch grows l block refer dsa render counterfeit branch longer authentic branch authentic branch grows l block successful dsannaccording pow protocol probability miner solves pow puzzle first among miner proportional hash rate let denote probability next block mined blockchain generated malicious miner hence probability next block mined blockchain generated honest miner let mathbbplmn denote probability length authentic branch n counterfeit branch built attacker block shorter authentic branch attacker finally extends counterfeit branch longer authentic branch authentic branch grows l block mathbbplllal probability attacker launch successful dsannnote malicious miner mine next block blockchain happens probability counterfeit branch block shorter authentic branch authentic branch remains n block contrast honest miner mine next block blockchain happens probability counterfeit branch block shorter authentic branch authentic branch grows n block end recursive form mathbbplmn expressed forall mincdotslla forall ninlcdotslnnmathbbplmnitimesmathbbplmnitimesmathbbplm n tagnnonce counterfeit branch becomes longer authentic branch ie counterfeit branch block shorter authentic branch length authentic branch reach l dsa launched attacker succeeds therefore following boundary conditionnnmathbbplnquadforall nl tagnnon hand length authentic branch grows l counterfeit branch still shorter authentic branch blockchain reach final length implies attacker fails launch successful dsa hence another boundary conditionnnmathbbplmlquadforall tagnnit worth pointing honest miner mine block length authentic branch grows l length counterfeit branch authentic branch honest miner mine block counterfeit branch already grown l block hence counterfeit branch already longer authentic branch implies already reached boundary condition honest miner mine block end dont need include case boundary condition nnby employing pursuit closedform expression mathbbplmn cast twosided boundary hitting problem twodimensional random walk two possible moving direction illustrated fig specific let mathbfsttriangleqmntsumtttmathbfdeltat denote position random walk twodimensional space tth step ie block mined blockchain mathbfdeltat random vectornnmathbfdeltatleftbeginarrayccmathbfdeltatriangleq ttextwith probability mathbfdeltatriangleqttextwith probability iendarrayright tagnnlet mathcalltriangleqleftmprimenprimetleftmprime rightright mathcalltriangleqleftmprimenprimetleftnprime lrightright define two boundary line twodimensional space mathcalltriangleqleftmprimenprimetleftnprime lrightrightnnnn warning truncated repetitionsnnprimetleftnprime lrightright boundary condition mathcalltriangleqleftmprimenprimetleftnprime lrightright boundary condition mathcalltriangleqleftmprimenprimetleftnprime lrightright boundary condition mathcalltriangleqleftmprimenprimetleftnprime lrightright boundary condition mathcalltriangleqleftmprimenprimetleftnprime lrightright boundary condition mathcalltriangleqleftmnnndimensional space respectively mathbbplmn rewritten asnnmathbbplmnsumtinftyprleftmathbfstinmathcallmathbfstprimenotinmathcallcupmathcallforall primetright tagnnthe closedform expression mathbbplmn given mn described following theoremnntheorem length authentic branch n counterfeit branch block shorter authentic branch probability mathbbplmn attacker launch successful dsa expressed asnnmathbbplmn tag leftbeginarrayclsumilnaimiii mitext mgeq nl text leq text mnl text inl text mnlendarrayrightnnwhere coefficient aim defined asnnaimleftbeginarraycltextif mtextif citextif cisumlimitsjmcisumlimitsjmsum limitsjjci cdotssumlimitsjmsumlimitsjjcdotssum limitsjjctextif sumlimitsjmsumlimitsjjcdotssumlimits jijijiendarrayright tagnnand constant ci ith catalan number given bynncioversetdeltafracibeginpmatrixi iendpmatrixfraciii tagnnproof easily see mathbbplmn nl mathbbplmn nl next prove case leq nlnnas illustrated fig random walk hit boundary line mathcall hitting boundary line mathcall possible case forall iln random walk move along boldsymboldelta mi step move along boldsymboldelta step thus mathbbplmn written general formnnmathbbplmnsumilnaimiiimi tagnnwhere aim constant denotes number path random walk hit boundary mathcall mith step moving mi step along boldsymboldelta step along boldsymboldelta random walk never hit mathcall mith step obvious thatnnamtext mgeq tagnnand hencennmathbbplmnimsumilnaimiiimi tagnnfig twodimensional random walk illustrationnnfig finitelylong blockchain doublespending attacknnby substituting obtainnnimsumilnaimiiimi itimesleftsumilnaimiiimiright qquaditimesleftsumilnaimiiim iright sumilnaimiiimi qquadsumilnaimiiimi imsumilnaimiiimi qquadsumilnaimiiimi imsumilnaimaimiiimi tagnnsince hold fundamental theorem algebra knownnaimaimaim forall textand mgeq tagnnsince mgeq getnnamamam forall mgeq tagnnfrom choosing furthermore setting havennmathbbplniitimesmathbbpln tagnnwhich yieldsnnisumilnaiiiiiisumilnaii iii tagnnby employing nnby fundamental theorem algebra know thatnnaiai forall iln tagnnfrom obtainnnaa tagnnand thereforennamm forall mgeq tagnnby employing recursive equation obtain ilnnnaimaisumjmaij forall tagnnmoreover knownnaiai forall iln tagnnwhich implies iln mnnaim aisumjmaij aisumjmaisumjmsum jjaicdots quadsumjmsumjjcdotssumj elljiasumjmsumjj cdotssumjijiaji aisumjmaisumjmsum jjaicdots quadsumjmsumjjcdotssumj ijia quadsumjmsumjjcdotssumj ijiji tagnnby employing nnnext need determine aim iln suppose another boundary line mathcallstackreldeltaleftleftmprimen primerighttleftnprimelrightright mathbbplprimemn probability random walk hit boundary line mathcall hitting boundary line mathcall similar knownnmathbbplprimemnsumilnaimprimeiiiminnwhere aimprime constant denotes number path random walk hit boundary mathcall mith step moving mi step along delta step along delta random walk never hit mathcall mith step clear thatnnaimprimeaim forall iln textand forall mgeq tagnnsimilar getnnaiprimeaiprime forall iln tagnnfrom knownnalnalnprimealnprime tagsimilar employing obtain mnnalnm aprimelnm aprimelnsumjmalnj aprimelnsumjmalnsumj msumjjaln qquadcdotssumjmsumjjcdots sumjlnjlna qquadsumjmsumjjcdotssumj lnjlnjln tagnnit seen determine value aprimei iln determine value aim iln forall mgeq hence obtain closedform expression mathbbplmn using follows derive closedform expression aprimei ilnnnnote aprimei denotes number path random walk hit boundary line mathcall ith step moving step along boldsymboldelta step along boldsymboldelta random walk never hit mathcall ith step know path twodimensional space start point nt arrives point nit ith step moreover first step path must stay half space mathcalstriangleqmprimenprimetmprimegeq light aprimei identical number lattice path point point iit consist step along vector step along vector never rise diagonal line ibyi grid path referred dyck path number path known ith catalan number ci therefore knownnaprimeicitriangleqfracibeginpmatrixi iendpmatrixfraciii forall iln tagnnby employing obtainnnmathbbplmn leftbeginarrayclsumilnaimiiim itextif mgeq nl textand leq textif mnl textor inl textif mnlendarrayright tagnnwhere coefficient aim expressed asnnaimleftbeginarraycltextif mtextif citextif citextif cisumlimitsjmcisumlimitsjmsum limitsjjci cdotssumlimitsjmsumlimitsjjcdotssum limitsjijctextand sumlimitsjmsumlimitsjjcdotssum limitsjijjiendarrayright tagnnwhich completes proof nnby substituting lla l n general closedform expression respectively obtain probability attacker launch successful dsa finitelylong blockchain intuitively speaking asymptotic regime ltoinfty boundary line mathcall fig essentially exist hence twodimensional random walk boundary hitting problem illustrated degenerate onedimensional random walk boundary hitting problem consequence probability attacker launch successful dsa finitelylong blockchain expected converge infinitelylong blockchain ltoinfty intuitive conjecture formally summarized rigorously proved following theoremnntheorem nl mathbbplmn strictly increase l increase constant moreover nl ltoinfty probability mathbbplmn converges tonnlimltoinftymathbbplmnleftbeginarrayclleftfraci irightm textif leq textif leq ileq endarrayright tagnnwhich equal probability attacker launch successful dsa infinitelylong blockchain counterfeit branch block shorter authentic branch nnproof nl havennmathbbplmn sumilnaimiiimi mathbbplmnalnmilnimln tagnnfrom know aimgeq forall imgeq hence alnmilnimln alnmilnimln implies thatnnmathbbplmn mathbbplmn textif tag mathbbplmn mathbbplmn textif itext tagfrom know mathbbplmn strictly increasing function l mathbbplmn constant l change definition mathbbplmn know mathbbplmnleq forall l since mathbbplmn strictly increasing bounded know mathbbplmn converges l increase monotone convergence theorem mathbbplmn doesnt change l change hence mathbbplmn also converges therefore mathbbplmn converges l increase impliesnnlimltoinftymathbbplmnlimltoinftymathbbplmn tagnnnote ngeq l havennmathbbpl mn sumilnaimiiimi sumilnaimiiimi mathbbplmn tagnnfrom getnnlimltoinftymathbbplmnlimltoinftymathbbplm n textif ngeq l tagnnfrom getnnlimltoinftymathbbplmnitimeslimltoinfty mathbbplmn qquadqquadqquadqquadqquadqquaditimeslimltoinfty mathbbplmn tagnnnote condition ngeq l hold case interest since authentic branch start l block attacker launch dsa substituting havennlimltoinftymathbbplmnitimeslimltoinfty mathbbplmn qquadqquadqquadqquadqquadqquadqquaditimesliml toinftymathbbplmn tagnnfor simplicity let gmtriangleqlimltoinftymathbbplmn mgeq obtainnngmitimes gmitimes gm tagnnfrom limltoinftymathbbpln impliesnnglimltoinftymathbbpln tagnnfrom havenngmgmfraciileftgmgmright tagnnwhich yieldsnngmgmleftfraciirightmleftggright tagnnmoreover recursive equation obtainnngmgggsumimleftfraciirightm tagnnnext determine g know nnng limltoinftymathbbpln limltoinftysumilnciiiii sumiinftyciiiii tagnnwhere ci ith catalan number note generating function catalan number defined nncxsumiinftycixifracsqrtxx tagnnby setting xii iin obtainnnsumiinftycileftiirighti fracsqrtiiii fracsqrtiii leftbeginarrayccfracii fracileq iendarrayright tagnnnote g g moreover since itimessumiinftyciiiisumiinftyciiii ig obtain nngleftbeginarrayccfraciii igeq endarrayright tagnnby employing obtainnnlimltoinftymathbbplmnleftbeginarrayccfracii mtextif leq textif leq ileq endarrayright tagnnwhich completes proof nnin theorem assumption nl hold case interest since demonstrated theorem since mathbbplmn increasing function l l increase converges probability success launching dsa infinitelylong blockchain know probability success launching dsa infinitelylong blockchain counterfeit branch block shorter authentic branch upper bound probability success launching dsa finitelylong blockchain n well known attacker owns half computational power whole network ie launch dsa infinitelylong blockchain called attack probability success launching attack always one however shown theorem case generally true normalized hash rate attacker mathbbplmn strictly increasing function l therefore see mathbbplmn strictly smaller even though demonstrates unlike infinitelylong blockchains probability success launching attack finitelylong blockchain strictly smaller reveals finitelylong blockchains resistant attack compared infinitelylong blockchainsnn iv simulation resultsnnin section numerically study probability mathbbplllal attacker launch successful dsa finitelylong blockchain different parameter l la l respectively particular employ monte carlo simulation corroborate theory developed paper number monte carlo run simulation result monte carlo simulation result specified legend label simulation figuresnnas index la block attacker attempt falsify varies fig depicts mathbbplllal different l l chosen respectively numerical result yielded theorem monte carlo simulation specified dashed solid line fig respectively clearly agree hence numerical result fig corroborate theorem seen fig mathbbplllal increase la increase moreover given la mathbbplllal increase increase la increase gap number block counterfeit branch authentic branch shrink therefore easier attacker extend counterfeit branch surpass authentic branch authentic branch grows l block moreover increase probability malicious miner successfully mine next block network increase hence also easier attacker launch successful dsannnext numerically investigate value l impact mathbbplllal la varies fig depicts mathbbplllal different l l seen fig numerical result yielded theorem agree monte carlo simulation moreover given la mathbbplllal increase l increase explained fact l increase take time honest miner extend authentic branch reach l block hence attacker better chance extend counterfeit branch longer authentic branch authentic branch grows l blocksnnfig depicts mathbbplllal different l la varies l numerical result yielded theorem exactly match monte carlo simulation result seen fig given la mathbbplllal increase l decrease la given l decrease gap number block counterfeit branch authentic branch shrink hence attacker better chance extend counterfeit branch longer authentic branch authentic branch grows l blocksnnlastly numerically corroborate theorem l increase fig depicts mathbbplllal obtained different la l blue red curve obtained respectively yellow purple curve obtained respectively seen fig curve obtained converge corresponding curve obtained l increase moreover curve obtained always corresponding curve obtained agrees theorem implies difficult launch successful dsa finitelylong blockchain infinitelylong blockchain moreover igeq dsa always launched successfully infinitelylong blockchain however seen fig igeq mathbbplllal finitelylong blockchain indicates finitelylong blockchains resistant attack infinitelylong blockchainsnn v conclusionsnnin paper theoretically studied vulnerability finitelylong blockchains term securing data doublespending attack developed general closedform expression probability attacker launch successful doublespending attack finitelylong blockchain probability characterizes vulnerability finitelylong blockchains securing data since attacker attempt falsify data already stored blockchain attacker launch successful doublespending attack proven finitelylong blockchains le vulnerable doublespending attack infinitelylong blockchains moreover unlike infinitelylong blockchains even though normalized hash rate attacker greater probability success launching doublespending attack finitelylong blockchain strictly le one indicates attack completely demolish security finitelylong blockchainsnn referencesnn asefi madhwal yanovich e gryazina application blockchain secure data transmission distributed state estimation ieee trans control netw syst pp external link document cited ssin asefi madhwal yanovich e gryazina application blockchain secure data transmission distributed state estimation ieee trans control netw syst pp external link document cited ssin asefi madhwal yanovich e gryazina application blockchain secure data transmission distributed state estimation ieee trans control netw syst pp external link document cited ssin asefi madhwal yanovich e gryazina application blockchain secure data transmission distributed state estimation ieee trans control netw syst pp external link document cited ssinnmissingpagepostnnim kim kim bitcoin v bitcoin v sc cha jf chen c su kh yeh blockchain connected gateway blebased device internet thing ieee access vol pp n pp n p ozisik b n levine explanation nakamotos analysis doublespend attack arxiv preprint arxiv n rosenfeld analysis hashratebased double spending arxiv preprint arxiv n c grunspan r perezmarco double spend race int j theor appl finance vol p n e zaghloul li w mutka j ren bitcoin blockchain security privacy ieee internet thing j vol pp n l zhou l wang sun p lv beekeeper blockchainbased iot system secure storage homomorphic computation ieee access vol pp n q yang h wang privacypreserving transactive energy management iotaided smart home via blockchain ieee internet thing j vol pp n pilkington blockchain technology principle application research handbook digital transformation edward elgar publishing n stiawan idris r f malik nurmaini n alsharif r budiarto et al investigating brute force attack pattern iot network j electr comput eng vol n r p stanley catalan number cambridge university press n r l wheeden zygmund measure integral dekker new york vol title testimonium costefficient blockchain relay transcription testimoniumnna costefficient blockchain relaynn philipp frauenthalernntu wiennn viennann austriannpantos gmbhnn viennann austriannpfrauenthalernn msigwartnn sschuledsgtuwienacatnncontactpantosionn marten sigwartnntu wiennn viennann austriannpfrauenthalernn msigwartnn sschuledsgtuwienacatnncontactpantosionn christof spanringnntu wiennn viennann austriannpfrauenthalernn msigwartnn sschuledsgtuwienacatnncontactpantosionn stefan schultenntu wiennn viennann austriannpfrauenthalernn msigwartnn sschuledsgtuwienacatnncontactpantosionn abstractnncurrent blockchain technology provide limited mean interoperability particular solution enabling blockchains verify existence data blockchains either costly fully decentralizednnto overcome limitation introduce testimonium novel blockchain relay scheme applies validationondemand pattern onchain execution simplified payment verification enable verification data across blockchains remaining fully decentralized evaluating scheme ethereumbased blockchains show testimonium achieves cost reduction existing solution scheme lay strong foundation generic blockchain interoperability instance enables development atomiccommit protocol distributed transaction across blockchainsnnnnpublished nnphilipp frauenthaler marten sigwart christof spanring stefan schulte testimonium costefficient blockchain relay pvldb xxx xxxxyyyyyy nndoi httpsdoiorgxxxxxxxxxxxxhttpsdoiorgxxxxxxxxxxxxnnnn introductionnnfor ability store data decentralized immutable way blockchain technology gained much attention industry research community potentially disruptive area finance business process management data provenance supply chain management healthcare take diverse requirement use case account variety different blockchain platform developed unlike emergence various nosql database alternative traditional database system field multiple independent unconnected blockchains unlikely blockchain rule emerges reinforces need interoperability solution especially scenario organization utilize different blockchains collaborate othernnin scenario may essential state change across blockchains treated atomic unit either succeeds fails howeverdespite already wellestablished traditional database distributed transaction seamlessly transferred blockchain field since interaction external system might jeopardize integrity decentralization guarantee blockchains like bitcoin ethereum ideally blockchain interoperability achieved preserving property integrity decentralization ie underlying crossblockchain communication rely trust centralized partynnone blockchain interoperability approach particularly promising socalled relay scheme relay scheme replicate block information source blockchain within destination blockchain allow latter verify existence data eg transaction source blockchain without requiring trust centralized entity ability verify arbitrary data across blockchains pave way generic blockchain interoperability eg enabling implementation atomiccommit protocol distributed transaction across multiple blockchains nnfor verification trustworthy block information source blockchain need validated destination blockchain according validation rule source blockchain however depending source destination blockchains validation expensive performed onchain within current relay solution inevitably lead either high operational cost expensive onchain validation bypassed need rely centralized componentnnto overcome issue introduce testimonium relay scheme fully decentralized costefficient even blockchains expensive validation protocol key concept sophisticated incentive scheme combined validationondemand approach evaluate scheme proof concept implementation ethereumbased blockchains show achieves cost reduction existing relay solutionsnnthe paper organized follows section provides background information section describes technical contribution paper section evaluate proposed relay regard security operational cost section give overview related work finally section concludes papernnnn backgroundnnthis section discus important background information testimonium first explain concept simplified payment verification spv describe spvs used facilitate blockchain relay schemesnn simplified payment verificationnnspvs enable client cryptographically verify particular transaction part blockchain without store full blockchain instead full blockchain spv client need keep copy block header contrast complete block block header store meta data eg block number transaction data thus block header consume fraction space complete block needsnnto get new block header client query node access full blockchain client copy header blockchain user prove spv client inclusion transaction blockchain spv client verify proof without keeping copy actual transaction data client leverage fact transaction block stored leaf socalled merkle tree hash merkle tree root node merkle root hash stored block header see fig nnin case user want prove inclusion particular transaction spv client user need provide socalled merkle proof membership proof contains node path transaction leaf root node see fig receiving proof spv client recalculates hash node along path leaf ie transaction root node final hash match merkle root hash stored block header membership transaction within corresponding block successfully verifiednn relay schemesnnspv client ability verify whether particular transaction exists blockchain blockchain relay like btc relay peacerelay utilize capability enable transaction inclusion verification across blockchains essentially relay spv client source blockchain running destination blockchain instance btc relay relay running ethereum blockchain ie destination blockchain enabling transaction inclusion verification block header bitcoin blockchain ie source blockchainnnfor successful spv relay need know block header source blockchain block header source blockchain need constantly submitted relay offchain client knowledge block header source blockchain relay leverage spv verify destination blockchain particular transaction included source blockchainnnto keep system fully decentralized ie require trust offchain client newly submitted block header first validated relay transaction inclusion verification performed furthermore competing branch blockchain common occurrence especially proof work pow blockchains branch usually consist valid block one branch eventually accepted main chain eg pow blockchains branch greatest amount work invested transaction inclusion verification performed block header part current main chain source blockchain relay need track branch representing main chainnna block header considered valid complies source blockchains standard validation procedure among thing usually involves validating consensus algorithm instance pow need verified enough work performed whereas blockchains may consist checking least certain amount validators eg signed block nnexisting relay like btc relay perform source blockchains header validation every submitted block header however depending source destination blockchains verifying validity block header onchain computation storageintensive example validating ethash pow algorithm ethereum requires fragment data used mining available onchain even optimized solution need approximately million gas executed ethereumbased blockchain see section performing validation every block header source blockchain lead extremely high operational cost best knowledge current relay scheme offer solution problem without involving trusted third party see section nnto tackle issue introduce testimonium relay scheme achieves significant cost reduction traditional blockchain relay fundamental concept testimonium discussed following sectionnn testimonium relay schemennthis section introduces testimonium relay scheme keep cost executing spvs onchain minimum deploying validationondemand pattern relayed block header testimonium requires trust single entity validation executed onchain reward structure incentivizing participationnnas mentioned section blockchain relay store copy block header source blockchain testimonium relay scheme assumes block header thennfigure block header merkle tree corresponding merkle proof membership txsource blockchain based data structure proposed satoshi nakamoto example case bitcoin ethereum many fork blockchain protocol block header contain least hash block parent block height hash root node merkle tree containing block transaction three field referred parenthash blockheight merkleroot respectively section discus additional requirement involved blockchains need satisfy furthermore testimonium introduces additional field typically present block header field needed executing certain action prefixed meta distinguish field usually present block headernntestimonium consists relay onchain program running destination blockchain two type offchain client submitter responsible relaying block header source blockchain destination blockchain disputters responsible detecting disputting submitted illegal block headersnn replicating source blockchainnnin relay scheme offchain client continuously submit block header source blockchain relay destination blockchain new header submitted multiple action performed testimonium relay submitted header used verifying existence transaction source blockchainnnalgorithm show pseudo code procedure undertaken testimonium relay whenever new block header submitted offchain client right arrival new header checked whether retrieved header already submitted relay line case submitted header rejected submitted block header stored global hashmap using header hash key header value function hash represents hash function used source blockchain calculate block hash eg storing bitcoin header hash would implement shannnext checked whether block referenced field parenthash exists relay ie whether already submitted testimonium relay shown line ensures continuous chain block header replicated within testimonium relaynnnfunctionsubmitblockheaderheader submitternifheaderscontainshashheader truethennreturnfalsenparenthash headerparenthashnifheaderscontainsparenthash falsethennreturnfalsenheadersputhashheader headernheadermlockeduntil lockperiodnheadermsubmitter submitternparent headersgetparenthashnparentmchldnappendhashheadernbranchheadsaddhashheadernifbranchheadscontainsparenthashthennbranchheadsremoveparenthashnheadermbranchid parentmbranchidnheadermjunction parentmjunctionnelsenlastbranchid lastbranchid nheadermbranchid lastbranchidnheadermjunction parenthashnifparentmchldnlength thennsetjunctionparentmchldnparenthashnmainchainhead getmainchainheadnnnalgorithm procedure performed testimonium relay receiving new header source blockchainnn optimistically accepting block headersnnas stated section executing source blockchains header validation procedure destination blockchain expensive performing validation every block header source blockchain would lead high operational cost therefore testimonium follows optimistic approach received block header accepted first without fully validated line nnof course since submitted block header fully validated illegal block header may accepted testimonium relay potentially enabling verification illegal transaction testimonium prevents assigning lock period newly received block header line period block header considered locked meaning used transaction inclusion verification furthermore within lock period offchain client ie disputers dispute header deem illegal case dispute header validation carried testimonium relay validation fails illegal block header eliminated section discus disputting illegal block header detail make submitter illegal block header accountable submitter address stored received block header using field msubmitter shown line nn handling blockchain branchesnnin pow blockchains like bitcoin ethereum multiple valid block block height exist parallel forming socalled blockchain branch multiple branch exist parallel one branch represents current main chain blockchain eg pow blockchains branch amount work invested block header appended branch main chain blockchain may change time represents challenge onchain spv execution since transaction inclusion verification successful requested block part main chainnna branch head represents recent block header blockchain branch keep track existing branch source blockchain testimonium relay track head branch way relay able constantly reevaluate current main chain source blockchain eg pow blockchains main chain identified searching branch highest total difficultynnwhenever new block header passed validation added set branch head line either becomes new head existing branch represents start completely new branch block header continues already existing branch replaces parent branch head line ff block header creates new branch header merely appended branch head set creation new branch affect existing branch head branch head main chain stored global variable mainchainhead whenever new block header submitted current main chain reevaluated line nn enabling efficient verificationsnnwhenever transaction inclusion verification requested certain block testimonium relay need determine whether block part main chain source blockchain block header contains hash pointer parent forming linked list could simply trace main chain head stored variable mainchainhead line way back reach requested block genesis block however depending far back requested block lie traversal expensive make traversal costefficient testimonium relay store additional helper variable block headernnfirst store reference preceding branch junction ie reference header branch newly submitted block header branched second store number identifying subpath current branch ie branch newly submitted block header new head refer number branch id meta data stored field mjunction mbranchid respectively case submitted header continues existing branch mjunction mbranchid set corresponding field value parent shown line new branch occurs mbranchid get assigned maximum branch id used far incremented one mjunction submitted header set parent hash line helper field mbranchid mjunction enable efficient search verifying transaction inclusion backwards traversal executed jump branch junction branch junction rather block blocknnfurthermore testimonium relay keep track block header child refer block c child block p parenthash c hold reference p refer block descendant block p reach p using hash pointer parenthash forming linked list analogous refer block p predecessor block whenever new block header received testimonium relay add hash parent child list line typically header one child header branch junction list contains least two child ie hash block header branching headernnthe child list useful number reason first allows easier updating mjunction field case new branch junction emerges line mjunction field descendant new branch junction need set hash branch junction function setjunction line update descendant header reached either child ie header branch head least two child ie header represents another branch junction second case block header successfully disputed child list used delete block header appended illegal block see section nnfinally child list also used facilitate transaction inclusion verification since help determine number confirming block next section look verification carried detailnn transaction inclusion verificationsnnas soon block header source blockchain replicated within testimonium relay destination blockchain transaction inclusion verification block header possible client eg smart contract sends request testimonium relay form transaction tx block b part source blockchain confirmed least n block answer verification request relay executes onchain spv first verifies header block b known unlocked ie lock period passed part main chain source blockchain second verifies block b confirmed least n succeeding block finally merkle proof membership submitted together verification request validatednn verifying block membership main chainnnas outlined section testimonium relay assigns branch id every submitted block header whenever submitted block header branch new branch currently maximum branch id incremented one assigned new header case submitted header continues existing branch get assigned branch id parentnnconsider example illustrated fig show source blockchain replicated within testimonium relay seen block header two consecutive branch junction branch junction branch head branch id branchid since submitted header branch id either set parent branch id maximum branch id incremented one know descendant block header h branch id equal greater branch id h analogous predecessor h branch id equal lower branch id hnnhence verifying main chain membership block header h branch id greater branch id main chain head know header h part main chain without traverse header main chainnnthis constraint used algorithm verify certain block header part main chain source blockchain ie whether block header predecessor main chain head parameter blockhash hold hash block header check whereas target contains corresponding header line nnthe algorithm start main chain head line point algorithm traverse branch junction reachable head long currently traversed block header branch id greater branch id target line nnsince header two consecutive branch junction branch junction branch head always branch id completely sufficient traverse branch junction since header inbetween skipped algorithm need check block header instead traversing header header look ie target main chain headnnafter execution whileloop variable current contains branch junction branch id equal lower branch id target branch id current strictly lower branch id target target part main chain function returnsfalse line f otherwise know header branch id ie part least one common branchnnhowever still case target part main chain consider block header x x fig x header returned loop ie current x header look ie target x part main fork x testimonium relay compare block height current target blockheightcurrentblockheight target part main chain function return false targetblockheightcurrentblockheight current target either current branch junction target main chain head hence case target part main chainnnfurther traversing branch junction branch junction checked whether lock period passed unlocked branch junction encountered first time child along path main chain stored variable confirmstart line main chain head already unlocked branch junction main chain unlocked well submitted either time main chain head case store main chain head variable confirmstart entering loop line causing check encountered branch junction lock period skipped besides boolean indicating whether header look lie main chain algorithm also return confirmstart variable header referenced confirmstart used starting point verifying whether requested header enough confirming block header consider example fig assuming function called block hash x block x latest unlocked branch junction starting point confirmation verification block x algorithm verifying number confirmation discussed following sectionnn verifying sufficient block confirmationsnnbesides checking whether header block supposedly containing transaction verify part main chain source blockchain also need ensured header confirmed enough succeeding block headersnnnfunctionispartofmainchainblockhashntarget headersgetblockhashncurrent headersgetmainchainreadnconfirmstart nifcurrentmlockeduntil thennconfirmstart mainchainheadnwhilecurrentmbranchid targetmbranchid donoldbranchid currentmbranchidncurrent headersgetcurrentmjunctionnifconfirmstart thencontinuenifcurrentmlockeduntil thennconfirmstart ngetchildbybranchcurrent oldbranchidnifcurrentmbranchid targetmbranchid thennreturn false confirmstartnifcurrentblockheight targetblockheight thennreturn false confirmstartnreturn true confirmstartnnnalgorithm verifies whether block header referenced blockhash part main chain source blockchainnnalgorithm show pseudo code verification variable blockhash indicates block header start verification confirmation specifies required number succeeding block note concrete number block confirmation considered secure depends source blockchain eg bitcoin six succeeding block deemed sufficient nnthe algorithm start specified block header ie blockhash recursively call function succeeding block header time decreasing number required confirmation one line case block header referenced parameter blockhash exist algorithm return false line f similarly block header reached end lock period yet may still disputed identified invalid disputers hence case algorithm encounter block header still locked verification fails well line fnnif block header exists unlocked checked whether confirmation required blocknnfigure example illustrating replication source blockchain within testimonium relay header doublelinked denoted arrow pointing direction green header represent current main chain source blockchain sake simplicity block hash ascending order make clearly evident block header submitted others relay eg block header x submitted block header x xb xa block header xb x x xa head corresponding branch block header x x x represent branch junctionsnnheader line f confirmation required function return true since block exists unlocked confirmed otherwise check whether header branch head ie child line f header branch head requires confirmation false returned since header succeeding block confirming isconfirmed called next childnnnotably algorithm always chooses first child next recursive call line course case block header branch junction multiple child exist thus caller algorithm need make sure function called block header number confirmation branch junction unlocked reached algorithm would need choose right child casennto avoid edge case function ispartofmainchain presented algorithm precalculates starting block header confirmation verification variable confirmstart ie since already traverse branch junction main chain head requested block header store branch junction traverse already unlocked since predecessor branch junction ensured unlocked well start confirmation verification branch junction instead requested block header reduced number confirmation encounter another branch junction confirmation verification branch junction locked stopping verification branch junction locked branch junction would already returned function ispartofmainchain starting point confirmation verificationnnnfunctionisconfirmedblockhash confirmationsnifheaderscontainsblockhashfalsethennreturnfalsenheaderheadersgetblockhashnifheadermlockeduntilnowthenreturnfalsenif confirmationsthenreturntruenifheadermchldnlengththenreturnfalsenchildheadermchldnnreturnisconfirmedchild confirmationsnnnalgorithm verifies whether block referenced blockhash least many confirmation specified parameter confirmationsnn verifying merkle proof membershipnnafter verifying block b part source blockchains current main chain block b confirmed least n succeeding block testimonium relay check merkle proof membership merkle proof depends data structure used source blockchain represent merkle tree proof concept see section implement merkle proof membership merkle patricia try merkle tree variation used blockchains like ethereum ethereum classicnnif verification merkle proof fails tx part block b successful tx included within block since testimonium relay already verified block b membership main chain source blockchain n block succeeding b assumed transaction tx fact part source blockchainnnas mentioned specifying sufficiently large number confirmation client requesting verification increase probability transaction tx remains main chain source blockchain verification procedure relies source blockchains header exactly replicated within testimonium relay destination blockchain therefore important disputers challenge illegal block header lock period detail disputing block header discussed next sectionnn disputing block headersnnto keep cost header submission low testimonium relay optimistically accepts newly submitted block header without performing source blockchains header validation procedure first potentially enables illegal block header enter relay transaction inclusion verification illegal block header prevented testimonium mean validationondemand patternnnthat newly submitted header assigned lock period offchain client ie disputers dispute block header deem illegal block header disputed header validation according validation protocol source blockchain carried validation fails illegal branch ie block header together descendant eliminated testimonium relay lock period passed transaction inclusion verification submitted header carried outnnthe validationondemand pattern leveraged whenever block header validation costly validating every single block header becomes expensivenn validationondemandnnalgorithm show pseudo code step performed whenever block header challenged disputer algorithm take hash disputed header input parameter first check whether disputed header still locked ie whether lock period expired yet line header locked anymore deemed valid disputednnif lock period header still active header validation triggered line concrete implementation validation depends block header validation procedure source blockchain reference implementation verification ethereum block header carried block header dispute since verifying ethashthe consensus algorithm used blockchains ethereum ethereum classicfor every submitted block header would otherwise lead high operational cost see section nnif validation return true ie block header valid falsely disputed function abort line case disputed header fact invalid validation return false illegal branch originating disputed header removed testimonium relay function prunebranch called line nnafter deletion illegal branch header hash also removed parent child list line since child list changed check line whether parent disputed block header become branch head parent hash added set branch head line parent exactly one child left line parent longer branch junction hence set field mjunction mbranchid descendant including next branch junction branch head corresponding field parent call updatedesc line omit pseudo code simple function due space constraint removal entire branch testimonium relay may change main chain thus line head main chain recalculatednn pruning illegal branchesnnalgorithm show pseudo code prunebranch function called remove illegal branch disputed block header removed function called recursively child disputed block header line recursive invocation prunebranch stop case header referenced blockhash child ie branch head besides removing header header hash map header hash also removed set branch head line nnto make submitter illegal block header accountable disputeheader function return list containing address submitter block header removed illegal branch course case header successfully disputed eg due expired lock period address returned returned address used penalize submitter discourage submission illegal block header future see section nnthe correct functioning testimonium relay ensured submitter continuously submit block header source blockchain destination blockchain disputers dispute submitted illegal block header however client submit dispute block header incur cost thus incentive structure encouraging participation needed detail incentive structure explained next sectionnnnfunctionprunebranchblockhashnheaderheadersgetblockhashnsubmittersnforall child headermchldn donbranchsubmittersprunebranchchildnsubmittersappendallbranchsubmittersnheadersremoveblockhashnsubmittersappendheadermsubmitternifbranchheadscontainsblockhashthennbranchheadsremoveblockhashnreturn submittersnnnalgorithm prune branch starting header referenced blockhashnn incentive structurennwithout incentive structure compensates offchain client submitting disputing block header submitter disputers may interest participating incentive structure propose reward offchain client submitting disputing block header also discourages submitter submitting illegal block headersnnto compensate disputers challenging illegal block header submitter required deposit stake stake locked duration lock period newly submitted block header stake locked withdrawn used submitting block header submitted header passed lock period without dispute submitter get back control corresponding locked stake however case block header disputed successfully within lock period ie validation block header fails disputer triggered dispute earns locked stake submitter well stake locked descendant illegal block header incentivize disputers also discourages submitter submitting illegal block header risk losing deposited stake course disputers incentivized dispute header potential reward higher cost executing disputennto encourage submission block header submitter receive fee every time submitted header used verifying inclusion transaction verification fee paid client requesting verification order fully compensate submitter total fee earned transaction inclusion verification header need greater initial submission cost header eq nntextitfeetimestextitno verificationstextitsubmission cost tagnnthe minimum verification fee thus calculated submission cost block header divided number verification taking place submitted block header eq nntextitfeefractextitsubmission costtextitno verification tagnnapplying validationondemand pattern together incentive structure rewarding participation already lower cost submitting new block header relay however submission cost decreased even applying slightly modified version contentaddressable storage pattern explained next sectionnnnn optimizationnnso far assumed data needed dispute transaction inclusion verification directly stored smart contract implementing testimonium relay however blockchains like bitcoin ethereum submitted transaction including parameter implicitly recorded blockchains transaction history take advantage fact storing hash block header block number certain meta data smart contract field parent hash merkle root hash longer need kept smart contract thus reducing amount stored data per block header subsequently reduces submission costnnwhenever client initiate dispute transaction inclusion verification read required full header data corresponding submittransactions recorded transaction history provide smart contract contract verify provided header integrity recalculating hash comparing hash stored smart contract way trust client invoking transaction inclusion verification block header dispute requirednnwhile pattern reduces submission cost lead increment cost transaction inclusion verification due increased amount data passed along transaction next section provide extensive evaluation testimonium assessing tradeoff well providing comprehensive security analysisnn evaluationnnin section evaluate proposed relay scheme regard operational cost security look prerequisite must fulfilled deploy testimonium relay schemenn quantitative analysisnnthe advantage testimonium traditional blockchain relay become apparent execution source blockchains standard header validation destination blockchain costly one example would bidirectional relay ethereum ethereum classic ethereum ethereum classic use ethash pow algorithm ethereum virtual machine evm execution environment however verification ethash native opcodes exist evm even gasoptimized implementation one provided smartpool verification ethash single block header still cost around million gas potentially leading high operational cost fully validating every single block header hence blockchains perfect fit validationondemand pattern employed testimonium relay schemenna advantage implementing testimonium first ethereumbased blockchains context sidechains sidechains used increase overall transaction throughput blockchain platform outsourcing certain transaction sidechain transfer digital asset main chain sidechain relay used prove existence certain piece state one chain chain vice versa ethereum popular blockchain regard decentralized application dapps digital asset experienced severe scalability issue past sidechains proposed combat issue testimonium lead cost saving traditional relay ethereumbased blockchains operation sidechains ethereum becomes lot cheapernn evaluation setupnnto evaluate operating cost testimonium implemented total three prototype testimonium testimonium baseline respectively evmbased blockchains like ethereum ethereum classic prototype testimonium testimonium implement validationondemand pattern testimonium additionally applies contentaddressable storage optimization explained section third prototype baseline act baseline experiment prototype implement validationondemand pattern instead fully validates block header submission done traditional relay btcrelay furthermore baseline use optimized search algorithm transaction inclusion verification instead implement naive search starting main chain head traversing header header supposedly containing transaction found genesis block reached functionality prototype summed table nnusing geth light client version collected block header containing branch ethereum main network period two month note also count uncle block branch sincewhen submitted testimoniumthey would introduce new branch fed block header three prototype deployed smart contract private development blockchain running parity ethereum node version beta config dev three prototype initialized block genesis blocknna fully functional reference implementation concept algorithm testimonium offchain client written go evaluation available opensource project github repeatability evaluation project contains three prototype used evaluation also evaluation script necessary block header data sql dump resultsnn
Original Title: Blockchain Technologies for Smart Energy Systems: Fundamentals,
  Challenges and Solutions
Original Transcription: "# Blockchain Technologies for Smart Energy Systems: Fundamentals, Challenges and Solutions\n\nNaveed UL Hassan*, Chau Yuen, and\n\nNaveed UL Hassan is with the Electrical Engineering Department, Lahore University of Management Sciences (LUMS), DHA, Lahore Cantt, 54792, Pakistan. (Email: naveed.hassan@lums.edu.pk).Chau Yuen is with the Engineering Product Development, Singapore University of Technology and Design (SUTD), 8 Somapah Road, 487372 Singapore. (Email: yuenchau@sutd.edu.sg).Dusit Niyato is with the School of Computer Engineering, Nanyang Technological University, 639798, Singapore. (e-mail: dniyato@ntu.edu.sg).This research is supported by Lahore University of Management Sciences Faculty Initiative Fund (FIF) Pakistan, and partly supported by the Natural Science Foundation of China and Jiangsu Province (Project No. 61750110529, 61850410535, BK20161147).\n\ntechnology solutions in each category. Blockchains possess several unique features, such as, decentralization, creation of a trustless network (in which nodes can resolve conflicts without a centralized authority), data storage in tamper-proof manner, fault tolerance and auditability. However, it should be noted that the choice of technology solutions has a significant impact on the resulting blockchain features and performance.\n\nThe use of blockchain in smart energy systems is a topic of tremendous research interest, because further development of these systems could potentially benefit from the integration of new and innovative technologies. Blockchain due to its unique features can facilitate numerous smart energy applications. For example, Figures 1 and 2 depict the blockchain concept and its potential role in two emerging smart energy applications. In Figure 1, blockchain technology is being used to facilitate P2P energy trading. In this application, energy prosumers can trade surplus energy with their neighbors. However, with the introduction of blockchain, intermediaries and brokers can be eliminated because data recorded on blockchain is verified by a distributed network of nodes. Automation can be achieved through computer programs called smart contracts, which are are stored on the blockchain, and define the contractual obligations as well as the transfer of assets between peers. Another application of blockchain is shown in Figure 2 for the verification of green energy. Once energy is added to the grid it becomes difficult to identify green energy from the traditional energy. However, a consumer can verify the renewable energy generated by the prosumer through the use of blockchain technology. These examples demonstrate the overall concept of blockchain technology and its use in smart energy systems. However, exact blockchain technology solutions (network, data, consensus, etc.) that should converge to fulfill the requirements of these applications are not obvious.\n\nFigure 1: P2P energy trading with the help of blockchain.\n\nThere are several research papers, projects, and ongoing trials that aim to leverage unique blockchain features to advance the digitalization of smart energy systems. Review of blockchain technology in energy sector can be found in [17, 18, 19]. In [17], authors provide a comprehensive review and classification of 140 blockchain based projects in the energy sector. In [18], authors explore potential challenges of blockchain based P2P microgrids and they discuss a framework that incorporates technological, economic, social, environment, and institutional dimensions. The paper suggests the inclusion of economic, social, and environmental dimensions to bridge the gap between technology and institutions. In [19], authors review blockchain based smart grid projects and discuss frameworks for further blockchain integration in smart grids. According to these frameworks, creation of a cyber layer designed for blockchain applications, aggregation of computing resources in microgrids, and smart grid protection and security issues can be leveraged to achieve better integration of blockchain in smart grids. Blockchain integration efforts in Internet of Things (IoT) are also discussed in [20, 21]. It is important to note that none of these papers identify the exact choice of blockchain technology solutions for different smart energy systems and applications.\n\nBlockchain technology is relatively new and although it holds tremendous potential, the number of blockchain technology solutions and implementation platforms are still developing. The choice of blockchain technology solutions that can fulfill the requirements of different smart energy applications (e.g., as shown in Figures 1 and 2) is not entirely obvious. In this paper, we provide a review of blockchain building blocks followed by the identification of the most suitable blockchain technologies according to the requirements of various smart energy systems. For example, blockchain network management techniques can be classified into public, consortium, and private categories. Similarly, data management techniques can be classified into on-chain (all data is stored on blockchain) and off-chain (only data hashes are stored on blockchain) types. Different combinations of these technology options result in different blockchain implementation platforms with different features and performance. We review important existing blockchain platforms and few representative blockchain based smart energy projects in four different domains, which include smart infrastructure (SI), energy trading (ET), green initiatives (GI), and energy management (EM). Through this review, we discover and reveal that existing blockchain platforms are\n\nFigure 2: Distributed green energy management with the help of blockchain.\n\nnot entirely suitable for smart energy systems. Therefore, in order to achieve appropriate integration of blockchain technology solutions for smart energy applications, we first consider sixteen requirements, which represent the needs of a broad selection of smart energy applications. We analyze the suitability of different blockchain technologies in fulfilling these requirements and determine appropriate blockchain building blocks for various smart energy applications. To summarize, our major contributions are the following:\n\n* We present a review of blockchain fundamentals and discuss various blockchain building blocks, which include network, data, consensus, identity, and automation management techniques.\n* We review existing blockchain platforms and classify representative blockchain-based smart energy projects into SI, ET, GI, and EM domains. We show that a large number of projects use blockchain building blocks that are computing- and resource- intensive, and hence less efficient in terms of data and identity management.\n* We list 16 requirements for smart energy systems and organize them into 4 different categories, namely decentralization & trust, data management, security, and scalability. Based on these requirements, we identify suitable blockchain building blocks that are suitable for smart energy systems and applications.\n* We further customize blockchain technology solutions for multiple energy applications within each domain (SI, ET, GI, EM).\n* We also identify open research areas related to blockchain technology that are needed to fulfill the future needs in smart energy systems.\n\nThe rest of the paper is organized as follows. In Section II, we present blockchain fundamentals and different blockchain technology solutions. In Section III, we review some blockchain integration efforts in smart energy systems. In Section IV, we identify appropriate blockchain technology solutions for various smart energy applications. In Section V, we discuss blockchain technology gaps for smart energy integration. We conclude the paper in Section VI.\n\n## II Blockchain\n\nIn this section, we present blockchain and various blockchain building technologies for network, data, consensus, identity, and automation management. The key points of this section are also summarized in Table I.\n\n### _Blockchain Fundamentals_\n\nBlockchain is a decentralized-digital-distributed ledger. A set of transactions, which may indicate transfer or exchange of monetary value or digital assets, such as, information, services or goods is produced and collected by a distributed network of computing nodes (P2P network). A time-stamped data block (containing these transactions) is created through decentralized consensus mechanism among the nodes according to pre-defined protocols. The newly created block also contains reference to the block that came before it (parent block) in the form of cryptographic hash thus establishing a link between the blocks. The new block is added in front of its parent block and a chain like structure of blocks is obtained, hence we get the name 'blockchain' (as shown in Figures 1 and 2). Once blockchain grows to a sufficient size, transactions recorded on it become practically immutable and resistant to change. Moreover, with blockchain, a 'trustless' network of nodes is also created. In a trustless network, non-trustingnodes can interact with each other without a centralized entity or an intermediary and conflicts are automatically resolved with the help of protocols.\n\n### _Blockchain Technology Solutions_\n\nBlockchain creation and maintenance requires network, data, consensus, identity, and automation management. Below we present various blockchain technology options in each category and discuss their advantages and disadvantages.\n\n**Blockchain Network Management**: Blockchain network management can be classified into three categories [12].\n\n**Public (N1)**: Public blockchain networks are truly decentralized and permissionless. Any node can join or leave the network. The nodes have full permission to maintain a complete copy of the blockchain (referred to as 'public blockchain'). All the nodes can issue transactions, and they can participate in the block creation process according to publicly defined protocols and algorithms.\n\n\n\n**Consortium (N2)**: Consortium blockchain networks are permissioned networks. The ability of a node to join the network or to access the blockchain is controlled by a group of organizations, which assign permissions to nodes across their organizations to join the network and to read or modify the associated 'consortium blockchain'. In some situations, nodes outside the consortium may also be allowed to access and read the consortium blockchain contents to achieve greater transparency. However, such nodes are not allowed to modify the blockchain state.\n\n**Private (N3)**: Private blockchain networks are also permissioned networks. The network is controlled by a single organization, which allows only a limited number of nodes within the organization to join the network and to read or modify the state of 'private blockchain'.\n\n**Data Management**: Blockchain records transactions and stores data. There are two broad techniques for blockchain data management [13].\n\n**On-Chain (D1)**: In on-chain data management, all the transactions are stored on the blockchain. The size of blockchain continuously grows and storage requirements keep on increasing. This method is not suitable for resource constrained nodes.\n\n**Off-Chain (D2)**: In off-chain data management, only the hash values of data transactions are stored in the blockchain, while raw transaction data is stored using traditional methods. In this method, storage requirements at network nodes are significantly reduced. However, there are additional requirements e.g., synchronization of database with blockchain and availability of server hosting raw data.\n\n**Consensus Management**: The choice of node/nodes entrusted to create a new block depends on the consensus algorithm adopted by the blockchain network. Consensus algorithms allow all the nodes in the network to agree to the same world view of the state of the blockchain. There are different types of consensus algorithms [14, 21].\n\n**Proof of Work (C1)**: In Proof of Work (PoW) algorithm, nodes compete to solve an appropriate hashing puzzle that requires expensive computing resources. Block created by the node which is the fastest to solve the given puzzle is accepted by the network. This method is useful in permissionless networks to avoid Sybil attacks. In Sybil attack, a single node may vote multiple times with different identities to influence the vote outcome. However, PoW is energy intensive and wastes tremendous amount of resources.\n\n**Proof of Stake (C2)**: In Proof of Stake (PoS) algorithm, nodes are selected to create new blocks in pseudo-random fashion. Probability of a node being selected is proportional to its economic stake in the network. This algorithm is also suitable for permissionless blockchain and punishes misbehaving nodes by confiscating their stake in the network. However, this method is prone to \"nothing at stake\" attack.\n\n**Voting-based (C3)**: In permissioned blockchain networks where only known nodes can join the network, consensus among validating nodes on the contents of new block can be achieved through voting mechanisms. Voting schemes are based on Byzantine fault tolerant (BFT) algorithms and its variants, such as, Tendermint and Federated BFT. In these methods multiple rounds of voting might be required to reach consensus and there is also a significant networking overhead, which has a negative impact on network scalability.\n\n**Authority-based (C4)**: Proof of Authority (PoAu) algorithm can also be used in certain blockchain networks. In this mechanism, authorized (trusted) nodes in the network create a new block in a round robin fashion. PoAu eliminates message exchange among nodes for consensus building and is more resource-efficient. However, inclusion of trustednodes reduces the trustless nature of the resulting blockchain network.\n\n**Identity Management**: Blockchain network relies on public key cryptography. Each node has a pair of public/private key to sign and verify transactions. There are different ways to manage the identity and entitlements of blockchain nodes [15].\n\n**Self-sovereign identity (S1)**: In this method, every node owns and controls its identity without relying on an external authority for attestation or verification of node credentials. There is no central server and personal data is not required for identity creation. Nodes can perform identity proofing by gathering attributes from an ecosystem of identity providers. Each node is allowed to create multiple keys as required to keep its identity private. Nodes can also selectively disclose their attributes to maintain privacy. Sovrin and uPort are examples of self-sovereign identity management systems.\n\n**Decentralized-trusted identity (S2)**: This method requires a central server to perform identity proofing of nodes. In the initial stage, a node has to provide identity proof (personal information) to the central server. After this bootstrap phase, node identity is recorded in the blockchain for later validation. Verified nodes can then create further keys as required. ShoCard and BitID are some examples of decentralized-trusted identity management system.\n\n**Automation Management**: Automation management on blockchain is carried out with the help of smart contracts, which may define contractual obligations, custody or transfer of digital assets and rights and privileges of nodes. Smart contracts provide greater automation and replicate actions that are generally performed by trusted third parties or intermediaries. Turing-complete programming languages that can support arbitrary logic and computations are generally required to develop smart contracts. We can broadly classify smart contracts into two types [16].\n\n**Deterministic smart contracts (T1)**: Deterministic smart contracts do not require any information from external party. All the necessary information to execute a smart contract can be obtained from the data already stored on the blockchain.\n\n**Non-deterministic smart contracts (T2)**: Non-deterministic smart contracts depend on information (called oracles or data feeds) from an external party, e.g. it may need external weather information for execution. Non-deterministic smart contracts provides greater flexibility at the expense of greater vulnerability to external attacks.\n\nThere is a wide variety of blockchain technology solutions. Combination of blockchain building blocks also result in different tradeoffs and different blockchain features. In addition, the requirements of different smart energy applications are also different. However, before identifying the best possible blockchain technology solutions for various smart energy applications, we first provide a brief review of existing blockchain platforms and blockchain integration efforts in smart energy systems.\n\n## III Review of Blockchain Integration in Smart Energy Systems\n\nIn this section, we review some blockchain integration efforts in smart energy systems. Please note that in this section, we do not intend to provide a complete survey of blockchain integration efforts in smart energy systems. A comprehensive review and classification of 140 blockchain based projects in the energy sector is available in [17]. In this section, we only present some selected platforms and projects in each smart energy domain with the objective to reveal that most of these efforts do not use blockchain technologies customized for energy applications. Thisreview will further facilitate us in the identification of the most suitable blockchain technology solutions according to the requirements of smart energy systems. The contributions of this section are summarized in Table II and Figure 3.\n\n### _Review of Blockchain Platforms Used in Smart Energy Systems_\n\nBlockchain platforms combine network, data, consensus, identity, and automation management technologies for the creation of blockchain based projects. Blockchain integration in smart energy applications is being carried out either using open-source or proprietary blockchain platforms. Popular open-source platforms include Ethereum, HyperLedger, Tendermint, and Energy web foundation (EWF). Proprietary platforms are developed to suite the requirements of specific applications and sometimes these platforms also develop proprietary management protocols and algorithms. It should be noted that a majority of open-source and proprietary platforms are non-modular [22].\n\n**Ethereum**: Ethereum is a generic open source blockchain development platform governed by Ethereum developers and it is widely used for developing blockchain applications for smart energy systems [23]. This platform was developed for public (N1) blockchain management. However, the open-source code of Ethereum can be easily modified to maintain consortium (N2) and private (N3) networks. Ethereum supports on-chain data management (D1). PoW (C1) consensus algorithm is currently used but there are plans to switch to PoS (C2) algorithm. The platform can support self-sovereign (S1) as well as decentralized-trusted (S2) identity management techniques. Ethereum supports Turing-complete programming languages (Solidity and Serpent), which can be used to create deterministic (T1) as well as non-deterministic (T2) smart contracts.\n\n**HyperLedger**: HypberLedger is an open-source blockchain development platform supported by The Linux foundation [24]. This platform can be used to set up consortium (N2) and private (N3) networks. The platform supports on-chain data management (D1), and voting-based consensus (C3) algorithms. This platform can support self-sovereign (S1) as well as decentralized trusted (S2) identity management techniques. Turing-complete programming languages such as, Java, Go, Solidity, Fabric and Rust, allow writing deterministic smart contracts (T1). However, support for non-deterministic smart contracts (T2) through oracles is not yet available.\n\n**Tendermint**: Tendermint is another application oriented framework that can be used to set up public, consortium or a private network of P2P nodes (N1,N2,N3) [25]. This platform supports on-chain data management (D1) and voting-based (C3) consensus algorithms. This platform can support self-sovereign (S1) as well as decentralized-trusted (S2) identity management techniques. The platform supports various Turing-complete programming languages that currently allows writing deterministic smart contracts (T1).\n\n**EWF**: EWF blockchain platform is supported by more than 70 companies and its aim is to integrate and accelerate blockchain technology in smart energy systems [26]. EWF platform is Ethereum-compliant but it is more customized for smart energy applications. EWF platform can be used to set up consortium (N2) and private (N3) networks, supports on chain-data management (D1), and PoAu (C4) consensus algorithm. This platform can support self-sovereign (S1) as well as decentralized-trusted (S2) identity management techniques. Deterministic (T1) and non-deterministic (T2) smart contracts can be developed in Turing complete C and C++ programming languages. Tobalaba, which is the test version of this platform is already available for developers.\n\n\n\n**Proprietary**: Several proprietary blockchain platforms also exist for smart energy applications. For example, Solar Bankers is developing a proprietary consensus algorithm called Obelisk which runs on their Skychain blockchain [27]. The idea is based on developing a trusted consortium of nodes, which generate and validate data blocks. Similarly, PROSUME is also developing a proprietary blockchain based platform to support a multitude of smart energy applications [28].\n\nIn Table II, we provide a summary of blockchain technology solutions supported by these platforms.\n\n### _Review of Blockchain Based Smart Energy Projects_\n\nWe review blockchain based smart energy projects in four smart energy domains, which include SI, ET, GI, and EM. These domains are broad and cover several interesting and useful applications. The list of domains and considered applications in each domain are presented in Figure 3. A short notation for each application is also introduced for further use in the paper. For example, SI-1 notation is used for automated metering infrastructure (AMI) application. The scenario in Figure 1 represents ET-2 application, while that in Figure 2 represents EM-3 application.\n\nDue to space limitations, in the following, we only discuss few representative projects in each domain. Further details of these projects can be found in [17, 29, 30, 20] and references therein.\n\n**Blockchain Projects in SI Domain**:\n\nFigure 3: Smart energy system domains and applications.\n\n\n\n**Bankymoon**: This project is related to AMI SI-1 application. Smart meters compute and communicate energy consumption of an industrial or residential building at regular intervals for billing automation and reduction of electricity theft incidents [31, 32]. However, in Bankymoon project, blockchain enabled smart meters are being developed and experimented in order to further automate financial transactions. These meters can be loaded with cryptocurrencies and payments can be settled in real-time through smart contracts. This project is being developed using Ethereum platform.\n\n**TheSunExchange**: This project is related to asset management SI-2 application. High initial costs of RES technologies could become a barrier in taking communities off-grid. However, this issue may be resolved by creating shared assets in smart energy systems e.g., by purchasing solar PVs through crowd-funding [33]. TheSunExchange project allows users to purchase solar panels and lease them to earn passive income. Blockchain integration enables transparent management of assets as well as the management of solar energy produced by these assets. Therefore, this project can be also be classified as an example of example of EM-3 application, which is related to distributed EM.\n\n**GridChain (PONTON)**: This project is related to power grid monitoring SI-3 application. In power grids, IoT sensors in the transmission and distribution systems facilitate monitoring of grid parameters in order to automate fault diagnosis and to maintain power-balance for grid stability [34]. Blockchain integration can further help in achieving transparency and fixing liability. In this context, the objective of GridChain project developed by PONTON is to enable real-time power balance and congestion management by providing coordination between various grid entities. This project can also be classified as an example of real-time DRM application (EM-2).\n\n**Blockchain Projects in ET Domain**:\n\n**EnerChain (PONTON)**: This project deals with wholesale energy trading ET-1 application. The integration of blockchain in energy trading applications achieves greater transparency and automation. EnerChain project is also developed by PONTON to enable wholesale energy trading in European regional power markets. The project aims to offer wholesale energy trading solutions in different time frames such as, day-ahead, monthly, quarterly, and yearly.\n\n**Brooklyn Microgrid**: This project is related to P2P energy trading ET-2 application, which is shown in Figure 1. In smart energy systems, prosumers can engage in decentralized energy trading activities where they can directly trade energy with other prosumers or consumers [35, 36]. Brooklyn Microgrid project is an example of real-world development of blockchain based P2P energy trading solution. In this project, prosumers can directly sell their surplus energy to their neighbors (without needing any brokers or intermediaries), energy transactions are recorded on blockchain, and payments are settled automatically through smart contracts.\n\n**Blockchain Projects in GI Domain**:\n\n**Nasdaq Linq**: This project is related to the management and trading of green certificates and carbon credits GI-1 application. To encourage RES uptake, several countries and states issue green certificates and carbon credits [7], which can also be traded. However, with greater integration of RES in power grids, management of these certificates is becoming challenging. In this context, Nasdaq Linq project aims to bring efficiency, quick verification, and elimination of paper records for green certificate management through the integration of blockchain. This projectis being developed using proprietary platform.\n\n**NRGeoin**: This project is related to the management of incentives for green behavior GI-2 application. In this project, NRGcoins are given as a reward to incentivize local production and consumption of green energy. It should be noted that 1 NRGcoin is equivalent to 1kWh energy. The use of virtual currency in this project creates additional value around their blockchain. However, unlike Bitcoin, these coins are not mined but are issued by the blockchain developers. The smart contract framework of this project is based on Ethereum platform.\n\n**Blockchain Projects in EM Domain**: DRM is an important concept in smart energy grids. However, blockchain based projects for EM-1 and EM-2 applications are relatively rare.\n\n**Key2Energy**: This project is related to distributed energy management EM-3 application. In this project, blockchain is used for energy management in multi-apartment houses. The objective is to maximize the profit of each house by selling PV energy and minimizing the energy cost of shared facilities in the building. Platform details of this project are not available.\n\n**Car eWallet**: Number of EVs with batteries is increasing. Due to mobility, management of EVs and their energy consumption becomes quite challenging [37]. Car eWallet project is related to EV EM-4 application. This project provides a blockchain based solution for car sharing, car rental, and EV charging. The project also allows automatic processing of payments.\n\nIn Table II, blockchain platforms used for these projects are also identified. It should be noted that several blockchain platforms (except EWF) are not exclusively developed for smart energy applications. Therefore, the embedded technology options in these platforms are also not entirely suitable for these applications. For example, a large number of projects use Ethereum, which embeds computing-intensive PoW algorithm. Similarly, several platforms lack capabilities to support off-chain data management as well as non-deterministic smart contract management. It is also important to note that most of the blockchain based smart energy projects are still in the development or trial phases, while real-world implementations are rare. In this context, in order to guide further research and development in this field, there is a need to identify appropriate blockchain technology solutions according to the requirements of smart energy systems. In the next section, we discuss these requirements and accordingly identify appropriate choice of blockchain technology solutions for various applications.\n\n## IV Appropriate Choice of blockchain technologies according to the smart energy system requirements\n\nWe first discuss suitable blockchain technology solutions according to the requirements of smart energy systems followed by the customization of these solutions for various applications. We summarize the key contributions of this section in Tables III and IV.\n\n### _Suitable Blockchain Technology Solutions According to Smart Energy System Requirements_\n\nWe first discuss a total of sixteen requirements (R1-R16) in four different categories, which are applicable to a broad selection of smart energy applications listed in Figure 3 and to the scenarios depicted in Figures 1 and 2.\n\n**Decentralization & Trust Requirements**:\n\n**Decentralization (R1)**: Due to the inclusion of RES and mobile loads (EVs), the architecture of smart energy systems is becoming decentralized. Efficient implementation of various applications in different domains requires decentralized networking and control.\n\n**Conflict Resolution Mechanism (R2)**: Smart energy domains involve interaction between multiple non-trusting nodes. Some mechanisms (entities or technologies) are therefore required to mediate between nodes in order to resolve conflicts.\n\n**Intermediaries (R3)**: In several smart energy applications, intermediaries are required to support the activities of principal players. The role of intermediaries arise due to operational and technological limitations of the principal players. For example, financial transactions between consumers and generators are mostly settled through banks. Similarly, brokers or energy trading platforms are required to match the buying and selling requirements of generators and consumers.\n\n**Non-repudiability (R4)**: Non-repudiability refers to the availability of irrefutable proof of who performed a certain action even if the nodes are not cooperating. In smart energy domains, non-repudiability is required to establish liability.\n\n**Data Management Requirements**\n\n**Tamper-proof record keeping (R5)**: Recording, trading and transportation of electricity, assets, and other resources is involved in various smart energy systems. It is also important to note that in several situations electricity flow occurs almost immediately while financial settlements are carried out later. Therefore, it becomes important to store data in a tamper-proof manner.\n\n**Data correction & erasure (R6)**: In the event of malfunction, hacking, or tampering of sensors or equipment, wrong data could get recorded. If such events are detected or reported, data correction or data erasure becomes essential. With increased automation, all the smart energy domains require a certain ability to correct and erase such erroneous data.\n\n**Data Backup (R7)**: Data loss can create inconvenience, disruption and financial loss. Similarly, data storage and retrieval from a single database also requires permanent availability of the data hosting node. Thus, a single point of failure is created in centralized systems. Data collected in various smart energy systems domains is often critical and important and therefore requires adequate backup to ensure smooth operations.\n\n**Privacy Protection (R8)**: In various smart energy systems there is a high requirement to keep data and node identity private. For example, smart meter data reveals private information about the habits, schedule and behavior of users.\n\n**Security Requirements**:\n\n**Authentication (R9)**: Authentication is concerned with determining the identity of a node in the system in order to block unauthorized access. A node can be authenticated through its unique credentials in the system (e.g., public key, address, name). Smart energy systems often involve critical data and infrastructure. Therefore, authentication is always required in all the smart energy domains.\n\n**Authorization (R10)**: Authorization deals with managing access and privileges of various nodes in the network. In smart energy systems, nodes have different roles and therefore require different authorization in different applications.\n\nIn addition, there is also a certain role of regulatory bodies and government agencies. Therefore, appropriate authorization and detecting any violations of privileges and rights is required in such systems.\n\n**Data Integrity (R11)**: Data integrity refers to the detection of unauthorized changes in data. Decentralized architecture requires large number of critical messages exchanged between various nodes and data integrity violations can result in safety problems or harmful attacks on the critical infrastructure.\n\n**Auditability (R12)**: Auditability is concerned with the ability to reconstruct complete history of certain event or action from the historical records. In smart energy systems, auditability is required to fix liability in case of malfunctions or conflicts or to safeguard commercial and financial interests or to fulfill regulatory requirements.\n\n**Scalability Requirements**:\n\n**Throughput (R13)**: In smart energy systems, a single node often produces a small amount of data. However, a large number of nodes are involved to build meaningful applications. If the data requirements of a single node is considered as a single transaction then a large number of transactions happen every second. Therefore, smart energy systems require high data throughout.\n\n**Latency (R14)**: Smart energy applications require low latency in order to ensure smooth monitoring, control and operation of appliances, equipment and processes. Latency of some critical applications e.g., required for grid stabilization, is only few ms.\n\n**Process Automation (R15)**: Smart energy systems are built on the promise of making RES integration, energy transportation and energy trading more efficient. This can be achieved through increased process automation resulting in the reduction in human intervention and simplification of legacy procedures.\n\n**Cost (R16)**: Smart energy systems integrate novel technologies and new equipment (smart meters, sensors, etc.), which help reduce various operating costs. However, high upfront costs due to equipment replacement or technology up-gradation is a major barrier in the adoption of various concepts. In this context, all the smart energy domains can benefit from cost reductions.\n\nBased on these requirements, we can now determine the suitability of blockchain technology solutions for various smart energy systems and applications. The suitability analysis is presented in Table III. This analysis is carried out by matching the features, advantages and disadvantages of various blockchain technology solutions discussed in Section II with smart energy system requirements. Based on this analysis, consortium (N2) and private (N3) network management emerge as more suitable options for such systems. Off-chain data management (D2) can also fulfill more requirements as compared to on-chain data management technique. Similarly authority-based consensus management (C4) is the best consensus algorithm for smart energy systems, while self-sovereign identity management (S1) and deterministic smart contracts (T1) can fulfill more requirements. This analysis enables quick identification of appropriate blockchain technology solutions for smart energy systems. However, different smart energy applications, such as, P2P energy trading and distributed green energy management (as shown in Figures 1 and 2) also have slightly different requirements. Hence, there is also a further need to customize blockchain technology solutions for various smart energy applications.\n\n\n\n### _Customization of Blockchain Technology Solutions for Various Smart Energy Applications_\n\nRequirements of smart energy applications differ from each other, which necessitate further customization of blockchain technology solutions. For example, some applications require low latency, some require high privacy protection, etc., [38, 39]. In this subsection, we further identify appropriate blockchain technology solutions for various smart energy applications shown in Figure 3. The discussion below is also summarized in Table IV.\n\n**SI domain**: AMI SI-1 application has relatively relaxed latency and throughput requirements. For this application, consortium (N2) and private (N3) network management techniques can be used. Private network management is preferred if data is directly handled by the utility. Since smart meters are resource constrained nodes, off-chain data management (D2) technique is more suitable. For consensus management, PoS (C2) and PoAu (C4) algorithms are better options. This application requires high privacy protection. However, because of regulatory and registration requirements of smart meter with utility company, self-sovereign identity (S1) management cannot be used. Instead decentralized-trusted identity (S2) management is a more suitable option. Moreover, necessary automation, if required, can be managed with the help of deterministic smart contracts (T1). Asset management SI-2 application has relatively low privacy and throughput requirements. For this application, choice of network, data, consensus, and automation management is the same as SI-1. For managing shared RES, PoS (C2) is more suitable option. However, when there are low latency requirements, PoAu (C4) algorithm is more preferable. For identity management, self-sovereign (S1) as well as decentralized-trusted identity (S2) management are suitable. However, if Know Your Customer (KYC) requirements are not applicable then self-sovereign (S1) technique can also be used. Grid monitoring application has extremely stringent latency requirements (few ms). For this application, network, data, identity, and automation management options are the same as identified for SI-1 application. However,due to extremely low latency requirements, only PoAu (C4) is a suitable consensus management solution for this application. However, even this algorithm can fail to meet the required performance.\n\n**ET domain**: Wholesale energy trading application has relatively low privacy requirements, therefore, public and consortium network management techniques (N1,N2) are more suitable. N1 should be used if trading platform is being developed across multiple regional markets. For more localized P2P energy trading ET-2 application, only consortium network management technique (N2) is suitable. For both the applications, off-chain data management (D2) technique is more suitable. For consensus, all the options are suitable for ET-1. For ET-2, PoW (C1) should be avoided because it is more resource-intensive. PoAu (C4) algorithm should also be avoided for ET-2 application because it requires trusted nodes in the network and dilutes the trustless feature of blockchain. Both the identity management schemes may be used for ET-1 and ET-2. Similarly, for both the applications, the choice between deterministic and non-deterministic smart contracts (T1,T2) can be made based on the availability of information inside or outside the network for the execution of smart contracts. With this information, the required ingredients to build the best blockchain for P2P energy trading scenario depicted in Figure 1 can be easily identified.\n\n**GI domain**: Privacy requirements of green certificates GI-1 applications are less stringent. Suitable blockchain technology solutions for this application are the same as we identified for ET-1 application. For behavior incentives GI-2 application with less stringent latency and throughput requirements, the choice of network, data, identity and automation management is the same as identified for SI-1 application. However, for consensus, voting-based (C3) technique can be used if there are limited number of nodes in the network and and PoAu (C4) techniques can also be adopted to conserve resources.\n\n**EM domain**: For contract-based DRM EM-1 application, suitable technology options are the same as identified for SI-1 application. However, for real-time DRM EM-2 application, due to extremely low latency requirements, only PoAu (C4) algorithm is more suitable choice, while all other options remain the same as identified for EM-1. For distributed energy management EM-3 application, suitable technology options for network, data, identity, and automation management are the same as we identified for ET-2 application. However, for this application, due to relatively low latency requirements, PoS (C2) and PoAu (C4) techniques are more suitable for consensus management. Finally, suitable technology options for EV EM-4 application are the same as identified for ET-2 application except that for EM-4 we can also use PoAu (C4) algorithm to conserve resources.\n\n## V Blockchain Technology Gaps for Smart Energy Systems\n\nBlockchain is still evolving and there are several technology gaps, which could limit its adaptation in smart energy systems. Below we discuss some blockchain technology gaps for smart energy systems.\n\n**Network management**: Management of blockchain network requires appropriate protocols and algorithms. These protocols are required for transaction forwarding, data dissemination, node discovery, maintaining a list of misbehaving nodes, and limit on number of peer connections. The performance of these protocols has a direct impact on latency, throughput, and speed of transaction processing. In this context, there is a need to develop delay-aware, security-aware, privacy-aware, and scalable network management protocols for blockchain integration in smart energy systems. Moreover, the protocols must also provide flexible parameters in order to achieve various tradeoffs according to latency and throughput requirements of smart energy applications.\n\n**Data management**: Implementation of off-chain data management, which is mostly required for resource constrained nodes in smart energy systems is more challenging as it requires synchronization and availability of conventional databases. In this context, determination of optimal amount of data that should be kept on-chain and off-chain for various applications is important. Storage of off-chain data in tamper-proof manner is also challenging. Furthermore, data models and database schema can also vary across different organizations or applications. Novel techniques for handling multiple types of data models, database schema, and query processing on blockchain are also required.\n\n**Consensus management**: PoAu algorithm is the fastest consensus management algorithm. However, the latency and throughput requirements of some applications are extremely stringent (in ms), and even PoAu may fail to fulfill those requirements. There is a clear need for further improvements in the consensus management techniques for smart energy applications. For example, the use of implicit consensus proposed in [40] maybe explored.\n\n**Identity management**: In several smart energy applications, due to KYC requirements enforced by the regulator, decentralized-trusted identity scheme has to be used. This scheme has less advantages as compared to more private self-sovereign identity management scheme. Recovering compromised identities can also become a challenge in some smart energy systems particularly for nodes with private or critical data.\n\n**Automation management**: Security of smart contract is critical because if a smart contract is not well-written and secure, it may be hacked or invoked under different circumstances that may not represent the actual intention of the original programmer. Non-deterministic smart contract management presents even a bigger security challenge. Smart energy applications involving critical data and industrial infrastructure necessitate appropriate programs and templates for the development of secure and well-written smart contracts. Smart contract execution often require sequential processing, which can slow down transaction verifications. Development of appropriate sharding techniques for parallel processing is therefore required to match the high performance demands of various applications.\n\n**Lack of suitable implementation platforms**: Many popular blockchain platforms are non-modular and they do not embed appropriate technology solutions for smart energy systems. For example, the platforms lack support for off-chain data management and non-deterministic smart contracts, which are mostly required for resource constrained nodes. Therefore, development of open source and modular blockchain platforms with appropriate embedded technologies to support multiple smart energy applications is critically needed.\n\n## VI Conclusion\n\nBlockchain technology is novel but complicated, and its integration in any domain requires the convergence of appropriate building blocks to achieve the respective desired objectives. Existing blockchain integration efforts in smart energy systems mostly use open-source blockchain platforms with embedded functionalities. These platforms are not entirely designed for energy applications and the development of blockchain based energy projects through these platforms may not provide the expected blockchain integration benefits. In this paper, we adopted a systematic approach, where we first collected the requirements of smart energy systems. After detailing the requirements for each smart energy domain, we determined the most suitable blockchain building blocks for respective smart energy systems. Accordingly, we identified blockchain technologies that meet these requirements. We further customized blockchain technologies for various smart energy applications in SI, ET, GI and EM domains. The analysis in this paper can help in the design of flexible blockchain platforms customized for smart energy systems, as well as reaping the most benefits out of blockchain integration in smart energy systems. Significant new research in blockchain technologies is still required to meet the diverse and often stringent latency, privacy, and security requirements of smart energy applications. Moreover, modular blockchain platforms, where embedded technology options can be changed on demand, would also be required to support and accelerate blockchain integration in a wide variety of smart energy applications.\n\n## References\n\n* [1] M. Liserre, T. Sauter, and J. Y. Hung, \"Future energy systems: Integrating renewable energy sources into the smart power grid through industrial electronics,\" _IEEE Industrial Electronics Magazine_, vol. 4, no. 1, pp. 18-37, 2010.\n* [2] H. Farhangi, \"A road map to integration: Perspectives on smart grid development,\" _IEEE Power and Energy Magazine_, vol. 12, no. 3, pp. 52-66, 2014.\n* [3] T. Strasser, P. Siano, and Y. Ding, \"Methods and systems for a smart energy city,\" _IEEE Transactions on Industrial Electronics_, vol. 66, no. 2, pp. 1363-1367, 2018.\n* [4] O. Hafez and K. Bhattacharya, \"Integrating ev charging stations as smart loads for demand response provisions in distribution systems,\" _IEEE Transactions on Smart Grid_, vol. 9, no. 2, pp. 1096-1106, 2018.\n* [5] T. Sousa, T. Soares, P. Pinson, F. Moret, T. Baroche, and E. Sorin, \"Peer-to-peer and community-based markets: A comprehensive review,\" _Renewable and Sustain. Energy Reviews_, vol. 104, pp. 367-378, 2019.\n* [6] W. Tushar, C. Yuen, H. Mohsenian-Rad, T. Saha, H. V. Poor, and K. L. Wood, \"Transforming energy networks via peer to peer energy trading: Potential of game theoretic approaches,\" _IEEE Signal Processing Magazine_, vol. 35, pp. 90-111, 2018.\n\n* [7] M. Hustveit, J. S. Frogner, and S.-E. Fleten, \"Tradable green certificates for renewable support: The role of expectations and uncertainty,\" _Energy_, vol. 141, pp. 1717-1727, 2017.\n* [8] H. T. Haider, O. H. See, and W. Elmenreich, \"A review of residential demand response of smart grid,\" _Renewable and Sustainable Energy Reviews_, vol. 59, pp. 166-178, 2016.\n* [9] K. Ma, Y. Yu, B. Yang, and J. Yang, \"Demand-side energy management considering price oscillations for residential building heating and ventilation systems,\" _IEEE Transactions on Industrial Informatics_, 2019.\n* [10] F. Tschorsch and B. Scheuermann, \"Bitcoin and beyond: A technical survey on decentralized digital currencies,\" _IEEE Communications Surveys & Tutorials_, vol. 18, no. 3, pp. 2084-2123, 2016.\n* [11] A. Narayanan, J. Bonneau, E. Felten, A. Miller, and S. Goldfeder, _Bitcoin and cryptocurrency technologies: a comprehensive introduction_. Princeton University Press, 2016.\n* [12] M. Vukolic, \"Rethinking permissioned blockchains,\" in _ACM Workshop on Blockchain, Cryptocurrencies and Contracts_, 2017, pp. 3-7.\n* [13] X. Xu, I. Weber, M. Staples, L. Zhu, J. Bosch, L. Bass, C. Pautasso, and P. Rimba, \"A taxonomy of blockchain-based systems for architecture design,\" in _IEEE ICSA_, 2017, pp. 243-252.\n* [14] T. T. A. Dinh, R. Liu, M. Zhang, G. Chen, B. C. Ooi, and J. Wang, \"Untangling blockchain: A data processing view of blockchain systems,\" _IEEE Transactions on Knowledge and Data Engineering_, vol. 30, no. 7, pp. 1366-1385, 2018.\n* [15] P. Dunphy and F. A. Petitcolas, \"A first look at identity management schemes on the blockchain,\" _IEEE Security & Privacy_, vol. 16, no. 4, pp. 20-29, 2018.\n* [16] M. Alharby and A. van Moorsel, \"Blockchain-based smart contracts: A systematic mapping study,\" _arXiv preprint arXiv:1710.06572_, 2017.\n* [17] M. Andoni, V. Robu, D. Flynn, S. Abram, D. Geach, D. Jenkins, P. McCallum, and A. Peacock, \"Blockchain technology in the energy sector: A systematic review of challenges and opportunities,\" _Renewable and Sustainable Energy Reviews_, vol. 100, pp. 143-174, 2019.\n* [18] A. Ahl, M. Yarime, K. Tanaka, and D. Sagawa, \"Review of blockchain-based distributed energy: Implications for institutional development,\" _Renewable and Sustainable Energy Reviews_, vol. 107, pp. 200-211, 2019.\n* [19] A. S. Musleh, G. Yao, and S. Muyeen, \"Blockchain applications in smart grid-review and frameworks,\" _IEEE Access_, 2019.\n* [20] A. Panarello, N. Tapas, G. Merlino, F. Longo, and A. Puliafito, \"Blockchain and iot integration: A systematic survey,\" _Sensors_, vol. 18, no. 8, p. 2575, 2018.\n* [21] M. S. Ali, M. Vecchio, M. Pincheira, K. Dolui, F. Antonelli, and M. H. Rehmani, \"Applications of blockchains in the internet of things: A comprehensive survey,\" _IEEE Comm. Surveys & Tutorials_, 2018.\n* [22] M. Belotti, N. Bozic, G. Pujolle, and S. Secci, \"A Vademecum on Blockchain Technologies: When, Which and How,\" Jan. 2019, working paper. [Online]. Available: [https://hal.sorbonne-universite.fr/hal-01870617](https://hal.sorbonne-universite.fr/hal-01870617)\n* [23] V. Buterin. An introductory paper to Ethereum. [Online] Available: [https://github.com/ethereum/wiki/wiki/White-Paper](https://github.com/ethereum/wiki/wiki/White-Paper). [19-03-2019].\n* [24] An introduction to Hyperledger. [Online] Available: [https://www.hyperledger.org/wp-content/uploads/2018/07/HL_Whitepaper_IntroductiontoHyperledger.pdf](https://www.hyperledger.org/wp-content/uploads/2018/07/HL_Whitepaper_IntroductiontoHyperledger.pdf). [19-03-2019].\n* [25] Tendermint documentation. [Online] Available: [https://media.readthedocs.org/pdf/rendermint/v0.21.0/tendermint.pdf](https://media.readthedocs.org/pdf/rendermint/v0.21.0/tendermint.pdf). [19-03-2019].\n* [26] The energy web chain: Accelerating the energy transition with an open-source, decentralized blockchain platform. [Online] Available: [https://energyweb.org/wp-content/uploads/2018/10/EWF-Paper-TheEnergyWebChain-v1-201810-FINAL.pdf](https://energyweb.org/wp-content/uploads/2018/10/EWF-Paper-TheEnergyWebChain-v1-201810-FINAL.pdf). [19-03-2019].\n* [27] Solar Bankers, initial coin offering whitepaper. [Online] Available: [https://solarbankers.com/wp-content/uploads/2017/10/SB-White-Paper_version2.pdf](https://solarbankers.com/wp-content/uploads/2017/10/SB-White-Paper_version2.pdf). [19-03-2019].\n* [28] PROSUME. [Online] Available: [https://prosume.io/wp-content/uploads/2017/09/white-paper_v2-2017.pdf](https://prosume.io/wp-content/uploads/2017/09/white-paper_v2-2017.pdf). [19-03-2019].\n* [29] J. Wu and N. Tran, \"Application of blockchain technology in sustainable energy systems: An overview,\" _Sustainability_, vol. 10, 2018.\n* [30] A. Goranovic, M. Meisel, L. Fotiiadis, S. Wilker, A. Treytl, and T. Sauter, \"Blockchain applications in microgrids an overview of current projects and concepts,\" in _IECON 2017-43rd Annual Conference of the IEEE Industrial Electronics Society_. IEEE, 2017, pp. 6153-6158.\n* [31] D. Alahakoon and X. Yu, \"Smart electricity meter data intelligence for future energy systems: A survey,\" _IEEE Transactions on Industrial Informatics_, vol. 12, no. 1, pp. 425-436, 2015.\n* [32] Y. Kabalci, \"A survey on smart metering and smart grid communication,\" _Renew. and Sust. Ener. Reviews_, vol. 57, pp. 302-318, 2016.\n* [33] P. T. Lam and A. O. Law, \"Crowfunding for renewable and sustainable energy projects: An exploratory case study approach,\" _Renewable and Sustainable Energy Reviews_, vol. 60, pp. 11-20, 2016.\n* [34] A. Zidan, M. Khairalla, A. M. Abdrabou, T. Khalifa, K. Shaban, A. Abdrabou, R. El Shatshat, and A. M. Gaouda, \"Fault detection, isolation, and service restoration in distribution systems: state-of-the-art and future trends,\" _IEEE Transactions on Smart Grid_, vol. 8, no. 5, pp. 2170-2185, 2017.\n\n* [35] Z. Li, J. Kang, R. Yu, D. Ye, Q. Deng, and Y. Zhang, \"Consortium blockchain for secure energy trading in industrial internet of things,\" _IEEE Transactions on Industrial Informatics_, vol. 14, no. 8, pp. 3690-3700, 2017.\n* [36] J. Kang, R. Yu, X. Huang, S. Maharjan, Y. Zhang, and E. Hossain, \"Enabling localized peer-to-peer electricity trading among plug-in hybrid electric vehicles using consortium blockchains,\" _IEEE Transactions on Industrial Informatics_, vol. 13, no. 6, pp. 3154-3164, 2017.\n* [37] F. A. Silva, \"Modern electric, hybrid electric, and fuel cell vehicles, [book news],\" _IEEE Industrial Electronics Magazine_, vol. 12, no. 4, pp. 46-48, 2018.\n* [38] V. C. Gungor, D. Sahin, T. Kocak, S. Ergut, C. Buccella, C. Cecati, and G. P. Hancke, \"A survey on smart grid potential applications and communication requirements,\" _IEEE Transactions on industrial informatics_, vol. 9, no. 1, pp. 28-42, 2013.\n* [39] Y. Yan, Y. Qian, H. Sharif, and D. Tipper, \"A survey on cyber security for smart grid communications,\" _IEEE Comm. Surveys and tutorials_, vol. 14, no. 4, pp. 998-1010, 2012.\n* [40] Z. Ren, K. Cong, J. Pouwelse, and Z. Erkin, \"Implicit consensus: Blockchain with unbounded throughput,\" _arXiv preprint arXiv:1705.11046_, 2017."

Title: Vulnerability of Finitely-long Blockchains in Securing Data
Transcription: "# Vulnerability of Finitely-long Blockchains in Securing Data\n\nYiming Jiang and Jiangfan Zhang,\n\nY. Jiang and J. Zhang are with the Department of Electrical and Computer Engineering, Missouri University of Science and Technology, Rolla MO 65409 USA (e-mail: yjk7z@mst.edu, jiangfanhang@mst.edu)\n\n###### Abstract\n\nRecently, blockchain has been applied in various fields to secure data exchanges and storage in decentralized systems. In a blockchain application where the task of the application which makes use of the data stored in a blockchain has to be accomplished by a time instant, the employed blockchain is essentially finitely-long. In this paper, we consider a general finitely-long blockchain model which is generalized from most existing works on finitely-long blockchain applications, and take the first step towards characterizing the vulnerability of finitely-long blockchains in securing data against double-spending attacks. For the first time, we develop a general closed-form expression for the probability of success in launching a double-spending attack on a finitely-long blockchain. This probability essentially characterizes the vulnerability of finitely-long blockchains. Then, we prove that the probability of success in launching a double-spending attack on a finitely-long blockchain is no greater than that on an infinitely-long blockchain, which implies that finitely-long blockchains are less vulnerable to double-spending attacks than infinitely-long blockchains. Moreover, we show that unlike infinitely-long blockchains which can be surely paralyzed by a 51% attack, finitely-long blockchains are more resistant to 51% attacks.\n\n Finitely-long blockchain, double-spending attack, proof-of-work, \\(51\\%\\) attack.\n\n## I Introduction\n\nAs cryptocurrencies are increasingly gaining popularity in both the financial sector and society at large, their underlying technology, referred to as blockchain, shows great potential for many applications in different engineering disciplines. Blockchain was firstly developed for financial applications [1, 2], and has provided feasible measures for establishing mutual trust among network nodes and defending against security threats to data storage and exchanges. Because of its security-by-design and distributed nature without authority, blockchain has been applied to diverse engineering fields, such as smart grids [3], vehicular networks [4], and smart city [5].\n\nAs an emerging secure distributed database technology that revolutionizes the way information is secured, distributed, and shared, blockchain technology can eliminate the need for the central authority and operates on a peer-to-peer network with the following vital components [6, 7]: (i) a chronologically ordered sequence of blocks that are cryptographically linked to each other and are shared, stored and synchronized over the network; (ii) strong cryptography enabling secure data storage and secure data exchanges, and (iii) a consensus protocol that enables verification and validation of the authenticity and integrity of stored and exchanged data, and thus enables mutual trust over the network instead of relying on a central authority. The cryptographic algorithms and digital signature algorithms of the blockchain technology can effectively prevent the impersonation of network nodes and the attacks on the information exchanges among network nodes.\n\nThe consensus is a procedure through which every new block that is added to the blockchain is the one and only version of the truth that is agreed upon by all network nodes, and hence, ensures that the local blockchain copies of the network nodes can reach a common agreement. In this way, consensus protocols can establish mutual trust among network nodes in a distributed computing environment without needing a central authority. There are several types of consensus protocols which can help blockchain network nodes achieve a common agreement, such as Proof of Work (PoW), Proof of Stake (PoS), Proof of Activity (PoA), and Proof of Capacity (PoC). The PoW requires every participant node to compete with each other to solve a computationally challenging puzzle to receive the right to add a new block to the blockchain. The PoS involves the allocation of responsibility in validating and adding new blocks to the blockchain to a participant node in proportion to the number of cryptocurrency tokens held by it [8]. The PoC allows sharing of memory space of the contributing nodes in the network [9]. The more memory or hard disk space a node has, the more rights it is granted for maintaining the blockchain. The PoA is a hybrid that makes use of aspects of both PoW and PoS [10]. Among all blockchain consensus protocols, the PoW is the most widely used consensus protocol. For example, Bitcoin, Litecoin, ZCash, and Bitcoin Cash all adopt PoW as their consensus protocols [11, 12, 13]. In this paper, unless otherwise noted, we assume that the considered blockchains employ the PoW consensus protocol.\n\nIt is worth mentioning that the blockchain technology cannot eradicate all security threats to the data stored in a blockchain. As mentioned in [1], blockchains are prone to the double-spending attack (DSA), which can possibly falsify the data stored in a blockchain and is considered one of the most devastating attacks against blockchains. In recent years, DSAs have occurred several times in financial blockchain applications and are expected to occur more often in the future. For example, one of Bitcoin forks, Bitcoin Gold, suffered double-spending attacks in 2018, and again in 2020, with more than 17 million U.S. dollars lost in total. For a blockchain application where the employed blockchain is utilized to store data, a successful DSA can modify the existing data stored in the blockchain without being perceived, and hence seriouslycompromise any task which makes use of the data stored in the blockchain.\n\nIn a blockchain application, the employed blockchain can be infinitely-long or finitely-long. If the task of the application which makes use of the data stored in the employed blockchain has to be accomplished by some time instant \\(t_{0}\\), then any future blocks and their data generated after \\(t_{0}\\) do not affect the accomplished task. To this end, from the perspective of the task, the blockchain can be deemed to reach its final length and stop growing when the task has been accomplished, even though after the task has been accomplished, the blockchain in fact keeps growing to record future data which may be used for other tasks. In light of this, we adopt the following definition to distinguish finitely-long blockchains from infinitely-long blockchains from the perspective of the task of the blockchain application.\n\n**Definition 1** (Finitely-long Blockchain).: _For a blockchain application, if the task of the application which makes use of the past and present data stored in the employed blockchain has to be accomplished by some time instant, then from the perspective of this task, the blockchain employed in this application is deemed finitely-long._\n\nIn many financial blockchain applications, the employed blockchain plays the role of a ledger recording financial transactions, see [1] for instance. In view of unceasing occurrence of transactions, the task of recording transactions has to be carried out over time and cannot be accomplished by a given time instant. Thus, the blockchain for this kind of application should be deemed infinitely-long, which is widely adopted in many recent works, see [1, 2] for instance. In contrast, in the blockchain applications for many engineering problems where their tasks have to be accomplished in a timely manner, the employed blockchains should be considered finitely-long according to Definition 1. For example, consider a blockchain-aided smart grid monitor system where the state of the power grid needs to be estimated based on meter measurements stored in a blockchain [14]. The estimation accuracy is generally determined by the number of meter measurements. Once the number of meter measurements stored in the blockchain is large enough to ensure that the estimation accuracy can meet a prescribed requirement, an estimate of the state of the power grid is produced, and hence, from then on, the growth of the blockchain can be regarded as terminated from the perspective of the task of state estimation since any future data stored in the blockchain will not affect the value of the produced state estimate. Another representative example of a finitely-long blockchain application is a blockchain-based e-voting system where once all ballots for the election have been securely recorded in the blockchain, the election result can be determined, and hence, the growth of the blockchain can be regarded as terminated from the perspective of the task of the election [15]. In some other existing works on blockchain applications, such as power auction [16], e-voting [17], and vehicular announcement network [18, 19], the employed blockchains are essentially finitely-long as well according to Definition 1. It is worth mentioning that for a finitely-long blockchain application, if an attacker aims at undermining the task of the application by falsifying the data stored in the blockchain, then any effective attack has to be successfully launched before the blockchain reaches its final length. Thus, from the perspective of attackers, the timeliness of attacks which are launched on finitely-long blockchains matters. This is very different from infinitely-long blockchains which gives rise to significant differences between the vulnerabilities of finitely-long blockchains and infinitely-long blockchains.\n\nLately, there has been a growing tendency to negligently assume that the data stored in a blockchain is perfectly secure in a lot of recent literature on finitely-long blockchain applications, see [20, 21, 22, 23] for instance. However, similar to infinitely-long blockchains, the data stored in a finitely-long blockchain are also subject to DSAs, and therefore, may not be perfectly secured in adversarial environments. The basic idea of the DSA is to build a counterfeit branch storing falsified data in a blockchain, and extend this counterfeit branch to be longer than the authentic branch of the blockchain. Once the counterfeit branch becomes longer than the authentic branch of the blockchain, the DSA is deemed to be launched successfully since the counterfeit branch and the data stored in it are considered valid while the authentic branch of the blockchain and its data are considered invalid according to the longest chain protocol of blockchain [1].\n\nThe DSA on infinitely-long blockchains has been studied in previous literature, see [24, 25, 26, 27] for instance. However, the analysis of DSAs on infinitely-long blockchains cannot be applied to finitely-long blockchains since there is a time limit for adversaries to attack finitely-long blockchains. In particular, unlike infinitely-long blockchains, in order to falsify the data stored in a finitely-long blockchain, a DSA has to be launched successfully before the time instant that the task is accomplished, that is, the time instant that the authentic branch of the blockchain grows to a predetermined final length. To the best of our knowledge, there is no existing work studying the vulnerability of finitely-long blockchains and analyzing DSAs on finitely-long blockchains. In this paper, we consider a general finitely-long blockchain model which is generalized from existing works on finitely-long blockchain applications. For the first time, we theoretically characterize the vulnerability of the finitely-long blockchain by developing the closed-form expression for the probability of success in launching a double-spending attack on a finitely-long blockchain.\n\n### _Summary of Results and Main Contributions_\n\nConsidering a finitely-long blockchain which is under a DSA, the vulnerability of the finitely-long blockchain can be characterized by the probabilities of success in launching a DSA on the finitely-long blockchain starting from different blocks of the authentic branch. We show that the derivation of these probabilities can be cast as a two-sided boundary hitting problem for a two-dimensional random walk with two possible walking directions. In particular, the two boundaries in this problem are orthogonal to each other, while the two possible walking directions of the random walk are not orthogonal to each other. Moreover, one walking direction of the random walk is neither orthogonal nor parallel to any of the two boundaries. For such a two-sided boundary hitting problem, the general closed-form expression for the probability that the random walk hits one boundary before the other is developed, which can describe the probability of success in launching a DSA on a finitely-long blockchain starting from any block of the authentic branch. This probability depends on the normalized hash rate of the attacker who launches the DSA, which is defined as the ratio of the computational power owned by the attacker to the total computational power of the blockchain network, the length of the authentic branch of the blockchain at the time of the attack, the ordinal number of the block where the DSA starts from, and the predetermined final length of the finitely-long blockchain.\n\nMoreover, we theoretically compare the vulnerability of finitely-long blockchains with that of infinitely-long blockchains. To be specific, we prove that the probability of success in launching a DSA on a finitely-long blockchain is no greater than that on an infinitely-long blockchain, which implies that finitely-long blockchains are less vulnerable to DSAs than infinitely-long blockchains. It has been proved in previous literature that if the normalized hash rate of an attacker is greater than \\(50\\%\\) and the attacker attacks an infinitely-long blockchain by launching a DSA, which is called a \\(51\\%\\) attack, then the probability of success in launching the DSA is always one, which implies that the attacker is able to falsify any data stored in the infinitely-long blockchain, and hence the security of the infinitely-long blockchain is completely demolished [1]. In contrast, we show that unlike infinitely-long blockchains, even though the normalized hash rate of an attacker is greater than \\(50\\%\\), the probability of success in launching a DSA on any finitely-long blockchain is strictly less than one. This indicates that 51% attacks cannot completely demolish the security of finitely-long blockchains.\n\n### _Related Work_\n\nFinitely-long blockchains have been recently integrated into diverse engineering applications to enhance data security, such as smart homes, smart grids, smart cities, and vehicle networks, see [15, 17, 18, 19, 20, 21, 22, 23, 28, 29] and the references therein. For example, in [19], the authors propose a blockchain-based vehicular announcement network where the blockchain is employed to protect data against tampering and make them widely available and accessible over the network against the possibility of node failures and hacking. In this application, the employed blockchain is actually finitely-long because once the task of querying recent accident reports which are stored in a blockchain is accomplished, the employed blockchain can be deemed to reach its final length and any future accident report will not affect the accomplished querying task. A traffic jam probability prediction system is proposed in [18] where a blockchain helps vehicles to securely share and request for the live traffic at a particular location. The blockchain employed in [18] is also finitely-long because once the task of prediction is accomplished, the growth of the blockchain can be considered to terminate from the perspective of the task of prediction and future traffic information does not affect the accomplished predicted probability. However, all the mentioned works assume the data stored in finitely-long blockchains are perfectly secure, which is not true in general. In particular, the data stored in a finitely-long blockchain can be modified by DSAs, which motivates us to investigate DSAs on finitely-long blockchains.\n\nThe DSA on infinitely-long blockchains has been well studied in previous literature, see [24, 25, 26, 27] and the references therein. In [1], the author points out infinitely-long blockchains are vulnerable to DSAs, and the author derives the probability of success in launching a DSA on an infinitely-long blockchain. Moreover, the author indicates that if an attacker controls more than half of the computational power of a blockchain network, the attacker can always successfully launch a DSA on the infinitely-long blockchain. Based on the results in [1], the authors of [26] provide a more detailed analysis on the properties of DSAs on infinitely-long blockchains. However, all the previous literature which theoretically investigates the DSA only focuses on infinitely-long blockchains, and cannot apply to finitely-long blockchains. In this paper, we consider DSAs launched on finitely-long blockchains, and develop the closed-form expression for the probability that an attacker successfully launches a DSA on a finitely-long blockchain.\n\nThe paper is organized as follows. In section II, the general finitely-long blockchain model and double-spending attack model are introduced. Section III analyzes the probability that an attacker successfully launches a DSA on a finitely-long blockchain. Numerical simulations are provided in Section IV, and Section V provides our conclusions.\n\n## II Finitely-long Blockchain and Adversary Models\n\nIn this section, we first introduce a general finitely-long blockchain model which subsumes most models adopted by previous works on finitely-long blockchain applications, and then the double-spending attack model is elaborated.\n\n### _Finitely-long Blockchain Model_\n\nWe consider a general finitely-long blockchain model which is generalized from most existing works on finitely-long blockchain applications, see [15, 17, 18, 19, 20, 21, 22, 23, 28, 29] for instance. The working mechanism of finitely-long blockchains is similar to that of infinitely-long blockchains proposed in [1], except that a finitely-long blockchain can be considered to stop growing when its longest branch reaches a predetermined final length.\n\nDifferent nodes can play different roles in a finitely-long blockchain network. The main duties of nodes include data generation, block/data routing, block/data verification, and block mining. In a finitely-long blockchain network, there are mainly two types of nodes, that is, wallets1 and miners [27]. The wallets produce data which can be transactions, sensor measurements, or any other information, while the main duty of miners is to generate blocks in the blockchain to store the data produced by the wallets. Note that it is possible that a node in a finitely-long blockchain network plays the roles of both wallet and miner. The working mechanism of a finitely-long blockchain network mainly includes two components which are presented below.\n\n#### Ii-A1 Data Exchanges\n\nIn a finitely-long blockchain network, wallets first transmit their data to every miner, and then the miners compete with each other to generate blocks to store wallets' data in the blockchain. The process of generating new blocks for the blockchain will be elaborated in Section II-A2. Once a miner generates a block, it sends the generated block to all the other nodes which retain local copies of the blockchain. In all these inter-node data exchanges, asymmetric encryption based on a public key infrastructure is used, which is illustrated in Fig. 1. To be specific, each node in the blockchain owns a public-private key pair that forms the digital identity of the node. The public key is available at the other nodes, while the private key is only available at its owner. A secure hash algorithm (SHA), e.g., SHA-256 and SHA-512 [30], is used in the data encryption process of every data exchange. To delineate the inter-node data exchanges, let's consider the data exchanges between a wallet and a miner as an example. Let \\(D_{j,t}\\) denote the \\(t\\)-th data of the \\(j\\)-th wallet where time index \\(t\\) where time index \\(t=1,2,...\\) Before transmitting \\(D_{j,t}\\) to miners, the \\(j\\)-th wallet first processes the message which contains data \\(D_{j,t}\\) and its time index \\(t\\) by employing an SHA and obtains a message digest. It then encrypts the message digest via its private key by using a digital signature algorithm, e.g., Elliptic Curve Digital Signature Algorithm [7], and produces a digital signature. Finally, the \\(j\\)-th wallet transmits the data package consisting of the message and the corresponding digital signature to all the miners of the network.\n\nOnce a miner receives a data package, it first decrypts the received digital signature via the public key of the wallet and obtains a message digest, which is signified by Message Digest B in Fig. 1. Then, the miner processes the received message via the SHA and obtains another message digest, which is represented by Message Digest A in Fig. 1. Only if these two message digests exactly match with each other, the authenticity of the received data package is verified and the received message will be used in the future processes. Otherwise, the received data package will be discarded and retransmission can take place. Note that the digital signature received at the miner can only be decrypted via the public key of the sender. Hence the miner can verify the identity of the sender to prevent impersonation of the sender. Moreover, the SHA and the digital signature algorithm can secure the data package transmission since it is computationally intractable for an attacker to either find a different message which yields the same message digest or generate a valid digital signature for a fake message digest without the private key of the sender [7, 30]. To this end, the authenticity of the data packages received at miners and the identities of senders can be validated and secured.\n\n#### Ii-A2 Block Mining and Consensus Protocol\n\nFor each time \\(t\\), every miner first collects data packages from all the wallets and verifies the authenticity of the collected data packages. Then every miner puts a header and all the wallets' data packages, that is, the messages \\((D_{j,t},t)\\) for all \\(j\\) and the digital signatures associated with these messages, into a new block. The header consists of a discrete timestamp, the hash value of the last block (parent block) of the longest valid branch in the miner's local copy of the blockchain, the Merkle Root which is the root of the Merkle tree constructed by recursively hashing pairs of data packages until there is only one hash [1], and a number called nonce which is the solution to a PoW puzzle. The hash value of the parent block which is stored in the header of the new block in essence cryptographically links the new block to its parent block. A simplified structure of a block is illustrated in Fig. 2.\n\nNext, the miners compete with each other in solving a difficult PoW puzzle for their new blocks, which is called mining. In Particular, each miner attempts to solve a PoW puzzle by searching for a valid nonce for its new block, via brute-force search, which renders the hash value of the new block with no less than a prescribed number of prefix zeros [1]. The difficulty of the PoW puzzle increases as the prescribed number of prefix zeros increases. When a miner solves its PoW puzzle first among all miners, i.e., finds a valid nonce value which meets the requirement, we say that the miner successfully mines its new block, and the miner broadcasts its new block to all the other nodes which retain local copies of blockchain. After receiving the newly mined block, the other nodes carry out a block validation procedure. Specifically, the other nodes first verify the authenticity of the messages in the received block, and confirm that the time index contained in each message of the received block is just one greater than that in the parent block of the received block. Then they verify that the hash value of the received block indeed has no less than the prescribed number of prefix zeros. If the received block can pass this block validation, all the other nodes will add this received block after its parent block in their local copies of blockchain, and switch to work on solving the PoW puzzle for the next block. The miner which solves its PoW puzzle first will be offered an incentive.\n\nFig. 1: Inter-node data exchanges based on the asymmetric encryption mechanism.\n\nThe block mining process described above can be considered as a hashing competition among miners, where the probability that a miner solves its PoW puzzle first is proportional to its normalized hash rate which is defined as the ratio of its computational power to the total computational power in the network [1]. It is possible that two or more miners may solve their puzzles almost at the same time, which may lead to distinct blockchain branches at different miners due to the decentralized nature of blockchain and communication delays among nodes. However, the longest branch in each miner's local copy of the blockchain, which is called the main chain, can reach a consensus due to the longest chain protocol of blockchain [1].\n\nThe structure of the wallet's message deserves some discussion. The purpose of including a time index \\(t\\) in every message is mainly twofold. On one hand, if there exist network latency and communication failure, miners may lose some wallets' data packages or may not receive wallets' data packages in a chronological order. The time index included in every message can help the miners discern if there is any data package lost and rearrange the received wallet's data packages in a chronological order. On the other hand, it is possible that a wallet's data \\(D_{j,t}\\) can be the same value for some different time indices. Including a time index \\(t\\) in every message can distinguish the same data at different times, and also prevent potential security threats. For example, consider the case that every message does not include a time index, and there exists a malicious miner. At a time \\(t_{1}\\), when forming its new block, the malicious miner can falsify the data package received from the \\(j\\)-th wallet by simply replacing it with the \\(j\\)-th wallet's data package generated at some time \\(t_{2}<t_{1}\\), which can be obtained in the malicious miner's copy of the blockchain. If this falsified block is mined, this falsification can pass the validation processes implemented at other nodes since the \\(j\\)-th wallet's data package generated at \\(t_{2}\\) is authentic and valid. On the contrary, if every message includes a time index, then this kind of falsification cannot pass the validation processes implemented at other nodes since the time index \\(t_{2}\\) contained in the falsified mined block is not one greater than \\(t_{1}-1\\) which is the time index in the parent block of the mined block.\n\nAs mentioned before, in a blockchain application where the task of the application has to be accomplished by some time instant, the employed blockchain can be deemed finitely-long. Let \\(L\\) denote the number of blocks mined in the longest branch of the employed blockchain when the task of the blockchain application is accomplished. As such, in the finitely-long blockchain model, we can assume that the growth of the blockchain terminates once its longest branch grows to \\(L\\) blocks.\n\n### _Double-Spending Attack Model_\n\nIn order to falsify the data which have already been stored in a blockchain, an attacker has to successfully launch a DSA [1]. Consider a finitely-long blockchain where \\(L_{0}\\) authentic blocks which store data for the task of the application have been mined to form an authentic branch. An attacker controls some malicious miners in the network which launches a DSA on the finitely-long blockchain in an attempt to falsify the data \\(\\{D_{j,L_{a}}\\}_{j\\in\\mathcal{A}}\\) from a subset \\(\\mathcal{A}\\) of wallets, which have already been stored in the \\(L_{a}\\)-th block \\((0<L_{a}\\leq L_{0})\\) of the authentic branch of the blockchain, to \\(\\{\\tilde{D}_{j,L_{a}}\\}_{j\\in\\mathcal{A}}\\). The steps of launching the DSA on the finitely-long blockchain can be summarized as follows. The attacker first has to hack into the subset \\(\\mathcal{A}\\) of wallets and steal their private keys to generate valid digital signatures for the falsified messages containing \\(\\{\\tilde{D}_{j,L_{a}}\\}_{j\\in\\mathcal{A}}\\). Then the attacker modifies the \\(L_{a}\\)-th authentic block to form a counterfeit block by replacing the \\(L_{a}\\)-th authentic block's data packages containing \\(\\{D_{j,L_{a}}\\}_{j\\in\\mathcal{A}}\\) with the falsified data messages containing \\(\\{\\tilde{D}_{j,L_{a}}\\}_{j\\in\\mathcal{A}}\\) and their corresponding digital signatures. After that, the attacker works on mining this counterfeit block by redoing a PoW puzzle to find a valid nonce value for the counterfeit block which can render the hash value of the counterfeit block with no less than a prescribed number of prefix zeros. Once a valid nonce value has been successfully found, the attacker broadcasts this mined counterfeit block to the other nodes which retain local copies of the blockchain. Since the mined counterfeit block can pass the block validation conducted at the other nodes, the other nodes will add this counterfeit block after the \\((L_{a}-1)\\)-th authentic block in their local copies of the blockchain. In a blockchain, only the longest branch is valid according to the longest chain protocol of blockchain. To this end, in order to ensure the validity of the \\(L_{a}\\)-th counterfeit block, the attacker has to mine more blocks after the \\(L_{a}\\)-th counterfeit block which are linked one after another to form a counterfeit branch, and extend this counterfeit branch to be the longest branch in the blockchain. The process of launching a DSA is illustrated in Fig. 3. It is worth mentioning that mining each block of the counterfeit branch requires the malicious miners to solve a PoW puzzle. Moreover, while the malicious miners work on hacking into the subset \\(\\mathcal{A}\\) of wallets and then extending the counterfeit branch, the honest miners simultaneously work on mining new blocks to extend the authentic branch before the counterfeit branch becomes the longest branch in the blockchain.\n\nAs illustrated in Fig. 3, the counterfeit branch consists of the authentic blocks with indices from \\(1\\) to \\((L_{a}-1)\\), the \\(L_{a}\\)-th counterfeit block, and all blocks linked after it. The authentic branch consists of the authentic blocks with indices from 1 to \\(L_{0}\\) and all blocks linked after the \\(L_{0}\\)-th authentic block. It is clear that the counterfeit branch diverges from the authentic branch at the \\((L_{a}-1)\\)-th block of the authentic branch. Once the counterfeit branch becomes longer than the authentic branch, all the honest miners switch from working on extending the authentic branch to working on extending the authentic branch. The honest miners switch from working on extending the authentic branch to working on extending the authentic branch to working on extending the authentic branch to working on the authentic branch.\n\nFig. 2: Structure of a block in the blockchain.\n\nthe counterfeit branch according to the longest chain protocol of blockchain [1]. As a result, the authentic branch will stop growing, and the counterfeit branch will remain the longest branch in the blockchain as time goes by.\n\nAt last, we make a remark on the value of \\(L_{0}\\) in practice. When wallets communicate with the malicious miners which are controlled by an attacker, it provides the attacker an opportunity to hack into these wallets. Generally, cybersecurity measures are taken at wallets to prevent attackers from hacking into the wallets and stealing their private keys. For example, as a basic preventative measure, most wallets are equipped with password protection to prevent hacking. In order to hack into the wallets equipped with password protection, the attacker has to employ a brute force attack which works through all possible keystrokes hoping to guess the password correctly [31]. It may take a long time for the attacker to hack into all wallets in the subset \\(\\mathcal{A}\\), during which honest miners generally can successfully mine some authentic blocks for an authentic branch, which implies that \\(L_{0}\\) is generally greater than \\(0\\) in practice owing to the cybersecurity measures taken at wallets. In addition, the cases where \\(L_{0}=L\\) or \\(L_{0}=0\\) are trivial. This is because if \\(L_{0}=L\\), then the task of the blockchain application has already been accomplished, and hence, the attacker has failed to launch a successful DSA. Moreover, if no authentic block has been mined in the blockchain, i.e., \\(L_{0}=0\\), when the attacker accomplishes hacking into the subset \\(\\mathcal{A}\\) of wallets, then no block storing the data for the task of the blockchain application has been mined in the blockchain, and therefore, the attacker does not need to launch a DSA on the blockchain anymore. This is because the attacker has already controlled the subset \\(\\mathcal{A}\\) of wallets and can falsify their data which are transmitted to miners before the blockchain records the data for the task of the blockchain application. In light of this, we assume that \\(0<L_{0}<L\\) throughout this paper.\n\n## III Probability of Success in Launching A Double-Spending Attack\n\nConsider the double-spending attack model described in Section II-B where \\(L_{0}\\) blocks have been mined in an authentic branch and an attacker attempts to falsify the data stored in the \\(L_{a}\\)-th authentic block by launching a DSA. The attacker has to build a counterfeit branch to be longer than the authentic branch before the task of a finitely-long blockchain application is accomplished, that is, the time instant at which the authentic branch grows to \\(L\\) blocks. We refer to a DSA which renders its counterfeit branch longer than the authentic branch before the authentic branch grows to \\(L\\) blocks as a successful DSA.\n\nAccording to the PoW protocol, the probability that a miner solves its PoW puzzle first among all the miners is proportional to its hash rate. Let \\(I\\) denote the probability that the next block mined in the blockchain is generated by a malicious miner. Hence the probability that the next block mined in the blockchain is generated by an honest miner is \\(1-I\\). Let \\(\\mathbb{P}_{L}(m,n)\\) denote the probability that if the length of the authentic branch is \\(n\\) and the counterfeit branch built by the attacker is \\(m\\) blocks shorter than the authentic branch, then the attacker finally extends the counterfeit branch to be longer than the authentic branch before the authentic branch grows to \\(L\\) blocks. As such, \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) is the probability that the attacker launches a successful DSA.\n\nNote that if a malicious miner mines the next block in the blockchain, which happens with probability \\(I\\), the counterfeit branch will be \\((m-1)\\) blocks shorter than the authentic branch while the authentic branch remains \\(n\\) blocks. In contrast, if an honest miner mines the next block in the blockchain, which happens with probability \\((1-I)\\), the counterfeit branch will be \\((m+1)\\) blocks shorter than the authentic branch and the authentic branch grows to \\((n+1)\\) blocks. To this end, the recursive form of \\(\\mathbb{P}_{L}(m,n)\\) can be expressed as, \\(\\forall m\\in\\{0,\\cdots,L_{0}-L_{a}+1\\}\\) and \\(\\forall n\\in\\{L_{0},\\cdots,L\\}\\),\n\n\\[\\mathbb{P}_{L}(m,n)=I\\times\\mathbb{P}_{L}(m-1,n)+(1-I)\\times\\mathbb{P}_{L}(m+ 1,n+1). \\tag{1}\\]\n\nOnce the counterfeit branch becomes longer than the authentic branch (i.e., the counterfeit branch is \\(-1\\) blocks shorter than the authentic branch) before the length of the authentic branch reaches \\(L\\), the DSA launched by the attacker succeeds, and therefore, we have the following boundary condition\n\n\\[\\mathbb{P}_{L}(-1,n)=1,\\quad\\forall 0<n<L. \\tag{2}\\]\n\nOn the other hand, if the length of the authentic branch grows to \\(L\\) and the counterfeit branch is still shorter than the authentic branch, the blockchain reaches its final length which implies that the attacker fails to launch a successful DSA. Hence, we have another boundary condition\n\n\\[\\mathbb{P}_{L}(m,L)=0,\\quad\\forall m>0. \\tag{3}\\]\n\nIt is worth pointing out that when an honest miner mines a block and then the length of the authentic branch grows to \\(L\\), the length of the counterfeit branch cannot be the same as that of the authentic branch. This is because if so, then before the honest miner mines a block, the counterfeit branch has already grown to \\(L\\) blocks, and hence, the counterfeit branch has already been longer than the authentic branch which implies that we have already reached the boundary condition in (2) before the honest miner mines a block. To this end, we don't need to include the case where \\(m=0\\) in the boundary condition in (3).\n\nBy employing (1), (2) and (3), the pursuit of the closed-form expression for \\(\\mathbb{P}_{L}(m,n)\\) can be cast as a two-sided boundary hitting problem for a two-dimensional random walk with two possible moving directions, which is illustrated in Fig. 4. To be specific, let \\(\\mathbf{s}_{T}\\triangleq[m,n]^{T}+\\sum_{t=1}^{t=T}\\mathbf{\\delta}_{t}\\) denote the position of the random walk in two-dimensional space after the \\(T\\)-th step (i.e., after \\(T\\) blocks have been mined in the blockchain), where for any \\(t\\), \\(\\mathbf{\\delta}_{t}\\) is a random vector\n\n\\[\\mathbf{\\delta}_{t}=\\left\\{\\begin{array}{cc}\\mathbf{\\delta}^{(1)}\\triangleq[-1,0]^{ T}&\\text{with probability }I,\\\\ \\mathbf{\\delta}^{(2)}\\triangleq[1,1]^{T}&\\text{with probability }1-I.\\end{array}\\right. \\tag{4}\\]\n\nLet \\(\\mathcal{L}_{1}\\triangleq\\left\\{[m^{\\prime},n^{\\prime}]^{T}\\left|m^{\\prime}= -1\\right.\\right\\}\\) and \\(\\mathcal{L}_{2}\\triangleq\\left\\{[m^{\\prime},n^{\\prime}]^{T}\\left|n^{\\prime}= L\\right.\\right\\}\\) define two boundary lines in two-dimensional space, and \\(\\mathcal{L}_{1}\\triangleq\\left\\{[m^{\\prime},n^{\\prime}]^{T}\\left|n^{\\prime}= L\\right.\\right\\}\\).\n\n\n\n+++ ==WARNING: Truncated because of repetitions==\n},n^{\\prime}]^{T}\\left|n^{\\prime}= L\\right.\\right\\}\\). The boundary condition is \\(\\mathcal{L}_{1}\\triangleq\\left\\{[m^{\\prime},n^{\\prime}]^{T}\\left|n^{\\prime}= L\\right.\\right\\}\\). The boundary condition is \\(\\mathcal{L}_{1}\\triangleq\\left\\{[m^{\\prime},n^{\\prime}]^{T}\\left|n^{\\prime}= L\\right.\\right\\}\\). The boundary condition is \\(\\mathcal{L}_{1}\\triangleq\\left\\{[m^{\\prime},n^{\\prime}]^{T}\\left|n^{\\prime}= L\\right.\\right\\}\\). The boundary condition is \\(\\mathcal{L}_{1}\\triangleq\\left\\{[m^{\\prime},n^{\\prime}]^{T}\\left|n^{\\prime}= L\\right.\\right\\}\\). The boundary condition is \\(\\mathcal{L}_{1}\\triangleq\\left\\{[m\n+++\n\ndimensional space, respectively. As such, \\(\\mathbb{P}_{L}(m,n)\\) can be rewritten as\n\n\\[\\mathbb{P}_{L}(m,n)=\\sum_{T=0}^{\\infty}\\Pr\\left(\\mathbf{s}_{T}\\in\\mathcal{L}_{1},\\mathbf{s}_{T^{\\prime}}\\notin\\mathcal{L}_{1}\\cup\\mathcal{L}_{2},\\;\\forall T^{ \\prime}<T\\right) \\tag{5}\\]\n\nThe closed-form expression for \\(\\mathbb{P}_{L}(m,n)\\) for any given \\(m,n\\) is described in the following theorem.\n\n**Theorem 1**.: _When the length of the authentic branch is \\(n\\) and the counterfeit branch is \\(m\\) blocks shorter than the authentic branch, the probability \\(\\mathbb{P}_{L}(m,n)\\) that an attacker launches a successful DSA can be expressed as_\n\n\\[\\mathbb{P}_{L}(m,n) \\tag{6}\\] \\[=\\left\\{\\begin{array}{cl}\\sum_{i=0}^{L-n-1}a_{i,m}(1-I)^{i}I^{ m+1+i}&\\text{, if }m\\geq 0,0<n<L,\\\\ &\\text{, and }0\\leq I<1\\\\ &\\text{, if }m=-1,0\\!<\\!n\\!<\\!L,\\\\ &\\text{, or }I=1,0<n<L\\\\ &\\text{, if }m>0,n=L\\end{array}\\right.\\]\n\n_where the coefficients \\(a_{i,m}\\) is defined as_\n\n\\[a_{i,m}=\\left\\{\\begin{array}{cl}1,&\\text{if }i=0,\\\\ 1+m,&\\text{if }i=1,\\\\ C_{i},&\\text{if }m=0,\\\\ C_{i+1}+\\sum\\limits_{j_{1}=3}^{m+1}C_{i}+\\sum\\limits_{j_{1}=3}^{m+1}\\sum \\limits_{j_{2}=3}^{j_{1}+1}C_{i-1}\\\\ +\\cdots+\\sum\\limits_{j_{1}=3}^{m+1}\\sum\\limits_{j_{2}=3}^{j_{1}+1}\\cdots\\sum \\limits_{j_{3}=3}^{j_{3}+1}C_{3}&\\text{if }i\\!>\\!1\\\\ +\\sum\\limits_{j_{1}=3}^{m+1}\\sum\\limits_{j_{2}=3}^{j_{1}+1}\\cdots\\sum\\limits_{ j_{i-1}=3}^{j_{i-2}+1}(1+j_{i-1}),\\end{array}\\right. \\tag{7}\\]\n\n_and the constant \\(C_{i}\\) is the \\(i\\)-th Catalan number which is given by_\n\n\\[C_{i}\\overset{\\Delta}{=}\\frac{1}{i+1}\\begin{pmatrix}2i\\\\ i\\end{pmatrix}=\\frac{(2i)!}{(i+1)!i!}. \\tag{8}\\]\n\nProof.: From (1) and (2), we can easily see that \\(\\mathbb{P}_{L}(m,n)=1\\) if \\(m=-1\\), or if \\(I=1\\) and \\(0<n<L\\), \\(\\mathbb{P}_{L}(m,n)=0\\) if \\(n=L\\). Next, we prove the case that \\(0\\leq I<1\\) and \\(0<n<L\\).\n\nAs illustrated in Fig. 4, if the random walk can hit the boundary line \\(\\mathcal{L}_{1}\\) before hitting the boundary line \\(\\mathcal{L}_{2}\\), all the possible cases are that \\(\\forall i=0,1,...,L-n-1\\), the random walk moves along \\(\\boldsymbol{\\delta}^{(1)}\\) by \\((m+1+i)\\) steps and moves along \\(\\boldsymbol{\\delta}^{(2)}\\) by \\(i\\) steps. Thus, \\(\\mathbb{P}_{L}(m,n)\\) can be written in the general form\n\n\\[\\mathbb{P}_{L}(m,n)=\\sum_{i=0}^{L-n-1}a_{i,m}(1-I)^{i}I^{m+1+i} \\tag{9}\\]\n\nwhere \\(a_{i,m}\\) is a constant which denotes the number of all the paths that the random walk hits the boundary \\(\\mathcal{L}_{1}\\) in the \\((m+2i+1)\\)-th step by moving \\((m+i+1)\\) steps along \\(\\boldsymbol{\\delta}^{(1)}\\) and \\(i\\) steps along \\(\\boldsymbol{\\delta}^{(2)}\\) and the random walk never hits \\(\\mathcal{L}_{1}\\) before the \\((m+2i+1)\\)-th step. It is obvious that\n\n\\[a_{0,m}=1\\;\\text{ for }m\\geq 0, \\tag{10}\\]\n\nand hence\n\n\\[\\mathbb{P}_{L}(m,n)=I^{(m+1)}+\\sum_{i=1}^{L-n-1}a_{i,m}(1-I)^{i}I^{m+1+i}. \\tag{11}\\]\n\nFig. 4: Two-dimensional random walk illustration.\n\nFig. 3: The finitely-long blockchain under a double-spending attack.\n\nBy substituting (9) and (11) into (1), we can obtain\n\n\\[I^{m+1}+\\sum_{i=1}^{L-n-1}a_{i,m}(1-I)^{i}I^{m+1+i}\\] \\[=I\\times\\left(\\sum_{i=0}^{L-n-1}a_{i,m-1}(1-I)^{i}I^{m+i}\\right)\\] \\[\\qquad+(1-I)\\times\\left(\\sum_{i=0}^{L-n-2}a_{i,m+1}(1-I)^{i}I^{m+ 2+i}\\right)\\] \\[=\\sum_{i=0}^{L-n-1}a_{i,m-1}(1-I)^{i}I^{m+1+i}\\] \\[\\qquad+\\sum_{i=0}^{L-n-2}a_{i,m+1}(1-I)^{i+1}I^{m+2+i}\\] \\[=I^{m+1}+\\sum_{i=1}^{L-n-1}a_{i,m-1}(1-I)^{i}I^{m+1+i}\\] \\[\\qquad+\\sum_{i=1}^{L-n-1}a_{i,m+1}(1-I)^{i}I^{m+1+i}\\] \\[=I^{m+1}+\\sum_{i=1}^{L-n-1}[a_{i,m-1}+a_{i-1,m+1}](1-I)^{i}I^{m+1+i}. \\tag{12}\\]\n\nSince (12) holds for any \\(I\\), by the fundamental theorem of algebra, we know\n\n\\[a_{i,m}=a_{i,m-1}+a_{i-1,m+1},\\ \\ \\forall i>0\\ \\text{and}\\ m\\geq 0. \\tag{13}\\]\n\nSince \\(a_{0,m}=1\\) for any \\(m\\geq 0\\), we can get\n\n\\[a_{1,m}=a_{1,m-1}+1=a_{1,0}+m,\\ \\ \\forall m\\geq 0 \\tag{14}\\]\n\nfrom (13) by choosing \\(i=1\\). Furthermore, by setting \\(m=0\\) in (1), we have\n\n\\[\\mathbb{P}_{L}(0,n)=I+(1-I)\\times\\mathbb{P}_{L}(1,n+1) \\tag{15}\\]\n\nwhich yields\n\n\\[I+\\sum_{i=1}^{L-n-1}a_{i,0}(1-I)^{i}I^{1+i}=I+\\sum_{i=1}^{L-n-1}a_{i-1,1}(1-I) ^{i}I^{1+i} \\tag{16}\\]\n\nby employing (9).\n\nBy the fundamental theorem of algebra, we know from (16) that\n\n\\[a_{i,0}=a_{i-1,1},\\ \\ \\forall i=1,...,L-n-1. \\tag{17}\\]\n\nFrom (10) and (17), we can obtain\n\n\\[a_{1,0}=a_{0,1}=1, \\tag{18}\\]\n\nand therefore,\n\n\\[a_{1,m}=1+m\\ \\ \\forall m\\geq 0 \\tag{19}\\]\n\nby employing (14). From the recursive equation in (13), we can obtain that for any \\(i=1,2,...,L-n-1\\),\n\n\\[a_{i,m}=a_{i,1}+\\sum_{j=3}^{m+1}a_{i-1,j},\\ \\forall m>1. \\tag{20}\\]\n\nMoreover, from (17), we know\n\n\\[a_{i,1}=a_{i+1,0},\\ \\ \\forall i=0,...,L-n-2, \\tag{21}\\]\n\nwhich implies that for all \\(i=1,...,L-n-2\\) and \\(m>1\\),\n\n\\[a_{i,m} =a_{i+1,0}+\\sum_{j_{1}=3}^{m+1}a_{i-1,j_{1}}\\] \\[=a_{i+1,0}+\\sum_{j_{1}=3}^{m+1}a_{i,0}+\\sum_{j_{1}=3}^{m+1}\\sum_{ j_{2}=3}^{j_{1}+1}a_{i-1,0}+\\cdots\\] \\[\\quad+\\sum_{j_{1}=3}^{m+1}\\sum_{j_{2}=3}^{j_{2}+1}\\cdots\\sum_{j_{ \\ell-2}=3}^{j_{i-3}+1}a_{3,0}+\\sum_{j_{1}=3}^{m+1}\\sum_{j_{2}=3}^{j_{2}+1} \\cdots\\sum_{j_{i-1}=3}^{j_{i-2}+1}a_{1,j_{i-1}}\\] \\[=a_{i+1,0}+\\sum_{j_{1}=3}^{m+1}a_{i,0}+\\sum_{j_{1}=3}^{m+1}\\sum_{ j_{2}=3}^{j_{1}+1}a_{i-1,0}+\\cdots\\] \\[\\quad+\\sum_{j_{1}=3}^{m+1}\\sum_{j_{2}=3}^{j_{2}+1}\\cdots\\sum_{j_{ i-2}=3}^{j_{i-3}+1}a_{3,0}\\] \\[\\quad+\\sum_{j_{1}=3}^{m+1}\\sum_{j_{2}=3}^{j_{2}+1}\\cdots\\sum_{j_{ i-1}=3}^{j_{i-2}+1}(1+j_{i-1}), \\tag{22}\\]\n\nby employing (19) and (20).\n\nNext, we need to determine \\(a_{i,m}\\) when \\(i=L-n-1\\). Suppose that there is another boundary line \\(\\mathcal{L}_{3}\\stackrel{{\\Delta}}{{=}}\\left\\{\\left[m^{\\prime},n^{ \\prime}\\right]^{T}\\left|n^{\\prime}=L+1\\right.\\right\\}\\) and \\(\\mathbb{P}_{L}^{\\prime}(m,n)\\) is the probability that the random walk hits the boundary line \\(\\mathcal{L}_{1}\\) before hitting the boundary line \\(\\mathcal{L}_{3}\\). Similar to (9), we know\n\n\\[\\mathbb{P}_{L}^{\\prime}(m,n)=\\sum_{i=0}^{L-n}a_{i,m}^{\\prime}(1-I)^{i}I^{m+1+i}\\]\n\nwhere \\(a_{i,m}^{\\prime}\\) is a constant which denotes the number of all the paths that the random walk hits the boundary \\(\\mathcal{L}_{1}\\) in the \\((m+2i+1)\\)-th step by moving \\((m+1+i)\\) steps along \\(\\delta^{(1)}\\) and \\(i\\) steps along \\(\\delta^{(2)}\\) and the random walk never hits \\(\\mathcal{L}_{1}\\) before the \\((m+2i+1)\\)-th step. It is clear that\n\n\\[a_{i,m}^{\\prime}=a_{i,m},\\ \\ \\forall i=0,...,L-n-1\\ \\text{and}\\ \\forall m\\geq 0. \\tag{23}\\]\n\nSimilar to (21), we can get\n\n\\[a_{i,1}^{\\prime}=a_{i+1,0}^{\\prime},\\ \\ \\forall i=0,...,L-n-1. \\tag{24}\\]\n\nFrom (23) and (24), we know\n\n\\[a_{L-n-1,1}=a_{L-n-1,1}^{\\prime}=a_{L-n,0}^{\\prime}. \\tag{25}\\]Similar to (22), by employing (23), we can obtain that for all \\(m>1\\),\n\n\\[a_{L-n-1,m} =a^{\\prime}_{L-n-1,m}\\] \\[=a^{\\prime}_{L-n,0}+\\sum_{j_{1}=3}^{m+1}a_{L-n-2,j_{1}}\\] \\[=a^{\\prime}_{L-n,0}+\\sum_{j_{1}=3}^{m+1}a_{L-n-1,0}+\\sum_{j_{1}=3} ^{m+1}\\sum_{j_{2}=3}^{j_{1}+1}a_{L-n-2,0}\\] \\[\\qquad+\\cdots+\\sum_{j_{1}=3}^{m+1}\\sum_{j_{2}=3}^{j_{2}+1}\\cdots \\sum_{j_{L-n-3}=3}^{j_{L-n-4}+1}a_{3,0}\\] \\[\\qquad+\\sum_{j_{1}=3}^{m+1}\\sum_{j_{2}=3}^{j_{2}+1}\\cdots\\sum_{j _{L-n-2}=3}^{j_{L-n-3}+1}(1+j_{L-n-2}). \\tag{26}\\]\n\nIt is seen from (10), (22), (23) and (26) that if we can determine the value of \\(a^{\\prime}_{i,0}\\) for all \\(i=3,4,...L-n\\), then we can determine the value of \\(a_{i,m}\\) for all \\(i=0,1,...L-n-1\\) and \\(\\forall m\\geq 0\\), and hence, we can obtain the closed-form expression for \\(\\mathbb{P}_{L}(m,n)\\) by using (9). In what follows, we will derive the closed-form expression for \\(a^{\\prime}_{i,0}\\) for all \\(i=3,4,...L-n\\).\n\nNote that \\(a^{\\prime}_{i,0}\\) denotes the number of all the paths that the random walk hits the boundary line \\(\\mathcal{L}_{1}\\) in the \\((2i+1)\\)-th step by moving \\((i+1)\\) steps along \\(\\boldsymbol{\\delta}^{(1)}\\) and \\(i\\) steps along \\(\\boldsymbol{\\delta}^{(2)}\\) and the random walk never hits \\(\\mathcal{L}_{1}\\) before the \\((2i+1)\\)-th step. We know that for any such path in two-dimensional space, it starts from the point \\([0,n]^{T}\\) and arrives at the point \\([0,n+i]^{T}\\) in the \\((2i)\\)-th step, and moreover, the first \\(2i\\) steps of the path must stay in the half space \\(\\mathcal{S}\\triangleq\\{[m^{\\prime},n^{\\prime}]^{T}\\,[m^{\\prime}\\geq 0\\}\\). In light of this, \\(a^{\\prime}_{i,0}\\) is identical to the number of all the lattice paths from the point \\([0,0]^{T}\\) to the point \\([i,i]^{T}\\) which consist of \\(i\\) steps along the vector \\([0,1]^{T}\\) and \\(i\\) steps along the vector \\([1,0]^{T}\\) and never rise above the diagonal line in the \\(i\\)-by-\\(i\\) grid. Such paths are referred to as the Dyck Paths, and the number of such paths is known as the \\(i\\)-th Catalan number \\(C_{i}\\)[32]. Therefore, we know\n\n\\[a^{\\prime}_{i,0}=C_{i}\\triangleq\\frac{1}{i+1}\\begin{pmatrix}2i\\\\ i\\end{pmatrix}=\\frac{(2i)!}{(i+1)!i!},\\ \\ \\forall i=3,...,L-n-1. \\tag{27}\\]\n\nBy employing (2), (3), (9), (10), (19), (22), (24), (26) and (27), we can obtain\n\n\\[\\mathbb{P}_{L}(m,n)\\\\ =\\left\\{\\begin{array}{cl}\\sum_{i=0}^{L-n-1}a_{i,m}(1-I)^{i}I^{m+ 1+i}&\\text{if }m\\geq 0,0<n<L,\\\\ &\\text{and }0\\leq I<1\\\\ &\\text{if }m=-1,0<n<L,\\\\ &\\text{or }I=1,0<n<L\\\\ &\\text{,if }m>0,n=L\\end{array}\\right. \\tag{28}\\]\n\nwhere the coefficients \\(a_{i,m}\\) can be expressed as\n\n\\[a_{i,m}=\\left\\{\\begin{array}{cl}1,&\\text{if }i=0,\\\\ 1+m,&\\text{if }i=1,\\\\ C_{i},&\\text{if }m=0,\\\\ C_{i+1},&\\text{if }m=1,\\\\ C_{i+1}+\\sum\\limits_{j_{1}=3}^{m+1}C_{i}+\\sum\\limits_{j_{2}=3}^{m+1}\\sum \\limits_{j_{2}=3}^{j_{1}+1}C_{i-1}\\\\ +\\cdots+\\sum\\limits_{j_{1}=3}^{m+1}\\sum\\limits_{j_{2}=3}^{j_{1}+1}\\cdots\\sum \\limits_{j_{i-2}=3}^{j_{3}+1}C_{3}&\\text{and m}>1,\\\\ +\\sum\\limits_{j_{1}=3}^{m+1}\\sum\\limits_{j_{2}=3}^{j_{1}+1}\\cdots\\sum \\limits_{j_{i-1}=3}^{j_{2}+1}(1+j_{i-1}),\\end{array}\\right. \\tag{29}\\]\n\nwhich completes the proof. \n\nBy substituting \\(L_{0}-L_{a}+1\\) and \\(L_{0}\\) for \\(m\\) and \\(n\\) in the general closed-form expression in (6), respectively, we can obtain the probability that the attacker launches a successful DSA on the finitely-long blockchain. Intuitively speaking, in the asymptotic regime where \\(L\\to\\infty\\), the boundary line \\(\\mathcal{L}_{2}\\) in Fig. 4 essentially does not exist, and hence, the two-dimensional random walk boundary hitting problem illustrated in (5) degenerates to a one-dimensional random walk boundary hitting problem. In consequence, the probability that the attacker launches a successful DSA on a finitely-long blockchain is expected to converge to that on an infinitely-long blockchain as \\(L\\to\\infty\\). This intuitive conjecture is formally summarized and rigorously proved in the following theorem.\n\n**Theorem 2**.: _If \\(0<n<L\\), then \\(\\mathbb{P}_{L}(m,n)\\) strictly increases as \\(L\\) increases when \\(0<I<1\\), and is constant when \\(I=0\\) or \\(1\\). Moreover, when \\(0<n<L\\), as \\(L\\to\\infty\\), the probability \\(\\mathbb{P}_{L}(m,n)\\) in (5) converges to_\n\n\\[\\lim_{L\\to\\infty}\\mathbb{P}_{L}(m,n)=\\left\\{\\begin{array}{cl}\\left(\\frac{I}{1- I}\\right)^{m+1}&,\\ \\text{if }\\ 0\\leq I<0.5,\\\\ 1&,\\ \\text{if }\\ 0.5\\leq I\\leq 1.\\end{array}\\right. \\tag{30}\\]\n\n_which equals the probability that an attacker launches a successful DSA on an infinitely-long blockchain when the counterfeit branch is \\(m\\) blocks shorter than the authentic branch [1, 26, 27]._\n\nProof.: When \\(0<n<L\\), from (6), we have\n\n\\[\\mathbb{P}_{L+1}(m,n) =\\sum_{i=0}^{L-n}a_{i,m}(1-I)^{i}I^{m+1+i}\\] \\[=\\mathbb{P}_{L}(m,n)+a_{L-n,m}(1-I)^{L-n}I^{m+1+L-n}. \\tag{31}\\]\n\nFrom (7), we know that \\(a_{i,m}\\geq 1\\),\\(\\forall i,m\\geq 0\\), and hence, we have \\(a_{L-n,m}(1-I)^{L-n}I^{m+1+L-n}>0\\) when \\(0<I<1\\) and \\(a_{L-n,m}(1-I)^{L-n}I^{m+1+L-n}=0\\) when \\(I=0\\) or \\(1\\). This implies that\n\n\\[\\mathbb{P}_{L+1}(m,n) >\\mathbb{P}_{L}(m,n),\\ \\text{if }0<I<1, \\tag{32}\\] \\[\\mathbb{P}_{L+1}(m,n) =\\mathbb{P}_{L}(m,n),\\ \\text{if }I=0\\text{ or }1. \\tag{33}\\]From (32) and (33), we know that when \\(0<I<1\\), \\(\\mathbb{P}_{L}(m,n)\\) is a strictly increasing function of \\(L\\), and when \\(I=0\\) or \\(1\\), \\(\\mathbb{P}_{L}(m,n)\\) is a constant as \\(L\\) changes. By the definition of \\(\\mathbb{P}_{L}(m,n)\\), we know that \\(\\mathbb{P}_{L}(m,n)\\leq 1\\), \\(\\forall L\\). Since when \\(0<I<1\\), \\(\\mathbb{P}_{L}(m,n)\\) is strictly increasing and bounded from above, we know \\(\\mathbb{P}_{L}(m,n)\\) converges as \\(L\\) increases by the monotone convergence theorem [33]. When \\(I=0\\) or \\(1\\), \\(\\mathbb{P}_{L}(m,n)\\) doesn't change as \\(L\\) changes, and hence, \\(\\mathbb{P}_{L}(m,n)\\) also converges. Therefore, \\(\\mathbb{P}_{L}(m,n)\\) converges as \\(L\\) increases, which implies\n\n\\[\\lim_{L\\to\\infty}\\mathbb{P}_{L}(m,n)=\\lim_{L\\to\\infty}\\mathbb{P}_{L+1}(m,n). \\tag{34}\\]\n\nNote that if \\(n\\geq L_{0}\\), we have\n\n\\[\\mathbb{P}_{L+1} (m+1,n+1)\\] \\[=\\sum_{i=0}^{(L+1)-(n+1)-1}a_{i,m+1}(1-I)^{i}I^{(m+1)+1+i}\\] \\[=\\sum_{i=0}^{(L)-(n)-1}a_{i,m+1}(1-I)^{i}I^{(m+1)+1+i}\\] \\[=\\mathbb{P}_{L}(m+1,n). \\tag{35}\\]\n\nFrom (34) and (35), we can get\n\n\\[\\lim_{L\\to\\infty}\\mathbb{P}_{L}(m+1,n+1)=\\lim_{L\\to\\infty}\\mathbb{P}_{L}(m+1, n),\\ \\ \\text{if}\\ n\\geq L_{0}. \\tag{36}\\]\n\nFrom (1), we can get\n\n\\[\\lim_{L\\to\\infty}\\mathbb{P}_{L}(m,n)=I\\times\\lim_{L\\to\\infty} \\mathbb{P}_{L}(m-1,n)\\] \\[\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+(1-I)\\times\\lim_{L\\to\\infty }\\mathbb{P}_{L}(m+1,n+1). \\tag{37}\\]\n\nNote that the condition \\(n\\geq L_{0}\\) holds for the cases of our interest since the authentic branch starts with \\(L_{0}\\) blocks when the attacker launches a DSA. Substituting (36) into (37), we have\n\n\\[\\lim_{L\\to\\infty}\\mathbb{P}_{L}(m,n)=I\\times\\lim_{L\\to\\infty} \\mathbb{P}_{L}(m-1,n)\\] \\[\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad\\qquad+(1-I)\\times\\lim_{L \\to\\infty}\\mathbb{P}_{L}(m+1,n). \\tag{38}\\]\n\nFor simplicity, let \\(g(m+1)\\triangleq\\lim_{L\\to\\infty}\\mathbb{P}_{L}(m,n)\\), \\(m\\geq-1\\), then from (38), we can obtain\n\n\\[g(m+1)=I\\times g(m)+(1-I)\\times g(m+2). \\tag{39}\\]\n\nFrom (2), we have \\(\\lim_{L\\to\\infty}\\mathbb{P}_{L}(-1,n)=1\\) which implies\n\n\\[g(0)=\\lim_{L\\to\\infty}\\mathbb{P}_{L}(-1,n)=1. \\tag{40}\\]\n\nFrom (39), we have\n\n\\[g(m+2)-g(m+1)=\\frac{I}{1-I}\\left[g(m+1)-g(m)\\right], \\tag{41}\\]\n\nwhich yields\n\n\\[g(m+1)-g(m)=\\left(\\frac{I}{1-I}\\right)^{m}\\left[g(1)-g(0)\\right]. \\tag{42}\\]\n\nMoreover, from the recursive equation in (42), we can obtain\n\n\\[g(m+1)-g(1)=[g(1)-g(0)]\\sum_{i=1}^{m}\\left(\\frac{I}{1-I}\\right)^{m}. \\tag{43}\\]\n\nNext, we will determine \\(g(1)\\). From (6) and (7), we know that for any \\(n\\),\n\n\\[g(1) =\\lim_{L\\to\\infty}\\mathbb{P}_{L}(0,n)\\] \\[=\\lim_{L\\to\\infty}\\sum_{i=0}^{L-n-1}C_{i}(1-I)^{i}I^{1+i}\\] \\[=\\sum_{i=0}^{\\infty}C_{i}(1-I)^{i}I^{1+i}. \\tag{44}\\]\n\nwhere \\(C_{i}\\) is the \\(i\\)-th Catalan number. Note that the generating function for the Catalan numbers is defined by [32]\n\n\\[c(x)=\\sum_{i=0}^{\\infty}C_{i}x^{i}=\\frac{1-\\sqrt{1-4x}}{2x}. \\tag{45}\\]\n\nBy setting \\(x=I(1-I)\\) for some \\(I\\in(0,1)\\) in (45), we can obtain\n\n\\[\\sum_{i=0}^{\\infty}C_{i}\\left[I(1-I)\\right]^{i}= \\frac{1-\\sqrt{1-4I(1-I)}}{2I(1-I)}\\] \\[= \\frac{1-\\sqrt{(1-2I)^{2}}}{2I(1-I)}\\] \\[= \\left\\{\\begin{array}{cc}\\frac{1}{1-I}&,0<I<0.5,\\\\ \\frac{1}{I}&,0.5\\leq I<1.\\end{array}\\right. \\tag{46}\\]\n\nNote that if \\(I=0\\), then \\(g(1)=0\\), and if \\(I=1\\), then \\(g(1)=1\\). Moreover, since \\(I\\times\\sum_{i=0}^{\\infty}C_{i}(I(1-I))^{i}=\\sum_{i=0}^{\\infty}C_{i}(1-I)^{i}I^ {1+i}=g(1)\\), we can obtain from (46)\n\n\\[g(1)=\\left\\{\\begin{array}{cc}\\frac{I}{1-I}&,I<0.5,\\\\ 1&,I\\geq 0.5.\\end{array}\\right. \\tag{47}\\]\n\nBy employing (40), (43) and (47), we can obtain\n\n\\[\\lim_{L\\to\\infty}\\mathbb{P}_{L}(m,n)=\\left\\{\\begin{array}{cc}(\\frac{I}{1-I} )^{m+1}&,\\text{if}\\ 0\\leq I<0.5,\\\\ 1&,\\text{if}\\ 0.5\\leq I\\leq 1.\\end{array}\\right. \\tag{48}\\]\n\nwhich completes the proof. \n\nIn Theorem 2, the assumption \\(0<n<L\\) holds for the cases of our interest since \\(0<L_{0}<L\\). As demonstrated by Theorem 2, since \\(\\mathbb{P}_{L}(m,n)\\) is an increasing function of \\(L\\), and as \\(L\\) increases, it converges to the probability of success in launching a DSA on an infinitely-long blockchain, we know that the probability of success in launching a DSA on an infinitely-long blockchain when the counterfeit branch is \\(m\\) blocks shorter than the authentic branch is an upper bound on the probability of success in launching a DSA on a finitely-long blockchain for any \\(m\\) and \\(n\\). It is well known that if an attacker owns more than half of the computational power of the whole network (i.e., \\(I>0.5\\)) and launches a DSA on an infinitely-long blockchain, which is called a 51% attack, the probability of success in launching the 51% attack is always one [1]. However, as shown by Theorem 2, for the case where \\(0<I<1\\) which is generally true if the normalized hash rate of the attacker is between 0 and 1, \\(\\mathbb{P}_{L}(m,n)\\) is a strictly increasing function of \\(L\\), and therefore, we can see from (30) that \\(\\mathbb{P}_{L}(m,n)\\) is strictly smaller than 1 even though \\(I>0.5\\). This demonstrates that unlike infinitely-long blockchains, the probability of success in launching a 51% attack on any finitely-long blockchain is strictly smaller than 1 which reveals that finitely-long blockchains are more resistant to 51% attacks when compared with infinitely-long blockchains.\n\n## IV Simulation Results\n\nIn this section, we numerically study the probability \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) that an attacker launches a successful DSA on a finitely-long blockchain for different parameters \\(L_{0}\\), \\(L_{a}\\), \\(L\\), and \\(I\\), respectively. In particular, we employ Monte Carlo simulations to corroborate the theories developed in this paper. The number of Monte Carlo runs is \\(10^{4}\\) in all simulation results, and the Monte Carlo simulation results are specified by the legend label \"Simulation\" in figures.\n\nAs the index \\(L_{a}\\) of the block that an attacker attempts to falsify varies from 1 to 60, Fig. 5 depicts \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) for different \\(I\\), where \\(L_{0}\\) and \\(L\\) are chosen to be 60 and 100, respectively. The numerical results yielded from Theorem 1 and Monte Carlo simulations are specified by dashed and solid lines in Fig. 5, respectively, which clearly agree with each other. Hence, the numerical results in Fig. 5 corroborate Theorem 1. It is seen from Fig. 5 that \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) increases as \\(L_{a}\\) increases, and moreover, for a given \\(L_{a}\\), \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) increases as \\(I\\) increases. This is because when \\(L_{a}\\) increases, the gap between the number of blocks in the counterfeit branch and that in the authentic branch shrinks, and therefore, it is easier for the attacker to extend its counterfeit branch to surpass the authentic branch before the authentic branch grows to \\(L\\) blocks. Moreover, when \\(I\\) increases, the probability that a malicious miner successfully mines the next block in the network increases, and hence, it is also easier for the attacker to launch a successful DSA.\n\nNext, we numerically investigate how the value of \\(L\\) impacts \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\). As \\(L_{a}\\) varies from \\(1\\) to \\(10\\), Fig. 6 depicts \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) for different \\(L\\), where \\(L_{0}=10\\) and \\(I=0.4\\). It is seen from Fig. 6 that the numerical results yielded from Theorem 1 agree with that from Monte Carlo simulations. Moreover, for a given \\(L_{a}\\), \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) increases as \\(L\\) increases. This can be explained by the fact that when \\(L\\) increases, it takes more time for the honest miners to extend the authentic branch to reach \\(L\\) blocks, and hence, the attacker has a better chance to extend the counterfeit branch to be longer than the authentic branch before the authentic branch grows to \\(L\\) blocks.\n\nFig. 7 depicts \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) for different \\(L_{0}\\) as \\(L_{a}\\) varies from \\(1\\) to \\(70\\), where \\(L=100\\) and \\(I=0.4\\). Again, the numerical results yielded from Theorem 1 exactly match the Monte Carlo simulation results. It is seen from Fig. 7 that for a given \\(L_{a}\\), \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) increases as \\(L_{0}\\) decreases. This is because when \\(L_{a}\\) is given and \\(L_{0}\\) decreases, the gap between the number of blocks in the counterfeit branch and that in the authentic branch shrinks, and hence, the attacker has a better chance to extend the counterfeit branch to be longer than the authentic branch before the authentic branch grows to \\(L\\) blocks.\n\nLastly, we numerically corroborate Theorem 2. As \\(L\\) increases, Fig. 8 depicts \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})\\) obtained from (6) and (30) for different \\(I\\), where \\(L_{a}=1\\) and \\(L_{0}=3\\). The blue and red curves are obtained from (6) and (30), respectively, when \\(I=0.4\\). The yellow and purple curves are obtained from (6) and (30), respectively, when \\(I=0.6\\). It is seen from Fig. 8 that the curves obtained from (6) converge to the corresponding curves obtained from (30) with the same \\(I\\) as \\(L\\) increases. Moreover, the curves obtained from (30) are always above the corresponding curves obtained from (6), which agrees with Theorem 2. This implies that it is more difficult to launch a successful DSA on a finitely-long blockchain than on an infinitely-long blockchain. Moreover, when \\(I\\geq 0.5\\), the DSA can always be launched successfully on an infinitely-long blockchain. However, it is seen from Fig. 8 that when \\(I\\geq 0.5\\), \\(\\mathbb{P}_{L}(L_{0}-L_{a}+1,L_{0})<1\\) for a finitely-long blockchain, which indicates that finitely-long blockchains are more resistant to \\(51\\%\\) attacks than infinitely-long blockchains.\n\n## V Conclusions\n\nIn this paper, we have theoretically studied the vulnerability of finitely-long blockchains in terms of securing data against double-spending attacks We have developed a general closed-form expression for the probability that an attacker launches a successful double-spending attack on a finitely-long blockchain. This probability characterizes the vulnerability of finitely-long blockchains in securing data since if an attacker attempts to falsify the data which have already been stored in a blockchain, the attacker has to launch a successful double-spending attack on it. We have proven that finitely-long blockchains are less vulnerable to double-spending attacks than infinitely-long blockchains. Moreover, unlike infinitely-long blockchains, even though the normalized hash rate of an attacker is greater than \\(50\\%\\), the probability of success in launching a double-spending attack on any finitely-long blockchain is strictly less than one. This indicates that \\(51\\%\\) attacks cannot completely demolish the security of finitely-long blockchains.\n\n## References\n\n* [1]S. Asefi, Y. Madhwal, Y. Yanovich, and E. Gryazina (2021) Application of blockchain for secure data transmission in distributed state estimation. IEEE Trans. Control Netw. Syst.1 (), pp. 1-1. External Links: Document Cited by: SSI.\n* [2]S. Asefi, Y. Madhwal, Y. Yanovich, and E. Gryazina (2021) Application of blockchain for secure data transmission in distributed state estimation. IEEE Trans. Control Netw. Syst.1 (), pp. 1-1. External Links: Document Cited by: SSI.\n* [3]S. Asefi, Y. Madhwal, Y. Yanovich, and E. Gryazina (2021) Application of blockchain for secure data transmission in distributed state estimation. IEEE Trans. Control Netw. Syst.1 (), pp. 1-1. External Links: Document Cited by: SSI.\n* [4]S. Asefi, Y. Madhwal, Y. Yanovich, and E. Gryazina (2021) Application of blockchain for secure data transmission in distributed state estimation. IEEE Trans. Control Netw. Syst.1 (), pp. 1-1. External Links: Document Cited by: SSI.\n\n[MISSING_PAGE_POST]\n\nim, Y. Kim, and Y. Kim (2019) Bitcoin vs. Bitcoin vs. 1* [22] S.-C. Cha, J.-F. Chen, C. Su, and K.-H. Yeh, \"A blockchain connected gateway for BLE-based devices in the Internet of Things,\" _IEEE Access_, vol. 6, pp. 24 639-24 649, 2018.\n* 2018_, 2018, pp. 1-6.\n* [24] A. P. Ozisik and B. N. Levine, \"An explanation of nakamoto's analysis of double-spend attacks,\" _arXiv preprint arXiv:1701.03977_, 2017.\n* [25] M. Rosenfeld, \"Analysis of hashrate-based double spending,\" _arXiv preprint arXiv:1402.2009_, 2014.\n* [26] C. Grunspan and R. Perez-Marco, \"Double spend races,\" _Int. J. Theor. Appl. Finance_, vol. 21, no. 08, p. 1850053, 2018.\n* [27] E. Zaghloul, T. Li, M. W. Mutka, and J. Ren, \"Bitcoin and blockchain: Security and privacy,\" _IEEE Internet Things J._, vol. 7, no. 10, pp. 10 288-10 313, 2020.\n* [28] L. Zhou, L. Wang, Y. Sun, and P. Lv, \"BeeKeeper: A blockchain-based IoT system with secure storage and homomorphic computation,\" _IEEE Access_, vol. 6, pp. 43 472-43 488, 2018.\n* [29] Q. Yang and H. Wang, \"Privacy-preserving transactive energy management for IoT-aided smart homes via blockchain,\" _IEEE Internet Things J._, vol. 8, no. 14, pp. 11 463-11 475, 2021.\n* [30] M. Pilkington, \"Blockchain technology: principles and applications,\" in _Research Handbook on Digital Transformations_. Edward Elgar Publishing, 2016.\n* [31] D. Stiawan, M. Idris, R. F. Malik, S. Nurmaini, N. Alsharif, R. Budiarto _et al._, \"Investigating brute force attack patterns in IoT network,\" _J. Electr. Comput. Eng._, vol. 2019, 2019.\n* [32] R. P. Stanley, _Catalan Numbers_. Cambridge University Press, 2015.\n* [33] R. L. Wheeden and A. Zygmund, _Measure and integral_. Dekker New York, 1977, vol. 26."

Title: Testimonium: A Cost-Efficient Blockchain Relay
Transcription: "# Testimonium:\n\nA Cost-Efficient Blockchain Relay\n\n Philipp Frauenthaler\n\nTU Wien\n\n Vienna\n\n Austria\n\n\\({}^{2}\\)Pantos GmbH\n\n Vienna\n\n Austria\n\n\\({}^{1}\\){p.frauenthaler\n\n m.sigwart\n\n s.schule}@dsg.tuwien.ac.at\n\n\\({}^{2}\\)contact@pantos.io\n\n Marten Sigwart\n\nTU Wien\n\n Vienna\n\n Austria\n\n\\({}^{1}\\){p.frauenthaler\n\n m.sigwart\n\n s.schule}@dsg.tuwien.ac.at\n\n\\({}^{2}\\)contact@pantos.io\n\n Christof Spanring\n\nTU Wien\n\n Vienna\n\n Austria\n\n\\({}^{1}\\){p.frauenthaler\n\n m.sigwart\n\n s.schule}@dsg.tuwien.ac.at\n\n\\({}^{2}\\)contact@pantos.io\n\n Stefan Schulte\n\nTU Wien\n\n Vienna\n\n Austria\n\n\\({}^{1}\\){p.frauenthaler\n\n m.sigwart\n\n s.schule}@dsg.tuwien.ac.at\n\n\\({}^{2}\\)contact@pantos.io\n\n###### Abstract\n\nCurrent blockchain technologies provide very limited means of interoperability. In particular, solutions enabling blockchains to verify the existence of data on other blockchains are either very costly or are not fully decentralized.\n\nTo overcome these limitations, we introduce Testimonium, a novel blockchain relay scheme that applies a validation-on-demand pattern and the on-chain execution of Simplified Payment Verifications to enable the verification of data across blockchains while remaining fully decentralized. Evaluating the scheme for Ethereum-based blockchains shows that Testimonium achieves a cost reduction of up to 92% over existing solutions. As such, the scheme lays a strong foundation for generic blockchain interoperability. For instance, it enables the development of an atomic-commit protocol for distributed transactions across blockchains.\n\n2015\n\nPublished for 11, 2015\n\nPhilipp Frauenthaler, Marten Sigwart, Christof Spanring, and Stefan Schulte. Testimonium: A Cost-Efficient Blockchain Relay. _PVLDB_, 12(xxx): xxxx-yyyyyy, 2019.\n\nDOI: [https://doi.org/10.14778/xxxxxx.xxxxxx](https://doi.org/10.14778/xxxxxx.xxxxxx)\n\n1\n\n## 1 Introduction\n\nFor its ability to store data in a decentralized and immutable way, blockchain technology has gained much attention by the industry and research communities as potentially disruptive in areas such as finance [26], business process management [31], data provenance [32, 35], supply chain management [38], or healthcare [25]. To take the diverse requirements of these use cases into account, a variety of different blockchain platforms have been developed [41], not unlike the emergence of various NoSQL databases as alternatives to traditional database systems [36]. In this field of multiple independent and unconnected blockchains [33], it is unlikely that a \"blockchain to rule them all\" emerges [42]. This reinforces the need for interoperability solutions, especially in scenarios where organizations which utilize different blockchains collaborate with each other.\n\nIn such scenarios, it may be essential that state changes across blockchains are treated as an atomic unit which either succeeds or fails [5]. However--despite already being well-established for traditional databases [20]--such distributed transactions cannot be seamlessly transferred to the blockchain field, since any interaction with external systems might jeopardize the integrity and decentralization guarantees of blockchains like Bitcoin and Ethereum. Ideally, blockchain interoperability is achieved while preserving the properties of integrity and decentralization, i.e., the underlying cross-blockchain communication should not rely on trust in a centralized party.\n\nOne blockchain interoperability approach that is particularly promising are so-called relay schemes. Relay schemes replicate block information of some source blockchain within a destination blockchain to allow the latter to verify the existence of data (e.g., transactions) on the source blockchain without requiring trust in a centralized entity [12]. The ability to verify arbitrary data across blockchains paves the way for more generic blockchain interoperability, e.g., by enabling the implementation of an atomic-commit protocol for distributed transactions across multiple blockchains [17].\n\nFor these verifications to be trustworthy, the block information of the source blockchain needs to be validated by the destination blockchain according to the validation rules of the source blockchain. However, depending on the source and destination blockchains, this validation can be very expensive when being performed on-chain. Within current relay solutions [1, 22], this inevitably leads to either very high operational cost or, if the expensive on-chain validation is by-passed, the need to rely on a centralized component.\n\nTo overcome this issue, we introduce Testimonium, a relay scheme that is fully decentralized while being cost-efficient even for blockchains with expensive validation protocols. The key to this concept is a sophisticated incentive scheme combined with a validation-on-demand approach. We evaluate the scheme in a proof of concept implementation for Ethereum-based blockchains to show that it achieves a cost reduction of up to 92% over existing relay solutions.\n\nThe paper is organized as follows. Section 2 provides background information while Section 3 describes the technical contributions of this paper. In Section 4, we evaluate the proposed relay with regards to security and operational cost. In Section 5, we give an overview of related work. Finally, Section 6 concludes the paper.\n\n\n\n## 2 Background\n\nThis section discusses important background information for Testimonium. For this, we first explain the concept of Simplified Payment Verification (SPV). We then describe how SPVs are used to facilitate blockchain relay schemes.\n\n### Simplified Payment Verification\n\nSPVs enable clients to cryptographically verify that a particular transaction is part of a blockchain without having to store the full blockchain [26]. Instead of the full blockchain, an SPV client only needs to keep a copy of the block headers. In contrast to complete blocks, block headers only store meta data (e.g., the block number) but no transaction data. Thus, block headers only consume a fraction of the space a complete block needs.\n\nTo get new block headers, the client can query nodes having access to the full blockchain. Once the client has a copy of the headers of the blockchain, users can prove to the SPV client the inclusion of transactions in the blockchain and the SPV client can verify these proofs without keeping a copy of the actual transaction data. For that, the client leverages the fact that the transactions of a block are stored as leaves in a so-called Merkle tree [27] and that the hash of the Merkle tree's root node (Merkle root hash) is stored in the block's header (see Fig. 1).\n\nIn case a user wants to prove the inclusion of a particular transaction to an SPV client, the user needs to provide a so-called Merkle proof of membership. This proof contains all nodes of the path from the transaction (leaf) up to the root node (see Fig. 1). When receiving such a proof, an SPV client recalculates the hashes of all nodes along the path from the leaf (i.e., the transaction) up to the root node. If the final hash matches the Merkle root hash of the stored block header, the membership of the transaction within the corresponding block has been successfully verified.\n\n### Relay Schemes\n\nSPV clients have the ability to verify whether or not a particular transaction exists on some blockchain. Block-chain relays like BTC Relay [1] and PeaceRelay [22] utilize this capability to enable transaction inclusion verifications across blockchains. Essentially, relays are SPV clients for a source blockchain running on a destination blockchain. For instance, BTC Relay is a relay running on the Ethereum blockchain (i.e., the destination blockchain) enabling transaction inclusion verifications on block headers from the Bitcoin blockchain (i.e., the source blockchain).\n\nFor successful SPV, the relay needs to know about the block headers of the source blockchain. For that, block headers of the source blockchain need to be constantly submitted to the relay by off-chain clients [12]. With knowledge of all block headers of the source blockchain, the relay can leverage SPV to verify on the destination blockchain that a particular transaction has been included in the source blockchain.\n\nTo keep the system fully decentralized, i.e., to not require any trust in any off-chain client, newly submitted block headers are first validated by the relay before transaction inclusion verifications can be performed on them [12]. Furthermore, competing branches of a blockchain are a common occurrence especially in Proof of Work (PoW) blockchains [40]. While these branches usually consist of valid blocks, only one branch is eventually accepted as the main chain (e.g., in PoW blockchains, the branch with the greatest amount of work invested in it [12]). As transaction inclusion verifications should only be performed for block headers that are part of the current main chain of the source blockchain, the relay needs to track the branch representing the main chain.\n\nA block header is considered valid if it complies with the source blockchain's standard validation procedure. Among other things, this usually involves validating the consensus algorithm. For instance, in PoW it needs to be verified that enough work has been performed whereas for other blockchains it may consist of checking that at least a certain amount of validators (e.g., 2/3) signed the block [12].\n\nExisting relays like BTC Relay perform the source blockchain's header validation for every submitted block header. However, depending on the source and destination blockchains, verifying the validity of a block header on-chain can be computation- and storage-intensive. For example, validating Ethash, the PoW algorithm of Ethereum, requires fragments of the data used during mining to be available on-chain. Even optimized solutions need approximately 3 million gas when executed on an Ethereum-based blockchain (see Section 4). Performing this validation for every block header of the source blockchain leads to extremely high operational cost. To the best of our knowledge, current relay schemes offer no solutions to this problem without involving trusted third parties (see Section 5).\n\nTo tackle this issue, we introduce Testimonium, a relay scheme that achieves a significant cost reduction over traditional blockchain relays. The fundamental concepts of Testimonium are discussed in the following section.\n\n## 3 Testimonium Relay Scheme\n\nThis section introduces Testimonium, a relay scheme that keeps cost of executing SPVs on-chain to a minimum by deploying a validation-on-demand pattern for relayed block headers. Testimonium requires no trust in a single entity as validations are executed on-chain with a reward structure incentivizing participation.\n\nAs mentioned in Section 2, blockchain relays store a copy of the block headers of some source blockchain. The Testimonium relay scheme assumes the block headers of the\n\nFigure 1: Block header with Merkle tree and corresponding Merkle proof of membership for Tx2source blockchain to be based on the data structure proposed by Satoshi Nakamoto [26], which is for example the case for Bitcoin and Ethereum, and the many forks of these blockchain protocols. That is, block headers contain at least the hash of the block's parent, the block's height, and the hash of the root node of the Merkle tree containing the block's transactions. These three fields are referred to as _parentHash_, _blockHeight_, and _merkleRoot_, respectively. In Section 4.3, we discuss additional requirements the involved blockchains need to satisfy. Furthermore, Testimonium introduces some additional fields typically not present in block headers. These fields are needed for executing certain actions and are prefixed with an \\(m\\) (for \"meta\") to distinguish them from fields usually present in a block header.\n\nTestimonium consists of the relay itself (an on-chain program running on the destination blockchain) and two types of off-chain clients: submitters are responsible for relaying block headers from the source blockchain to the destination blockchain, and disputters are responsible for detecting and disputting submitted illegal block headers.\n\n### Replicating the Source Blockchain\n\nIn relay schemes, off-chain clients continuously submit block headers of the source blockchain to the relay on the destination blockchain. When a new header is submitted, multiple actions are performed by the Testimonium relay before the submitted header can be used for verifying the existence of transactions on the source blockchain.\n\nAlgorithm 1 shows the pseudo code for the procedure undertaken by the Testimonium relay whenever a new block header is submitted by an off-chain client. Right after the arrival of a new header, it is checked whether the retrieved header has already been submitted to the relay (Line 2). If this is the case, the submitted header is rejected. Submitted block headers are stored in a global hashmap using the header's hash as key and the header itself as value. The function hash represents the hash function used on the source blockchain to calculate block hashes, e.g., when storing Bitcoin headers, hash would implement _SHA-256_[27].\n\nNext, it is checked whether the block referenced by the field _parentHash_ exists on the relay (i.e., whether it has already been submitted to the Testimonium relay), as shown in Line 5. This ensures that only a continuous chain of block headers is replicated within the Testimonium relay.\n\n```\n1:functionSubmitBlockHeader(header, submitter)\n2:ifheaders.contains(hash(header)) == truethen\n3:returnfalse\n4:parentHash = header.parentHash\n5:ifheaders.contains(parentHash) == falsethen\n6:returnfalse\n7:headers.put(hash(header), header)\n8:header.m.lockedUntil = now + LOCK_PERIOD\n9:header.m.submitter = submitter\n10:parent = headers.get(parentHash)\n11:parent.m.chldn.append(hash(header))\n12:branchHeads.add(hash(header))\n13:ifbranchHeads.contains(parentHash)then\n14:branchHeads.remove(parentHash)\n15:header.m.branchId = parent.m.branchId\n16:header.m.junction = parent.m.junction\n17:else\n18:lastBranchId = lastBranchId + 1\n19:header.m.branchId = lastBranchId\n20:header.m.junction = parentHash\n21:ifparent.m.chldn.length == 2then\n22:setJunction(parent.m.chldn[0],parentHash)\n23:mainChainHead = getMainChainHead()\n```\n\n**Algorithm 1** Procedure performed by the Testimonium relay when receiving a new header of the source blockchain\n\n### Optimistically Accepting Block Headers\n\nAs stated in Section 2.2, executing the source blockchain's header validation procedure on the destination blockchain can be very expensive. Performing this validation for every block header of the source blockchain would lead to high operational cost. Therefore, Testimonium follows an optimistic approach where received block headers are accepted at first without being fully validated (Line 7).\n\nOf course, since submitted block headers are not fully validated, illegal block headers may be accepted by the Testimonium relay, potentially enabling the verification of illegal transactions. Testimonium prevents this by assigning a lock period to newly received block headers (Line 8). During this period, a block header is considered \"locked\", meaning that it cannot be used for transaction inclusion verifications. Furthermore, within this lock period, off-chain clients (i.e., the _disputers_) can dispute headers they deem illegal. In case of a dispute, the header validation is carried out by the Testimonium relay and if the validation fails, the illegal block header is eliminated. Section 3.3 discusses the disputting of illegal block headers in detail. Further, to make submitters of illegal block headers accountable, the submitter's address is stored in the received block header by using the field _m.submitter_, as shown in Line 9.\n\n### Handling Blockchain Branches\n\nIn PoW blockchains like Bitcoin and Ethereum, multiple valid blocks with the same block height can exist in parallel, forming so-called blockchain branches. While multiple branches can exist in parallel, only one of these branches represents the current main chain of the blockchain, e.g., in PoW blockchains this is the branch with the most amount of work invested in it [12]. As more block headers are appended to branches, the main chain of a blockchain may change over time. This represents a challenge to on-chain SPV execution since transaction inclusion verifications should only be successful if the requested block is part of the main chain.\n\nA branch head represents the most recent block header of a blockchain branch. To keep track of all existing branches of the source blockchain, the Testimonium relay tracks the head of each branch. This way, the relay is able to constantly re-evaluate the current main chain of the source blockchain, e.g., in PoW blockchains, the main chain is identified by searching for the branch with the highest total difficulty.\n\nWhenever a new block header has passed the validation, it is added to the set of branch heads (Line 12) as it either becomes the new head of an existing branch or it represents the start of a completely new branch. If a block header continues an already existing branch, it replaces its parent as a branch head (Lines 13ff). If a block header creates a new branch, the header is merely appended to the branch head set as the creation of a new branch does not affect existing branch heads. The branch head of the main chain is stored in the global variable _mainChainHead_. Whenever a new block header is submitted, the current main chain is re-evaluated (Line 23).\n\n#### Enabling Efficient Verifications\n\nWhenever a transaction inclusion verification is requested on a certain block, the Testimonium relay needs to determine whether the block is part of the main chain of the source blockchain. As each block header contains a hash pointer to its parent forming a linked list, we could simply trace from the main chain's head (stored in variable _mainChainHead_, Line 23) all the way back until we reach the requested block or the genesis block. However, depending on how far back the requested block lies, this traversal can be expensive. To make this traversal more cost-efficient, the Testimonium relay stores additional helper variables with each block header.\n\nFirst, it stores a reference to the preceding branch junction, i.e., a reference to the header where the branch of the newly submitted block header branched off. Second, it stores a number identifying a subpath of the current branch, i.e., the branch of which the newly submitted block header is the new head. We refer to this number as branch id. This meta data is stored in the fields _m.junction_ and _m.branchId_, respectively. In case the submitted header continues an existing branch, _m.junction_ and _m.branchId_ are set to the corresponding field values of its parent, as shown in Lines 15 and 16. If a new branch occurs, _m.branchId_ gets assigned the maximum branch id used so far incremented by one and _m.junction_ of the submitted header is set to the parent's hash (Lines 18 to 20). The helper fields _m.branchId_ and _m.junction_ enable a more efficient search when verifying transaction inclusions, as the backwards traversal can be executed in jumps from branch junction to branch junction rather than from block to block.\n\nFurthermore, the Testimonium relay keeps track of each block header's children. We refer to some block \\(c\\) as child of some other block \\(p\\) if the _parentHash_ of \\(c\\) holds a reference to \\(p\\). Further, we refer to a block \\(d\\) as descendant of some other block \\(p\\) if \\(d\\) can reach \\(p\\) using the hash pointers (_parentHash_) forming the linked list. Analogous, we refer to block \\(p\\) as predecessor of block \\(d\\). Whenever a new block header is received, the Testimonium relay adds its hash to its parent's child list (Line 11). Typically, a header only has one child. If the header is a branch junction, the list contains at least two children (i.e., the hashes of the block headers branching off from the header).\n\nThe child list is useful for a number of reasons. First, it allows an easier updating of the _m.junction_ field. In case a new branch junction emerges (Line 21), the _m.junction_ field of the descendants of the new branch junction needs to be set to the hash of the branch junction. The function setJunction (Line 22) updates each descendant until a header is reached that has either no child (i.e., the header is a branch head) or at least two children (i.e., the header represents another branch junction). Second, in case a block header is successfully disputed, the child list is used to delete all block headers that were appended to the illegal block (see Section 3.3).\n\nFinally, the child list is also used to facilitate transaction inclusion verifications since it helps to determine the number of confirming blocks. In the next section, we look at how these verifications are carried out in detail.\n\n### Transaction Inclusion Verifications\n\nAs soon as a block header of the source blockchain is replicated within the Testimonium relay on the destination blockchain, transaction inclusion verifications on that block header are possible. For that, a client (e.g., a smart contract) sends a request to the Testimonium relay in the form of \"Is transaction \\(tx\\) of block \\(b\\) part of the source blockchain and confirmed by at least \\(n\\) blocks?\". To answer such a verification request, the relay executes an on-chain SPV. First, it verifies that the header of block \\(b\\) is known, unlocked (i.e., the lock period has passed), and part of the main chain of the source blockchain. Second, it verifies that block \\(b\\) is confirmed by at least \\(n\\) succeeding blocks. Finally, the Merkle proof of membership which has to be submitted together with the verification request is validated.\n\n#### Verifying Block Membership on the Main Chain\n\nAs outlined in Section 3.1, the Testimonium relay assigns a branch id to every submitted block header. Whenever a submitted block header branches off a new branch, the currently maximum branch id is incremented by one and assigned to the new header. In case a submitted header continues an existing branch, it gets assigned the branch id of its parent.\n\nConsider the example illustrated in Fig. 2 which shows a source blockchain replicated within a Testimonium relay. As can be seen, all block headers between two consecutive branch junctions or between a branch junction and a branch head have the same branch id _BranchId_. Since a submitted header's branch id is either set to its parent's branch id or to the maximum branch id incremented by one, we know that all descendants of some block header \\(h\\) have a branch id equal to or greater than the branch id of \\(h\\). Analogous, all predecessors of \\(h\\) have a branch id equal to or lower than the branch id of \\(h\\).\n\nHence, when verifying the main chain membership of some block header \\(h\\) that has a branch id greater than the branch id of the main chain's head, we know that header \\(h\\) is not part of the main chain without having to traverse any headers of the main chain.\n\nThis constraint is used by Algorithm 2 to verify that a certain block header is part of the main chain of the source blockchain, i.e., whether the block header is a predecessor of the main chain's head. The parameter _blockHash_ holds the hash of the block header to check, whereas _target_ contains the corresponding header (Line 2).\n\nThe algorithm starts at the main chain's head (Line 3). From that point on, the algorithm traverses each branch junction reachable from the head as long as the currently traversed block header's branch id is greater than the branch id of _target_ (Lines 7-13).\n\nSince all headers between two consecutive branch junctions or between a branch junction and the branch's head always have the same branch id, it is completely sufficient to only traverse branch junctions. Since all headers in-between are skipped, the algorithm needs to check only few block headers instead of traversing all headers between the header to look for (i.e., _target_) and the main chain's head.\n\nAfter the execution of the while-loop, variable _current_ contains the branch junction with a branch id equal to or lower than the branch id of _target_. If the branch id of _current_ is strictly lower than the branch id of _target_, _target_ cannot be a part of the main chain and the function returnsfalse (Line 14f). Otherwise, we know that both headers have the same branch id, i.e., they are both part of at least one common branch.\n\nHowever, it can still be the case that _target_ is not part of the main chain. Consider block headers _0x15_ and _0x16_ in Fig. 2. If _0x15_ is the header returned by the loop (i.e., _current_) and _0x16_ the header to look for (i.e., _target_), _0x15_ is part of the main fork while _0x16_ is not. As such, the Testimonium relay compares the block heights of _current_ and _target_. _blockHeight_\\(>\\)_current.blockHeight_, _target_ is not part of the main chain and the function returns false. If _target.blockHeight_\\(<=\\)_current.blockHeight_, _current_ and _target_ are either the same or _current_ is a branch junction between _target_ and the main chain's head. Hence, in both cases, _target_ is part of the main chain.\n\nFurther, when traversing branch junctions, each branch junction is checked whether its lock period has passed. If an unlocked branch junction is encountered for the first time, its child along the path of the main chain is stored in the variable _confirmStart_ (Lines 10-13). If the main chain's head is already unlocked, then all branch junctions on the main chain are unlocked as well (they have been submitted either before or at the same time as the main chain's head). In this case, we store the main chain's head in the variable _confirmStart_ before entering the loop (Lines 5-6), causing the check of each encountered branch junction's lock period to be skipped. Besides a boolean indicating whether the header to look for lies on the main chain, the algorithm also returns the _confirmStart_ variable. The header referenced by _confirmStart_ is used as starting point for verifying whether the requested header has enough confirming block headers. Once more, consider the example in Fig. 2. Assuming the function is called with block hash _0x11_, and block _0x15_ is the latest unlocked branch junction, then the starting point for the confirmation verification is block _0x18_. The algorithm verifying the number of confirmations is discussed in the following section.\n\n### Verifying Sufficient Block Confirmations\n\nBesides checking whether the header of the block supposedly containing the transaction to verify is part of the main chain of the source blockchain, it also needs to be ensured that the header is confirmed by enough succeeding block headers.\n\n```\n1:functionisPartOfMainChain(blockHash)\n2:target = headers.get(blockHash)\n3:current = headers.get(mainChainRead)\n4:confirmStart = 0\n5:ifcurrent.m.lockedUntil \\(<\\) now then\n6:confirmStart = mainChainHead\n7:whilecurrent.m.branchId \\(>\\) target.m.branchId do\n8:oldBranchId = current.m.branchId\n9:current = headers.get(current.m.junction)\n10:ifconfirmStart \\(!=0\\)thencontinue\n11:ifcurrent.m.lockedUntil \\(<\\) now then\n12:confirmStart =\n13:getChildByBranch(current, oldBranchId)\n14:ifcurrent.m.branchId \\(<\\) target.m.branchId then\n15:return (false, confirmStart)\n16:ifcurrent.blockHeight \\(<\\) target.blockHeight then\n17:return (false, confirmStart)\n18:return (true, confirmStart)\n```\n\n**Algorithm 2** Verifies whether the block header referenced by _blockHash_ is part of the main chain of the source blockchain.\n\nAlgorithm 3 shows the pseudo code for this verification. Variable _blockHash_ indicates the block header from where to start the verification, and _confirmations_ specifies the required number of succeeding blocks. Note, the concrete number of block confirmations considered secure depends on the source blockchain, e.g., in Bitcoin six succeeding blocks are deemed sufficient [9].\n\nThe algorithm starts from the specified block header (i.e., _blockHash_) and recursively calls the function for each succeeding block header each time decreasing the number of required confirmations by one (Line 9). In case the block header referenced by the parameter _blockHash_ does not exist, the algorithm returns false (Line 2f). Similarly, a block header that has not reached the end of the lock period yet may still be disputed and identified as invalid by disputers. Hence, in case the algorithm encounters a block header that is still locked, the verification fails as well (Line 5f).\n\nIf the block header exists and is unlocked, it is checked whether further confirmations are required for the block\n\nFigure 2: An example illustrating the replication of a source blockchain within a Testimonium relay. Headers are double-linked, denoted by arrows pointing in both directions. Green headers represent the current main chain of the source blockchain. For the sake of simplicity, block hashes are in ascending order to make it clearly evident which block headers have been submitted before others to the relay, e.g., block header 0x11 was submitted after block header 0x10, 0x1B after 0x1A, and so on. Block headers _0x1B_, _0x14, 0x17,_ and _0x1A_ are heads of the corresponding branch. Block headers _0x10, 0x12_, and _0x15_ represent branch junctions.\n\nheader (Line 6f). If no more confirmations are required, the function returns _true_, since the block exists, is unlocked and confirmed. Otherwise, we check whether the header is a branch head, i.e., has no children (Line 7f). If the header is a branch head but requires further confirmations, _false_ is returned, since the header has no succeeding blocks confirming it. If not, isConfirmed is called on the next child.\n\nNotably, the algorithm always chooses the first child for the next recursive call (Line 8). Of course, in case the block header is a branch junction, multiple children exist. Thus, the caller of the algorithm needs to make sure that the function is only called on a block header and a number of confirmations so that no further branch junction that is unlocked is reached as the algorithm would need to choose the right child in that case.\n\nTo avoid this edge case, the function isPartOfMainChain presented in Algorithm 2 precalculates the starting block header for the confirmation verification (variable _confirmStart_), i.e., since it already traverses all branch junctions between the main chain's head and the requested block header, it can store any branch junction it traverses that is already unlocked. Since all predecessors of that branch junction are ensured to be unlocked as well, we can start the confirmation verification from that branch junction instead of from the requested block header with a reduced number of confirmations. If we encounter another branch junction during the confirmation verification, the branch junction will be locked, stopping the verification. If the branch junction were not locked, the branch junction would have already been returned by function isPartOfMainChain as starting point for the confirmation verification.\n\n```\n1:functionisConfirmed(blockHash, confirmations)\n2:ifheaders.contains(blockHash)==falsethen\n3:returnfalse\n4:header=headers.get(blockHash)\n5:ifheader.m.lockedUntil>=nowthenreturnfalse\n6:if confirmations==0thenreturntrue\n7:ifheader.m.chldn.length==0thenreturnfalse\n8:child=header.m.chldn[0]\n9:returnisConfirmed(child, confirmations-1)\n```\n\n**Algorithm 3** Verifies whether the block referenced by _blockHash_ has at least as many confirmations as specified in the parameter _confirmations_.\n\n### Verifying Merkle Proof of Membership\n\nAfter verifying that block \\(b\\) is part of the source block-chain's current main chain and that block \\(b\\) is confirmed by at least \\(n\\) succeeding blocks, the Testimonium relay checks the Merkle proof of membership. A Merkle proof depends on the data structures used in the source blockchain to represent Merkle trees. Our proof of concept (see Section 4) implements Merkle proof of memberships for Merkle Patricia Tries [2], a Merkle tree variation used in blockchains like Ethereum and Ethereum Classic.\n\nIf the verification of the Merkle proof fails, \\(tx\\) is not part of block \\(b\\). If it is successful, \\(tx\\) is included within the block. Since the Testimonium relay has already verified block \\(b\\)'s membership in the main chain of the source blockchain and \\(n\\) blocks succeeding \\(b\\), it can be assumed that transaction \\(tx\\) is in fact part of the source blockchain.\n\nAs mentioned before, by specifying a sufficiently large number of confirmations, clients requesting a verification increase the probability that transaction \\(tx\\) remains in the main chain of the source blockchain. Further, the verification procedure relies on the source blockchain's headers being exactly replicated within the Testimonium relay on the destination blockchain. Therefore, it is important that the disputers challenge any illegal block headers during the lock period. The details of disputing block headers are discussed in the next section.\n\n### Disputing Block Headers\n\nTo keep the cost of header submissions low, the Testimonium relay optimistically accepts newly submitted block headers without performing the source blockchain's header validation procedure at first. While this potentially enables illegal block headers to enter the relay, transaction inclusion verifications on such illegal block headers are prevented in Testimonium by means of a validation-on-demand pattern.\n\nThat is, each newly submitted header is assigned a lock period during which off-chain clients (i.e., the disputers) can dispute any block headers they deem illegal. When a block header is disputed, the header validation according to the validation protocol of the source blockchain is carried out. If the validation fails, the illegal branch, i.e., the block header together with all its descendants is eliminated from the Testimonium relay. Only after the lock period has passed, transaction inclusion verifications on the submitted headers can be carried out.\n\nThe validation-on-demand pattern can be leveraged whenever the block header validation is so costly that validating every single block header becomes too expensive.\n\n### Validation-on-demand\n\nAlgorithm 4 shows the pseudo code for the steps performed whenever a block header is challenged by a disputer. The algorithm takes the hash of the disputed header as input parameter. First, it checks whether the disputed header is still locked, i.e., whether the lock period has not expired yet (Line 3). Headers which are not locked anymore are deemed valid, so they cannot be disputed.\n\nIf the lock period of the header is still active, the header validation is triggered (Line 4). The concrete implementation of this validation depends on the block header validation procedure of the source blockchain. In our reference implementation, the verification of Ethereum block headers is carried out on block header disputes, since verifying Ethash--the consensus algorithm used by blockchains such as Ethereum and Ethereum Classic--for every submitted block header would otherwise lead to high operational cost (see Section 4).\n\nIf the validation returns _true_, i.e., the block header is valid and was falsely disputed, the function aborts (Line 4). In case the disputed header is in fact invalid (the validation returns _false_), the illegal branch originating from the disputed header is removed from the Testimonium relay. For that, the function pruneBranch is called (Line 5).\n\nAfter the deletion of the illegal branch, the header's hash is also removed from its parent's child list (Line 7). Since the child list has been changed, we check in Line 8 whether the parent of the disputed block header has now become a branch head. If so, the parent's hash is added to the set of branch heads (Line 9). If the parent has exactly one child left (Line 10), the parent is no longer a branch junction. Hence, we set the fields _m.junction_ and _m.branchId_ of all descendants up to and including the next branch junction or branch head to the corresponding fields of the parent (call of updateDesc in Line 11). We omit the pseudo code of this simple function due to space constraints. Further, the removal of an entire branch from the Testimonium relay may change the main chain. Thus, in Line 12, the head of the main chain is recalculated.\n\n#### Pruning Illegal Branches\n\nAlgorithm 5 shows the pseudo code for the pruneBranch function which is called to remove an illegal branch. Before the disputed block header itself is removed, the function is called recursively for each child of the disputed block header (Line 5). The recursive invocation of pruneBranch stops in case the header referenced by _blockHash_ has no children, i.e., it is a branch head. If so, besides removing the header from the _headers_ hash map, the header's hash is also removed from the set of branch heads (Lines 7-10).\n\nTo make submitters of illegal block headers accountable, the disputeHeader function returns a list containing the addresses of the submitters of all the block headers being removed with the illegal branch. Of course, in case no header was successfully disputed (e.g., due to an expired lock period), no address is returned. The returned addresses are used to penalize submitters to discourage the submission of illegal block headers in the future (see Section 3.4).\n\nThe correct functioning of the Testimonium relay is only ensured if submitters continuously submit block headers of the source blockchain to the destination blockchain and if disputers dispute submitted illegal block header. However, clients that submit and dispute block headers incur cost. Thus, an incentive structure for encouraging participation is needed. The details of this incentive structure are explained in the next section.\n\n```\n1:functionpruneBranch(blockHash)\n2:header=headers.get(blockHash)\n3:submitters=[]\n4:forall child in header.m.chldn do\n5:branchSubmitters=pruneBranch(child)\n6:submitters.appendAll(branchSubmitters)\n7:headers.remove(blockHash)\n8:submitters.append(header.m.submitter)\n9:ifbranchHeads.contains(blockHash)then\n10:branchHeads.remove(blockHash)\n11:return submitters\n```\n\n**Algorithm 5** Prunes the branch starting at the header referenced by _blockHash_\n\n### Incentive Structure\n\nWithout an incentive structure that compensates off-chain clients for submitting and disputing block headers, submitters and disputers may have no interest in participating. The incentive structure we propose rewards off-chain clients for submitting and disputing block headers and also discourages submitters from submitting illegal block headers.\n\nTo compensate the disputers for challenging illegal block headers, the submitters are required to deposit a stake. The stake is locked for the duration of the lock period of newly submitted block headers. While the stake is locked, it cannot be withdrawn and cannot be used for submitting further block headers. After a submitted header has passed the lock period without a dispute, the submitter gets back control of the corresponding locked stake. However, in case the block header is disputed successfully within the lock period, i.e., the validation of the block header fails, the disputer that triggered the dispute earns the locked stake of the submitter as well as any stake that was locked for any descendant of the illegal block header. Not only does this incentivize disputers, it also discourages submitters from submitting illegal block headers as they risk losing the deposited stake. Of course, disputers are only incentivized to dispute headers if the potential reward is higher than the cost of executing the dispute.\n\nTo encourage the submission of block headers, submitters receive a fee every time their submitted headers are used for verifying the inclusion of transactions. This verification fee is paid by the client requesting the verification. In order to fully compensate submitters, the total fees earned by transaction inclusion verifications on each header need to be greater than the initial submission cost for that header (Eq. (1)).\n\n\\[\\textit{{fee}}\\times\\textit{no. of verifications}>\\textit{submission cost} \\tag{1}\\]\n\nThe minimum verification fee can thus be calculated as the submission cost of a block header divided by the number of verifications taking place on the submitted block header (Eq. (2)).\n\n\\[\\textit{{fee}}>\\frac{\\textit{submission cost}}{\\textit{no. of verifications}} \\tag{2}\\]\n\nApplying a validation-on-demand pattern together with an incentive structure rewarding participation already lowers the cost of submitting new block headers to the relay. However, submission cost can be decreased even further by applying a slightly modified version of the content-addressable storage pattern [15] which is explained in the next section.\n\n\n\n### Further Optimization\n\nSo far, we have assumed that all data needed for disputes and transaction inclusion verifications is directly stored in the smart contract implementing the Testimonium relay. However, in blockchains like Bitcoin or Ethereum, all submitted transactions including their parameters are implicitly recorded in each blockchain's transaction history. We can take advantage of this fact storing only the hash of the block header, the block number and certain meta data in the smart contract itself. Fields such as the parent hash or the Merkle root hash no longer need to be kept in the smart contract, thus reducing the amount of stored data per block header which subsequently reduces submission cost.\n\nWhenever clients initiate a dispute or a transaction inclusion verification, they read the required full header data from the corresponding submit-transactions recorded in the transaction history and provide it to the smart contract. The contract can then verify the provided headers' integrity by recalculating their hashes and comparing it to the hashes stored in the smart contract. This way, no trust in the client invoking a transaction inclusion verification or a block header dispute is required.\n\nWhile this pattern further reduces submission cost, it leads to an increment of cost for transaction inclusion verifications due to the increased amount of data that has to be passed along with each transaction. In the next section, we provide an extensive evaluation of Testimonium assessing this trade-off as well as providing a comprehensive security analysis.\n\n## 4 Evaluation\n\nIn this section, we evaluate the proposed relay scheme with regards to operational cost and security. Further, we look at the prerequisites that must be fulfilled to deploy a Testimonium relay scheme.\n\n### Quantitative Analysis\n\nThe advantages of Testimonium over traditional blockchain relays become apparent when the execution of the source blockchain's standard header validation on the destination blockchain is very costly. One example of this would be a bi-directional relay between Ethereum and Ethereum Classic. Both, Ethereum and Ethereum Classic, use Ethash as PoW algorithm and the Ethereum Virtual Machine (EVM) as execution environment. However, for the verification of Ethash, no native opcodes exist in the EVM. Even with gas-optimized implementations as the one provided by SmartPool [23], the verification of Ethash for a single block header still costs around 3 million gas, potentially leading to very high operational cost when fully validating every single block header. Hence, these blockchains are a perfect fit for the validation-on-demand pattern employed by the Testimonium relay scheme.\n\nA further advantage of implementing Testimonium first for Ethereum-based blockchains is in the context of sidechains. Sidechains can be used to increase overall transaction throughput of a blockchain platform by outsourcing certain transactions to a sidechain [6]. To transfer digital assets between the main chain and the sidechain, relays can be used to prove the existence of certain pieces of state on one chain from the other chain and vice versa. Ethereum being the most popular blockchain with regards to decentralized applications (DApps) and digital assets [13, 14] has experienced severe scalability issues in the past [13]. Sidechains have been proposed to combat these issues [28]. As Testimonium leads to cost savings of up to 92% over traditional relays for Ethereum-based blockchains, the operation of sidechains for Ethereum becomes a lot cheaper.\n\n### Evaluation Setup\n\nTo evaluate the operating cost of Testimonium, we have implemented a total of three prototypes (_Testimonium1_, _Testimonium2_, and _Baseline_, respectively) for EVM-based blockchains like Ethereum and Ethereum Classic. The prototypes _Testimonium1_ and _Testimonium2_ both implement the validation-on-demand pattern. _Testimonium2_ additionally applies the content-addressable storage optimization as explained in Section 3.5. The third prototype _Baseline_ acts as baseline for our experiments. This prototype does not implement the validation-on-demand pattern. Instead, it fully validates each block header at submission as done by traditional relays such as BTCRelay. Furthermore, _Baseline_ does not use the optimized search algorithm for transaction inclusion verifications and instead implements a naive search starting from the main chain's head, traversing each header until the header supposedly containing the transaction is found or the genesis block is reached. The functionality of each prototype is summed up in Table 1.\n\nUsing a Geth light client (version 1.9.10), we collected 154,445 block headers containing 2,542 branches from the Ethereum main network over a period of two months. Note that we also count uncle blocks as branches, since--when submitted to Testimonium--they would introduce a new branch. We then fed these block headers into the three prototypes that were deployed as smart contracts to a private development blockchain running on a Parity Ethereum node (version 2.6.8-beta, -config dev). All three prototypes were initialized with block #9121452 as genesis block.\n\nA fully functional reference implementation of all concepts and algorithms of Testimonium, an off-chain client written in Go, and the evaluation are available as open-source projects on GitHub1,2,3. For repeatability, the evaluation project not only contains the three prototypes used for the evaluation, but also the evaluation scripts, the necessary block header data as SQL dump, and the results.\n\n\

Tuple 44:
Cleaned Title: framework blockchain interoperability runtime selection
Cleaned Transcription: framework blockchain interoperability runtime selectionnnphilipp frauenthaler michael borkowski stefan schultenn distributed system group tu wien vienna austriannpfrauenthaler mborkowski sschulteinfosystuwienacatnn abstractnnthe suitability particular blockchain given use case depends mainly blockchains functional nonfunctional property property may vary time thus selected blockchain may become unsuitable given use case uncertainty may hinder widespread adoption blockchain technology generalnnto mitigate impact volatile blockchain property propose framework monitor several blockchains allows user define functional nonfunctional requirement determines appropriate blockchain enables switchover chain runtime evaluation using reference implementation show switching another blockchain save cost enable user benefit better performance higher level trustnn blockchain interoperability blockchain metric runtime selectionnn introductionnnin past year cryptocurrencies gained significant public attention first prominent cryptocurrency bitcoin proposed satoshi nakamoto blockchains proven suitable distributed ledger recording transaction bitcoin cryptocurrencies blockchain technology also potential applied use case eg internet thing business process nnthe suitability particular blockchain given use case depends various property eg cost writing data blockchain time data record permanently included thus remains unchanged sufficient probability transaction throughput network overall hash rate distribution hash power among miner mining pool blockchain property vary time eg network hash rate may decrease variation property may cause blockchain become unsuitable given use case consequence may hinder widespread adoption blockchain technology general since uncertain suitability given use case future pose significant risk engineer evaluating utilization blockchains nnfootnote httpsetherscaniocharthashratehttpsetherscaniocharthashratennto facilitate adoption blockchain technology introduce generalpurpose framework storing arbitrary data blockchains framework abstract technical detail offer interface reading data writing data multiple blockchains mitigate impact volatile blockchain property proposed framework provides switchover functionality allowing switch another beneficial blockchain runtime framework monitor multiple blockchains calculates individual benefit determines beneficial one based userdefined requirement furthermore framework able react various event rapid decrease blockchain network hash rate steadily increase cost writing data blockchain beyond volatile blockchain property proposed framework also able meet changing user demand selecting appropriate blockchain combination blockchain selection algorithm switchover functionality enables user benefit low cost better performance higher level trust use reference implementation supporting bitcoin ethereum classic expanse evaluate frameworknnsummarizing contribution work followsnn identify concrete metric relevant monitoring runtime selection blockchainsn propose mechanism determining beneficial blockchain based userdefined requirementsn describe requirement technical design proposed frameworkn evaluate benefit proposed framework term cost performance trust using reference implementationnnthe remainder paper structured follows section ii motivate work section iii present relevant blockchain metric mechanism determining beneficial blockchain switchover functionality section iv provides evaluation presented work section v give overview related work finally section vi concludes papernn ii motivationnnour work aim overcome issue regarding volatile blockchain property changing user demand selection appropriate blockchain among many following elaborate issue detailnnin recent past cryptocurrency user witnessed several price fluctuation eg bitcoins market price reached alltime high close usd december declined peak november nnthe sensitivity cryptocurrencies price fluctuation influence cost writing data blockchain eg varying transaction feesnnfurthermore november community witnessed hash war supporter two competing hard fork bitcoin cash bitcoin cash abc bitcoin cash sv prevent fork get damaged even destroyed competitor opposing side collected much hash power possible leading centralization hard fork additionally considerable amount hash power shifted bitcoin bitcoin cash peak time war due shift bitcoins hash rate decreased seven percent general decreasing network hash rate may lead loss trust blockchain since becomes easier malicious node get control overall hash power enabling perform attack since change leading fork constantly encouraged community member conflict may also emerge futurennanother important aspect blockchain degree decentralization many miner collude others mining pool number participating node grows time pool overall hash rate increase well mining pool concentrating hash power perform strategy available single majority miner nnin blockchain network transaction replicated every network node increasing storage requirement thus affecting scalability currently average public blockchains like bitcoin ethereum process transaction per second despite multiple attempt solve problem eg increasing size limit bitcoin block transferring value offchain using lightning network scalability still open issue thus increasing workload may raise time take new transaction mined additionally user may compete intensively get transaction included one next block possibly leading higher transaction fee since difficult predict workload blockchain confronted progression cost performance unclearnnfootnote httpslightningnetworkhttpslightningnetworknna blockchain project aiming improve scalability corda developed r consortium consortium address scalability problem reducing replication transaction across network node approach may negatively affect availability data integrity also improve privacy corda blockchain project addressing particular requirement since advent bitcoin diverse range blockchains emerged resulting solution many different feature configuration difference range cost efficiency storage performance decentralization access restriction nnfootnote httpswwwrcomhttpswwwrcomnndue various feature property different blockchains equally suitable given use case inevitably leading question blockchain meet requirement user largest extent described blockchain property vary time variation may impact suitability particular blockchain given use case assuming decentralized application relied bitcoin cash hash war application user would completely reliant miner contradicting requirement decentralization case may appropriate switch another blockchain providing similar feature along higher degree decentralization furthermore also user requirement may change time thus another blockchain may become appropriate certain use case eg demanding access restriction offered permissioned blockchainsnnsummarizing engineer seeking utilize blockchain application face diverse range blockchain technology different feature configuration furthermore former technology decision may become outdated due variation blockchain property changing user demand order overcome issue solution required monitor multiple blockchains determines appropriate one based user preference enables switchover blockchains runtime framework supposed continuously monitor several blockchains case another blockchain becomes appropriate currently used one framework expected suggest switching chain ie route subsequent operation eg reading writing data new blockchain additionally switchover userdefined amount data stored currently used blockchain could moved target chain instance may essential certain amount data needed target blockchain processing case community losing trust currently used blockchain next section introduce framework implement needed functionalitiesnn iii approachnnin order address requirement outlined previous section proposed framework consists three main component monitoring component continuously survey information supported blockchain calculates metric value based metric value blockchain selection algorithm calculates blockchains benefit selects beneficial one case another blockchain beneficial currently used one switchover suggested switchover component provides possibility switch one blockchain anothernnin following first introduce section iiia blockchain metric supported monitoring component section iiib discus blockchain selection algorithm section iiic present functionality switchover component finally technical design framework discussed section iiidnnnn blockchain metricsnnin order select appropriate blockchain user able define particular selection metric applied order ass blockchain match need user following present eight blockchain metric relevant comparison different blockchains categorized costrelated metric performancerelated metric securityrelated metric reputation notably framework presented paper allows extend metric model metric necessary therefore discussed metric considered exemplary main requirement metric added metric model measurable case cost performance security metric defined user case reputation metricsnn iiia cost writing kb data blockchain mnnthis metric represents cost writing one kilobyte data blockchain usd since many blockchains allow user prioritize transaction specifying transaction fee cost may vary depending fee user willing pay calculation based transaction fee provided framework user case fee provided framework automatically determines fee cause submitted transaction get included within predefined number block since exemplarily use bitcoin ethereum ethereum classic expanse reference implementation set number six tradeoff cost performance case blockchains connected framework different block number may appropriate using introduced metric framework determine cheapest blockchain selected one kilobyte basis calculation metric since amount sufficient store various kind meta data eg log event case another amount appropriate changed without restrictionsnn iiia cost retrieving kb data blockchain mnnthis metric specifies cost retrieving one kilobyte data blockchain usd typically reading data blockchain free charge nevertheless introduce metric since proposed framework intended applicable wide range use case including possible invocation nonreadonly smart contract method retrieving data blockchain eg access logging metric enables framework compare different blockchains regarding cost retrieving data analogous amount data used calculation changed without restrictionsnn iiia exchange rate mnnthis metric represents current exchange rate usd native cryptocurrency particular blockchain eg market price one bitcoin usd exchange rate required calculating cost interacting particular blockchainnn iiia interblock time mnnthe interblock time specifies rolling average time second take mine block calculated basis block mined last hour interblock time used indicator blockchains performancenn iiia transaction throughput mnnthe transaction throughput represents rolling average number transaction processed per second calculated based transaction mined last hour analogous metric used observe blockchains performancenn iiia degree decentralization mnnthis metric specifies distribution network hash power among miner mining pool framework provides mapping miner address proportion mined block proportion specified percent calculated block mined last hour case ethereumbased blockchains uncle block also taken account metric allows identification miner control large amount hash power miner controlling network hash power tamper blockchain since able generate block enabling master longest chain nn iiia network hash rate mnnthis metric specifies hash rate network performed recent hour hash rate computed current difficulty block mined last hour case ethereumbased blockchains uncle block also taken account metric allows observe progression network hash rate enabling identification significant declinesnn iiia reputation mnnthe reputation integer value indicates degree renown blockchain associated may reflect various property trust frequency new feature release number fork community consensus controversy security concern etc value indicates worst reputation whereas value represents excellent reputation metric introduced compare different blockchains renownnnmetrics mm calculated automatically framework monitoring component manual user input required since metric highly depends subjective assessment framework usernnan overview metric data type given table innnn blockchain selection algorithmnnnext introduce concept comparing different blockchains selecting appropriate one give user opportunity define metric high low importance respectively first introduce weighted ranking system used calculate blockchains benefit blockchain metric assigned userdefined weight indicating importance calculating overall ranking blockchains table ii show six possible weight offered frameworknnfurthermore user specify score assignment function saf blockchain metric saf map concrete metric value score shown di denotes data type metric inntextsafdimapsto tagnnthe saf applied order normalize different data type range data possible combine different metric use weighted ranking blockchains despite fact data range data type single metric differnnthe score calculated saf quantifies well metric satisfies certain property eg interblock time second may rewarded score complete example saf could defined user given section ivnnin table iii five possible score value meaning presented saf metric applied corresponding metric value supported blockchain assuming framework support bitcoin ethereum saf applied cost writing data bitcoin blockchain cost writing data ethereum blockchain next step saf applied cost reading data bitcoin blockchain cost reading data ethereum blockchain procedure repeated mm presented example entire process result two score value metric one bitcoin one ethereum providing weight score assignment user able customize internal logic framework meet desired needsnnthe benefit blockchain mathcalb calculated summing metric weighted score shown n denotes number blockchain metric weighti represents userdefined weight metric mi scoremathcalbi club score value metric mi blockchain mathcalb obtained applying saf value metric mi mathcalbnnsumintextweighticdottextscoremathcalbi tagnnthe presented formula applied supported blockchain blockchain highest benefit chosen beneficial one table iv show example weighted ranking two blockchains evaluated blockchain benefit total weighted score whereas blockchain b benefit therefore blockchain considered beneficialnnthe introduced weighted ranking system allows quantification blockchains benefit basis userdefined weight score assignment however offer mechanism enforcing certain requirement eg interblock time lower equal second blockchain must fulfill circumstance regardless benefit example shown table iv outline situation blockchain worse score interblock time blockchain b still beneficial one due score metricsnnhowever might case utmost importance user particular metric certain threshold met eg example mentioned interblock time value second thus blockchain selection algorithm adapted consider blockchains fulfill additional requirement ie blockchains satisfy additional requirement serve candidate weighted ranking system blockchains regardednnfor purpose introduce metric validation function mvf shown function map tuple tuple di represents data type metric minntextmvfdtimescdotstimes dmapstotextittruetextitfalse tagnnthe leftmost first value returned tuple indicates whether metric valid ie whether satisfies user requirement second value indicates whether metric valid forth last rightmost value tuple represents validity blockchain may result combination single boolean value eg linking single boolean value propositional formula enables user specify complex requirement single boolean value needed decision switchover see section iiic concrete implementation proposed function provided usernn switchover functionalitynnas described section ii switchover process routing subsequent operation eg read write operation another blockchain depending user preference switchover either performed fully automated beneficial blockchain detected first approved usernnfurthermore framework allows user define amount already existing data record moved currently used blockchain destination chain switchover amount may depend metric caused switchover instance community losing trust currently used blockchain may essential transfer data stored currently used blockchain least data specific period time destination blockchainnnin order customize framework logic determining amount data transferred user specify custom strategy whenever appropriate blockchain detected ie switchover suggested framework custom strategy triggered framework forward metric weighted score validation result obtained mvf currently used blockchain suggested chain userdefined strategy presence information enables user define strategy able determine amount data basis metric cause currently used chain le appropriate suggested onennthe amount data transferred specified date range instance userdefined strategy specifies range data record mined range copied destination chain noted use term transfer data describe data copied one blockchain another data course deleted original blockchain goal data transfer merely make sure data get lost instance number miner particular blockchain rapidly decrease reflected low degree decentralization chance high malicious powerful attacker perform attack blockchain thus rendering data blockchain uselessnnin order prevent framework performing multiple switchovers within short period time eg due frequent variation order weighted ranking system introduce switchover suppression period period defined user framework suppresses subsequent switchover suggestion switchover suppression period elapses regardless many change occurring ranking system thus one switchover suggested every period preventing immediate switchovers blockchains timespan defined framework start switchover immediately beneficial blockchain detected automatic switchovers enablednn technical designnnfigure present overview framework architecture proposed framework consists core logic number blockchain proxy depicted external network node serve bridge framework blockchain network eg ethereum network used framework interacting blockchains network eg submitting new transaction requesting new blocksnnthe core logic communicates blockchain proxy consists three major component presented section iiia iiic monitoring component blockchain selection algorithm switchover component based data requested via blockchain proxy core logic validates blockchains metric applying mvf calculates blockchains benefit determines beneficial chain provides functionality switching another blockchain core logic agnostic blockchains technical detail instead according blockchain proxy translates data particular blockchain neutral format processed core logic supported blockchain proxy implemented proxy abstract interaction underlying blockchain providing interface used core logic example interaction writing new data record blockchain reading data record blockchain requesting new blocksnnwe selected bitcoin ethereum ethereum classic expanse prototypical implementation proposed framework first three blockchains chosen due popularity whereas expanse selected since storing data cheap due low market price notably proposed framework restricted blockchains mentioned blockchains considered exemplary case blockchains supported framework extended providing additional proxy implementationsnnfootnote httpsgithubcompfblockchaininterophttpsgithubcompfblockchaininteropnnin order save disk space framework keep block memory needed calculating blockchainsmetrics ie block mined last hour storednnthe framework design incorporates reactive programming paradigm reactive programming paradigm data flow propagation change play key role data source change value change propagated entire topology ie operator observer part topology registered receive notification informed change framework architecture external network node act data source new block received framework subsequent computation step triggered order recalculate metric discussed section iiia new block affect calculation metric value change metric value affect blockchain selection algorithm ie weighted ranking system mvf discussed section iiibnnin following elaborate calculation metric taking account four blockchains selected prototypical implementation framework ie bitcoin ethereum ethereum classic expansenn iiia cost writing kb data blockchain mnna cheap method storing data bitcoin blockchain use script operation code opreturn opreturn mark transaction output invalid accepts userdefined sequence byte order write data record bitcoin blockchain transaction one input two output one output spends remaining coin another one hold data sufficient transaction store byte data second output overall size byte store one kilobyte data transaction required overall size transaction cdot byte size transaction store remaining byte overall size byte multiplied userdefined transaction fee satoshi per byte user provide transaction fee estimation transaction fee requested external apisnnethereumbased blockchains like selected ethereum ethereum classic expanse offer three possibility storing data blockchain first possibility store record data field transaction ethereum ethereum classic system use ethereum virtual machine every transaction cost gas every nonzero byte stored transaction data field additional gas paid number byte stored transaction bounded current block gas limit single transaction carrying one kilobyte data would consume cdot gas february block gas limit ethereum ethereum classic far enough executing transaction holding one kilobyte datannthe second possibility store data log cost storing one byte log eight gas additional gas paid log operation however option requires smart contract emits log event due different way writing contract difficult calculate cost nevertheless second option expensive first since every input data intended logged event also encoded data field transaction submitted contract callnnthe third option store data smart contractsnnfig architecture proposed frameworknnstorage storing byte word smart contract storage cost gas additional gas paid transaction contains contract call input datanntherefore first option cheapest one statement also hold expanse since aforementioned operation consume gas cost expanse virtual machine case user specify preferred gas price framework request median gas price external network nodesnnfootnote httpsexpansetechdocsdeveloperhttpsexpansetechdocsdevelopernn iiic cost retrieving kb data blockchain mnnsince data record stored transaction data field without involvement smart contract reading data record free charge hence current reference implementation metric always zero supported blockchainsnn iiic exchange rate mnnthe framework continuously request current market price usd cryptocurrencies associated supported blockchains reference implementation use cryptocompare external service exposing interface requesting market pricesnnfootnote httpsminapicryptocomparecomhttpsminapicryptocomparecomnn iiic interblock time mnnthe rolling average time two block computed applying formula shown n denotes number block mined last hour presented formula applied supported blockchainsnnfraccdot n tagnn iiic transaction throughput mnnas shown transaction throughput rolling average computed summing number transaction stored block mined last hour dividing sum cdot n denotes total number mined block last hour txcounti represents number transaction block innfracsumintexttxcounticdot tagnn iiic degree decentralization mnnwe calculate distribution network hash power two different way due fundamental difference bitcoin ethereumbased blockchains bitcoin sufficient count number block miner mined least one block last hour step divide miner block counter overall number block ethereumbased blockchains addition regular block also uncle block taken account since miner also spend computational power integrating blocksnn iiic network hash rate mnnfor bitcoin average number hash per second network performed last hour computed shown nnfracncdotfracdcdot tagnnhere n denotes number block mined last hour dcdot specifies expected number hash calculated find block difficulty bitcoin set average new block mined every ten minute second thus number block expected get mined within hour since new block anticipated get mined every ten minute dcdot hash expected computed second yielding average network hash rate fracdcdot hash per second term fracn adjusts hash rate case le block mined calculate hash rate ethereumbased network summing difficulty field block uncle block mined last hour dividing sum number second equal hoursnn iv evaluationnnin order evaluate proposed framework investigate benefit term cost performance trust using exemplary scenario analyze framework reaction varying blockchain property well handling changing user demandsnnsince framework relies external network node set bitcore node bitcoin two parity node ethereum ethereum classic use gexp run expanse network node deployed network node us respective main chain experiment deploy network node separate virtual machine vcpu gb ram hosted google cloud platform framework executed macbook pro late ghz intel core gb mhz ddr intel iris mb gb ssd macos oracle jdk nnfootnote httpsbitcoreiohttpsbitcoreionnfootnote httpswwwparityioethereumhttpswwwparityioethereumnnfootnote httpexpanseorggithubiogoexpansehttpexpanseorggithubiogoexpansennin following four evaluation scenario presented scenario analyzes exemplarily framework reaction varying blockchain metric emulating decreasing hash rate experiment select expanse currently used blockchain experiment also performed blockchains bitcoin ethereum ethereum classic without restriction customize framework internal logic provide implementation mvf return tuple true true true true true false true false case network hash rate drop ghs otherwise true true true true true true true thus network hash rate drop ghs corresponding blockchain invalid denoted boolean value false furthermore set metric weight provide metric score assignment function always return score value since conduction experiment relevant blockchain selected framework detection decreasing hash rate starting hash rate ghs emulate decreasing hash rate reduced ghs every second shown listing hash rate listing log extraction show reaction framework case network hash rate expense decrease rapidlynn switchover suggestion expensenn expense network hash rate ghsnn expense network hash rate ghsnn expense network hash rate ghsnn expense network hash rate ghsnn expense network hash rate ghsnn hash rate ghs violatednn switchover suggestion ethereum classicnnunder ghs framework suggests switch another blockchain ethereum classicnnfor scenario assume framework used serviceoriented architecture made different service adopted operated several independent possibly competing business partner order monitor adherence servicelevel agreement slas service publish relevant information blockchain conduct scenario based metric value measured nnscenario analyzes benefit framework selection mechanism term cost performance trust assume involved business partner want use blockchain cheap fast high level trust framework configured weighted ranking setting outlined table v since assume demand cheap fast write operation high level trust set weight five highest importance metric ignored ie set corresponding weight zero since read operation free reference implementation make use smart contract order benefit accurate selection define score assignment granularly possible eg considering low cost score assignmentnnaccording popularity miner activity assume reputation bitcoin ethereum reputation ethereum classic reputation expense order emulate execution framework fed value measured day according weighted ranking outlined table vi metric weight zero omitted ethereum beneficial blockchain key point selection followsnn using ethereum cost writing one kb data approximately time lower cost writing amount data bitcoin blockchain cost writing data ethereum classic expense blockchains time time lower respectively cost using ethereumn compared bitcoin price usd exchange rate ethereum time lower price usd one ether approximately time greater price one token ethereum classic exchange rate usd expense cheapest tokenn ethereum feature interblock time time shorter bitcoin three time shorter expense ethereum classic almost interblock time ethereumn throughput transaction per second tps ethereum process far greatest number transaction whereas bitcoin rate tps ethereum classic rate tps expense handle tpsn network hash rate ethereum time greater rate ethereum classic time greater hash rate expense bitcoin network mine hash rate approximately time greater ethereumn biggest ethereum miner control network hash power whereas biggest ethereum classic expense miner control respectively biggest miner bitcoin network control nnscenario investigates framework handling changing user demand indicated adjusted metric weight assume engineer one business partner plan run dataintensive test adopted service since large amount data scheduled written blockchain low cost preferred furthermore assume reputation neglected test execution scenario conducted based weighted ranking setting outlined table v order incorporate changed demand weighted ranking system set weight furthermore assume change take effect table vii show weighted ranking based changed setting metric value gathered metric weight zero omitted since ethereum classic highest benefit selected beneficial chain due lack significant variation blockchain metric ethereum beneficial chain entire date range switching ethereum ethereum classic cost writing one kb data decreased factor furthermore ethereum classic almost interblock time ethereum approximately second since expanse interblock time second ethereum classic preferred shown table viinnthe intention scenario show effect changing user requirement indicated adjusted score assignment assume interblock time second completely sufficient conducting service test moreover transaction throughput becomes le important test execution due large amount test data written blockchain low cost still high priority scenario conducted based weighted ranking setting scenario reflect changed user requirement weighted ranking setting score assignment changed inftyto since transaction throughput lower priority weight set assume weighted ranking setting changed based metric value measured changed setting framework selects expanse beneficial chain since highest score shown table viii due lack significant variation blockchain metric ethereum classic beneficial chain entire date range switchover ethereum classic expanse enables cost reduction factor approximately nnsummarizing evaluation see framework select appropriate blockchain based user preference furthermore able react volatile blockchain property handle changing user demand feature allow user benefit low cost better performance higher level trustnn v related worknndespite fact blockchain technology gained much research momentum recent year best knowledge many approach aiming providing mean switch different blockchainsnnone earliest contribution field blockchain interoperability atomic crosschain protocol acc proposed tiernolan protocol enables user different cryptocurrencies swap asset atomic fashion contribution focusing transfer asset atomic swap technology tast tesseract barterdex metronome republic protocol furthermore sidechains aim provide interoperability two blockchains locking asset source chain creating target blockchain transferred asset used one blockchain time cryptographic proof ensure asset locked source chain new one created target chain nnfootnote httpspantosiohttpspantosionnfootnote httpsdocskomododplatformcomhomewhitepaperhtmlhttpsdocskomododplatformcomhomewhitepaperhtmlnnfootnote httpswwwmetronomeiohttpswwwmetronomeionnfootnote httpsrenprojectiohttpsrenprojectionnfootnote httpspolikadotnetworkhttpspolikadotnetworknnfootnote httpscosmosnetworkhttpscosmosnetworknnfootnote httpscosmosnetworkhttpscosmosnetworknnfootnote httpwwwblockcolliderorghttpwwwblockcolliderorgnnbeyond trading asset polkadot cosmos block collider aim integrate blockchains general way eg enabling communication smart contract located different blockchainsnnfootnote httpswwwbitecailcomhttpswwwbitecailcomnna remarkable contribution field blockchain interoperability btcrelay smart contract running ethereum verifies bitcoin transaction contract actsas bridge bitcoin blockchain ethereum smart contract enabling user pay bitcoin using ethereum dappsnnto best knowledge contribution field selection blockchains runtime discussed approach integrate mechanism selecting beneficial blockchain based userdefined requirement furthermore presented approach provide functionality switching back forth several blockchains migrating already existing datann vi conclusionnnin paper presented framework capable switching back forth blockchains runtime proposed framework monitor several blockchains calculates blockchains benefit according userdefined setting determines beneficial one furthermore framework able react variation blockchain metric handle changing user demand presented framework design detail using reference implementation javannour evaluation show switching another blockchain save cost enable user benefit better performance higher level trust modular design framework allows future researcher add support blockchains providing additional proxy implementationsnnas described section iii framework able copy data currently used blockchain destination chain switchover however proposed framework enable migration smart contract blockchains allowing automatic deployment required smart contract destination chain feature may relevant data record managed smart contract rather stored transaction data field therefore investigated future work furthermore reference implementation store data record published ethereum ethereum classic expanse transaction data field rather smart contract storage leading slower access time possible solution want investigate improve time needed searching data tracking transaction hold data recordsnn referencesnn atzori blockchain technology decentralized governance state still necessary journal governance regulation vol cited ssin e bainoungiisha l carreton v cutsem mostinckx w meuter survey reactive programming acm comput surv pp english external link document cited ssin b bambrough senior banker burn bitcoin basic problem note httpwwwforbescomsitesbillybambroughseniorbankerwarmsbitcoinhasabasicproblemaccessedhttpwwwforbescomsitesbillybambroughseniorbankerwarmsbitcoinhasabasicproblemaccessed cited ssin bentov ji f zhang li x zhao l breidenbach p daian juels tesseract realtime cryptocurency exchange using trusted hardware iacr cryptology eprint archive vol pp external link document cited ssin dziembowski introduction cryptocurrencies nd acm sigsac conference computer communication security pp cited ssin dziembowski introduction cryptocurrencies th acm sigsac conference computer communication security pp cited ssin j herrerajonneomarti c perezsola privacy bitcoin transaction new challenge blockchain scalability solution modeling decision artificial intelligence pp cited ssin ic lin liao survey blockchain security issue challenge international journal network security pp cited ssin l maruping v venkatesh r agarwal control theory perspective agile methodology use changing user requirement information system research pp cited ssin challenge opportunity acm transaction management information system pp external link document cited ssin mingxiao xiaofeng z zhe w xiangwei c qijun review consensus algorithm blockchain ieee international conference system man cybernetics pp cited ssin nakamoto bitcoin peertopeer electronic cash system note httpbitcoinorgbitcoinpdfaccessedhttpbitcoinorgbitcoinpdfaccessed cited ssin narayanan j bonneau e felten miller goldfeder bitcoin cryptocurrency technology comprehensive introduction princeton university press cited ssin nakamoto bitcoin peertopeer electronic cash system note httpbitcoinorgbitcoinpdfaccessedhttpbitcoinorgbitcoinpdfaccessed cited ssin narayanan j bonneau e felten miller goldfeder bitcoin cryptocurrency technology comprehensive introduction princeton university press cited ssin nakamoto bitcoin peertopeer electronic cash system note httpbitcoinorgbitcoinpdfaccessedhttpbitcoinorgbitcoinpdfaccessed cited ssin nakamoto bitcoin peertopeer electronic cash system note httpbitcoinorgbitcoinpdfaccessedhttpbitcoinorgbitcoinpdfaccessed cited ssin sward veena f stonedahl data insertion bitcoins blockchain ledger pp cited ssin f tschorsch b scheuermann bitcoin beyond technical survey decentralized digital currency ieee communication survey tutorial pp cited ssin g wood ethereum secure decentralised generalised transaction ledger note httpsethereumgithubioyellowpaperpaperpdfaccessedhttpsethereumgithubioyellowpaperpaperpdfaccessed cited ssin x xu c pautasso l zhu v gramoli ponomarev b tran chen blockchain software connector th working ieeeifip conference software architecture pp cited ssin x xu weber staple l zhu j bosch l bass c pautasso p rimba taxonomy blockchainbased system architecture design ieee international conference software architecture pp cited ssin zohar bitcoin hood communication acm pp cited ssivan zohar bitcoin hood communication acm pp cited ssivan zohar bitcoin hood communication acm pp cited ssivan zohar bitcoin hood communication acm pp cited ssivan zohar bitcoin hood communication acm pp cited ssivan zohar bitcoin hood communication acm pp cited ssivan zohar bitcoin hood communication acm pp cited ssivan narayanan j bonneau e felten miller goldfeder bitcoin cryptocurrency technology comprehensive introduction princeton university press cited ssin zohar bitcoin hood communication acm pp cited ssivan narayanan j bonneau e felten miller goldfeder bitcoin cryptocurrency technology comprehensive introduction princeton university press cited ssin zohar bitcoin peertopeer electronic cash system note httpbitcoinorgbitcoinpdfaccessedhttpbitcoinorgbitcoinpdfaccessed cited ssin zohar bitcoin hood communication acm pp cited ssivan zohar bitcoin hood communication acm pp cited ssivan narayanan j bonneau e felten miller goldfeder bitcoin cryptocurrency technology comprehensive introduction princeton university press cited ssin zohar bitcoin peertopeer electronic cash system note httpbitcoinorgbitcoinpdfaccessedhttpbitcoinorgbitcoinpdfaccessed cited ssin zohar bitcoin hood communication acm pp cited ssivan zohar bitcoin hood communication acm pp cited ssiva title decision framework blockchain adoption transcription decision framework blockchain adoptionnn vittorio capocasalennvittoriocapocasalepolitoitnnguido perbolinnguidoperbolipolitoitnn abstractnnblockchain distributed ledger technology gaining interest academy company institution nonetheless path toward blockchain adoption straightforward blockchain complex technology requires revisiting standard way addressing problem tackling decentralized perspective thus decisionmakers adopt blockchain technology wrong reason prefer suitable one work present decision framework blockchain adoption help decisionmakers decide whether blockchain applicable valuable preferable technology particular decision framework composed small set question answered managerial standpoint require deep technical knowledge blockchainrelated topicsnnblockchain adoption blockchain suitability decision making decision flowchart usenn introductionnnat present company undergoing radical transformation based information sharing digitization known collectively industry revolution revolution driven recent technological advancement physical monitoring data elaboration virtualization automation technology one side data acquisition storage becoming cheaper accurate peertopeer technology blockchain interplanetary file system transforming existing business paradigm nnblockchain creates trust among nontrusting party without relying intermediary blockchain composed network node managing shared distributed database tampering attempt prevented replicating state database node smart contract independently executed node used alter state database thus leveraging tamperresiliency blockchain smart contract could enhance fairness critical process protect valuable resource automate business operation given relevance topic smart contractbased alternative existing service surging multiple sector including finance insurance logistics energy morennnonetheless blockchain complex technology introduces many compromise issue technical legal economic level thus decisionmakers often lack necessary knowledge make informed decision blockchain adoption misconception widespread field unsurprisingly blockchain often chosen wrong reason preferred better technology consequently many blockchain project last long fail fulfill original goal context essential develop standard tool simplify managerial decision process blockchain adoptionnnwe contribute current body knowledge making following contributionsnn propose decision flowchart blockchain adoption help decisionmakers understand blockchain applicable valuable preferable solution framework requireany deep technical knowledge blockchain technology effectively employed decisionmakers different backgroundsn discus rationale behind decision driver framework shed light hidden caveat blockchain technology sufficiently discussed existing literaturennthe remaining part study structured follows section briefly describes blockchain technology present summary related work section describes blockchain adoption decision framework section concludes studynn backgroundnnthis section summarizes main concept related blockchain moreover section includes summary related worksnn blockchainnnblockchain technology enables data sharing among nontrusting party blockchain allows solving trust issue without leveraging trusted third party blockchain composed network peer share common database shared database ledger data appended peer manages copy ledger independently others thus peer maliciously alter copy global state ledger decided based stored majority copy zheng et al luo et al assume uniform distribution voting power among peer simplify discussion however refer majority peer mean majority voting powernnblockchains categorized according governance model follows buterin lin liao nn publicany peer join blockchain system gain voting power public blockchains solve trust issue among participant peer autonomously validate transactionsn consortiumthe blockchain system managed wellidentified peer set rule interacting ledger gaining voting power consortium blockchains solve trust issue among consortium membersn fully privatea single peer manages blockchain system thus system decentralizednn problem statementnnmany realworld system intrinsically decentralized example supply chain composed numerous company behavior one affect performance whole supply chain thus logical manage supply chain decentralized way allowing company vote best strategy improve performance whole supply chainnnthe introduction blockchain technology created opportunity decentralize management data thus blockchain gained adoption intrinsically decentralized system previously relied trusted third party nonetheless blockchain complex technology introduces many hidden compromise issue moreover decisionmakers often lack necessary technical knowledge make informed decision blockchain adoption thus blockchain often adopted wrong reason preferred better technology belotti et al halaburda carson et al labazova et al nnto solve problem created framework help decisionmakers understand blockchain applicable valuable preferable solution framework require deep technical knowledge blockchain technology effectively employed decisionmakers different backgroundsnn related worksnnaccording ref almeshal alhogail blockchain suitability framework divided three category decision model conceptual framework decision flowchartsnndecision model use mathematical model decide blockchain adoption example baf framework determining ideal blockchain solution based weighted evaluation detailed user requirement gourisetti et al nnconceptual framework identify factor consider adopting blockchain technology based practical experience researcher example ten technologydriven factor considered framework proposed ref scriber author included nontechnological factor eg environmental consideration regulation clobessy et al labazova openended question addressed considering blockchain adoption proposed ref angelis ribeiro da silva nndecision flowchart based graph node represent closedended question edge represent related answer user led decision path dictated answer pick many author adopted strategy literature study proposed multistep framework decide blockchain adoption type blockchain needed peck others deepened discussion providing guideline implementing working solution belotti et al considering security threat using blockchain puthal et al analyzing realworld use case hassija et al wust gervais gatteschi et al b framework explicitly designed manager proposed ref challener et al multiple framework analyzed condensed single one ref koens poll however agree decision driver proposed work example requiring presence multiple writer unnecessary group entity may need record tamperproof way written third one case blockchain could viable solution multiple record keep could prevent writer altering past data thus blockchain adoption driven presence multiple decision maker keeper decide data alterable multiple writersnnref lo et al describes framework composed seven main question four subquestions however good technical understanding technology necessary answer proposed question tenstep decision framework proposed ref pedersen et al framework useful considers many aspect ignored similar worksnnfinally author proposed decision framework blockchain adoption tailored specific use case eg logistics ar et al ganeriwalla et al hribernik et al construction industry hunhevicz hall nn blockchain adoption decision frameworknnthis section describes decision framework blockchain adoption graphically summarized fig introducing approach want make important remarksnn blockchain meaningful decentralized governance required even though locution distributed ledger technology gained adoption decentralization matter distribution comefrombeyond n blockchain inefficient used necessary blockchain technology allowing managing database decentralized fashion however database managed single entity technological solution better challener et al nnas consequence previous point fully private blockchains little use opinion employed prevent accidental data modification nondistributed ledger efficient eg immudb paiknn
Original Title: A Framework for Blockchain Interoperability and Runtime Selection
Original Transcription: "# A Framework for Blockchain Interoperability and Runtime Selection\n\nPhilipp Frauenthaler1, Michael Borkowski1, Stefan Schulte1\n\n1 _Distributed Systems Group, TU Wien, Vienna, Austria_\n\n{p.frauenthaler, m.borkowski, s.schulte}@infosys.tuwien.ac.at\n\n###### Abstract\n\nThe suitability of a particular blockchain for a given use case depends mainly on the blockchain's functional and non-functional properties. Such properties may vary over time, and thus, a selected blockchain may become unsuitable for a given use case. This uncertainty may hinder the widespread adoption of blockchain technologies in general.\n\nTo mitigate the impact of volatile blockchain properties, we propose a framework that monitors several blockchains, allows the user to define functional and non-functional requirements, determines the most appropriate blockchain, and enables the switchover to that chain at runtime. Our evaluation using a reference implementation shows that switching to another blockchain can save cost and enable users to benefit from better performance and a higher level of trust.\n\n Blockchain interoperability, blockchain metrics, runtime selection\n\n## I Introduction\n\nIn the past few years, cryptocurrencies have gained significant public attention [13, 28]. The first and most prominent cryptocurrency is Bitcoin, proposed in 2008 by Satoshi Nakamoto [8, 19, 24]. While blockchains have proven to be suitable as distributed ledgers for recording transactions in Bitcoin and other cryptocurrencies [20, 24], blockchain technologies have also the potential to be applied in other use cases, e.g., the Internet of Things or business processes [11, 17, 22].\n\nThe suitability of a particular blockchain for a given use case depends on various properties, e.g., the cost of writing data into that blockchain, the time until a data record is permanently included and thus remains unchanged with sufficient probability, the transaction throughput, the network's overall hash rate, or the distribution of the hash power among miners and mining pools [27]. Blockchain properties vary over time, e.g., the network hash rate may decrease1. Variations of properties may cause a blockchain to become unsuitable for a given use case and, in further consequence, may hinder the widespread adoption of blockchain technologies in general, since the uncertain suitability for a given use case in the future poses significant risk for engineers evaluating the utilization of blockchains [1].\n\nFootnote 1: [https://etherscan.io/chart/hashrate](https://etherscan.io/chart/hashrate)\n\nTo facilitate the adoption of blockchain technologies, we introduce a general-purpose framework for storing arbitrary data on blockchains. The framework abstracts technical details and offers interfaces for reading data from and writing data into multiple blockchains. To mitigate the impact of volatile blockchain properties, the proposed framework provides a switchover functionality allowing to switch to another, more beneficial blockchain at runtime. The framework monitors multiple blockchains, calculates their individual benefits and determines the most beneficial one based on user-defined requirements. Furthermore, the framework is able to react to various events such as a rapid decrease of a blockchain network's hash rate or a steadily increase of the cost of writing data into a blockchain. Beyond volatile blockchain properties, the proposed framework is also able to meet changing user demands by selecting a more appropriate blockchain. The combination of the blockchain selection algorithm and the switchover functionality enables users to benefit from low cost, better performance, and a higher level of trust. We use a reference implementation supporting Bitcoin, Ethereum Classic, and Expanse to evaluate our framework.\n\nSummarizing, the contributions of our work are as follows:\n\n* We identify concrete metrics relevant for the monitoring and the runtime selection of blockchains.\n* We propose a mechanism for determining the most beneficial blockchain based on user-defined requirements.\n* We describe the requirements and the technical design of the proposed framework.\n* We evaluate the benefits of the proposed framework in terms of cost, performance, and trust using a reference implementation.\n\nThe remainder of this paper is structured as follows: In Section II, we further motivate our work. Section III presents relevant blockchain metrics, a mechanism for determining the most beneficial blockchain, and the switchover functionality. Section IV provides an evaluation of the presented work and Section V gives an overview of related work. Finally, Section VI concludes the paper.\n\n## II Motivation\n\nOur work aims to overcome issues regarding volatile blockchain properties, changing user demands, and the selection of an appropriate blockchain among many. In the following, we elaborate on these issues in more detail.\n\nIn the recent past, cryptocurrency users witnessed several price fluctuations, e.g., Bitcoin's market price reached an all-time high close to 20,000 USD in December 2017 [3] and declined about 75% from this peak until November 2018 [9].\n\nThe sensitivity of cryptocurrencies for price fluctuations influences the cost of writing data into a blockchain, e.g., through varying transaction fees.\n\nFurthermore, in November 2018, the community has witnessed a \"hash war\" between the supporters of two competing hard forks of Bitcoin Cash (Bitcoin Cash ABC and Bitcoin Cash SV) [21]. To prevent the own fork to get damaged or even destroyed by the competitors, both opposing sides collected as much hash power as possible, leading to a centralization of both hard forks [12]. Additionally, a considerable amount of hash power has been shifted from Bitcoin to Bitcoin Cash during the peak time of the \"war\". Due to this shift, Bitcoin's hash rate decreased by seven percent [21]. In general, a decreasing network hash rate may lead to a loss of trust in a blockchain since it becomes easier for malicious nodes to get control over more than 50% of the overall hash power, enabling them to perform a 51% attack [15]. Since changes leading to forks are constantly encouraged by community members, such conflicts may also emerge in the future.\n\nAnother important aspect of a blockchain is its degree of decentralization. Many miners collude with others through mining pools [20]. If the number of participating nodes grows over time, the pool's overall hash rate increases as well. Mining pools concentrating more than 50% of the hash power can perform any strategy available to a single majority miner [8].\n\nIn blockchain networks, all transactions are replicated on every network node, increasing storage requirements and thus affecting scalability [27]. Currently, on average, public blockchains like Bitcoin or Ethereum can only process 3-20 transactions per second [26]. Despite multiple attempts to solve this problem (e.g., increasing the size limit of Bitcoin blocks or transferring values off-chain by using the Lightning Network2), scalability is still an open issue [14, 26]. Thus, an increasing workload may raise the time it takes until new transactions are mined. Additionally, users may compete more intensively to get their transactions included in one of the next blocks, possibly leading to higher transaction fees. Since it is difficult to predict the workload a blockchain is confronted with, the progression of cost and performance is unclear.\n\nFootnote 2: [https://lightning.network/](https://lightning.network/)\n\nA blockchain project aiming to improve scalability is Corda, developed by the R3 consortium3. The consortium addresses the scalability problem by reducing the replication of transactions across network nodes. This approach may negatively affect availability and data integrity, but also improve privacy [27]. Corda is not the only blockchain project addressing particular requirements. Since the advent of Bitcoin in 2008, a diverse range of blockchains has emerged, resulting in solutions with many different features and configurations. Differences range from cost efficiency, storage and performance to decentralization and access restrictions [27].\n\nFootnote 3: [https://www.r3.com/](https://www.r3.com/)\n\nDue to their various features and properties, different blockchains are not equally suitable for a given use case, inevitably leading to the question which blockchain meets the requirements of a user to the largest extent [27]. As described above, blockchain properties vary over time. Such variations may impact the suitability of a particular blockchain for a given use case. Assuming a decentralized application relied on Bitcoin Cash during the \"hash war\", application users would have been completely reliant on a few miners, contradicting the requirement of decentralization. In such a case, it may be appropriate to switch to another blockchain providing similar features along with a higher degree of decentralization. Furthermore, also user requirements may change over time and thus, another blockchain may become more appropriate for a certain use case [16], e.g., demanding access restrictions offered by permissioned blockchains.\n\nSummarizing, engineers seeking to utilize a blockchain for their applications face a diverse range of blockchain technologies with different features and configurations. Furthermore, a former technology decision may become outdated due to variations of blockchain properties or changing user demands. In order to overcome these issues, a solution is required that monitors multiple blockchains, determines the most appropriate one based on user preferences, and enables a switchover between blockchains at runtime. Such a framework is supposed to continuously monitor several blockchains. In case another blockchain becomes more appropriate than the currently used one, the framework is expected to suggest switching to that chain, i.e., to route subsequent operations (e.g., reading or writing data) to the new blockchain. Additionally, during the switchover, a user-defined amount of data stored on the currently used blockchain could be moved to the target chain. This, for instance, may be essential if a certain amount of data is needed on the target blockchain for further processing or in case the community is losing trust in the currently used blockchain. In the next section, we will introduce how our framework implements the needed functionalities.\n\n## III Approach\n\nIn order to address the requirements outlined in the previous section, the proposed framework consists of three main components: The _Monitoring Component_ continuously surveys information about each supported blockchain and calculates metric values. Based on these metric values, the _Blockchain Selection Algorithm_ calculates each blockchain's benefit and selects the most beneficial one. In case another blockchain is more beneficial than the currently used one, a switchover is suggested. The _Switchover Component_ provides the possibility to switch from one blockchain to another.\n\nIn the following, we first introduce in Section III-A the blockchain metrics supported by the Monitoring Component. In Section III-B, we discuss the Blockchain Selection Algorithm, while Section III-C presents the functionality of the Switchover Component. Finally, the technical design of the framework is discussed in Section III-D.\n\n\n\n### _Blockchain Metrics_\n\nIn order to select the most appropriate blockchain, users should be able to define particular selection metrics, which are then applied in order to assess how a blockchain matches the needs of the user. In the following, we present eight blockchain metrics relevant for the comparison of different blockchains. They can be categorized into cost-related metrics (M1-3), performance-related metrics (M4-5), security-related metrics (M6-7), and reputation (M8). Notably, the framework presented in this paper allows to extend the metric model by further metrics, if necessary. Therefore, the discussed metrics should be considered as exemplary. The main requirement for a metric to be added to the metric model is that it is measurable (which is the case for the cost, performance, and security metrics below) or can be defined by the user (which is the case for reputation metrics).\n\n#### Iii-A1 Cost of writing 1 KB of data into a blockchain (M1)\n\nThis metric represents the cost of writing one kilobyte of data into a blockchain (in USD). Since many blockchains allow their users to prioritize transactions by specifying transaction fees, the cost may vary depending on the fees the user is willing to pay. The calculation is based on the transaction fees provided by the framework user. In case no fees are provided, the framework automatically determines fees that will cause submitted transactions to get included within a pre-defined number of blocks. Since we exemplarily use Bitcoin, Ethereum, Ethereum Classic, and Expanse in the reference implementation, we set this number to six as a trade-off between cost and performance. In case other blockchains are connected to the framework, a different block number may be more appropriate. By using the introduced metric, the framework can determine the cheapest blockchain. We have selected one kilobyte as basis for the calculation of this metric, since this amount is sufficient to store various kinds of meta data, e.g., log events. In case another amount is more appropriate, it can be changed without any restrictions.\n\n#### Iii-A2 Cost of retrieving 1 KB of data from a blockchain (M2)\n\nThis metric specifies the cost of retrieving one kilobyte of data from a blockchain (in USD). Typically, reading data from a blockchain is free of charge. Nevertheless, we introduce this metric since the proposed framework is intended to be applicable for a wide range of use cases, including possible invocations of non-read-only smart contract methods for retrieving data from a blockchain (e.g., access logging). This metric enables the framework to compare different blockchains regarding cost of retrieving data. Analogous to M1, the amount of data used for the calculation can be changed without any restrictions.\n\n#### Iii-A3 Exchange rates (M3)\n\nThis metric represents the current exchange rate between USD and the native cryptocurrency of a particular blockchain, e.g., the market price for one Bitcoin in USD. Exchange rates are required for calculating the cost of interacting with a particular blockchain.\n\n#### Iii-A4 Inter-block time (M4)\n\nThe inter-block time specifies the rolling average of the time (in seconds) it takes to mine a block and is calculated on the basis of all blocks that have been mined during the last 24 hours. The inter-block time is used as an indicator of a blockchain's performance.\n\n#### Iii-A5 Transaction throughput (M5)\n\nThe transaction throughput represents the rolling average of the number of transactions that are processed per second and is calculated based on all transactions that have been mined during the last 24 hours. Analogous to M4, this metric is used to observe a blockchain's performance.\n\n#### Iii-A6 Degree of decentralization (M6)\n\nThis metric specifies the distribution of the network's hash power among miners or mining pools. The framework provides a mapping between miner addresses and their proportion of mined blocks. The proportion is specified in percent and is calculated from the blocks that have been mined during the last 24 hours. In case of Ethereum-based blockchains, uncle blocks are also taken into account. This metric allows the identification of miners that control large amounts of hash power. Miners controlling more than 50% of a network's hash power can tamper with the blockchain, since they are able to generate more blocks, enabling them to master the longest chain [18].\n\n#### Iii-A7 Network hash rate (M7)\n\nThis metric specifies the hash rate the network has performed in the recent 24 hours. The hash rate is computed from the current difficulty and from the blocks that have been mined during the last 24 hours. In case of Ethereum-based blockchains, uncle blocks are also taken into account. This metric allows to observe the progression of the network's hash rate, enabling the identification of significant declines.\n\n#### Iii-A8 Reputation (M8)\n\nThe reputation is an integer value between 0 and 10, and indicates the degree of renown a blockchain is associated with. It may reflect various properties such as trust, frequency of new feature releases, number of forks, community consensus and controversies, security concerns, etc. The value 0 indicates the worst reputation, whereas the value 10 represents an excellent reputation. This metric is introduced to compare different blockchains by their renown.\n\nMetrics M1-M7 are calculated automatically by the framework's Monitoring Component. For M8, manual user input is required, since this metric highly depends on the subjective assessment of the framework user.\n\nAn overview of each metric's data type is given in Table I.\n\n\n\n### _Blockchain Selection Algorithm_\n\nNext, we introduce concepts for comparing different blockchains and for selecting the most appropriate one. To give the user the opportunity to define which metrics are of high and low importance, respectively, we first introduce a weighted ranking system used to calculate a blockchain's benefit. For this, each blockchain metric is assigned a user-defined weight indicating its importance when calculating an overall ranking of blockchains. Table II shows six possible weights offered by the framework.\n\nFurthermore, the user has to specify a _Score Assignment Function_ (SAF) for each blockchain metric. The SAF maps a concrete metric value to a score, as shown in (1). \\(D_{i}\\) denotes the data type of metric \\(i\\).\n\n\\[\\text{SAF}:D_{i}\\mapsto\\{0,1,2,3,4\\} \\tag{1}\\]\n\nThe SAF is applied in order to normalize different data types and ranges of data. Through this, it is possible to combine the different metrics and use them for a weighted ranking of blockchains, despite the fact that the data ranges and data types of the single metrics differ.\n\nThe score calculated by the SAF quantifies how well a metric satisfies a certain property, e.g., an inter-block time of 100 seconds may be rewarded with a score of 2. A complete example for how a SAF could be defined by the user is given in Section IV.\n\nIn Table III, five possible score values and their meanings are presented. The SAF of a metric is applied to the corresponding metric value of each supported blockchain. Assuming the framework supports Bitcoin and Ethereum, the SAF of M1 is applied to the cost of writing data into the Bitcoin blockchain and to the cost of writing data into the Ethereum blockchain. In a next step, the SAF of M2 is applied to the cost of reading data from the Bitcoin blockchain and to the cost of reading data from the Ethereum blockchain. The same procedure is repeated for M3-M8. In the presented example, the entire process results in two score values for each metric (one for Bitcoin and one for Ethereum). By providing weight and score assignments, the user is able to customize the internal logic of the framework to meet desired needs.\n\nThe benefit of a blockchain \\(\\mathcal{B}\\) is calculated by summing up each metric's weighted score, as shown in (2), where \\(n\\) denotes the number of blockchain metrics, weight\\({}_{i}\\) represents the user-defined weight of metric \\(M_{i}\\) and score\\({}_{\\mathcal{B}[i]}\\) clubs the score value of metric \\(M_{i}\\) for blockchain \\(\\mathcal{B}\\) (obtained by applying the SAF to the value of metric \\(M_{i}\\) for \\(\\mathcal{B}\\)).\n\n\\[\\sum_{i=1}^{n}\\text{weight}_{i}\\cdot\\text{score}_{\\mathcal{B}[i]} \\tag{2}\\]\n\nThe presented formula is applied for each supported blockchain. The blockchain with the highest benefit is chosen as the most beneficial one. Table IV shows an example of a weighted ranking, where two blockchains are evaluated. Blockchain A has a benefit (total weighted score) of 103, whereas Blockchain B has a benefit of 101. Therefore, blockchain A is considered as more beneficial.\n\nThe introduced weighted ranking system allows the quantification of a blockchain's benefit on the basis of user-defined weights and score assignments. However, it does not offer a mechanism for enforcing certain requirements (e.g., an inter-block time lower than or equal to 60 seconds) a blockchain _must_ fulfill under all circumstances, regardless of its benefit. The example shown in Table IV outlines a situation where Blockchain A has a worse score for M4 (inter-block time) than Blockchain B, but A is still the most beneficial one due to the scores of other metrics.\n\nHowever, it might be the case that it is of utmost importance to the user that for a particular metric a certain threshold is met, e.g., in the example just mentioned, that the inter-block time (M4) has at most a value of 60 seconds. Thus, the Blockchain Selection Algorithm is adapted to consider only those blockchains that fulfill such additional requirements, i.e., only those blockchains that satisfy these additional requirements serve as candidates for the weighted ranking system. All other blockchains are not further regarded.\n\nFor that purpose, we introduce the _Metric Validation Function_ (MVF). As shown in (3), this function maps an 8-tuple to a 9-tuple. \\(D_{i}\\) represents the data type of metric \\(M_{i}\\).\n\n\\[\\text{MVF}:D_{1}\\times\\cdots\\times D_{8}\\mapsto\\{\\textit{true},\\textit{false}\\}^ {9} \\tag{3}\\]\n\nThe left-most (first) value of the returned 9-tuple indicates whether metric M1 is valid (i.e., whether it satisfies user requirements), the second value indicates whether metric M2 is valid and so forth. The last (right-most) value of the 9-tuple represents the validity of a blockchain and may be the result of a combination of the single boolean values, e.g., linking the single boolean values to a propositional formula. This enables the user to specify more complex requirements. The single boolean values are needed for further decisions during the switchover (see Section III-C). The concrete implementation of the proposed function has to be provided by the user.\n\n### _Switchover Functionality_\n\nAs described in Section II, a switchover is the process of routing all subsequent operations (e.g., read and write operations) to another blockchain. Depending on user preferences, the switchover is either performed fully automated once a more beneficial blockchain is detected, or has first to be approved by the user.\n\nFurthermore, the framework allows the user to define the amount of already existing data records that should be moved from the currently used blockchain to the destination chain during a switchover. This amount may depend on the metric(s) that caused the switchover. For instance, if the community is losing trust in the currently used blockchain, it may be essential to transfer _all_ data stored on the currently used blockchain or at least data of a specific period of time to the destination blockchain.\n\nIn order to customize the framework's logic for determining the amount of data that should be transferred, the user can specify a custom strategy. Whenever a more appropriate blockchain is detected, i.e., a switchover is suggested by the framework, this custom strategy is triggered. The framework forwards each metric's weighted score and the validation results (obtained from the MVF) of both the currently used blockchain and the suggested chain to the user-defined strategy. The presence of this information enables the user to define a strategy that is able to determine the amount of data on the basis of those metrics that cause the currently used chain to be less appropriate than the suggested one.\n\nThe amount of data to be transferred is specified by a date range. For instance, if the user-defined strategy specifies a range between 01.02.2019 and 28.02.2019, all data records mined during this range are copied to the destination chain. It should be noted, that - while we use the term \"transfer data\" to describe that data is copied from one blockchain to another - data can of course not be deleted from the original blockchain. The goal of data transfers is merely to make sure that no data gets lost. For instance, if the number of miners for a particular blockchain rapidly decreases and this is reflected in a very low degree of decentralization (M6), the chance is very high that a malicious, powerful attacker can perform a 51% attack on the blockchain, thus rendering the data in the blockchain useless.\n\nIn order to prevent the framework from performing multiple switchovers within a short period of time, e.g., due to frequent variations of the order in the weighted ranking system, we introduce a _switchover suppression period_. This period can be defined by the user. The framework suppresses subsequent switchover suggestions until the switchover suppression period elapses, regardless of how many changes are occurring in the ranking system. Thus, at most one switchover is suggested every period, preventing immediate switchovers between blockchains. If no timespan is defined, the framework starts the switchover immediately after a more beneficial blockchain has been detected (and automatic switchovers are enabled).\n\n### _Technical Design_\n\nFigure 1 presents an overview of the framework's architecture. The proposed framework consists of the _Core Logic_ and a number of _Blockchain Proxies_. The depicted external network nodes serve as bridges between the framework and blockchain networks (e.g., the Ethereum network). They are used by the framework for interacting with a blockchain's network, e.g., for submitting new transactions or requesting new blocks.\n\nThe Core Logic communicates with Blockchain Proxies and consists of the three major components presented in Sections III-A to III-C: The Monitoring Component, the Blockchain Selection Algorithm, and the Switchover Component. Based on data requested via the Blockchain Proxies, the Core Logic validates each blockchain's metrics by applying MVF, calculates each blockchain's benefit, determines the most beneficial chain, and provides the functionality for switching to another blockchain. The Core Logic is agnostic to a blockchain's technical details. Instead, the according Blockchain Proxy translates data from a particular blockchain into a neutral format that can be processed by the Core Logic. For each supported blockchain, such a proxy is implemented. A proxy abstracts interactions with the underlying blockchain by providing an interface used by the Core Logic. Examples for interactions are writing new data records into a blockchain, reading data records from a blockchain, and requesting new blocks.\n\nWe have selected Bitcoin, Ethereum, Ethereum Classic, and Expanse for the prototypical implementation of the proposed framework4. The first three blockchains have been chosen due to their popularity, whereas Expanse has been selected since storing data is very cheap due to the low market price. Notably, the proposed framework is not restricted to these blockchains. The mentioned blockchains should be considered as exemplary. In case further blockchains should be supported, the framework can be extended by providing additional proxy implementations.\n\nFootnote 4: [https://github.com/pf92/blockchain-interop](https://github.com/pf92/blockchain-interop)\n\nIn order to save disk space, the framework only keeps blocks in memory that are needed for calculating each blockchain'smetrics, i.e., only blocks which have been mined during the last 24 hours are stored.\n\nThe framework's design incorporates the reactive programming paradigm. In the reactive programming paradigm, data flows and the propagation of changes play a key role. If a data source changes its value, the change is propagated through the entire topology, i.e., each operator or observer that is part of the topology or is registered to receive notifications is informed about changes [2]. In the framework's architecture, external network nodes act as data sources. Once a new block is received by the framework, subsequent computation steps are triggered in order to recalculate the metrics discussed in Section III-A. Each new block affects the calculation of the metric values, and changes of metric values affect the blockchain selection algorithm, i.e., the weighted ranking system and the MVF, as discussed in Section III-B.\n\nIn the following, we further elaborate on the calculation of each metric, taking into account the four blockchains which we have selected for the prototypical implementation of our framework, i.e., Bitcoin, Ethereum, Ethereum Classic, and Expanse.\n\n#### Iii-A1 Cost of writing 1 KB of data into a blockchain (M1)\n\nA cheap method for storing data on the Bitcoin blockchain is to use the script operation code OP_RETURN [23]. OP_RETURN marks a transaction output as invalid and accepts a user-defined sequence of up to \\(80\\) bytes [7, 23]. In order to write data records into the Bitcoin blockchain, a transaction with one input and two outputs (one output that spends the remaining coins and another one that holds the data) is sufficient. A transaction that stores \\(80\\) bytes of data in its second output has an overall size of \\(282\\) bytes. To store one kilobyte of data, \\(13\\) transactions are required. The overall size of these \\(13\\) transactions is 12 \\(\\cdot\\) 282 + 266 = 3,650. \\(266\\) bytes is the size of the transaction that stores the remaining \\(64\\) bytes. The overall size of 3,650 bytes is multiplied with the user-defined transaction fees (Satoshi per byte). If the user does not provide transaction fees, an estimation of transaction fees is requested from external APIs.\n\nEthereum-based blockchains like the selected Ethereum, Ethereum Classic, and Expanse, offer three possibilities for storing data on the blockchain [27]. The first possibility is to store records in the data field of a transaction. In Ethereum and Ethereum Classic (both systems use the Ethereum Virtual Machine), every transaction costs 21,000 gas. For every non-zero byte that is stored in a transaction's data field, additional 68 gas have to be paid [25]. The number of bytes stored in a transaction is bounded by the current block gas limit. A single transaction carrying one kilobyte of data would consume at most 21,000 + 68 \\(\\cdot\\) 1024 = 90,632 gas. As of February 2019, the block gas limit for Ethereum and Ethereum Classic is about 8,000,000, far enough for executing transactions holding one kilobyte of data.\n\nThe second possibility is to store data in logs. The cost of storing one byte in a log is eight gas. Additional \\(375\\) gas have to be paid for the LOG operation [25]. However, this option requires a smart contract that emits log events. Due to different ways of writing such a contract, it is difficult to calculate the cost. Nevertheless, the second option is more expensive than the first, since every input data intended to be logged as event is also encoded in the data field of the transaction submitted for the contract call.\n\nThe third option is to store data in a smart contract's\n\nFig. 1: Architecture of the proposed framework.\n\nstorage. Storing a 32-byte word in a smart contract's storage costs 20,000 gas [25]. Additional gas has to be paid for the transaction that contains the contract call and the input data.\n\nTherefore, the first option is the cheapest one. This statement also holds for Expanse, since the aforementioned operations consume the same gas cost on the Expanse Virtual Machine5. In case the user does not specify a preferred gas price, the framework requests the median gas price from the external network nodes.\n\nFootnote 5: [https://expanse.tech/docs/developer/](https://expanse.tech/docs/developer/)\n\n#### Iii-C2 Cost of retrieving 1 KB of data from a blockchain (M2)\n\nSince data records are stored in a transaction's data field without the involvement of smart contracts, reading data records is free of charge. Hence, in the current reference implementation, this metric is always zero for all supported blockchains.\n\n#### Iii-C3 Exchange rates (M3)\n\nThe framework continuously requests the current market price in USD for cryptocurrencies associated with the supported blockchains. In the reference implementation, we use CryptoCompare6, an external service exposing interfaces for requesting these market prices.\n\nFootnote 6: [https://min-api.cryptocompare.com/](https://min-api.cryptocompare.com/)\n\n#### Iii-C4 Inter-block time (M4)\n\nThe rolling average of the time between two blocks is computed by applying the formula shown in (4), where \\(n\\) denotes the number of blocks mined during the last 24 hours. The presented formula is applied for all supported blockchains.\n\n\\[\\frac{24\\cdot 3600}{n} \\tag{4}\\]\n\n#### Iii-C5 Transaction throughput (M5)\n\nAs shown in (5), the transaction throughput (rolling average) is computed by summing up the number of transactions stored in each block that has been mined during the last 24 hours, and by dividing this sum by \\(24\\cdot 3600\\). \\(n\\) denotes the total number of mined blocks during the last 24 hours and txcount\\({}_{i}\\) represents the number of transactions of block \\(i\\).\n\n\\[\\frac{\\sum_{i=1}^{n}\\text{txcount}_{i}}{24\\cdot 3600} \\tag{5}\\]\n\n#### Iii-C6 Degree of decentralization (M6)\n\nWe calculate the distribution of a network's hash power in two different ways due to fundamental differences between Bitcoin- and Ethereum-based blockchains. In Bitcoin, it is sufficient to count the number of blocks for each miner that has mined at least one block during the last 24 hours and, in a further step, to divide each miner's block counter by the overall number of blocks. For Ethereum-based blockchains, in addition to regular blocks, also uncle blocks are taken into account, since miners also spend computational power for integrating these blocks.\n\n#### Iii-C7 Network hash rate (M7)\n\nFor Bitcoin, the average number of hashes per second the network has performed in the last 24 hours is computed as shown in (6).\n\n\\[\\frac{n}{144}\\cdot\\frac{D\\cdot 2^{32}}{600} \\tag{6}\\]\n\nHere, \\(n\\) denotes the number of blocks that have been mined during the last 24 hours. \\(D\\cdot 2^{32}\\) specifies the expected number of hashes that have to be calculated to find a block with difficulty \\(D\\)[6]. In Bitcoin, \\(D\\) is set such that, on average, a new block is mined every ten minutes (600 seconds) [6]. Thus, \\(144\\) is the number of blocks are expected to get mined within 24 hours. Since a new block is anticipated to get mined every ten minutes, \\(D\\cdot 2^{32}\\) hashes are expected to be computed in 600 seconds, yielding an average network hash rate of \\(\\frac{D\\cdot 2^{32}}{600}\\) hashes per second [6]. The term \\(\\frac{n}{144}\\) adjusts this hash rate in case less than or more than \\(144\\) blocks have been mined. We calculate the hash rate of Ethereum-based networks by summing up the _difficulty_ field of each block and each uncle block mined during the last 24 hours and by dividing this sum by the number of seconds equal to 24 hours.\n\n## IV Evaluation\n\nIn order to evaluate the proposed framework, we investigate its benefit in terms of cost, performance, and trust by using exemplary scenarios. For this, we analyze the framework's reaction to varying blockchain properties as well as its handling of changing user demands.\n\nSince the framework relies on external network nodes, we set up a Bitcore7 node for Bitcoin, two Parity8 nodes for Ethereum and Ethereum Classic, and we use gexp9 to run an Expanse network node. Each deployed network node uses the respective main chain. For our experiments, we deploy each network node on a separate virtual machine (1 vCPU, 4 GB RAM) hosted on the Google Cloud Platform. The framework itself is executed on a MacBook Pro (late 2013, 2.4 GHz Intel Core i5, 8 GB 1600 MHz DDR3, Intel Iris 1536 MB, 256 GB SSD, macOS 10.13.6, Oracle JDK 10).\n\nFootnote 7: [https://bitcore.io/](https://bitcore.io/)\n\nFootnote 8: [https://www.parity.io/ethereum/](https://www.parity.io/ethereum/)\n\nFootnote 9: [http://expanse-org.github.io/go-expanse/](http://expanse-org.github.io/go-expanse/)\n\nIn the following, four evaluation scenarios are presented. Scenario 1 analyzes exemplarily the framework's reaction to varying blockchain metrics by emulating a decreasing hash rate. For this experiment, we select Expanse as the currently used blockchain. The experiment can also be performed with other blockchains such as Bitcoin, Ethereum, or Ethereum Classic without any restrictions. To customize the framework's internal logic, we provide an implementation of the MVF that returns the 9-tuple (true, true, true, true, true, false, true, false) in case the network hash rate drops below 180 GH/s, otherwise (true, true, true, true, true, true, true). Thus, if the network hash rate drops below 180 GH/s, M7 and the corresponding blockchain are invalid (denoted by the boolean value _false_). Furthermore, we set each metric's weight to 1 and provide for each metric a score assignment function that always returns a score value of 1, since for the conduction of this experiment it is not relevant which blockchain is selected by the framework after the detection of a decreasing hash rate. Starting at a hash rate of 200 GH/s, we emulate a decreasing hash rate reduced by 5 GH/s every 5 seconds. As shown in Listing 1, once the hash rate is Listing 1. Log extraction that shows the reaction of the framework in case the network hash rate of Expense decreases rapidly.\n\n13:52:25,189 - Switchover suggestion: Expense\n\n13:52:26,983 - Expense network hash rate: 195.0 GH/s\n\n13:52:31,984 - Expense network hash rate: 190.0 GH/s\n\n13:52:37,806 - Expense network hash rate: 185.0 GH/s\n\n13:52:42,807 - Expense network hash rate: 180.0 GH/s\n\n13:52:46,844 - Expense network hash rate: 175.0 GH/s\n\n13:52:46,845 - Hash rate (175.0 GH/s) violated\n\n13:52:46,847 - Switchover suggestion: Ethereum Classic\n\nunder 180 GH/s, the framework suggests to switch to another blockchain (here: Ethereum Classic).\n\nFor Scenarios 2-4, we assume that the framework is used in a service-oriented architecture that is made up of different services adopted and operated by several independent and possibly competing business partners. In order to monitor the adherence to service-level agreements (SLAs), services publish relevant information to a blockchain. We conduct these scenarios based on metric values measured between 25.09.2018 and 17.10.2018.\n\nScenario 2 analyzes the benefit of the framework's selection mechanism in terms of cost, performance, and trust. We assume the involved business partners want to use a blockchain that is cheap, fast and has a high level of trust. The framework is configured with the weighted ranking settings outlined in Table V. Since we assume a demand for very cheap and fast write operations, and a high level of trust, we set the weights for M1, M3, M4, M5, M6, M7 and M8 to five (highest importance). Metric M2 can be ignored (i.e., we set the corresponding weight to zero), since read operations are free and our reference implementation does not make use of smart contracts. In order to benefit from an accurate selection, we define the score assignments as granularly as possible, e.g., by considering very low cost in the score assignment.\n\nAccording to their popularity and miner activity, we assume a reputation of 10 for Bitcoin and Ethereum, a reputation of 9 for Ethereum Classic and a reputation of 5 for Expense. In order to emulate an execution on 25.09.2018, the framework is fed with the values measured on that day. According to the weighted ranking outlined in Table VI (metrics with a weight of zero are omitted), Ethereum is the most beneficial blockchain. The key points of this selection are as follows:\n\n* By using Ethereum, the cost of writing one KB of data is approximately 24 times lower than the cost of writing the same amount of data into the Bitcoin blockchain. The cost of writing data into the Ethereum Classic and Expense blockchains is about 154 times and about 96 times lower, respectively, than the cost when using Ethereum.\n* Compared to Bitcoin with a price of 6,394.25 USD, the exchange rate of Ethereum is about 30 times lower. The price in USD for one Ether is approximately 20 times greater than the price for one token on Ethereum Classic. With an exchange rate of 0.36 USD, Expense is the cheapest token.\n* Ethereum features an inter-block time about 38 times shorter than Bitcoin and about three times shorter than Expense. Ethereum Classic has almost the same inter-block time as Ethereum.\n* With a throughput of about 5.74 transactions per second (tps), Ethereum processes by far the greatest number of transactions, whereas Bitcoin has a rate of 2.57 tps, Ethereum Classic a rate of 0.47 tps, and Expense handles only 0.06 tps.\n* The network hash rate of Ethereum is about 16 times greater than the rate of Ethereum Classic and about 1,275 times greater than the hash rate of Expense. The Bitcoin network mines with a hash rate approximately 217,012 times greater than that of Ethereum.\n* The biggest Ethereum miner controls about 24% of the network's hash power, whereas the biggest Ethereum Classic and Expense miners control about 42% and 48%, respectively. The biggest miner of the Bitcoin network controls about 20%.\n\nScenario 3 investigates the framework's handling of changing user demands indicated by adjusted metric weights. We assume that engineers of one business partner plan to run data-intensive tests on their adopted services. Since a large amount of data is scheduled to be written into the blockchain, low cost is preferred. Furthermore, we assume that the reputation can be neglected for the test execution. This scenario is conducted based on the weighted ranking settings outlined in Table V. In order to incorporate the changed demands in the weighted ranking system, we set the weights for M6, M7, and M8 to 0. Furthermore, we assume that these changes take effect on 07.10.2018. Table VII shows the weighted ranking based on the changed settings and the metric values gathered on 07.10.2018 (metrics with a weight of zero are omitted). Since Ethereum Classic has the highest benefit, it is selected as the most beneficial chain. Due to the lack of significant variations of blockchain metrics between 25.09.2018 and 07.10.2018, Ethereum has been the most beneficial chain for the entire date range. By switching from Ethereum to Ethereum Classic, the cost of writing one KB of data has been decreased by a factor of 42. Furthermore, Ethereum Classic has almost the same inter-block time as Ethereum (approximately 14 seconds). Since Expanse has an inter-block time of 44 seconds, Ethereum Classic has been preferred, as shown in Table VII.\n\nThe intention of Scenario 4 is to show the effects of changing user requirements indicated by adjusted score assignments. For this, we assume that an inter-block time between 30 and 60 seconds is completely sufficient for conducting further service tests. Moreover, the transaction throughput becomes less important for further test executions. Due to the large amount of test data that is written to the blockchain, low cost have still high priority. This scenario is conducted based on the weighted ranking settings of Scenario 3. To reflect the changed user requirements in the weighted ranking settings, the score assignment for M4 is changed to: \\([0;60)\\to 4\\), \\([60;120)\\to 3\\), \\([120;180)\\to 2\\), \\([180;240)\\to 1\\), \\([240;\\infty)\\to 0\\). Since the transaction throughput has a lower priority, the weight for M5 is set to 3. We further assume that the weighted ranking settings are changed on 17.10.2018. Based on the metric values measured on 17.10.2018 and the changed settings, the framework selects Expanse as the most beneficial chain, since it has the highest score (as shown in Table VIII). Due to the lack of significant variations of blockchain metrics between 07.10.2018 and 17.10.2018, Ethereum Classic has been the most beneficial chain for the entire date range. A switchover from Ethereum Classic to Expanse enables a cost reduction by a factor of approximately 45.\n\nSummarizing our evaluation, we see that the framework can select the most appropriate blockchain based on user preferences. Furthermore, it is able to react to volatile blockchain properties and it can handle changing user demands. These features allow users to benefit from low cost, better performance, and a higher level of trust.\n\n## V Related Work\n\nDespite the fact that blockchain technologies have gained much research momentum in recent years, to the best of our knowledge, there are not too many approaches aiming at providing the means to switch between different blockchains.\n\nOne of the earliest contributions in the field of blockchain interoperability is the atomic cross-chain protocol (ACCS) proposed by TierNolan in 2013 [5]. This protocol enables users of different cryptocurrencies to swap their assets in an atomic fashion. Further contributions focusing on the transfer of assets are The Atomic Swap Technology (TAST)10, Tesseract [4], BarterDEX11, Metronome12, and the Republic Protocol13. Furthermore, sidechains aim to provide interoperability between two blockchains by locking assets on the source chain and creating them on the target blockchain. Transferred assets can only be used on one blockchain at the same time. Cryptographic proofs ensure that assets have been locked on the source chain, before new ones can be created on the target chain [10].\n\nFootnote 10: [https://pantos.io](https://pantos.io)\n\nFootnote 11: [https://docs.komododplatform.com/home-whitepaper.html](https://docs.komododplatform.com/home-whitepaper.html)\n\nFootnote 12: [https://www.metronome.io/](https://www.metronome.io/)\n\nFootnote 13: [https://renproject.io/](https://renproject.io/)\n\nFootnote 14: [https://polikadot.network/](https://polikadot.network/)\n\nFootnote 15: [https://cosmos.network/](https://cosmos.network/)\n\nFootnote 16: [https://cosmos.network/](https://cosmos.network/)\n\nFootnote 17: [http://www.blockcollider.org/](http://www.blockcollider.org/)\n\nBeyond the trading of assets, Polkadot14, Cosmos15, and Block Collider16 aim to integrate blockchains in a more general way, e.g., by enabling communication between smart contracts located on different blockchains.\n\nFootnote 14: [https://www.bitecail.com/](https://www.bitecail.com/)\n\nA further remarkable contribution in the field of blockchain interoperability is BTCRelay17, a smart contract running on Ethereum that verifies Bitcoin transactions. The contract actsas bridge between the Bitcoin blockchain and Ethereum smart contracts, enabling users to pay with Bitcoin for using Ethereum DAPPs.\n\nTo the best of our knowledge, there are no contributions in the field of selection of blockchains during runtime. The discussed approaches do not integrate a mechanism for selecting the most beneficial blockchain based on user-defined requirements. Furthermore, the presented approaches do not provide a functionality for switching back and forth between several blockchains and for migrating already existing data.\n\n## VI Conclusion\n\nIn this paper, we have presented a framework capable of switching back and forth between blockchains at runtime. The proposed framework monitors several blockchains, calculates each blockchain's benefits according to user-defined settings, and determines the most beneficial one. Furthermore, the framework is able to react to variations of blockchain metrics and it can handle changing user demands. We have presented the framework's design in detail, using a reference implementation in Java.\n\nOur evaluation shows that switching to another blockchain can save cost and enable users to benefit from better performance and a higher level of trust. The modular design of the framework allows future researchers to add support for further blockchains by providing additional proxy implementations.\n\nAs described in Section III, the framework is able to copy data from the currently used blockchain to the destination chain during a switchover. However, the proposed framework does not enable the migration of smart contracts between blockchains, allowing the automatic deployment of required smart contracts on the destination chain. Such a feature may be relevant if data records are managed by smart contracts rather than stored in a transaction's data field and will therefore be investigated in our future work. Furthermore, the reference implementation stores data records published to Ethereum, Ethereum Classic, and Expanse in a transaction's data field rather than in a smart contract's storage, leading to slower access times. A possible solution we want to investigate is to improve the time needed for searching data by a tracking of transactions that hold data records.\n\n## References\n\n* [1]M. Atzori (2017) Blockchain technology and decentralized governance: is the state still necessary?. In Journal of Governance and Regulation, Vol. 6. Cited by: SSI.\n* [2]E. Bainoungiisha, A. L. Carreton, T. v. Cutsem, S. Mostinckx, and W. d. Meuter (2013) A Survey on Reactive Programming. In ACM Comput. Surv., pp. 54:4 (English). External Links: Document Cited by: SSI.\n* [3]B. Bambrough (2019) Senior Banker Burns Bitcoin Has A 'Basic' Problem. Note: [http://www.forbes.com/sites/billy/bambrough/2019/01/22/senior-banker-warms-bitcoin-has-a-basic-problemAccessed](http://www.forbes.com/sites/billy/bambrough/2019/01/22/senior-banker-warms-bitcoin-has-a-basic-problemAccessed): 13.02.2019 Cited by: SSI.\n* [4]I. Bentov, Y. Ji, F. Zhang, Y. Li, X. Zhao, L. Breidenbach, P. Daian, and A. Juels (2017) Tesseract: real-time cryptocurency exchange using Trusted Hardware.. In IACR Cryptology ePrint Archive, Vol., pp.. External Links: Document Cited by: SSI.\n* [5]S. Dziembowski (2015) Introduction to Cryptocurrencies. In 22nd ACM SIGSAC Conference on Computer and Communications Security, pp. 1700-1701. Cited by: SSI.\n* [6]S. Dziembowski (2015) Introduction to Cryptocurrencies. In 20th ACM SIGSAC Conference on Computer and Communications Security, pp. 1700-1701. Cited by: SSI.\n* [7]J. Herrera-Jonneomarti and C. Perez-Sola (2016) Privacy in Bitcoin Transactions: New Challenges from Blockchain Scalability Solutions. In Modeling Decisions for Artificial Intelligence, pp. 26-44. Cited by: SSI.\n* [8]I.-C. Lin and T. Liao (2017) A Survey of Blockchain Security Issues and Challenges. In International Journal of Network Security, pp. 653-659. Cited by: SSI.\n* [9]L. M. Maruping, V. Venkatesh, and R. Agarwal (2009) A Control Theory Perspective on Agile Methodology Use and Changing User Requirements. In Information Systems Research, pp. 377-399. Cited by: SSI.\n* Challenges and Opportunities. In ACM Transactions on Management Information Systems, pp.. External Links: Document Cited by: SSI.\n* [11]D. Mingxiao, M. Xiaofeng, Z. Zhe, W. Xiangwei, and C. Qijun (2017) A review on consensus algorithm of blockchain. In IEEE International Conference on Systems, Man, and Cybernetics, pp. 2567-2572. Cited by: SSI.\n* [12]S. Nakamoto (2008) Bitcoin: a peer-to-peer electronic cash system. Note: [http://bitcoin.org/bitcoin.pdfAccessed](http://bitcoin.org/bitcoin.pdfAccessed): 06.02.2019 Cited by: SSI.\n* [13]A. Narayanan, J. Bonneau, E. Felten, A. Miller, and S. Goldfeder (2016) Bitcoin and Cryptocurrency Technologies: a comprehensive introduction. Princeton University Press. Cited by: SSI.\n* [14]S. Nakamoto (2008) Bitcoin: a peer-to-peer electronic cash system. Note: [http://bitcoin.org/bitcoin.pdfAccessed](http://bitcoin.org/bitcoin.pdfAccessed): 06.02.2019 Cited by: SSI.\n* [15]A. Narayanan, J. Bonneau, E. Felten, A. Miller, and S. Goldfeder (2016) Bitcoin and Cryptocurrency Technologies: a comprehensive introduction. Princeton University Press. Cited by: SSI.\n* [16]S. Nakamoto (2008) Bitcoin: a peer-to-peer electronic cash system. Note: [http://bitcoin.org/bitcoin.pdfAccessed](http://bitcoin.org/bitcoin.pdfAccessed): 06.02.2019 Cited by: SSI.\n* [17]S. Nakamoto (2008) Bitcoin: a peer-to-peer electronic cash system. Note: [http://bitcoin.org/bitcoin.pdfAccessed](http://bitcoin.org/bitcoin.pdfAccessed): 06.02.2019 Cited by: SSI.\n* [18]A. Sward, I. Veena, and F. Stonedahl (2018) Data Insertion in Bitcoin's Blockchain'. In Ledger 3, pp. 1-23. Cited by: SSI.\n* [19]F. Tschorsch and B. Scheuermann (2016) Bitcoin and Beyond: a Technical Survey on Decentralized Digital Currencies. In IEEE Communications Surveys Tutorials, pp. 2084-2123. Cited by: SSI.\n* [20]G. Wood (2014) Ethereum: a secure decentralised generalised transaction ledger. Note: [https://ethereum.github.io/yellowpaper/paper.pdfAccessed](https://ethereum.github.io/yellowpaper/paper.pdfAccessed): 19.02.2019 Cited by: SSI.\n* [21]X. Xu, C. Pautasso, L. Zhu, V. Gramoli, A. Ponomarev, A. B. Tran, and S. Chen (2016) The Blockchain as a Software Connector.. In 13th Working IEEE/IFIP Conference on Software Architecture, pp. 182-191. Cited by: SSI.\n* [22]X. Xu, I. Weber, M. Staples, L. Zhu, J. Bosch, L. Bass, C. Pautasso, and P. Rimba (2017) A taxonomy of blockchain-based systems for architecture design.. In IEEE International Conference on Software Architecture, pp. 243-252. Cited by: SSI.\n* [23]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [24]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [25]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [26]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [27]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [28]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [29]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [30]A. Narayanan, J. Bonneau, E. Felten, A. Miller, and S. Goldfeder (2016) Bitcoin and Cryptocurrency Technologies: a comprehensive introduction. Princeton University Press. Cited by: SSI.\n* [31]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [32]A. Narayanan, J. Bonneau, E. Felten, A. Miller, and S. Goldfeder (2016) Bitcoin and Cryptocurrency Technologies: a comprehensive introduction. Princeton University Press. Cited by: SSI.\n* [33]A. Zohar (2015) Bitcoin: a peer-to-peer electronic cash system. Note: [http://bitcoin.org/bitcoin.pdfAccessed](http://bitcoin.org/bitcoin.pdfAccessed): 06.02.2019 Cited by: SSI.\n* [34]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [35]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [36]A. Narayanan, J. Bonneau, E. Felten, A. Miller, and S. Goldfeder (2016) Bitcoin and Cryptocurrency Technologies: a comprehensive introduction. Princeton University Press. Cited by: SSI.\n* [37]A. Zohar (2015) Bitcoin: a peer-to-peer electronic cash system. Note: [http://bitcoin.org/bitcoin.pdfAccessed](http://bitcoin.org/bitcoin.pdfAccessed): 06.02.2019 Cited by: SSI.\n* [38]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A.\n* [39]A. Zohar (2015) Bitcoin: under the hood. In Communications of the ACM 58.9, pp. 104-113. Cited by: SSIV-A."

Title: A Decision Framework for Blockchain Adoption
Transcription: "# A Decision Framework for Blockchain Adoption\n\n Vittorio Capocasale\n\nvittorio.capocasale@polito.it\n\n&Guido Perboli\n\nguido.perboli@polito.it\n\n###### Abstract\n\nBlockchain and distributed ledger technologies are gaining the interest of the academy, companies, and institutions. Nonetheless, the path toward blockchain adoption is not straightforward, as blockchain is a complex technology that requires revisiting the standard way of addressing problems and tackling them from a decentralized perspective. Thus, decision-makers adopt blockchain technology for the wrong reasons or prefer it to more suitable ones. This work presents a decision framework for blockchain adoption to help decision-makers decide whether blockchain is applicable, valuable, and preferable to other technologies. In particular, The decision framework is composed of a small set of questions that can be answered from a managerial standpoint and that do not require a deep technical knowledge of blockchain-related topics.\n\nblockchain adoption blockchain suitability decision making decision flowchart when to use.\n\n## 1 Introduction\n\nAt present, companies are undergoing radical transformations based on information sharing and digitization, known collectively as the Industry 4.0 revolution [20]. Such a revolution is driven by the recent technological advancements in physical monitoring, data elaboration, virtualization, and automation technologies [1, 17, 13]. On one side, data acquisition and storage is becoming cheaper and more accurate [14]; on the other, peer-to-peer technologies such as blockchain[15] and the Interplanetary File System [14] are transforming existing business paradigms [21].\n\nBlockchain creates trust among non-trusting parties without relying on intermediaries. A blockchain is composed of a network of nodes managing a shared and distributed database: tampering attempts are prevented by replicating the state of the database on each node. Smart contracts are independently executed by each node and are used to alter the state of the database. Thus, by leveraging the tamper-resiliency of the blockchain, smart contracts could enhance the fairness of critical processes, protect valuable resources, and automate business operations. Given the relevance of such topics [1, 16], smart contract-based alternatives to existing services are surging in multiple sectors, including finance [24], insurance [11], logistics[22], energy [23, 24], and more.\n\nNonetheless, blockchain is a complex technology that introduces many compromises and issues at all technical, legal, and economic levels. Thus, decision-makers often lack the necessary knowledge to make informed decisions on blockchain adoption, and misconceptions are widespread in the field [18]. Unsurprisingly, blockchain is often chosen for the wrong reasons or is preferred to better technologies [1, 15, 12]. Consequently, many blockchain projects do not last long or fail to fulfill the original goals [19]. In this context, it is essential to develop standards and tools to simplify the managerial decision process on blockchain adoption.\n\nWe contribute to the current body of knowledge by making the following contributions:\n\n* we propose a decision flowchart for blockchain adoption that helps decision-makers understand when blockchain is applicable, valuable, and preferable to other solutions. The framework does not requireany deep technical knowledge of blockchain technology and can be effectively employed by decision-makers with different backgrounds;\n* we discuss the rationale behind each of the decision drivers of our framework to shed some light on some of the hidden caveats of blockchain technology, as they are not sufficiently discussed in the existing literature.\n\nThe remaining part of this study is structured as follows: Section 2 briefly describes the blockchain technology and presents a summary of the related works; Section 3 describes the blockchain adoption decision framework; Section 4 concludes the study.\n\n## 2 Background\n\nThis section summarizes the main concepts related to blockchain. Moreover, this section includes a summary of the related works.\n\n### Blockchain\n\nBlockchain is a technology that enables data sharing among non-trusting parties. Blockchain allows for solving trust issues without leveraging trusted third parties. Blockchain is composed of a network of peers that share a common database. The shared database is a ledger, as data can only be appended to it. Each peer manages its copy of the ledger independently from the others. Thus, peers can maliciously alter their copy, but not the global state of the ledger, which is decided based on what is stored in the majority of the copies (Zheng et al., 2018; Luo et al., 2022). We assume a uniform distribution of voting power among the peers to simplify the discussion. However, when we refer to the majority of the peers, we mean the majority of the voting power.\n\nBlockchains can be categorized according to their governance model as follows (Buterin, 2015; Lin and Liao, 2017).\n\n* **Public**--Any peer can join the blockchain system and gain voting power. Public blockchains solve trust issues among their participants, as peers can autonomously validate transactions.\n* **Consortium**--The blockchain system is managed by some well-identified peers who can set the rules for interacting with the ledger and gaining voting power. Consortium blockchains solve trust issues among the consortium members.\n* **Fully private**--A single peer manages the blockchain system. Thus, the system is not decentralized.\n\n### Problem Statement\n\nMany real-world systems are intrinsically decentralized. For example, supply chains are composed of numerous companies, and the behavior of each one affects the performance of the whole supply chain. Thus, it is logical to manage supply chains in a decentralized way by allowing each company to vote on the best strategy to improve the performance of the whole supply chain.\n\nThe introduction of blockchain technologies has created the opportunity to decentralize the management of data. Thus, blockchain has gained adoption in all those intrinsically decentralized systems that previously relied on trusted third parties. Nonetheless, blockchain is a complex technology and introduces many hidden compromises and issues. Moreover, decision-makers often lack the necessary technical knowledge to make informed decisions on blockchain adoption. Thus, blockchain is often adopted for the wrong reasons or is preferred to better technologies (Belotti et al., 2019; Halaburda, 2018; Carson et al., 2018; Labazova et al., 2019).\n\nTo solve this problem, we created a framework that helps decision-makers understand when blockchain is applicable, valuable, and preferable to other solutions. The framework does not require a deep technical knowledge of blockchain technology and can be effectively employed by decision-makers with different backgrounds.\n\n### Related Works\n\nAccording to Ref. (Almeshal and Alhogail, 2021), blockchain suitability frameworks can be divided into three categories: decision models, conceptual frameworks, and decision flowcharts.\n\nDecision models use mathematical models to decide on blockchain adoption. For example, BAF is a framework for determining the ideal blockchain solution based on a weighted evaluation of detailed user requirements (Gourisetti et al., 2020).\n\nConceptual frameworks identify the factors to consider in adopting blockchain technologies based on the practical experience of researchers. For example, ten technology-driven factors are considered by the framework proposed in Ref. [Scriber, 2018]. Other authors included non-technological factors (e.g., environmental considerations, such as regulations) [Clobessy et al., 2020, Labazova, 2019]. Open-ended questions that should be addressed when considering blockchain adoption are proposed in Ref. [Angelis and Ribeiro da Silva, 2019].\n\nDecision flowcharts are based on graphs where nodes represent closed-ended questions and edges represent the related answers. Users are led to a decision by the path dictated by the answers they pick. Many authors adopted such a strategy in the literature. A study proposed a multi-step framework to decide on blockchain adoption and the type of blockchain needed [Peck, 2017]. Others deepened the discussion by providing some guidelines on implementing working solutions [Belotti et al., 2019], considering the security threats of using blockchain [Puthal et al., 2021], and analyzing real-world use cases [Hassija et al., 2021, Wust and Gervais, 2018, Gatteschi et al., 2018b]. A framework explicitly designed for managers is proposed in Ref. [Challener et al., 2019]. Multiple frameworks were analyzed and condensed into a single one in Ref. [Koens and Poll, 2018]. However, we do not agree with some of the decision drivers proposed in all such works. For example, requiring the presence of multiple writers is unnecessary: a group of entities may need to record in a tamper-proof way what is written by a third one. In such a case, a blockchain could be a viable solution, as the multiple record keeps could prevent the writer from altering past data. Thus, blockchain adoption should be driven by the presence of multiple decision makers (the keepers can decide which data are alterable), not multiple writers.\n\nRef. [Lo et al., 2018] describes a framework composed of seven main questions and four subquestions. However, a good technical understanding of the technology is necessary to answer some of the proposed questions. A ten-step decision framework is proposed in Ref. [Pedersen et al., 2019]. The framework is very useful as it considers many aspects that are ignored in similar works.\n\nFinally, some authors proposed decision frameworks for blockchain adoption that are tailored to specific use cases (e.g., logistics [Ar et al., 2020, Ganeriwalla et al., 2018, Hribernik et al., 2020] and the construction industry [Hunhevicz and Hall, 2020]).\n\n## 3 Blockchain Adoption Decision Framework\n\nThis section describes our decision framework for blockchain adoption, which is graphically summarized in Fig. 1. Before introducing our approach, we want to make a few important remarks.\n\n* Blockchain is meaningful when decentralized governance is required. Even though the locution distributed ledger technology has gained adoption, decentralization is what matters, not distribution [Come-from-Beyond, 2020].\n* Blockchain is inefficient and should be used only when necessary. Blockchain is the only technology allowing for managing a database in a decentralized fashion. However, if the database can be managed by a single entity, other technological solutions are better [Challener et al., 2019].\n\nAs a consequence of the previous points, fully private blockchains have little to no use, in our opinion. They can be employed to prevent accidental data modifications, but non-distributed ledgers are more efficient (e.g., ImmuDB [Paik\n\n\

Tuple 45:
Cleaned Title: logic blockchain update
Cleaned Transcription: logic blockchain updatesnnkai brunnlernnbern university applied science switzerland kaibruennlerbfhchnndandolo flumininnzhaw school engineering switzerland dandolofluminizhawchnnthomas studernnuniversity bern switzerland tstuderinfunibechnn abstractnnblockchains distributed data structure used achieve consensus system cryptocurrencies like bitcoin smart contract like ethereum although blockchains gained lot popularity recently logicbased model blockchains available introduce bcl dynamic logic reason blockchain update show bcl sound complete respect simple blockchain modelnnkeywordsblockchain modal logic dynamic epistemic logicnn introductionnnbitcoin cryptocurrency us peertopeer technology support direct usertouser transaction without intermediary bank credit card company order prevent double spending common issue system without central control bitcoin maintains complete public record transaction node network ledger called blockchainnnthe blockchain essentially growing sequence block contain approved transaction cryptographic hash previous block sequence blockchain stored locally node update propagated entire network node receive transaction first verify validity ie whether compatible preceeding transaction valid added blockchain sent node blockchain technology general solution byzantine general problem used financial transaction also many application like eg smart contract nnherlihy moir propose develop logic accountability design verify blockchain system particular discus blockchain scenario test logic authorization ii logic concurrency iii logic incentivesnnin present paper interested accountability study blockchains perspective dynamic epistemic logic given state blockchain entail knowledge transaction taken place ask knowledge change new block received might added blockchain develop dynamic logic bcl semantics based blockchain model update operator bcl interpreted receiving new block aim paper investigate dynamic blockchain updatesnnthe deductive system bcl includes reduction axiom make possible establish completeness reduction updatefree case however since blockchain update performed certain consistency condition satisfied use conditional reduction axiom similar one developed steiner model consistency preserving update moreover unlike traditional public announcement blockchain update lead inconsistent state ie update total like nnwe base bcl existing blockchain implementation use simple model first blockchain sequence propositional formula maintain list provisional update block consist two part sequence number called index block propositional formula block received following case distinction performed index block l current length blockchainnn ileq l block ignoredn il formula block consistent blockchain added blockchain otherwise block ignored blockchain extended procedure performed also block stored list provisional updatesn il block added list provisional updatesnnalthough simple model feature two important logical property blockchains consistency must preserved blocksmay received wrong order case stored separately missing block receivednnthe main contribution paper point view dynamic epistemic logic maintain list provisional update mean support update immediate effect may lead belief change later certain update performed bcl first dynamic epistemic logic feature provisional update kindnnthe paper organized follows next section introduces blockchain model language bcl semantics section introduce deductive system bcl establish soundness bcl section section show normal form theorem bcl used section prove completeness bcl final section study key principle epistemic dynamic blockchain logic discus future worknn simple dynamic epistemic blockchain logicnnthe set natural number denoted mathbbnldots set positive natural number denoted mathbbnldots use omega least ordinal omegan ninmathbbnnnlet sigmalanglesigmaldotssigmanrangle finite sequence define length mathsflensigman infinite sequence sigmalanglesigmasigmaldotsrangle set mathsflensigmaomega finite infinite sequence sigmalanglesigmasigmaldotssigmaildotsrangle set sigmaisigmai empty sequence denoted langlerangle set mathsflenlanglerangle append x finite sequence sigmalanglesigmaldotssigmanrangle symbol set sigmacirc xlanglesigmaldotssigmanxrangle also need set component sequence sigma definennmathsfsetsigmax textthere xsigmainnin particular mathsfsetlanglerangleemptyset moreover use shorthand xinsigma xinmathsfsetsigmannwe start countable set atomic proposition mathcalapppldots set formula mathcallmathsfcl classical propositional logic given following grammarnnabot p ato aquadwhere pinmathcalapnnin order introduce language mathcallmathsfb blockchain logic need another countable set special atomic proposition mathcalaqqqldots disjoint mathcalap use special proposition later keep track length blockchain formula mathcallmathsfb given grammarnnfbot p q fto f box iafquadnnwhere pinmathcalap qinmathcalaq ainmathcallmathsfcl iinmathbbn operator form ia called blockchain update simply updatesnnnote mathcallmathsfb express higherorder knowledge ie express knowledge propositional fact knowledge knowledge factsnnfor language paper define boolean connective eg negation conjunction disjunction usual moreover assume unary connective bind stronger binary onesnnfor mathcallmathsfcl use semantics classical propositional logic valuationmathsfv subset mathcalap define truth mathcallmathsfclformula mathsfv symbol mathsfvmodels usual set gamma mathcallmathsfclformulas write mathsfvmodelsgamma mathsfvmodels aingamma set gamma satisfiable valuation mathsfv mathsfvmodelsgamma say gammaentailsa symbol gammamodels valuation mathsfv havennmathsfvmodelsgammaquadtextimpliesquadmathsfvmodels annnow introduce blockchain semantics mathcallmathsfbnndefinition block pair ia mathcallmathsfclformula iinmathbbn call index formula block ia define function mathsfind mathsffml mathsfindiai mathsffmliaanndefinition modelmathsfmmathsfimathsfbcmathsfpumathsfv quadruple wherenn mathsfi set mathcallmathsfclformulasn mathsfbc sequence mathcallmathsfclformulasn mathsfpu finite sequence blocksn mathsfv valuation ie mathsfvsubseteqmathcalapsuch thatnnmathsficupmathsfsetmathsfbcmbox satisfiable tagnnandnnmboxfor block iainmathsfpumbox imathsflenmathsfbc tagnnthe component model mathsfimathsfbcmathsfpumathsfv following meaningnn mathsfi model initial background knowledgen mathsfbc blockchainn mathsfpu stand provisional update sequence mathsfpu consists block announced could yet added blockchain index high maybe added mathsfbc later ie missing block addedn mathsfv state atomic proposition truennwe need auxiliary definition order precisely describe blockchain dynamicsnndefinition n let mathsfpu finite sequence block let mathsffindimathsfpu least jinmathbbn mathcallmathsfclformula iamathsfpujn let sigmalanglesigmaldotssigmaisigmaisigmaildotsrangle sequence set mathsfremoveisigmalanglesigmaldotssigmaisigmai ldotsranglen given set mathcallmathsfclformulas mathsfi sequence mathcallmathsfclformulas mathsfbc finite sequence block mathsfpu chain completion completemathsfimathsfbcmathsfpu computed according algorithm let u comment chain completion procedure number refer line algorithm nn n index block must contain could added blockchain mathsfbcn nainmathsfpu formula mean mathsfpu contains block could added mathsfbcn find next formula b could added mathsfbc remove corresponding block mathsfpun mathsflcupmathsfsetmathsfbccupb satisfiable mean b consistent current belief test guarantee always satisfiedn update blockchain mathsfbc bn remove block mathsfpu whose index le equal current length blockchain mathsfbc blockchain never get shorter block never added removing guarantee always satisfiednnnote mathsfbc mathsfpu satisfy condition definition model chain completion algorithm return mathsfbc mathsfpu unchangednnlemma let set mathcallmathsfclformulas let mathsfbc sequence mathcallmathsfclformulas mathsficupmathsfsetmathsfbc satisfiable let mathsfpu arbitrary finite sequence block mathsfbcprimemathsfpuprimemathsfcompletemathsfi mathsfbcmathsfpu find thatnn mathsficupmathsfsetmathsfbcprime satisfiable andn block iainmathsfpuprime imathsflenmathsfbcprimennproof assumptionnnmathsficupmathsfsetmathsfbctext satisfiable tagnnholds argument passed algorithm moreover condition line guarantee loop invariant loop line ie hold iteration since mathsfbc changed line also hold final result show first claim lemmannit easy see thatnnnmathsflenmathsfbc tagnnalso loop invariant loop line particular hold line thus loop line remove block ia mathsfpu imathsflenmathsfbc moreover loop line terminated loop condition must false mean mathsfpu contain block ia imathsflenmathsfbc finish proof second claim nndefinition let mathsfmmathsfimathsfbcmathsfpumathsfv model ia block updated modelmathsfmia defined mathsfimathsfbcprimemathsfpuprimemathsfv wherennmathsfbcprimemathsfpuprimemathsfcompletemathsfi mathsfbcmathsfpucirciannremark note mathsfmia welldefined lemma know mathsfmia indeed modelnndefinition let mathsfmmathsfimathsfbcmathsfpumathsfv model define truth mathcallmathsfbformula f mathsfm symbol mathsfmnnnn warning truncated repetitionsnmodels f inductively bynn mathsfmnotmodelsbotn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p pinmathsfv pinmathcalapn mathsfmmodels p ifnnn mathsfmmodels qi ileqmathsflenmathsfbc qiinmathcalaqn mathsfmmodels fto g mathsfmnotmodels f mathsfmmodels gn mathsfmmodelsbox mathsficupmathsfsetmathsfbcmodels mathsfmmodelsiaf mathsfmiamodels fnnwe define validity respect class model provisional updatesnndefinition call model mathsfmmathsfimathsfbcmathsfpumathsfv initial mathsfpulanglerangle formula f called valid mathsfmmodels f initial model mathsfmnn deductive system mathsfbclnnin order present axiomatic system blockchain logic need formalize acceptance condition stating whether received block added blockchain need formula mathsfaccia expressing formula consistent current belief current length blockchain thus mathsfaccia hold block ia accepted added blockchain truth definition atomic proposition qiinmathcalaq say qi true blockchain contains least element mean formula qiwedgeneg qi true blockchain contains exactly element lead following definition mathsfaccia iinmathbbnnnmathsfacciabegincasesneg qiwedgenegboxneg atext qiwedgeneg qiwedgenegboxneg atext iendcasesnnas desired find mathsfaccia true chain completion algorithm append formula blockchain see lemma laternnan mathcallmathsfbformula called compliant blockchain update occur correct order formally use following definitionnndefinition mathcallmathsfbformula f compliant occurrence iaoperator f scope jboperator jinnnow define system mathsfbcl epistemic blockchain logic formulated language mathcallmathsfb consists following axiomsnnbegintabularl l pt every instance propositional tautology k boxfto gtobox ftobox g negboxbot q qito qj ij iabottobot iapleftrightarrow p pinmathcalap mathsfacciatoiaqileftrightarrowtop qiinmathcalaq negmathsfacciatoiaqileftrightarrow qi qiinmathcalaq iaqjleftrightarrow qj qjinmathcalaq ineq j ialdotsikakfto gleftrightarrow ialdotsikakftoialdotsikakg mathsfacciatoiabox bleftrightarrowboxato b negmathsfacciatoiabox bleftrightarrowbox b hcldotshkckiajbfleftrightarrow hcldotshkckjaibf ineq j endtabularnnnote may choose k case axiom form iajbfleftrightarrowjaibf ineq jnnin order formulate rule bcl need following notation let hp formula may contain occurrence atomic proposition p hf denote result simultaneously replacing occurrence p hp formula f rule bcl arennmathsfmpfracfgqquad fto gqquadmathsfnecfracabox qquadmathsfsubfracfleftrightarrow ghfleftrightarrow hgnnwhere mathsfsub applied hfleftrightarrow hg compliant formulannremark semantics includes infinite blockchains given model mathsfimathsfbcmathsfpumathsfv sequence bc may infinite length want exclude model add infinitary rulennfracqiquadtextfor iinmathbbnbotnnto bcl rule state qi must false mean bc finite lengthnnsoundnessnnbefore establish soundness mathsfbcl show preparatory lemmasnnlemma let mathsfmmathsfimathsfbclangleranglemathsfv initial model let mathsfimathsfbcprimemathsfpuprimemathsfvmathsfm ia block iann mathsfmmodelsmathsfaccia mathsfbcprimemathsfbccirc particular yield mathsflenmathsfbcprimei j jneq mmodels qjquadtextif ifquadmathsfmiamodels qjn mathsfmnotmodelsmathsfaccia mathsfbcprimemathsfbcnnproof assume mathsfmmodelsmathsfaccia mean mathsflenmathsfbci mathsficupmathsfsetmathsfbccupa satisfiable hence findnnmathsfcompletemathsfimathsfbclangleranglecirciamathsf bccirc alangleranglenntherefore mathsfbcprimemathsfbccirc immediately yieldsnnmathsflenmathsfbcprimeimathsflenmathsfbcnnand j jneq innmmodels qjquadtextif ifquadmathsfmiamodels qjnnassume mathsfmnotmodelsmathsfaccia impliesnnmathsflenmathsfbcneq itext mathsficupmathsfset mathsfbccupatext satisfiablennhence mathsfbcprimemathsfpuprimemathsfcompletemathsfi mathsfbclangleranglecircia find mathsfbcprimemathsfbc nnlemma axiom mathsfbcl validnnproof show case let mathsfmmathsfimathsfbclangleranglemathsfv initial modelnn negboxbot definition model mathsficupmathsfsetmathsfbc satisfiable hence mathsficupmathsfsetmathsfbcnotmodelsbot mean mathsfmnotmodelsboxbotnn qito qj ij assume mathsfmmodels qi mean ileqmathsflenmathsfbc hence ji jleqmathsflenmathsfbc give mathsfmmodels qin mathsfacciatoiaqileftrightarrowtop assume mathsfmmodelsmathsfaccia using lemma get mathsfmiamodels qi thus mathsfmmodelsiaqileftrightarrowtop desiredn negmathsfacciatoiaqileftrightarrow qi assume mathsfmnotmodelsmathsfaccia use lemma obtain mathsfmmodelsiaqileftrightarrow qin iaqjleftrightarrow qj qjinmathcalaq ineq j mathsfmnotmodelsmathsfaccia obtain mathsfmmodelsiaqjleftrightarrow qj previous case mathsfmmodelsmathsfaccia lemma mathsfmmodelsiaqjleftrightarrow qj ineq jn mathsfacciatoiabox bleftrightarrowboxato b assume mathsfmmodelsmathsfaccia let mathsfimathsfbcprimemathsfpuprimemathsfvmathsfm ia lemma get mathsfbcprimemathsfbccirc thus mathsfsetmathsfbcprimemathsfsetmathsfbccupa deduction theorem classical logic find mathsficupmathsfsetmathsfbccupamodelsmathsfclbquad textif ifquadmathsficupmathsfsetmathsfbcmodels mathsfclato b yield mathsfmmodelsiabox bleftrightarrowboxato bn negmathsfacciatoiabox bleftrightarrowbox b assume mathsfmnotmodelsmathsfaccia lemma immediately get mathsfmmodelsiabox bleftrightarrowbox b nnlemma let mathsfmmathsfimathsfbcmathsfpumathsfv arbitrary model let ia block imathsflenmathsfbc mathsfmiamathsfimathsfbcmathsfpucirciamathsfvnnproof letnnmathsfbcprimemathsfpuprimemathsfcompletemathsfi mathsfbcmathsfpucirciannsince mathsfm model condition satisfied therefore find mathsfbcprimemathsfbc mathsfpuprimemathsfpucircia mathsfmiamathsfimathsfbcmathsfpucirciamathsfv nnlemma let mathsfmmathsfimathsfbclangleranglemathsfv initial model let ia block ileqmathsflenmathsfbc mathsfmia initial model toonnproof let mathsfpulangleiarangle andnnmathsfbcprimemathsfpuprimemathsfcompletemathsfi mathsfbcmathsfpuif imathsflenmathsfbc ia removed mathsfpu line algorithm imathsflenmathsfbc ia removed mathsfpu line case find mathsfpuprimelanglerangle mean mathsfmia initial nnlemma let mathsfimathsfbcmathsfpumathsfv model f mathcallmathsfbformula ia occurring f imathsflenmathsfbc thennnmathsfimathsfbcmathsfpumathsfvmodels fquadtextif ifquadmathsfimathsfbclangleranglemathsfvmodels fnnproof induction structure f case distinction outermost connective interesting case fiag since imathsflenmathsfbc assumption find lemma mathsfimathsfbcmathsfpumathsfviamathsfimathsf bcmathsfpucirciamathsfv thus getnnmathsfimathsfbcmathsfpumathsfvmodelsiagquadtextif ifquadmathsfimathsfbcmathsfpucirciamathsfvmodels g tagnnusing ih twice yieldsnnmathsfimathsfbcmathsfpucirciamathsfvmodels gquadtext ifquadmathsfimathsfbclangleiaranglemathsfvmodels g tagnnagain since imathsflenmathsfbc find thatnnmathsfimathsfbclangleiaranglemathsfvmathsfimathsf bclangleranglemathsfviannand thusnnmathsfimathsfbclangleiaranglemathsfvmodels gquadtext ifquadmathsfimathsfbclangleranglemathsfvmodelsiag tagnntaking together yield desired result nnnow show rule mathsfsub preserve validitynnlemma let hpfg mathcallmathsfbformulas hfleftrightarrow hg compliant thatnntextif fleftrightarrow g valid hfleftrightarrow hg valid toonnproof show validity hfleftrightarrow hg induction structure hp distinguish following casesnn h contain p find hhfhg hence hfleftrightarrow hg trivially validn hp hff hgg thus hfleftrightarrow hg valid assumptionn hhprimeto hprimeprime follows immediately ihn hbox hprime ih find hprimefleftrightarrow hprimeg valid since mathcallmathsfb include nested boxoperators hprimep mathcallmathsfclformula since hfleftrightarrow hg formula f g must mathcallmathsfclformulas hence hprimefleftrightarrow hprimeg mathcallmathsfclformula obtain modelsmathsfclhprimefleftrightarrow hprimeg hence mathsfmmodelsbox hprimef mathsfmmodelsbox hprimeg model mathsfm yield hfleftrightarrow hg validn hiahprime let mathsfmmathsfimathsfbclangleranglemathsfv initial model distinguish following case ileqmathsflenmathsfbc lemma find mathsfmia initial model thus ih infer mathsfmiamodels hprimefleftrightarrow hprimeg infer mathsfmmodelsiahprimefleftrightarrowiahprimeg validity mathsfamathsf imathsflenmathsfbc lemma find mathsfmiamathsfimathsfbclangleiaranglemathsfv since hf compliant obtain jb occurring hf jmathsflenmathsfbc hence obtain lemma mathsfmiamodels hprimefquadtextif ifquad mathsfimathsfbclangleranglemathsfvmodels hprimef ih get mathsfimathsfbclangleranglemathsfvmodels hprimefquad textif ifquadmathsfimathsfbclangleranglemathsfv model hprimeg since hg compliant find hprimeg satisfies condition lemma thus use lemma obtain mathsfimathsfbclangleranglemathsfvmodels hprimegquad textif ifquadmathsfmiamodels hprimeg taking together yieldsnnmathsfmmodelsiahprimefleftrightarrowiahprimegnnwe established axiom mathsfbcl valid mathsfsub preserve validity easy see rule mathsfmp mathsfnec also preseve validity soundness mathsfbcl follows immediatelynncorollary formula f havennvdash fquadtextimpliesquad ftext validnnremark reduction axiom hold noninitial model indeed let mathsfmemptysetlangleranglelangletoprangleemptyset find mathsfmpemptysetlangle ptopranglelanglerangleemptyset hence mathsfmpmodels q mathsfmmodelspq also mathsfmnotmodels qnnremark remark also implies block necessitation rule would sound validity f entail validity iaf indeed axiom pqleftrightarrow q valid formula toppqleftrightarrow q valid shown previous remarknnremark rule mathsfsub would preserve validity drop condition conclusion must compliant indeed let u consider valid formula pqleftrightarrow q without compliance condition rule mathsfsub would derive pprimepqleftrightarrowpprimeq valid formulann normal formnnremember formula compliant blockchain update occur correct order section establish normal form theorem simple blockchain logicnndefinition base formula formula one following form include case blockchain updatesnn ialdotsimambot ialdotsimamp pinmathcalapcupmathcalaqn ialdotsimambox bnnformulas normal form given followsnn compliant base formula normal formn f g normal form fto gnnremark immediate consequence definition obtain formula fnnif f normal form f compliantnnthe following theorem state formula provably equivalent formula normal formnntheorem mathcallmathsfbformula f mathcallmathsfbformula g normal form vdash fleftrightarrow gnnproof induction structure f distinguish following casesnn case fbot finmathcalapcupmathcalaq fbox b trivialn fgto h ih gprime hprime normal form vdash gleftrightarrow gprime vdash hleftrightarrow hprime hence fprimegprimeto hprime find vdash fleftrightarrow fprime fprime normal formn fialdotsikakg g form ikakgprime subinduction g distinguish gbot gpinmathcalapcupmathcalaq gbox b case f base formula using axiom find compliant base formula fprime vdash fleftrightarrow fprimen ggprimeto gprimeprime axiom vdash fleftrightarrowialdotsikakgprimetoia ldotsikakgprimeprime moreover ih hprime hprimeprime normal form vdash hprimeleftrightarrowialdotsikakgprime vdash hprimeprimeleftrightarrowialdotsikakg primeprime find hhprimeto hprimeprime normal form vdash fleftrightarrow hnncompletenessnnwe first show mathsfbcl complete modal formula modal language mathcallmathsfm consists updatefree mathcallmathsfbformulas formally mathcallmathsfm given following grammarnnfbot p q fto f box aquadnnwhere pinmathcalap qinmathcalaq ainmathcallmathsfclnnwe need collection mathsfbclbox mathsfbcl axiom given mathcallmathsfm usual satisfaction relation kripke model denoted modelsboxnnlemma mathcallmathsfmformula f havennftext valid quad implies quadvdash fnnproof show contrapositive assume notvdash f since f modal formula kripke model mathsfk world w thatnnmathsfkwnotmodelsboxf tagnnandnnmathsfkwmodelsboxgqquadtextfor gin bclbox tagnnbased kripke model mathsfk construct initial update model mathsfmmathsfimathsfbclangleranglemathsfv follows note mathsfkwmodelsboxqito qj ji let k least iinmathbbn mathsfkwnotmodelsboxqi exists komega otherwise setnn mathsfiainmathcallmathsfcl mathsfkwmodelsbox box mathsfbcbegincaseslangletopldotstoprangletext mathsflenmathsfbcktextif komega langletoptopldotsrangletextif komegaendcasesn mathsfvpinmathcalap kwmodels pnnthis definition mathsfbc mean mathsfbc infinite sequence top komegannfor mathcallmathsfmformula g havennmathsfkwmodelsboxgquadtextif ifquadmathsfmmodels g tagnnwe show induction structure g distinguish following case gpinmathcalap immediate definition mathsfvn gqiinmathcalaq komega mathsfkwmodelsboxqi since mathsflenmathsfbcomega also mathsfmmodels qi komega mathsfkwmodelsboxqi iff ileq kmathsflenmathsfbc iff mathsfmmodels qin gbot trivialn ggto g induction hypothesisn gbox mathsfkwmodelsbox mathsfmmodelsbox definition mathsfl mathsfmmodelsbox mathsflcupmathsfsetmathsfbcmodels definition mathsfbc mathsflmodels mathsfl deductively closed get ainmathsfl yield mathsfkwmodelsbox annby conclude mathsfmnotmodels f desired nnwe establish completeness compliant formula using translation compliant formula provably equivalent updatefree formula start defining mapping h eliminates update operatorsnndefinition mapping mathsfh iafmid finmathcallmathsfm mathcallmathsfm inductively defined bynnmathsfhiabot bot mathsfhiap pquadtextfor pinmathcalap mathsfhiaqi mathsfaccialor qi mathsfhiaqj qjquadtextfor qjinmathcalaqtext ineq j mathsfhiafto g mathsfhiaftomathsfhiag mathsfhiabox b mathsfacciawedgeboxato bveenegmathsfaccia wedgebox bnnthe mapping mathsfh corresponds reduction axiom mathsfbcl thus easy show following lemma induction structure fnnlemma let f mathcallmathsfbformula form iag ginmathcallmathsfm vdash fleftrightarrowmathsfhfnnwe define translation mathsft mathcallmathsfb mathcallmathsfmdefinition mapping mathtttmathcallmathsfbrightarrowmathcallmathsfm inductively defined bynnmathtttbot bot mathtttp pquadtextfor pinmathcalapcupmathcalaq mathtttfto g mathtttfrightarrowmathtttg mathtttbox box mathtttiaf mathsfhiamathtttfnnlemma compliant formula f havennvdash fleftrightarrowmathtttfnnproof proof induction structure f two interesting casesnn fgto h ih find vdash gleftrightarrowmathtttg vdash hleftrightarrowmathttth thus vdashgto hleftrightarrowmathtttgrightarrowmathttth yield desired result mathtttgrightarrowmathttthmathtttgto hn fiag ih find vdash gleftrightarrowmathtttg since iag compliant assumption use mathsfsub infer iagleftrightarrowiamathtttg lemma know vdashiamathtttgleftrightarrowmathsfhiamathtttg finally conclude vdashiagleftrightarrowmathsfhiamathtttg yield claim since mathtttiafmathsfhiamathtttfnntheorem compliant mathcallmathsfbformula f havennftext valid quad implies quadvdash fnnproof assume f valid compliant mathcallmathsfbformula lemma know vdash fleftrightarrowmathtttf hence soundness mathsfbcl get mathtttf valid since mathtttf mathcallmathsfmformula lemma yield vdashmathtttf using lemma conclude vdash fnncombining theorem theorem easily yield completeness full languagenntheorem mathcallmathsfbformula f havennftext valid quad implies quadvdash fnnproof assume f mathcallmathsfbformula valid theorem find compliant mathcallmathsfbformula g thatnnvdash fleftrightarrow g tagnnhence soundness mathsfbcl know g valid applying theorem yield vdash g finally conclude vdash f nn conclusionnnwe presented mathsfbcl dynamic logic reason simple blockchain model semantics full complexity blockchains used bitcoin ethereum yet exhibit two key property blockchains blockchain extension must preserve consistency block may received wrong order note however although receiving block wrong order important logical possibility happens rarely practice bitcoin protocol average generation time new block minute average time node receives block second nnin order illustrate dynamic simple blockchain logic state valid principle mathsfbcl following examplennexample following formula valid thus provable mathsfbclnnpersistence box atoibbox belief persistent ie receiving new block lead retraction previous beliefsnconsistency ibnegboxbot receiving new block result inconsistent beliefsnsuccess mathsfacciatoiabox block ia acceptable believed receiving iannfailure qiveeneg qirightarrowibbox aleftrightarrowbox current length blockchain receiving block ib change current beliefsnnproofn persistence box arightarrowibbox let mathsfmmathsfimathsfbclangleranglemathsfv initial model assume mathsfmmodelsbox mathsficupmathsfsetmathsfbcmodels let mathsfimathsfbcprimemathsfpuprimemathsfvmathsfm ib find mathsfsetmathsfbcsubseteqmathsfsetmathsfbcprime therefore mathsficupmathsfsetmathsfbcprimemodels hence mathsfmibmodelsbox mathsfmmodelsibbox consistency ibnegboxbot let mathsfmmathsfimathsfbclangleranglemathsfv initial model set mathsfimathsfbcprimemathsfpuprimemathsfvmathsfm ib lemma know mathsficupmathsfsetmathsfbcprime satisfiable ie mathsficupmathsfsetmathsfbcprimenotmodelsbot hence mathsfmibmodelsnegboxbot mathsfmmodelsibnegboxbotn success mathsfacciarightarrowiabox let mathsfmmathsfimathsfbclangleranglemathsfv initial model assume mathsfmmodelsmathsfaccia let mathsfimathsfbcprimemathsfpuprimemathsfvmathsfm ia lemma know mathsfbcprimemathsfbccirc thus mathsficupmathsfsetmathsfbcprimemodels therefore mathsfmiamodelsbox mathsfmmodelsiabox failure qiveeneg qirightarrowibbox aleftrightarrowbox let mathsfmmathsfimathsfbclangleranglemathsfv initial model assume mathsfmmodels qiveeneg qi find mathsfmnotmodelsmathsfaccib indeed mathsfmmodels qitext implies mathsfmnotmodelsmathsfaccib mathsfmmodelsneg qitext implies itext mathsfmnotmodelsmathsfaccib let mathsfimathsfbcprimemathsfpuprimemathsfvmathsfm ib lemma know mathsfbcprimemathsfbc therefore mathsfmibmodelsbox mathsfmmodelsbox yield mathsfmmodelsibbox aleftrightarrowbox nnthere still many open issue epistemic blockchain logic let u mention three first although blockchains called chain data structure actually used treelike different option choose valid branch bitcoin simply us branch greatest proofofwork effort invested simplicity think longest branch recent research show ghost rule used eg ethereum provides better security higher transaction throughput plan extend bcl handle treelike structure corresponding fork thechain particular requires form probability logic model fact older transaction smaller probability reversed nnone purpose blockchains provide data structure make possible achieve common knowledge among group agent distributed system logic common knowledge wellunderstood believe fully developed blockchain logic support multiple agent common knowledge operatorsnnin multiagent setting agent node instance blockchain justification logic could provide formal approach handle evidence term could represent blockchain instance instance seen justifying agent knowledge accepted transaction approach would require develop new dynamic justification logic moreover underlying blockchain model support fork chain need justification logic probability operator nn referencesnn antonopoulos mastering bitcoin unlocking digital cryptocurrencies oreilly medium inc n artemov sn explicit provability constructive semantics bulletin symbolic logic mar n brunnler k studer syntactic cutelimination common knowledge annals pure applied logic n bucheli kuznets r studer realizing public announcement justification journal computer system science n buterin v ethereum nextgeneration smart contract decentralized application platform httpsgithubcomethereumwikiwikiwhitepaperhttpsgithubcomethereumwikiwikiwhitepaper retrieved feb n decker c wattenhofer r information propagation bitcoin network th ieee international conference peertopeer computing pp n van ditmarsch h van der hoek w kooi b dynamic epistemic logic synthese library vol springer n van ditmarsch h kooi b secret success synthese n fagin r halpern jy moses vardi reasoning knowledge mit press n grunspan c perezmarco r double spend race arxiv eprints n herlihy moir blockchains logic accountability keynote address proceeding st annual acmieee symposium logic computer science pp lics jager g kretz studer cutfree common knowledge journal applied logic n kokkinis maksimovic p ognjanovic z studer first step towards probabilistic justification logic logic journal igpl n kooi b expressivity completeness public update logic via reduction axiom journal applied nonclassical logic n kuznets r studer update evidence belief expansion artemov sn nerode ed logical foundation computer science international symposium lfcs san diego ca usa january proceeding lecture note computer science vol pp springer n lamport l shostak r pea byzantine general problem acm trans program lang syst n meyer jjc van der hoek w epistemic logic ai computer science cambridge university press n nakamoto bitcoin peertopeer electronic cash system n renne b public communication justification logic journal logic computation dec published online july n sompolinsky zohar secure highrate transaction processing bitcoin bohme r okamoto ed financial cryptography data security th international conference fc revised selected paper pp springer berlin heidelberg berlin heidelberg n steiner system consistency preserving belief change artemov parikh r ed proceeding rationality knowledge pp th european summer school logic language information association logic language information n steiner studer total public announcement artemov nerode ed proceeding logical foundation computer science lncs vol pp springer n wood g ethereum secure decentralised generalised transaction ledger eip revision httpsethereumgithubioyellowpaperpaperpdfhttpsethereumgithubioyellowpaperpaperpdf retrieved feb title managing blockchain system application process model blockchain configuration transcription managing blockchain system application process model blockchain configurationsnnolga labazovannuniversity colognennlabazovawisounikoelndennfrol kazannnit university copenhagennnerkaitudknntujas dehlingnnkarlsruhe institute technologynndehlingkitedunntuure tuunanennnuniversity jyvaskylanntuurettuunanenjyufinnali sunyaevnnkarlsruhe institute technologynnsunyaevkitedunn abstractnnblockchain radical innovation unique value proposition shift trust institution algorithm still potential blockchains remains elusive due knowledge gap computer science research socioeconomic research building information technology governance literature theory coevolution study develops process model blockchain configuration capture blockchain capability dimension application area demonstrate applicability proposed blockchain configuration process model four blockchain project proposed blockchain configuration process model assist selection configuration blockchain system based set known requirement blockchain project finding contribute research bridging knowledge gap computer science socioeconomic research blockchain specifically explore existing blockchain concept integrate process model blockchain configurationsnn introductionnnit take year blockchain system fully adopted business journey already begun iansiti lakhani blockchain radical innovation potential change business logic many industry blockchains unique value proposition shift institutional trust towards algorithmic consensus mechanism beck mullerbloch network node within blockchain system process record transaction within socalled block nakamoto blockchain system advantage removing single point failure improving data integrity availability contrast centralized database leverage aforementioned feature organization different industry eg finance energy healthcare considering deploy blockchain system reduce intermediary decrease management cost accelerate business process tap new revenue source furlonger valdes nnhowever current blockchain project akin trialanderror approach purposeful information system development due lack best practice blockchain development unclear longterm business value furlonger valdes beck mullerbloch word initiated blockchain project prone failure orinefficient resource allocation instance ninetytwo percent blockchain project launched total investment volume billion defunct indefinitely delayed trujillo fromhart srinivas nnthe main reason failure either flawed system design incompatible application area risius spohrer illustrate jasper project bank canada revealed blockchain system wholesale payment competitive compared centralized system regard operating cost chapman et al example illustrates narrowscoped blockchain prototype exhibit issue regard technical scalability resource efficiency user traceability lacking protection fraud ylihuumo et al xu et al nnthe existing literature blockchain focus either technical aspect use case lindman tuunainen rossi notheisen hawlitschek weinhardt instance technical study explore various consensus mechanism cryptographic protocol predominately focusing financial transaction application case eg bitcoin hand research blockchain use case focus business application energy trading rutkin healthcare azaria ekblaw vieira lippman supply chain management glaser mendling et al however aforementioned study predominantly ideadriven exhibit challenge due lack feasible technical solution avital et al lindman et al beck et al develop successful proof concept blockchain application area research blockchain technology ie technical aspect blockchain application ie business use case considered conjointlynnwe build information technology governance literature apply theory coevolution technology application areasgrodal gotsopoulos suarez lens explore coevolving blockchain configuration application area bridging knowledge technology underlying blockchains application area create condition developing successful blockchainbased system iansiti lakhani nnfootnote term application area refer concept category mentioned grodal et al nnwe explore current body blockchain research present model form process model blockchain configuration capture blockchain capability routinized repeatable applicationspecific process enabling business transform resource business value ray muhanna barney tallon answer following research question application area advisable blockchain system blockchain system purposefully configured across application casesnnto create blockchain configuration process model systematically developed taxonomy group blockchain application area across mutually exclusive blockchain configuration nickerson varshney muntermann identified blockchain concept relationship consolidated blockchain configuration process model structure blockchain concept four category semantic feature reciprocal relationship blockchain governance blockchain application area blockchain property blockchain deployment illustrate applicability proposed blockchain configuration process model four selected blockchain projectsnnwith research contribute extant research blockchain presenting granular holistic view identified blockchain concept relationship practitioner proposed model offer guidance manager identify suitable blockchain system corresponding application area developmentnnthis paper proceeds follows section discus theoretical aspect governance theory coevolution technology application section outline threestep exploratory research approach creating blockchain configuration process model section present blockchain configuration process model section illustrate applicability blockchain configuration process model four blockchain project section discus finding implication theory practice suggest avenue future researchnn theoretical backgroundnn governancennit governance defined collection decision right accountability encourage desirable behavior context brown grant decision right represent governing control aspect asset whereas accountability capture monitoring decisionmaking process incentive play vital part governance motivate guide agent act favorably purpose specific system overall literature governance discus three basic governance approach first centralized governance includes executive committee decisionmaking characterized centralized business process providing control architecture possessing formal assessment monitoring decision second decentralized approach governance requires governance mechanism decisionmaking insists local accountability brown magill schwarz hirschheim brown grant lastlycompanies aim balance benefit centralized decentralized model follow hybrid governance approach company establish centralized group provide core service allowing business unit control portion overall function boynton zmud rockart nn blockchain governancennthe successful blockchain system adapt governance organizational environment business value creation kharitonov beck et al introduced le decentralized data management solution blockchain system evolve continuously aligned different governance approach beck et al specify decision right dimension blockchain centralization decisionmaking power either concentrated governing node distributed equally among node blockchain network regard accountability differ right monitor decision blockchain system ability adjust action based consequence incurred beck et al vein different incentive scheme motivate agent act within blockchain system monetary nonmonetary rewardsnn theory coevolution technology applicationsnnthe theory coevolution technology application area industry emergence focus mechanism continuous coevolution start period divergence continues period convergence grodal et al period divergence characterized high diversity technology address emerging application requirement technology evolve fulfill application requirement continuous design recombination application area influenced pool readymade technological design turn satisfy group application requirement following period convergence result consensus among producer respect efficient technological design mature application areasnnthe blockchain domain currently early stage industry emergence characterized high diversity technological design potential application area lindman et al miscione ziolkowski zavolokina schwabe schlegel zavolokina schwabe variety consensus mechanism karame androulaki capkun anonymity scheme reid harrigan produce various experimental solution largely unrelated opaque emerging blockchain application case ylihuumo et al nevertheless number blockchain application experiment growing leading different blockchainbased service supply chain management glaser mendling et al energy trading rutkin authentication service miscione et al nnin turn blockchain application case fully supported readymade technological solution risius spohrer far extant research blockchain system yield isolated unstructured concept offer limited support configuring blockchain system application areasnn research approachnnour research approach developing blockchain configuration process model comprises three consecutive step figure first explore blockchain concept relationship taxonomy development based literature business report instantiated decentralized application nickerson et al second structure finding form blockchain configuration process model third illustrate applicability blockchain configuration process model four blockchain projectsnn taxonomy developmentnnto organize extant knowledge blockchain employed taxonomy development method proposed nickerson et al define taxonomy set dimension dimension consists mutually exclusive collectively exhaustive characteristic way object consideration one one characteristic every dimension nickerson et al p taxonomy development method proceeds three stage initial stage metacharacteristic ending condition defined according purpose taxonomy developed main stage taxonomy developed object classified taxonomy study application case dimension characteristic identified inductive deductive iteration inductive iteration empirical case analyzed determine dimension characteristic taxonomy deductive iteration dimension characteristic derived existing scientific knowledge base final stage taxonomy evaluated ending conditionsnnthe aim taxonomy derive classify blockchain application area dimension driven blockchain characteristic therefore selected blockchain characteristic eg consensus mechanism anonymity level metacharacteristic metacharacteristic serf basis identification dimension characteristicsnnfigure research approach blockchain configuration process modelnnwe developed taxonomy four iteration first three iteration inductive iteration identified application case derive dimension characteristic inductive iteration used different type source scientific literature business review white paper blockchain application respectively fourth iteration deductive iteration revised taxonomy based previous classification blockchain system first iteration searched paper article web science core collection search string blockchain distributed ledger october title abstract keywords covering whole period publication webster watson vom brocke et al search returned fiftyone paper article screening title abstract discarded ten paper nonblockchain research coded fortyone remaining relevant paper article first iteration identified six dimension fourteen characteristic six application area ten application case analysis existing scientific literature revealed detailed information separate blockchain characteristic eg consensus mechanism specific blockchain application example eg energy market prediction platform lacked comprehensivenessnnfootnote used index science citation index expanded present social science citation index present art humanity citation index present conference proceeding citation index science present conference proceeding citation index social science humanity present book citation index science present book citation index social science humanity present emerging source citation index presentnnin second iteration analyzed business report provide le precise comprehensive information investigated twenty business report published national agency consulting company international institution revised taxonomy added two dimension six characteristic one application casennto fill remaining gap taxonomy reviewed eightysix blockchain system application eg bitcoin ethereum hyperledger third iteration possible used application otherwise read available documentation white paper third iteration added four new application casesnnthe fourth iteration deductive derived characteristic dimension application case fifteen previous classification used previous classification could identify extant literature october analysis showed taxonomy consistent extant blockchain classificationsnnall ending condition proposed nickerson al fulfilled fourth iteration first found blockchain application case described existing scientific literature business report classified taxonomy second dimension unique mutually exclusive characteristic unique within dimension third application case classified single characteristic dimension fourth taxonomy conciseconsists dimension classify application case fifth taxonomy robustdifferentiates application case others sixth taxonomy explanatory comprehensive extensiblehighlights main feature application case extended new application case arisenn consolidation findingsnnbased taxonomy development synthesized finding process model blockchain configuration model capture characteristic application area pertinent blockchain system specifically model structured four dimension distinct semantic feature reciprocal relationship blockchain governance blockchain application area blockchain property blockchain deployment synthesize blockchain concept investigate relationship coded data using three type coding schemesopen coding axial coding selective coding strauss corbin applied open coding initial categorization blockchain concept axial coding removal overlapping concept iteratively testing blockchain concept data selective coding identify relationship concept one researcher coded source three time november april november another researcher validated result iteration strauss dispute resolved group discussionsnnfootnote open coding process grouping category subcategories strauss corbin p axial coding process testing category related subcategories relationship data strauss corbin p selective coding process category unified around core category category need explication filledin descriptive detail strauss corbin pnn blockchain configuration process modelnnbased set known requirement blockchain project ie blockchain governance blockchain application area blockchain configuration process model figure support configuration blockchain property selection blockchain deployment attribute ie processing settlement transactionsnnthe blockchain configuration process model proceeds three step first one chooses suitable governance approach decentralized hybrid centralized application area ie financial transaction enforcement asset management storage communication ranking reflects requirement blockchain project example blockchain application located intersection blockchain governance application area second proposed model identifies appropriate blockchain property according selected application area eg financial transaction blockchain property token equity utility customizability fixed custom data type log asset history retention whole update third blockchain configuration process model support blockchain deployment ie processing settlement according selected blockchain governance approach eg decentralized blockchain deployment attribute comprise access ie private public validation ie permissioned unpermissioned consensus mechanism ie proofofwork proofofstake practical byzantine fault tolerance selfdeveloped consensus mechanism anonymity level ie anonymous pseudonymous identifiablennafter finishing three step blockchain configuration process model terminates complex blockchain project include different blockchain capability process reiteratednn blockchain governancennthe blockchain configuration process model account different approach governancedecentralized hybrid centralized brown grant decentralized approach blockchain governance implies node network decision right accountability right bitcoin example blockchains decentralized governance bitcoin network participant hold right decide correct functioning system whereas transparency data blockchains allows actor monitor decision nakamoto collectively governed company startup often require decentralized blockchain governance spread decision right accountability among actor network reduce network overloadnnblockchains governed hybrid governance approach allow authenticated predefined user monitor decision however one node part network participation decisionmaking requires additional permission ripple example blockchain hybrid governance ripple network predefined node trusted organization deal directly support peertopeer financial settlement systemnnfigure blockchain configuration process modelnnwalsh et al hybrid approach blockchain governance useful interorganizational collaboration blockchains keep network closed ensure confidentiality information whereas decision right distributed among node networknna centralized approach blockchain governance support blockchains node usually small number node authorized validate transaction require additional authorization decision right example system centralized blockchain governance ibm hyperledger blockchains support regulatory supervisory node monitor system hyperledger architecture working group centralized blockchain governance useful support enterprise business project predefined number user network usually semitrusted organization individual monitor decision node right validate transactionsnn blockchain application areasnnthe taxonomy yield six blockchain application area comprise total fourteen application case application area group application case similar semantic feature instance usage scenario similar combination blockchain configuration first application area financial transaction capture application case concerned money transfer exchange anonymous conventional cryptocurrencies wealth storage micropayments utilize blockchains decentralized governance eg bitcoin primecoin namecoin zcash darkcoin interorganizational crossborder microfinancial transaction employ hybrid approach blockchain governance eg ripple stellar centralissued financial instrument deployed blockchains centralized governance instance rscoin fedcoin project koning may allow federal state independently launch coinsnnthe second application area blockchains enforcement enforcement ensure compliance law regulation rule standard social norm application logic beck et al blockchainbased enforcement individual instance developed ethereum platform support decentralized approach blockchain governance interorganizational enforcement usually employ blockchains hybrid governance ripple codius allows executing enforcement predefined organization blockchains centralized governance useful deployment centrally issued enforcement eg r corda example uk barclays bank built prototype r corda platform translates legal contract smart contract involved party monitor decide amendment original smart contract walsh et al nnthe third application area asset management concerned management task authentication know customer service luxury good provenance control business asset management offchain registered asset usually requires decentralized governance blockchains example user prove ownership verify origin asset keeping label bitcoin blockchain eg colored coin keep information confidential interorganizational asset management eg everledger applies hybrid blockchain governance enterprise blockchains centralized governance may suitable managing interorganizational asset example maersk ibm introduce tradelens platform realtime access shipping data shipping document utilizes hyperledgerbased blockchainnnthe fourth application area storage concerned keeping digital asset certificate music video file blockchains kishigami et al blockchainbased decentralized storage implemented blockchains decentralized governance requires high number node distribute transaction load network instance storj project leverage sharding split encrypted data wilkinson et al blockchains hybrid centralized governance seem inappropriate blockchainbased storage extensive resource requirement blockchain deployment availability effective alternative solution decentralized storage service salviotti de rossi abbatemarco nnthe fifth application area communication messaging iot communication realized blockchains decentralized governance content intended mass communication eg whisper unger et al communication system based blockchains hybrid centralized governance create additional value compared peertopeer messenger telehash used many decentralized service eg ibm adeptnnthe sixth application area ranking single application case global reputation rating eg dennis owenson supported blockchains decentralized governance allows number untrusted participant create blockchainbased reputation blockchains hybrid centralized governance seem inappropriate ranking availability alternative solution example ranking based peertopeer system gnutella salviotti et al nnnn blockchain propertiesnnblockchain property allow configuration blockchains according application area identify four important blockchain property token specify transaction processed blockchain represented equity token capture transfer value party eg alice transfer bitcoin bob utility token elaborate contain extensive data application logic customizability capture blockchains ability process application logic customizability indicates blockchain handle application logic fixed customizability support builtin configuration customizability custom blockchains support processing application logic provided user data type focus type data shared blockchain user log imply exchange log executed transaction digital asset mean whole digital asset document message video music file exchanged history retention ascertains whether whole blockchain starting genesis block recent update kept distributed nodesnnthe choice blockchain property depends blockchain application area everything primarily used financial transaction based equity token financial transaction require customizability example bitcoin scripting language purposefully turingcomplete walsh et al blockchains financial transaction exchange log executed financial transaction keep whole transaction history nakamoto nnenforcements based utility token eg company stock ownership beck et al enforcement customized smart contract executed across participant blockchain network peter panayi chapelle enforcement exchange log smart contract retrieve whole history log security reasonsnnasset management based utility token eg data access fixed customizability allows user use builtin configuration executed action asset represented log eg access asset asset change continuously kept blockchainnnblockchainbased storage supported utility token provides fixed customizability blockchains storage blockchains keep digital asset improve scalability blockchains recent update asset stored user interested current state asset change timenncommunication employ utility token fixed customizability blockchains exchange digital asset form text message blockchains keep whole communication history pureswaran panikkar nair brody ibm adept however application case far production stagennranking us utility token allows fixed customizability blockchains exchange log action usually reputation rating score keep recent update transaction history outdated vote necessary calculating reputation rating safely removed blockchains dennis owenson nn blockchain deploymentnnblockchain deployment attribute depend blockchain governance identified four blockchain deployment attribute access represents ability read submit data blockchain beck et al private access make blockchain available reading submitting data authorized user public access allows everyone read data submit data blockchain validation indicates different mechanism validating transaction blockchain permissioned validation mean authorized user validate transaction participate consensus finding validation unpermissioned user network validate transaction consensus mechanism concerned mechanism reaching consensus blockchain update proofofwork requires validating note spend resource work usually processor time storage space proofofstake requires user proof ownership token establish stake blockchain practical byzantine fault tolerance requires agreement majority validating node validating node transaction validation selfdeveloped consensus mechanism usually include several highly trusted node achieving systemlevel agreement anonymity level ass accuracy user matched particular identity characteristic anonymous user provide identifying information work blockchain characteristic pseudonymous user work pseudonym blockchains characteristic identifiable ask automatically collect personally identifiable information email address ip addressesnna decentralized approach blockchain governance implies public access blockchains allows participant network monitor transaction unpermissioned validation invite participant participate consensus finding proofofwork proofofstake consensus mechanism ensure correct functioning blockchain system network large number untrusted node blockchains decentralized governance support anonymity pseudonymity usersnna hybrid approach blockchain governance requires private access blockchains make blockchain available authorized user however unpermissioned validation requires user blockchain network participate consensus finding blockchainnetwork consists small number trusted node make possible use energyefficient communicationheavy practical byzantine fault tolerance consensus mechanism blockchains hybrid governance frequently ask name surname email address eg hyperledger ripple make user identifiablennin blockchains centralized governance private access allows authorized user monitor transaction permissioned validation allows authorized user validate transaction participate consensus finding often validating node find consensus based resourcesaving selfdeveloped mechanism node privatepermissioned blockchains must identifiable trustednn four blockchain projectsnnwe illustrate applicability usefulness blockchain configuration process model four blockchain project db systel ibm public mobility litsonar academic literature tool dscm tool data sharing factory blockchainopenscienceorg portal researchersnnwe selected different type blockchain project exhibit three different blockchain governance approach ie centralized hybrid decentralized different application area demonstrate analytical capability identifying common dissimilar configuration conducted four openended semistructured interview leading researcher solution architect leading developer september october interview lasted minute average duration minute interview transcribed coded using nvivo software interview interviewee applied blockchain configuration process model project discussed usefulness blockchain configuration process model blockchain concept relationship according blockchain project addition used secondary data source triangulate data understand relationship blockchain concept actual use gathered page interview transcription secondary data table nn
Original Title: A Logic of Blockchain Updates
Original Transcription: "# A Logic of Blockchain Updates\n\nKai Brunnler\n\n1Bern University of Applied Sciences, Switzerland, kai.bruennler@bfh.ch\n\nDandolo Flumini\n\n2ZHAW School of Engineering, Switzerland, dandolo.flumini@zhaw.ch\n\nThomas Studer\n\n3University of Bern, Switzerland, tstuder@inf.unibe.ch\n\n###### Abstract\n\nBlockchains are distributed data structures that are used to achieve consensus in systems for cryptocurrencies (like Bitcoin) or smart contracts (like Ethereum). Although blockchains gained a lot of popularity recently, there is no logic-based model for blockchains available. We introduce BCL, a dynamic logic to reason about blockchain updates, and show that BCL is sound and complete with respect to a simple blockchain model.\n\nKeywords:blockchain, modal logic, dynamic epistemic logic\n\n## 1 Introduction\n\nBitcoin [18] is a cryptocurrency that uses peer-to-peer technology to support direct user-to-user transactions without an intermediary such as a bank or credit card company. In order to prevent double spending, which is a common issue in systems without central control, Bitcoin maintains a complete and public record of all transactions at each node in the network. This ledger is called the _blockchain_.\n\nThe blockchain is essentially a growing sequence of blocks, which contain approved transactions and a cryptographic hash of the previous block in the sequence. Because the blockchain is stored locally at each node, any update to it has to be propagated to the entire network. Nodes that receive a transaction first verify its validity (i.e., whether it is compatible with all preceeding transactions). If it is valid, then it is added to the blockchain and sent to all other nodes [1, 20]. Blockchain technology, as a general solution to the Byzantine Generals' Problem [16], is now not only used for financial transactions but also for many other applications like, e.g., smart contracts [5].\n\nHerlihy and Moir [11] propose to develop a logic of accountability to design and verify blockchain systems. In particular, they discuss blockchain scenarios to test (i) logics of authorization, (ii) logics of concurrency, and (iii) logics of incentives.\n\nIn the present paper, we are not interested in accountability but study blockchains from the perspective of dynamic epistemic logic [7]. A given state of the blockchain entails knowledge about the transactions that have taken place. We ask: _how does this knowledge change when a new block is received that might be added to the blockchain?_ We develop a dynamic logic, BCL, with a semantics that is based on a blockchain model. The update operators of BCL are interpreted as receiving new blocks. It is the aim of this paper to investigate the dynamics of blockchain updates.\n\nThe deductive system for BCL includes reduction axioms that make it possible to establish completeness by a reduction to the update-free case [14]. However, since blockchain updates are only performed if certain consistency conditions are satisfied, we use conditional reduction axioms similar to the ones developed by Steiner to model consistency preserving updates [21]. Moreover, unlike traditional public announcements [7], blockchain updates cannot lead to an inconsistent state, i.e., updates are total, like in [22].\n\nWe do not base BCL on an existing blockchain implementation but use a very simple model. First of all, the blockchain is a sequence of propositional formulas. Further we maintain a list of provisional updates. Our blocks consist of two parts: a sequence number (called the index of the block) and a propositional formula. If a block is received, then the following case distinction is performed where \\(i\\) is the index of the block and \\(l\\) is the current length of the blockchain:\n\n1. \\(i\\leq l\\). The block is ignored.\n2. \\(i=l+1\\). If the formula of the block is consistent with the blockchain, then it is added to the blockchain; otherwise the block is ignored. If the blockchain has been extended, then this procedure is performed also with the blocks stored in the list of provisional updates.\n3. \\(i>l+1\\). The block is added to the list of provisional updates.\n\nAlthough this is a simple model, it features two important logical properties of blockchains: consistency must be preserved and blocksmay be received in the wrong order in which case they are stored separately until the missing blocks have been received.\n\nThe main contribution of our paper from the point of view of dynamic epistemic logic is that we maintain a list of provisional updates. That means we support updates that do not have an immediate effect but that may lead to a belief change later only after certain other updates have been performed. BCL is the first dynamic epistemic logic that features provisional updates of this kind.\n\nThe paper is organized as follows. The next section introduces our blockchain model, the language of BCL, and its semantics. In Section 3, we introduce a deductive system for BCL. We establish soundness of BCL in Section 4. In Section 5, we show a normal form theorem for BCL, which is used in Section 6 to prove completeness of BCL. The final section studies some key principles of the epistemic dynamics of our blockchain logic and discusses future work.\n\n## 2 A simple dynamic epistemic blockchain logic\n\nThe set of all natural numbers is denoted by \\(\\mathbb{N}:=\\{0,1,2,\\ldots\\}\\). The set of positive natural numbers is denoted by \\(\\mathbb{N}^{+}:=\\{1,2,\\ldots\\}\\). We use \\(\\omega\\) for the least ordinal such that \\(\\omega>n\\), for all \\(n\\in\\mathbb{N}\\).\n\nLet \\(\\sigma=\\langle\\sigma_{1},\\ldots,\\sigma_{n}\\rangle\\) be a finite sequence. We define its _length_ by \\(\\mathsf{len}(\\sigma):=n\\). For an infinite sequence \\(\\sigma=\\langle\\sigma_{1},\\sigma_{2},\\ldots\\rangle\\) we set \\(\\mathsf{len}(\\sigma):=\\omega\\). Further for a (finite or infinite) sequence \\(\\sigma=\\langle\\sigma_{1},\\sigma_{2},\\ldots,\\sigma_{i},\\ldots\\rangle\\) we set \\((\\sigma)_{i}:=\\sigma_{i}\\). The _empty sequence_ is denoted by \\(\\langle\\rangle\\) and we set \\(\\mathsf{len}(\\langle\\rangle):=0\\). We can append \\(x\\) to a finite sequence \\(\\sigma:=\\langle\\sigma_{1},\\ldots,\\sigma_{n}\\rangle\\), in symbols we set \\(\\sigma\\circ x:=\\langle\\sigma_{1},\\ldots,\\sigma_{n},x\\rangle\\). We will also need the set of all components of a sequence \\(\\sigma\\) and define\n\n\\[\\mathsf{set}(\\sigma):=\\{x\\ |\\ \\text{there is an $i$ such that $x=\\sigma_{i}$}\\}.\\]\n\nIn particular, we have \\(\\mathsf{set}(\\langle\\rangle):=\\emptyset\\). Moreover, we use the shorthand \\(x\\in\\sigma\\) for \\(x\\in\\mathsf{set}(\\sigma)\\).\n\nWe start with a countable set of atomic propositions \\(\\mathcal{AP}:=\\{P0,P1,\\ldots\\}\\). The set of formulas \\(\\mathcal{L}_{\\mathsf{cl}}\\) of classical propositional logic is given by the following grammar\n\n\\[A::=\\bot\\ |\\ P\\ |\\ A\\to A\\quad,\\]where \\(P\\in\\mathcal{AP}\\).\n\nIn order to introduce the language \\(\\mathcal{L}_{\\mathsf{B}}\\) for blockchain logic, we need another countable set of special atomic propositions \\(\\mathcal{AQ}:=\\{Q1,Q2,\\ldots\\}\\) that is disjoint with \\(\\mathcal{AP}\\). We will use these special propositions later to keep track of the length of the blockchain. The formulas of \\(\\mathcal{L}_{\\mathsf{B}}\\) are now given by the grammar\n\n\\[F::=\\bot\\ |\\ P\\ |\\ Q\\ |\\ F\\to F\\ |\\ \\Box A\\ |\\ [i,A]F\\quad,\\]\n\nwhere \\(P\\in\\mathcal{AP}\\), \\(Q\\in\\mathcal{AQ}\\), \\(A\\in\\mathcal{L}_{\\mathsf{cl}}\\), and \\(i\\in\\mathbb{N}^{+}\\). The operators of the form \\([i,A]\\) are called _blockchain updates_ (or simply _updates_).\n\nNote that in \\(\\mathcal{L}_{\\mathsf{B}}\\) we cannot express higher-order knowledge, i.e., we can only express knowledge about propositional facts but not knowledge about knowledge of such facts.\n\nFor all languages in this paper, we define further Boolean connectives (e.g. for negation, conjunction, and disjunction) as usual. Moreover, we assume that unary connectives bind stronger than binary ones.\n\nFor \\(\\mathcal{L}_{\\mathsf{cl}}\\) we use the semantics of classical propositional logic. A _valuation_\\(\\mathsf{v}\\) is a subset of \\(\\mathcal{AP}\\) and we define the truth of an \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formula \\(A\\) under \\(\\mathsf{v}\\), in symbols \\(\\mathsf{v}\\models A\\) as usual. For a set \\(\\Gamma\\) of \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formulas, we write \\(\\mathsf{v}\\models\\Gamma\\) if \\(\\mathsf{v}\\models A\\) for all \\(A\\in\\Gamma\\). The set \\(\\Gamma\\) is _satisfiable_ if there is a valuation \\(\\mathsf{v}\\) such that \\(\\mathsf{v}\\models\\Gamma\\). We say \\(\\Gamma\\)_entails_\\(A\\), in symbols \\(\\Gamma\\models A\\), if for each valuation \\(\\mathsf{v}\\) we have\n\n\\[\\mathsf{v}\\models\\Gamma\\quad\\text{implies}\\quad\\mathsf{v}\\models A.\\]\n\nNow we introduce the blockchain semantics for \\(\\mathcal{L}_{\\mathsf{B}}\\).\n\nDefinition 1: A _block_ is a pair \\([i,A]\\) where \\(A\\) is an \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formula and \\(i\\in\\mathbb{N}^{+}\\). We call \\(i\\) the _index_ and \\(A\\) the _formula_ of the block \\([i,A]\\). We define functions \\(\\mathsf{ind}\\) and \\(\\mathsf{fml}\\) by \\(\\mathsf{ind}[i,A]:=i\\) and \\(\\mathsf{fml}[i,A]:=A\\).\n\nDefinition 2: A _model_\\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\) is a quadruple where\n\n1. \\(\\mathsf{I}\\) is a set of \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formulas\n2. \\(\\mathsf{BC}\\) is a sequence of \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formulas\n3. \\(\\mathsf{PU}\\) is a finite sequence of blocks\n4. \\(\\mathsf{v}\\) is a valuation, i.e. \\(\\mathsf{v}\\subseteq\\mathcal{AP}\\)_such that_\n\n\\[\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\mbox{ is satisfiable} \\tag{1}\\]\n\n_and_\n\n\\[\\mbox{for each block }[i,A]\\in\\mathsf{PU}\\mbox{ we have }i>\\mathsf{len}(\\mathsf{BC})+1. \\tag{2}\\]\n\nThe components of a model \\((\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\) have the following meaning:\n\n1. \\(\\mathsf{I}\\) models initial background knowledge.\n2. \\(\\mathsf{BC}\\) is the blockchain.\n3. \\(\\mathsf{PU}\\) stands for _provisional updates_. The sequence \\(\\mathsf{PU}\\) consists of those blocks that have been announced but that could not yet be added to the blockchain because their index is too high. Maybe they will be added to \\(\\mathsf{BC}\\) later (i.e., after the missing blocks have been added).\n4. \\(\\mathsf{v}\\) states which atomic propositions are true.\n\nWe need some auxiliary definition in order to precisely describe the blockchain dynamics.\n\nDefinition 3:\n1. Let \\(\\mathsf{PU}\\) be a finite sequence of blocks. Then we let \\(\\mathsf{find}(i,\\mathsf{PU})\\) be the least \\(j\\in\\mathbb{N}^{+}\\) such that there is an \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formula \\(A\\) with \\([i,A]=(\\mathsf{PU})_{j}\\).\n2. Let \\(\\sigma=\\langle\\sigma_{1},\\ldots,\\sigma_{i-1},\\sigma_{i},\\sigma_{i+1},\\ldots\\rangle\\) be a sequence. We set \\[\\mathsf{remove}(i,\\sigma):=\\langle\\sigma_{1},\\ldots,\\sigma_{i-1},\\sigma_{i+1 },\\ldots\\rangle.\\]\n3. Given a set of \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formulas \\(\\mathsf{I}\\), a sequence of \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formulas \\(\\mathsf{BC}\\), and a finite sequence of blocks \\(\\mathsf{PU}\\), then the _chain completion complete\\((\\mathsf{I},\\mathsf{BC},\\mathsf{PU})\\)_ is computed according to Algorithm 1._Let us comment on the chain completion procedure. The numbers refer to the lines in Algorithm 1.\n\n1. \\(n\\) is the index a block must contain so that it could be added to the blockchain \\(\\mathsf{BC}\\).\n2. '\\([n,A]\\in\\mathsf{PU}\\) for some formula \\(A\\)' means that \\(\\mathsf{PU}\\) contains a block that could be added to \\(\\mathsf{BC}\\).\n3. Find the next formula \\(B\\) that could be added to \\(\\mathsf{BC}\\) and remove the corresponding block from \\(\\mathsf{PU}\\).\n4. '\\(\\mathsf{l}\\cup\\mathsf{set}(\\mathsf{BC})\\cup\\{B\\}\\) is satisfiable' means that \\(B\\) is consistent with the current belief. This test guarantees that (1) will always be satisfied.\n5. Update the blockchain \\(\\mathsf{BC}\\) with \\(B\\).\n6. Remove all blocks from \\(\\mathsf{PU}\\) whose index is less than or equal to the current length of the blockchain \\(\\mathsf{BC}\\). Because the blockchain never gets shorter, these block will never be added. Removing them guarantees that (2) will always be satisfied.\n\nNote if \\(\\mathsf{BC}\\) and \\(\\mathsf{PU}\\) satisfy condition (2) in the definition of a model, then the chain completion algorithm will return \\(\\mathsf{BC}\\) and \\(\\mathsf{PU}\\) unchanged.\n\nLemma 1: _Let \\(|\\) be a set of \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formulas and let \\(\\mathsf{BC}\\) be a sequence of \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formulas such that \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\) is satisfiable. Let \\(\\mathsf{PU}\\) be an arbitrary finite sequence of blocks. For \\((\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime}):=\\mathsf{complete}(\\mathsf{I}, \\mathsf{BC},\\mathsf{PU})\\) we find that_\n\n1. \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC}^{\\prime})\\) _is satisfiable and_\n2. _for each block_ \\([i,A]\\in\\mathsf{PU}^{\\prime}\\) _we have_ \\(i>\\mathsf{len}(\\mathsf{BC}^{\\prime})+1\\)_._\n\nProof: By assumption,\n\n\\[\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\text{ is satisfiable} \\tag{3}\\]\n\nholds for the arguments passed to the algorithm. Moreover, the condition in line 6 guarantees that (3) is a loop invariant of the while loop in lines 2-10, i.e., it holds after each iteration. Since \\(\\mathsf{BC}\\) is not changed after line 10, (3) also holds for the final result, which shows the first claim of the lemma.\n\nIt is easy to see that\n\n\\[n=\\mathsf{len}(\\mathsf{BC})+1 \\tag{4}\\]\n\nalso is a loop invariant of while loop in lines 2-10. In particular, (4) holds after line 10 and thus the for loop in lines 11-15 removes all blocks \\([i,A]\\) from \\(\\mathsf{PU}\\) with \\(i<\\mathsf{len}(\\mathsf{BC})+1\\). Moreover, after the while loop in lines 2-10 has terminated, its loop condition must be false, which means that \\(\\mathsf{PU}\\) cannot contain a block \\([i,A]\\) with \\(i=\\mathsf{len}(\\mathsf{BC})+1\\). This finishes the proof of the second claim. \n\nDefinition 4: Let \\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\) be a model and \\([i,A]\\) be a block. The _updated model_\\(\\mathsf{M}^{[i,A]}\\) is defined as \\((\\mathsf{I},\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime},\\mathsf{v})\\) where\n\n\\[(\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime}):=\\mathsf{complete}(\\mathsf{I}, \\mathsf{BC},\\mathsf{PU}\\circ[i,A]).\\]\n\nRemark 1: Note that \\(\\mathsf{M}^{[i,A]}\\) is well-defined: by Lemma 1 we know that \\(\\mathsf{M}^{[i,A]}\\) is indeed a model.\n\nDefinition 5: Let \\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\) be a model. We define the truth of an \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula \\(F\\) in \\(\\mathsf{M}\\), in symbols \\(\\mathsf{M}\n\n\n\n+++ ==WARNING: Truncated because of repetitions==\n\\models F\\), inductively by:\n\n1. \\(\\mathsf{M}\\not\\models\\bot\\);\n2. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n3. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n4. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n5. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n6. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n7. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n8. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n9. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n10. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n11. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n12. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n13. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n14. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n15. \\(\\mathsf{M}\\models P\\) if \\(P\\in\\mathsf{v}\\) for \\(P\\in\\mathcal{AP}\\);\n16. \\(\\mathsf{M}\\models P\\) if\n+++\n\n3. \\(\\mathsf{M}\\models Qi\\) _if_ \\(i\\leq\\mathsf{len}(\\mathsf{BC})\\) _for_ \\(Qi\\in\\mathcal{AQ}\\)_;_\n4. \\(\\mathsf{M}\\models F\\to G\\) _if_ \\(\\mathsf{M}\\not\\models F\\) _or_ \\(\\mathsf{M}\\models G\\)_;_\n5. \\(\\mathsf{M}\\models\\Box A\\) _if_ \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\models A\\)_;_\n6. \\(\\mathsf{M}\\models[i,A]F\\) _if_ \\(\\mathsf{M}^{[i,A]}\\models F\\)_._\n\nWe define validity only with respect to the class of models that do not have provisional updates.\n\nDefinition 6: We call a model \\(\\mathsf{M}=(\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\) _initial_ if \\(\\mathsf{PU}=\\langle\\rangle\\). A formula \\(F\\) is called _valid_ if \\(\\mathsf{M}\\models F\\) for all initial models \\(\\mathsf{M}\\).\n\n## 3 The deductive system \\(\\mathsf{BCL}\\)\n\nIn order to present an axiomatic system for our blockchain logic, we need to formalize an _acceptance condition_ stating whether a received block can be added to the blockchain. That is we need a formula \\(\\mathsf{Acc}(i,A)\\) expressing that the formula \\(A\\) is consistent with the current beliefs and the current length of the blockchain is \\(i-1\\). Thus if \\(\\mathsf{Acc}(i,A)\\) holds, then the block \\([i,A]\\) will be accepted and added to the blockchain. The truth definition for the atomic propositions \\(Qi\\in\\mathcal{AQ}\\) says that \\(Qi\\) is true if the blockchain contains at least \\(i\\) elements. That means the formula \\(Q(i-1)\\wedge\\neg Qi\\) is true if the blockchain contains exactly \\(i-1\\) elements. This leads to the following definition of \\(\\mathsf{Acc}(i,A)\\) for \\(i\\in\\mathbb{N}^{+}\\):\n\n\\[\\mathsf{Acc}(i,A):=\\begin{cases}\\neg Qi\\wedge\\neg\\Box\\neg A&\\text{ if }i=1\\\\ Q(i-1)\\wedge\\neg Qi\\wedge\\neg\\Box\\neg A&\\text{ if }i>1\\end{cases}\\]\n\nAs desired, we find that if \\(\\mathsf{Acc}(i,A)\\) is true, then the chain completion algorithm can append the formula \\(A\\) to the blockchain (see Lemma 2 later).\n\nAn \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula is called compliant if the blockchain updates occur in the correct order. Formally, we use the following definition.\n\nDefinition 7: An \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula \\(F\\) is _compliant_ if no occurrence of a \\([i,A]\\)-operator in \\(F\\) is in the scope of some \\([j,B]\\)-operator with \\(j>i\\).\n\nNow we can define the system \\(\\mathsf{BCL}\\) for _Epistemic Blockchain Logic_. It is formulated in the language \\(\\mathcal{L}_{\\mathsf{B}}\\) and consists of the following axioms:\n\n\\begin{tabular}{l l} (PT) & Every instance of a propositional tautology \\\\ (K) & \\(\\Box(F\\to G)\\to(\\Box F\\to\\Box G)\\) \\\\ (D) & \\(\\neg\\Box\\bot\\) \\\\ (Q) & \\(Qi\\to Qj\\) if \\(i>j\\) \\\\ (A1) & \\([i,A]\\bot\\to\\bot\\) \\\\ (A2) & \\([i,A]P\\leftrightarrow P\\) for \\(P\\in\\mathcal{AP}\\) \\\\ (A3.1) & \\(\\mathsf{Acc}(i,A)\\to([i,A]Qi\\leftrightarrow\\top)\\) for \\(Qi\\in\\mathcal{AQ}\\) \\\\ (A3.2) & \\(\\neg\\mathsf{Acc}(i,A)\\to([i,A]Qi\\leftrightarrow Qi)\\) for \\(Qi\\in\\mathcal{AQ}\\) \\\\ (A3.3) & \\([i,A]Qj\\leftrightarrow Qj\\) for \\(Qj\\in\\mathcal{AQ}\\) and \\(i\\neq j\\) \\\\  & \\([i_{1},A_{1}]\\ldots[i_{k},A_{k}](F\\to G)\\leftrightarrow\\) \\\\ (A4) & \\(([i_{1},A_{1}]\\ldots[i_{k},A_{k}]F\\to[i_{1},A_{1}]\\ldots[i_{k},A_{k}]G)\\) \\\\ (A5.1) & \\(\\mathsf{Acc}(i,A)\\to([i,A]\\Box B\\leftrightarrow\\Box(A\\to B))\\) \\\\ (A5.2) & \\(\\neg\\mathsf{Acc}(i,A)\\to([i,A]\\Box B\\leftrightarrow\\Box B)\\) \\\\ (A6) & \\([h_{1},C_{1}]\\ldots[h_{k},C_{k}][i,A][j,B]F\\leftrightarrow\\) \\\\  & \\([h_{1},C_{1}]\\ldots[h_{k},C_{k}][j,A][i,B]F\\)  for \\(i\\neq j\\) \\\\ \\end{tabular}\n\nNote that in (A6), we may choose \\(k\\) to be \\(0\\), in which case the axiom has the form \\([i,A][j,B]F\\leftrightarrow[j,A][i,B]F\\) for \\(i\\neq j\\).\n\nIn order to formulate the rules of BCL, we need the following notation. Let \\(H(P)\\) be a formula that may contain occurrences of the atomic proposition \\(P\\). By \\(H(F)\\), we denote the result of simultaneously replacing each occurrence of \\(P\\) in \\(H(P)\\) with the formula \\(F\\). The rules of BCL are:\n\n\\[(\\mathsf{MP})\\,\\frac{F}{G}\\qquad F\\to G\\qquad(\\mathsf{NEC})\\,\\frac{A}{\\Box A }\\qquad(\\mathsf{SUB})\\,\\frac{F\\leftrightarrow G}{H(F)\\leftrightarrow H(G)}\\]\n\nwhere \\((\\mathsf{SUB})\\) can only be applied if \\(H(F)\\leftrightarrow H(G)\\) is a compliant formula.\n\nRemark 2: Our semantics includes infinite blockchains: in a given model \\((\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\), the sequence BC may have infinite length. If we want to exclude such models, then we have to add an infinitary rule\n\n\\[\\frac{Qi\\quad\\text{for all }i\\in\\mathbb{N}^{+}}{\\bot}\\]\n\nto BCL. This rule states that some \\(Qi\\) must be false, which means that BC has finite length.\n\nSoundness\n\nBefore we can establish soundness of \\(\\mathsf{BCL}\\), we have to show some preparatory lemmas.\n\nLemma 2: _Let \\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\) be an initial model. Further let \\((\\mathsf{I},\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime},\\mathsf{v}):=\\mathsf{M}^{[ i,A]}\\) for some block \\([i,A]\\)._\n\n1. _If_ \\(\\mathsf{M}\\models\\mathsf{Acc}(i,A)\\)_, then_ \\(\\mathsf{BC}^{\\prime}=\\mathsf{BC}\\circ A\\)_. In particular, this yields_ \\(\\mathsf{len}(\\mathsf{BC}^{\\prime})=i\\) _and for each_ \\(j\\) _with_ \\(j\\neq i\\)_,_ \\[M\\models Qj\\quad\\text{if and only if}\\quad\\mathsf{M}^{[i,A]}\\models Qj.\\]\n2. _If_ \\(\\mathsf{M}\\not\\models\\mathsf{Acc}(i,A)\\)_, then_ \\(\\mathsf{BC}^{\\prime}=\\mathsf{BC}\\)_._\n\nProof: Assume \\(\\mathsf{M}\\models\\mathsf{Acc}(i,A)\\). That means \\(\\mathsf{len}(\\mathsf{BC})+1=i\\) and \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\cup\\{A\\}\\) is satisfiable. Hence we find\n\n\\[\\mathsf{complete}(\\mathsf{I},\\mathsf{BC},\\langle\\rangle\\circ[i,A])=(\\mathsf{ BC}\\circ A,\\langle\\rangle).\\]\n\nTherefore \\(\\mathsf{BC}^{\\prime}=\\mathsf{BC}\\circ A\\). This immediately yields\n\n\\[\\mathsf{len}(\\mathsf{BC}^{\\prime})=i=\\mathsf{len}(\\mathsf{BC})+1\\]\n\nand for each \\(j\\) with \\(j\\neq i\\),\n\n\\[M\\models Qj\\quad\\text{if and only if}\\quad\\mathsf{M}^{[i,A]}\\models Qj.\\]\n\nAssume \\(\\mathsf{M}\\not\\models\\mathsf{Acc}(i,A)\\). This implies\n\n\\[\\mathsf{len}(\\mathsf{BC})+1\\neq i\\text{ or }\\mathsf{I}\\cup\\mathsf{set}( \\mathsf{BC})\\cup\\{A\\}\\text{ is not satisfiable.}\\]\n\nHence for \\((\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime}):=\\mathsf{complete}(\\mathsf{I}, \\mathsf{BC},\\langle\\rangle\\circ[i,A])\\), we find \\(\\mathsf{BC}^{\\prime}=\\mathsf{BC}\\). \n\nLemma 3: _Each axiom of \\(\\mathsf{BCL}\\) is valid._\n\nProof: We only show some cases. Let \\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\) be an initial model.\n\n1. \\(\\neg\\Box\\bot\\). By the definition of a model, we have that \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\) is satisfiable. Hence \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\not\\models\\bot\\), which means \\(\\mathsf{M}\\not\\models\\Box\\bot\\).\n\n2. \\(Qi\\to Qj\\) for \\(i>j\\). Assume \\(\\mathsf{M}\\models Qi\\). That means \\(i\\leq\\mathsf{len}(\\mathsf{BC})\\). Hence, for \\(j<i\\), we have \\(j\\leq\\mathsf{len}(\\mathsf{BC})\\), which gives \\(\\mathsf{M}\\models Qi\\).\n3. \\(\\mathsf{Acc}(i,A)\\to([i,A]Qi\\leftrightarrow\\top)\\). Assume \\(\\mathsf{M}\\models\\mathsf{Acc}(i,A)\\). Using Lemma 2, we get \\(\\mathsf{M}^{[i,A]}\\models Qi\\). Thus \\(\\mathsf{M}\\models[i,A]Qi\\leftrightarrow\\top\\) as desired.\n4. \\(\\neg\\mathsf{Acc}(i,A)\\to([i,A]Qi\\leftrightarrow Qi)\\). Assume \\(\\mathsf{M}\\not\\models\\mathsf{Acc}(i,A)\\). We use again Lemma 2 to obtain \\(\\mathsf{M}\\models[i,A]Qi\\leftrightarrow Qi\\).\n5. \\([i,A]Qj\\leftrightarrow Qj\\) for \\(Qj\\in\\mathcal{AQ}\\) and \\(i\\neq j\\). If \\(\\mathsf{M}\\not\\models\\mathsf{Acc}(i,A)\\), we obtain \\(\\mathsf{M}\\models[i,A]Qj\\leftrightarrow Qj\\) as in the previous case. If \\(\\mathsf{M}\\models\\mathsf{Acc}(i,A)\\), then again by Lemma 2, \\(\\mathsf{M}\\models[i,A]Qj\\leftrightarrow Qj\\) for \\(i\\neq j\\).\n6. \\(\\mathsf{Acc}(i,A)\\to([i,A]\\Box B\\leftrightarrow\\Box(A\\to B))\\). Assume \\(\\mathsf{M}\\models\\mathsf{Acc}(i,A)\\) and let \\[(\\mathsf{I},\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime},\\mathsf{v}):=\\mathsf{M}^ {[i,A]}.\\] By Lemma 2 we get \\(\\mathsf{BC}^{\\prime}=\\mathsf{BC}\\circ A\\). Thus \\(\\mathsf{set}(\\mathsf{BC}^{\\prime})=\\mathsf{set}(\\mathsf{BC})\\cup\\{A\\}\\). By the deduction theorem for classical logic we find \\[\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\cup\\{A\\}\\models_{\\mathsf{CL}}B\\quad \\text{if and only if}\\quad\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\models_{ \\mathsf{CL}}A\\to B,\\] which yields \\(\\mathsf{M}\\models[i,A]\\Box B\\leftrightarrow\\Box(A\\to B)\\).\n7. \\(\\neg\\mathsf{Acc}(i,A)\\to([i,A]\\Box B\\leftrightarrow\\Box B)\\). Assume \\(\\mathsf{M}\\not\\models\\mathsf{Acc}(i,A)\\). From Lemma 2, we immediately get \\(\\mathsf{M}\\models[i,A]\\Box B\\leftrightarrow\\Box B\\). \n\nLemma 4: _Let \\(\\mathsf{M}=(\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\) be an arbitrary model and let \\([i,A]\\) be a block such that \\(i>\\mathsf{len}(\\mathsf{BC})+1\\). Then we have \\(\\mathsf{M}^{[i,A]}=(\\mathsf{I},\\mathsf{BC},\\mathsf{PU}\\circ[i,A],\\mathsf{v})\\)._\n\nProof: Let\n\n\\[(\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime}):=\\mathsf{complete}(\\mathsf{I}, \\mathsf{BC},\\mathsf{PU}\\circ[i,A]).\\]\n\nSince \\(\\mathsf{M}\\) is a model, condition (2) is satisfied. Therefore, we find that \\(\\mathsf{BC}^{\\prime}=\\mathsf{BC}\\) and \\(\\mathsf{PU}^{\\prime}=\\mathsf{PU}\\circ[i,A]\\), which is \\(\\mathsf{M}^{[i,A]}=(\\mathsf{I},\\mathsf{BC},\\mathsf{PU}\\circ[i,A],\\mathsf{v})\\). \n\nLemma 5: _Let \\(\\mathsf{M}=(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\) be an initial model and let \\([i,A]\\) be a block such that \\(i\\leq\\mathsf{len}(\\mathsf{BC})+1\\). Then \\(\\mathsf{M}^{[i,A]}\\) is an initial model, too._\n\nProof: Let \\(\\mathsf{PU}=\\langle[i,A]\\rangle\\) and\n\n\\[(\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime}):=\\mathsf{complete}(\\mathsf{I}, \\mathsf{BC},\\mathsf{PU}).\\]If \\(i=\\mathsf{len}(\\mathsf{BC})+1\\), then \\([i,A]\\) is removed from \\(\\mathsf{PU}\\) in line 5 of Algorithm 1. If \\(i<\\mathsf{len}(\\mathsf{BC})+1\\), then \\([i,A]\\) is removed from \\(\\mathsf{PU}\\) in line 13. In both cases we find \\(\\mathsf{PU}^{\\prime}=\\langle\\rangle\\), which means that \\(\\mathsf{M}^{[i,A]}\\) is initial. \n\nLemma 6: _Let \\((\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\) be a model and \\(F\\) be an \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula such that for each \\([i,A]\\) occurring in \\(F\\) we have \\(i>\\mathsf{len}(\\mathsf{BC})+1\\). Then_\n\n\\[(\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\models F\\quad\\text{if and only if}\\quad(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\models F.\\]\n\nProof: By induction on the structure of \\(F\\) and a case distinction on the outermost connective. The only interesting case is \\(F=[i,A]G\\). Since \\(i>\\mathsf{len}(\\mathsf{BC})+1\\) by assumption, we find by Lemma 4 that \\((\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})^{[i,A]}=(\\mathsf{I},\\mathsf{ BC},\\mathsf{PU}\\circ[i,A],\\mathsf{v})\\). Thus we get\n\n\\[(\\mathsf{I},\\mathsf{BC},\\mathsf{PU},\\mathsf{v})\\models[i,A]G\\quad\\text{if and only if}\\quad(\\mathsf{I},\\mathsf{BC},\\mathsf{PU}\\circ[i,A],\\mathsf{v})\\models G. \\tag{5}\\]\n\nUsing I.H. twice yields\n\n\\[(\\mathsf{I},\\mathsf{BC},\\mathsf{PU}\\circ[i,A],\\mathsf{v})\\models G\\quad\\text{ if and only if}\\quad(\\mathsf{I},\\mathsf{BC},\\langle[i,A]\\rangle,\\mathsf{v})\\models G. \\tag{6}\\]\n\nAgain since \\(i>\\mathsf{len}(\\mathsf{BC})+1\\) we find that\n\n\\[(\\mathsf{I},\\mathsf{BC},\\langle[i,A]\\rangle,\\mathsf{v})=(\\mathsf{I},\\mathsf{ BC},\\langle\\rangle,\\mathsf{v})^{[i,A]}\\]\n\nand thus\n\n\\[(\\mathsf{I},\\mathsf{BC},\\langle[i,A]\\rangle,\\mathsf{v})\\models G\\quad\\text{ if and only if}\\quad(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\models[i,A]G. \\tag{7}\\]\n\nTaking (5), (6), and (7) together yields the desired result. \n\nNow we can show that the rule (\\(\\mathsf{SUB}\\)) preserves validity.\n\nLemma 7: _Let \\(H(P),F,G\\) be \\(\\mathcal{L}_{\\mathsf{B}}\\)-formulas such that \\(H(F)\\leftrightarrow H(G)\\) is compliant. We have that_\n\n\\[\\text{if $F\\leftrightarrow G$ is valid, then $H(F)\\leftrightarrow H(G)$ is valid, too.}\\]\n\nProof: We show the validity of \\(H(F)\\leftrightarrow H(G)\\) by induction on the structure of \\(H(P)\\). We distinguish the following cases.\n\n1. \\(H\\) does not contain \\(P\\). We find \\(H=H(F)=H(G)\\). Hence \\(H(F)\\leftrightarrow H(G)\\) is trivially valid.\n2. \\(H=P\\). We have \\(H(F)=F\\) and \\(H(G)=G\\). Thus \\(H(F)\\leftrightarrow H(G)\\) is valid by assumption.\n3. \\(H=H^{\\prime}\\to H^{\\prime\\prime}\\). Follows immediately by I.H.\n4. \\(H=\\Box H^{\\prime}\\) By I.H., we find that \\(H^{\\prime}(F)\\leftrightarrow H^{\\prime}(G)\\) is valid. Since \\(\\mathcal{L}_{\\mathsf{B}}\\) does not include nested \\(\\Box\\)-operators, \\(H^{\\prime}(P)\\) is an \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formula. Since \\(H(F)\\leftrightarrow H(G)\\) is a formula, \\(F\\) and \\(G\\) must be \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formulas, too. Hence, \\(H^{\\prime}(F)\\leftrightarrow H^{\\prime}(G)\\) is an \\(\\mathcal{L}_{\\mathsf{cl}}\\)-formula and we obtain \\(\\models_{\\mathsf{CL}}H^{\\prime}(F)\\leftrightarrow H^{\\prime}(G)\\). Hence we have \\(\\mathsf{M}\\models\\Box H^{\\prime}(F)\\) if and only if \\(\\mathsf{M}\\models\\Box H^{\\prime}(G)\\) for any model \\(\\mathsf{M}\\), which yields that \\(H(F)\\leftrightarrow H(G)\\) is valid.\n5. \\(H=[i,A]H^{\\prime}\\). Let \\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\) be an initial model. We distinguish the following cases: 1. \\(i\\leq\\mathsf{len}(\\mathsf{BC})+1\\). By Lemma 5, we find that \\(\\mathsf{M}^{[i,A]}\\) is an initial model. Thus by the I.H. we infer \\(\\mathsf{M}^{[i,A]}\\models H^{\\prime}(F)\\leftrightarrow H^{\\prime}(G)\\), from which we infer \\[\\mathsf{M}\\models[i,A]H^{\\prime}(F)\\leftrightarrow[i,A]H^{\\prime}(G)\\] by the validity of \\((\\mathsf{A}\\mathsf{4})\\). 2. \\(i>\\mathsf{len}(\\mathsf{BC})+1\\). By Lemma 4, we find that \\[\\mathsf{M}^{[i,A]}=(\\mathsf{I},\\mathsf{BC},\\langle[i,A]\\rangle,\\mathsf{v}).\\] Since \\(H(F)\\) is compliant, we obtain that for each \\([j,B]\\) occurring in \\(H(F)\\), we have \\(j>\\mathsf{len}(\\mathsf{BC})+1\\). Hence we obtain by Lemma 6 that \\[\\mathsf{M}^{[i,A]}\\models H^{\\prime}(F)\\quad\\text{if and only if}\\quad( \\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\models H^{\\prime}(F).\\] (8) By I.H. we get \\[(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\models H^{\\prime}(F)\\quad \\text{if and only if}\\quad(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v}) \\models H^{\\prime}(G).\\] (9) Since \\(H(G)\\) is compliant, we find that \\(H^{\\prime}(G)\\) satisfies the condition of Lemma 6. Thus we can use that lemma again to obtain \\[(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\models H^{\\prime}(G)\\quad \\text{if and only if}\\quad\\mathsf{M}^{[i,A]}\\models H^{\\prime}(G).\\] (10)Taking (8), (9), and (10) together yields\n\n\\[\\mathsf{M}\\models[i,A]H^{\\prime}(F)\\leftrightarrow[i,A]H^{\\prime}(G).\\]\n\nWe have established that the axioms of \\(\\mathsf{BCL}\\) are valid and that (\\(\\mathsf{SUB}\\)) preserves validity. It is easy to see that the rules (\\(\\mathsf{MP}\\)) and (\\(\\mathsf{NEC}\\)) also preseve validity. Soundness of \\(\\mathsf{BCL}\\) follows immediately.\n\nCorollary 1: _For each formula \\(F\\) we have_\n\n\\[\\vdash F\\quad\\text{implies}\\quad F\\text{ is valid}.\\]\n\nRemark 3: The reduction axiom (A3.3) does not hold in non-initial models. Indeed, let \\(\\mathsf{M}:=(\\emptyset,\\langle\\rangle,\\langle[2,\\top]\\rangle,\\emptyset)\\). We find that \\(\\mathsf{M}^{[1,P]}=(\\emptyset,\\langle P,\\top\\rangle,\\langle\\rangle,\\emptyset)\\). Hence \\(\\mathsf{M}^{[1,P]}\\models Q2\\), which is \\(\\mathsf{M}\\models[1,P]Q2\\). But we also have \\(\\mathsf{M}\\not\\models Q2\\).\n\nRemark 4: The above remark also implies that a block necessitation rule would not be sound, that is the validity of \\(F\\) does not entail the validity of \\([i,A]F\\). Indeed, the axiom \\([1,P]Q2\\leftrightarrow Q2\\) is valid; but the formula \\([2,\\top]([1,P]Q2\\leftrightarrow Q2)\\) is not valid as shown in the previous remark.\n\nRemark 5: The rule (\\(\\mathsf{SUB}\\)) would not preserve validity if we drop the condition that the conclusion must be compliant. Indeed, let us again consider the valid formula \\([1,P]Q2\\leftrightarrow Q2\\). Without the compliance condition, the rule (\\(\\mathsf{SUB}\\)) would derive \\([2,P^{\\prime}][1,P]Q2\\leftrightarrow[2,P^{\\prime}]Q2\\), which is not a valid formula.\n\n## 5 Normal form\n\nRemember that a formula is compliant if the blockchain updates occur in the correct order. In this section, we establish a normal form theorem for our simple blockchain logic.\n\nDefinition 8: A _base formula_ is a formula that has one of the following forms (which include the case of no blockchain updates):\n\n1. \\([i_{1},A_{1}]\\ldots[i_{m},A_{m}]\\bot\\)2. \\([i_{1},A_{1}]\\ldots[i_{m},A_{m}]P\\) _with_ \\(P\\in\\mathcal{AP}\\cup\\mathcal{AQ}\\)__\n3. \\([i_{1},A_{1}]\\ldots[i_{m},A_{m}]\\Box B\\)__\n\n_Formulas in normal form are given as follows:_\n\n1. _each compliant base formula is in normal form_\n2. _if_ \\(F\\) _and_ \\(G\\) _are in normal form, then so is_ \\(F\\to G.\\)__\n\nRemark 6: As an immediate consequence of this definition, we obtain that for each formula \\(F\\),\n\nif \\(F\\) is in normal form, then \\(F\\) is compliant.\n\nThe following theorem states that for each formula, there is a provably equivalent formula in normal form.\n\nTheorem 4.1: _For each \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula \\(F\\), there is an \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula \\(G\\) in normal form such that \\(\\vdash F\\leftrightarrow G\\)._\n\nProof: We do an induction on the structure of \\(F\\) and distinguish the following cases:\n\n1. The cases when \\(F=\\bot\\), \\(F\\in\\mathcal{AP}\\cup\\mathcal{AQ}\\), or \\(F=\\Box B\\) are trivial.\n2. \\(F=G\\to H\\). By I.H., there are \\(G^{\\prime}\\) and \\(H^{\\prime}\\) in normal form such that \\(\\vdash G\\leftrightarrow G^{\\prime}\\) and \\(\\vdash H\\leftrightarrow H^{\\prime}\\). Hence for \\(F^{\\prime}:=G^{\\prime}\\to H^{\\prime}\\), we find \\(\\vdash F\\leftrightarrow F^{\\prime}\\) and \\(F^{\\prime}\\) is in normal form.\n3. \\(F=[i_{1},A_{1}]\\ldots[i_{k},A_{k}]G\\) with \\(G\\) not of the form \\([i_{k+1},A_{k+1}]G^{\\prime}\\). Subinduction on \\(G\\). We distinguish: 1. \\(G=\\bot\\), \\(G=P\\in\\mathcal{AP}\\cup\\mathcal{AQ}\\), or \\(G=\\Box B\\). In this case, \\(F\\) is a base formula. Using axiom (A6), we find a compliant base formula \\(F^{\\prime}\\) such that \\(\\vdash F\\leftrightarrow F^{\\prime}\\).\n2. \\(G=G^{\\prime}\\to G^{\\prime\\prime}\\). Then by axiom (A4) \\[\\vdash F\\leftrightarrow([i_{1},A_{1}]\\ldots[i_{k},A_{k}]G^{\\prime}\\to[i_{1},A_ {1}]\\ldots[i_{k},A_{k}]G^{\\prime\\prime}).\\] Moreover, by I.H., there are \\(H^{\\prime}\\) and \\(H^{\\prime\\prime}\\) in normal form such that \\[\\vdash H^{\\prime}\\leftrightarrow[i_{1},A_{1}]\\ldots[i_{k},A_{k}]G^{\\prime}\\] and \\[\\vdash H^{\\prime\\prime}\\leftrightarrow[i_{1},A_{1}]\\ldots[i_{k},A_{k}]G^{ \\prime\\prime}.\\] We find that \\(H:=H^{\\prime}\\to H^{\\prime\\prime}\\) is in normal form and \\(\\vdash F\\leftrightarrow H\\).\n\nCompleteness\n\nWe first show that \\(\\mathsf{BCL}\\) is complete for modal formulas. The modal language \\(\\mathcal{L}_{\\mathsf{M}}\\) consists of all update-free \\(\\mathcal{L}_{\\mathsf{B}}\\)-formulas. Formally, \\(\\mathcal{L}_{\\mathsf{M}}\\) is given by the following grammar\n\n\\[F::=\\bot\\ |\\ P\\ |\\ Q\\ |\\ F\\to F\\ |\\ \\Box A\\quad,\\]\n\nwhere \\(P\\in\\mathcal{AP}\\), \\(Q\\in\\mathcal{AQ}\\), and \\(A\\in\\mathcal{L}_{\\mathsf{cl}}\\).\n\nWe need the collection \\(\\mathsf{BCL}^{\\Box}\\) of all \\(\\mathsf{BCL}\\) axioms that are given in \\(\\mathcal{L}_{\\mathsf{M}}\\). The usual satisfaction relation for Kripke models is denoted by \\(\\models_{\\Box}\\).\n\nLemma 8: _For each \\(\\mathcal{L}_{\\mathsf{M}}\\)-formula \\(F\\) we have_\n\n\\[F\\text{ is valid \\quad implies \\quad}\\vdash F.\\]\n\nProof: We show the contrapositive. Assume \\(\\not\\vdash F\\). Since \\(F\\) is a modal formula, there is a Kripke model \\(\\mathsf{K}\\) with a world \\(w\\) such that\n\n\\[\\mathsf{K},w\\not\\models_{\\Box}F \\tag{11}\\]\n\nand\n\n\\[\\mathsf{K},w\\models_{\\Box}G\\qquad\\text{for all }G\\in BCL^{\\Box}. \\tag{12}\\]\n\nBased on the Kripke model \\(\\mathsf{K}\\), we construct an initial update model \\(\\mathsf{M}=(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\) as follows. Note that because of (12), we have \\(\\mathsf{K},w\\models_{\\Box}Qi\\to Qj\\) if \\(j<i\\). Let \\(k\\) be the least \\(i\\in\\mathbb{N}^{+}\\) such that \\(\\mathsf{K},w\\not\\models_{\\Box}Qi\\) if it exists and \\(k:=\\omega\\) otherwise. We set:\n\n1. \\(\\mathsf{I}:=\\{A\\in\\mathcal{L}_{\\mathsf{cl}}\\ |\\ \\mathsf{K},w\\models_{\\Box} \\Box A\\}\\);\n2. \\(\\mathsf{BC}:=\\begin{cases}\\langle\\top,\\ldots,\\top\\rangle\\text{ such that }\\mathsf{len}(\\mathsf{BC})=k-1&\\text{if }k<\\omega\\\\ \\langle\\top,\\top,\\ldots\\rangle&\\text{if }k=\\omega\\end{cases}\\)\n3. \\(\\mathsf{v}:=\\{P\\in\\mathcal{AP}\\ |\\ K,w\\models P\\}\\).\n\nThis definition of \\(\\mathsf{BC}\\) means that \\(\\mathsf{BC}\\) is an infinite sequence of \\(\\top\\) if \\(k=\\omega\\).\n\nFor each \\(\\mathcal{L}_{\\mathsf{M}}\\)-formula \\(G\\) we have\n\n\\[\\mathsf{K},w\\models_{\\Box}G\\quad\\text{if and only if}\\quad\\mathsf{M}\\models G. \\tag{13}\\]\n\nWe show (13) by induction on the structure of \\(G\\) and distinguish the following cases:1. \\(G=P\\in\\mathcal{AP}\\). Immediate by the definition of \\(\\mathsf{v}\\).\n2. \\(G=Qi\\in\\mathcal{AQ}\\). If \\(k=\\omega\\), we have \\(\\mathsf{K},w\\models_{\\Box}Qi\\) and, since \\(\\mathsf{len}(\\mathsf{BC})=\\omega\\), also \\(\\mathsf{M}\\models Qi\\). If \\(k<\\omega\\), we have \\(\\mathsf{K},w\\models_{\\Box}Qi\\) iff \\(i\\leq k-1=\\mathsf{len}(\\mathsf{BC})\\) iff \\(\\mathsf{M}\\models Qi\\).\n3. \\(G=\\bot\\). Trivial.\n4. \\(G=G_{1}\\to G_{2}\\). By induction hypothesis.\n5. \\(G=\\Box A\\). If \\(\\mathsf{K},w\\models\\Box A\\), then \\(\\mathsf{M}\\models\\Box A\\) by the definition of \\(\\mathsf{l}\\). If \\(\\mathsf{M}\\models\\Box A\\), then \\(\\mathsf{l}\\cup\\mathsf{set}(\\mathsf{BC})\\models A\\). By the definition of \\(\\mathsf{BC}\\), this is \\(\\mathsf{l}\\models A\\). Because \\(\\mathsf{l}\\) is deductively closed, we get \\(A\\in\\mathsf{l}\\), which yields \\(\\mathsf{K},w\\models\\Box A\\).\n\nBy (11) and (13) we conclude \\(\\mathsf{M}\\not\\models F\\) as desired. \n\nWe establish completeness for compliant formulas using a translation from compliant formulas to provably equivalent update-free formulas. We start with defining a mapping \\(h\\) that eliminates update operators.\n\nDefinition 9: The mapping \\(\\mathsf{h}\\) from \\(\\{[i,A]F\\mid F\\in\\mathcal{L}_{\\mathsf{M}}\\}\\) to \\(\\mathcal{L}_{\\mathsf{M}}\\) is inductively defined by:\n\n\\[\\mathsf{h}([i,A]\\bot) :=\\bot\\] \\[\\mathsf{h}([i,A]P) :=P\\quad\\text{for }P\\in\\mathcal{AP}\\] \\[\\mathsf{h}([i,A]Qi) :=\\mathsf{Acc}(i,A)\\lor Qi\\] \\[\\mathsf{h}([i,A]Qj) :=Qj\\quad\\text{for }Qj\\in\\mathcal{AQ}\\text{ and }i\\neq j\\] \\[\\mathsf{h}([i,A](F\\to G)) :=\\mathsf{h}([i,A]F)\\to\\mathsf{h}([i,A]G)\\] \\[\\mathsf{h}([i,A]\\Box B) :=(\\mathsf{Acc}(i,A)\\wedge\\Box(A\\to B))\\vee(\\neg\\mathsf{Acc}(i,A) \\wedge\\Box B)\\]\n\nThe mapping \\(\\mathsf{h}\\) corresponds to the reduction axioms of \\(\\mathsf{BCL}\\). Thus it is easy to show the following lemma by induction on the structure of \\(F\\).\n\nLemma 9: _Let \\(F\\) be an \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula of the form \\([i,A]G\\) such that \\(G\\in\\mathcal{L}_{\\mathsf{M}}\\). We have that \\(\\vdash F\\leftrightarrow\\mathsf{h}(F)\\)._\n\nWe define a translation \\(\\mathsf{t}\\) from \\(\\mathcal{L}_{\\mathsf{B}}\\) to \\(\\mathcal{L}_{\\mathsf{M}}\\)Definition 10: The mapping \\(\\mathtt{t}:\\mathcal{L}_{\\mathsf{B}}\\rightarrow\\mathcal{L}_{\\mathsf{M}}\\) is inductively defined by:\n\n\\[\\mathtt{t}(\\bot) :=\\bot\\] \\[\\mathtt{t}(P) :=P\\quad\\text{for }P\\in\\mathcal{AP}\\cup\\mathcal{AQ}\\] \\[\\mathtt{t}(F\\to G) :=\\mathtt{t}(F)\\rightarrow\\mathtt{t}(G)\\] \\[\\mathtt{t}(\\Box A) :=\\Box A\\] \\[\\mathtt{t}([i,A]F) :=\\mathsf{h}([i,A]\\mathtt{t}(F))\\]\n\nLemma 10: _For each compliant formula \\(F\\), we have_\n\n\\[\\vdash F\\leftrightarrow\\mathtt{t}(F).\\]\n\nProof: The proof is by induction on the structure of \\(F\\). There are two interesting cases.\n\n1. \\(F=G\\to H\\). By I.H. we find \\(\\vdash G\\leftrightarrow\\mathtt{t}(G)\\) and \\(\\vdash H\\leftrightarrow\\mathtt{t}(H)\\). Thus we have \\[\\vdash(G\\to H)\\leftrightarrow(\\mathtt{t}(G)\\rightarrow\\mathtt{t}(H)),\\] which yields the desired result by \\(\\mathtt{t}(G)\\rightarrow\\mathtt{t}(H)=\\mathtt{t}(G\\to H)\\).\n2. \\(F=[i,A]G\\). By I.H. we find \\(\\vdash G\\leftrightarrow\\mathtt{t}(G)\\). Since \\([i,A]G\\) is compliant by assumption, we can use \\((\\mathsf{SUB})\\) to infer \\([i,A]G\\leftrightarrow[i,A]\\mathtt{t}(G)\\). By Lemma 9, we know \\[\\vdash[i,A]\\mathtt{t}(G)\\leftrightarrow\\mathsf{h}([i,A]\\mathtt{t}(G)).\\] We finally conclude \\(\\vdash[i,A]G\\leftrightarrow\\mathsf{h}([i,A]\\mathtt{t}(G))\\), which yields the claim since \\[\\mathtt{t}([i,A]F)=\\mathsf{h}([i,A]\\mathtt{t}(F)).\\]\n\nTheorem 5.1: _For each compliant \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula \\(F\\) we have_\n\n\\[F\\text{ is valid \\quad implies \\quad}\\vdash F.\\]\n\nProof: Assume that \\(F\\) is a valid and compliant \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula. By Lemma 10, we know \\(\\vdash F\\leftrightarrow\\mathtt{t}(F)\\). Hence by soundness of \\(\\mathsf{BCL}\\), we get that \\(\\mathtt{t}(F)\\) is valid, too. Since \\(\\mathtt{t}(F)\\) is an \\(\\mathcal{L}_{\\mathsf{M}}\\)-formula, Lemma 8 yields \\(\\vdash\\mathtt{t}(F)\\). Using Lemma 10 again, we conclude \\(\\vdash F\\).\n\nCombining Theorem 3.1 and Theorem 3.2 easily yields completeness for the full language.\n\nTheorem 3.2: _For each \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula \\(F\\) we have_\n\n\\[F\\text{ is valid \\quad implies \\quad}\\vdash F.\\]\n\nProof: Assume \\(F\\) is a \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula that is valid. By Theorem 3.1, we find a compliant \\(\\mathcal{L}_{\\mathsf{B}}\\)-formula \\(G\\) such that\n\n\\[\\vdash F\\leftrightarrow G. \\tag{14}\\]\n\nHence by soundness of \\(\\mathsf{BCL}\\), we know that \\(G\\) is valid, too. Applying Theorem 3.2 yields \\(\\vdash G\\). We finally conclude \\(\\vdash F\\) by (14). \n\n## 7 Conclusion\n\nWe have presented \\(\\mathsf{BCL}\\), a dynamic logic to reason about a simple blockchain model. Our semantics does not have the full complexity of the blockchains used in Bitcoin or Ethereum, yet it exhibits two key properties of blockchains: blockchain extensions must preserve consistency and blocks may be received in the wrong order. Note, however, that although receiving blocks in the wrong order is an important logical possibility, it only happens rarely in practice: in the Bitcoin protocol the average generation time of a new block is 10 minutes; the average time until a node receives a block is only 6.5 seconds [6].\n\nIn order to illustrate the dynamics of our simple blockchain logic, we state some valid principles of \\(\\mathsf{BCL}\\) in the following example.\n\nExample 1: The following formulas are valid (and thus provable) in \\(\\mathsf{BCL}\\):\n\n**Persistence:**: \\(\\Box A\\to[i,B]\\Box A\\). Beliefs are persistent, i.e., receiving a new block cannot lead to a retraction of previous beliefs.\n**Consistency:**: \\([i,B]\\neg\\Box\\bot\\). Receiving a new block cannot result in inconsistent beliefs.\n**Success:**: \\(\\mathsf{Acc}(i,A)\\to[i,A]\\Box A\\). If a block \\([i,A]\\) is acceptable, then \\(A\\) is believed after receiving \\([i,A]\\).4\n\n**Failure:**: \\((Qi\\vee\\neg Q(i-1))\\rightarrow([i,B]\\Box A\\leftrightarrow\\Box A)\\). If the current length of the blockchain is not \\(i-1\\), then receiving a block \\([i,B]\\) will not change the current beliefs.\n\nProof:\n1. Persistence: \\(\\Box A\\rightarrow[i,B]\\Box A\\). Let \\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\) be an initial model and assume \\(\\mathsf{M}\\models\\Box A\\). That is \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC})\\models A\\). Let \\((\\mathsf{I},\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime},\\mathsf{v}):=\\mathsf{M} ^{[i,B]}\\). We find that \\(\\mathsf{set}(\\mathsf{BC})\\subseteq\\mathsf{set}(\\mathsf{BC}^{\\prime})\\). Therefore, \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC}^{\\prime})\\models A\\), hence \\(\\mathsf{M}^{[i,B]}\\models\\Box A\\) and \\(\\mathsf{M}\\models[i,B]\\Box A\\).\n2. Consistency: \\([i,B]\\neg\\Box\\bot\\). We let \\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\) be an initial model. Further, we set \\((\\mathsf{I},\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime},\\mathsf{v}):=\\mathsf{M} ^{[i,B]}\\). By Lemma 1 we know that \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC}^{\\prime})\\) is satisfiable, i.e., \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC}^{\\prime})\\not\\models\\bot\\). Hence we have \\(\\mathsf{M}^{[i,B]}\\models\\neg\\Box\\bot\\), which is \\(\\mathsf{M}\\models[i,B]\\neg\\Box\\bot\\).\n3. Success: \\(\\mathsf{Acc}(i,A)\\rightarrow[i,A]\\Box A\\). Let \\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\) be an initial model and assume \\(\\mathsf{M}\\models\\mathsf{Acc}(i,A)\\). Let \\((\\mathsf{I},\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime},\\mathsf{v}):=\\mathsf{M} ^{[i,A]}\\). By Lemma 2, we know \\(\\mathsf{BC}^{\\prime}=\\mathsf{BC}\\circ A\\). Thus \\(\\mathsf{I}\\cup\\mathsf{set}(\\mathsf{BC}^{\\prime})\\models A\\) and, therefore \\(\\mathsf{M}^{[i,A]}\\models\\Box A\\), which is \\(\\mathsf{M}\\models[i,A]\\Box A\\).\n4. Failure: \\((Qi\\vee\\neg Q(i-1))\\rightarrow([i,B]\\Box A\\leftrightarrow\\Box A)\\). Again, we let \\(\\mathsf{M}:=(\\mathsf{I},\\mathsf{BC},\\langle\\rangle,\\mathsf{v})\\) be an initial model and assume \\(\\mathsf{M}\\models Qi\\vee\\neg Q(i-1)\\). We find that \\(\\mathsf{M}\\not\\models\\mathsf{Acc}(i,B)\\). Indeed, \\[\\mathsf{M}\\models Qi\\text{ implies }\\mathsf{M}\\not\\models\\mathsf{Acc}(i,B)\\] and \\[\\mathsf{M}\\models\\neg Q(i-1)\\text{ implies }i>1\\text{ and }\\mathsf{M}\\not\\models\\mathsf{Acc}(i,B).\\] Let \\((\\mathsf{I},\\mathsf{BC}^{\\prime},\\mathsf{PU}^{\\prime},\\mathsf{v}):=\\mathsf{M} ^{[i,B]}\\). By Lemma 2, we know \\(\\mathsf{BC}^{\\prime}=\\mathsf{BC}\\). Therefore, \\(\\mathsf{M}^{[i,B]}\\models\\Box A\\) if and only if \\(\\mathsf{M}\\models\\Box A\\), which yields \\(\\mathsf{M}\\models[i,B]\\Box A\\leftrightarrow\\Box A\\). \n\nThere are still many open issues in epistemic blockchain logic. Let us mention three of them. First of all, although blockchains are called _chains_, the data structure that is actually used is more tree-like and there are different options how to choose the valid branch: Bitcoin simply uses the branch that has the greatest proof-of-work effort invested in it [18] (for simplicity we can think of it as the longest branch); but recent research shows that the GHOST rule [20] (used, e.g., in Ethereum [23]) provides better security at higher transaction throughput. We plan to extend BCL so that it can handle tree-like structures and the corresponding forks of thechain. In particular, this requires some form of probability logic to model the fact that older transactions have smaller probability of being reversed [10, 18, 20].\n\nOne of the purposes of blockchains is to provide a data structure that makes it possible to achieve common knowledge among a group of agents in a distributed system. Logics of common knowledge are well-understood [3, 9, 12, 17] and we believe that a fully developed blockchain logic should support multiple agents and common knowledge operators.\n\nIn a multi-agent setting, each agent (node) has her own instance of a blockchain. Justification logics [2] could provide a formal approach to handle this. Evidence terms could represent blockchain instances and those instances can be seen as justifying the agents' knowledge about the accepted transactions. This approach would require to develop new dynamic justification logics [4, 19, 15]. Moreover, if the underlying blockchain model supports forks of the chain, then we need justification logics with probability operators [13].\n\n## References\n\n* [1] Antonopoulos, A.M.: Mastering Bitcoin: Unlocking Digital Crypto-Currencies. O'Reilly Media, Inc. (2014)\n* [2] Artemov, S.N.: Explicit provability and constructive semantics. Bulletin of Symbolic Logic 7(1), 1-36 (Mar 2001)\n* [3] Brunnler, K., Studer, T.: Syntactic cut-elimination for common knowledge. Annals of Pure and Applied Logic 160(1), 82-95 (2009)\n* [4] Bucheli, S., Kuznets, R., Studer, T.: Realizing public announcements by justifications. Journal of Computer and System Sciences 80(6), 1046-1066 (2014)\n* [5] Buterin, V.: Ethereum: A next-generation smart contract and decentralized application platform (2013), [https://github.com/ethereum/wiki/wiki/White-Paper](https://github.com/ethereum/wiki/wiki/White-Paper), retrieved 2 Feb. 2017\n* [6] Decker, C., Wattenhofer, R.: Information propagation in the Bitcoin network. In: 13th IEEE International Conference on Peer-to-Peer Computing. pp. 1-10 (2013)\n* [7] van Ditmarsch, H., van der Hoek, W., Kooi, B.: Dynamic Epistemic Logic, Synthese Library, vol. 337. Springer (2007)\n* [8] van Ditmarsch, H., Kooi, B.: The secret of my success. Synthese 151(2), 201-232 (2006)\n* [9] Fagin, R., Halpern, J.Y., Moses, Y., Vardi, M.Y.: Reasoning about Knowledge. MIT Press (1995)\n* [10] Grunspan, C., Perez-Marco, R.: Double spend races. ArXiv e-prints 1702.02867 (2017)\n* [11] Herlihy, M., Moir, M.: Blockchains and the logic of accountability: Keynote address. In: Proceedings of the 31st Annual ACM/IEEE Symposium on Logic in Computer Science. pp. 27-30. LICS '16 (2016)* [12] Jager, G., Kretz, M., Studer, T.: Cut-free common knowledge. Journal of Applied Logic 5(4), 681-689 (2007)\n* [13] Kokkinis, I., Maksimovic, P., Ognjanovic, Z., Studer, T.: First steps towards probabilistic justification logic. Logic Journal of IGPL 23(4), 662-687 (2015)\n* [14] Kooi, B.: Expressivity and completeness for public update logics via reduction axioms. Journal of Applied Non-Classical Logics 17(2), 231-253 (2007)\n* [15] Kuznets, R., Studer, T.: Update as evidence: Belief expansion. In: Artemov, S.N., Nerode, A. (eds.) Logical Foundations of Computer Science, International Symposium, LFCS 2013, San Diego, CA, USA, January 6-8, 2013, Proceedings, Lecture Notes in Computer Science, vol. 7734, pp. 266-279. Springer (2013)\n* [16] Lamport, L., Shostak, R., Pease, M.: The byzantine generals problem. ACM Trans. Program. Lang. Syst. 4(3), 382-401 (1982)\n* [17] Meyer, J.J.C., van der Hoek, W.: Epistemic Logic for AI and Computer Science. Cambridge University Press (1995)\n* [18] Nakamoto, S.: Bitcoin: A peer-to-peer electronic cash system (2009)\n* [19] Renne, B.: Public communication in justification logic. Journal of Logic and Computation 21(6), 1005-1034 (Dec 2011), published online July 2010\n* [20] Sompolinsky, Y., Zohar, A.: Secure high-rate transaction processing in bitcoin. In: Bohme, R., Okamoto, T. (eds.) Financial Cryptography and Data Security: 19th International Conference, FC 2015, Revised Selected Papers. pp. 507-527. Springer Berlin Heidelberg, Berlin, Heidelberg (2015)\n* [21] Steiner, D.: A system for consistency preserving belief change. In: Artemov, S., Parikh, R. (eds.) Proceedings of Rationality and Knowledge. pp. 133-144. 18th European Summer School of Logic, Language and Information, Association for Logic, Language and Information (2006)\n* [22] Steiner, D., Studer, T.: Total public announcements. In: Artemov, S., Nerode, A. (eds.) Proceedings of Logical Foundations of Computer Science. LNCS, vol. 4514, pp. 498-511. Springer (2007)\n* [23] Wood, G.: Ethereum: A secure decentralised generalised transaction ledger, EIP-150 revision (2017), [https://ethereum.github.io/yellowpaper/paper.pdf](https://ethereum.github.io/yellowpaper/paper.pdf), retrieved 2 Feb. 2017"

Title: Managing Blockchain Systems and Applications: A Process Model for
  Blockchain Configurations
Transcription: "# Managing Blockchain Systems and Applications: A Process Model for Blockchain Configurations\n\nOlga Labazova\n\nUniversity of Cologne\n\nlabazova@wiso.uni-koeln.de\n\nFrol Kazan\n\nIT University of Copenhagen\n\nerka@itu.dk\n\nTujas Dehling\n\nKarlsruhe Institute of Technology\n\ndehling@kit.edu\n\nTuure Tuunanen\n\nUniversity of Jyvaskyla\n\ntuure.t.tuunanen@jyu.fi\n\nAli Sunyaev\n\nKarlsruhe Institute of Technology\n\nsunyaev@kit.edu\n\n###### Abstract\n\n_Blockchain is a radical innovation with a unique value proposition that shifts trust from institutions to algorithms. Still, the potential of blockchains remains elusive due to knowledge gaps between computer science research and socio-economic research. Building on information technology governance literature and the theory of coevolution, this study develops a process model for blockchain configurations that captures blockchain capability dimensions and application areas. We demonstrate the applicability of the proposed blockchain configuration process model on four blockchain projects. The proposed blockchain configuration process model assists with the selection and configuration of blockchain systems based on a set of known requirements for a blockchain project. Our findings contribute to research by bridging knowledge gaps between computer science and socio-economic research on blockchain. Specifically, we explore existing blockchain concepts and integrate them in a process model for blockchain configurations._\n\n## 1 Introduction\n\nIt will take years for blockchain systems to be fully adopted by businesses, but the journey has already begun (Iansiti and Lakhani, 2017). Blockchain is a radical innovation that has the potential to change the business logic for many industries. Blockchain's unique value proposition is the shift from institutional trust towards algorithmic consensus mechanisms (Beck and Muller-Bloch, 2017). Network nodes within blockchain systems process and record transactions within so-called blocks (Nakamoto, 2008). Blockchain systems have the advantage of removing single points of failure and improving data integrity and availability in contrast to centralized databases. To leverage the aforementioned features, organizations in different industries (e.g., finance, energy, healthcare) are considering to deploy blockchain systems to reduce intermediaries, decrease management costs, accelerate business processes, and tap into new revenue sources (Furlonger and Valdes, 2017).\n\nHowever, current blockchain projects are more akin to trial-and-error approaches than purposeful information systems development due to a lack of best practices for blockchain development and unclear long-term business value (Furlonger and Valdes, 2017; Beck and Muller-Bloch, 2017). In other words, most initiated blockchain projects are prone for failure orinefficient resource allocations. For instance, ninety-two percent of 26,000 blockchain projects launched in 2016, with a total investment volume of over $1.5 billion, are defunct or indefinitely delayed (Trujillo, Fromhart and Srinivas, 2017).\n\nThe main reasons for failure are either flawed system designs or incompatible application areas (Risius and Spohrer, 2017). To illustrate, the Jasper project by the Bank of Canada revealed that a blockchain system for wholesale payments is not competitive compared to centralized systems with regards to its operating costs (Chapman et al., 2017). The example illustrates that narrow-scoped blockchain prototypes exhibit issues with regards to technical scalability, resource efficiency, user traceability, or lacking protection against fraud (Yli-Huumo et al., 2016; Xu et al., 2017).\n\nThe existing literature on blockchain focuses either on technical aspects or use cases (Lindman, Tuunainen and Rossi, 2017; Notheisen, Hawlitschek and Weinhardt, 2017). For instance, technical studies explore various consensus mechanisms and cryptographic protocols, predominately focusing on financial transactions as an application case (e.g., Bitcoin). On the other hand, research on blockchain use cases have their foci on business applications such as energy trading (Rutkin, 2016), healthcare (Azaria, Ekblaw, Vieira and Lippman, 2016), or supply chain management (Glaser, 2017; Mendling et al., 2017). However, the aforementioned studies are predominantly idea-driven and exhibit challenges due to a lack of feasible technical solutions (Avital et al., 2016; Lindman et al., 2017; Beck et al., 2017). To develop successful proof of concepts for blockchain application areas, research on blockchain technology (i.e., technical aspects) and blockchain applications (i.e., business use cases) should be considered conjointly.\n\nWe build on information technology (IT) governance literature and apply the theory of coevolution of technologies and application areas1(Grodal, Gotsopoulos and Suarez, 2015) as a lens to explore coevolving blockchain configurations and application areas. Bridging knowledge about the technology underlying blockchains and their application areas will create conditions for developing successful blockchain-based systems (Iansiti and Lakhani, 2017).\n\nFootnote 1: By the term application areas we refer to the concept of categories as mentioned by Grodal et al. (2015).\n\nWe explore the current body of blockchain research and present our model in the form of a process model for blockchain configurations that captures blockchain capabilities, that is, routinized, repeatable, and application-specific processes, enabling businesses to transform resources into business value (Ray, Muhanna and Barney, 2005; Tallon, 2007). We answer the following research question: _What application areas are advisable for blockchain systems and how can blockchain systems be purposefully configured across application cases?_\n\nTo create the blockchain configuration process model, we systematically developed a taxonomy that groups blockchain application areas across mutually exclusive blockchain configurations (Nickerson, Varshney and Muntermann, 2013). The identified blockchain concepts and their relationships are consolidated in the blockchain configuration process model, which structures the blockchain concepts in four categories by semantic features and reciprocal relationships: (1) blockchain governance, (2) blockchain application areas, (3) blockchain properties, and (4) blockchain deployment. We illustrate the applicability of the proposed blockchain configuration process model on four selected blockchain projects.\n\nWith this research, we contribute to the extant research on blockchain by presenting a more granular and holistic view on identified blockchain concepts and their relationships. For practitioners, our proposed model offers guidance to managers to identify suitable blockchain systems and their corresponding application areas before development.\n\nThis paper proceeds as follows. In section 2, we discuss the theoretical aspects of IT governance and the theory of coevolution of technologies and applications. In section 3, we outline our three-step exploratory research approach for creating the blockchain configuration process model. In section 4, we present the blockchain configuration process model. In section 5, we illustrate the applicability of the blockchain configuration process model on four blockchain projects. In section 6, we discuss our findings, implications for theory and practice, and suggest avenues for future research.\n\n## 2 Theoretical Background\n\n### IT Governance\n\nIT governance can be defined as a collection of decision rights and accountabilities to encourage desirable behavior in the context of IT (Brown and Grant, 2005). Decision rights represent the governing control aspect over assets, whereas accountabilities capture the monitoring of decision-making processes. Incentives play a vital part in IT governance, because they motivate and guide agents to act favorably for the purposes of specific systems. Overall, the literature on IT governance discusses three basic governance approaches. First, centralized governance includes executive committees for decision-making and is characterized by having centralized business processes, providing control over architectures, and possessing formal assessments and monitoring decisions. Second, a decentralized approach to IT governance requires no or few governance mechanisms for decision-making and insists on local accountabilities (Brown and Magill, 1994; Schwarz and Hirschheim, 2003; Brown and Grant, 2005). Lastly,companies that aim to balance the benefits of the centralized and decentralized models follow a hybrid governance approach. These companies establish a centralized group to provide core services while allowing business units to control a portion of the overall functions (Boynton and Zmud, 1987; Rockart, 1988).\n\n#### 2.1.1 Blockchain Governance\n\nThe most successful blockchain systems will be those that adapt their governance to the organizational environments for business value creation (Kharitonov, 2017; Beck et al., 2018). Being introduced as a more or less decentralized data management solution, blockchain systems evolve continuously and are aligned with different IT governance approaches. Beck et al. (2018) specify decision rights as a dimension of blockchain centralization. Decision-making power can either be concentrated in few governing nodes or distributed equally among all nodes in the blockchain network. With regard to accountabilities, they differ in their rights to monitor decisions on blockchain systems, having the ability to adjust actions based on consequences incurred (Beck et al., 2018). In the same vein, different incentive schemes motivate agents to act within blockchain systems for monetary or non-monetary rewards.\n\n### Theory of Co-evolution of Technologies and Applications\n\nThe theory of coevolution of technologies and application areas during industry emergence focuses on mechanisms of their continuous coevolution, which starts with a period of divergence and continues with a period of convergence (Grodal et al., 2015). The period of divergence is characterized by high diversity in technology to address emerging application requirements. Technologies evolve and fulfill more application requirements through continuous design recombination. Application areas are influenced by a pool of ready-made technological designs, which in turn satisfy groups of application requirements. The following period of convergence results in consensus among producers with respect to efficient technological designs for mature application areas.\n\nThe blockchain domain is currently at an early stage of industry emergence and is characterized by a high diversity of technological designs and potential application areas (Lindman et al., 2017; Miscione, Ziolkowski, Zavolokina and Schwabe, 2018; Schlegel, Zavolokina and Schwabe, 2018). A variety of consensus mechanisms (Karame, Androulaki and Capkun, 2012) and anonymity schemes (Reid and Harrigan, 2013) produce various experimental solutions that are largely unrelated or opaque to emerging blockchain application cases (Yli-Huumo et al., 2016). Nevertheless, the number of blockchain application experiments are growing, leading to different blockchain-based services, such as supply chain management (Glaser, 2017; Mendling et al., 2017), energy trading (Rutkin, 2016), or authentication services (Miscione et al., 2018).\n\nIn turn, blockchain application cases are not fully supported by ready-made technological solutions (Risius and Spohrer, 2017). So far, extant research on blockchain systems yields isolated and unstructured concepts and offers only limited support for configuring blockchain systems for application areas.\n\n## 3 Research Approach\n\nOur research approach for developing the blockchain configuration process model comprises three consecutive steps (Figure 1). First, we explore blockchain concepts and their relationships through taxonomy development based on literature, business reports, and instantiated decentralized applications (Nickerson et al., 2013). Second, we structure the findings in the form of the blockchain configuration process model. Third, we illustrate the applicability of the blockchain configuration process model on four blockchain projects.\n\n### Taxonomy Development\n\nTo organize extant knowledge on blockchain, we employed the taxonomy development method proposed by Nickerson et al. (2013), who define a taxonomy as a set of dimensions. Each dimension consists of \"mutually exclusive and collectively exhaustive characteristics in a way that each object under consideration has one and only one characteristic in every dimension\" (Nickerson et al., 2013, p.5). The taxonomy development method proceeds in three stages. In the initial stage, a metacharacteristic and ending conditions are defined according to the purposes of the taxonomy to be developed. In the main stage, the taxonomy is developed. Objects to be classified with the taxonomy (in this study, application cases, dimensions, and characteristics) are identified during inductive or deductive iterations. During inductive iterations, empirical cases are analyzed to determine dimensions and characteristics for the taxonomy. During deductive iterations, dimensions and characteristics are derived from the existing scientific knowledge base. In the final stage, the taxonomy is evaluated against ending conditions.\n\nThe aim of the taxonomy is to derive and classify blockchain application areas and dimensions driven by blockchain characteristics. Therefore, we selected blockchain characteristics (e.g., consensus mechanism, anonymity level) as a metacharacteristic. The metacharacteristic serves as basis for identification of further dimensions and characteristics.\n\nFigure 1: Research Approach. The Blockchain Configuration Process Model\n\nWe developed the taxonomy in four iterations. The first three iterations were inductive iterations, where we identified application cases to derive dimensions and characteristics. For each inductive iteration, we used different types of sources: scientific literature, business reviews, and white papers of blockchain applications, respectively. The fourth iteration was a deductive iteration where we revised the taxonomy based on previous classifications of blockchain systems. _In the first iteration_, we searched papers and articles in the web of science core collection2 with the search string \"blockchain OR distributed ledger\" on October 17, 2016, in title, abstract, and keywords, covering the whole period of publications (Webster and Watson, 2002; Vom Brocke et al., 2009). The search returned fifty-one papers and articles. After screening the titles and abstracts, we discarded ten papers as non-blockchain research and coded the forty-one remaining relevant papers and articles. In the first iteration, we identified six dimensions with fourteen characteristics and six application areas with ten application cases. The analysis of the existing scientific literature revealed detailed information on separate blockchain characteristics (e.g., consensus mechanisms) or specific blockchain application examples (e.g., energy markets, prediction platforms) but lacked comprehensiveness.\n\nFootnote 2: Used indices: “Science Citation Index Expanded (1900-present), Social Sciences Citation Index (1900-present), Arts & Humanities Citation Index (1975-present), Conference Proceedings Citation Index- Science (1990-present), Conference Proceedings Citation Index- Social Science & Humanities (1990-present), Book Citation Index- Science (2005-present), Book Citation Index– Social Sciences & Humanities (2005-present), and Emerging Sources Citation Index (2015-present)”\n\n_In the second iteration_, we analyzed business reports, which provide less precise, but more comprehensive information. We investigated twenty business reports published by national agencies, consulting companies, and international institutions. We revised the taxonomy and added two dimensions, six characteristics, and one application case.\n\nTo fill the remaining gaps in the taxonomy, we reviewed eighty-six blockchain systems and applications (e.g., Bitcoin, Ethereum, Hyperledger) _in the third iteration._ If possible, we used the applications; otherwise, we read available documentation and white papers. During the third iteration, we added four new application cases.\n\n_The fourth iteration_ was deductive, where we derived characteristics, dimensions, and application cases from fifteen previous classifications. We used all previous classifications that we could identify in extant literature until October 2018. This analysis showed that our taxonomy is consistent with extant blockchain classifications.\n\nAll ending conditions proposed by Nickerson at al. (2013) were fulfilled after the fourth iteration. First, all found blockchain application cases described in the existing scientific literature or business reports can be classified with the taxonomy. Second, each dimension is unique and mutually exclusive and each characteristic is unique within its own dimension. Third, all application cases were classified with a single characteristic for each dimension. Fourth, the taxonomy is concise--consists only of dimensions that classify application cases. Fifth, the taxonomy is robust--differentiates each application case from all others. Sixth, the taxonomy is explanatory, comprehensive, and extensible--highlights the main features of each application case and can be extended when new application cases arise.\n\n### Consolidation of the Findings\n\nBased on the taxonomy development, we synthesized the findings into a process model for blockchain configurations. The model captures characteristics and application areas that are pertinent to blockchain systems. Specifically, the model is structured by four dimensions, which are distinct by their semantic features and reciprocal relationships: (1) blockchain governance, (2) blockchain application area, (3) blockchain properties, and (4) blockchain deployment. To synthesize blockchain concepts and investigate their relationships, we coded the data using three types of coding schemes--open coding, axial coding, and selective coding3 (Strauss and Corbin, 1990). We applied open coding for initial categorization of blockchain concepts; axial coding for removal of overlapping concepts while iteratively testing the blockchain concepts against the data, and selective coding to identify the relationships between concepts. One researcher coded the sources three times (November 2016, April 2017, November 2017) and another researcher validated the results after each iteration (Strauss, 1987). Disputes were resolved in group discussions.\n\nFootnote 3: Open coding is a process for grouping categories and subcategories (Strauss & Corbin, 1990, p.12). Axial coding is a process for testing “that categories are related to their subcategories, and the relationships against data” (Strauss & Corbin, 1990, p.13). Selective coding is a process “by which all categories are unified around a ‘core’ category, and categories that need further explication are filled-in with descriptive details” (Strauss & Corbin, 1990, p.14).\n\n## 4 The Blockchain Configuration Process Model\n\nBased on a set of known requirements of a blockchain project (i.e., blockchain governance, blockchain application area), the blockchain configuration process model (Figure 2) supports configuration of blockchain properties and selection of blockchain deployment attributes (i.e., processing and settlement of transactions).\n\nThe blockchain configuration process model proceeds in three steps. First, one chooses the suitable governance approach (decentralized, hybrid, or centralized) and the application area (i.e., financial transactions, enforcements, asset management, storage, communication, or ranking) that reflects the requirements of the blockchain project. Examples of blockchain applications are located at the intersection of blockchain governance and application area. Second, the proposed model identifies appropriate blockchain properties according to the selected application area (e.g., financial transactions). The blockchain properties are token (equity, utility), customizability (no, fixed, custom), data type (logs, assets), and history retention (whole, updates). Third, the blockchain configuration process model supports the blockchain deployment (i.e., processing and settlement) according to the selected blockchain governance approach (e.g., decentralized). The blockchain deployment attributes comprise access (i.e., private, public), validation (i.e., permissioned, unpermissioned), consensus mechanism (i.e., proof-of-work, proof-of-stake, Practical Byzantine Fault Tolerance, self-developed consensus mechanism), and the anonymity level (i.e., anonymous, pseudonymous, identifiable).\n\nAfter finishing the three steps, the blockchain configuration process model terminates. For complex blockchain projects that include different blockchain capabilities, the process can be reiterated.\n\n### Blockchain Governance\n\nThe blockchain configuration process model accounts for different approaches of IT governance--decentralized, hybrid, and centralized (Brown and Grant, 2005). _A decentralized approach to blockchain governance_ implies that all nodes in the network have decision rights and accountability rights. Bitcoin is an example of blockchains with decentralized governance. In the Bitcoin network, all participants hold rights to decide on the correct functioning of the system, whereas transparency of the data on blockchains allows all actors to monitor decisions (Nakamoto, 2008). Collectively governed companies or startups often require decentralized blockchain governance to spread decision rights and accountabilities among all actors in the network to reduce the network overload.\n\nBlockchains that are governed by a _hybrid governance approach_ allow only authenticated and predefined users to monitor decisions. However, ones a node is a part of the network, participation in decision-making requires no additional permissions. Ripple is an example of a blockchain with hybrid governance. In the Ripple network, predefined nodes are trusted organizations that deal directly with each other to support a peer-to-peer financial settlement system\n\nFigure 2: The Blockchain Configuration Process Model\n\n(Walsh et al., 2016). A hybrid approach to blockchain governance is useful for inter-organizational collaboration, where blockchains keep the network closed to ensure the confidentiality of the information, whereas the decision rights are distributed among all nodes in the network.\n\nA centralized approach to blockchain governance supports blockchains where nodes (usually only a small number of nodes) that have been authorized to validate transactions require additional authorization to have decision rights. An example for systems with centralized blockchain governance are IBM (Hyperledger) blockchains, which support regulatory and supervisory nodes to monitor the system (Hyperledger Architecture Working Group, 2017). Centralized blockchain governance is useful to support enterprise business projects, where a predefined number of users in the network, usually semi-trusted organizations or individuals, can monitor decisions while only few nodes have rights to validate transactions.\n\n### Blockchain Application Areas\n\nThe taxonomy yields six blockchain application areas, which comprise a total of fourteen application cases. Application areas group application cases with similar semantic features, for instance, usage scenarios, and with similar combinations of blockchain configurations. The first application area is _financial transactions_, which captures application cases concerned with money transfer and exchange. Anonymous and conventional cryptocurrencies, wealth storage, and micro-payments utilize blockchains with decentralized governance (e.g., Bitcoin, Primecoin, Namecoin, Zcash, and Darkcoin). Interorganizational cross-border and micro-financial transactions employ a hybrid approach to blockchain governance (e.g., Ripple, Stellar). Central-issued financial instruments are deployed on blockchains with centralized governance. For instance, RSCoin and Fedcoin projects (Koning, 2016) may allow federal states to independently launch coins.\n\nThe second application area of blockchains is _enforcement_. Enforcements ensure compliance with laws, regulations, rules, standards, or social norms through application logic (Beck et al., 2018). Blockchain-based enforcements between individuals can, for instance, be developed on the Ethereum platform, which supports a decentralized approach to blockchain governance. Interorganizational enforcements usually employ blockchains with hybrid governance, such as Ripple Codius, which allows executing enforcements between predefined organizations. Blockchains with centralized governance can be useful for deployment of centrally issued enforcements (e.g., R3 Corda). For example, UK Barclays Bank built a prototype on the R3 Corda platform that translates legal contracts into smart contracts, where all involved parties can monitor (but not decide) on amendments to the original smart contracts (Walsh et al., 2016).\n\nThe third application area is _asset management_ and concerned with management tasks such as authentication, know your customer services, luxury goods provenance, and control of business assets. The management of off-chain registered assets usually requires decentralized governance of blockchains. For example, a user can prove the ownership or verify the origin of an asset by keeping their labels on the Bitcoin blockchain (e.g., Colored Coins). To keep information confidential, interorganizational asset management (e.g., Everledger) applies hybrid blockchain governance. For enterprises, blockchains with centralized governance may be suitable for managing interorganizational assets. For example, Maersk and IBM introduce TradeLens, a platform for real-time access to shipping data and shipping documents that utilizes a Hyperledger-based blockchain.\n\nThe fourth application area is _storage_ and is concerned with keeping digital assets, such as certificates or music and video files, on blockchains (Kishigami et al., 2015). Blockchain-based decentralized storage is implemented on blockchains with decentralized governance, because it requires a high number of nodes to distribute the transaction load of the network. For instance, the Storj project leverages sharding to split encrypted data (Wilkinson et al., 2014). Blockchains with hybrid and centralized governance seem inappropriate for blockchain-based storage, because of extensive resource requirements for blockchain deployment and the availability of effective alternative solutions, such as decentralized storage services (Salviotti, de Rossi and Abbatemarco, 2018).\n\nThe fifth application area is _communication_. Messaging and IoT communication can be realized on blockchains with decentralized governance, because the content is intended for mass communication (e.g., Whisper; Unger et al., 2015). Communication systems based on blockchains with hybrid and centralized governance do not create additional value compared to peer-to-peer messengers such as Telehash, which are used by many decentralized services (e.g., IBM Adept).\n\nThe sixth application area is _ranking_ with a single application case. Global reputation & rating (e.g., Dennis and Owenson, 2016) is supported by blockchains with decentralized governance and allows a number of untrusted participants to create blockchain-based reputations. Blockchains with hybrid and centralized governance seem inappropriate for ranking, because of the availability of alternative solutions, for example, ranking based on peer-to-peer systems such as Gnutella (Salviotti et al., 2018).\n\n\n\n### Blockchain Properties\n\nBlockchain properties allow for configuration of blockchains according to application areas. We identify four important blockchain properties. _Token_ specify how transactions processed by a blockchain are represented. Equity tokens capture transfer of value between parties (e.g., Alice transfers 1 Bitcoin to Bob). Utility tokens are more elaborate and contain more extensive data and application logic. _Customizability_ captures a blockchain's ability to process application logic. No customizability indicates that the blockchain cannot handle application logic. Fixed customizability supports built-in configurations. If customizability is custom, blockchains support processing of application logic provided by users. _Data type_ focuses on the type of data shared between blockchain users. Logs imply an exchange of logs of executed transactions. Digital assets mean that the whole digital assets such as documents, messages, and video or music files, are exchanged. _History retention_ ascertains whether the whole blockchain, starting with a genesis block, or only its recent updates are kept and distributed between nodes.\n\nThe choice of blockchain properties depends on blockchain application areas. Everything that is primarily used for _financial transactions_ is based on equity tokens. Financial transactions require no customizability. For example, the Bitcoin scripting language is purposefully not Turing-complete (Walsh et al., 2016). Blockchains for financial transactions exchange logs of executed financial transactions and keep the whole transaction history (Nakamoto, 2008).\n\n_Enforcements_ are based on utility tokens (e.g., company stock ownership) (Beck et al., 2018). Enforcements are customized by smart contracts, which are executed across participants in the blockchain network (Peters, Panayi and Chapelle, 2015). Enforcements exchange logs of smart contracts and retrieve the whole history of logs for security reasons.\n\n_Asset management_ is based on utility tokens (e.g., data access). Fixed customizability allows users to use built-in configurations. Executed actions under the assets are represented by logs (e.g., access to assets, asset changes), which are continuously kept on the blockchain.\n\nBlockchain-based _storage_ is supported by utility tokens and provides for fixed customizability of blockchains. Storage blockchains keep digital assets. To improve scalability of blockchains, only recent updates of assets are stored. Users are more interested in the current state of the assets and not in their changes over time.\n\n_Communication_ employs utility tokens, fixed customizability of blockchains, and exchange of digital assets in the form of text messages. Blockchains keep the whole communication history (Pureswaran, Panikkar, Nair, & Brody, 2015; IBM Adept). However, application cases are far from the production stage.\n\n_Ranking_ uses utility tokens and allows for fixed customizability. Blockchains exchange logs of actions, usually reputation or rating scores, and keeps only recent updates of the transaction history, because outdated votes are not necessary for calculating reputation or rating and can be safely removed from blockchains (Dennis and Owenson, 2016).\n\n### Blockchain Deployment\n\nBlockchain deployment attributes depend on blockchain governance. We identified four blockchain deployment attributes. _Access_ represents the ability to read and submit data on a blockchain (Beck et al., 2018). Private access makes a blockchain available for reading and submitting data only to authorized users. Public access allows everyone to read data from and submit data to a blockchain. _Validation_ indicates different mechanisms for validating transactions on a blockchain. Permissioned validation means that only authorized users validate transactions and participate in consensus finding. If validation is unpermissioned, all users in the network validate transactions. _Consensus mechanism_ is concerned with mechanisms for reaching consensus on blockchain updates. Proof-of-work requires validating notes to spend resources (or work), usually processor time or storage space. Proof-of-stake requires users to proof the ownership of tokens to establish their stake in the blockchain. Practical Byzantine Fault Tolerance requires agreement by the majority of validating nodes (2/3 of validating nodes) for transaction validation. Self-developed consensus mechanisms usually include several highly trusted nodes for achieving system-level agreements. _Anonymity level_ assesses with what accuracy users can be matched to particular identities. If the characteristic is anonymous, users do not have to provide any identifying information to work with a blockchain. If the characteristic is pseudonymous, users have to work under a pseudonym. Blockchains with the characteristic identifiable ask for or automatically collect personally identifiable information such as email addresses or IP addresses.\n\n_A decentralized approach to blockchain governance_ implies public access to blockchains, which allows all participants in the network to monitor transactions. Unpermissioned validation invites all participants to participate in consensus finding. Proof-of-work or proof-of-stake consensus mechanisms ensure the correct functioning of the blockchain system in a network with a large number of untrusted nodes. Blockchains with decentralized governance support anonymity and pseudonymity of users.\n\n_A hybrid approach to blockchain governance_ requires private access to blockchains that makes a blockchain only available to authorized users. However, unpermissioned validation requires all users in the blockchain network to participate in consensus finding. The blockchainnetwork consists of a small number of trusted nodes that makes it possible to use energy-efficient but communication-heavy Practical Byzantine Fault Tolerance as consensus mechanism. Blockchains with hybrid governance frequently ask for name, surname, and email address (e.g., Hyperledger, Ripple) to make users identifiable.\n\nIn blockchains with _centralized governance_, private access allows only authorized users to monitor transactions. Permissioned validation allows only authorized users to validate transactions and participate in consensus finding. Often validating nodes find consensus based on resource-saving, self-developed mechanisms. Nodes in private-permissioned blockchains must be identifiable and trusted.\n\n## 5 Four Blockchain Projects\n\nWe illustrate the applicability and usefulness of the blockchain configuration process model on four blockchain projects: (1) DB Systel & IBM (public mobility), (2) LitSonar (academic literature tool), (3) dSCM Tool (data sharing between factories), and (4) Blockchain4openscience.org (portal for researchers).\n\nWe selected different types of blockchain projects that exhibit three different blockchain governance approaches (i.e., centralized, hybrid, and decentralized) and different application areas to demonstrate its analytical capabilities for identifying common and dissimilar configurations. We conducted four open-ended, semi-structured interviews with leading researchers, solution architects, or leading developers in September and October 2018. Interviews lasted between 46 and 85 minutes with an average duration of 58 minutes. The interviews were transcribed and coded using NVivo software. During the interviews, interviewees applied the blockchain configuration process model to their projects and discussed the usefulness of the blockchain configuration process model, blockchain concepts, and their relationships according to their blockchain project. In addition, we used secondary data sources to triangulate data and understand the relationship between blockchain concepts and actual use. We gathered 229 pages of interview transcriptions and secondary data (Table 1).\n\n\

Tuple 46:
Cleaned Title: framework blockchainbased application
Cleaned Transcription: framework blockchainbased applicationsnnephraim feignnieee life fellownn abstractnnblockchains recently generated explosive interest academia industry many proposed application description many proposal visionary projection realizable proposal even basic definition often missing define blockchain blockchain network discus two different well known class blockchain network cryptocurrencies git repository identify common primitive element use construct framework explicitly articulating characterizes blockchain network framework consists set question every blockchain initiative address outset intended help one decide whether blockchain appropriate approach particular application assist initial design stagenn introductionnnblockchain heralded foundational technology potential create new foundation economic social system people claim blockchain streamline electronic health record process add greater visibility efficiency across entire supply chain deliver higher value customer trading relationship track ownership real estate may disrupt insurance industry change way share data process claim prevent fraud could revolutionize internet thing nnthere explicit description blockchains cited application blockchains cryptocurrencies well understood satoshi nakamoto writes needed enable electronic transaction without relying trust complete immutable public record transaction design goal cryptocurrencies quite contrary cryptocurrency purist would prefer record strengthen identityhiding nakamoto wrote well known already accomplish without trusted party transaction must publicly announced public ledger price pay order enable cryptocurrency integritynnwhat exactly trust nakamoto referring paper online forum writesthe root problem conventional currency trust thats required make work central bank must trusted debase currency history fiat currency full breach trust bank must trusted hold money transfer electronically lend wave credit bubble barely fraction reserve trust privacy trust let identity thief drain accountsnnthe central bank fiat currency issue nakamoto bemoans pale comparison analogue cryptocurrency world anybody create cryptocurrency even established one fork whim creator bank abuse relative total currency volume pale comparison ponzi scheme cryptocurrency exchange draining account cryptocurrencies lose wide margin concern trust bank hold transfer fund genuine mostly case transfer prohibited legal authority big advantage cryptocurrencies offer identityhiding able cover track gain advantage bitcoin neededa blockchain proofofwork pow cost advantage today estimated kwh electricity consumed per transaction slow batchprocessing transaction plus loss standard payment service fraud protection loss recoverynnthe enormous cost operating bitcoin network recognized new type cryptocurrencies deployed deal use proofofstake po instead pow emerging ethereum expected implement version near future po add escrow component network bringing little closer standard payment system still bypassing central authority blockchains application currency go even conforming standard trust model permissionedblockchains suggested enterprise application participant need obtain invitation permission join access control mechanism could vary existing participant could decide future entrant regulatory authority could issue license participation consortium could make decision instead moving even trust averse system private network permissioned also restrict see blockchainnngit may successful blockchain platform operational decade popular version control system used primarily team development software used maintain set textbased record software power bitcoin developed git open source project every branch git repository blockchain commits block peer software developer maintain master branch repository git permissionbased consensus based trust mining proofofanything git blockchains opensource project visible public private repository restrict see themnnunlike bitcoin forking inadvertent uncommon event git branching modus operandi unlike bitcoin fork abandoned upon acceptance longest blockchain git branch frequently merged strikingly unlike bitcoin total aversion central authority even though git peertopeer system git project almost always used conjunction git hosting service github bitbucket perforce cloudforge nnpeople disagree whether git branch blockchains definition proposed new field consistent like approach term blockchain refers datastructure term blockchain network refers data structure deployed also want definition sufficiently broad include cryptocurrencies git branch operate totally different trust environmentsnndefinition blockchain sequence block data block first cryptographically linked predecessornncryptographic linking well understood specifying block cryptographically linked bitcoin linking described git linking nndefinition blockchain network peertopeer network peer collaborate achieve common goal using blockchainnnthe bitcoin system blockchain network git repository blockchain network master branch blockchain used collaboration git peer often fork blockchain creating new branch collaborate using master branch strive merge branch general insist peer maintain identical complete blockchains network maintain immutable blockchain though may common goal applicationsnnbackgroundnnbitcoin git blockchains fundamental data structure common block connected cryptographic hash fundamental difference presence absence proofofwork pow cryptographic hashing pow studied long time word blockchain introduced instructive see deployed ask sudden two combined generating much enthusiasmnnthe idea chaining block data together cryptographic hash around since late ralph merkles patent granted cryptographic protocol already evolving data structure named merkle tree found utility peertopeer system peer needed share identical data change data would quickly detected case change detected recourse change undone peer want change accept peer want change undo peer reach consensus diverge along distinct pathsnnthe bitcoin blockchain binary merkle tree every right branch contains one leaf considered sequence left right every bitcoin block store transaction data merkle tree therefore change easily detectable bitcoin transaction irreversible remedy double spend therefore preserve bitcoins integrity nakamoto introduce pow fortuitously pow also provided mechanism disseminating new bitcoins incentivizing peersnnpow introduced c dwork naor combat email spam generally pow used deter people undesirable thing making expensive pow proposed mitigate distributed denialofservice attack pow proposed provide incentive peertopeer system particular pow used bitcoin variant adam back hashcash proposed requires finding nonce yield hash leading snnuntil bitcoin pow gain significant traction study original proposed application spam prevention concluded pow work bitcoin thing changed user insisted payment system participant hide identity gain outweighed costsnn blockchain network dynamicsnnthe blockchain network cryptocurrencies git characterized following activitiesnn developer create deploy networknnonce network deployednn user input data networkn peer propose block add blockchainn peer validate proposed blocksn peer strive reach consensusnnthey also different two fundamental waysnn whether irreversible inputsn whether blockchain immutablennand case peer incentivized performnnwe see three type participant developer user peer developer play critical role part framework framework relates steadystate network operationalnnwith cryptocurrencies peer user user peer user input transaction receive payment interaction blockchain blockchain public everybody user looking however one use blockchain prove payment particular payee one force payee provide proof received payment whole class user analyze cryptocurrency blockchains catch illegal behavior money laundering tax evasion include u department dea fbi ice irs sec nnin git user enter data blockchain also peer input snippet code together create maintain desired code git user peer hide identity quite opposite seek recognition contribution another set user take code deploy itnnin bitcoin peer succeeds pow propose block comprising set transaction size limited bitcoin protocol bitcoin incentive peer validate block proposing network almost always even though peer working hard proof one get propose block rare case fork two peer propose block peer validate immediately afterwards peer start work proof peer succeeds proposes new block transaction one see enormous cost every cycle peer duplicate effort essentially wasteful necessary maintain integrity systemnnin git block commit data describing change made code change take form addition deletion code size limitation commit several peer may simultaneously submit block code working individually may added blockchainnnin bitcoin validation involves fixed deterministic set rule accomplished automatically without human intervention peer validate payer sufficient fund cover payment verify bitcoins used payment still circulation nakamoto pointed way confirm absence transaction aware transaction bitcoin peer need entire blockchainnnin git validation nuanced involves human activity fixed deterministic rule specify validity block new block proposed add master branch peer must check crash code order must entire code git peer need entire master branch peer guarantee block crash code say tested sufficiently comfortable proceeding forward bug later found somebody probably fix may also validate proposed code actually user wrote message part commit desirablennconsensus bitcoin automatic peer choose candidate blockchain greatest height bitcoin protocol pow guarantee long peer possessing majority hash power network validate truthfully asymptotically blockchain greatest height valid note majority hash power network majority peer necessary user trust bitcoin network consensus blockchain may fork peer may continue either branch forknnconsensus git automatic peer structured hierarchical authority may know converse often defer peer significant contribution git us interesting form po stake includes peer reputation permission level membership development team bitcoin consensus reached project may fork peer may continue choosennbitcoin transaction irreversible payment made recourse git user commits block subtle bug peer catch somebody fix bug later commit uncommon git eventnnthe bitcoin blockchain practically immutable git design one rewrite history nncryptocurrency peer incentivized mining reward transaction fee git peer opensource project rewarded getting code desire recognition closed project peer often salaried software developersnn frameworknnthe framework set question ask specific relating blockchain network dynamic used conceptual stage development blockchainbased applicationnnbegintabularppt hline user data user input input irreversible peer peer create block peer validate peer validate peer reach consensus blockchain immutable peer incentivized hline endtabularnnwho user user task current system handle well want something could done without blockchain primarily concerned data risk anticipating reduced cost performance expectation like transaction latency expect user access restriction blockchain one blockchain several class user several blockchains one class usersnnwhat data user input user enter blob large data set transactional data pointer blob stored elsewhere one blockchain several type transaction several blockchains particular type transactionnnare input irreversible potential liabilitiesnnwho peer become peer many peer necessary desirable number peer initial peer much trust amongst peer peer access restriction blockchain peer also peer blockchain networksnnhow peer create block many transaction contract whatever go block block formed block size limitation data block structured unstructured peer process data putting blocknnwhat peer validate peer validate data satisfies certain condition aside syntactical constraint andor proofofsomething validation deterministic peer sometimes make judgement callsnnhow peer validate information peer need order validate need blockchain able validate need entire blockchain peer communicate validationnnhow peer reach consensus trust model peer communicate consensus processnnis blockchain immutable potential liabilitiesnnhow peer incentivized peer compete reward user compete get peer service inputsnn discussionnnpeople recently become enamored avoiding reliance trust accurately think create distributed network untrusting peer trustworthy individual organization think complete history record even personal one public display identity hidden want contractual compliance obligation automatically validated without third party intervention see blockchain driving technology enabling thisnnas seen core technology behind blockchain known decade cryptographic linking data used peertopeer file sharing bittorrent data software distribution need proofofwork tampering could quickly detected dealt thing changed bitcoin double spending even detected immediately could undone bitcoin introduced novel twist combining cryptographic linking proofofwork percolating several year concept generating tremendous excitementnngit show blockchains successful environment trust make sense restrict definition blockchain particular trust model different trust model lead different validation consensus protocol open source project hosted github provide example trustbased consensus practice example see instruction prospective peer relating consensus bitcoin core contrast instruction peer git platform software nnwhen designing business application one ask application fraud accidental error happen many case hardly ever happen data stored typically happen data entry case validation may require level trust example supplychain application peer actually present transaction occur like box loaded truck validate data entered true record happenednnimmutability requirement almost currently proposed blockchains liability example public blockchain secret key compromised immutable record associated key permanently exposed standard system password compromised record associated password exposed password changed relaxing requirement immutability may appropriate choice blockchainbased applicationsnnirreversibility considered advantage certain application also liability bitcoin payer even use blockchain prove payee bitcoin owner loses private key coin associated permanently lost equivalent passwordreset bitcoin estimated million bitcoins already lost forever nnconclusionnnblockchainbased application cryptocurrencies git early stage clearly enormous enthusiasm explore create foresee spectrum trust model evolving blockchain network validation consensus protocol corresponding defined blockchains blockchain network expanding usual definition requiring immutability looked two motivating example polar opposite trust model bitcoin git considering common property created framework compel concreteness discussing proposed blockchainbased application guide early design stagesnn referencesnn httpshbrorgthetruthaboutblockchainhttpshbrorgthetruthaboutblockchainn httpswwwwiredcommovingpatientdatamessyblockchainhelphttpswwwwiredcommovingpatientdatamessyblockchainhelpn httpswwwibmcomblockchainsupplychainhttpswwwibmcomblockchainsupplychainn httpswwwfastcompanycomwillblockchainrevolutionizeglobalrealestatenexthttpswwwfastcompanycomwillblockchainrevolutionizeglobalrealestatenextn httpswwwfastcompanycomwillblockchainrevolutionizeglobalrealestatenexthttpswwwfastcompanycomwillblockchainrevolutionizeglobalrealestatenextn httpswwwforbescomsitesdelltechnologieshowblockchaincouldrevolutionizetheinternetofthihttpswwwforbescomsitesdelltechnologieshowblockchaincouldrevolutionizetheinternetofthin httpsbitcoinorgbitcoinpdfhttpsbitcoinorgbitcoinpdfn w dai bmoney httpwwwweidaicombmoneytxthttpwwwweidaicombmoneytxt n httpppfoundationningcomforumtopicsbitcoinopensourcehttpppfoundationningcomforumtopicsbitcoinopensourcen httpscoinmarketcapcomhttpscoinmarketcapcomn httpfortunecombitcoincashbchhardforkblockchainusdcoinbasehttpfortunecombitcoincashbchhardforkblockchainusdcoinbasen httpswwwtheatlanticcomtechnologyarchivecryptocurrencyponzischemeshttpswwwtheatlanticcomtechnologyarchivecryptocurrencyponzischemesn httpswwwbenzingacomfintechbiggestcryptocurrencyhacksinhistoryhttpswwwbenzingacomfintechbiggestcryptocurrencyhacksinhistoryn httpswwwinccomwillyakowiczstartupslawenforcementagenciescatchcriminalswhousecryptocurrencyhttpswwwinccomwillyakowiczstartupslawenforcementagenciescatchcriminalswhousecryptocurrencyn httpsdigiconomistnetbitcoinenergyconsumptionhttpsdigiconomistnetbitcoinenergyconsumptionn httpswwwposlistorghttpswwwposlistorgn httpsarxivorgpdfvpdfhttpsarxivorgpdfvpdfn httpshackernooncomwhatisproofofstakeehttpshackernooncomwhatisproofofstakeen httpswwwibmcomblogsblockchainthedifferencebetweenpublicandprivateblockchainhttpswwwibmcomblogsblockchainthedifferencebetweenpublicandprivateblockchainn httpsoctoversegithubcomhttpsoctoversegithubcomn httpsgithubcombitcoinbitcoinhttpsgithubcombitcoinbitcoinn httpswwwgittowercombloggithostingservicescomparedhttpswwwgittowercombloggithostingservicescomparedn httpsstackoverflowcomquestionswhyisgitnotconsideredablockchainhttpsstackoverflowcomquestionswhyisgitnotconsideredablockchainn httpsnewsycombinatorcomitemidhttpsnewsycombinatorcomitemidn httpsmediumcomshemmonisagitrepositoryablockchaincbcdchttpsmediumcomshemmonisagitrepositoryablockchaincbcdc httpswwwredditcomrbitcoincommentssxisgitablockchaindomainstowersaysyeshttpswwwredditcomrbitcoincommentssxisgitablockchaindomainstowersaysyesn w wang et al decentralized caching content delivery based blockchain game theoretic perspective httpsarxivorgpdfpdfhttpsarxivorgpdfpdfn httpsenwikipediaorgwikilinkedtimestampinghttpsenwikipediaorgwikilinkedtimestampingn httpsbitcoinorgendeveloperreferenceblockheadershttpsbitcoinorgendeveloperreferenceblockheadersn httpsgistgithubcommasakhttpsgistgithubcommasakn method providing digital signature u patent ralph c merkle filed granted httpspatentsgooglecompatentushttpspatentsgooglecompatentusn ralph c merkle protocol public key cryptosystems ieee symp security privacy oakland ca httpwwwmerklecompapersprotocolspdfhttpwwwmerklecompapersprotocolspdfn httpsenwikipediaorgwikimerkletreehttpsenwikipediaorgwikimerkletreen httpsbrilliantorgwikimerkletreehttpsbrilliantorgwikimerkletreen crypto lncs springer verlag pp httpwwwwisdomweizmannacilhttpwwwwisdomweizmannacilsimnaorpaperspvppsn mankins r krishnan c boyd j zao frentz mitigating distributed denial service attack dynamic resource pricing proc th annual computer security application conference acsas n serjantov lewis puzzle pp system th cab ernet radical work shop corsica oct httpswebeecsumicheduhttpswebeecsumichedusimzmaoeecspapersserjantovpdfn httpwwwhashcashorgpapersannouncetxthttpwwwhashcashorgpapersannouncetxtn httpswwwclcamacukhttpswwwclcamacuksimrncproofworkpdfn httpswwwethnewscomsixusgovernmentagencieshireinvestigativeblockchainfirmchainalysishttpswwwethnewscomsixusgovernmentagencieshireinvestigativeblockchainfirmchainalysisn httpsenbitcoinitwikiprotocolruleshttpsenbitcoinitwikiprotocolrulesn httpsgitscmcombookenvgittoolsrewritinghistoryhttpsgitscmcombookenvgittoolsrewritinghistoryn httpsenwikipediaorgwikibittorrenthttpsenwikipediaorgwikibittorrentn httpsenwikipediaorgwikicodesigninghttpsenwikipediaorgwikicodesigningn httpsgithubcombitcoinbitcoinblobmastercontributingmdhttpsgithubcombitcoinbitcoinblobmastercontributingmdn httpsgithubcomgitgitblobmasterdocumentationsubmittingpatcheshttpsgithubcomgitgitblobmasterdocumentationsubmittingpatchesn httpfortunecomlostbitcoinshttpfortunecomlostbitcoins title selecting reliable blockchain peer via hybrid blockchain reliability prediction transcription selecting reliable blockchain peer via hybrid blockchain reliability predictionnnpeilin zhengnnsun yatsen universitynnguangzhou china zhengplmailsysueducnnnzibin zhengnnsun yatsen universitynnguangzhou china zibinzhengyeahnetnnliang chennnsun yatsen universitynnguangzhou china jasonckgmailcomnn abstractnnblockchain blockchainbased decentralized application attracting increasing attention recently public blockchain system user usually connect thirdparty peer run peer join pp blockchain network however connecting unreliable blockchain peer make user waste resource even lose million dollar cryptocurrencies order select reliable blockchain peer urgently needed evaluate predict reliability faced problem propose hbrp hybrid blockchain reliability prediction model extract blockchain reliability factor make personalized prediction user largescale realworld experiment conducted blockchain requester blockchain peer implement dataset test case released experimental result show proposed model obtains better accuracy approachesnn acmcopyright acmcopyright acmcopyright nn warning truncated repetitionsn acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyright acmcopyrightnnnin paper propose hybrid collaborative reliability prediction model blockchain system called hbrp hbrp predict success rate blockchain peer directly main idea hbrp extract blockchainrelated factor request history eg block hash block height us relationship similar blockchain user peer collaborative prediction hybrid linear regression way hbrp obtains personalized prediction result different user higher accuracy approach realworld experiment show shown figure deploy blockchain requester evaluate predict reliability realworld blockchain peer showing feasibility effectiveness modelnnin summary main contribution paper summarized followsnn propose hbrp hybrid blockchain reliability prediction model blockchain system model extract blockchain factor related reliability us relationship similar user peer personalized predictionn conduct realworld experiment test case requester blockchain peer shown figure result show effectiveness proposed model implement dataset opensourcennthe rest paper organized follows section introduces basic concept blockchain system section describes motivating example reliability prediction blockchain system section proposes detail hybrid blockchain reliability prediction model including data processing training prediction section introduces implement hbrp experiment result section provides related work discussion blockchain reliability section concludes paper give future worknn basic conceptsnnthis section introduces basic concept blockchain decentralize applicationnnin narrow sense blockchain kind data structure concept blockchain firstly proposed underlying storage peertopeer payment bitcoinbleader shown figure every block contains transaction period time every block joint chainlike data structure named blockchain peer peertopeer network maintains blockchain keep via consensus protocol block hash value hash value contained next block make tamperresistant traceablennin wide sense blockchain regarded new kind distributed system basic concept blockchain listed followsnn transaction transaction represents message change ledger transferring cryptocurrencies someone want send bitcoin others broadcast transaction pp networkn block block data package consists transaction period time block hash value self bleader bleader bleader hash value used check authenticity blockn chain chain consists block linked hash bitcoin blockchainbleader every block generated previous one record hash previous block chainlike structure shown figure n mining public blockchain system receive previous block peer try find nonce next block get reward bitcoin process called mining peer called minersn decentralized application blockchainbased decentralized application dapp use blockchain underlying technology bleader bleader bleader bleader dapp user connect thirdparty peer get blockchain data figure show different thirdparty blockchain peer dapps user connect unreliable peer dapp would worknnin summary blockchain growing chainlike data structure maintained peer pp network peer pp network want get latest socalled highest correct block therefore blockchain peer reliable return latest block requestersnnfigure different thirdparty blockchain peer dappsnnfigure data structure blockchainbleader nnnn motivating examplennin section motivating example blockchain reliability prediction given blockchain user choose either run blockchain peer use thirdparty peer interact blockchain system shown figure matter user run peer select blockchain peer connect challenge peer online time test see one reliable influence reliability blockchain peer divided two fold blockchain mining blockchainbased application usernn blockchain miningnnthe premise blockchain mining user get latest previous block user connects peer low reliability get previous block time user waste computing resource computing wrong block without reward cryptocurrencies improve block synchronization speed economic benefit vital evaluate predict reliability blockchain peersnn blockchainbased application usernnassumed user figure like blockchainbased application user connect thirdparty blockchain peer need select reliable one since unreliable peer cause consequence example one famous wallet cryptocurrencies called imtoken reported fail sync ethereum network brock et al moment user think wrongly transaction confirmed network send repeated transaction cause loss moneynnthus really important blockchain user know blockchain peer reliable avoid loss cryptocurrencies improve experience blockchainnnand reality user connect blockchain peer meanwhile mean lot peer unknown reliability thus necessary predict unknown reliability blockchain peersnnin summary motivation paper evaluate predict reliability blockchain peer help select reliable peer improve blockchain synchronization speed avoid loss money improve experience blockchainnn methodologynnin section methodology hybrid blockchain reliability prediction model introduced including architecture step detailsnn architecturennthe architecture blockchain reliability prediction shown figure consists major role followsnn blockchain peer blockchain peer node maintaining blockchain pp networkn blockchain requester requester node installed hbrp data collecting program randomly request blockchain data peer period time requester considered user blockchain systemsn data collector predictor data collector central server collecting test case blockchain requester data used evaluate predict reliability blockchain systemsnnthe main idea architecture user contribute blockchain request history central data collector collector summarize historical data personalized reliability prediction user peer shown figure step hybrid blockchain reliability prediction block request testing upload test case reliability prediction select reliable peersnnfigure motivating example blockchain reliability predictionnnfigure architecture blockchain reliability predictionnn block request testingnnin period time requester one blockchain peer candidate connect knowing candidate reliable requester need connect however limited network condition requester request candidate meantime therefore hbrp proposes random batch block request testing blockchain peersnnthe random batch request testing include several stage followsnn given batch size mathbfn time period mathbft secondsn time period requester selects mathbfn candidate list randomlyn requester request latest block selected candidate par record height hash local storagenn upload test casesnnafter stage requester achieves raw data tuple clientip batchtime peerip starttime endtime height blockhash example shown table particular hbrp record batchtime compare test case sent time see one return higher block hbrp also record starttime endtime see long roundtrip time every test case hbrp record height blockhash order backtrack whether peer return correct blocknnwhen enough test case requester choose upload test case collector test case requester contribute collector accurate reliability prediction donenn reliability predictionnnafter receiving enough test case user collectorpredictor choose different predicting model reliability prediction user peer reliability prediction key step whole architecture shown figure hbrp model includes three substeps hbrp matrix generationcollaborative prediction hybrid trainingprediction detailed model implement proposed next subsection main idea itnn hbrp matrix generation substep regarded data preprocessing hbrp proposes factor related blockchain reliability transfer data list test case metric substep factor extracted requesterpeer matrixn collaborative prediction since blockchain peer show different network delay different user reliability observed different user could different case study section show difference therefore necessary model personalized prediction different user attack problem substep find similar blockchain user peer predict unknown reliability factor themn hybrid trainingprediction hbrp assumed mapping reliability factor extracted previous substeps thus reliability predicted based prediction related factor substep hbrp first train linear regression model using known reliability factor hbrp us model predicted factor reliability predictionnnsincerely directly predicting reliability without extracting factor could chosen direct reliability prediction make lose lot valuable information source data hbrp extract factor test case collaborative prediction finding similar blockchain userspeersnnin summary key idea maximize use available information blockchain feature user similarity detailed model propose next subsectionnn select reliable peersnnbased personalized reliability prediction result user choose blockchain peer reliability blockchainbased application user reliable peer chosen blockchain miner choose top k peer ranked predicted reliabilitynn hybrid block reliability prediction modelnnin subsection detail hybrid block reliability prediction model described shown figure nn blockchain factor matrix generationnnafter finishing block request testing data collector use request data generate blockchain factor matrixnnfirst set blockstolerance value maxblockback represent max tolerance block backwardness peer blockchain set timetolerance value maxrtt represent max roundtrip time peernnthe success rate matrix generated follownnfor requester mathbfri peer mathbfpj set success counter reliable request textbfsuccessrequestij failure counter textbffailurerequestijnnnext backtrack batch block request peer peer response successfully itnn return right block block hash right corresponding block height main blockchainn return recent block height block height subtracted highest one batch maxblockback maxblockback set requires peer reliable return highest block batchn return time roundtrip time request peer maxrttnnif blockchain peer pj response successfully batch count textbfsuccessrequestij otherwise textbffailurerequestij success rate requester ri peer pj calculated nntotalrequestijtextbfsuccessrequestijtextbffailurerequest ij tagnntextbfsuccessrateijfractextbfsuccessrequestijtotal textbfrequestij tagnnafter matrix success rate achieved shown figure gray area known success rate yellow area unknown success rate needed predict research service computing use success rate failurerate predict unknown entry matrix predict reliability service however blockchain reliability would lose information source data take blockchain factor account therefore hbrp generates three matrix corresponding three blockchain related factorsnn right block matrix right block matrix reflects rate pj return correct block ri generated following equation rightblockijfracrightblockrequestijtotalrequestij rightblockrequestij counter request return right block pj rin recent height matrix recent height matrix reflects rate pj return recent height ri generated following equation recentheightijfracrecentheightrequestijtotalrequestij recentheightrequestij counter request return recent height pj rin roundtrip time matrix roundtrip time matrix reflects average roundtrip time block request pj ri generated following equation roundtriptimeijfracsumkrttijktotalrequestij rttijk roundtrip time request ri pj batch knnin summary phase hbrp generates one success rate matrix three blockchain related factor matrix main idea matrix generation extract information related blockchain source data thus prediction using data accuratenn collaborative predictionnnafter generating matrix rightblock matrix recentheight matrix roundtriptime matrix used three collaborative filtering model target predict missing value blank matrix shown figure target step predict factor assumed three event right block recent height time corresponding matrix independent thus every factor matrix predicted following phase independentlynnsimilarity calculationnn
Original Title: A Framework for Blockchain-Based Applications
Original Transcription: "# A Framework for Blockchain-Based Applications\n\nEphraim Feig\n\nIEEE Life Fellow\n\n###### Abstract\n\nBlockchains have recently generated explosive interest from both academia and industry, with many proposed applications. But descriptions of many these proposals are more visionary projections than realizable proposals, and even basic definitions are often missing. We define \"blockchain\" and \"blockchain network\", and then discuss two very different, well known classes of blockchain networks: cryptocurrencies and Git repositories. We identify common primitive elements of both and use them to construct a framework for explicitly articulating what characterizes blockchain networks. The framework consists of a set of questions that every blockchain initiative should address at the very outset. It is intended to help one decide whether or not blockchain is an appropriate approach to a particular application, and if it is, to assist in its initial design stage.\n\n## 1 Introduction\n\nBlockchain has been heralded as \"a foundational technology: It has the potential to create new foundations for our economic and social systems\"[1]. People claim that blockchain will streamline the electronic health records process [2]; will \"add greater visibility and efficiency across the entire supply chain to deliver higher value to your customers and trading relationships\"[3]; will track ownership of real estate [4]; may \"disrupt the insurance industry and change the way we share data, process claims and prevent fraud\"[5]; \"could revolutionize the Internet of Things\" [6].\n\nThere are no explicit description of the blockchains in the cited applications. But the blockchains of cryptocurrencies are well understood. As Satoshi Nakamoto writes [7], they are needed to enable \"electronic transactions without relying on trust.\" A complete, immutable public record of transactions is not a design goal in cryptocurrencies. Quite the contrary, cryptocurrency purists would prefer no record at all, to strengthen identity-hiding. Nakamoto wrote that, as was well known already [8], \"To accomplish this without a trusted party, transactions must be publicly announced.\" The public ledger is the price to pay in order to enable cryptocurrency with integrity.\n\nWhat exactly is the trust that Nakamoto was referring to in his paper? In an online forum [9] he writes,\"The root problem with conventional currency is all the trust that's required to make it work. The central bank must be trusted not to debase the currency, but the history of fiat currencies is full of breaches of that trust. Banks must be trusted to hold our money and transfer it electronically, but they lend it out in waves of credit bubbles with barely a fraction in reserve. We have to trust them with our privacy, trust them not to let identity thieves drain our accounts.\"\n\nThe central bank and fiat currencies issues that Nakamoto bemoans pale in comparison to their analogues in the cryptocurrency world. Anybody can create a cryptocurrency (there are over 1,500 of them [10]) and even the most established ones will fork at the whims of their creators [11]. As for banks' abuses, relative to total currency volume, they pale in comparison to Ponzi schemes by cryptocurrency exchanges [12]. As for draining accounts, cryptocurrencies lose by a wide margin [13]. The concern that we have to trust banks to hold and transfer funds is genuine, but mostly in cases where the transfer is prohibited by some legal authority. The big advantage cryptocurrencies offer is identity-hiding, and only to those who are able to cover their tracks [14]. To gain this advantage, Bitcoin neededa blockchain with proof-of-work (PoW). The cost for this advantage today (3/1/2018) is estimated at 791 KWh of electricity consumed per transaction [15], slow batch-processing of transactions, plus the loss of such standard payment services as fraud protection and loss recovery.\n\nThe enormous costs of operating the Bitcoin network are recognized, and new types cryptocurrencies are being deployed to deal with them. Those that use proof-of-stake (PoS) instead of PoW are emerging [16], and Ethereum is expected to implement its version [17] in the near future. PoS adds an escrow component to the network [18], bringing it a little closer to standard payment systems, while still bypassing central authority. Blockchains for applications other than currencies go even further in conforming to standard trust models. Permissioned-blockchains have been suggested for enterprise applications, in which \"participants need to obtain an invitation or permission to join. The access control mechanism could vary: existing participants could decide future entrants; a regulatory authority could issue licenses for participation; or a consortium could make the decisions instead.\"[19] Moving even further from trust averse systems, we have private networks that are not only permissioned but also restrict who can see the blockchain.\n\nGit may be the most successful blockchain platform [20] and has been operational over a decade. It is the most popular version control system. While it is used primarily for team development of software, it can be used to maintain any set of text-based records. The software that powers Bitcoin is developed on Git [21] as an open source project. Every branch of a Git repository is a blockchain with commits as blocks. Peers are software developers, and they all should maintain the master branch of the repository. Git is permission-based, and consensus is based on trust; there is no mining or proof-of-anything. Git blockchains of open-source projects are visible to the public; private repositories restrict who can see them.\n\nUnlike Bitcoin, where forking is an inadvertent, uncommon event, with Git, branching is modus operandi. Unlike Bitcoin, where forks are abandoned upon acceptance of a longest blockchain, in Git, branches are frequently merged. And strikingly, unlike Bitcoin, where there is total aversion to central authority, even though Git is a peer-to-peer system, Git projects are almost always used in conjunction with some Git hosting service such as GitHub, Bitbucket, Perforce or CloudForge [22].\n\nPeople disagree whether or not Git branches are blockchains [23, 24, 25, 26] because there have been only few definitions proposed in this new field, and these have not been consistent. We like the approach in [27], where the term \"blockchain\" refers to a data-structure, and the term \"blockchain network\" refers to how that data structure is deployed. We also want the definitions sufficiently broad so as to include cryptocurrencies and Git branches, which operate in totally different trust environments.\n\n**Definition:** A _blockchain_ is a sequence of blocks of data in which each block, other than the first, is cryptographically linked to its predecessor.\n\nCryptographic linking is well understood [28]. We are not specifying how the blocks are cryptographically linked. Bitcoin linking is described in [29] and Git linking in [30].\n\n**Definition:** A _blockchain network_ is a peer-to-peer network in which peers collaborate to achieve a common goal by using a blockchain.\n\nThe Bitcoin system is a blockchain network. A Git repository is a blockchain network, with the master branch as the blockchain used in collaboration. While Git peers often fork the blockchain by creating new branches, they collaborate using the master branch and strive to merge their other branches with it. In general, we do not insist that peers all maintain identical or complete blockchains, or that the network maintain an immutable blockchain, though these may be the common goal in some applications.\n\nBackground\n\nBitcoin and Git blockchains have a fundamental data structure in common- blocks connected by cryptographic hashes- and a fundamental difference- the presence or absence of proof-of-work (PoW). Both cryptographic hashing and PoW have been studied a long time before the word blockchain was introduced. It is instructive to see how they were deployed and then ask, why all of a sudden, the two of them combined are generating so much enthusiasm?\n\nThe idea of chaining blocks of data together with cryptographic hashes has been around since the late 1970's. By 1982, when Ralph Merkle's patent [31] was granted, cryptographic protocols were already evolving [32]. The data structure named after him, the Merkle Tree, found utility in peer-to-peer systems in which peers all needed to share identical data [33, 34]. Any change in the data would be very quickly detected. In most cases, when a change is detected, there is recourse, the change can be undone. Peers who want the change can accept it; peers who do not want the change, can undo it. If peers cannot reach consensus, they can diverge along distinct paths.\n\nThe Bitcoin blockchain is a binary Merkle Tree in which every right branch contains only one leaf, considered as a sequence from left to right. Every Bitcoin block stores transaction data as a Merkle Tree. Therefore, any change is easily detectable. But a bitcoin transaction is irreversible, and there is no remedy to a double spend. Therefore, to preserve Bitcoin's integrity, Nakamoto had to introduce PoW. Fortuitously, PoW also provided the mechanism for disseminating new bitcoins and incentivizing peers.\n\nPoW was introduced by C. Dwork and M. Naor in 1992 [35] to combat email spam. More generally, PoW can be used to deter people from doing undesirable things by making them very expensive. PoW was proposed to mitigate distributed denial-of-service attacks [36]. In 2003, PoW was proposed to provide incentives in peer-to-peer systems [37]. The particular PoW used in Bitcoin is a variant of Adam Back's Hashcash [38], proposed in 1997, which requires finding a nonce that yields a hash with some leading 0's.\n\nUntil Bitcoin, PoW did not gain any significant traction. A study of its original proposed application, spam prevention, concluded that PoW \"does not work\" [39]. With Bitcoin, things changed. There were users who insisted on a payment system in which participants hide their identities, and for them, the gains outweighed the costs.\n\n## 3 Blockchain Network Dynamics\n\nThe blockchain networks of cryptocurrencies and Git are characterized by the following activities:\n\n1. Developers create and deploy the network.\n\nOnce the network is deployed,\n\n1. Users input data into the network\n2. Peers propose blocks to add to the blockchain\n3. Peers validate proposed blocks\n4. Peers strive to reach consensus\n\nThey are also different in two fundamental ways:\n\n1. Whether or not there are irreversible inputs\n2. Whether or not the blockchain is immutable\n\nAnd in all cases,8. Peers are incentivized to perform\n\nWe see three types of participants: developers, users and peers. While developers play a critical role, they are not part of the framework. The framework relates to the steady-state network once it is operational.\n\nWith cryptocurrencies, peers are users but most users are not peers. Most users just input transactions. When they receive payments, they have no interaction with the blockchain. The blockchain being public, everybody can be a user by just looking at it. However, one cannot use the blockchain to prove payment to a particular payee because one cannot force a payee to provide proof of received payment. There is a whole class of users who analyze cryptocurrency blockchains to catch illegal behavior such as money laundering and tax evasion. These include US departments DEA, FBI, ICE, IRS and SEC [40].\n\nIn Git, users who enter data into the blockchain are also peers. They input snippets of code and together they create and maintain some desired code. Git users who are peers do not hide their identities, but quite the opposite, seek recognition for their contributions. Another set of users take the code and deploy it.\n\nIn Bitcoin, after a peer succeeds a PoW, it will propose a block comprising a set of transactions, the size limited by the Bitcoin protocol. The Bitcoin incentives are such that the peer will validate the block before proposing it to the network. Almost always, even though all peers are working hard on their proofs, only one gets to propose a block (in the rare case of a fork, two or more peers will each propose a block) and the other peers will validate it. Immediately afterwards, the peers start all over again, work on their proofs, and when a peer succeeds, it proposes a new block of transactions. One can see the enormous costs here, as at every cycle, all the peers' duplicate efforts are essentially wasteful but necessary to maintain the integrity of the system.\n\nIn Git, a block is a commit, with data describing changes made to the code. These changes take the form of additions to and deletions from the code. There are no size limitations to a commit. Several peers may simultaneously submit blocks of code that they have been working on individually, and all of these may be added to the blockchain.\n\nIn Bitcoin, validation involves a fixed, deterministic set of rules [41] and is accomplished automatically, without human intervention. Peers validate that payers have sufficient funds to cover their payments, and to do so, they have to verify that the bitcoins used for payment are still in circulation. As Nakamoto pointed out [7], \"The only way to confirm the absence of a transaction is to be aware of all transactions.\" This is why a Bitcoin peer needs the entire blockchain.\n\nIn Git, validation is more nuanced and involves human activity. There are no fixed, deterministic rules that specify validity for a block. When a new block is proposed to add to the master branch, peers must check that it does not crash the code. In order to do that, they must have the entire code. This is why a Git peer needs the entire master branch. Peers cannot guarantee that a block does not crash the code; they can only say they tested it sufficiently and are comfortable with proceeding forward; if a bug is later found, somebody will probably fix it. They may also validate that the proposed code actually does what the user wrote in the message part of the commit that it should do, and that what it does is desirable.\n\nConsensus in Bitcoin is automatic. Peers choose the candidate blockchain of greatest height. The Bitcoin protocol with its PoW guarantees that, as long as peers possessing a majority of the hash power in the network validate truthfully, then asymptotically, the blockchain with greatest height will be valid. Note that it is a majority of hash power in the network, not a majority of peers, that is necessary for users to trust the Bitcoin network. If there is no consensus, the blockchain may fork and peers may continue with either or both branches of the fork.\n\nConsensus in Git is not automatic. Peers are structured with hierarchical authority. They may know each other, converse with each other, and often defer to peers with the most significant contributions. Git uses an interesting form of PoS; the stake includes a peer's reputation, permission level, and membership in the development team. As with Bitcoin, if no consensus is reached, the project may fork and peers may continue as they choose.\n\nBitcoin transactions are irreversible. Once a payment is made, there is no recourse. With Git, if a user commits a block with a subtle bug that the peers did not catch, somebody can fix that bug in a later commit. This is not an uncommon Git event.\n\nThe Bitcoin blockchain is practically immutable. With Git, by design, one can rewrite history [42].\n\nCryptocurrency peers are incentivized with mining rewards and transaction fees. Git peers on open-source projects are rewarded by getting the code they desire and by recognition. On closed projects, peers are often salaried software developers.\n\n## 4 The Framework\n\nThe framework is a set of questions that ask for specifics relating to blockchain network dynamics. It should be used at the conceptual stage, before development, of a blockchain-based application.\n\n\\begin{tabular}{|p{227.6pt}|} \\hline  1. Who are the users? \\\\  2. What data do users input? \\\\  3. Are any inputs irreversible? \\\\  4. Who are the peers? \\\\  5. How do peers create blocks? \\\\  6. What do peers validate? \\\\  7. How do peers validate? \\\\  8. How do peers reach consensus? \\\\  9. Is the blockchain immutable? \\\\  10. How are peers incentivized? \\\\ \\hline \\end{tabular}\n\n**Who are the users?** Do users have a task that current systems not handle well? Do they want to do something that they could not have done without a blockchain? Are they primarily concerned that their data is at risk? Are they anticipating reduced costs? What performance expectations, like transaction latency, do they expect? Will users have access restrictions to the blockchain? Will there be one blockchain for several classes of users or several blockchains, each for one class of users?\n\n**What data do users input?** Do users enter blobs (large data sets) or transactional data with pointers to blobs that are stored elsewhere? Will there be one blockchain for several types of transactions or several blockchains, each for a particular type of transaction?\n\n**Are any inputs irreversible?** For these, what are the potential liabilities?\n\n**Who are the peers?** Who can become a peer? How many peers are necessary? What is a desirable number of peers? Who are the initial peers? How much trust is there amongst the peers? Will peers have access restrictions to the blockchain? Are some peers also peers in other blockchain networks?\n\n**How do peers create blocks?** How many transactions or contracts or whatever go into a block? When are blocks formed? Do blocks have size limitations? Is the data in the blocks structured or unstructured or both? Do peers have to process data before putting it in a block?\n\n**What do peers validate?** Do peers validate that the data satisfies certain conditions aside from syntactical constraints and/or proof-of-something? Is validation deterministic or do peers sometimes have to make judgement calls?\n\n**How do peers validate?** What information do peers need in order to validate? Do they need the blockchain to be able to validate? Do they need the entire blockchain? Can peers communicate with each other during validation?\n\n**How do peers reach consensus?** What is the trust model? Can peers communicate with each other during the consensus process?\n\n**Is the blockchain immutable?** If so, what are the potential liabilities?\n\n**How are peers incentivized?** Do peers compete for rewards? Do users compete to get peers to service their inputs?\n\n## 5 Discussion\n\nPeople have recently become enamored with avoiding reliance on trust. More accurately, they think they can create distributed networks of untrusting peers that are more trustworthy than individuals or organizations. They think that complete histories of records, even personal ones, should be on public display, with identities hidden. They want contractual or compliance obligations automatically validated without third party intervention. They see blockchain as the driving technology enabling all this.\n\nAs we have seen, the core technologies behind blockchain have been known for decades. Cryptographic linking of data is used in peer-to-peer file sharing such as BitTorrent [43] and data and software distribution [44]. They do not need proof-of-work because any tampering could be quickly detected and dealt with. Things changed with Bitcoin, where double spending, even if detected immediately, could not be undone. Bitcoin introduced a novel twist, combining cryptographic linking with proof-of-work, and after percolating for several years, the concept is now generating tremendous excitement.\n\nGit shows that blockchains can be successful in environments of trust. It makes sense, then, not to restrict the definition of blockchain to any particular trust model. Different trust models will lead to different validation and consensus protocols. Open source projects that are hosted on GitHub provide examples of trust-based consensus practices. For example, see the instructions to prospective peers relating to consensus in Bitcoin Core [45]. Contrast that with the instruction to peers of the Git platform software [46].\n\nWhen designing a business application, one should ask, where in the application do fraud or accidental errors happen? In many cases, they hardly ever happen to the data once it is stored, but typically happen during data entry. In such cases, validation may require some level of trust. For example, in supply-chain applications, if peers are not actually present when transactions occur (like boxes loaded on a truck), how will they validate that data entered are true records of what happened?\n\nImmutability, a requirement in almost all currently proposed blockchains, can be a liability. For example, with a public blockchain, if a secret key is compromised, then all immutable records associated with that key are permanently exposed. With standard systems, if a password is compromised, records associated with that password are exposed until the password is changed. Relaxing the requirement for immutability may be an appropriate choice for some blockchain-based applications.\n\nIrreversibility, which is considered an advantage in certain applications, can also be a liability. With Bitcoin, a payer cannot even use the blockchain to prove who is the payee. If a bitcoin owner loses a private key, the coin associated with it is permanently lost. There is no equivalent to a password-reset in Bitcoin. It is estimated that millions of bitcoins are already lost forever [47].\n\nConclusion\n\nBlockchain-based applications other than cryptocurrencies and Git are at a very early stage, and there is clearly enormous enthusiasm to explore and create them. We foresee a spectrum of trust models evolving, and blockchain networks with validation and consensus protocols corresponding to them. We defined blockchains and blockchain networks, expanding the usual definition by not requiring immutability. We looked at two motivating examples with polar opposite trust models- Bitcoin and Git. By considering their common properties, we created a framework to compel concreteness in discussing proposed blockchain-based applications and to guide in their early design stages.\n\n## References\n\n* [1][https://hbr.org/2017/01/the-truth-about-blockchain](https://hbr.org/2017/01/the-truth-about-blockchain)\n* [2][https://www.wired.com/2017/02/moving-patient-data-messy-blockchain-help/](https://www.wired.com/2017/02/moving-patient-data-messy-blockchain-help/)\n* [3][https://www.ibm.com/blockchain/supply-chain/](https://www.ibm.com/blockchain/supply-chain/)\n* [4][https://www.fastcompany.com/40449268/will-blockchain-revolutionize-global-real-estate-next](https://www.fastcompany.com/40449268/will-blockchain-revolutionize-global-real-estate-next)\n* [5][https://www.fastcompany.com/40449268/will-blockchain-revolutionize-global-real-estate-next](https://www.fastcompany.com/40449268/will-blockchain-revolutionize-global-real-estate-next)\n* [6][https://www.forbes.com/sites/delltechnologies/2017/06/27/how-blockchain-could-revolutionize-the-internet-of-thi](https://www.forbes.com/sites/delltechnologies/2017/06/27/how-blockchain-could-revolutionize-the-internet-of-thi)\n* [7][https://bitcoin.org/bitcoin.pdf](https://bitcoin.org/bitcoin.pdf)\n* [8] W. Dai, b-money, [http://www.weidai.com/bmoney.txt](http://www.weidai.com/bmoney.txt), 1998\n* [9][http://p2pfoundation.ning.com/forum/topics/bitcoin-open-source](http://p2pfoundation.ning.com/forum/topics/bitcoin-open-source)\n* [10][https://coinmarketcap.com/](https://coinmarketcap.com/)\n* [11][http://fortune.com/2017/08/07/bitcoin-cash-bch-hard-fork-blockchain-usd-coinbase/](http://fortune.com/2017/08/07/bitcoin-cash-bch-hard-fork-blockchain-usd-coinbase/)\n* [12][https://www.theatlantic.com/technology/archive/2017/05/cryptocurrency-ponzi-schemes/528624/](https://www.theatlantic.com/technology/archive/2017/05/cryptocurrency-ponzi-schemes/528624/)\n* [13][https://www.benzinga.com/fintech/17/11/10824764/12-biggest-cryptocurrency-hacks-in-history](https://www.benzinga.com/fintech/17/11/10824764/12-biggest-cryptocurrency-hacks-in-history)\n* [14][https://www.inc.com/will-yakowicz/startups-law-enforcement-agencies-catch-criminals-who-use-cryptocurrency](https://www.inc.com/will-yakowicz/startups-law-enforcement-agencies-catch-criminals-who-use-cryptocurrency).]\n* [15][https://digiconomist.net/bitcoin-energy-consumption](https://digiconomist.net/bitcoin-energy-consumption)\n* [16][https://www.poslist.org/](https://www.poslist.org/)\n* [17][https://arxiv.org/pdf/1710.09437v2.pdf](https://arxiv.org/pdf/1710.09437v2.pdf)\n* [18][https://hackernoon.com/what-is-proof-of-stake-8e0433018256](https://hackernoon.com/what-is-proof-of-stake-8e0433018256)]\n* [19][https://www.ibm.com/blogs/blockchain/2017/05/the-difference-between-public-and-private-blockchain/](https://www.ibm.com/blogs/blockchain/2017/05/the-difference-between-public-and-private-blockchain/)\n* [20][https://octoverse.github.com/](https://octoverse.github.com/)\n* [21][https://github.com/bitcoin/bitcoin](https://github.com/bitcoin/bitcoin)\n* [22][https://www.git-tower.com/blog/git-hosting-services-compared/](https://www.git-tower.com/blog/git-hosting-services-compared/)\n* [23][https://stackoverflow.com/questions/46192377/why-is-git-not-considered-a-block-chain](https://stackoverflow.com/questions/46192377/why-is-git-not-considered-a-block-chain)\n* [24][https://news.ycombinator.com/item?id=9436847](https://news.ycombinator.com/item?id=9436847)\n* [25][https://medium.com/@shemmon/is-a-git-repository-a-blockchain-35cb1cd2c491](https://medium.com/@shemmon/is-a-git-repository-a-blockchain-35cb1cd2c491)* [26][https://www.reddit.com/r/Bitcoin/comments/33s8x0/is_git_a_block_chain_domains_tower_says_yes/](https://www.reddit.com/r/Bitcoin/comments/33s8x0/is_git_a_block_chain_domains_tower_says_yes/)\n* [27] W. Wang, et al, \"Decentralized Caching for Content Delivery Based on Blockchain: A Game Theoretic Perspective\", [https://arxiv.org/pdf/1801.07604.pdf](https://arxiv.org/pdf/1801.07604.pdf)\n* [28][https://en.wikipedia.org/wiki/Linked_timestamping](https://en.wikipedia.org/wiki/Linked_timestamping)\n* [29][https://bitcoin.org/en/developer-reference#block-headers](https://bitcoin.org/en/developer-reference#block-headers)\n* [30][https://gist.github.com/masak/2415865](https://gist.github.com/masak/2415865)\n* [31] Method of providing digital signatures, US Patent 4,309,569, Ralph C. Merkle, Filed 9/5/1979, Granted 1/5/1982. [https://patents.google.com/patent/US4309569](https://patents.google.com/patent/US4309569)\n* [32] Ralph C. Merkle: Protocols for Public Key Cryptosystems, IEEE Symp. on Security and Privacy, 4/14-16/1980, Oakland, CA. [http://www.merkle.com/papers/Protocols.pdf](http://www.merkle.com/papers/Protocols.pdf)\n* [33][https://en.wikipedia.org/wiki/Merkle_tree](https://en.wikipedia.org/wiki/Merkle_tree)\n* [34][https://brilliant.org/wiki/merkle-tree/](https://brilliant.org/wiki/merkle-tree/)\n* CRYPTO'92, LNCS 740, Springer Verlag 1992, pp.139-147. [http://www.wisdom.weizmann.ac.il/](http://www.wisdom.weizmann.ac.il/)\\(\\sim\\)naor/PAPERS/pvp.ps\n* [36] D. Mankins, R. Krishnan, C. Boyd, J. Zao and M. Frentz: Mitigating Distributed Denial of Service Attacks with Dynamic Resource Pricing, Proc. of 17th Annual Computer Security Applications Conference (ACSAS 2001), 2001.\n* [37] A. Serjantov and S. Lewis: Puzzles in P2P Systems, 8th Cab erNet Radicals Work- shop, Corsica, Oct 2003. [https://web.eecs.umich.edu/](https://web.eecs.umich.edu/)\\(\\sim\\)zmao/eecs589/papers/Serjantov04.pdf\n* [38][http://www.hashcash.org/papers/announce.txt](http://www.hashcash.org/papers/announce.txt)\n* [39][https://www.cl.cam.ac.uk/](https://www.cl.cam.ac.uk/)\\(\\sim\\)rnc1/proofwork.pdf\n* [40][https://www.ethnews.com/six-us-government-agencies-hire-investigative-blockchain-firm-chainalysis](https://www.ethnews.com/six-us-government-agencies-hire-investigative-blockchain-firm-chainalysis)\n* [41][https://en.bitcoin.it/wiki/Protocol_rules](https://en.bitcoin.it/wiki/Protocol_rules)\n* [42][https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History](https://git-scm.com/book/en/v2/Git-Tools-Rewriting-History)\n* [43][https://en.wikipedia.org/wiki/BitTorrent](https://en.wikipedia.org/wiki/BitTorrent)\n* [44][https://en.wikipedia.org/wiki/Code_signing](https://en.wikipedia.org/wiki/Code_signing)\n* [45][https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md](https://github.com/bitcoin/bitcoin/blob/master/CONTRIBUTING.md)\n* [46][https://github.com/git/git/blob/master/Documentation/SubmittingPatches](https://github.com/git/git/blob/master/Documentation/SubmittingPatches)\n* [47][http://fortune.com/2017/11/25/lost-bitcoins/](http://fortune.com/2017/11/25/lost-bitcoins/)"

Title: Selecting Reliable Blockchain Peers via Hybrid Blockchain Reliability
  Prediction
Transcription: "# Selecting Reliable Blockchain Peers via Hybrid Blockchain Reliability Prediction\n\nPeilin Zheng\n\nSun Yat-sen University\n\nGuangzhou, China zhengpl3@mail2.sysu.edu.cn\n\nZibin Zheng\n\nSun Yat-sen University\n\nGuangzhou, China zibinzheng@yeah.net\n\nLiang Chen\n\nSun Yat-sen University\n\nGuangzhou, China jasonck@gmail.com\n\n###### Abstract.\n\nBlockchain and blockchain-based decentralized applications are attracting increasing attentions recently. In public blockchain systems, users usually connect to third-party peers or run a peer to join the P2P blockchain network. However, connecting to unreliable blockchain peers will make users waste resources and even lose millions of dollars of cryptocurrencies. In order to select the reliable blockchain peers, it is urgently needed to evaluate and predict the reliability of them. Faced with this problem, we propose H-BRP, Hybrid Blockchain Reliability Prediction model to extract the blockchain reliability factors then make personalized prediction for each user. Large-scale real-world experiments are conducted on 100 blockchain requesters and 200 blockchain peers. The implement and dataset of 2,000,000 test cases are released. The experimental results show that the proposed model obtains better accuracy than other approaches.\n\n2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17\n\n+++ ==WARNING: Truncated because of repetitions==\n, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright 17, 2017 acmcopyright\n+++\n\nIn this paper, we propose a hybrid collaborative reliability prediction model for blockchain systems, called _H-BRP_. H-BRP does not predict the success rate of the blockchain peers directly. The main idea of H-BRP is to extract blockchain-related factors from the request history (e.g., block hash, block height). Then it uses the relationship between similar blockchain users and peers to do the collaborative prediction with hybrid linear regression. In this way, H-BRP obtains personalized prediction results for different users with higher accuracy than other approaches, as the real-world experiment shows. As shown in Figure 1, we deploy 100 blockchain requesters to evaluate and predict the reliability of 200 real-world blockchain peers, showing the feasibility and effectiveness of the model.\n\nIn summary, the main contributions of this paper are summarized as follows:\n\n* We propose H-BRP, Hybrid Blockchain Reliability Prediction model for blockchain systems. This model can extract blockchain factors related to reliability. And, it uses the relationship between similar users and peers for personalized prediction.\n* We conduct real-world experiment with 2,000,000 test cases from 100 requesters to 200 blockchain peers as shown in Figure 1. The results show the effectiveness of the proposed model. The implement and dataset will be open-source.\n\nThe rest of the paper is organized as follows. Section 2 introduces the basic concepts of blockchain systems. Section 3 describes the motivating example of reliability prediction of blockchain systems. Section 4 proposes the details of the Hybrid Blockchain Reliability Prediction model, including the data processing, training and prediction. Section 5 introduces the implement of H-BRP and the experiment results. Section 6 provides the related work and discussion about blockchain reliability. Section 7 concludes the paper and gives the future work.\n\n## 2. Basic Concepts\n\nThis section introduces the basic concepts of the blockchain and decentralize application.\n\nIn a narrow sense, the blockchain is a kind of data structure. The concept of the blockchain was firstly proposed as the underlying storage for peer-to-peer payments in Bitcoin(Bleader, 2018). As shown in Figure 2, every block contains the transactions in a period of time. Then every block is joint to a chain-like data structure named blockchain. Each peer in the peer-to-peer network maintains a blockchain by itself. And they keep it the same with each other via consensus protocols. Each block has a hash value of itself and this hash value is contained in the next block to make it tamper-resistant and traceable.\n\nIn a wide sense, the blockchain can be regarded as a new kind of distributed system. The basic concepts of blockchain are listed as follows:\n\n* Transaction: A transaction represents a message to change the ledger, such as transferring cryptocurrencies. If someone wants to send Bitcoin to others, he should broadcast the transaction to the p2p network.\n* Block: Block is a data package consists of the transactions in a period of time. Each block has a hash value of it self (Bleader, 2018; Bleader, 2018; Bleader, 2018) so that the hash value can be used to check the authenticity of the block.\n* Chain: The chain consists of all the blocks that are linked by their hash. In the Bitcoin blockchain(Bleader, 2018), every block is generated after the previous one so that they record the hash of the previous block. This chain-like structure is shown in Figure 2.\n* Mining: In public blockchain systems, after receive the previous block, the peers will try to find out a nonce for the next block to get the rewards, such as Bitcoin. This process is so called _mining_ and the peers are called _miners_.\n* Decentralized Application: Blockchain-based decentralized applications (_DApp_) use blockchain as the underlying technology (Bleader, 2018; Bleader, 2018; Bleader, 2018; Bleader, 2018). Most DApp users connect to third-party peers to get the blockchain data. Figure 3 shows different third-party blockchain peers in DApps. If the user connect to an unreliable peer, the DApp would not work.\n\nIn summary, blockchain is a growing chain-like data structure maintained by peers in P2P network. Each peer in the P2P network wants to get the latest (or so-called highest) correct block. Therefore, a blockchain peer is reliable if it can return the latest block for the requesters.\n\nFigure 3. Different Third-party Blockchain Peers in DApps\n\nFigure 2. Data Structure of Blockchain(Bleader, 2018)\n\n\n\n## 3. Motivating Example\n\nIn this section, a motivating example of blockchain reliability prediction is given. Blockchain users can choose either to run blockchain peers by themselves or use the third-party peers to interact with the blockchain systems. As shown in Figure 4, no matter the user run a peer by himself or not, he should select some blockchain peers to connect to. The challenge is that, there are more than 20,000 peers online at the same time, and he cannot test all of them to see which one is reliable for him. The influence of the reliability of the blockchain peers can be divided into two folds: for blockchain mining and for blockchain-based application user.\n\n### For Blockchain Mining\n\nThe premise of blockchain mining is that the user should get the latest previous block. If the user connects to the peers with low reliability, he cannot get the previous block in time. Then the user will waste the computing resources in computing at the wrong block without any rewards of cryptocurrencies. To improve the block synchronization speed and economic benefit, it is vital to evaluate and predict the reliability of the blockchain peers.\n\n### For Blockchain-based Application User\n\nAssumed that the user in Figure 4 is like most blockchain-based application users that he connect to third-party blockchain peers. Then he need to select the most reliable one since unreliable peer will cause consequences. For example, one of the most famous wallet of cryptocurrencies called imToken had been reported to fail to sync with the Ethereum network (Brock et al., 2015). At that moment, the users think wrongly that their transactions are not confirmed by the network, then they send other repeated transactions again and again, which causes the loss of their money.\n\nThus it is really important for the blockchain users to know which blockchain peer is more reliable to avoid the loss of cryptocurrencies and improve the experience with the blockchain.\n\nAnd, in reality, a user cannot connect to all the blockchain peers in the meanwhile, which means that there are lots of peer of unknown reliability. Thus it is necessary to predict the unknown reliability of blockchain peers.\n\nIn summary, the motivations of this paper are to evaluate and predict the reliability of blockchain peers and help select the reliable peers to improve the blockchain synchronization speed, avoid loss of money, and improve the experience of blockchain.\n\n## 4. Methodology\n\nIn this section, the methodology of Hybrid Blockchain Reliability Prediction model will be introduced, including the architecture and the steps in details.\n\n### Architecture\n\nThe architecture of the blockchain reliability prediction is shown in Figure 5. It consists of 3 major roles as follows:\n\n* **Blockchain Peers:** Blockchain peers are the nodes which maintaining the blockchain in the P2P network.\n* **Blockchain Requesters:** Requesters are the nodes installed with the H-BRP data collecting program, which will randomly request the blockchain data from some of the peers in a period of time. The requesters can be considered as the users in the blockchain systems.\n* **Data Collector & Predictor:** Data collector is a central server that collecting all the test cases from the blockchain requesters. Then the data will be used to evaluate and predict the reliability of the blockchain systems.\n\nThe main idea of this architecture is that users can contribute their blockchain request history to a central data collector. Then the collector will summarize the historical data and do personalized reliability prediction for each user and peer. As shown in Figure 5, there are 4 steps of Hybrid Blockchain Reliability Prediction: _Block Request Testing, Upload Test Cases, Reliability Prediction_, and _Select Reliable Peers_.\n\nFigure 4. Motivating Example of Blockchain Reliability Prediction\n\nFigure 5. Architecture of the Blockchain Reliability Prediction\n\n#### 4.1.1. **Block Request Testing**\n\nIn a period of time, a requester has more than one blockchain peer as candidate to connect to. Before knowing the candidates are reliable or not, the requester needs to connect to them. However, limited by the network conditions, the requester cannot request all the candidates in the meantime. Therefore, H-BRP proposes random batch block request testing for blockchain peers.\n\nThe random batch request testing include several stages as follows:\n\n1. Given a batch size \\(\\mathbf{n}\\), and the time period of \\(\\mathbf{t}\\) seconds,\n2. For each time period, each requester selects \\(\\mathbf{n}\\) candidates from the list randomly.\n3. Each requester requests the latest block from the selected candidates, parses it and records the height and hash to the local storage.\n\n#### 4.1.2. **Upload Test Cases**\n\nAfter above stages, a requester achieves the raw data in a tuple of \\(<\\)_ClientIP_, _BatchTime_, _PeerIP_, _StartTime_, _EndTime_, _Height_, _BlockHash\\(>\\)_. The example is shown in Table 1. In particular, H-BRP records the BatchTime to compare the test cases that are sent at the same time to see which one returns the higher block. H-BRP also records the StartTime and EndTime to see how long the round-trip time is during every test case. And, H-BRP records the Height and BlockHash in order to backtrack that whether the peer returns a correct block.\n\nWhen there are enough test cases, the requester can choose to upload the test cases to the collector. The more test cases that the requesters contribute to the collector, the more accurate reliability prediction will be done.\n\n#### 4.1.3. **Reliability Prediction**\n\nAfter receiving enough test cases from users, the collector/predictor can choose different predicting model to do reliability prediction for the users and peers. Reliability prediction is the key step in the whole architecture. As shown in Figure 5, H-BRP model includes three substeps: _H-BRP Matrix Generation_,_Collaborative Prediction_, and _Hybrid Training/Prediction_. The detailed model and implement will be proposed in the next subsection. Here are the main ideas of it.\n\n* _H-BRP Matrix Generation_: This substep can be regarded as the data preprocessing. H-BRP proposes some factors that are related to blockchain reliability. It transfers the data from a list of test cases into some metrics. In this substep, each factor is extracted into a requester-peer matrix.\n* _Collaborative Prediction_: Since blockchain peer shows different network delay to different users, the reliability observed by different users could be different. The case study in Section 5 will show this difference. Therefore, it is necessary for the model to do personalized prediction for different users. To attack this problem, this substep is to find out similar blockchain users or peers, and then predict the unknown reliability factors for them.\n* _Hybrid Training/Prediction_: H-BRP assumed that there is a mapping between the reliability and factors extracted in previous substeps. Thus the reliability can be predicted based on the prediction of the related factors. In this substep, H-BRP first trains a linear regression model using the known reliability and factors. After that, H-BRP uses this model and the predicted factors to do reliability prediction.\n\nSincerely, directly predicting the reliability without extracting the factors could be chosen. But direct reliability prediction will make it lose lots of valuable information from the source data. That is why H-BRP extracts the factors from the test cases and do collaborative prediction by finding similar blockchain users/peers.\n\nIn summary, the key idea is to maximize the use of available information, such as blockchain features and users' similarity. The detailed model will be propose in next subsection.\n\n#### 4.1.4. **Select Reliable Peers**\n\nBased on the personalized reliability prediction result, the users can choose the blockchain peers with more reliability. For blockchain-based application users, the most reliable peer should be chosen. As for blockchain miners, they can choose top K peers ranked by predicted reliability.\n\n### Hybrid Block Reliability Prediction Model\n\nIn this subsection, the details of Hybrid Block Reliability Prediction Model will be described, as shown in Figure 6.\n\n#### 4.2.1. **Blockchain Factor Matrix Generation**\n\nAfter finishing the block request testing, the data collector use the request data to generate the Blockchain Factor Matrix.\n\nFirst, Set up a blocks-tolerance value as _MaxBlockBack_ to represent the max tolerance for block backwardness of the peer in the blockchain. Then set up a time-tolerance value as _MaxRTT_ to represent the max round-trip time for the peer.\n\nThe Success Rate Matrix is generated as follow:\n\nFor each requester \\(\\mathbf{R}_{i}\\) and peer \\(\\mathbf{P}_{j}\\), set up a success counters for reliable requests as \\(\\textbf{{SuccessRequest}}_{i,j}\\) and a failure counters as \\(\\textbf{{FailureRequest}}_{i,j}\\).\n\nNext backtrack each batch of block requests to the peer, the peer responses successfully if and only if it:\n\n1. **Returns right block:** The block hash is right in the corresponding block height on the main blockchain.\n2. **Returns recent block height:** The block height subtracted from the highest one in the batch is no more than _MaxBlockBack_. If _MaxBlockBack_ is set to 0, it requires the peer is reliable only when it returns the highest block in the batch.\n3. **Returns in time:** The round-trip time of the request to the peer is no more than _MaxRTT_.\n\nIf the blockchain peer \\(P_{j}\\) responses successfully in a batch, then count it into \\(\\textbf{{SuccessRequest}}_{i,j}\\), otherwise into \\(\\textbf{{FailureRequest}}_{i,j}\\). Then the success rate of requester \\(R_{i}\\) to peer \\(P_{j}\\) can be calculated by :\n\n\\[TotalRequest_{i,j}=\\textbf{{SuccessRequest}}_{i,j}+\\textbf{{FailureRequest}} _{i,j} \\tag{1}\\]\n\n\\[\\textbf{{SuccessRate}}_{i,j}=\\frac{\\textbf{{SuccessRequest}}_{i,j}}{Total \\textbf{{Request}}_{i,j}} \\tag{2}\\]\n\nAfter that, a matrix of success rate is achieved. As shown in Figure 6, the gray area is the known success rates, while the yellow area is the unknown success rates, which is needed to predict. Some research in service computing use the success rate or failurerate to predict the unknown entries in the matrix to predict the reliability of service. However, in blockchain reliability, this would lose some information from the source data because it do not take blockchain factors into account. Therefore, H-BRP generates three matrix corresponding to the above three blockchain related factors:\n\n1. **Right Block Matrix:** Right Block Matrix reflects on the rate at which the \\(P_{j}\\) returns the correct block to \\(R_{i}\\). It can be generated by the following equation: \\[RightBlock_{i,j}=\\frac{RightBlockRequest_{i,j}}{TotalRequest_{i,j}}\\] (3) where \\(RightBlockRequest_{i,j}\\) is the counter of the requests that return the right block from \\(P_{j}\\) to \\(R_{i}\\).\n2. **Recent Height Matrix**: Recent Height Matrix reflects on the rate at which the \\(P_{j}\\) returns the recent height to \\(R_{i}\\). It can be generated by the following equation: \\[RecentHeight_{i,j}=\\frac{RecentHeightRequest_{i,j}}{TotalRequest_{i,j}}\\] (4) where \\(RecentHeightRequest_{i,j}\\) is the counter of the requests that return the recent height from \\(P_{j}\\) to \\(R_{i}\\).\n3. **Round-trip Time Matrix**: Round-trip Time Matrix reflects on the average round-trip time of the block requests between \\(P_{j}\\) and \\(R_{i}\\). It can be generated by the following equation: \\[RoundTripTime_{i,j}=\\frac{\\sum_{k}RTT_{i,j,k}}{TotalRequest_{i,j}}\\] (5) where \\(RTT_{i,j,k}\\) is the round-trip time of the request from \\(R_{i}\\) to \\(P_{j}\\) in batch \\(k\\).\n\nIn summary, in this phase, H-BRP generates one Success Rate matrix and three blockchain related factor matrices. The main idea of the matrix generation is to extract more information related to blockchain in the source data. Thus the prediction using this data will be more accurate.\n\n#### 4.2.2. **Collaborative Prediction**\n\nAfter generating the matrices, the RightBlock Matrix, RecentHeight Matrix and RoundTripTime Matrix will be used into three collaborative filtering models. The target is to predict the missing value in the blank of the matrix. As shown in Figure 6, the target in this step is to predict the factors. It is assumed that the three events (right block, recent height, and in time) corresponding to the matrix are independent. Thus every factor matrix will be predicted through the following phases independently.\n\n**(1)Similarity Calculation**\n\n\

Tuple 47:
Cleaned Title: scalable multichain coordination via hierarchical longest chain rule
Cleaned Transcription: scalable multichain coordination via hierarchical longest chain rulennyanni georghiadesnndepartment ecennuniversity texas austinnnaustin txnnyannigeorghiadesutexasedunnkarl kredernnchief architectnndominant strategiesnnaustin txnnjonathandominantstrategiesionnalan orwicknnceonndominant strategiesnnaustin txnnalandominantstrategiesionns vishwanath advisor dominant strategy incubates startup blockchain domain chainhubnn abstractnnthis paper introduces blockreduce proofofwork based blockchain system achieves high transaction throughput mean hierarchy merged mined blockchains operating parallel partition overall application state notably full pow available within network applied blockchains blockreduce crossblockchain state transition enabled seamlessly within core protocol paper show given hierarchy blockchains associated security model blockreduce scale superlinearly transaction throughput number blockchains operated protocolnn blockchain distributed system performance scalability proofofworknn introductionnnblockchains popular mean enable trustless decentralized peertopeer value transfer among approach achieving distributed consensus cryptocurrencies proofofwork pow oldest established arguably wellunderstood however powbased cryptocurrencies currently limited term transaction throughput comparison traditional payment mechanism credit card resulted increased transaction cost greater shift towards alternate scaling mechanism particular proofofstake po proofofx consensus protocol proliferation layer protocol proposed implemented order enable lower transaction fee approach different trust model comparison proofofwork result come associated challenge weaknessesnnthe two notable cryptocurrencies bitcoin ethereum powbased maximum throughput transaction per second whereas visa alone execute transaction per second credit card network indeed presumed without proof majority people pow cryptocurrencies simply meet throughput requirement global currencynnfootnote time writing ethereum yet attempted transition proofofstakennin paper introduce blockreduce pow cryptocurrency achieves high transaction throughput layer protocol describe blockreduce first identifying primary factor cause low transaction throughput therefore large fee pow blockchains address ameliorate factor resulting truly scalable solutionnnthe primary tool underlying solution scalability followsnnlatencydependent clustering network node noted across literature network latency one biggest factor scalability blockchain system work translate understanding network latency suitable hierarchical clustering node selfpartition hierarchy subnetworks share lowlatency connection subnetwork operates blockchain validate update partition overall application statenntransactiondependent security currently vast majority pow cryptocurrencies afford level securitywhere purpose security refers amount work adversary would need perform order succeed doublespend attackfor transaction regardless economic value transaction however humancommerceinteractions lowvalue transaction secured level highvalue transaction example credit card transaction low value often require signature higher value transaction go stringent signature verification process ultimately even blockchain domain believe security transactionvalue dependent highvalue block associated transaction afforded greater security guarantee thus amount work applied transaction sake settlement need shortterm although order prevent transaction conflict proliferating eventually transaction blockreduce must validated secured maximum amount work available systemnnmerged mining blockreduce composed tree blockchains operated parallel rather performing pow computation single block header miner simultaneously mine blockchain level tree using pow computation one pow solution might correspond block multiple blockchains two effect blockreduce first miner always mine root tree meaning root blockchain receives mining power network second block found periodically shared blockchains different level tree block called coincident block allows work shared across blockchains also enables crossblockchain statetransitionsnn proofofwork blockchainsnnthe first published instance proofofwork applied blockchains nakamotos famous bitcoin protocol nakamoto combined pow block selection rule called longest chain rule achieve nakamoto consensus transaction blockreduce us pow reach similar form consensus blockchain tree order accommodate hierarchical structure define variant longest chain rule refer hierarchical longest chain rule describe aspect blockreduce protocol detail section ivb ivdnn proofofwork efficiencynna significant limiter transaction throughput public blockchains amount time take data propagate within peertopeer network block mined order provide intuition phenomenon define pow efficiency blockchain fraction pow computation contribute canonical chain ie chain block committed transaction ledgerstate machine ideal setting node follow protocol network delay block propagation pow efficiency mathcale propagation delay miner instantaneously adopt new block canonical chainnnto model realistic setting define lambda total rate block generation network network delay delta time block found received node network model computes effective block generation rate fraclambdalambdadelta resulting pow efficiency mathcalefraclambdadeltannfurthermore fraction beta node adversarial mining private branch blockchain part attack computes pow efficiency honest node mathcalefracbetabetalambdadelta varies inversely delta hand assuming adversary experience negligible network delay mining private chain ie deltaapprox pow efficiency approximately herein lie problem delta fixed adversary relative advantage honest node increase block generation rate increase system bitcoin suppress lambda order reduce impact delta pow efficiency honest node phenomenon discussed various work several solution presented assume delta fixed blockreduce partition network subnetworks delta experienced subnetwork smaller overall network thereby allowing subnetwork operate blockchain higher block generation rate achieve maintaining equal pow efficiency across blockchains believe critical truly scalable blockchain moreover utilize hierarchical longest chain rule described section ivd guarantee blockchain receives maximum amount work available network thereby achieving high transaction throughput without sacrificing security pow efficiencynn contributionsnnwe present blockreduce pow blockchain system enables high transaction throughput utilizing hierarchy merged mined blockchains operating parallel nonoverlapping partition application state best knowledge blockreduce first protocol promise superlinear scaling number parallel blockchains operates still securing blockchain maximum amount work available network introduce hierarchical longest chain rule blockselection mechanism allows blockchain hierarchy inherit work parent blockchain also enables native crossblockchain state transitionsbetween state partition hierarchy finally analyze performance protocol demonstrate superlinear scalability blockreducenn ii related worknnthere number proposal scaling transaction throughput blockchains provide brief summary several type approachesnn parallel pow blockchainsnnin manner conceptually similar blockreduce many protocol aim achieve high transaction throughput operating several blockchains parallel pow version parallel chain involves mining metablock containing candidate block number parallel chain operate nonoverlapping state partition notably parallel chain support crossblockchain transaction therefore limited application blockreduce chainweb another protocol operating many parallel chain block header reference header chain order braid chain together chainweb allows crossblockchain state transition also feature mechanism chain inherit work one another achieve linear increase transaction throughput number parallel chain whereas blockreduce achieves superlinear scalingnn proofofstake protocolsnnmany proofofstake protocol proposed implemented ouroboros praos ethereums planned move proofofstake mean enable high transaction throughput low settlement time however proofofstake protocol currently afford security guarantee pow also often suffer shortcoming nothing stake problem predictability next eligible validator nn layer protocolsnnthere multiple layer protocol ie protocol operate independently periodically interact blockchain developed order facilitate high transaction throughput include starkware polygon lightning among many others although architecture achieve high transaction throughput layer solution inevitably require alternate trust model core blockchain protocol may suited use case blockreduce scale layer protocol require additional assumption achieve high transaction throughputnn iii modelnnin section describe network model analyze blockreduce protocol adopt simple overlaynetwork model understand interaction node dregular graph n network node model arises standard set forth bitcoin protocol executed node attempt default maintain set peersnnwe assume synchronous roundbased model block propagation according probability number synchronous round required data broadcast via gossip random dregular network n node isnnobigfraclnfracdfracdlnfracd bigln n tagnnwe use result characterize overall network propagation delay delta ie amount time take single block propagated across network term average singlelink propagation delay delta followsnndeltadeltaobigfraclnfracdfracdln fracdbigln n tagnnadopting shortened notation give u following boundnndeltadelta cdln n tagnnwe define delta way show delta decrease delta n decrease section iv use understanding show delta reduced higher order blockchains within blockreduce protocol thereby allowing higher block generation rate still maintaining high pow efficiency within blockchainsnn iv hierarchy blockchainsnnin section describe blockreduce protocol show node operating particular blockchain able agree upon statenn notationnnthe blockreduce protocol requires node selfpartition hierarchy subnetworks hierarchy tree consisting r level called order subnetwork denoted mathcalnvecv vecv unique path root specified node hierarchy tree root hierarchy tree order leaf order r example blockreduce hierarchy structure associated subnetwork partitioning provided figure example hierarchy three order network order two child subnetworksnneach subnetwork mathcalnvecv operates blockchain mathcalbvecv achieve consensus partition state mathcalsvecv blockchains order r block arrival rate lambdar network delay deltar average singlelink propagation delay deltarnnwe adopt functional notation discussing relationship subnetworks blockchains state partition denote mathsfparentmathcalnvecv parent subnetwork mathcalnvecv hierarchy tree mathsfordermathcalnvecvvecv order mathcalnvecv often overload functional notation input mathcalbvecv mathcalsvecv simply vecv function evaluated waynn merged miningnnmining blockreduce similar mining standard pow blockchain except blockreduce multiple block mined simultaneously using technique called merged mining longest chain rule lcr introduced bitcoin modified accommodate hierarchical structure blockreducenneach blockreduce miner selects order r blockchain leaf node tree simultaneously mine blockchain along path root leaf example miner might select leaf mathcalb case would simultaneously mine mathcalb mathcalb mathcalb accomplish miner construct block blockchain mining concatenate block header together perform pow computation combined block header result block share block hashnnblockchains closer root hierarchy increasing overlapping pow difficulty thaat block meet difficulty requirement blockchain order r also meet difficulty requirement blockchain order greater ie root r example figure depicts sequence block system order example difficulty requirement order block block hash leading binary expansion whereas order block requires leading order block requires leading case order block leading also meet difficulty requirement order block shared multiple order way called coincident block serf coincide blockchains shared block reference section ivd show hierarchical longest chain rule coincident block impose partial ordering blockchains different order enables crossblockchain state transitionsnn partitioning ledger statennwe adopt generic state model transaction constitutes update application state generality allows blockreduce support unspent transaction output utxo model application state simply set utxos well sophisticated smart contract model application state smart contract state state partitioned blockchains preventnnfigure hierarchy tree order box subnetwork operates distinct blockchainnnfigure example block visualization system order box represents block value inside box hexadecimal representation block hash block bottom row make blockchain mathcalb forth block b meet difficulty requirement mathcalb therefore coincident block shared order b also coincident block shared order block b b meet difficulty requirement mathcalbnnfigure illustration topological network segregation full network b two order subnetworks c four order subnetworksnnduplication purpose crossblockchain state transition transaction must specify origin blockchain vecvo destination blockchain vecvd origin destination transaction state transition occurs way traditional blockchain implementation origin transaction different destination example asset tranferred one blockchain another state update involves removing asset origin state adding destination state lead following protocol rulennprotocol rule order transaction origin vecvo valid state modifies must valid respect mathcalsvecvonnfor example user attempting move asset vecvo vecvd transaction must origin vecvo user must demonstrate ownership asset vecvonn hierarchical longest chain rulennblockreduce utilizes novel consensus rule select canonical chainie chain block referencing state update appliedfor blockchain bitcoin traditional system longest chain rule lcr stipulates canonical chain sequence valid block work often referred longest chain accurately heaviest chain blockreduce follows similar rule must also account existence coincident block within hierarchynnbefore defining hierarchical longest chain rule hlcr first define condition block must meet considered valid specific requirement may vary implementation varying block size transaction andor smart contract structure block header composition general define valid block followsnnprotocol rule valid block block considered valid meet protocol rule predecessor order also validnnin word valid block must conform rule blockchain must reference prior block deviate rule importantly coincident block predecessor multiple order predecessor invalid block also invalid guarantee coincident block either valid blockchains meet difficulty requirement none next define hlcr miner use determine canonical chain blockreducennprotocol rule hierarchical longest chain rule canonical chain root blockchain mathcalb heaviest sequence valid block mathcalb canonical chain blockchain mathcalbvecv order greater heaviest sequence block contains coincident block mathcalbvecv mathsfparentmathcalbvecv present canonical chain mathsfparentmathcalbvecv coincident block mathcalbvecv mathsfparentmathcalbvecv present canonical chain mathsfparentmathcalbvecvnnin word canonical chain root blockchain selected via standard lcr blockchain mathcalbvecv order greater canonical chain must include coincident block shared mathcalbvecv mathsfparentmathcalbvecv present canonical chain mathsfparentmathcalbvecv however coincident block mathcalbvecv mathsfparentmathcalbvecv canonical chain mathsfparentmathcalbvecv canonical chain mathcalbvecvnnif incoming block cause canonical chain change state update dictated block longer part canonical chain must reverted new state update applied canonical chain must contain coincident block shared parent blockchain otherwise crossblockchain state transition applied origin destination could later reverted origin destination thus causing inconsistency overall network statenn interblockchain ordering via coincident blocksnnwithin single blockchain block canonical chain totally ordered according distance genesis block blockchains different order block partially ordered due coincident block arise merged miningnnintuitively coincident block serf shared point time blockchains allowing node agree upon block came coincident block block came example figure node mathcaln received block b agree block b came b even mining mathcalbnnthis property coincident block allows node mathcalnvecv mathsfparentmathcalnvecv agree existence ordering block prior coincident block either blockchain section ivg show enables crossblockchain state transition occur node operating destination blockchain agree precisely state transition applied destination statenn inherited work via coincident blocksnnwe argue sake short term settlement block containing transaction low economic value may secured fraction maximum work available network potential economic loss successful attack small however longer term security level sufficient block containing crossblockchain state transition removed canonical chain mathcalbvecvo state transition transaction already applied mathcalsvecvoprime inconsistency overall application state might arisennthe hlcr prevents type inconsistency requiring canonical chain child blockchain must contain coincident block shared parent blockchain regardless number block competing fork word coincident block removed canonical chain mathcalnvecv first removed canonical chain mathsfparentmathcalnvecv result mathcalnvecvinherits work applied mathsfparentmathcalnvecv adversary attempting remove block mathcalnvecv would need sufficient mining power remove mathsfparentmathcalnvecvnn state updatesnnin order guarantee consistent application state node sufficient node mathcalnvecv agree initial state defined genesis block apply state update mathcalsvecv order simple transaction origin destination state update applied order referenced blockchain transaction different origin destination state transition must handled two step first mathcalsvecvoprime updated according transaction eg removal asset origin state soon included block canonical chain mathcalbvecvoprime mathcalsvecvoprime however updated immediately initially way node operating mathcalbvecvoprime agree upon state transition applied protocol rule describes criterion must met state transition applied mathcalsvecvoprime protocol rule describes order state update applied block processednnprotocol rule let tx transaction origin vecvo destination vecvd let vecva highest order common ancestor vecvo vecvd state transition pertaining mathcalsvecvoprime applied soon block containing tx part canonical chain mathcalbvecvoprime state transition pertaining mathcalsvecvdprime however applied coincident block found shared mathcalbvecvoprime mathcalbvecvaprime mathsfordermathcalbvecvdprimemathsfordermathcalb vecvaprime subsequent coincident block found shared mathcalbvecvdprime mathcalbvecvaprimennintuitively chain coincident block must constructed link vecvo vecvd predecessor reference vecvo vecvd different branch tree chain must travel back hierarchy chain established node mathcalnvecvoprime verify block containing tx canonical chain mathcalbvecvoprime coincident block mathcalbvecvoprime mathcalbvecvaprime also agree upon existence coincident block mathcalbvecvdprime mathcalbvecvaprime update mathcalsvecvdprime result coincident blocknnthe next rule defines order eligible state update applied node must apply update order guarantee consistent statennprotocol rule state transition given block b mathcalbvecv applied mathcalsvecv following order first b coincident block transaction destination vecv eligible applied mathcalsvecv according protocol rule applied order highest origin order lowest origin order transaction origin order applied order blockchain index ie left right tree order transaction origin index applied chronological order according inclusion origin blockchain transaction directly referenced b applied mathcalsvecv order referenced bnnprotocol rule guarantee node subnetwork perform state transition order meaning two node agree canonical chain consistent local state formalized theorem ivnntheorem iv given blockchain mathcalbvecv two correct node mathcalnvecv agree canonical chain mathcalbvecv agree mathcalsvecvnnwe prove theorem iv inductively first remarking two correct node must agree upon genesis block associated state blockchain instantiated show inductive stepfor block canonical chain mathcalbvecv node must apply state update mathcalsvecv order prove via contradiction showing case case basis regardless origin destination transaction one node applies state update transaction least one node break protocol rule therefore node agree initial state subsequent state update statement follows due space constraint omit full proof papernnas corollary theorem iv correct node mathcaln agree canonical chain mathcalb also agree mathcals ensures node system agree upon state root blockchain blockreduce thereby achieving similar guarantee singleblockchain systemnnnn v analysisnnin section show blockreduce achieves transaction throughput scale superlinearly number blockchains ordernn decreased propagation delay via network partitioningnnsubnetworks order r ie root subnetwork network delay deltar strictly le delta delta analagous delta experienced traditional blockchain operated full network n node due decreased size subnetworks ability node select subnetwork share lowlatency peer connection order reduce overall block propagation time experiencennit clear equation smaller network naturally lower propagation delay larger network order enhance intuition assume q subnetworks order r subnetwork equal size bound deltar followsnndeltar deltarcdlnbigfracnqbig taga deltadeltarcdln q tagbnnthen propagation delay order strictly increasing number subnetworks ordernnadditionally remark distribution nodetonode latency bitcoin measured latency node vary significantly one pair next assume absence protocol mechanism requiring node join particular subnetwork node elect mine subnetwork minimizes peertopeer latency reduce probability block lost due network fork result argue subnetwork order greater average perlink propagation delay deltar node order r subnetworks smaller delay node mathcalnie deltardelta r use result proof nonetheless support claim theorem vnnoverall network propagation delay within subnetwork much smaller network whole ie network delay similar system bitcoin result rate block generation much higher within subnetworknn aggregate throughputnnin section show within order hierarchy total transaction throughput increase number blockchains order increase even pow efficiency remains fixed blockchain moreover show increase superlinear number blockchains order additional blockchain partition network thus reduces propagation delay experienced node subnetwork state property blockreduce formally following theoremnntheorem v aggregate transaction throughput order blockreduce protocol scale superlinearly number blockchains order blockchains hierarchy identical pow efficiencynnwe prove theorem showing effective block generation rate order r blockchain grows number order r blockchains increasesnnproof recall lambdar total block generation rate blockchain order r effective block generation rate lambdarfraclambdarlambdardeltar pow efficiency mathcalerfraclambdardeltar suffices show q number blockchains order r lambdar increase q increasesnnwe hold pow efficiency fixed blockchains root blockchain ie fraclambdadeltafraclambdardeltar substituting result equation getnnfraclambdadeltafraclambdardeltadeltar cdln q tagnnwhich simplifies tonnlambdarfraclambdadeltadeltadeltarcdln q tagnnthen effective block generation rateie rate block appended canonical chainfor order r blockchain pow efficiency root blockchain isnnlambdarfraclambdadeltadeltadeltarcdln q lambdadelta tagnnclearly right hand size equation increase q meaning lambdar well block assumed contain number transaction statement follows nn vi discussion future worknnblockreduce powbased blockchain system achieves high transaction throughput hierarchy merged mined blockchains operate partition overall application state parallel critically full pow available network applied blockchains blockreduce andcrossblockchain state transition enabled seamlessly within core protocol section highlight several discussion point avenue future worknn vb selfselection subnetwork participationnnmining node blockreduce allowed mine vertical slice blockchains within pow hierarchy tree however vast majority miner pow blockchain economically motivated miner elect mine blockchains grant highest reward way blockchains within order selfbalancing miner naturally drift towards available blockchains reduced competition absence competitive advantage mining power miner elect mine blockchains share lowest latency connection order minimize probability block lost network fork believe alignment incentive result formation lowlatency cluster mining node able achieve high pow efficiency although leave construction suitable incentive mechanism gametheoretical analysis future worknn vb lowvalue transaction security settlement time tradeoffsnnblockreduce user high degree flexibility transacting control shortterm security settlement time transaction selecting blockchain transact higher order blockchains low settlement time low security short term subnetworks operating blockchains high block generation rate control fraction overall mining power ideal transaction low economic value consequence lowvalue transaction removed canonical chain minor user desiring higher degree security might elect transact lower order blockchains order utilize larger fraction pow network despite tradeoff longer settlement time precise characterization tradeoff specific particular implementation likely blockreduce implementation provide default wallet capable selecting appropriate transaction location automated fashionnn vb expected hierarchy structure future implementationnnalthough designed blockreduce support arbitrary hierarchy tree realworld hardware network infrastructure well timing requirement functional blockchain network limit number order number blockchains per order realizable practice number blockchains blockreduce hierarchy increase time required crossblockchain state transition also increase due decreasing relative frequency coincident block linking blockchain example blockchain mathcalb child blockchains average every block mathcalb coincident child blockchain number increase child blockchains expected time required coincident block found one particular child increase dramatically implementation empirical testing required determine optimal configuration given use case network topologynn vb conclusionnnwe presented blockreduce blockchain system operates hierarchy blockchains parallel showed blockreduce achieves transaction throughput scale superlinearly number blockchains operated system without reducing security transactionnn referencesnn abadi annnn warning truncated repetitionsn annn x xu weber staple l zhu j bosch l bass c pautasso p rimba taxonomy blockchainbased system architecture design ieee international conference software architecture icsa ieee pp n neudecker characterization bitcoin peertopeer network vol title experimentation earlystage video game startup practice challenge transcription experimentation earlystage video game startup practice challenge footnote author version manuscript accepted publication proceeding th international conference software business icsob manuscript version made available ccbyncnd license httpcreativecommonsorghttpcreativecommonsorg licensesbyncnd henry edison blekinge institute technology karlskrona sweden henryedisonbthse jorge melegati free university bozenbolzano bolzano italy jorgeaugustomelegationcalvesunibzit elizabeth bjarnason lund university lund sweden elizabethbjarnasoncslthse abstract experimentation considered critical successful software product business development including video game startup video game startup need wow quality distinguish competition thus need continuously experiment find quality running time resource study aimed explore company perform experimentation interviewed four cofounder video game startup finding identify six practice scenario video game startup conduct experiment challenge associated initial result could inform startup possibility challenge guide future research keywordsexperimentation video game startup challenge gaming startup introduction last year video game increasingly replaced traditional game leisure activity disrupted spend leisure time video game market become established evergrowing global industry two decade global video market worth usd billion revenue expected grow annual growth rate originally video game refer game require microprocessor use analogue intensity signal displayed cathode ray tube crt availability new imaging technology console home computer virtual reality vr device etc made idea video game conceptual le tied specific technology developing successful video game demanding complex process involves expertise various discipline eg softwaregame development art animation sound engineering etc may increase complexity communication coordination furthermore unclear whether game succeed market pose major risk game publisher investing new game development project unlike software startup video game startup build technological solution solve real problem instead combine art science craft offer fun entertainment experience game yet requirement metric applied yet must validated stage development process effective adoption implementation experimentation staged process study aim gain insight video game startup approach experimentation develop game guide study explore research question video game startup use experimentation practice background related work innovative endeavour required knowledge success generally unknown thus experimentation particularly useful acquiring knowledge reducing uncertainty experimentation approach based continuously identifying critical assumption transforming hypothesis prioritising testing experiment support refute however startup persist original idea rather experimenting research game startup exists limited mobile game development examplevanhala et al analysed six finnish mobile game startup found human capital important element business model moreover key challenge raise awareness game player kasurinen et al showed game developer generally pleased tool available experiment concept build prototype research also show iterative incremental nature agile method positively impact communication game quality ability find fun aspect mobile game feature contrast agile principle embracing change increase pressure meet deadline mobile game startup cautious considering minimum viable product concept first version game artefact released market need sufficient quality attract lock user adequate amount time allow development game study aim complement existing research investigating video game startup conduct experimentation research methodology performed semistructured interview gain insight video game startup conduct experimentation interview candidate identified first author collaborating blekinge business incubator bbi karlskronasweden first interview business coach incubator provided list founder independent indie internal video game startup operating inside larger company interview held recorded video conferencing system microsoft team lasting minute profile interviewee shown table audio recording transcribed analysed using thematic analysis transcript sent back interviewee followup question clarification result section report finding describing six experimentation scenario quote information herein derived interview transcript technical digital prototyping interview reveal early stage main challenge game development lie ideation process execution making game work hence first purpose experimentation ass technical feasibility team develop game game initial idea usually outlined game design document describes game high level user perspective team build prototype using engine eg unity test game complexity scope mana brigade slightly different approach taken company started performing experiment marching cube algorithm algorithm implemented unity user experience tested using vr device footnote marching cube algorithm extract surface mesh volume interviewee agree technical experimentation crucial evaluate capability build game example solve problem build game need key people certain skill expertise technical experimentation also showcase capability potential investor publisher
Original Title: Scalable Multi-Chain Coordination via the Hierarchical Longest Chain
  Rule
Original Transcription: "# Scalable Multi-Chain Coordination via the Hierarchical Longest Chain Rule\n\nYanni Georghiades\n\n_Department of ECE_\n\n_University of Texas Austin_\n\nAustin, TX\n\nyanni.georghiades@utexas.edu\n\nKarl Kreder\n\n_Chief Architect_\n\n_Dominant Strategies_\n\nAustin, TX\n\njonathan@dominantstrategies.io\n\nAlan Orwick\n\n_CEO_\n\n_Dominant Strategies_\n\nAustin, TX\n\nalan@dominantstrategies.io\n\nS. Vishwanath is an advisor to Dominant Strategies and incubates startups in the blockchain domain through ChainHub.\n\n###### Abstract\n\nThis paper introduces BlockReduce, a Proof-of-Work based blockchain system which achieves high transaction throughput by means of a hierarchy of merged mined blockchains, each operating in parallel on a partition of the overall application state. Most notably, the full PoW available within the network is applied to all blockchains in BlockReduce, and cross-blockchain state transitions are enabled seamlessly within the core protocol. This paper shows that, given a hierarchy of blockchains and its associated security model, BlockReduce scales superlinearly in transaction throughput with the number of blockchains operated by the protocol.\n\n blockchain, distributed systems, performance, scalability, proof-of-work\n\n## I Introduction\n\nBlockchains are popular as a means to enable trustless, decentralized, peer-to-peer value transfer. Among the approaches to achieving distributed consensus in cryptocurrencies, Proof-of-Work (PoW) is the oldest, most established, and arguably most well-understood. However, PoW-based cryptocurrencies are currently limited in terms of transaction throughput in comparison with traditional payment mechanisms such as credit cards. This has resulted in increased transaction costs and a greater shift towards alternate scaling mechanisms. In particular, Proof-of-Stake (PoS), other Proof-of-X consensus protocols, and a proliferation of Layer 2 protocols have been proposed and implemented in order to enable lower transaction fees. All of these approaches have different trust models in comparison with Proof-of-Work and, as a result, come with their own associated challenges and weaknesses.\n\nThe two most notable cryptocurrencies, Bitcoin and Ethereum, are both PoW-based1 and have a maximum throughput of under 20 transactions per second [1, 2], whereas Visa alone can execute more than 2,000 transactions per second on their credit card network [2]. Indeed, it is now presumed (without proof) by a majority of people that PoW cryptocurrencies simply cannot meet the throughput requirements of a global currency.\n\nFootnote 1: at the time of writing, Ethereum has not yet attempted the transition to Proof-of-Stake\n\nIn this paper, we introduce BlockReduce, a PoW cryptocurrency that achieves high transaction throughput (as a Layer 1 protocol). We describe BlockReduce by first identifying the primary factors that cause low transaction throughput (and therefore, large fees) in PoW blockchains. We then address and ameliorate each factor, resulting in a truly scalable solution.\n\nThe primary tools underlying our solution for scalability are as follows:\n\n**Latency-dependent Clustering of Network Nodes**: As noted across the literature [3], network latency is one of the biggest factors in the scalability of blockchain systems. In our work, we translate this understanding of network latency into a suitable hierarchical clustering, where nodes self-partition into a hierarchy of sub-networks with which they share low-latency connections. Each sub-network operates its own blockchain to validate and update a partition of the overall application state.\n\n**Transaction-dependent Security**: Currently, a vast majority of PoW cryptocurrencies afford the same level of security--where, for our purposes, security refers to the amount of work an adversary would need to perform in order to succeed in a double-spend attack--for all transactions, regardless of the economic value of the transaction. However, in most human-commerceinteractions, low-value transactions are not secured to the same level as high-value transactions. For example, credit card transactions of low value often do not require signatures, while higher value transactions go through a more stringent signature verification process. Ultimately, even in the blockchain domain, we believe that security should be transaction-value dependent, with high-value blocks (and associated transactions) afforded greater security guarantees. Thus, the amount of work applied to all transactions for the sake of settlement need not be the same in the short-term, although in order to prevent transaction conflicts from proliferating, eventually all transactions in BlockReduce must be validated and secured by the maximum amount of work available to the system.\n\n**Merged Mining**: BlockReduce is composed of a tree of blockchains operated in parallel. Rather than performing PoW computations on a single block header, miners simultaneously mine a blockchain at each level of the tree using the same PoW computations, and one PoW solution might correspond to a block in multiple blockchains. This has two effects in BlockReduce. The first is that all miners always mine on the root of the tree, meaning the root blockchain receives all of the mining power of the network. The second is that blocks are found periodically which are shared between blockchains at different levels of the tree (these blocks are called _coincident blocks_), which allows work to be shared across blockchains and also enables cross-blockchain state-transitions.\n\n### _Proof-of-Work Blockchains_\n\nThe first published instance of Proof-of-Work being applied to blockchains is Nakamoto's famous Bitcoin protocol [4], where Nakamoto combined PoW with a block selection rule called the Longest Chain Rule to achieve Nakamoto consensus on transactions. BlockReduce uses PoW to reach a similar form of consensus on each blockchain in the tree. In order to accommodate for this hierarchical structure, we define a variant of the Longest Chain Rule which we refer to as the Hierarchical Longest Chain Rule. We describe these aspects of the BlockReduce protocol in more detail in Sections IV-B and IV-D.\n\n### _Proof-of-Work Efficiency_\n\nA significant limiter of transaction throughput in public blockchains is the amount of time it takes for data to propagate within the peer-to-peer network after blocks are mined. In order to provide intuition about this phenomenon, we define the _PoW efficiency_ of a blockchain as the fraction of PoW computations which contribute to the canonical chain (i.e., the chain of blocks which are committed to the transaction ledger/state machine). In the ideal setting in which all nodes follow the protocol and there are no network delays on block propagation, the PoW efficiency, \\(\\mathcal{E}\\), is 1. This is because when there are no propagation delays, all miners instantaneously adopt each new block into their canonical chain.\n\nTo model a more realistic setting, we define \\(\\lambda\\) as the total rate of block generation by the network and the network delay \\(\\Delta\\) as the time between when a block is found and when it is received by all nodes in the network. Under this model, [5] computes the effective block generation rate to be \\(\\frac{\\lambda}{1+\\lambda\\Delta}\\), resulting in a PoW efficiency of \\(\\mathcal{E}=\\frac{1}{1+\\lambda\\Delta}\\).\n\nFurthermore, if a fraction \\(\\beta\\) of nodes are adversarial and are mining a private branch of the blockchain as part of an attack, then [5] computes the PoW efficiency of honest nodes to be \\(\\mathcal{E}=\\frac{(1-\\beta)}{1+(1-\\beta)\\lambda\\Delta}\\), which varies inversely with \\(\\Delta\\). On the other hand, assuming the adversary experiences negligible network delay with itself while mining a private chain (i.e., \\(\\Delta\\approx 0\\)), then their PoW efficiency is approximately 1. Herein lies the problem. If \\(\\Delta\\) is fixed, then an adversary's relative advantage over honest nodes increases as the block generation rate increases. Systems such as Bitcoin suppress \\(\\lambda\\) in order to reduce the impact of \\(\\Delta\\) on the PoW efficiency of honest nodes. This phenomenon is discussed in various works [6, 7], and several solutions have been presented which assume \\(\\Delta\\) to be fixed. In BlockReduce, we partition the network into sub-networks so that the \\(\\Delta\\) experienced by each sub-network is smaller than that of the overall network, thereby allowing each sub-network to operate a blockchain with a higher block generation rate. We can achieve this while maintaining an equal PoW efficiency across all blockchains, which we believe is critical to a truly scalable blockchain. Moreover, we utilize the Hierarchical Longest Chain Rule described in Section IV-D to guarantee that each blockchain receives the maximum amount of work available to the network, thereby achieving high transaction throughput without sacrificing security or PoW efficiency.\n\n### _Our Contributions_\n\nWe present BlockReduce, a PoW blockchain system which enables high transaction throughput by utilizing a hierarchy of merged mined blockchains operating in parallel on non-overlapping partitions of the application state. To the best of our knowledge, BlockReduce is the first protocol which promises superlinear scaling with the number of parallel blockchains it operates while still securing each blockchain with the maximum amount of work available to the network. We introduce the Hierarchical Longest Chain Rule as a block-selection mechanism which allows each blockchain in the hierarchy to inherit the work of its parent blockchain and also enables native, cross-blockchain state transitionsbetween any state partitions in the hierarchy. Finally, we analyze the performance of the protocol to demonstrate the superlinear scalability of BlockReduce.\n\n## II Related Work\n\nThere have been a number of proposals for scaling transaction throughput in blockchains. We provide a brief summary of several types of approaches.\n\n### _Parallel PoW Blockchains_\n\nIn a manner conceptually similar to BlockReduce, many protocols aim to achieve high transaction throughput by operating several blockchains in parallel. The PoW version of Parallel Chains [8] involves mining a metablock containing candidate blocks for a number of parallel chains which operate non-overlapping state partitions. Notably, Parallel Chains does not support cross-blockchain transactions and is therefore of more limited application than BlockReduce. Chainweb [9] is another protocol operating many parallel chains, where each block header references the headers of other chains in order to braid the chains together. Chainweb allows cross-blockchain state transitions and also features a mechanism by which chains inherit work from one another, but it can achieve only a linear increase in transaction throughput with the number of parallel chains whereas BlockReduce achieves superlinear scaling.\n\n### _Proof-of-Stake Protocols_\n\nMany Proof-of-Stake protocols have been proposed and implemented, such as Ouroboros Praos [10] and Ethereum's planned move to Proof-of-Stake, as a means to enable high transaction throughput and low settlement times. However, Proof-of-Stake protocols currently do not afford the same security guarantees as PoW and also often suffer from shortcomings such as the \"nothing at stake\" problem or predictability on the next eligible validator [11].\n\n### _Layer 2 Protocols_\n\nThere are multiple Layer 2 protocols (i.e., protocols which operate independently and only periodically interact with the blockchain) which have been developed in order to facilitate high transaction throughput. These include Starkware, Polygon, and Lightning among many others [12]. Although some such architectures can achieve high transaction throughput, Layer 2 solutions inevitably require alternate trust models from the core blockchain protocol which may not be suited for all use cases. BlockReduce scales as a Layer 1 protocol and does not require those additional assumptions to achieve high transaction throughput.\n\n## III Model\n\nIn this section, we describe the network model under which we analyze the BlockReduce protocol. We adopt a simple _overlay_-network model to understand the interactions between nodes: that of a \\(d\\)-regular graph on \\(N\\) network nodes. This model arises from the standard set forth by Bitcoin, where the protocol executed by each node attempts by default to maintain a set of 8 peers.\n\nWe assume a synchronous, round-based model for block propagation. According to [13], with probability \\(1-o(1)\\), the number of synchronous rounds required for data to broadcast via gossip in a random \\(d\\)-regular network of \\(N\\) nodes is\n\n\\[(1+o(1))\\big{(}\\frac{1}{\\ln(2(1-\\frac{1}{d}))}-\\frac{1}{d\\ln(1-\\frac{1}{d})} \\big{)}\\ln N. \\tag{1}\\]\n\nWe use this result to characterize the overall network propagation delay \\(\\Delta\\) (i.e., the amount of time it takes for a single block to be propagated across the network) in terms of the average single-link propagation delay, \\(\\delta\\), as follows.\n\n\\[\\Delta=\\delta(1+o(1))\\big{(}\\frac{1}{\\ln(2(1-\\frac{1}{d}))}-\\frac{1}{d\\ln(1- \\frac{1}{d})}\\big{)}\\ln N. \\tag{2}\\]\n\nAdopting the shortened notation of [13], this gives us the following bound:\n\n\\[\\Delta<\\delta C_{d}\\ln N. \\tag{3}\\]\n\nWe define \\(\\Delta\\) in this way to show that \\(\\Delta\\) decreases as \\(\\delta\\) or \\(N\\) decrease. In Section IV we use this understanding to show that \\(\\Delta\\) is reduced in higher order blockchains within the BlockReduce protocol, thereby allowing for higher block generation rates while still maintaining high PoW efficiency within those blockchains.\n\n## IV A Hierarchy of Blockchains\n\nIn this section, we describe the BlockReduce protocol and show that all nodes operating a particular blockchain are able to agree upon its state.\n\n### _Notation_\n\nThe BlockReduce protocol requires that nodes self-partition into a hierarchy of sub-networks, where the hierarchy is a tree consisting of \\(R\\) levels called _orders_. Each sub-network is denoted \\(\\mathcal{N}_{\\vec{v}}\\), where \\(\\vec{v}\\) is the unique path from the root to the specified node in the hierarchy tree. The root of the hierarchy tree is of order \\(1\\), and the leaves are of order \\(R\\). An example of a BlockReduce hierarchy structure and its associated sub-network partitioning is provided in Figures 1 and 2. In this example, the hierarchy has three orders, and networks of order 1 and 2 each have two child sub-networks.\n\nEach sub-network \\(\\mathcal{N}_{\\vec{v}}\\) operates a blockchain \\(\\mathcal{B}_{\\vec{v}}\\) to achieve consensus on a partition of the state \\(\\mathcal{S}_{\\vec{v}}\\). Blockchains of order \\(r\\) have block arrivals at a rate \\(\\lambda_{r}\\), network delay \\(\\Delta_{r}\\), and an average single-link propagation delay \\(\\delta_{r}\\).\n\nWe adopt a functional notation when discussing relationships between sub-networks, blockchains, and state partitions. We denote \\(\\mathsf{parent}(\\mathcal{N}_{\\vec{v}})\\) to be the parent sub-network of \\(\\mathcal{N}_{\\vec{v}}\\) in the hierarchy tree and \\(\\mathsf{order}(\\mathcal{N}_{\\vec{v}})=|\\vec{v}|\\) to be the order of \\(\\mathcal{N}_{\\vec{v}}\\). We often overload this functional notation with inputs \\(\\mathcal{B}_{\\vec{v}}\\), \\(\\mathcal{S}_{\\vec{v}}\\), or simply \\(\\vec{v}\\), and these functions are evaluated in the same way.\n\n### _Merged Mining_\n\nMining in BlockReduce is similar to mining in a standard PoW blockchain except that, in BlockReduce, multiple blocks are mined simultaneously using a technique called _merged mining_[14], and the Longest Chain Rule (LCR) introduced by Bitcoin [4] is modified to accommodate the hierarchical structure of BlockReduce.\n\nEach BlockReduce miner selects an order \\(R\\) blockchain (a leaf node in the tree) and simultaneously mines each blockchain along the path from root to leaf. For example, the miner might select the leaf \\(\\mathcal{B}_{\\{1,1,1\\}}\\), in which case they would simultaneously mine \\(\\mathcal{B}_{\\{1\\}}\\), \\(\\mathcal{B}_{\\{1,1\\}}\\), and \\(\\mathcal{B}_{\\{1,1,1\\}}\\). To accomplish this, miners construct a block for each blockchain they are mining, concatenate the block headers together, and perform PoW computations on the combined block header; as a result, those blocks will all share the same block hash.\n\nBlockchains closer to the root of the hierarchy have increasing and overlapping PoW difficulties so thaat a block which meets the difficulty requirement of a blockchain of order \\(r\\) also meets the difficulty requirement of each blockchain of order greater (i.e., further from the root) than \\(r\\). For example, Figure 3 depicts a sequence of blocks in a system with 3 orders. In this example, the difficulty requirement for an order 1 block is that the block hash has 12 leading 0's (in the binary expansion), whereas an order 2 block requires only 8 leading 0's, and an order 3 block requires 4 leading 0's. In this case, an order 1 block with 12 leading 0's also meets the difficulty requirement of each other order. A block which is shared by multiple orders in this way is called a _coincident block_ because it serves to coincide these blockchains under a shared block reference. In Section IV-D, we show that under the Hierarchical Longest Chain Rule, coincident blocks impose a partial ordering on blockchains of different orders which enables cross-blockchain state transitions.\n\n### _Partitioning the Ledger State_\n\nWe adopt a generic state model in which each transaction constitutes an update to the application state. This generality allows BlockReduce to support the Unspent Transaction Output (UTXO) model, in which the application state is simply the set of all UTXOs, as well as more sophisticated smart contract models, where the application state is the smart contract state. State is partitioned between all blockchains to prevent\n\nFigure 1: Hierarchy tree with 3 orders, where each box is a sub-network which operates a distinct blockchain.\n\nFigure 3: Example block visualization for a system with 3 orders. Each box represents a block, and the value inside the box is the hexadecimal representation of the block hash. Blocks in the bottom row make up blockchain \\(\\mathcal{B}_{\\{1,1,1\\}}\\) and so forth. Block \\(B_{2}\\) meets the difficulty requirement of \\(\\mathcal{B}_{\\{1,1\\}}\\) and is therefore a coincident block shared by orders 2 and 3, \\(B_{4}\\) is also a coincident block but is shared by all 3 orders, and blocks \\(B_{1}\\) and \\(B_{3}\\) only meet the difficulty requirement of \\(\\mathcal{B}_{\\{1,1,1\\}}\\).\n\nFigure 2: Illustration of topological network segregation: a) full network b) two order 2 sub-networks c) four order 3 sub-networks.\n\nduplication, and for the purpose of cross-blockchain state transitions, each transaction must specify an origin blockchain \\(\\vec{v_{o}}\\) and a destination blockchain \\(\\vec{v_{d}}\\). If the origin and destination of a transaction are the same, the state transition occurs in the same way as a traditional blockchain implementation. If the origin of a transaction is different from its destination, for example if an asset is being tranferred from one blockchain to another, then the state update involves removing the asset from the origin state and adding it to the destination state. This leads to the following protocol rule.\n\n**Protocol Rule 1.** In order for a transaction with origin \\(\\vec{v_{o}}\\) to be valid, the state that it modifies must be valid with respect to \\(\\mathcal{S}_{\\vec{v_{o}}}\\).\n\nFor example, if a user is attempting to move an asset from \\(\\vec{v_{o}}\\) to \\(\\vec{v_{d}}\\), then the transaction must have origin \\(\\vec{v_{o}}\\) and the user must demonstrate ownership of the asset in \\(\\vec{v_{o}}\\).\n\n### _The Hierarchical Longest Chain Rule_\n\nBlockReduce utilizes a novel consensus rule to select the _canonical chain_--i.e., the chain of blocks referencing state updates to be applied--for each blockchain. In Bitcoin and other more traditional systems, the Longest Chain Rule (LCR) stipulates that the canonical chain is the sequence of valid blocks with the most work (often referred to as the longest chain or, more accurately, the heaviest chain) [4]. BlockReduce follows a similar rule but must also account for the existence of coincident blocks within the hierarchy.\n\nBefore defining the _Hierarchical Longest Chain Rule_ (HLCR), we first define what conditions a block must meet to be considered valid. While specific requirements may vary between implementations, such as varying block size, transaction and/or smart contract structure, or block header composition, in general we can define a valid block as follows.\n\n**Protocol Rule 2** (Valid Block).: A block is considered valid if it meets all protocol rules and all of its predecessors (of any order) are also valid.\n\nIn other words, a valid block must conform to the rules of the blockchain and must reference no prior blocks which deviate from those rules. Importantly, because a coincident block has a predecessor at multiple orders, if _any_ of its predecessors are invalid then the block is also invalid. This guarantees that a coincident block is either valid in all blockchains for which it meets the difficulty requirement or none of them. Next, we define the HLCR which miners use to determine the canonical chain in BlockReduce.\n\n**Protocol Rule 3** (The Hierarchical Longest Chain Rule).: The canonical chain of the root blockchain \\(\\mathcal{B}_{\\{1\\}}\\) is the heaviest sequence of valid blocks in \\(\\mathcal{B}_{\\{1\\}}\\). The canonical chain of any blockchain \\(\\mathcal{B}_{\\vec{v}}\\) of order greater than \\(1\\) is the heaviest sequence of blocks which contains _all_ coincident blocks between \\(\\mathcal{B}_{\\vec{v}}\\) and \\(\\mathsf{parent}(\\mathcal{B}_{\\vec{v}})\\) which are present in the canonical chain of \\(\\mathsf{parent}(\\mathcal{B}_{\\vec{v}})\\), and _no_ coincident blocks between \\(\\mathcal{B}_{\\vec{v}}\\) and \\(\\mathsf{parent}(\\mathcal{B}_{\\vec{v}})\\) which _are not_ present in the canonical chain of \\(\\mathsf{parent}(\\mathcal{B}_{\\vec{v}})\\).\n\nIn other words, the canonical chain for the root blockchain is selected via the standard LCR. For each other blockchain \\(\\mathcal{B}_{\\vec{v}}\\) of order greater than \\(1\\), the canonical chain must include all coincident blocks that are shared between \\(\\mathcal{B}_{\\vec{v}}\\) and \\(\\mathsf{parent}(\\mathcal{B}_{\\vec{v}})\\) that are present in the canonical chain of \\(\\mathsf{parent}(\\mathcal{B}_{\\vec{v}})\\). However, if there is some coincident block between \\(\\mathcal{B}_{\\vec{v}}\\) and \\(\\mathsf{parent}(\\mathcal{B}_{\\vec{v}})\\) that is not in the canonical chain of \\(\\mathsf{parent}(\\mathcal{B}_{\\vec{v}})\\), then it cannot be in the canonical chain of \\(\\mathcal{B}_{\\vec{v}}\\).\n\nIf an incoming block causes the canonical chain to change, then the state updates dictated by blocks which are no longer part of the canonical chain must be reverted and the new state updates applied. This is why the canonical chain must contain all coincident blocks that are shared with the parent blockchain, as otherwise a cross-blockchain state transition which has been applied at both origin and destination could later be reverted at the origin but not the destination, thus causing an inconsistency in the overall network state.\n\n### _Inter-Blockchain Ordering via Coincident Blocks_\n\nWithin a single blockchain, all blocks in the canonical chain are totally ordered according to their distance from the genesis block. Between blockchains of different orders, blocks are partially ordered due to the coincident blocks which arise from merged mining.\n\nIntuitively, a coincident block serves as a shared point in \"time\" between blockchains, allowing nodes to agree upon which blocks came \"before\" the coincident block and which blocks came \"after.\" For example, in Figure 3, nodes in \\(\\mathcal{N}_{\\{1,1\\}}\\) which have received block \\(B_{4}\\) can all agree that block \\(B_{3}\\) came before \\(B_{4}\\) even if they are not mining \\(\\mathcal{B}_{\\{1,1,1\\}}\\).\n\nThis property of coincident blocks allows all nodes in both \\(\\mathcal{N}_{\\vec{v}}\\) and \\(\\mathsf{parent}(\\mathcal{N}_{\\vec{v}})\\) to agree on the existence and ordering of all blocks prior to the coincident block in either blockchain. In Section IV-G, we show that this enables cross-blockchain state transitions to occur, as nodes operating the destination blockchain can agree on precisely if and when the state transition should be applied to the destination state.\n\n### _Inherited Work via Coincident Blocks_\n\nWe argue that, for the sake of short term settlement, blocks containing transactions of low economic value may be secured with a fraction of the maximum work available to the network, as the potential economic loss from a successful attack is small. However, in the longer term, this security level is not sufficient. If a block containing a cross-blockchain state transition were to be removed from the canonical chain of \\(\\mathcal{B}_{\\vec{v_{o}}}\\), but the state transition for that transaction had already been applied to \\(\\mathcal{S}_{\\vec{v_{o}}^{\\prime}}\\), then an inconsistency in the overall application state might arise.\n\nThe HLCR prevents this type of inconsistency by requiring that the canonical chain of a child blockchain must contain any coincident blocks that are shared with its parent blockchain, regardless of the number of blocks in any competing fork. In other words, a coincident block is removed from the canonical chain of \\(\\mathcal{N}_{\\vec{v}}\\) if and only if it is first removed from the canonical chain of \\(\\mathsf{parent}(\\mathcal{N}_{\\vec{v}})\\). The result is that \\(\\mathcal{N}_{\\vec{v}}\\)_inherits_ the work applied to \\(\\mathsf{parent}(\\mathcal{N}_{\\vec{v}})\\), because an adversary attempting to remove the block from \\(\\mathcal{N}_{\\vec{v}}\\) would need to have sufficient mining power to remove it from \\(\\mathsf{parent}(\\mathcal{N}_{\\vec{v}})\\).\n\n### _State Updates_\n\nIn order to guarantee consistent application state between nodes, it is sufficient that all nodes in \\(\\mathcal{N}_{\\vec{v}}\\) agree on the initial state (which can be defined in the genesis block) and then apply the same state updates to \\(\\mathcal{S}_{\\vec{v}}\\) in the same order. This is simple for transactions with the same origin and destination, as the state updates can be applied in the order that they are referenced by that blockchain. For transactions with different origin and destination, the state transition must be handled in two steps. First, \\(\\mathcal{S}_{\\vec{v_{o}}^{\\prime}}\\) is updated according to the transaction (e.g., the removal of an asset from the origin state) as soon as it is included in a block in the canonical chain of \\(\\mathcal{B}_{\\vec{v_{o}}^{\\prime}}\\). \\(\\mathcal{S}_{\\vec{v_{o}}^{\\prime}}\\), however, cannot be updated immediately, as there is initially no way for nodes operating \\(\\mathcal{B}_{\\vec{v_{o}}^{\\prime}}\\) to agree upon when the state transition should be applied. Protocol Rule 4 describes the criteria which must be met for a state transition to be applied to \\(\\mathcal{S}_{\\vec{v_{o}}^{\\prime}}\\), and Protocol Rule 5 describes the order in which all state updates are applied when a block is processed.\n\n**Protocol Rule 4**.: Let \\(tx\\) be a transaction with origin \\(\\vec{v_{o}}\\) and destination \\(\\vec{v_{d}}\\), and let \\(\\vec{v_{a}}\\) be the highest order common ancestor between \\(\\vec{v_{o}}\\) and \\(\\vec{v_{d}}\\). The state transition pertaining to \\(\\mathcal{S}_{\\vec{v_{o}}^{\\prime}}\\) is applied as soon as the block containing \\(tx\\) is a part of the canonical chain of \\(\\mathcal{B}_{\\vec{v_{o}}^{\\prime}}\\). The state transition pertaining to \\(\\mathcal{S}_{\\vec{v_{d}}^{\\prime}}\\), however, is only applied after a coincident block is found which is shared by \\(\\mathcal{B}_{\\vec{v_{o}}^{\\prime}}\\) and \\(\\mathcal{B}_{\\vec{v_{a}}^{\\prime}}\\) and, if \\(\\mathsf{order}(\\mathcal{B}_{\\vec{v_{d}}^{\\prime}})>\\mathsf{order}(\\mathcal{B}_ {\\vec{v_{a}}^{\\prime}})\\), a subsequent coincident block is found which is shared by \\(\\mathcal{B}_{\\vec{v_{d}}^{\\prime}}\\) and \\(\\mathcal{B}_{\\vec{v_{a}}^{\\prime}}\\).\n\nIntuitively, a chain of coincident blocks must be constructed which link \\(\\vec{v_{o}}\\) and \\(\\vec{v_{d}}\\) through predecessor references, and if \\(\\vec{v_{o}}\\) and \\(\\vec{v_{d}}\\) are in different branches of the tree, the chain must travel \"up\" and then \"back down\" the hierarchy until that chain is established. Nodes in \\(\\mathcal{N}_{\\vec{v_{o}}^{\\prime}}\\) can verify that the block containing \\(tx\\) is in the canonical chain of \\(\\mathcal{B}_{\\vec{v_{o}}^{\\prime}}\\) because of the coincident block between \\(\\mathcal{B}_{\\vec{v_{o}}^{\\prime}}\\) and \\(\\mathcal{B}_{\\vec{v_{a}}^{\\prime}}\\), and they can also agree upon the existence of the coincident block between \\(\\mathcal{B}_{\\vec{v_{d}}^{\\prime}}\\) and \\(\\mathcal{B}_{\\vec{v_{a}}^{\\prime}}\\) and the updates to \\(\\mathcal{S}_{\\vec{v_{d}}^{\\prime}}\\) which result from that coincident block.\n\nThe next rule defines the order in which eligible state updates are to be applied, as all nodes must apply updates in the same order to guarantee consistent state.\n\n**Protocol Rule 5**.: The state transitions for a given block \\(B\\) in \\(\\mathcal{B}_{\\vec{v}}\\) are applied to \\(\\mathcal{S}_{\\vec{v}}\\) in the following order. First, if \\(B\\) is a coincident block, all transactions with destination \\(\\vec{v}\\) which are eligible to be applied to \\(\\mathcal{S}_{\\vec{v}}\\) according to Protocol Rule 4 are applied in order by highest origin order to lowest origin order. Transactions with the same origin order are applied in order of the blockchain index (i.e., from left to right in the tree) at that order, and transactions with the same origin index are applied in chronological order according to their inclusion in their origin blockchain. After that, all transactions directly referenced by \\(B\\) are applied to \\(\\mathcal{S}_{\\vec{v}}\\) in the order in which they are referenced by \\(B\\).\n\nProtocol Rules 3, 4, and 5 guarantee that all nodes in the same sub-network perform state transitions in the same order, meaning any two nodes which agree on the canonical chain will have consistent local state. This is formalized by Theorem IV.1.\n\n**Theorem IV.1**.: _For any given blockchain \\(\\mathcal{B}_{\\vec{v}}\\), any two correct nodes in \\(\\mathcal{N}_{\\vec{v}}\\) which agree on the canonical chain of \\(\\mathcal{B}_{\\vec{v}}\\) will agree on \\(\\mathcal{S}_{\\vec{v}}\\)._\n\nWe prove Theorem IV.1 inductively, first remarking that any two correct nodes must agree upon the genesis block and the associated state when the blockchain is instantiated. We then show the inductive step--for each block in the canonical chain of \\(\\mathcal{B}_{\\vec{v}}\\), both nodes must apply the same state updates to \\(\\mathcal{S}_{\\vec{v}}\\) and in the same order. We prove this via contradiction, showing on a case by case basis that regardless of the origin and destination of a transaction, if one node applies the state update for that transaction and the other does not, then at least one of the nodes breaks a protocol rule. Therefore both nodes agree on the initial state and each subsequent state update, and the statement follows. Due to space constraints, we omit the full proof from this paper.\n\nAs a corollary of Theorem IV.1, all correct nodes in \\(\\mathcal{N}_{\\{1\\}}\\) which agree on the canonical chain of \\(\\mathcal{B}_{\\{1\\}}\\) also agree on \\(\\mathcal{S}_{\\{1\\}}\\). This ensures that all nodes in the system agree upon the state of the root blockchain in BlockReduce, thereby achieving similar guarantees to that of a single-blockchain system.\n\n\n\n## V Analysis\n\nIn this section we show that BlockReduce achieves transaction throughput that scales superlinearly with the number of blockchains in each order.\n\n### _Decreased Propagation Delay via Network Partitioning_\n\nSub-networks of order \\(r>1\\) (i.e., all but the root sub-network) have a network delay \\(\\Delta_{r}\\) which is strictly less than \\(\\Delta_{1}\\), where \\(\\Delta_{1}\\) is analagous to the \\(\\Delta\\) experienced by a traditional blockchain operated by a full network of \\(N\\) nodes. This is due to the decreased size of the sub-networks and the ability for nodes to select the sub-network with which they share low-latency peer connections in order to reduce the overall block propagation time that they experience.\n\nIt is clear from Equation 3 that a smaller network naturally has lower propagation delays than a larger network. In order to enhance this intuition, if we assume that there are \\(q\\) sub-networks of order \\(r\\) and each sub-network is of equal size, then we can bound \\(\\Delta_{r}\\) as follows:\n\n\\[\\Delta_{r} <\\delta_{r}C_{d}\\ln\\big{(}\\frac{N}{q}\\big{)} \\tag{4a}\\] \\[<\\Delta_{1}-\\delta_{r}C_{d}\\ln q \\tag{4b}\\]\n\nThen the propagation delay for any order will be strictly increasing with the number of sub-networks in that order.\n\nAdditionally, we remark that under the distribution of node-to-node latencies in Bitcoin as measured by [15], latency between nodes can vary significantly from one pair to the next. We assume that in the absence of a protocol mechanism requiring nodes to join a particular sub-network, each node will elect to mine in the sub-network which minimizes their peer-to-peer latencies to reduce the probability that their blocks are lost due to network forks. As a result, we argue that in each sub-network of order greater than \\(1\\), the average per-link propagation delay \\(\\delta_{r}\\) between nodes in order \\(r\\) sub-networks will be smaller than the delay between nodes in \\(\\mathcal{N}_{(1)}\\)--i.e., \\(\\delta_{r}<\\delta_{1}\\) for all \\(r>1\\). While we do not use this result in our proof, it nonetheless further supports the claim in Theorem V.1.\n\nOverall, the network propagation delay within each sub-network will be much smaller than that of the network as a whole (i.e., the network delay of a similar system such as Bitcoin), and as a result the rate of block generation can be much higher within each sub-network.\n\n### _Aggregate Throughput_\n\nIn this section, we show that within each order in the hierarchy, the total transaction throughput increases as the number of blockchains in that order increases even if the PoW efficiency remains fixed for each blockchain. Moreover, we show that the increase is superlinear with the number of blockchains in each order, as each additional blockchain further partitions the network and thus reduces the propagation delay experienced by nodes in each sub-network. We state this property of BlockReduce more formally in the following theorem.\n\n**Theorem V.1**.: _The aggregate transaction throughput of each order in the BlockReduce protocol scales superlinearly with the number of blockchains in that order, and all blockchains in the hierarchy have identical PoW efficiency._\n\nWe prove this theorem by showing that the effective block generation rate of an order \\(r>1\\) blockchain grows as the number of order \\(r\\) blockchains increases.\n\nProof.: Recall that \\(\\lambda_{r}\\) is the total block generation rate of a blockchain of order \\(r\\), then the effective block generation rate is \\(\\lambda_{r}^{*}=\\frac{\\lambda_{r}}{1+\\lambda_{r}\\Delta_{r}}\\), and the PoW efficiency is \\(\\mathcal{E}_{r}=\\frac{1}{1+\\lambda_{r}\\Delta_{r}}\\). It suffices to show that if \\(q\\) is the number of blockchains of order \\(r\\), \\(\\lambda_{r}^{*}\\) increases as \\(q\\) increases.\n\nWe hold the PoW efficiency fixed between all blockchains to that of the root blockchain, i.e., \\(\\frac{1}{1+\\lambda_{1}\\Delta_{1}}=\\frac{1}{1+\\lambda_{r}\\Delta_{r}}\\) Substituting the results from Equation 4, we get\n\n\\[\\frac{1}{1+\\lambda_{1}\\Delta_{1}}>\\frac{1}{1+\\lambda_{r}(\\Delta_{1}-\\delta_{r} C_{d}\\ln q)}, \\tag{5}\\]\n\nwhich simplifies to\n\n\\[\\lambda_{r}>\\frac{\\lambda_{1}\\Delta_{1}}{\\Delta_{1}-\\delta_{r}C_{d}\\ln q}. \\tag{6}\\]\n\nThen the effective block generation rate--i.e., the rate at which blocks are appended to the canonical chain--for an order \\(r\\) blockchain with the same PoW efficiency as that of the root blockchain is\n\n\\[\\lambda_{r}^{*}>\\frac{\\lambda_{1}\\Delta_{1}}{(\\Delta_{1}-\\delta_{r}C_{d}\\ln q )(1+\\lambda_{1}\\Delta_{1})}. \\tag{7}\\]\n\nClearly, the right hand size of this equation increases with \\(q\\), meaning \\(\\lambda_{r}^{*}\\) does as well. Then because all blocks are assumed to contain the same number of transactions, the statement follows. \n\n## VI Discussion and Future Work\n\nBlockReduce is a PoW-based blockchain system which achieves high transaction throughput through a hierarchy of merged mined blockchains which each operate a partition of the overall application state in parallel. Critically, the full PoW available to the network is applied to all blockchains in BlockReduce, andcross-blockchain state transitions are enabled seamlessly within the core protocol. In this section, we highlight several discussion points and avenues for future work.\n\n#### V-B1 Self-selection of sub-network participation.\n\nMining nodes in BlockReduce are allowed to mine any vertical slice of blockchains within the PoW hierarchy tree. However, because the vast majority of miners in any PoW blockchain are economically motivated, most miners will elect to mine the blockchains which grant them the highest rewards. In this way, blockchains within each order will be self-balancing as miners naturally drift towards any available blockchains with reduced competition. In the absence of competitive advantage in mining power, miners will elect to mine the blockchains with which they share the lowest latency connections in order to minimize the probability that their blocks are lost to network forks. We believe that this alignment of incentives should result in the formation of low-latency clusters of mining nodes which are able to achieve very high PoW efficiency, although we leave the construction of a suitable incentive mechanism and a game-theoretical analysis to future work.\n\n#### V-B2 Low-value transaction security and settlement time tradeoffs.\n\nBlockReduce users have a high degree of flexibility when transacting, as they can control both the short-term security and the settlement time of their transactions by selecting which blockchain to transact in. Higher order blockchains have low settlement times and low security in the short term, as the sub-networks operating these blockchains have a high block generation rate but only control a fraction of the overall mining power. This is ideal for transactions of low economic value, as the consequence of a low-value transaction being removed from the canonical chain is minor. Users desiring a higher degree of security might elect to transact in lower order blockchains in order to utilize a larger fraction of the PoW of the network despite the tradeoff of longer settlement times. The precise characterization of this tradeoff will be specific to a particular implementation, and it is likely that any BlockReduce implementation will provide a default wallet which is capable of selecting the appropriate transaction location in an automated fashion.\n\n#### V-B3 Expected hierarchy structure and future implementation.\n\nAlthough we have designed BlockReduce to support an arbitrary hierarchy tree, real-world hardware and network infrastructure as well as timing requirements of a functional blockchain network will limit both the number of orders and the number of blockchains per order that are realizable in practice. As the number of blockchains in the BlockReduce hierarchy increases, the time required for a cross-blockchain state transition also increases due to the decreasing relative frequency of coincident blocks linking each blockchain. For example, if a blockchain \\(\\mathcal{B}\\) has 3 child blockchains, then an average of 1 in every 3 blocks in \\(\\mathcal{B}\\) will be coincident with each child blockchain. If this number increases to 100 child blockchains, the expected time required for a coincident block to be found with one particular child increases dramatically. Implementation and empirical testing will be required to determine the optimal configuration for any given use case and network topology.\n\n#### V-B4 Conclusion\n\nWe presented BlockReduce, a blockchain system which operates a hierarchy of blockchains in parallel, and showed that BlockReduce achieves transaction throughput that scales superlinearly with the number of blockchains operated by the system without reducing the security of each transaction.\n\n## References\n\n* [1]M. A. Abadi, A. A.\n\n\n\n+++ ==WARNING: Truncated because of repetitions==\n. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A. A\n+++\n\n* [14] X. Xu, I. Weber, M. Staples, L. Zhu, J. Bosch, L. Bass, C. Pautasso, and P. Rimba, \"A taxonomy of blockchain-based systems for architecture design,\" in _2017 IEEE international conference on software architecture (ICSA)_. IEEE, 2017, pp. 243-252.\n* [15] T. Neudecker, \"Characterization of the Bitcoin Peer-to-Peer Network (2015-2018),\" vol. 2019, no. 1, 2019."

Title: Experimentation in Early-Stage Video Game Startups: Practices and
  Challenges
Transcription: # Experimentation in Early-Stage Video Game Startups: Practices and Challenges+
Footnote †: This is the authors’ version of the manuscript accepted for publication in the Proceedings of 14th International Conference on Software Business (ICSOB), 2023. This manuscript version is made available under the CC-BY-NC-ND4.0 license. [http://creativecommons.org/](http://creativecommons.org/) licenses/by-nc-nd/4.0

Henry Edison

1Blekinge Institute of Technology, Karlskrona, Sweden

1henry.edison@bth.se

Jorge Melegati

2Free University of Bozen-Bolzano, Bolzano, Italy

2JorgeAugusto.Melegati@oncalves@unibz.it

Elizabeth Bjarnason

3Lund University, Lund, Sweden

3elizabeth.bjarnason@cs.lth.se

###### Abstract

Experimentation has been considered critical for successful software product and business development, including in video game startups. Video game startups need "wow" qualities that distinguish them from the competition. Thus, they need to continuously experiment to find these qualities before running out of time and resources. In this study, we aimed to explore how these companies perform experimentation. We interviewed four co-founders of video game startups. Our findings identify six practices, or scenarios, through which video game startups conduct experiments and challenges associated with these. The initial results could inform these startups about the possibilities and challenges and guide future research.

Keywords:experimentation, video game startups, challenges, gaming startups

## 1 Introduction

Over the last 40 years, video games have increasingly replaced traditional games as leisure activities and have disrupted how we spend our leisure time. The video game market has become an established and ever-growing global industry for over two decades. In 2022, the global video market was worth USD 42.9 billion, and the revenue is expected to grow with an annual growth rate of 8.74%1. Originally, video games refer to the games that do not require a microprocessor and use analogue intensity signals displayed on a cathode ray tube (CRT) [17]. The availability of new imaging technologies, such as consoles, home computers, Virtual Reality (VR) devices, etc., has made the idea of video games more conceptual and less tied to a specific technology [5].

Developing a successful video game is a very demanding and complex process. It involves expertise from various disciplines, e.g. software/game development, arts, animation, sound engineering, etc., which may increase the complexity of communication and coordination [10]. Furthermore, it is unclear whether a game will succeed in the market, which poses a major risk to game publishers when investing in new game development projects. Unlike other software startups, video game startups do not build technological solutions to solve real problems. Instead, they combine art, science, and craft to offer fun, entertainment, and experience through the games [2, 11]. Yet, these requirements have no metrics to be applied, yet they must be validated at each stage of the development process.

An effective adoption and implementation of experimentation is a staged process [13]. In this study, we aim to gain insights into how video game startups approach experimentation to develop games. To guide the study, we explore the research question: _How do video game startups use experimentation in practice?_

## 2 Background and Related Work

In innovative endeavours, the required knowledge for success is generally unknown [9]. Thus, experimentation is particularly useful for acquiring knowledge and reducing uncertainty. Experimentation is an approach based on continuously identifying critical assumptions, transforming them as hypotheses, and prioritising and testing them with experiments to support or refute them [12]. However, most startups persist with the original ideas rather than experimenting [6, 7, 14].

While research in game startups exists, they are limited to mobile game development. For example,Vanhala et al. [16] analysed six Finnish mobile game startups and found that human capital is the most important element in their business models. Moreover, the key challenge is to raise the awareness of game players. Kasurinen et al. [8] showed that game developers are generally pleased by the tools available to experiment with the concept and build prototypes.

Research also shows that the iterative and incremental nature of agile methods positively impacts communication, game quality, and the ability to find the fun aspects of the mobile game features [10]. In contrast, the agile principle of embracing changes increases the pressure to meet the deadline [1]. Mobile game startups should be cautious in considering the minimum viable product concept. The first version of a game artefact released to the market needs to be of sufficient quality to attract and lock in users for an adequate amount of time to allow for further development of the game [15]. This study aims to complement existing research by investigating how video game startups conduct experimentation.

## 3 Research Methodology

We performed semi-structured interviews [3] to gain insights into how video game startups conduct experimentation. Interview candidates were identified by the first author collaborating with Blekinge Business Incubator (BBI) in Karlskrona,Sweden. The first interview was with a business coach in the incubator, who provided a list of founders of independent (indie) and internal video game startups operating inside larger companies. The interviews were held and recorded in a video conferencing system (Microsoft Teams), each lasting between 60 and 90 minutes. The profiles of the interviewees are shown in Table 1. The audio recordings were transcribed and analysed using thematic analysis [4]. The transcripts were sent back to the interviewees for follow-up questions and clarification.

## 4 Results

This section reports our findings by describing six experimentation scenarios. All quotes and information herein are derived from the interview transcripts.

### Technical or digital prototyping

Our interviews reveal that, in the early stages, the main challenge of game development lies not in the ideation process but in the execution and making the game work. Hence, the first purpose of experimentation is to assess the technical feasibility of the team to develop the game. The game's initial idea is usually outlined in a game design document and describes the game at a high level from the user's perspective. The team builds prototypes using a 3D engine, e.g., Unity, to test the game's complexity and scope. In Mana Brigade, a slightly different approach was taken. This company started out performing experiments with a marching cube algorithm2. This algorithm was then implemented in Unity, and the user experience was tested using VR devices.

Footnote 2: Marching cubes is an algorithm to extract a 2D surface mesh from a 3D volume.

All interviewees agree that technical experimentation is crucial to evaluate their capability to build the game. For example, if they can solve all problems to build a game or need key people with certain skills and expertise. Technical experimentation also showcases their capabilities to potential investors or publishers.

Tuple 48:
Cleaned Title: large language model better reasoner selfverification
Cleaned Transcription: large language model better reasoner selfverification yixuan weng minjun zhu fei xia bin li shizhu shenping liu bin sun kang liu jun zhao laboratory cognition decision intelligence complex system ia ca school artificial intelligence university chinese academy science college electrical information engineering hunan university unisound beijing china shanghai artificial intelligence laboratory wengsyxgmailcom shizhuhe kliu jzhaonlpriaaccn abstract recently chain thought cot prompting large language model llm eg gpt shown strong reasoning ability several natural language processing task arithmetic commonsense logical reasoning however llm cot require multistep prompting multitoken prediction highly sensitive individual mistake vulnerable error accumulation issue make llm need ability verify answer fact inferring conclusion thinking decision task people often check reverifying step avoid mistake paper propose prove llm also similar selfverification ability take conclusion obtained cot one condition solving original problem performing backward verification answer llm deduced obtain interpretable answer validation score select candidate answer highest score experimental result demonstrate proposed method improve reasoning performance various arithmetic commonsense logical reasoning datasets code publicly available httpsgithubcomwengyxselfverificationhttpsgithubcomwengyxselfverification introduction ability reasoning process thinking decisionmaking essential aspect human intelligence recently chain thought cot prompting wei et al good way solve arithmetic commonsense logical reasoning task large language model llm help llm simulating human thinking process solving complex natural language processing nlp task cot guide llm generate series intermediate reasoning step address complex problem rather predict final answer approach shown advance performance several challenging nlp task even using training sample madaan et al saparov fu et al gu et al although cot enable llm solve complex reasoning task highly sensitive individual mistake vulnerable error accumulation shen et al tiny mistake occurs change meaning deviation whole statement xiao et al leading incorrect answer cobbe et al especially problematic using cot addressing multistep precise reasoning mathematical calculation due lack error correction mechanism difficult llm obtain correct result possible error multiple step reasoning detecting mitigating error essential improve reasoning capability previous method resolve issue training another verifier evaluate correctness model output shen et al li et al however drawback work one hand training verifier requires lot human annotation additional finetuned model limit widespread use task domain hand verifier finetuned language model easily explainable making difficult ass model reliability based output score therefore challenge obtaining better reasoner based llm get verifier avoid manual annotation additional training better extended migrated field task address challenge overcome limitation training verifier propose utilizing llm reasoner selfverification selecting better prediction result numerous decisionmaking task human often perform selfverification inferred conclusion mitigate mistake poole mackworth paper propose demonstrate llm posse similar selfverification ability better reasoning cot carried following two step forward reasoning backward verification specifically forward reasoning llm reason generate candidate answer using cot question candidate answer form different conclusion verified backward verification mask original condition predict result using another cot rank candidate conclusion based verification score calculated assessing consistency predicted original condition value example shown figure taking f fmathcalc condition predict value condition attribute hatf correctness fmathcalc evaluated comparing consistency value predicted hatf original f verification method employ llm selfverification prompt eliminating need finetuning gradient updating approach enables automatic verification multiple candidate answer corresponding conclusion mitigating deviation correct thought chain original cot verification score arises evaluating step backward verification phase rather direct output neural network model cobbe et al li et al enhancing explainability prediction outcome solution process li et al yu et al zhu et al conducted experiment various opensource datasets mathematical reasoning common sense logical reasoning task achieving result beyond baseline eg gsmk singleeq addition also attempt combine method approach improving forward reasoning selfconsistency wang et al leasttomost zhou et al experimental result show method also improves upon forward reasoning approach contribution summarized follows propose prove large language model llm selfverify prediction result proposed method provide interpretable verification score without need train additional verifier conducted extensive experiment multiple llm experimental result multiple mathematical commonsense logical reasoning datasets achieve significant improvement compared baseline introduced truefalse item verification general task backward verification stage proposed condition mask verification based characteristic arithmetic task method applied wide range reasoning datasets potentially paving way selfvalidation become new paradigm following pretraining prompt learning thus motivating exploration capability llm related work language model reasoning extensively studied order evaluate various reasoning ability language model arora et al madaan et al sun et al including arithmetic reasoning koncelkedziorski et al roy roth patel et al cobbe et al commonsense reasoning talmor et al bhagavatula et al geva figure answer question verified masking predicting condition original context mimic selfverification ability human predict accuracy fmathcalc predicting original condition f f right based conclusion et al zhu et al logical reasoning liu et al yu et al solve reasoning task researcher utilized pretrained language reasoning model asai hajishirzi deng et al xia et al finetuned general llm cobbe et al early work attempted solve complex reasoning task using seqseq model wang et al li et al later specialized encoderdecoder architecture designed improve reasoning performance shen jin zhu et al recent work suggested adopt pretraining task improve arithmetic reasoning ability yoran et al wang et al however method require significant amount human annotation paper proposed obtain answer automatically verify multiple reasoning task incontext learning large language model gpt exhibit impressive fewshot learning ability lu et al qiao et al closely approximate predictor computed gradient descent akyurek et al requires filling exemplar context prompt without need finetuning dataset training example wang et al weng et al however approach struggle task requiring complex reasoning rae et al drive researcher explore prompting strategy cot wei et al chained reasoning approach insert multistep reasoning path generating final answer wang et al proposed selfconsistency decoding strategy vote reasoning path kojima et al demonstrated llm could zeroshot reasoner prompt let think stepbystep method focus constructing cot ignore high sensitivity llm individual mistake generating chain conclusion cot may unreliable dhuliawala et al chu et al weng et al paper proved llm selfverify conclusion answer verification common method evaluating reordering candidate answer trained language understanding model kushman et al train classifier select best answer candidate answer roy roth train global scoring model guide search process better answer shen et al proposed joint training answer generation rank language model cobbe et al lightman et al finetunes language model verifier calculates tokenlevel solutionlevel verification score predicate result however method need additional annotation work require training example provide explainable verification score proposed method proposed method used verify prediction result shown figure process mainly consists two step first step forward reasoning similar normal cot except multiple candidate answer generated sampling decoding second step calculate verification score candidate answer selfverification method answer highest score selected final answer forward reasoning forward reasoning llm reasoner generate candidate answer chain thought prompting augment input several cot prompt similar original query send llm llm performs sampling decoding generate multiple candidate verification shown figure reasoning task large language model mathcallmathcalm given question mathcalx accompanied chain thought set mathrmc fewshot setting whole prompt also contains questioncot promptanswer tuples input mathcalx subdivided mathcalxffldotsfrq fi condition fact q question represented natural language clause subsentences specifically order generate stepbystep solution cot followed wei et al designed cot prompt set mathrmc reasoning dataset eg gsmk dataset contains n sample sample question dotmathcalx chain thout dott answer doty sample used input testtime example mathrmc concatenated prompt mathrmcdotmathcalxdotmathbftdotmathbfy dotmathcalxdotmathbftdotmathbfyldots dotmathcalxndotmathbftndotmathbfyn therefore mathcallmathcallmathcalm required follow prompt mathrmc generate chain thought mathbftmathbfcot generating final answer mathbfymathcalpmathbfymathrmcmathcalxmathcalpmathbftcotmathrm cmathcalxtimesmathcalpmathbfymathrmcmathcalxmathbftcot ensure diversity different answer adapt sampling decoding generate multiple mathbfy k time specifically sampling decoding random decoding method select next word sampling probability distribution possible word step multiple candidate answer obtained repeatedly using sampling decoding example generate candidate answer example figure backward verification step may generate multiple different answer step used verify select best answer backward verification involves several substeps first original question candidate answer rewritten conclusion supplemented new condition incarnadine color figure considered two method construct new question general qa task truefalse item verification given based condition asking llm whether condition mutually satisfied broad applicability arithmetic reasoning task definite condition mask indicate reasoning direction language model propose condition mask verification method design question verification stage finally perform multiple experiment compute verification score comparing consistency predicted condition value original masked condition value select candidate answer highest score final answer rewritten candidate conclusion besides rewrite original question candidate answer conclusion supplement new condition backward verification step specifically use instruction prompt please change question answer complete declarative sentence q answer change q mathbfy new declarative sentence fmathcaly mathcalllm shown figure rewrite question conclusion jackie apple adam condition masking question generation diversity problem make difficult balance need coherence fact consistency question answer practical operation tackle issue included clear question asking language model accurately predict truefalse item verification tfv approach applied wide range reasoning qa task directly add correct true false condition requiring llm selfevaluate correctness condition condition mask verification cmv figure example selfverification step one llm generates candidate answer form different conclusion step two llm verifies conclusion turn computes verification score use regular expression filter specific condition number mask turn mask condition randomly select condition unnecessary condition may masked significantly impact verification answer example dana worked hour friday hour saturday hour sunday earns per hour much money dana earn weekend since condition hour affect conclusion difficult predict correctly replace occurrence f original mathcalx x turn ask mathcallmathcallmathcalm repredict rewrite question example might find value f replace x add answer x end new question effectively turning equation technique help guide language model towards correct answer verification score calculation backward verification chain thought similar solving equation design chain thought prompt like forward reasoning guide llm generating solving process input newly constructed sentence mathcallmathcallmathcalm tfv directly count number answer true score cmv match final result masked condition due limited performance llm condition verified backward verification step easy score resulting lack differentiation address repeat sampling decoding process p time verification score accurately reflect model confidence given conclusion erd verification score calculated follows smalltextttscoremathbfybegincasessumppsumrr mathcallmathcallmathcalmpmathcalxfrfyfr texttfv sumppmathcallmathcallmathcalmpmathcalxfy textcmvendcases bullet indicator function finally select one highest verification score k candidate answer generated result mathbfoutputoperatornameargmaxkinkmathbfscorek example cmv figure verification match result generated selfverification llm masked condition one conclusion verification score four correct result verification score finally choose highest verification score final conclusion experiment setting task dataset evaluated eight datasets three reasoning task arithmetic reasoning commonsense reasoning logical reasoning datasets highly heterogeneous term input format see appendix detailed description dataset example different datasets given table appendix arithmetic reasoning performed experiment following arithmetic datasets singleeq koncelkedziorski et al addsub hosseini et al multiarith roy roth aquarat ling et al gsmk cobbe et al svamp arkil et al commonsense reasoning commonsenseqa csqa talmor et al typical dataset task requires commonsense knowledge world accurately answer question complex meaning logical reasoning date understanding du srivastava et al involves inferring date given context model conducted experiment evaluate original gpt chen et al codedavinci model instructgpt model ouyang et al codedavinci additionally conducted analysis experiment public gpt brown et al prediction result different reasoning task datasets obtained openais api appendix show reproducibility statement footnote openais api httpsopenaicomapihttpsopenaicomapi prompt conducted experiment fewshot setting without finetuning original llm ensure fair comparison used prompt wei et al forward reasoning made several change prompt backward verification detail shown appendix implementation experiment perform cot prompting llm llm generate conclusion answer sampling decoding without topk truncation forward reasoning generated k candidate answer conclusion backward verification candidate conclusion generated p time maximum token length decoding llm generates output select part text conforms conclusion format appendix show specific strategy different task addition ensure fair comparison ran experiment three time calculated average result result analysis main experimental result shown table table show proposed selfverification method sv improve previous method datasets method achieved new stateoftheart sota performance six eight datasets appendix show specific example language model selfverification dataset additionally observed selfverification led average increase highperforming instructgpt model indicates model strong forward reasoning capability also benefit selfverification mechanism detailed experimental conclusion analysis described follows current selfverification method suitable arithmetic reasoning task reasoning task find average performance improvement arithmetic reasoning task uparrow higher reasoning task uparrow table believe reason easier find required mask condition arithmetic reasoning
Original Title: Large Language Models are Better Reasoners with Self-Verification
Original Transcription: # Large Language Models are Better Reasoners with Self-Verification

Yixuan Weng\({}^{1}\), Minjun Zhu\({}^{1,2}\), Fei Xia\({}^{1,2}\), Bin Li\({}^{3}\),

**Shizhu He\({}^{1,2}\)+, Shenping Liu\({}^{4}\), Bin Sun\({}^{3}\), Kang Liu\({}^{1,2,5}\), Jun Zhao\({}^{1,2}\)**

\({}^{1}\) The Laboratory of Cognition and Decision Intelligence for Complex Systems, IA, CAS

\({}^{2}\) School of Artificial Intelligence, University of Chinese Academy of Sciences

\({}^{3}\) College of Electrical and Information Engineering, Hunan University

\({}^{4}\)Unisound, Beijing, China

\({}^{5}\)Shanghai Artificial Intelligence Laboratory

wengsyx@gmail.com, {shizhu.he, kliu, jzhao}@nlpr.ia.ac.cn

###### Abstract

Recently, with the chain of thought (CoT) prompting, large language models (LLMs), e.g., GPT-3, have shown strong reasoning ability in several natural language processing tasks such as arithmetic, commonsense, and logical reasoning. However, LLMs with CoT require multi-step prompting and multi-token prediction, which is highly sensitive to individual mistakes and vulnerable to error accumulation. The above issues make the LLMs need the ability to verify the answers. In fact, after inferring conclusions in some thinking decision tasks, people often check them by re-verifying steps to avoid some mistakes. In this paper, we propose and prove that LLMs also have similar self-verification abilities. We take the conclusion obtained by CoT as one of the conditions for solving the original problem. By performing a backward verification of the answers that LLM deduced for itself, we can obtain interpretable answer validation scores to select the candidate answer with the highest score. Experimental results demonstrate that the proposed method can improve the reasoning performance on various arithmetic, commonsense, and logical reasoning datasets. Our code is publicly available at: [https://github.com/WENGYX/Self-Verification](https://github.com/WENGYX/Self-Verification).

## 1 Introduction

The ability of reasoning in the process of thinking and decision-making is an essential aspect of human intelligence. Recently, chain of thought (CoT) prompting (Wei et al., 2022) has been a good way to solve the arithmetic, commonsense, and logical reasoning tasks with large language models (LLMs), which help the LLMs simulating the human thinking process when solving complex natural language processing (NLP) tasks. CoT guides LLMs to generate a series of intermediate reasoning steps to address complex problems rather than just predict a final answer. This approach has been shown the advance performances on several challenging NLP tasks, even when using only a few or no training samples (Madaan et al., 2022; Saparov and He, 2022; Fu et al., 2022; Gu et al., 2023).

Although CoT can enable LLMs to solve complex reasoning tasks, it is highly sensitive to individual mistakes and vulnerable to error accumulation (Shen et al., 2021). If a tiny mistake occurs, it can change the meaning deviations of the whole statement (Xiao et al., 2022), leading to incorrect answers (Cobbe et al., 2021). That is especially problematic in using CoT for addressing multi-step precise reasoning (such as mathematical calculation). Due to the lack of the error correction mechanism, it is difficult for the LLMs to obtain correct results from the possible errors in multiple steps reasoning. Detecting and mitigating errors is essential to improve reasoning capabilities.

Previous methods resolve the above issue by training another verifier to evaluate the correctness of the model's output (Shen et al., 2021; Li et al., 2022). However, there are some drawbacks in these work. On the one hand, training a verifier requires a lot of human annotations and additional fine-tuned models, which limits its widespread use in other tasks and domains. On the other hand, the verifier fine-tuned by a language model is not easily explainable, making it difficult to assess the model's reliability based on its output scores. Therefore, **the challenge of obtaining a better reasoner based on the LLMs is to get a verifier that can avoid manual annotation and additional training**, so that it can be better extended and migrated to other fields and tasks.

To address this challenge and overcome the limitations of training verifiers, we propose utilizing LLMs as reasoners with self-verification for selecting better prediction results. In numerous decision-making tasks, humans often perform self-verification of inferred conclusions to mitigate mistakes (Poole and Mackworth, 2010). In this paper, we propose and demonstrate that LLMs possess a similar self-verification ability, the better reasoning with CoT is carried out in the following two steps, **Forward Reasoning** and **Backward Verification**. Specifically, in Forward Reasoning, LLM reasons generate candidate answers using CoT, and the question and candidate answers form different conclusions to be verified. And in Backward Verification, We mask the original condition and predict its result using another CoT. We rank candidate conclusions based on a verification score, which is calculated by assessing the consistency between the predicted and original condition values. For example, as shown in Figure 1, by taking \(f_{2}\) and \(f_{\mathcal{C}}\) as conditions to predict the value of condition attribute in \(\hat{f}_{1}\), the correctness of \(f_{\mathcal{C}}\) can be evaluated by comparing the consistency of values of the predicted \(\hat{f}_{1}\) and the original \(f_{1}\) in verification.

Our method employs LLMs for self-verification with only a few prompts, eliminating the need for fine-tuning or gradient updating. This approach enables automatic verification of multiple candidate answers and corresponding conclusions, mitigating deviations from the correct thought chain in the original CoT. Our verification score arises from evaluating each step during the backward verification phase, rather than from the direct output of a neural network model (Cobbe et al., 2021; Li et al., 2022), enhancing the explainability of prediction outcomes and solution processes (Li et al., 2021; Yu et al., 2023; Zhu et al., 2023). We conducted experiments on various open-source datasets for mathematical reasoning, common sense, and logical reasoning tasks, achieving results beyond the baseline (e.g., \(60.8\to 65.1\) on GSM8K, \(91.01\to 93.40\) on SingleEq). In addition, we also attempt to combine our method with some approaches to improving forward reasoning, such as self-consistency (Wang et al., 2023) and Least-to-Most (Zhou et al., 2023). The experimental results show that our method also improves upon these forward reasoning approaches.

Our contributions are summarized as follows:

1. We propose and prove that large language models (LLMs) can self-verify their prediction results. The proposed method can provide interpretable verification scores without the need for train additional verifiers.
2. We have conducted extensive of experiments with multiple LLMs, and the experimental results on multiple mathematical, common-sense, and logical reasoning datasets achieve a significant improvement compared to the baseline.
3. We introduced True-False Item Verification for General Tasks in the backward verification stage and proposed Condition Mask Verification based on the characteristics of Arithmetic Tasks. Our method can be applied to a wide range of reasoning datasets, potentially paving the way for self-validation to become a new paradigm following pre-training and prompt learning, thus motivating further exploration of the capabilities of LLMs.

## 2 Related Work

**Language Model Reasoning**. It has been extensively studied in order to evaluate the various reasoning abilities of language models (Arora et al., 2022; Madaan et al., 2022; Sun et al., 2022), including arithmetic reasoning (Koncel-Kedziorski et al., 2015; Roy and Roth, 2016; Patel et al., 2021; Cobbe et al., 2021), commonsense reasoning (Talmor et al., 2018; Bhagavatula et al., 2019; Geva

Figure 1: The answer of a question can be verified by masking and predicting the conditions of the original contexts. To mimic the self-verification ability of human, we predict the accuracy of \(f_{\mathcal{C}}\) by predicting the original conditions \(f_{1}\) or \(f_{2}\) is right or not based on this conclusion.

et al., 2021; Zhu et al., 2022), and logical reasoning Liu et al. (2020); Yu et al. (2020). To solve these reasoning tasks, researchers have utilized pre-trained language reasoning models Asai and Hajishirzi (2020); Deng et al. (2021); Xia et al. (2022) or fine-tuned general LLMs Cobbe et al. (2021). Early work attempted to solve complex reasoning tasks using Seq2Seq models Wang et al. (2018); Li et al. (2019). Later, specialized encoder-decoder architectures were designed to improve reasoning performance Shen and Jin (2020); Zhu et al. (2022). More recent work has suggested to adopt pre-training tasks to improve arithmetic reasoning ability Yoran et al. (2021); Wang et al. (2022). However, these methods require a significant amount of human annotation. In this paper, we proposed to obtain answers automatically and verify them in multiple reasoning tasks.

**In-context Learning**. Large language models such as GPT-3 exhibit impressive few-shot learning ability Lu et al. (2022); Qiao et al. (2022), and closely approximate the predictors computed by gradient descent Akyurek et al. (2022). It requires only filling a few exemplars into context as prompts and without the need for finetuning on a dataset of training examples Wang et al. (2022); Weng et al. (2023). However, this approach struggles with tasks requiring complex reasoning Rae et al. (2021), which drives researchers to explore other prompting strategies. CoT Wei et al. (2022) is a chained reasoning approach that inserts a multi-step reasoning path before generating the final answer. Wang et al. (2023) proposed a self-consistency decoding strategy to vote on the reasoning path, and Kojima et al. (2022) demonstrated that LLMs could as zero-shot reasoners through the prompt "Let's think step-by-step". These methods focus on constructing the CoT but ignore the high sensitivity of LLMs to individual mistakes in generating these chains, so some of these conclusions by CoT may be unreliable Dhuliawala et al. (2023); Chu et al. (2023); Weng et al. (2023). In this paper, we proved that LLMs can self-verify their conclusions.

**Answer Verification**. It is a common method for evaluating and reordering candidate answers with a trained language understanding model. Kushman et al. (2014) train a classifier to select the best answer from candidate answers, while Roy and Roth (2016) train a global scoring model to guide the search process for better answers. Shen et al. (2021) proposed the joint training of answer generation and rank with language model. Cobbe et al. (2021) and Lightman et al. (2023) fine-tunes language model as a verifier, which calculates token-level and solution-level verification scores for a predicate result. However, the above method all need additional annotations. In our work, we do not require training examples and can provide an explainable verification score.

## 3 The Proposed Method

The proposed method can be used to verify prediction results. As shown in Figure 2, the process mainly consists of two steps. The first step, forward reasoning, is similar to the normal CoT, except that multiple candidate answers are generated through sampling decoding. In the second step, we calculate the verification scores for each candidate's answer by the self-verification method, and the answer with the highest score is selected as the final answer.

### Forward Reasoning

In forward reasoning, the LLM reasoners generate candidate answers with the chain of thought prompting. We augment the input with several CoT prompts similar to the original query and then send it to the LLM. The LLM then performs sampling decoding to generate multiple candidates for verification.

As shown in Figure 2, for a reasoning task, the large language model \(\mathcal{L}\mathcal{M}\) is given a question \(\mathcal{X}\) which is accompanied by a chain of thought set \(\mathrm{C}\). In few-shot setting, the whole prompt also contains other question-CoT prompt-answer tuples. The input \(\mathcal{X}\) can be further subdivided into \(\mathcal{X}=\{f_{1},f_{2},\ldots,f_{R},q\}\), where each \(f_{i}\) is a condition (fact), and \(q\) is a question, both represented as natural language clause or sub-sentences.

Specifically, in order to generate step-by-step solutions with CoT, we followed Wei et al. (2022) and designed CoT prompt set \(\mathrm{C}\) for the reasoning dataset (e.g., the GSM8K dataset), which contains \(n\) samples, each sample has the question \(\dot{\mathcal{X}}\), chain of thout \(\dot{t}\), and the answer \(\dot{y}\). These samples are used as the input of test-time. Each example in \(\mathrm{C}\) is concatenated as a prompt:

\[\mathrm{C}=(\dot{\mathcal{X}}_{0},\dot{\mathbf{t}}_{0},\dot{\mathbf{y}}_{0});( \dot{\mathcal{X}}_{1},\dot{\mathbf{t}}_{1},\dot{\mathbf{y}}_{1});\ldots;( \dot{\mathcal{X}}_{n},\dot{\mathbf{t}}_{n},\dot{\mathbf{y}}_{n})\]

Therefore, \(\mathcal{L}\mathcal{L}\mathcal{M}\) is required to follow the prompt of \(\mathrm{C}\) to generate the chain of thought \(\mathbf{t}_{\mathbf{CoT}}\) before generating the final answer \(\mathbf{y}\):\[\mathcal{P}(\mathbf{y}|\mathrm{C},\mathcal{X})=\mathcal{P}(\mathbf{t_{CoT}}|\mathrm{ C},\mathcal{X})\times\mathcal{P})(\mathbf{y}|\mathrm{C},\mathcal{X},\mathbf{t_{CoT}})\]

To ensure the diversity of different answers, we adapt sampling decoding [2] to generate multiple \(\mathbf{y}\) for \(K\) times. Specifically, sampling decoding is a random decoding method, which can select the next word by sampling from a probability distribution over the possible words at each step. Multiple candidate answers can be obtained when repeatedly using sampling decoding. For example, we generate _"18"_ and _"2"_ as candidate answers in the example of Figure 2.

### Backward Verification

Step 1 may generate multiple different answers, this step is used to verify and select the best answer. Backward verification involves several sub-steps. First, the original question with each candidate's answer is rewritten as a conclusion and then supplemented as a new condition (incarnadine color in Figure 2). Then, we considered two methods to construct new questions. In the general QA task, the True-False Item Verification is given based on all the conditions, asking the LLM whether these conditions are mutually satisfied, it has a broad applicability. In Arithmetic reasoning tasks, as the definite condition masks can indicate the reasoning direction of the language model, we propose the Condition Mask Verification method to design questions for the verification stage. Finally, we perform multiple experiments to compute the verification score by comparing the consistency between the predicted condition value and the original masked condition value, and select the candidate answer with the highest score as the final answer.

#### 3.2.1 Rewritten Candidate Conclusion

Besides, we rewrite the original question with the candidate's answer as a conclusion and then supplement it as a new condition in the backward verification step. Specifically, we use the instruction prompt _"Please change the questions and answers into complete declarative sentences [q] The answer is [y]"_ to change \(q\) and \(\mathbf{y}\) into new declarative sentence \(f_{\mathcal{Y}}\) by \(\mathcal{LLM}\). As shown in Figure 2, we can rewrite the question and conclusion as _"Jackie has 18 apples more than Adam"_.

#### 3.2.2 Condition Masking

For question generation, the diversity of the problems makes it difficult to balance the need for coherence and fact consistency between questions and answers in practical operation [23, 24]. To tackle this issue, we included clear questions asking the language model to accurately predict.

**True-False Item Verification (TFV).** This approach can be applied to a wide range of reasoning QA tasks. We directly add "Do it is correct (True or False)?" after all the conditions, requiring the LLM to self-evaluate the correctness of these conditions.

**Condition Mask Verification (CMV).** Further,

Figure 2: Example of self-verification. In the step one, LLM generates candidate answers and forms different conclusions. Then, in the step two, LLM verifies these conclusions in turn and computes the verification score.

we use regular expressions to filter out specific conditions, such as numbers, and then mask them in turn. If we do not mask all conditions but randomly select a condition, unnecessary conditions may be masked, which will significantly impact the verification answer. For example, "_Dana worked 9 hours on Friday, 10 hours on Saturday, and 3 hours on Sunday. She earns $13 per hour. How much money did Dana earn in weekend?_", since condition 1 (9 hours) does not affect the conclusion, it is difficult to predict it correctly. We replace all occurrences of \(f\) in the original \(\mathcal{X}\) with "\(X\)" in turn, and ask \(\mathcal{L}\mathcal{L}\mathcal{M}\) to re-predict it. Then we rewrite the question. For example, we might find a value in \(f_{1}\) and replace it with "\(X\)". We can then add _"What is the answer of '\(X\)'?"_ to the end of the new question, effectively turning it into an equation. This technique helps to guide the language model towards the correct answer.

#### 3.2.3 Verification Score Calculation

This backward verification chain of thought is similar to solving an equation. We design a chain of thought prompt, like forward reasoning, to guide LLM in generating a solving process. We input the newly constructed sentences into \(\mathcal{L}\mathcal{L}\mathcal{M}\). For TFV, we can directly count the number of answers that are True as the score, and for CMV, we will match its final result with the masked condition.

Due to the limited performance of LLM itself, if the condition is verified only once in the backward verification step, it is easy to have the same score, resulting in a lack of differentiation. To address this, we repeat the sampling decoding process \(P\) times, so that the verification score can more accurately reflect the model's confidence for a given conclusion (Erd, 1970).

The verification score is calculated as follows:

\[\small\texttt{Score}_{\mathbf{y}}=\begin{cases}\sum_{p=1}^{P}(\sum_{r=1}^{R} 1_{(\mathcal{L}\mathcal{L}\mathcal{M}_{p}(\mathcal{X}-f_{r}+f_{y})=f_{r})})& \text{TFV}\\ \sum_{p=1}^{P}(1_{(\mathcal{L}\mathcal{L}\mathcal{M}_{p}(\mathcal{X}+f_{y}))} )&\text{CMV}\end{cases}\]

Where \(1_{(\bullet)}\) is an indicator function.

Finally, we select the one with the highest verification score from the K candidate answers generated as a result.

\[\mathbf{Output}=\operatorname*{argmax}_{k\in[0,K]}(\mathbf{Score}_{k})\]

For example for CMV, in Figure 2.3)Verification, we match the results generated by the self-verification of LLM with the masked conditions. There is one "_10_" in the conclusion of \(A_{1}\), so the verification score is \(1\). There are four correct results in \(A_{2}\), so the verification score is \(4\), and we finally choose \(A_{2}\), which has the highest verification score, as the final conclusion.

## 4 Experiment Setting

### Task and Dataset

We evaluated eight datasets on three reasoning tasks: arithmetic reasoning, commonsense reasoning, and logical reasoning. These datasets are highly heterogeneous in terms of their input formats (see Appendix A.2 for the detailed description of each dataset. Examples of different datasets are given in Table 7 of Appendix A.4).

* **Arithmetic Reasoning.** We performed experiments on the following 6 arithmetic datasets: SingleEq (Koncel-Kedziorski et al., 2015), AddSub (Hosseini et al., 2014), MultiArith (Roy and Roth, 2016), AQUA-RAT (Ling et al., 2017), GSM8K (Cobbe et al., 2021), and SVAMP (Arkil et al., 2021).
* **Commonsense Reasoning.** CommonsenseQA (CSQA) (Talmor et al., 2018) is the most typical dataset of the task, which requires commonsense knowledge about the world to accurately answer questions with complex meanings.
* **Logical Reasoning.** Date Understanding (DU) (Srivastava et al., 2022) involves inferring a date from a given context.

### Model

We conducted experiments to evaluate the original GPT-3 (Chen et al., 2021) (code-davinci-001) model and the Instruct-GPT model (Ouyang et al., 2022) (code-davinci-002). Additionally, we conducted analysis experiments with public GPT-3 (Brown et al., 2020). All prediction results of different reasoning tasks and datasets are obtained by OpenAI's API 1. Appendix A.3 shows the reproducibility statement.

Footnote 1: OpenAI’s API: [https://openai.com/api/](https://openai.com/api/)

### Prompts

We conducted all experiments in the few-shot setting without any fine-tuning of the original LLM. To ensure a fair comparison, we used the same prompts as in Wei et al. (2022) for forward reasoning. We made several changes of the prompts for backward verification (the details are shown in Appendix A.5).

### Implementation

In each experiment, we perform CoT prompting on the LLMs, then LLMs generate conclusions (answers) by sampling decoding without top-k truncation. When forward reasoning, we generated \(K=5\) candidate answers (conclusions). In backward verification, each candidate conclusion generated \(P=10\) times, and the maximum token length of each decoding was 168. After LLM generates the output, we only select the part of the text that conforms to the conclusion format. Appendix A.1 shows the specific strategy for different tasks. In addition, to ensure a fair comparison, we ran each experiment three times and calculated the average result.

## 5 Result and Analysis

The main experimental results are shown in Table 1. The table shows that the proposed self-verification method (SV) can improve previous methods in all datasets. Our method achieved a new state-of-the-art (SOTA) performance in six of these eight datasets. Appendix A.4 shows specific examples of language model self-verification for each dataset. Additionally, we observed that self-verification led to an average increase of 2.33% in the high-performing Instruct-GPT model, which indicates that the model with strong forward reasoning capabilities also benefits from the self-verification mechanism. The detailed experimental conclusions and analysis are described as follows:

**The current self-verification method is more suitable for arithmetic reasoning tasks than other reasoning tasks.** We find that the average performance improvement of arithmetic reasoning tasks (\(1.67\%/2.84\%\uparrow\)) is higher than that of other reasoning tasks (\(0.62\%/0.78\%\uparrow\)) in Table 1. We believe the reason is that it is easier to find the required mask conditions for arithmetic reasoning

Tuple 49:
Cleaned Title: training verifier solve math word problem
Cleaned Transcription: missingpagefail parameter count achieve even moderate performance distribution challenging math dataset hendrycks et al evidence strongly motivates search method favorable scaling law propose training verifier evaluate correctness model generated solution similar concurrent work shen et al test time sample fixed number candidate solution select solution ranked highest verifier verifier benefit inherent optionality verification simpler task generation general facilitate research releasing gsmk dataset k high quality problem grade school math level designed dataset high linguistic diversity relying relatively simple grade school math concept stateoftheart language model struggle achieve high performance dataset primarily due high diversity among problem time gsmk solution depend elementary concept achieving high test performance tractable goal main contribution follows present curated dataset k grade school math question natural language solution useful probing informal reasoning ability large language model show compared finetuning baseline use verifier result approximately performance boost x model size increase verifier scale significantly better increased data show dropout act strong regularizer significantly improving performance finetuning verification figure three example problem gsmk calculation annotation highlighted red dataset gsmk consists k high quality grade school math problem created human problem writer segmented k training problem k test problem problem take step solve solution primarily involve performing sequence elementary calculation using basic arithmetic operation timesdiv reach final answer bright middle school student able solve every problem created gsmk based following design principle high quality avoid errorprone scraping procedure instead rely human worker create problem performing extensive quality control based worker answer agreement estimate le percent problem contain breaking error high diversity strive high diversity among problem actively avoid designing problem drawn linguistic template differ superficial detail issue prevalent among many datasets creating individual problem relatively unique heldout test performance becomes far relevant metric moderate difficulty choose problem distribution challenging large stateoftheart language model without completely intractable gsmk help u better understand data scaling trend different model method difficulty sweet spot problem require concept beyond level early algebra vast majority problem solved without explicitly defining variable natural language solution collect solution natural language rather pure math expression believe generally useful data format expect shed light property large language model internal monologue instructed problem writer explain work much possible allowed write solution diverse linguistic style full gsmk dataset found httpsgithubcomopenaigradeschoolmathhttpsgithubcomopenaigradeschoolmath example problem shown figure discus additional dataset detail appendix related work related datasets early math word problem datasets kushman et al roy roth relatively small well suited testing limit modern language model dolphink huang et al larger dataset containingk problem solution provided form equation final answer aquarat ling et al contains k problem dataset unfortunately suffers high degree problem templatization poor quality control natural language solution mathqa recently released subset aquarat focused correcting mistake amini et al even corrected dataset data quality issue around data inconsistency miao et al apek zhao et al largest publicly available dataset consisting k chinese elementary schoollevel math problem however due language barrier lack natural language solution unable evaluate method dataset recently developed asdiv dataset miao et al contains k math word problem address common flaw prior datasets ensuring problem high diversity high quality share design principle creation gsmk however note gsmk larger provides natural language solution consists problem average require step solve math dataset hendrycks et al larger significantly complex gsmk high difficulty make challenging accurately measure progress given current capability stateoftheart language model recent reasoningrelated datasets focused mathematical reasoning symbolic math lample charton reading comprehension logiqa liu et al commonsense question answering commonenseqa talmor et al similar commonsenseqa gsmk includes question require basic background knowledge like number day week similar logiqa requires mix reading comprehension logical reasoning gsmks main difficulty lie properly interpreting question reasoning step solve related method previous work attempted solve classic math word problem benchmark recurrent seqseq model sutskever et al closely related variant wang et al huang et al recent work improved performance designing specialized encoderdecoder architecture amini et al chiang chen xie sun chen et al li et al strongest result often relying large pretrained encoders bert family chen et al kim et al liang et al recent work recommended additional pretraining task improve math reasoning skill large transformerbased model hendrycks et al propose pretraining model new amp corpus derived khan academy problem mathematica script similarly shen et al propose pretrained corpus prek college level curriculum extracted internet peng et al propose pretraining predicting masked subexpressions expression tree similar verification method finetuned language model select among many model completion nichols et al proposed sampleandrank approach improve collaborative storytelling ability large language model training signal coming preference human worker concurrent work closely related shen et al applied similar approach solving math word problem jointly training model generate rank solution work share many fundamental similarity approach though differ several key respect first focus attention space natural language solution richer general solution format pure mathematical expression moreover choice enables model develop verbal analytical skill produce solution readily interpretable human second provide evidence verifier scale far favorably additional data baseline method finally use separate generator verifier network order prevent generator overfitting method investigate two method solve problem gsmk finetuning verification finetuning baseline method us language modeling objective generative pretraining gpt brown et al test time judge performance autoregressively sampling single low temperature solution checking whether final answer correct contrast verification consists sampling multiple high temperature solution assigning solution score outputting highest ranked solution verifier trained judge correctness solution training signal determined solely whether solution reached correct final answer figure final test performance various gpt model size finetuning training set different size mean standard deviation shown across run method use model gpt family initialization primarily focusing b b model size b model largest produce impressive result b model significantly convenient research purpose discus hyperparameter choice appendix b model frequently fail accurately perform calculation although larger model make fewer arithmetic mistake smaller model remains common source error mitigate issue train model use calculator injecting calculation annotation training set test time calculator override sampling model chooses use annotation detail found appendix c finetuning perform finetuning updating model parameter minimize crossentropy loss training token figure show test performance finetuning training set varying size epoch visualize data function training set size function model size test performance determined single low temperature sample test problem unsurprisingly see b model significantly outperforms smaller model assuming loglinear trend naively extrapolate result estimate model parameter would required reach solve rate using full gsmk training set even harder extrapolate along data dimension since performance appear follow loglinear trend nevertheless appears likely b model would require least two additional order magnitude training data reach solve rate figure show b test performance varies course figure test solve rate finetuning b model full gsmk training set model allowed make guess left guess right training epoch use testn denote percentage problem solved correctly least allowing model make n separate guess problem use low temperature generate test sample use higher temperature generate test sample temperature value chosen empirically produce best result test performance improves approximately monotonically even though quickly begin overfitting test loss unfortunately test performance degrades much sharply test increase number epoch expected model repeatedly encounter data becomes increasingly uncalibrated overconfident prediction test time overconfidence lead poor coverage solution space effect becomes noticeable considering multiple sample test time choosing model good coverage critical successfully train verifier empirically see test performance peak within first epoch reason use model trained epoch generate sample training verifier provide several example solution b b model appendix also note important allow model generate full natural language solution outputting final answer instead finetune b model directly output final answer without intermediate step performance drop drastically verification improve upon finetuning baseline train verifier judge correctness modelgenerated solution search verifier test time conditioned problem candidate solution verifier output probability solution correct training solution labeled correct incorrect based solely whether reach correct final answer practice solution reach correct final answer using flawed reasoning leading false positive figure diagram verification training pipeline shown figure train verifier follows finetune model generator epoch training set sample completion generator training problem label solution correct incorrect train verifier single epoch dataset training epoch enough generator learn basic skill domain choose train longer since diversity generated solution begin collapse point shown figure train separate generator verifier model limit generator training prevent overfitting principle possible combine model unless otherwise specified use model size generator verifier addition predicting solution correctness also train verifier language modeling objective generator serf valuable auxiliary objective verifier discus additional verifier training detail appendix e test time sample completion test problem rank verifier return one highest verifier score comparison verification finetuning shown figure b b model size find beneficial use verification low dataset size believe due pressure overfit correct answer small datasets overfitting correct answer happens faster learning generalizable property correct reasoning however use sufficiently large dataset see strong boost verifier figure comparison finetuning verification using b b model size verification considers solution per problem mean standard deviation shown across run except b verification show single run interesting note b verifier take earlier b verifier requiring fewer training problem surpass finetuning baseline see appendix example solution found verifier appendix f visualization verifier confidence verification ablation either train verifier make single scalar prediction conditioned entire generated solution make scalar prediction token solution default choose latter training verifier make prediction token viewed tokenlevel value function compare two method figure respectively labeled solutionlevel tokenlevel predicting value function every token challenging noisier task judging full completion however despite initially slower training tokenlevel verifier ultimately outperforms solutionlevel verifier moreover tokenlevel verifier still improving late training whereas solutionlevel verifier quickly show sign overfitting hypothesize full value function provides useful auxiliary signal encourages model judge reasoning throughout solution rather merely memorizing correct final answer figure b ablate objective used training verifier discussed section optionally include language modeling objective alongside verification objective compare using objective using verification objective although reasonable choice including language modeling objective strict improvement make intuitive figure verification ablation sense better understanding language distribution aid verifier discriminating sample figure c separately ablate model size generator verifier find using large generator small verifier performs significantly better using small generator large verifier verification still remarkably effective even verifier much smaller generator suggests verifier may often relying relatively coarse heuristic discriminate solution given generator rather attempting thorough form verification additional experiment test time compute test time choose generate arbitrarily many solution judged verifier selecting highest ranked completion figure show b verifier performance varies number completion per test problem scale performance improves increase number completion beyond point performance start decrease suggests benefit search eventually outweighed risk finding adversarial solution fool verifier general evaluate verifier test performance using completion since capture benefit verification relatively modest compute cost increase performance take majority vote among top verifierranked solution instead selecting single top solution figure performance amount test time compute varies voting process considers final answer reached individual solution final answer selected one vote figure bb show performance varies allow greater number top sample cast vote unsurprisingly starting greater number sample afford allow greater number sample cast vote sample optimal allow top sample cast vote sample approximately optimal allow top cast vote regularization find finetuning verification strongly benefit use dropout regularizer specifically apply residual dropout vaswani et al along residual path layer network use dropout dropout experiment chosen based result hyperparameters sweep note gpt model pretrained dropout experiment involving dropout therefore perform additional pretraining dropout subsequently finetuning model mitigates distribution shift model experience finetuning first investigate effect dropout finetuning across various training set size figure aa show dropout lead significant improvement baseline next investigate effect dropout verifier considering solutionlevel tokenlevel variant figure bb see dropout significantly improves solutionlevel verifier mitigating overfitting occurs unregularized baseline notably using dropout solutionlevel verifier reach similar level performance tokenlevel verifier figure cc apply dropout tokenlevel verifier since tokenlevel verifier already le susceptible overfitting surprise impact dropout le significant nevertheless still see slight gain training tokenlevel verifier dropout note increase batch size tokenlevel verifier factor better handle difficult objective noise dropout figure b finetuning verification dropout ablation conclusion seen verification provides significant performance boost relative finetuning baseline full dataset b verification slightly outperforms finetuned b model thereby offering boost approximately equivalent x model size increase also seen tokenlevel verifier le prone overfitting solutionlevel verifier method benefit regularization residual dropout expect verification scale well problem distribution require complex mathematical reasoning hope gsmk support development new method scale even better acknowledgement thank dan hendrycks leo gao alec radford giambattista parasandolo valuable feedback paper harri edward yura burda michael wu nick ryder many insightful conversation michael petrov alethea power jacob jackson technical assistance openai supercomputing team infrastructure made experiment possible team surge ai performing gsmk data collection reference amini et al amini gabriel p lin r koncelkedziorski choi h hajishirzi mathqa towards interpretable math word problem solving operationbased formalism arxiv preprint arxiv brown et al b brown b mann n ryder subbiah j kaplan p dhariwal neelakantan p shyam g sastry askell et al language model fewshot learner arxiv preprint arxiv chen et al k chen q huang h palangi p smolensky k forbus j gao mapping naturallanguage problem formallanguage solution using structured neural representation icml chen et al x chen c liang w yu zhou song q v le neural symbolic reader scalable integration distributed symbolic representation reading comprehension international conference learning representation chiang chen tr chiang yn chen semanticallyaligned equation generation solving reasoning math word problem arxiv preprint arxiv hendrycks et al hendrycks c burn kadavath arora basart e tang song j steinhardt measuring mathematical problem solving math dataset arxiv preprint arxiv h huang shi c lin j yin wy well computer solve math word problem largescale dataset construction evaluation proceeding th annual meeting association computational linguistics volume long paper page huang et al huang j liu cy lin j yin neural math word problem solver reinforcement learning proceeding th international conference computational linguistics page kaplan et al j kaplan mccandlish henighan b brown b chess r child gray radford j wu amodei scaling law neural language model arxiv preprint arxiv kim et al b kim k ki lee g gweon point expression solving algebraic word problem using expressionpointer transformer model proceeding conference empirical method natural language processing emnlp page kushman et al n kushman artzi l zettlemoyer r barzilay learning automatically solve algebra word problem proceeding nd annual meeting association computational linguistics volume long paper page lample charton g lample f charton deep learning symbolic mathematics arxiv preprint arxiv li et al li l wu feng f xu f xu zhong graphtotree neural network learning structured inputoutput translation application semantic parsing math word problem emnlp liang et al z liang j zhang j shao x zhang mwpbert strong baseline math word problem ling et al w ling yogatama c dyer p blunsom program induction rationale generation learning solve explain algebraic word problem arxiv preprint arxiv liu et al j liu l cui h liu huang wang zhang logiqa challenge dataset machine reading comprehension logical reasoning ijcai miao et al sy miao cc liang ky su diverse corpus evaluating developing english math word problem solver arxiv preprint arxiv nichols et al e nichols l gao r gomez collaborative storytelling largescale neural language model arxiv preprint arxiv peng et al peng k yuan l gao z tang mathbert pretrained model mathematical formula understanding arxiv ab zhang et al roy roth solving general arithmetic word problem proceeding conference empirical method natural language processing page lisbon portugal sept association computational linguistics doi vd url httpsaclanthologyorgdhttpsaclanthologyorgd shen et al j shen yin l li l shang x jiang zhang q liu generate rank multitask framework math word problem arxiv preprint arxiv shen et al b j shen yamashita e prihar n heffernan x wu b graff lee mathbert pretrained language model general nlp task mathematics education b sutskever et al sutskever vinyals q v le sequence sequence learning neural network advance neural information processing system page talmor et al talmor j herzig n lourie j berant commonsenseqa question answering challenge targeting commonsense knowledge arxiv preprint arxiv vaswani et al vaswani n shazeer n parmar j uszkoreit l jones n gomez l kaiser polosukhin attention need advance neural information processing system page wang et al wang pruksachatkun n nangia singh j michael f hill levy r bowman superglue stickier benchmark generalpurpose language understanding system arxiv preprint arxiv wang et al wang x liu shi deep neural solver math word problem proceeding conference empirical method natural language processing page copenhagen denmark sept association computational linguistics doi vd url httpsaclanthologyorgdhttpsaclanthologyorgd xie sun z xie sun goaldriven treestructured neural model math word problem ijcai zhao et al w zhao shang liu l wang j liu apek largescale templaterich dataset math word problem arxiv preprint arxiv dataset detail initially collected starting set thousand problem natural language solution hiring freelance contractor upwork upworkcom worked surge ai surgehqai nlp data labeling platform scale data collection collecting full dataset asked worker resolve problem worker resolving problem originally wrote checked whether final answer agreed original solution problem produced disagreement either repaired discarded performed another round agreement check smaller subset problem finding problem still produce disagreement among contractor estimate fraction problem contain breaking error ambiguity possible larger percentage problem contain subtle error assist contractor writing question provided seed question automatically generated fewshot prompted b gpt model contractor allowed use seed question directly use inspiration make modification come question entirely instructed contractor descriptive possible solution reuse problem setting template different question ensure contractor reusing problem template computed pairwise similarity score problem used provide feedback contractor hyperparameters include table important hyperparameters performed sweep learning rate batch size order magnitude direction value table unable find significant improvement reasonable choice verifier temperature eg instead objective crossentropy instead mean squared error also negligible effect ablation
Original Title: Training Verifiers to Solve Math Word Problems
Original Transcription: [MISSING_PAGE_FAIL:1]

parameter count to achieve even moderate performance on distributions as challenging as the MATH dataset (Hendrycks et al., 2021). This evidence strongly motivates the search for methods with more favorable scaling laws.

We propose training verifiers to evaluate the correctness of model generated solutions, similar to concurrent work by Shen et al. (2021). At test time, we sample a fixed number of candidate solutions and select the solution ranked highest by the verifier. Verifiers benefit both from their inherent optionality and from verification being a simpler task than generation in general.

To facilitate research, we are releasing GSM8K, a dataset of 8.5K high quality problems at the grade school math level. We designed this dataset to have high linguistic diversity while relying on relatively simple grade school math concepts. State-of-the-art language models struggle to achieve high performance on this dataset, primarily due to the high diversity among problems. At the same time, GSM8K solutions depend only on elementary concepts, so achieving high test performance is a tractable goal.

Our main contributions are as follows:

1. We present a curated dataset of 8.5K grade school math questions and natural language solutions, useful for probing the informal reasoning ability of large language models.
2. We show that, compared to a finetuning baseline, the use of verifiers results in approximately the same performance boost as a 30x model size increase, and that verifiers scale significantly better with increased data.
3. We show that dropout acts as a strong regularizer, significantly improving performance for both finetuning and verification.

Figure 1: Three example problems from GSM8K. Calculation annotations are highlighted in red.

Dataset

GSM8K consists of 8.5K high quality grade school math problems created by human problem writers. We segmented these into 7.5K training problems and 1K test problems. These problems take between 2 and 8 steps to solve, and solutions primarily involve performing a sequence of elementary calculations using basic arithmetic operations (\(+-\times\div\)) to reach the final answer. A bright middle school student should be able to solve every problem.

We created GSM8K based on the following design principles.

* **High Quality** We avoid error-prone scraping procedures and instead rely on human workers to create problems. After performing extensive quality control based on workers' answer agreement, we estimate that less than 2 percent of problems contain breaking errors.
* **High Diversity** We strive for high diversity among problems. We actively avoid designing problems that are drawn from the same linguistic template or differ only in superficial details, an issue that is prevalent among many other datasets. By creating each individual problem to be relatively unique, held-out test performance becomes a far more relevant metric.
* **Moderate Difficulty** We choose a problem distribution that is challenging for large state-of-the-art language models, without being completely intractable. GSM8K will help us better understand the data scaling trends of different models and methods in this difficulty sweet spot. Problems require no concepts beyond the level of early Algebra, and the vast majority of problems can be solved without explicitly defining a variable.
* **Natural Language Solutions** We collect solutions in natural language rather than as pure math expressions. We believe this is the most generally useful data format, and we expect it to shed light on the properties of large language models' internal monologues. We instructed problem writers to explain their work as much as possible, but we allowed them to write solutions in their own diverse linguistic styles.

The full GSM8K dataset can be found at [https://github.com/openai/grade-school-math](https://github.com/openai/grade-school-math). Example problems are shown in Figure 1, and we discuss additional dataset details in Appendix A.

## 3 Related Work

### Related Datasets

Early math word problem datasets (Kushman et al., 2014; Roy and Roth, 2015) are relatively small and are not well suited for testing the limits of modern language models. Dolphin18K (Huang et al., 2016) is a larger dataset containing18K problems, but solutions are provided only in the form of equations or final answers. AQuA-RAT (Ling et al., 2017) contains 100K problems, but this dataset unfortunately suffers from both a high degree of problem templatization and poor quality control of the natural language solutions. MathQA is a recently released subset of AQuA-RAT focused on correcting these mistakes (Amini et al., 2019), but even the corrected dataset has data quality issues, with around 30% of the data having inconsistencies (Miao et al., 2021). Ape210K (Zhao et al., 2020) is the largest publicly available dataset, consisting of 210K Chinese elementary school-level math problems. However, due to the language barrier and the lack of natural language solutions, we're unable to evaluate our methods on this dataset.

The recently developed ASDiv dataset (Miao et al., 2021), which contains 2.3K math word problems, addresses common flaws in prior datasets by ensuring problems have both high diversity and high quality. We share those design principles in the creation of GSM8K. However, we note that GSM8K is larger, provides natural language solutions, and consists of problems that on average require more steps to solve. The MATH dataset (Hendrycks et al., 2021) is larger and significantly more complex than GSM8K, but the high difficulty makes it challenging to accurately measure progress given the current capabilities of state-of-the-art language models.

Other recent reasoning-related datasets have focused on mathematical reasoning on symbolic math (Lample and Charton, 2019), reading comprehension (LogiQA) (Liu et al., 2020), and commonsense question answering (CommonenseQA) (Talmor et al., 2018). Similar to CommonsenseQA, GSM8K includes questions that require basic background knowledge, like the number of days in a week. Similar to LogiQA, which requires a mix of reading comprehension and logical reasoning, GSM8K's main difficulty lies in both properly interpreting a question and reasoning through the steps to solve it.

### Related Methods

Previous work has attempted to solve classic math word problem benchmarks with recurrent seq2seq models (Sutskever et al., 2014) and closely related variants (Wang et al., 2017; Huang et al., 2018). More recent work has improved performance by designing specialized encoder-decoder architectures (Amini et al., 2019; Chiang and Chen, 2018; Xie and Sun, 2019; Chen et al., 2020; Li et al., 2020), with the strongest results often relying on large pretrained encoders from the BERT family (Chen et al., 2019; Kim et al., 2020; Liang et al., 2021).

Other recent work has recommended additional pretraining tasks to further improve the math reasoning skills of large transformer-based models. Hendrycks et al. (2021) propose pretraining models on a new AMPS corpus, derived from Khan Academy problems and Mathematica scripts. Similarly, Shen et al. (2021) propose a pretrained a corpus of pre-K to college level curricula extracted from the internet, and Peng et al. (2021) propose pretraining by predicting masked subexpressions from expression trees.

Similar to verification, other methods have finetuned a language model to select among many model completions. Nichols et al. (2020) proposed a sample-and-rank approach to improve the collaborative storytelling ability of large language models, with the training signal coming from the preferences of human workers. In concurrent work closely related to our own, Shen et al. (2021) applied a similar approach to solving math word problems, jointly training a model to both generate and rank solutions. Our work shares many fundamental similarities with their approach, though we differ in several key respects. First, we focus attention on the space of natural language solutions, as this is a richer and more general solution format than pure mathematical expressions. Moreover, this choice enables our models to develop verbal analytical skills and to produce solutions that are more readily interpretable by humans. Second, we provide evidence that verifiers scale far more favorably with additional data than baseline methods. Finally, we use separate generator and verifier networks, in order to prevent the generator from overfitting.

## 4 Methods

We investigate two methods to solve problems in GSM8K: finetuning and verification. Finetuning, our baseline method, uses the same language modeling objective as the generative pretraining in GPT-3 (Brown et al., 2020). At test time, we judge performance by autoregressively sampling a single low temperature solution and checking whether the final answer is correct. In contrast, verification consists of sampling multiple high temperature solutions, assigning each solution a score, and outputting the highest ranked solution. Verifiers are trained to judge the correctness of solutions, with the training signal determined solely by whether or not the solution reached the correct final answer.

Figure 2: Final test performance for various GPT-3 model sizes after finetuning on training sets of different sizes. Mean and standard deviation is shown across 3 runs.

For both methods, we use models from the GPT-3 family as our initialization, primarily focusing on the 175B and 6B model sizes. The 175B model is the largest and produces the most impressive results, while the 6B model is significantly more convenient for research purposes. We discuss hyperparameter choices in Appendix B.

Our models frequently fail to accurately perform calculations. Although larger models make fewer arithmetic mistakes than smaller models, this remains a common source of errors. To mitigate this issue, we train all models to use a calculator by injecting calculation annotations into the training set. At test time, a calculator will override sampling when the model chooses to use these annotations. Details can be found in Appendix C.

### Finetuning

We perform finetuning by updating model parameters to minimize the cross-entropy loss over all training tokens. Figure 2 shows test performance after finetuning on training sets of varying sizes for 20 epochs. We visualize the same data both as a function of training set size and as a function of model size. Test performance is determined by a single low temperature (\(T=0\)) sample for each test problem. Unsurprisingly, we see that the 175B model significantly outperforms the smaller models. Assuming a log-linear trend, we can naively extrapolate these results to estimate that a model with \(10^{16}\) parameters would be required to reach an 80% solve rate, when using the full GSM8K training set. It is even harder to extrapolate along the data dimension, since performance does not appear to follow a log-linear trend. Nevertheless, it appears likely that the 175B model would require at least two additional orders of magnitude of training data to reach an 80% solve rate.

In Figure 3, we show how 6B test performance varies over the course of 100

Figure 3: Test solve rate after finetuning a 6B model on the full GSM8K training set, when the model is allowed to make 1 guess (left) or 100 guesses (right).

training epochs. We use test@N to denote the percentage of problems solved correctly at least once when allowing the model to make N separate guesses for each problem. We use a low temperature (\(T=0\)) to generate test@1 samples and we use a higher temperature (\(T=0.7\)) to generate test@100 samples. Both temperature values were chosen empirically to produce the best results. Test@1 performance improves approximately monotonically, even though we quickly begin overfitting on test loss. Unfortunately, test@100 performance degrades much more sharply than test@1 as we increase the number of epochs. This is to be expected: as the model repeatedly encounters the same data, it becomes increasingly uncalibrated and overconfident in its predictions. At test time, this overconfidence leads to poor coverage of the solution space, an effect which only becomes noticeable when we are considering multiple samples at test time.

Choosing a model with good coverage is critical to successfully train verifiers. Empirically, we see that test@100 performance peaks within the first few epochs. For this reason, we use models trained for 2 epochs to generate samples for training verifiers. We provide several example solutions from 6B and 175B models in Appendix D. We also note that it is important to allow the model to generate the full natural language solution before outputting a final answer. If we instead finetune a 6B model to directly output the final answer without any intermediate steps, performance drops drastically from 20.6% to 5.2%.

### Verification

To improve upon the finetuning baseline, we train verifiers to judge the correctness of model-generated solutions and search against these verifiers at test time. Conditioned on the problem and a candidate solution, the verifier outputs the probability that the solution is correct. Training solutions are labeled as correct or incorrect based solely on whether they reach the correct final answer. In practice, some solutions will reach the correct final answer using flawed reasoning, leading to false positives.

Figure 4: A diagram of the verification training pipeline.

As shown in Figure 4, we train the verifier as follows:

1. Finetune a model (the "generator") for 2 epochs on the training set.
2. Sample 100 completions from the generator for each training problem and label each solution as correct or incorrect.
3. Train a verifier for a single epoch on this dataset.

Training for 2 epochs is enough for the generator to learn basic skills in this domain. We choose not to train for longer, since the diversity of generated solutions begins to collapse after this point, as shown in Figure 3. We train separate generator and verifier models to limit the generator's training and prevent overfitting, but in principle, it should be possible to combine these models. Unless otherwise specified, we use the same model size for the generator and the verifier. In addition to predicting solution correctness, we also train the verifier with the same language modeling objective as the generator. This serves as a valuable auxiliary objective for the verifier. We discuss additional verifier training details in Appendix E.

At test time, we sample 100 completions to each test problem, rank them with the verifier, and then return the one with the highest verifier score. A comparison between verification and finetuning is shown in Figure 5 for both the 6B and 175B model sizes. We find that it is not beneficial to use verification at low dataset sizes. We believe this is due to the pressure to overfit to the correct answer: with small datasets, overfitting to the correct answer happens faster than learning more generalizable properties of correct reasoning. However, once we use a sufficiently large dataset, we see a strong boost from verifiers.

Figure 5: A comparison between finetuning and verification using 6B and 175B model sizes. Verification considers 100 solutions per problem. Mean and standard deviation is shown across 3 runs, except for 175B verification which shows only a single run.

It's interesting to note that the 175B verifiers "take off" earlier than the 6B verifiers, requiring fewer training problems to surpass the finetuning baseline. See Appendix D for example solutions found by verifiers and Appendix F for a visualization of verifier confidence.

### Verification Ablations

We can either train verifiers to make a single scalar prediction conditioned on the entire generated solution, or to make a scalar prediction after each token in the solution. By default, we choose the latter, training verifiers to make predictions after each token. This can be viewed as a token-level value function. We compare these two methods in Figure 5(a), respectively labeled "solution-level" and "token-level".

Predicting the value function at every token is a more challenging and noisier task than judging only the full completion. However, despite the initially slower training, the token-level verifier ultimately outperforms the solution-level verifier. Moreover, the token-level verifier is still improving late in training, whereas the solution-level verifier quickly shows signs of overfitting. We hypothesize that the full value function provides a useful auxiliary signal that encourages the model to judge the reasoning throughout solutions, rather than merely memorizing the correct final answer.

In Figure 5(b), we ablate the objective used when training verifiers. As discussed in Section 4.2, we can optionally include a language modeling objective alongside the verification objective. We compare using both objectives to using only the verification objective. Although both are reasonable choices, including the language modeling objective is a strict improvement. This makes intuitive

Figure 6: Verification ablations

sense: better understanding this language distribution should only aid the verifier in discriminating between samples.

In Figure 5(c), we separately ablate the model size of the generator and the verifier. We find that using a large generator with a small verifier performs significantly better than using a small generator with a large verifier. Verification is still remarkably effective, even when the verifier is much smaller than the generator. This suggests that the verifier may often be relying on relatively coarse heuristics to discriminate between solutions from a given generator, rather than attempting a more thorough form of verification.

## 5 Additional Experiments

### Test Time Compute

At test time, we can choose to generate arbitrarily many solutions to be judged by the verifier before selecting the highest ranked completion. Figure 6(a) shows how 6B verifier performance varies with the number of completions per test problem. At this scale, performance improves as we increase the number of completions up to 400. Beyond this point, performance start to decrease. This suggests that the benefits of search are eventually outweighed by the risk of finding adversarial solutions that fool the verifier. In general, we evaluate verifier test performance using 100 completions, since this captures most of the benefits of verification with a relatively modest compute cost.

To further increase performance, we can take a majority vote among the top verifier-ranked solutions instead of selecting only the single top solution.

Figure 7: Performance as the amount of test time compute varies.

This voting process considers only the final answer reached by the individual solutions: the final answer selected is the one with the most votes. Figure (b)b shows how performance varies as we allow a greater number of top samples to cast a vote. Unsurprisingly, when starting with a greater number of samples, we can afford to allow a greater number of samples to cast a vote. When we have only 100 samples, it is optimal to allow only the top 3-5 samples to cast a vote. When we have 3200 samples, it is approximately optimal to allow the top 30 to cast a vote.

### Regularization

We find that both finetuning and verification strongly benefit from the use of dropout as a regularizer. Specifically, we apply residual dropout (Vaswani et al., 2017) along the residual paths of each layer in the network. We use 20% dropout for all dropout experiments, chosen based on the results of a hyperparameters sweep. We note that GPT-3 models are not pretrained with dropout. For experiments involving dropout, we therefore perform additional pretraining with dropout before subsequently finetuning the models. This mitigates the distribution shift the model experiences during finetuning.

We first investigate the effect of dropout on finetuning across various training set sizes. Figure (a)a shows that dropout leads to a significant improvement over baseline. We next investigate the effect of dropout on verifiers, considering both the solution-level and token-level variants. In Figure (b)b, we see that dropout significantly improves solution-level verifiers, mitigating the overfitting that occurs in the unregularized baseline. Notably, using dropout with solution-level verifiers reaches a similar level of performance as token-level verifiers. In Figure (c)c, we apply dropout to token-level verifiers. Since token-level verifiers are already less susceptible to overfitting, it is no surprise that the impact of dropout is less significant. Nevertheless, we do still see a slight gain from training token-level verifiers with dropout. Note that we increase the batch size for token-level verifiers by a factor of 4, to better handle the more difficult objective and the noise from dropout.

Figure 8: 6B finetuning and verification dropout ablations.

Conclusion

We have seen that verification provides a significant performance boost relative to a finetuning baseline. On the full dataset, 6B verification slightly outperforms a finetuned 175B model, thereby offering a boost approximately equivalent to a 30x model size increase. We have also seen that token-level verifiers are less prone to overfitting than solution-level verifiers, and that all methods benefit from regularization with residual dropout. We expect verification to scale well to problem distributions that require more complex mathematical reasoning, and we hope GSM8K supports the development of new methods that scale even better.

## Acknowledgements

We thank Dan Hendrycks, Leo Gao, Alec Radford, and Giambattista Parasandolo for their valuable feedback on this paper; Harri Edwards, Yura Burda, Michael Wu, and Nick Ryder for many insightful conversations; Michael Petrov, Alethea Power, and Jacob Jackson for their technical assistance; the OpenAI Supercomputing team for the infrastructure that made these experiments possible; and the team at Surge AI for performing the GSM8K data collection.

## References

* Amini et al. [2019] A. Amini, S. Gabriel, P. Lin, R. Koncel-Kedziorski, Y. Choi, and H. Hajishirzi. Mathqa: Towards interpretable math word problem solving with operation-based formalisms. _arXiv preprint arXiv:1905.13319_, 2019.
* Brown et al. [2020] T. B. Brown, B. Mann, N. Ryder, M. Subbiah, J. Kaplan, P. Dhariwal, A. Neelakantan, P. Shyam, G. Sastry, A. Askell, et al. Language models are few-shot learners. _arXiv preprint arXiv:2005.14165_, 2020.
* Chen et al. [2020] K. Chen, Q. Huang, H. Palangi, P. Smolensky, K. D. Forbus, and J. Gao. Mapping natural-language problems to formal-language solutions using structured neural representations. In _ICML_, 2020.
* Chen et al. [2019] X. Chen, C. Liang, A. W. Yu, D. Zhou, D. Song, and Q. V. Le. Neural symbolic reader: Scalable integration of distributed and symbolic representations for reading comprehension. In _International Conference on Learning Representations_, 2019.
* Chiang and Chen [2018] T.-R. Chiang and Y.-N. Chen. Semantically-aligned equation generation for solving and reasoning math word problems. _arXiv preprint arXiv:1811.00720_, 2018.
* Hendrycks et al. [2021] D. Hendrycks, C. Burns, S. Kadavath, A. Arora, S. Basart, E. Tang, D. Song, and J. Steinhardt. Measuring mathematical problem solving with the math dataset. _arXiv preprint arXiv:2103.03874_, 2021.
* H D. Huang, S. Shi, C. Lin, J. Yin, and W.-Y. Ma. How well do computers solve math word problems? large-scale dataset construction and evaluation. In _Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 887-896, 2016.
* Huang et al. (2018) D. Huang, J. Liu, C.-Y. Lin, and J. Yin. Neural math word problem solver with reinforcement learning. In _Proceedings of the 27th International Conference on Computational Linguistics_, pages 213-223, 2018.
* Kaplan et al. (2020) J. Kaplan, S. McCandlish, T. Henighan, T. B. Brown, B. Chess, R. Child, S. Gray, A. Radford, J. Wu, and D. Amodei. Scaling laws for neural language models. _arXiv preprint arXiv:2001.08361_, 2020.
* Kim et al. (2020) B. Kim, K. S. Ki, D. Lee, and G. Gweon. Point to the expression: Solving algebraic word problems using the expression-pointer transformer model. In _Proceedings of the 2020 Conference on Empirical Methods in Natural Language Processing (EMNLP)_, pages 3768-3779, 2020.
* Kushman et al. (2014) N. Kushman, Y. Artzi, L. Zettlemoyer, and R. Barzilay. Learning to automatically solve algebra word problems. In _Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers)_, pages 271-281, 2014.
* Lample and Charton (2019) G. Lample and F. Charton. Deep learning for symbolic mathematics. _arXiv preprint arXiv:1912.01412_, 2019.
* Li et al. (2020) S. Li, L. Wu, S. Feng, F. Xu, F. Xu, and S. Zhong. Graph-to-tree neural networks for learning structured input-output translation with applications to semantic parsing and math word problem. _EMNLP_, 2020.
* Liang et al. (2021) Z. Liang, J. Zhang, J. Shao, and X. Zhang. Mwp-bert: A strong baseline for math word problems, 07 2021.
* Ling et al. (2017) W. Ling, D. Yogatama, C. Dyer, and P. Blunsom. Program induction by rationale generation: Learning to solve and explain algebraic word problems. _arXiv preprint arXiv:1705.04146_, 2017.
* Liu et al. (2020) J. Liu, L. Cui, H. Liu, D. Huang, Y. Wang, and Y. Zhang. Logiqa: A challenge dataset for machine reading comprehension with logical reasoning. In _IJCAI_, 2020.
* Miao et al. (2021) S.-Y. Miao, C.-C. Liang, and K.-Y. Su. A diverse corpus for evaluating and developing english math word problem solvers. _arXiv preprint arXiv:2106.15772_, 2021.
* Nichols et al. (2020) E. Nichols, L. Gao, and R. Gomez. Collaborative storytelling with large-scale neural language models. _arXiv preprint arXiv:2011.10208_, 2020.
* Peng et al. (2021) S. Peng, K. Yuan, L. Gao, and Z. Tang. Mathbert: A pre-trained model for mathematical formula understanding. _ArXiv_, abs/2105.00377, 2021.
* Zhang et al. (2020)S. Roy and D. Roth. Solving general arithmetic word problems. In _Proceedings of the 2015 Conference on Empirical Methods in Natural Language Processing_, pages 1743-1752, Lisbon, Portugal, Sept. 2015. Association for Computational Linguistics. doi: 10.18653/v1/D15-1202. URL [https://aclanthology.org/D15-1202](https://aclanthology.org/D15-1202).
* Shen et al. (2021a) J. Shen, Y. Yin, L. Li, L. Shang, X. Jiang, M. Zhang, and Q. Liu. Generate & rank: A multi-task framework for math word problems. _arXiv preprint arXiv:2109.03034_, 2021a.
* Shen et al. (2021b) J. T. Shen, M. Yamashita, E. Prihar, N. Heffernan, X. Wu, B. Graff, and D. Lee. Mathbert: A pre-trained language model for general nlp tasks in mathematics education, 08 2021b.
* Sutskever et al. (2014) I. Sutskever, O. Vinyals, and Q. V. Le. Sequence to sequence learning with neural networks. In _Advances in neural information processing systems_, pages 3104-3112, 2014.
* Talmor et al. (2018) A. Talmor, J. Herzig, N. Lourie, and J. Berant. Commonsenseqa: A question answering challenge targeting commonsense knowledge. _arXiv preprint arXiv:1811.00937_, 2018.
* Vaswani et al. (2017) A. Vaswani, N. Shazeer, N. Parmar, J. Uszkoreit, L. Jones, A. N. Gomez, L. Kaiser, and I. Polosukhin. Attention is all you need. In _Advances in neural information processing systems_, pages 5998-6008, 2017.
* Wang et al. (2019) A. Wang, Y. Pruksachatkun, N. Nangia, A. Singh, J. Michael, F. Hill, O. Levy, and S. R. Bowman. Superglue: A stickier benchmark for general-purpose language understanding systems. _arXiv preprint arXiv:1905.00537_, 2019.
* Wang et al. (2017) Y. Wang, X. Liu, and S. Shi. Deep neural solver for math word problems. In _Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing_, pages 845-854, Copenhagen, Denmark, Sept. 2017. Association for Computational Linguistics. doi: 10.18653/v1/D17-1088. URL [https://aclanthology.org/D17-1088](https://aclanthology.org/D17-1088).
* Xie and Sun (2019) Z. Xie and S. Sun. A goal-driven tree-structured neural model for math word problems. In _IJCAI_, 2019.
* Zhao et al. (2020) W. Zhao, M. Shang, Y. Liu, L. Wang, and J. Liu. Ape210k: A large-scale and template-rich dataset of math word problems. _arXiv preprint arXiv:2009.11506_, 2020.

Dataset Details

We initially collected a starting set of a thousand problems and natural language solutions by hiring freelance contractors on Upwork (upwork.com). We then worked with Surge AI (surgehq.ai), an NLP data labeling platform, to scale up our data collection. After collecting the full dataset, we asked workers to re-solve all problems, with no workers re-solving problems they originally wrote. We checked whether their final answers agreed with the original solutions, and any problems that produced disagreements were either repaired or discarded. We then performed another round of agreement checks on a smaller subset of problems, finding that 1.7% of problems still produce disagreements among contractors. We estimate this to be the fraction of problems that contain breaking errors or ambiguities. It is possible that a larger percentage of problems contain subtle errors.

To assist contractors with writing questions, we provided seed questions automatically generated from a few-shot prompted 175B GPT-3 model. Contractors were allowed to use those seed questions directly, to use them as inspiration and make modifications, or to come up with their own questions entirely. We instructed contractors to be as descriptive as possible in their solutions, and to not re-use problem settings or templates between different questions. To ensure contractors were not re-using problem templates, we computed pairwise similarity scores between problems and used this to provide feedback to contractors.

Hyperparameters

We include a table of important hyperparameters below. We performed sweeps of the learning rate and batch size by an order of magnitude in both directions from the values in the table and were unable to find any significant improvements. Other reasonable choices for both the verifier temperature (eg: 1.0 instead of 0.7) and objective (cross-entropy instead of mean squared error) also had negligible effect in our ablations.

